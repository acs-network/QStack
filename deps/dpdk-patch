diff --git a/.gitattributes b/.gitattributes
deleted file mode 100644
index fe555f8..0000000
--- a/.gitattributes
+++ /dev/null
@@ -1,3 +0,0 @@
-*.c   diff=cpp
-*.h   diff=cpp
-*.py  diff=python
diff --git a/.gitignore b/.gitignore
deleted file mode 100644
index 6df5ba0..0000000
--- a/.gitignore
+++ /dev/null
@@ -1,14 +0,0 @@
-doc/guides/nics/overview_table.txt
-doc/guides/cryptodevs/overview_feature_table.txt
-doc/guides/cryptodevs/overview_cipher_table.txt
-doc/guides/cryptodevs/overview_auth_table.txt
-doc/guides/cryptodevs/overview_aead_table.txt
-cscope.out.po
-cscope.out.in
-cscope.out
-cscope.files
-GTAGS
-GPATH
-GRTAGS
-tags
-TAGS
diff --git a/README b/README
index 55df158..04d0841 100644
--- a/README
+++ b/README
@@ -9,3 +9,5 @@ API documentation, and sample application information.
 
 For questions and usage discussions, subscribe to: users@dpdk.org
 Report bugs and issues to the development mailing list: dev@dpdk.org
+
+18.02.2
diff --git a/config/common_base b/config/common_base
index 20d4cbc..85218ff 100644
--- a/config/common_base
+++ b/config/common_base
@@ -538,7 +538,7 @@ CONFIG_RTE_LIBRTE_PMD_MRVL_CRYPTO_DEBUG=n
 #
 # Compile generic security library
 #
-CONFIG_RTE_LIBRTE_SECURITY=y
+#CONFIG_RTE_LIBRTE_SECURITY=y
 
 #
 # Compile generic event device library
@@ -597,7 +597,7 @@ CONFIG_RTE_RING_USE_C11_MEM_MODEL=n
 # Compile librte_mempool
 #
 CONFIG_RTE_LIBRTE_MEMPOOL=y
-CONFIG_RTE_MEMPOOL_CACHE_MAX_SIZE=512
+CONFIG_RTE_MEMPOOL_CACHE_MAX_SIZE=100000
 CONFIG_RTE_LIBRTE_MEMPOOL_DEBUG=n
 
 #
@@ -620,6 +620,12 @@ CONFIG_RTE_MBUF_DEFAULT_MEMPOOL_OPS="ring_mp_mc"
 CONFIG_RTE_MBUF_REFCNT_ATOMIC=y
 CONFIG_RTE_PKTMBUF_HEADROOM=128
 
+
+#
+# Compile circular queue
+#
+CONFIG_RTE_CIRCULAR_QUEUE=y
+
 #
 # Compile librte_timer
 #
diff --git a/config/rte_config.h b/config/rte_config.h
index 08bcb1c..ec7b364 100644
--- a/config/rte_config.h
+++ b/config/rte_config.h
@@ -34,7 +34,7 @@
 #define RTE_CONTIGMEM_DEFAULT_BUF_SIZE (512*1024*1024)
 
 /* mempool defines */
-#define RTE_MEMPOOL_CACHE_MAX_SIZE 512
+#define RTE_MEMPOOL_CACHE_MAX_SIZE 1000000
 
 /* mbuf defines */
 #define RTE_MBUF_DEFAULT_MEMPOOL_OPS "ring_mp_mc"
diff --git a/drivers/net/e1000/Makefile b/drivers/net/e1000/Makefile
index 9c87e88..341f141 100644
--- a/drivers/net/e1000/Makefile
+++ b/drivers/net/e1000/Makefile
@@ -8,7 +8,7 @@ include $(RTE_SDK)/mk/rte.vars.mk
 #
 LIB = librte_pmd_e1000.a
 
-CFLAGS += -O3
+CFLAGS += -O3 -g
 CFLAGS += $(WERROR_FLAGS)
 LDLIBS += -lrte_eal -lrte_mbuf -lrte_mempool -lrte_ring
 LDLIBS += -lrte_ethdev -lrte_net -lrte_kvargs
diff --git a/drivers/net/ixgbe/Makefile b/drivers/net/ixgbe/Makefile
index f8cad12..f3eae62 100644
--- a/drivers/net/ixgbe/Makefile
+++ b/drivers/net/ixgbe/Makefile
@@ -10,6 +10,7 @@ LIB = librte_pmd_ixgbe.a
 
 CFLAGS += -DALLOW_EXPERIMENTAL_API
 CFLAGS += -O3
+CFLAGS += -g
 CFLAGS += $(WERROR_FLAGS)
 
 EXPORT_MAP := rte_pmd_ixgbe_version.map
diff --git a/drivers/net/ixgbe/ixgbe_ethdev.h b/drivers/net/ixgbe/ixgbe_ethdev.h
index c56d652..14345fa 100644
--- a/drivers/net/ixgbe/ixgbe_ethdev.h
+++ b/drivers/net/ixgbe/ixgbe_ethdev.h
@@ -752,4 +752,32 @@ int ixgbe_config_rss_filter(struct rte_eth_dev *dev,
 	return idx;
 }
 
+#if 0
+static inline void 
+ixgbe_get_start_ave_time(struct dpdk_private_context *dpc)
+{
+	dpc->check_last_time = rte_rdtsc_precise();
+} 
+
+
+static inline int 
+ixgbe_get_end_ave_time(struct dpdk_private_context *dpc)
+{
+
+	long int timer = 0;
+	int count = dpc->check_time;
+    dpc->check_time++;
+	dpc->check_total_time = dpc->check_total_time +  rte_rdtsc_precise() - dpc->check_last_time;
+	dpc->check_last_time = 0;
+	if(dpc->check_time == 1000000)
+	{
+        timer = (dpc->check_total_time * 1000000000) / ((double)rte_get_tsc_hz()* dpc->check_time);
+	    fprintf(stderr,"xdma time is %ld ns and dpc->check_time is %d , dpc->check_total_time is%ld \n",timer,dpc->check_time,dpc->check_total_time );
+	    dpc->check_time = 0;
+		dpc->check_total_time = 0;
+	}
+
+	return timer;
+}
+#endif
 #endif /* _IXGBE_ETHDEV_H_ */
diff --git a/drivers/net/ixgbe/ixgbe_rxtx.c b/drivers/net/ixgbe/ixgbe_rxtx.c
index 6c582b4..c659750 100644
--- a/drivers/net/ixgbe/ixgbe_rxtx.c
+++ b/drivers/net/ixgbe/ixgbe_rxtx.c
@@ -120,10 +120,15 @@ uint16_t ixgbe_xmit_fixed_burst_vec(void *tx_queue, struct rte_mbuf **tx_pkts,
 	for (i = 0; i < txq->tx_rs_thresh; ++i, ++txep) {
 		/* free buffers one at a time */
 		m = rte_pktmbuf_prefree_seg(txep->mbuf);
+		
 		txep->mbuf = NULL;
-
+		if(m->udata64 == 2)
+		{
+			continue;
+		}
 		if (unlikely(m == NULL))
 			continue;
+		
 
 		if (nb_free >= RTE_IXGBE_TX_MAX_FREE_BUF_SZ ||
 		    (nb_free > 0 && m->pool != free[0]->pool)) {
@@ -853,7 +858,10 @@ uint16_t ixgbe_xmit_fixed_burst_vec(void *tx_queue, struct rte_mbuf **tx_pkts,
 				rte_prefetch0(&txn->mbuf->pool);
 
 				if (txe->mbuf != NULL) {
-					rte_pktmbuf_free_seg(txe->mbuf);
+				//zz 1
+					if(txe->mbuf->pool->private_type != 2 ){
+						rte_pktmbuf_free_seg(txe->mbuf);
+					}
 					txe->mbuf = NULL;
 				}
 
@@ -887,8 +895,15 @@ uint16_t ixgbe_xmit_fixed_burst_vec(void *tx_queue, struct rte_mbuf **tx_pkts,
 			txn = &sw_ring[txe->next_id];
 			rte_prefetch0(&txn->mbuf->pool);
 
-			if (txe->mbuf != NULL)
-				rte_pktmbuf_free_seg(txe->mbuf);
+			if (txe->mbuf != NULL) {
+				//zz 2
+				
+				if(txe->mbuf->pool->private_type != 2 ){
+			//	if(txe->mbuf->udata64 != 2 ){
+					rte_pktmbuf_free_seg(txe->mbuf);
+				}
+				txe->mbuf = NULL;
+			}
 			txe->mbuf = m_seg;
 
 			/*
diff --git a/drivers/net/ixgbe/ixgbe_rxtx.h b/drivers/net/ixgbe/ixgbe_rxtx.h
index 69c718b..84debbd 100644
--- a/drivers/net/ixgbe/ixgbe_rxtx.h
+++ b/drivers/net/ixgbe/ixgbe_rxtx.h
@@ -27,14 +27,14 @@
 #define	IXGBE_MIN_RING_DESC	32
 #define	IXGBE_MAX_RING_DESC	4096
 
-#define RTE_PMD_IXGBE_TX_MAX_BURST 32
-#define RTE_PMD_IXGBE_RX_MAX_BURST 32
-#define RTE_IXGBE_TX_MAX_FREE_BUF_SZ 64
+#define RTE_PMD_IXGBE_TX_MAX_BURST 1024
+#define RTE_PMD_IXGBE_RX_MAX_BURST 1024
+#define RTE_IXGBE_TX_MAX_FREE_BUF_SZ 128
 
 #define RTE_IXGBE_DESCS_PER_LOOP    4
 
 #ifdef RTE_IXGBE_INC_VECTOR
-#define RTE_IXGBE_RXQ_REARM_THRESH      32
+#define RTE_IXGBE_RXQ_REARM_THRESH      64
 #define RTE_IXGBE_MAX_RX_BURST          RTE_IXGBE_RXQ_REARM_THRESH
 #endif
 
diff --git a/examples/Makefile b/examples/Makefile
deleted file mode 100644
index 17ecf7f..0000000
--- a/examples/Makefile
+++ /dev/null
@@ -1,108 +0,0 @@
-#   BSD LICENSE
-#
-#   Copyright(c) 2016 6WIND S.A.
-#
-#   Redistribution and use in source and binary forms, with or without
-#   modification, are permitted provided that the following conditions
-#   are met:
-#
-#     * Redistributions of source code must retain the above copyright
-#       notice, this list of conditions and the following disclaimer.
-#     * Redistributions in binary form must reproduce the above copyright
-#       notice, this list of conditions and the following disclaimer in
-#       the documentation and/or other materials provided with the
-#       distribution.
-#     * Neither the name of 6WIND S.A. nor the names of its
-#       contributors may be used to endorse or promote products derived
-#       from this software without specific prior written permission.
-#
-#   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-#   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-#   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-#   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-#   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-#   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-#   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-#   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-#   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-#   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-#   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-DIRS-$(CONFIG_RTE_LIBRTE_BBDEV) += bbdev_app
-DIRS-$(CONFIG_RTE_LIBRTE_PMD_BOND) += bond
-DIRS-y += cmdline
-DIRS-$(CONFIG_RTE_LIBRTE_DISTRIBUTOR) += distributor
-DIRS-y += ethtool
-DIRS-y += exception_path
-DIRS-$(CONFIG_RTE_LIBRTE_EFD) += server_node_efd
-DIRS-$(CONFIG_RTE_LIBRTE_FLOW_CLASSIFY) += flow_classify
-DIRS-y += flow_filtering
-DIRS-y += helloworld
-DIRS-$(CONFIG_RTE_LIBRTE_PIPELINE) += ip_pipeline
-ifeq ($(CONFIG_RTE_LIBRTE_LPM),y)
-DIRS-$(CONFIG_RTE_IP_FRAG) += ip_reassembly
-DIRS-$(CONFIG_RTE_IP_FRAG) += ip_fragmentation
-endif
-ifeq ($(CONFIG_RTE_LIBRTE_ACL)$(CONFIG_RTE_LIBRTE_HASH)$(CONFIG_RTE_LIBRTE_LPM)$(CONFIG_RTE_LIBRTE_SECURITY),yyyy)
-DIRS-$(CONFIG_RTE_LIBRTE_CRYPTODEV) += ipsec-secgw
-endif
-DIRS-$(CONFIG_RTE_LIBRTE_HASH) += ipv4_multicast
-DIRS-$(CONFIG_RTE_LIBRTE_KNI) += kni
-DIRS-y += l2fwd
-ifneq ($(PQOS_INSTALL_PATH),)
-DIRS-y += l2fwd-cat
-endif
-DIRS-$(CONFIG_RTE_LIBRTE_CRYPTODEV) += l2fwd-crypto
-DIRS-$(CONFIG_RTE_LIBRTE_JOBSTATS) += l2fwd-jobstats
-DIRS-y += l2fwd-keepalive
-DIRS-y += l2fwd-keepalive/ka-agent
-ifeq ($(CONFIG_RTE_LIBRTE_HASH),y)
-DIRS-$(CONFIG_RTE_LIBRTE_LPM) += l3fwd
-endif
-DIRS-$(CONFIG_RTE_LIBRTE_ACL) += l3fwd-acl
-ifeq ($(CONFIG_RTE_LIBRTE_LPM)$(CONFIG_RTE_LIBRTE_HASH),yy)
-DIRS-$(CONFIG_RTE_LIBRTE_POWER) += l3fwd-power
-DIRS-y += l3fwd-vf
-endif
-DIRS-y += link_status_interrupt
-DIRS-$(CONFIG_RTE_LIBRTE_LPM) += load_balancer
-DIRS-y += multi_process
-DIRS-y += netmap_compat/bridge
-DIRS-$(CONFIG_RTE_LIBRTE_REORDER) += packet_ordering
-ifeq ($(CONFIG_RTE_ARCH_X86_64),y)
-DIRS-y += performance-thread
-endif
-DIRS-$(CONFIG_RTE_LIBRTE_IEEE1588) += ptpclient
-DIRS-$(CONFIG_RTE_LIBRTE_METER) += qos_meter
-DIRS-$(CONFIG_RTE_LIBRTE_SCHED) += qos_sched
-DIRS-y += quota_watermark
-DIRS-$(CONFIG_RTE_ETHDEV_RXTX_CALLBACKS) += rxtx_callbacks
-DIRS-y += service_cores
-DIRS-y += skeleton
-ifeq ($(CONFIG_RTE_LIBRTE_HASH),y)
-DIRS-$(CONFIG_RTE_LIBRTE_VHOST) += tep_termination
-endif
-DIRS-$(CONFIG_RTE_LIBRTE_TIMER) += timer
-DIRS-$(CONFIG_RTE_LIBRTE_VHOST) += vhost vhost_scsi
-DIRS-y += vmdq
-DIRS-y += vmdq_dcb
-ifeq ($(CONFIG_RTE_LIBRTE_POWER), y)
-ifeq ($(shell pkg-config --atleast-version=0.9.3 libvirt; echo $$?), 0)
-DIRS-y += vm_power_manager
-else
-$(info vm_power_manager requires libvirt >= 0.9.3)
-endif
-endif
-
-DIRS-y += eventdev_pipeline
-
-include $(RTE_SDK)/mk/rte.extsubdir.mk
diff --git a/examples/bbdev_app/Makefile b/examples/bbdev_app/Makefile
deleted file mode 100644
index 18dd99d..0000000
--- a/examples/bbdev_app/Makefile
+++ /dev/null
@@ -1,59 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# binary name
-APP = bbdev
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-
-endif
diff --git a/examples/bbdev_app/main.c b/examples/bbdev_app/main.c
deleted file mode 100644
index 254cc06..0000000
--- a/examples/bbdev_app/main.c
+++ /dev/null
@@ -1,1160 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2017 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <string.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <sys/types.h>
-#include <sys/unistd.h>
-#include <sys/queue.h>
-#include <stdarg.h>
-#include <ctype.h>
-#include <errno.h>
-#include <math.h>
-#include <assert.h>
-#include <getopt.h>
-#include <signal.h>
-
-#include "rte_atomic.h"
-#include "rte_common.h"
-#include "rte_eal.h"
-#include "rte_cycles.h"
-#include "rte_ether.h"
-#include "rte_ethdev.h"
-#include "rte_ip.h"
-#include "rte_lcore.h"
-#include "rte_malloc.h"
-#include "rte_mbuf.h"
-#include "rte_memory.h"
-#include "rte_mempool.h"
-#include "rte_log.h"
-#include "rte_bbdev.h"
-#include "rte_bbdev_op.h"
-
-/* LLR values - negative value for '1' bit */
-#define LLR_1_BIT 0x81
-#define LLR_0_BIT 0x7F
-
-#define MAX_PKT_BURST 32
-#define NB_MBUF 8191
-#define MEMPOOL_CACHE_SIZE 256
-
-/* Hardcoded K value */
-#define K 40
-#define NCB (3 * RTE_ALIGN_CEIL(K + 4, 32))
-
-#define CRC_24B_LEN 3
-
-/* Configurable number of RX/TX ring descriptors */
-#define RTE_TEST_RX_DESC_DEFAULT 128
-#define RTE_TEST_TX_DESC_DEFAULT 512
-
-#define BBDEV_ASSERT(a) do { \
-	if (!(a)) { \
-		usage(prgname); \
-		return -1; \
-	} \
-} while (0)
-
-static const struct rte_eth_conf port_conf = {
-	.rxmode = {
-		.mq_mode = ETH_MQ_RX_NONE,
-		.max_rx_pkt_len = ETHER_MAX_LEN,
-		.split_hdr_size = 0,
-		.header_split = 0, /**< Header Split disabled */
-		.hw_ip_checksum = 0, /**< IP checksum offload disabled */
-		.hw_vlan_filter = 0, /**< VLAN filtering disabled */
-		.jumbo_frame = 0, /**< Jumbo Frame Support disabled */
-		.hw_strip_crc = 0, /**< CRC stripped by hardware */
-	},
-	.txmode = {
-		.mq_mode = ETH_MQ_TX_NONE,
-	},
-};
-
-struct rte_bbdev_op_turbo_enc def_op_enc = {
-	/* These values are arbitrarily put, and does not map to the real
-	 * values for the data received from ethdev ports
-	 */
-	.rv_index = 0,
-	.code_block_mode = 1,
-	.cb_params = {
-		.k = K,
-	},
-	.op_flags = RTE_BBDEV_TURBO_CRC_24A_ATTACH
-};
-
-struct rte_bbdev_op_turbo_dec def_op_dec = {
-	/* These values are arbitrarily put, and does not map to the real
-	 * values for the data received from ethdev ports
-	 */
-	.code_block_mode = 1,
-	.cb_params = {
-		.k = K,
-	},
-	.rv_index = 0,
-	.iter_max = 8,
-	.iter_min = 4,
-	.ext_scale = 15,
-	.num_maps = 0,
-	.op_flags = RTE_BBDEV_TURBO_NEG_LLR_1_BIT_IN
-};
-
-struct app_config_params {
-	/* Placeholders for app params */
-	uint16_t port_id;
-	uint16_t bbdev_id;
-	uint64_t enc_core_mask;
-	uint64_t dec_core_mask;
-
-	/* Values filled during init time */
-	uint16_t enc_queue_ids[RTE_MAX_LCORE];
-	uint16_t dec_queue_ids[RTE_MAX_LCORE];
-	uint16_t num_enc_cores;
-	uint16_t num_dec_cores;
-};
-
-struct lcore_statistics {
-	unsigned int enqueued;
-	unsigned int dequeued;
-	unsigned int rx_lost_packets;
-	unsigned int enc_to_dec_lost_packets;
-	unsigned int tx_lost_packets;
-} __rte_cache_aligned;
-
-/** each lcore configuration */
-struct lcore_conf {
-	uint64_t core_type;
-
-	unsigned int port_id;
-	unsigned int rx_queue_id;
-	unsigned int tx_queue_id;
-
-	unsigned int bbdev_id;
-	unsigned int enc_queue_id;
-	unsigned int dec_queue_id;
-
-	uint8_t llr_temp_buf[NCB];
-
-	struct rte_mempool *bbdev_dec_op_pool;
-	struct rte_mempool *bbdev_enc_op_pool;
-	struct rte_mempool *enc_out_pool;
-	struct rte_ring *enc_to_dec_ring;
-
-	struct lcore_statistics *lcore_stats;
-} __rte_cache_aligned;
-
-struct stats_lcore_params {
-	struct lcore_conf *lconf;
-	struct app_config_params *app_params;
-};
-
-
-static const struct app_config_params def_app_config = {
-	.port_id = 0,
-	.bbdev_id = 0,
-	.enc_core_mask = 0x2,
-	.dec_core_mask = 0x4,
-	.num_enc_cores = 1,
-	.num_dec_cores = 1,
-};
-
-static rte_atomic16_t global_exit_flag;
-
-/* display usage */
-static inline void
-usage(const char *prgname)
-{
-	printf("%s [EAL options] "
-			"  --\n"
-			"  --enc_cores - number of encoding cores (default = 0x2)\n"
-			"  --dec_cores - number of decoding cores (default = 0x4)\n"
-			"  --port_id - Ethernet port ID (default = 0)\n"
-			"  --bbdev_id - BBDev ID (default = 0)\n"
-			"\n", prgname);
-}
-
-/* parse core mask */
-static inline
-uint16_t bbdev_parse_mask(const char *mask)
-{
-	char *end = NULL;
-	unsigned long pm;
-
-	/* parse hexadecimal string */
-	pm = strtoul(mask, &end, 16);
-	if ((mask[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return 0;
-
-	return pm;
-}
-
-/* parse core mask */
-static inline
-uint16_t bbdev_parse_number(const char *mask)
-{
-	char *end = NULL;
-	unsigned long pm;
-
-	/* parse hexadecimal string */
-	pm = strtoul(mask, &end, 10);
-	if ((mask[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return 0;
-
-	return pm;
-}
-
-static int
-bbdev_parse_args(int argc, char **argv,
-		struct app_config_params *app_params)
-{
-	int optind = 0;
-	int opt;
-	int opt_indx = 0;
-	char *prgname = argv[0];
-
-	static struct option lgopts[] = {
-		{ "enc_core_mask", required_argument, 0, 'e' },
-		{ "dec_core_mask", required_argument, 0, 'd' },
-		{ "port_id", required_argument, 0, 'p' },
-		{ "bbdev_id", required_argument, 0, 'b' },
-		{ NULL, 0, 0, 0 }
-	};
-
-	BBDEV_ASSERT(argc != 0);
-	BBDEV_ASSERT(argv != NULL);
-	BBDEV_ASSERT(app_params != NULL);
-
-	while ((opt = getopt_long(argc, argv, "e:d:p:b:", lgopts, &opt_indx)) !=
-		EOF) {
-		switch (opt) {
-		case 'e':
-			app_params->enc_core_mask =
-				bbdev_parse_mask(optarg);
-			if (app_params->enc_core_mask == 0) {
-				usage(prgname);
-				return -1;
-			}
-			app_params->num_enc_cores =
-				__builtin_popcount(app_params->enc_core_mask);
-			break;
-
-		case 'd':
-			app_params->dec_core_mask =
-				bbdev_parse_mask(optarg);
-			if (app_params->dec_core_mask == 0) {
-				usage(prgname);
-				return -1;
-			}
-			app_params->num_dec_cores =
-				__builtin_popcount(app_params->dec_core_mask);
-			break;
-
-		case 'p':
-			app_params->port_id = bbdev_parse_number(optarg);
-			break;
-
-		case 'b':
-			app_params->bbdev_id = bbdev_parse_number(optarg);
-			break;
-
-		default:
-			usage(prgname);
-			return -1;
-		}
-	}
-	optind = 0;
-	return optind;
-}
-
-static void
-signal_handler(int signum)
-{
-	printf("\nSignal %d received\n", signum);
-	rte_atomic16_set(&global_exit_flag, 1);
-}
-
-static void
-print_mac(unsigned int portid, struct ether_addr *bbdev_ports_eth_address)
-{
-	printf("Port %u, MAC address: %02X:%02X:%02X:%02X:%02X:%02X\n\n",
-			(unsigned int) portid,
-			bbdev_ports_eth_address->addr_bytes[0],
-			bbdev_ports_eth_address->addr_bytes[1],
-			bbdev_ports_eth_address->addr_bytes[2],
-			bbdev_ports_eth_address->addr_bytes[3],
-			bbdev_ports_eth_address->addr_bytes[4],
-			bbdev_ports_eth_address->addr_bytes[5]);
-}
-
-static inline void
-pktmbuf_free_bulk(struct rte_mbuf **mbufs, unsigned int nb_to_free)
-{
-	unsigned int i;
-	for (i = 0; i < nb_to_free; ++i)
-		rte_pktmbuf_free(mbufs[i]);
-}
-
-static inline void
-pktmbuf_userdata_free_bulk(struct rte_mbuf **mbufs, unsigned int nb_to_free)
-{
-	unsigned int i;
-	for (i = 0; i < nb_to_free; ++i) {
-		struct rte_mbuf *rx_pkt = mbufs[i]->userdata;
-		rte_pktmbuf_free(rx_pkt);
-		rte_pktmbuf_free(mbufs[i]);
-	}
-}
-
-/* Check the link status of all ports in up to 9s, and print them finally */
-static int
-check_port_link_status(uint16_t port_id)
-{
-#define CHECK_INTERVAL 100 /* 100ms */
-#define MAX_CHECK_TIME 90 /* 9s (90 * 100ms) in total */
-	uint8_t count;
-	struct rte_eth_link link;
-
-	printf("\nChecking link status.");
-	fflush(stdout);
-
-	for (count = 0; count <= MAX_CHECK_TIME &&
-			!rte_atomic16_read(&global_exit_flag); count++) {
-		memset(&link, 0, sizeof(link));
-		rte_eth_link_get_nowait(port_id, &link);
-
-		if (link.link_status) {
-			const char *dp = (link.link_duplex ==
-				ETH_LINK_FULL_DUPLEX) ?
-				"full-duplex" : "half-duplex";
-			printf("\nPort %u Link Up - speed %u Mbps - %s\n",
-				port_id, link.link_speed, dp);
-			return 0;
-		}
-		printf(".");
-		fflush(stdout);
-		rte_delay_ms(CHECK_INTERVAL);
-	}
-
-	printf("\nPort %d Link Down\n", port_id);
-	return 0;
-}
-
-static inline void
-add_ether_hdr(struct rte_mbuf *pkt_src, struct rte_mbuf *pkt_dst)
-{
-	struct ether_hdr *eth_from;
-	struct ether_hdr *eth_to;
-
-	eth_from = rte_pktmbuf_mtod(pkt_src, struct ether_hdr *);
-	eth_to = rte_pktmbuf_mtod(pkt_dst, struct ether_hdr *);
-
-	/* copy header */
-	rte_memcpy(eth_to, eth_from, sizeof(struct ether_hdr));
-}
-
-static inline void
-add_awgn(struct rte_mbuf **mbufs, uint16_t num_pkts)
-{
-	RTE_SET_USED(mbufs);
-	RTE_SET_USED(num_pkts);
-}
-
-/* Encoder output to Decoder input adapter. The Decoder accepts only soft input
- * so each bit of the encoder output must be translated into one byte of LLR. If
- * Sub-block Deinterleaver is bypassed, which is the case, the padding bytes
- * must additionally be insterted at the end of each sub-block.
- */
-static inline void
-transform_enc_out_dec_in(struct rte_mbuf **mbufs, uint8_t *temp_buf,
-		uint16_t num_pkts, uint16_t k)
-{
-	uint16_t i, l, j;
-	uint16_t start_bit_idx;
-	uint16_t out_idx;
-	uint16_t d = k + 4;
-	uint16_t kpi = RTE_ALIGN_CEIL(d, 32);
-	uint16_t nd = kpi - d;
-	uint16_t ncb = 3 * kpi;
-
-	for (i = 0; i < num_pkts; ++i) {
-		uint16_t pkt_data_len = rte_pktmbuf_data_len(mbufs[i]) -
-				sizeof(struct ether_hdr);
-
-		/* Resize the packet if needed */
-		if (pkt_data_len < ncb) {
-			char *data = rte_pktmbuf_append(mbufs[i],
-					ncb - pkt_data_len);
-			if (data == NULL)
-				printf(
-					"Not enough space in decoder input packet");
-		}
-
-		/* Translate each bit into 1 LLR byte. */
-		start_bit_idx = 0;
-		out_idx = 0;
-		for (j = 0; j < 3; ++j) {
-			for (l = start_bit_idx; l < start_bit_idx + d; ++l) {
-				uint8_t *data = rte_pktmbuf_mtod_offset(
-					mbufs[i], uint8_t *,
-					sizeof(struct ether_hdr) + (l >> 3));
-				if (*data & (0x80 >> (l & 7)))
-					temp_buf[out_idx] = LLR_1_BIT;
-				else
-					temp_buf[out_idx] = LLR_0_BIT;
-				++out_idx;
-			}
-			/* Padding bytes should be at the end of the sub-block.
-			 */
-			memset(&temp_buf[out_idx], 0, nd);
-			out_idx += nd;
-			start_bit_idx += d;
-		}
-
-		rte_memcpy(rte_pktmbuf_mtod_offset(mbufs[i], uint8_t *,
-				sizeof(struct ether_hdr)), temp_buf, ncb);
-	}
-}
-
-static inline void
-verify_data(struct rte_mbuf **mbufs, uint16_t num_pkts)
-{
-	uint16_t i;
-	for (i = 0; i < num_pkts; ++i) {
-		struct rte_mbuf *out = mbufs[i];
-		struct rte_mbuf *in = out->userdata;
-
-		if (memcmp(rte_pktmbuf_mtod_offset(in, uint8_t *,
-				sizeof(struct ether_hdr)),
-				rte_pktmbuf_mtod_offset(out, uint8_t *,
-				sizeof(struct ether_hdr)),
-				K / 8 - CRC_24B_LEN))
-			printf("Input and output buffers are not equal!\n");
-	}
-}
-
-static int
-initialize_ports(struct app_config_params *app_params,
-		struct rte_mempool *ethdev_mbuf_mempool)
-{
-	int ret;
-	uint16_t port_id = app_params->port_id;
-	uint16_t q;
-	/* ethernet addresses of ports */
-	struct ether_addr bbdev_port_eth_addr;
-
-	/* initialize ports */
-	printf("\nInitializing port %u...\n", app_params->port_id);
-	ret = rte_eth_dev_configure(port_id, app_params->num_enc_cores,
-		app_params->num_dec_cores, &port_conf);
-
-	if (ret < 0) {
-		printf("Cannot configure device: err=%d, port=%u\n",
-			ret, port_id);
-		return -1;
-	}
-
-	/* initialize RX queues for encoder */
-	for (q = 0; q < app_params->num_enc_cores; q++) {
-		ret = rte_eth_rx_queue_setup(port_id, q,
-			RTE_TEST_RX_DESC_DEFAULT,
-			rte_eth_dev_socket_id(port_id),
-			NULL, ethdev_mbuf_mempool);
-		if (ret < 0) {
-			printf("rte_eth_rx_queue_setup: err=%d, queue=%u\n",
-				ret, q);
-			return -1;
-		}
-	}
-	/* initialize TX queues for decoder */
-	for (q = 0; q < app_params->num_dec_cores; q++) {
-		ret = rte_eth_tx_queue_setup(port_id, q,
-			RTE_TEST_TX_DESC_DEFAULT,
-			rte_eth_dev_socket_id(port_id), NULL);
-		if (ret < 0) {
-			printf("rte_eth_tx_queue_setup: err=%d, queue=%u\n",
-				ret, q);
-			return -1;
-		}
-	}
-
-	rte_eth_promiscuous_enable(port_id);
-
-	rte_eth_macaddr_get(port_id, &bbdev_port_eth_addr);
-	print_mac(port_id, &bbdev_port_eth_addr);
-
-	return 0;
-}
-
-static void
-lcore_conf_init(struct app_config_params *app_params,
-		struct lcore_conf *lcore_conf,
-		struct rte_mempool **bbdev_op_pools,
-		struct rte_mempool *bbdev_mbuf_mempool,
-		struct rte_ring *enc_to_dec_ring,
-		struct lcore_statistics *lcore_stats)
-{
-	unsigned int lcore_id;
-	struct lcore_conf *lconf;
-	uint16_t rx_queue_id = 0;
-	uint16_t tx_queue_id = 0;
-	uint16_t enc_q_id = 0;
-	uint16_t dec_q_id = 0;
-
-	/* Configure lcores */
-	for (lcore_id = 0; lcore_id < 8 * sizeof(uint64_t); ++lcore_id) {
-		lconf = &lcore_conf[lcore_id];
-		lconf->core_type = 0;
-
-		if ((1ULL << lcore_id) & app_params->enc_core_mask) {
-			lconf->core_type |= (1 << RTE_BBDEV_OP_TURBO_ENC);
-			lconf->rx_queue_id = rx_queue_id++;
-			lconf->enc_queue_id =
-					app_params->enc_queue_ids[enc_q_id++];
-		}
-
-		if ((1ULL << lcore_id) & app_params->dec_core_mask) {
-			lconf->core_type |= (1 << RTE_BBDEV_OP_TURBO_DEC);
-			lconf->tx_queue_id = tx_queue_id++;
-			lconf->dec_queue_id =
-					app_params->dec_queue_ids[dec_q_id++];
-		}
-
-		lconf->bbdev_enc_op_pool =
-				bbdev_op_pools[RTE_BBDEV_OP_TURBO_ENC];
-		lconf->bbdev_dec_op_pool =
-				bbdev_op_pools[RTE_BBDEV_OP_TURBO_DEC];
-		lconf->bbdev_id = app_params->bbdev_id;
-		lconf->port_id = app_params->port_id;
-		lconf->enc_out_pool = bbdev_mbuf_mempool;
-		lconf->enc_to_dec_ring = enc_to_dec_ring;
-		lconf->lcore_stats = &lcore_stats[lcore_id];
-	}
-}
-
-static void
-print_lcore_stats(struct lcore_statistics *lstats, unsigned int lcore_id)
-{
-	static const char *stats_border = "_______";
-
-	printf("\nLcore %d: %s enqueued count:\t\t%u\n",
-			lcore_id, stats_border, lstats->enqueued);
-	printf("Lcore %d: %s dequeued count:\t\t%u\n",
-			lcore_id, stats_border, lstats->dequeued);
-	printf("Lcore %d: %s RX lost packets count:\t\t%u\n",
-			lcore_id, stats_border, lstats->rx_lost_packets);
-	printf("Lcore %d: %s encoder-to-decoder lost count:\t%u\n",
-			lcore_id, stats_border,
-			lstats->enc_to_dec_lost_packets);
-	printf("Lcore %d: %s TX lost packets count:\t\t%u\n",
-			lcore_id, stats_border, lstats->tx_lost_packets);
-}
-
-static void
-print_stats(struct stats_lcore_params *stats_lcore)
-{
-	unsigned int l_id;
-	unsigned int bbdev_id = stats_lcore->app_params->bbdev_id;
-	unsigned int port_id = stats_lcore->app_params->port_id;
-	int len, ret, i;
-
-	struct rte_eth_xstat *xstats;
-	struct rte_eth_xstat_name *xstats_names;
-	struct rte_bbdev_stats bbstats;
-	static const char *stats_border = "_______";
-
-	const char clr[] = { 27, '[', '2', 'J', '\0' };
-	const char topLeft[] = { 27, '[', '1', ';', '1', 'H', '\0' };
-
-	/* Clear screen and move to top left */
-	printf("%s%s", clr, topLeft);
-
-	printf("PORT STATISTICS:\n================\n");
-	len = rte_eth_xstats_get(port_id, NULL, 0);
-	if (len < 0)
-		rte_exit(EXIT_FAILURE,
-				"rte_eth_xstats_get(%u) failed: %d", port_id,
-				len);
-
-	xstats = calloc(len, sizeof(*xstats));
-	if (xstats == NULL)
-		rte_exit(EXIT_FAILURE,
-				"Failed to calloc memory for xstats");
-
-	ret = rte_eth_xstats_get(port_id, xstats, len);
-	if (ret < 0 || ret > len) {
-		free(xstats);
-		rte_exit(EXIT_FAILURE,
-				"rte_eth_xstats_get(%u) len%i failed: %d",
-				port_id, len, ret);
-	}
-
-	xstats_names = calloc(len, sizeof(*xstats_names));
-	if (xstats_names == NULL) {
-		free(xstats);
-		rte_exit(EXIT_FAILURE,
-				"Failed to calloc memory for xstats_names");
-	}
-
-	ret = rte_eth_xstats_get_names(port_id, xstats_names, len);
-	if (ret < 0 || ret > len) {
-		free(xstats);
-		free(xstats_names);
-		rte_exit(EXIT_FAILURE,
-				"rte_eth_xstats_get_names(%u) len%i failed: %d",
-				port_id, len, ret);
-	}
-
-	for (i = 0; i < len; i++) {
-		if (xstats[i].value > 0)
-			printf("Port %u: %s %s:\t\t%"PRIu64"\n",
-					port_id, stats_border,
-					xstats_names[i].name,
-					xstats[i].value);
-	}
-
-	ret = rte_bbdev_stats_get(bbdev_id, &bbstats);
-	if (ret < 0) {
-		free(xstats);
-		free(xstats_names);
-		rte_exit(EXIT_FAILURE,
-				"ERROR(%d): Failure to get BBDEV %u statistics\n",
-				ret, bbdev_id);
-	}
-
-	printf("\nBBDEV STATISTICS:\n=================\n");
-	printf("BBDEV %u: %s enqueue count:\t\t%"PRIu64"\n",
-			bbdev_id, stats_border,
-			bbstats.enqueued_count);
-	printf("BBDEV %u: %s dequeue count:\t\t%"PRIu64"\n",
-			bbdev_id, stats_border,
-			bbstats.dequeued_count);
-	printf("BBDEV %u: %s enqueue error count:\t\t%"PRIu64"\n",
-			bbdev_id, stats_border,
-			bbstats.enqueue_err_count);
-	printf("BBDEV %u: %s dequeue error count:\t\t%"PRIu64"\n\n",
-			bbdev_id, stats_border,
-			bbstats.dequeue_err_count);
-
-	printf("LCORE STATISTICS:\n=================\n");
-	for (l_id = 0; l_id < RTE_MAX_LCORE; ++l_id) {
-		if (stats_lcore->lconf[l_id].core_type == 0)
-			continue;
-		print_lcore_stats(stats_lcore->lconf[l_id].lcore_stats, l_id);
-	}
-
-	free(xstats);
-	free(xstats_names);
-}
-
-static int
-stats_loop(void *arg)
-{
-	struct stats_lcore_params *stats_lcore = arg;
-
-	while (!rte_atomic16_read(&global_exit_flag)) {
-		print_stats(stats_lcore);
-		rte_delay_ms(500);
-	}
-
-	return 0;
-}
-
-static inline void
-run_encoding(struct lcore_conf *lcore_conf)
-{
-	uint16_t i;
-	uint16_t port_id, rx_queue_id;
-	uint16_t bbdev_id, enc_queue_id;
-	uint16_t nb_rx, nb_enq, nb_deq, nb_sent;
-	struct rte_mbuf *rx_pkts_burst[MAX_PKT_BURST];
-	struct rte_mbuf *enc_out_pkts[MAX_PKT_BURST];
-	struct rte_bbdev_enc_op *bbdev_ops_burst[MAX_PKT_BURST];
-	struct lcore_statistics *lcore_stats;
-	struct rte_mempool *bbdev_op_pool, *enc_out_pool;
-	struct rte_ring *enc_to_dec_ring;
-	const int in_data_len = (def_op_enc.cb_params.k / 8) - CRC_24B_LEN;
-
-	lcore_stats = lcore_conf->lcore_stats;
-	port_id = lcore_conf->port_id;
-	rx_queue_id = lcore_conf->rx_queue_id;
-	bbdev_id = lcore_conf->bbdev_id;
-	enc_queue_id = lcore_conf->enc_queue_id;
-	bbdev_op_pool = lcore_conf->bbdev_enc_op_pool;
-	enc_out_pool = lcore_conf->enc_out_pool;
-	enc_to_dec_ring = lcore_conf->enc_to_dec_ring;
-
-	/* Read packet from RX queues*/
-	nb_rx = rte_eth_rx_burst(port_id, rx_queue_id, rx_pkts_burst,
-			MAX_PKT_BURST);
-	if (!nb_rx)
-		return;
-
-	if (unlikely(rte_mempool_get_bulk(enc_out_pool, (void **)enc_out_pkts,
-			nb_rx) != 0)) {
-		pktmbuf_free_bulk(rx_pkts_burst, nb_rx);
-		lcore_stats->rx_lost_packets += nb_rx;
-		return;
-	}
-
-	if (unlikely(rte_bbdev_enc_op_alloc_bulk(bbdev_op_pool, bbdev_ops_burst,
-			nb_rx) != 0)) {
-		pktmbuf_free_bulk(enc_out_pkts, nb_rx);
-		pktmbuf_free_bulk(rx_pkts_burst, nb_rx);
-		lcore_stats->rx_lost_packets += nb_rx;
-		return;
-	}
-
-	for (i = 0; i < nb_rx; i++) {
-		char *data;
-		const uint16_t pkt_data_len =
-				rte_pktmbuf_data_len(rx_pkts_burst[i]) -
-				sizeof(struct ether_hdr);
-		/* save input mbuf pointer for later comparison */
-		enc_out_pkts[i]->userdata = rx_pkts_burst[i];
-
-		/* copy ethernet header */
-		rte_pktmbuf_reset(enc_out_pkts[i]);
-		data = rte_pktmbuf_append(enc_out_pkts[i],
-				sizeof(struct ether_hdr));
-		if (data == NULL) {
-			printf(
-				"Not enough space for ethernet header in encoder output mbuf\n");
-			continue;
-		}
-		add_ether_hdr(rx_pkts_burst[i], enc_out_pkts[i]);
-
-		/* set op */
-		bbdev_ops_burst[i]->turbo_enc = def_op_enc;
-
-		bbdev_ops_burst[i]->turbo_enc.input.data =
-				rx_pkts_burst[i];
-		bbdev_ops_burst[i]->turbo_enc.input.offset =
-				sizeof(struct ether_hdr);
-		/* Encoder will attach the CRC24B, adjust the length */
-		bbdev_ops_burst[i]->turbo_enc.input.length = in_data_len;
-
-		if (in_data_len < pkt_data_len)
-			rte_pktmbuf_trim(rx_pkts_burst[i], pkt_data_len -
-					in_data_len);
-		else if (in_data_len > pkt_data_len) {
-			data = rte_pktmbuf_append(rx_pkts_burst[i],
-					in_data_len - pkt_data_len);
-			if (data == NULL)
-				printf(
-					"Not enough storage in mbuf to perform the encoding\n");
-		}
-
-		bbdev_ops_burst[i]->turbo_enc.output.data =
-				enc_out_pkts[i];
-		bbdev_ops_burst[i]->turbo_enc.output.offset =
-				sizeof(struct ether_hdr);
-	}
-
-	/* Enqueue packets on BBDevice */
-	nb_enq = rte_bbdev_enqueue_enc_ops(bbdev_id, enc_queue_id,
-			bbdev_ops_burst, nb_rx);
-	if (unlikely(nb_enq < nb_rx)) {
-		pktmbuf_userdata_free_bulk(&enc_out_pkts[nb_enq],
-				nb_rx - nb_enq);
-		rte_bbdev_enc_op_free_bulk(&bbdev_ops_burst[nb_enq],
-				nb_rx - nb_enq);
-		lcore_stats->rx_lost_packets += nb_rx - nb_enq;
-
-		if (!nb_enq)
-			return;
-	}
-
-	lcore_stats->enqueued += nb_enq;
-
-	/* Dequeue packets from bbdev device*/
-	nb_deq = 0;
-	do {
-		nb_deq += rte_bbdev_dequeue_enc_ops(bbdev_id, enc_queue_id,
-				&bbdev_ops_burst[nb_deq], nb_enq - nb_deq);
-	} while (unlikely(nb_deq < nb_enq));
-
-	lcore_stats->dequeued += nb_deq;
-
-	/* Generate and add AWGN */
-	add_awgn(enc_out_pkts, nb_deq);
-
-	rte_bbdev_enc_op_free_bulk(bbdev_ops_burst, nb_deq);
-
-	/* Enqueue packets to encoder-to-decoder ring */
-	nb_sent = rte_ring_enqueue_burst(enc_to_dec_ring, (void **)enc_out_pkts,
-			nb_deq, NULL);
-	if (unlikely(nb_sent < nb_deq)) {
-		pktmbuf_userdata_free_bulk(&enc_out_pkts[nb_sent],
-				nb_deq - nb_sent);
-		lcore_stats->enc_to_dec_lost_packets += nb_deq - nb_sent;
-	}
-}
-
-static void
-run_decoding(struct lcore_conf *lcore_conf)
-{
-	uint16_t i;
-	uint16_t port_id, tx_queue_id;
-	uint16_t bbdev_id, bbdev_queue_id;
-	uint16_t nb_recv, nb_enq, nb_deq, nb_tx;
-	uint8_t *llr_temp_buf;
-	struct rte_mbuf *recv_pkts_burst[MAX_PKT_BURST];
-	struct rte_bbdev_dec_op *bbdev_ops_burst[MAX_PKT_BURST];
-	struct lcore_statistics *lcore_stats;
-	struct rte_mempool *bbdev_op_pool;
-	struct rte_ring *enc_to_dec_ring;
-
-	lcore_stats = lcore_conf->lcore_stats;
-	port_id = lcore_conf->port_id;
-	tx_queue_id = lcore_conf->tx_queue_id;
-	bbdev_id = lcore_conf->bbdev_id;
-	bbdev_queue_id = lcore_conf->dec_queue_id;
-	bbdev_op_pool = lcore_conf->bbdev_dec_op_pool;
-	enc_to_dec_ring = lcore_conf->enc_to_dec_ring;
-	llr_temp_buf = lcore_conf->llr_temp_buf;
-
-	/* Dequeue packets from the ring */
-	nb_recv = rte_ring_dequeue_burst(enc_to_dec_ring,
-			(void **)recv_pkts_burst, MAX_PKT_BURST, NULL);
-	if (!nb_recv)
-		return;
-
-	if (unlikely(rte_bbdev_dec_op_alloc_bulk(bbdev_op_pool, bbdev_ops_burst,
-			nb_recv) != 0)) {
-		pktmbuf_userdata_free_bulk(recv_pkts_burst, nb_recv);
-		lcore_stats->rx_lost_packets += nb_recv;
-		return;
-	}
-
-	transform_enc_out_dec_in(recv_pkts_burst, llr_temp_buf, nb_recv,
-			def_op_dec.cb_params.k);
-
-	for (i = 0; i < nb_recv; i++) {
-		/* set op */
-		bbdev_ops_burst[i]->turbo_dec = def_op_dec;
-
-		bbdev_ops_burst[i]->turbo_dec.input.data = recv_pkts_burst[i];
-		bbdev_ops_burst[i]->turbo_dec.input.offset =
-				sizeof(struct ether_hdr);
-		bbdev_ops_burst[i]->turbo_dec.input.length =
-				rte_pktmbuf_data_len(recv_pkts_burst[i])
-				- sizeof(struct ether_hdr);
-
-		bbdev_ops_burst[i]->turbo_dec.hard_output.data =
-				recv_pkts_burst[i];
-		bbdev_ops_burst[i]->turbo_dec.hard_output.offset =
-				sizeof(struct ether_hdr);
-	}
-
-	/* Enqueue packets on BBDevice */
-	nb_enq = rte_bbdev_enqueue_dec_ops(bbdev_id, bbdev_queue_id,
-			bbdev_ops_burst, nb_recv);
-	if (unlikely(nb_enq < nb_recv)) {
-		pktmbuf_userdata_free_bulk(&recv_pkts_burst[nb_enq],
-				nb_recv - nb_enq);
-		rte_bbdev_dec_op_free_bulk(&bbdev_ops_burst[nb_enq],
-				nb_recv - nb_enq);
-		lcore_stats->rx_lost_packets += nb_recv - nb_enq;
-
-		if (!nb_enq)
-			return;
-	}
-
-	lcore_stats->enqueued += nb_enq;
-
-	/* Dequeue packets from BBDevice */
-	nb_deq = 0;
-	do {
-		nb_deq += rte_bbdev_dequeue_dec_ops(bbdev_id, bbdev_queue_id,
-				&bbdev_ops_burst[nb_deq], nb_enq - nb_deq);
-	} while (unlikely(nb_deq < nb_enq));
-
-	lcore_stats->dequeued += nb_deq;
-
-	rte_bbdev_dec_op_free_bulk(bbdev_ops_burst, nb_deq);
-
-	verify_data(recv_pkts_burst, nb_deq);
-
-	/* Free the RX mbufs after verification */
-	for (i = 0; i < nb_deq; ++i)
-		rte_pktmbuf_free(recv_pkts_burst[i]->userdata);
-
-	/* Transmit the packets */
-	nb_tx = rte_eth_tx_burst(port_id, tx_queue_id, recv_pkts_burst, nb_deq);
-	if (unlikely(nb_tx < nb_deq)) {
-		pktmbuf_userdata_free_bulk(&recv_pkts_burst[nb_tx],
-				nb_deq - nb_tx);
-		lcore_stats->tx_lost_packets += nb_deq - nb_tx;
-	}
-}
-
-static int
-processing_loop(void *arg)
-{
-	struct lcore_conf *lcore_conf = arg;
-	const bool run_encoder = (lcore_conf->core_type &
-			(1 << RTE_BBDEV_OP_TURBO_ENC));
-	const bool run_decoder = (lcore_conf->core_type &
-			(1 << RTE_BBDEV_OP_TURBO_DEC));
-
-	while (!rte_atomic16_read(&global_exit_flag)) {
-		if (run_encoder)
-			run_encoding(lcore_conf);
-		if (run_decoder)
-			run_decoding(lcore_conf);
-	}
-
-	return 0;
-}
-
-static int
-prepare_bbdev_device(unsigned int dev_id, struct rte_bbdev_info *info,
-		struct app_config_params *app_params)
-{
-	int ret;
-	unsigned int q_id, dec_q_id, enc_q_id;
-	struct rte_bbdev_queue_conf qconf = {0};
-	uint16_t dec_qs_nb = app_params->num_dec_cores;
-	uint16_t enc_qs_nb = app_params->num_enc_cores;
-	uint16_t tot_qs = dec_qs_nb + enc_qs_nb;
-
-	ret = rte_bbdev_setup_queues(dev_id, tot_qs, info->socket_id);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE,
-				"ERROR(%d): BBDEV %u not configured properly\n",
-				ret, dev_id);
-
-	/* setup device DEC queues */
-	qconf.socket = info->socket_id;
-	qconf.queue_size = info->drv.queue_size_lim;
-	qconf.op_type = RTE_BBDEV_OP_TURBO_DEC;
-
-	for (q_id = 0, dec_q_id = 0; q_id < dec_qs_nb; q_id++) {
-		ret = rte_bbdev_queue_configure(dev_id, q_id, &qconf);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-					"ERROR(%d): BBDEV %u DEC queue %u not configured properly\n",
-					ret, dev_id, q_id);
-		app_params->dec_queue_ids[dec_q_id++] = q_id;
-	}
-
-	/* setup device ENC queues */
-	qconf.op_type = RTE_BBDEV_OP_TURBO_ENC;
-
-	for (q_id = dec_qs_nb, enc_q_id = 0; q_id < tot_qs; q_id++) {
-		ret = rte_bbdev_queue_configure(dev_id, q_id, &qconf);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-					"ERROR(%d): BBDEV %u ENC queue %u not configured properly\n",
-					ret, dev_id, q_id);
-		app_params->enc_queue_ids[enc_q_id++] = q_id;
-	}
-
-	ret = rte_bbdev_start(dev_id);
-
-	if (ret != 0)
-		rte_exit(EXIT_FAILURE, "ERROR(%d): BBDEV %u not started\n",
-			ret, dev_id);
-
-	printf("BBdev %u started\n", dev_id);
-
-	return 0;
-}
-
-static inline bool
-check_matching_capabilities(uint64_t mask, uint64_t required_mask)
-{
-	return (mask & required_mask) == required_mask;
-}
-
-static void
-enable_bbdev(struct app_config_params *app_params)
-{
-	struct rte_bbdev_info dev_info;
-	const struct rte_bbdev_op_cap *op_cap;
-	uint16_t bbdev_id = app_params->bbdev_id;
-	bool encoder_capable = false;
-	bool decoder_capable = false;
-
-	rte_bbdev_info_get(bbdev_id, &dev_info);
-	op_cap = dev_info.drv.capabilities;
-
-	while (op_cap->type != RTE_BBDEV_OP_NONE) {
-		if (op_cap->type == RTE_BBDEV_OP_TURBO_ENC) {
-			if (check_matching_capabilities(
-					op_cap->cap.turbo_enc.capability_flags,
-					def_op_enc.op_flags))
-				encoder_capable = true;
-		}
-
-		if (op_cap->type == RTE_BBDEV_OP_TURBO_DEC) {
-			if (check_matching_capabilities(
-					op_cap->cap.turbo_dec.capability_flags,
-					def_op_dec.op_flags))
-				decoder_capable = true;
-		}
-
-		op_cap++;
-	}
-
-	if (encoder_capable == false)
-		rte_exit(EXIT_FAILURE,
-			"The specified BBDev %u doesn't have required encoder capabilities!\n",
-			bbdev_id);
-	if (decoder_capable == false)
-		rte_exit(EXIT_FAILURE,
-			"The specified BBDev %u doesn't have required decoder capabilities!\n",
-			bbdev_id);
-
-	prepare_bbdev_device(bbdev_id, &dev_info, app_params);
-}
-
-int
-main(int argc, char **argv)
-{
-	int ret;
-	unsigned int nb_bbdevs, flags, lcore_id;
-	void *sigret;
-	struct app_config_params app_params = def_app_config;
-	struct rte_mempool *ethdev_mbuf_mempool, *bbdev_mbuf_mempool;
-	struct rte_mempool *bbdev_op_pools[RTE_BBDEV_OP_TYPE_COUNT];
-	struct lcore_conf lcore_conf[RTE_MAX_LCORE] = { {0} };
-	struct lcore_statistics lcore_stats[RTE_MAX_LCORE] = { {0} };
-	struct stats_lcore_params stats_lcore;
-	struct rte_ring *enc_to_dec_ring;
-	bool stats_thread_started = false;
-	unsigned int master_lcore_id = rte_get_master_lcore();
-
-	rte_atomic16_init(&global_exit_flag);
-
-	sigret = signal(SIGTERM, signal_handler);
-	if (sigret == SIG_ERR)
-		rte_exit(EXIT_FAILURE, "signal(%d, ...) failed", SIGTERM);
-
-	sigret = signal(SIGINT, signal_handler);
-	if (sigret == SIG_ERR)
-		rte_exit(EXIT_FAILURE, "signal(%d, ...) failed", SIGINT);
-
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid EAL arguments\n");
-
-	argc -= ret;
-	argv += ret;
-
-	/* parse application arguments (after the EAL ones) */
-	ret = bbdev_parse_args(argc, argv, &app_params);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid BBDEV arguments\n");
-
-	/*create bbdev op pools*/
-	bbdev_op_pools[RTE_BBDEV_OP_TURBO_DEC] =
-			rte_bbdev_op_pool_create("bbdev_op_pool_dec",
-			RTE_BBDEV_OP_TURBO_DEC, NB_MBUF, 128, rte_socket_id());
-	bbdev_op_pools[RTE_BBDEV_OP_TURBO_ENC] =
-			rte_bbdev_op_pool_create("bbdev_op_pool_enc",
-			RTE_BBDEV_OP_TURBO_ENC, NB_MBUF, 128, rte_socket_id());
-
-	if ((bbdev_op_pools[RTE_BBDEV_OP_TURBO_DEC] == NULL) ||
-			(bbdev_op_pools[RTE_BBDEV_OP_TURBO_ENC] == NULL))
-		rte_exit(EXIT_FAILURE, "Cannot create bbdev op pools\n");
-
-	/* Create encoder to decoder ring */
-	flags = (app_params.num_enc_cores == 1) ? RING_F_SP_ENQ : 0;
-	if (app_params.num_dec_cores == 1)
-		flags |= RING_F_SC_DEQ;
-
-	enc_to_dec_ring = rte_ring_create("enc_to_dec_ring",
-		rte_align32pow2(NB_MBUF), rte_socket_id(), flags);
-
-	/* Get the number of available bbdev devices */
-	nb_bbdevs = rte_bbdev_count();
-	if (nb_bbdevs <= app_params.bbdev_id)
-		rte_exit(EXIT_FAILURE,
-				"%u BBDevs detected, cannot use BBDev with ID %u!\n",
-				nb_bbdevs, app_params.bbdev_id);
-	printf("Number of bbdevs detected: %d\n", nb_bbdevs);
-
-	if (!rte_eth_dev_is_valid_port(app_params.port_id))
-		rte_exit(EXIT_FAILURE,
-				"cannot use port with ID %u!\n",
-				app_params.port_id);
-
-	/* create the mbuf mempool for ethdev pkts */
-	ethdev_mbuf_mempool = rte_pktmbuf_pool_create("ethdev_mbuf_pool",
-			NB_MBUF, MEMPOOL_CACHE_SIZE, 0,
-			RTE_MBUF_DEFAULT_BUF_SIZE, rte_socket_id());
-	if (ethdev_mbuf_mempool == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot create ethdev mbuf mempool\n");
-
-	/* create the mbuf mempool for encoder output */
-	bbdev_mbuf_mempool = rte_pktmbuf_pool_create("bbdev_mbuf_pool",
-			NB_MBUF, MEMPOOL_CACHE_SIZE, 0,
-			RTE_MBUF_DEFAULT_BUF_SIZE, rte_socket_id());
-	if (bbdev_mbuf_mempool == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot create ethdev mbuf mempool\n");
-
-	/* initialize ports */
-	ret = initialize_ports(&app_params, ethdev_mbuf_mempool);
-
-	/* Check if all requested lcores are available */
-	for (lcore_id = 0; lcore_id < 8 * sizeof(uint64_t); ++lcore_id)
-		if (((1ULL << lcore_id) & app_params.enc_core_mask) ||
-				((1ULL << lcore_id) & app_params.dec_core_mask))
-			if (!rte_lcore_is_enabled(lcore_id))
-				rte_exit(EXIT_FAILURE,
-						"Requested lcore_id %u is not enabled!\n",
-						lcore_id);
-
-	/* Start ethernet port */
-	ret = rte_eth_dev_start(app_params.port_id);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "rte_eth_dev_start:err=%d, port=%u\n",
-				ret, app_params.port_id);
-
-	ret = check_port_link_status(app_params.port_id);
-	if (ret < 0)
-		exit(EXIT_FAILURE);
-
-	/* start BBDevice and save BBDev queue IDs */
-	enable_bbdev(&app_params);
-
-	/* Initialize the port/queue configuration of each logical core */
-	lcore_conf_init(&app_params, lcore_conf, bbdev_op_pools,
-			bbdev_mbuf_mempool, enc_to_dec_ring, lcore_stats);
-
-	stats_lcore.app_params = &app_params;
-	stats_lcore.lconf = lcore_conf;
-
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		if (lcore_conf[lcore_id].core_type != 0)
-			/* launch per-lcore processing loop on slave lcores */
-			rte_eal_remote_launch(processing_loop,
-					&lcore_conf[lcore_id], lcore_id);
-		else if (!stats_thread_started) {
-			/* launch statistics printing loop */
-			rte_eal_remote_launch(stats_loop, &stats_lcore,
-					lcore_id);
-			stats_thread_started = true;
-		}
-	}
-
-	if (!stats_thread_started &&
-			lcore_conf[master_lcore_id].core_type != 0)
-		rte_exit(EXIT_FAILURE,
-				"Not enough lcores to run the statistics printing loop!");
-	else if (lcore_conf[master_lcore_id].core_type != 0)
-		processing_loop(&lcore_conf[master_lcore_id]);
-	else if (!stats_thread_started)
-		stats_loop(&stats_lcore);
-
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		ret |= rte_eal_wait_lcore(lcore_id);
-	}
-
-	return ret;
-}
diff --git a/examples/bbdev_app/meson.build b/examples/bbdev_app/meson.build
deleted file mode 100644
index 8e06a8a..0000000
--- a/examples/bbdev_app/meson.build
+++ /dev/null
@@ -1,13 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-deps += 'bbdev'
-allow_experimental_apis = true
-sources = files(
-	'main.c'
-)
diff --git a/examples/bond/Makefile b/examples/bond/Makefile
deleted file mode 100644
index e7afce3..0000000
--- a/examples/bond/Makefile
+++ /dev/null
@@ -1,72 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2015 Intel Corporation
-
-# binary name
-APP = bond_app
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-LDFLAGS += -lrte_pmd_bond
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += $(WERROR_FLAGS)
-
-# workaround for a gcc bug with noreturn attribute
-# http://gcc.gnu.org/bugzilla/show_bug.cgi?id=12603
-ifeq ($(CONFIG_RTE_TOOLCHAIN_GCC),y)
-CFLAGS_main.o += -Wno-return-type
-endif
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -O3
-
-ifeq ($(CONFIG_RTE_BUILD_SHARED_LIB),y)
-LDLIBS += -lrte_pmd_bond
-endif
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-
-endif
diff --git a/examples/bond/main.c b/examples/bond/main.c
deleted file mode 100644
index d4097d0..0000000
--- a/examples/bond/main.c
+++ /dev/null
@@ -1,802 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#include <stdint.h>
-#include <sys/queue.h>
-#include <sys/socket.h>
-#include <stdlib.h>
-#include <string.h>
-#include <stdio.h>
-#include <assert.h>
-#include <errno.h>
-#include <signal.h>
-#include <stdarg.h>
-#include <inttypes.h>
-#include <getopt.h>
-#include <termios.h>
-#include <unistd.h>
-#include <pthread.h>
-
-#include <rte_common.h>
-#include <rte_log.h>
-#include <rte_memory.h>
-#include <rte_memcpy.h>
-#include <rte_eal.h>
-#include <rte_launch.h>
-#include <rte_atomic.h>
-#include <rte_cycles.h>
-#include <rte_prefetch.h>
-#include <rte_lcore.h>
-#include <rte_per_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_interrupts.h>
-#include <rte_random.h>
-#include <rte_debug.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-#include <rte_ip.h>
-#include <rte_tcp.h>
-#include <rte_arp.h>
-#include <rte_spinlock.h>
-
-#include <cmdline_rdline.h>
-#include <cmdline_parse.h>
-#include <cmdline_parse_num.h>
-#include <cmdline_parse_string.h>
-#include <cmdline_parse_ipaddr.h>
-#include <cmdline_parse_etheraddr.h>
-#include <cmdline_socket.h>
-#include <cmdline.h>
-
-#include "main.h"
-
-#include <rte_devargs.h>
-
-
-#include "rte_byteorder.h"
-#include "rte_cpuflags.h"
-#include "rte_eth_bond.h"
-
-#define RTE_LOGTYPE_DCB RTE_LOGTYPE_USER1
-
-#define NB_MBUF   (1024*8)
-
-#define MAX_PKT_BURST 32
-#define BURST_TX_DRAIN_US 100      /* TX drain every ~100us */
-#define BURST_RX_INTERVAL_NS (10) /* RX poll interval ~100ns */
-
-/*
- * RX and TX Prefetch, Host, and Write-back threshold values should be
- * carefully set for optimal performance. Consult the network
- * controller's datasheet and supporting DPDK documentation for guidance
- * on how these parameters should be set.
- */
-#define RX_PTHRESH 8 /**< Default values of RX prefetch threshold reg. */
-#define RX_HTHRESH 8 /**< Default values of RX host threshold reg. */
-#define RX_WTHRESH 4 /**< Default values of RX write-back threshold reg. */
-#define RX_FTHRESH (MAX_PKT_BURST * 2)/**< Default values of RX free threshold reg. */
-
-/*
- * These default values are optimized for use with the Intel(R) 82599 10 GbE
- * Controller and the DPDK ixgbe PMD. Consider using other values for other
- * network controllers and/or network drivers.
- */
-#define TX_PTHRESH 36 /**< Default values of TX prefetch threshold reg. */
-#define TX_HTHRESH 0  /**< Default values of TX host threshold reg. */
-#define TX_WTHRESH 0  /**< Default values of TX write-back threshold reg. */
-
-/*
- * Configurable number of RX/TX ring descriptors
- */
-#define RTE_RX_DESC_DEFAULT 1024
-#define RTE_TX_DESC_DEFAULT 1024
-
-#define BOND_IP_1	7
-#define BOND_IP_2	0
-#define BOND_IP_3	0
-#define BOND_IP_4	10
-
-/* not defined under linux */
-#ifndef NIPQUAD
-#define NIPQUAD_FMT "%u.%u.%u.%u"
-#endif
-
-#define MAX_PORTS	4
-#define PRINT_MAC(addr)		printf("%02"PRIx8":%02"PRIx8":%02"PRIx8 \
-		":%02"PRIx8":%02"PRIx8":%02"PRIx8,	\
-		addr.addr_bytes[0], addr.addr_bytes[1], addr.addr_bytes[2], \
-		addr.addr_bytes[3], addr.addr_bytes[4], addr.addr_bytes[5])
-
-uint16_t slaves[RTE_MAX_ETHPORTS];
-uint16_t slaves_count;
-
-static uint16_t BOND_PORT = 0xffff;
-
-static struct rte_mempool *mbuf_pool;
-
-static struct rte_eth_conf port_conf = {
-	.rxmode = {
-		.mq_mode = ETH_MQ_RX_NONE,
-		.max_rx_pkt_len = ETHER_MAX_LEN,
-		.split_hdr_size = 0,
-		.ignore_offload_bitfield = 1,
-		.offloads = DEV_RX_OFFLOAD_CRC_STRIP,
-	},
-	.rx_adv_conf = {
-		.rss_conf = {
-			.rss_key = NULL,
-			.rss_hf = ETH_RSS_IP,
-		},
-	},
-	.txmode = {
-		.mq_mode = ETH_MQ_TX_NONE,
-	},
-};
-
-static void
-slave_port_init(uint16_t portid, struct rte_mempool *mbuf_pool)
-{
-	int retval;
-	uint16_t nb_rxd = RTE_RX_DESC_DEFAULT;
-	uint16_t nb_txd = RTE_TX_DESC_DEFAULT;
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_rxconf rxq_conf;
-	struct rte_eth_txconf txq_conf;
-	struct rte_eth_conf local_port_conf = port_conf;
-
-	if (!rte_eth_dev_is_valid_port(portid))
-		rte_exit(EXIT_FAILURE, "Invalid port\n");
-
-	rte_eth_dev_info_get(portid, &dev_info);
-	if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-		local_port_conf.txmode.offloads |=
-			DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-	retval = rte_eth_dev_configure(portid, 1, 1, &local_port_conf);
-	if (retval != 0)
-		rte_exit(EXIT_FAILURE, "port %u: configuration failed (res=%d)\n",
-				portid, retval);
-
-	retval = rte_eth_dev_adjust_nb_rx_tx_desc(portid, &nb_rxd, &nb_txd);
-	if (retval != 0)
-		rte_exit(EXIT_FAILURE, "port %u: rte_eth_dev_adjust_nb_rx_tx_desc "
-				"failed (res=%d)\n", portid, retval);
-
-	/* RX setup */
-	rxq_conf = dev_info.default_rxconf;
-	rxq_conf.offloads = local_port_conf.rxmode.offloads;
-	retval = rte_eth_rx_queue_setup(portid, 0, nb_rxd,
-					rte_eth_dev_socket_id(portid),
-					&rxq_conf,
-					mbuf_pool);
-	if (retval < 0)
-		rte_exit(retval, " port %u: RX queue 0 setup failed (res=%d)",
-				portid, retval);
-
-	/* TX setup */
-	txq_conf = dev_info.default_txconf;
-	txq_conf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-	txq_conf.offloads = local_port_conf.txmode.offloads;
-	retval = rte_eth_tx_queue_setup(portid, 0, nb_txd,
-				rte_eth_dev_socket_id(portid), &txq_conf);
-
-	if (retval < 0)
-		rte_exit(retval, "port %u: TX queue 0 setup failed (res=%d)",
-				portid, retval);
-
-	retval  = rte_eth_dev_start(portid);
-	if (retval < 0)
-		rte_exit(retval,
-				"Start port %d failed (res=%d)",
-				portid, retval);
-
-	struct ether_addr addr;
-
-	rte_eth_macaddr_get(portid, &addr);
-	printf("Port %u MAC: ", portid);
-	PRINT_MAC(addr);
-	printf("\n");
-}
-
-static void
-bond_port_init(struct rte_mempool *mbuf_pool)
-{
-	int retval;
-	uint8_t i;
-	uint16_t nb_rxd = RTE_RX_DESC_DEFAULT;
-	uint16_t nb_txd = RTE_TX_DESC_DEFAULT;
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_rxconf rxq_conf;
-	struct rte_eth_txconf txq_conf;
-	struct rte_eth_conf local_port_conf = port_conf;
-
-	retval = rte_eth_bond_create("net_bonding0", BONDING_MODE_ALB,
-			0 /*SOCKET_ID_ANY*/);
-	if (retval < 0)
-		rte_exit(EXIT_FAILURE,
-				"Faled to create bond port\n");
-
-	BOND_PORT = retval;
-
-	rte_eth_dev_info_get(BOND_PORT, &dev_info);
-	if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-		local_port_conf.txmode.offloads |=
-			DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-	retval = rte_eth_dev_configure(BOND_PORT, 1, 1, &local_port_conf);
-	if (retval != 0)
-		rte_exit(EXIT_FAILURE, "port %u: configuration failed (res=%d)\n",
-				BOND_PORT, retval);
-
-	retval = rte_eth_dev_adjust_nb_rx_tx_desc(BOND_PORT, &nb_rxd, &nb_txd);
-	if (retval != 0)
-		rte_exit(EXIT_FAILURE, "port %u: rte_eth_dev_adjust_nb_rx_tx_desc "
-				"failed (res=%d)\n", BOND_PORT, retval);
-
-	/* RX setup */
-	rxq_conf = dev_info.default_rxconf;
-	rxq_conf.offloads = local_port_conf.rxmode.offloads;
-	retval = rte_eth_rx_queue_setup(BOND_PORT, 0, nb_rxd,
-					rte_eth_dev_socket_id(BOND_PORT),
-					&rxq_conf, mbuf_pool);
-	if (retval < 0)
-		rte_exit(retval, " port %u: RX queue 0 setup failed (res=%d)",
-				BOND_PORT, retval);
-
-	/* TX setup */
-	txq_conf = dev_info.default_txconf;
-	txq_conf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-	txq_conf.offloads = local_port_conf.txmode.offloads;
-	retval = rte_eth_tx_queue_setup(BOND_PORT, 0, nb_txd,
-				rte_eth_dev_socket_id(BOND_PORT), &txq_conf);
-
-	if (retval < 0)
-		rte_exit(retval, "port %u: TX queue 0 setup failed (res=%d)",
-				BOND_PORT, retval);
-
-	for (i = 0; i < slaves_count; i++) {
-		if (rte_eth_bond_slave_add(BOND_PORT, slaves[i]) == -1)
-			rte_exit(-1, "Oooops! adding slave (%u) to bond (%u) failed!\n",
-					slaves[i], BOND_PORT);
-
-	}
-
-	retval  = rte_eth_dev_start(BOND_PORT);
-	if (retval < 0)
-		rte_exit(retval, "Start port %d failed (res=%d)", BOND_PORT, retval);
-
-	rte_eth_promiscuous_enable(BOND_PORT);
-
-	struct ether_addr addr;
-
-	rte_eth_macaddr_get(BOND_PORT, &addr);
-	printf("Port %u MAC: ", (unsigned)BOND_PORT);
-		PRINT_MAC(addr);
-		printf("\n");
-}
-
-static inline size_t
-get_vlan_offset(struct ether_hdr *eth_hdr, uint16_t *proto)
-{
-	size_t vlan_offset = 0;
-
-	if (rte_cpu_to_be_16(ETHER_TYPE_VLAN) == *proto) {
-		struct vlan_hdr *vlan_hdr = (struct vlan_hdr *)(eth_hdr + 1);
-
-		vlan_offset = sizeof(struct vlan_hdr);
-		*proto = vlan_hdr->eth_proto;
-
-		if (rte_cpu_to_be_16(ETHER_TYPE_VLAN) == *proto) {
-			vlan_hdr = vlan_hdr + 1;
-
-			*proto = vlan_hdr->eth_proto;
-			vlan_offset += sizeof(struct vlan_hdr);
-		}
-	}
-	return vlan_offset;
-}
-
-struct global_flag_stru_t {
-	int LcoreMainIsRunning;
-	int LcoreMainCore;
-	uint32_t port_packets[4];
-	rte_spinlock_t lock;
-};
-struct global_flag_stru_t global_flag_stru;
-struct global_flag_stru_t *global_flag_stru_p = &global_flag_stru;
-
-/*
- * Main thread that does the work, reading from INPUT_PORT
- * and writing to OUTPUT_PORT
- */
-static int lcore_main(__attribute__((unused)) void *arg1)
-{
-	struct rte_mbuf *pkts[MAX_PKT_BURST] __rte_cache_aligned;
-	struct ether_addr d_addr;
-
-	struct ether_hdr *eth_hdr;
-	struct arp_hdr *arp_hdr;
-	struct ipv4_hdr *ipv4_hdr;
-	uint16_t ether_type, offset;
-
-	uint16_t rx_cnt;
-	uint32_t bond_ip;
-	int i = 0;
-	uint8_t is_free;
-
-	bond_ip = BOND_IP_1 | (BOND_IP_2 << 8) |
-				(BOND_IP_3 << 16) | (BOND_IP_4 << 24);
-
-	rte_spinlock_trylock(&global_flag_stru_p->lock);
-
-	while (global_flag_stru_p->LcoreMainIsRunning) {
-		rte_spinlock_unlock(&global_flag_stru_p->lock);
-		rx_cnt = rte_eth_rx_burst(BOND_PORT, 0, pkts, MAX_PKT_BURST);
-		is_free = 0;
-
-		/* If didn't receive any packets, wait and go to next iteration */
-		if (rx_cnt == 0) {
-			rte_delay_us(50);
-			continue;
-		}
-
-		/* Search incoming data for ARP packets and prepare response */
-		for (i = 0; i < rx_cnt; i++) {
-			if (rte_spinlock_trylock(&global_flag_stru_p->lock) == 1) {
-				global_flag_stru_p->port_packets[0]++;
-				rte_spinlock_unlock(&global_flag_stru_p->lock);
-			}
-			eth_hdr = rte_pktmbuf_mtod(pkts[i], struct ether_hdr *);
-			ether_type = eth_hdr->ether_type;
-			if (ether_type == rte_cpu_to_be_16(ETHER_TYPE_VLAN))
-				printf("VLAN taged frame, offset:");
-			offset = get_vlan_offset(eth_hdr, &ether_type);
-			if (offset > 0)
-				printf("%d\n", offset);
-			if (ether_type == rte_cpu_to_be_16(ETHER_TYPE_ARP)) {
-				if (rte_spinlock_trylock(&global_flag_stru_p->lock) == 1)     {
-					global_flag_stru_p->port_packets[1]++;
-					rte_spinlock_unlock(&global_flag_stru_p->lock);
-				}
-				arp_hdr = (struct arp_hdr *)((char *)(eth_hdr + 1) + offset);
-				if (arp_hdr->arp_data.arp_tip == bond_ip) {
-					if (arp_hdr->arp_op == rte_cpu_to_be_16(ARP_OP_REQUEST)) {
-						arp_hdr->arp_op = rte_cpu_to_be_16(ARP_OP_REPLY);
-						/* Switch src and dst data and set bonding MAC */
-						ether_addr_copy(&eth_hdr->s_addr, &eth_hdr->d_addr);
-						rte_eth_macaddr_get(BOND_PORT, &eth_hdr->s_addr);
-						ether_addr_copy(&arp_hdr->arp_data.arp_sha, &arp_hdr->arp_data.arp_tha);
-						arp_hdr->arp_data.arp_tip = arp_hdr->arp_data.arp_sip;
-						rte_eth_macaddr_get(BOND_PORT, &d_addr);
-						ether_addr_copy(&d_addr, &arp_hdr->arp_data.arp_sha);
-						arp_hdr->arp_data.arp_sip = bond_ip;
-						rte_eth_tx_burst(BOND_PORT, 0, &pkts[i], 1);
-						is_free = 1;
-					} else {
-						rte_eth_tx_burst(BOND_PORT, 0, NULL, 0);
-					}
-				}
-			} else if (ether_type == rte_cpu_to_be_16(ETHER_TYPE_IPv4)) {
-				if (rte_spinlock_trylock(&global_flag_stru_p->lock) == 1)     {
-					global_flag_stru_p->port_packets[2]++;
-					rte_spinlock_unlock(&global_flag_stru_p->lock);
-				 }
-				ipv4_hdr = (struct ipv4_hdr *)((char *)(eth_hdr + 1) + offset);
-				if (ipv4_hdr->dst_addr == bond_ip) {
-					ether_addr_copy(&eth_hdr->s_addr, &eth_hdr->d_addr);
-					rte_eth_macaddr_get(BOND_PORT, &eth_hdr->s_addr);
-					ipv4_hdr->dst_addr = ipv4_hdr->src_addr;
-					ipv4_hdr->src_addr = bond_ip;
-					rte_eth_tx_burst(BOND_PORT, 0, &pkts[i], 1);
-				}
-
-			}
-
-			/* Free processed packets */
-			if (is_free == 0)
-				rte_pktmbuf_free(pkts[i]);
-		}
-		rte_spinlock_trylock(&global_flag_stru_p->lock);
-	}
-	rte_spinlock_unlock(&global_flag_stru_p->lock);
-	printf("BYE lcore_main\n");
-	return 0;
-}
-
-struct cmd_obj_send_result {
-	cmdline_fixed_string_t action;
-	cmdline_ipaddr_t ip;
-};
-static inline void get_string(struct cmd_obj_send_result *res, char *buf, uint8_t size)
-{
-	snprintf(buf, size, NIPQUAD_FMT,
-		((unsigned)((unsigned char *)&(res->ip.addr.ipv4))[0]),
-		((unsigned)((unsigned char *)&(res->ip.addr.ipv4))[1]),
-		((unsigned)((unsigned char *)&(res->ip.addr.ipv4))[2]),
-		((unsigned)((unsigned char *)&(res->ip.addr.ipv4))[3])
-		);
-}
-static void cmd_obj_send_parsed(void *parsed_result,
-		__attribute__((unused)) struct cmdline *cl,
-			       __attribute__((unused)) void *data)
-{
-
-	struct cmd_obj_send_result *res = parsed_result;
-	char ip_str[INET6_ADDRSTRLEN];
-
-	struct rte_mbuf *created_pkt;
-	struct ether_hdr *eth_hdr;
-	struct arp_hdr *arp_hdr;
-
-	uint32_t bond_ip;
-	size_t pkt_size;
-
-	if (res->ip.family == AF_INET)
-		get_string(res, ip_str, INET_ADDRSTRLEN);
-	else
-		cmdline_printf(cl, "Wrong IP format. Only IPv4 is supported\n");
-
-	bond_ip = BOND_IP_1 | (BOND_IP_2 << 8) |
-				(BOND_IP_3 << 16) | (BOND_IP_4 << 24);
-
-	created_pkt = rte_pktmbuf_alloc(mbuf_pool);
-	if (created_pkt == NULL) {
-		cmdline_printf(cl, "Failed to allocate mbuf\n");
-		return;
-	}
-
-	pkt_size = sizeof(struct ether_hdr) + sizeof(struct arp_hdr);
-	created_pkt->data_len = pkt_size;
-	created_pkt->pkt_len = pkt_size;
-
-	eth_hdr = rte_pktmbuf_mtod(created_pkt, struct ether_hdr *);
-	rte_eth_macaddr_get(BOND_PORT, &eth_hdr->s_addr);
-	memset(&eth_hdr->d_addr, 0xFF, ETHER_ADDR_LEN);
-	eth_hdr->ether_type = rte_cpu_to_be_16(ETHER_TYPE_ARP);
-
-	arp_hdr = (struct arp_hdr *)((char *)eth_hdr + sizeof(struct ether_hdr));
-	arp_hdr->arp_hrd = rte_cpu_to_be_16(ARP_HRD_ETHER);
-	arp_hdr->arp_pro = rte_cpu_to_be_16(ETHER_TYPE_IPv4);
-	arp_hdr->arp_hln = ETHER_ADDR_LEN;
-	arp_hdr->arp_pln = sizeof(uint32_t);
-	arp_hdr->arp_op = rte_cpu_to_be_16(ARP_OP_REQUEST);
-
-	rte_eth_macaddr_get(BOND_PORT, &arp_hdr->arp_data.arp_sha);
-	arp_hdr->arp_data.arp_sip = bond_ip;
-	memset(&arp_hdr->arp_data.arp_tha, 0, ETHER_ADDR_LEN);
-	arp_hdr->arp_data.arp_tip =
-			  ((unsigned char *)&res->ip.addr.ipv4)[0]        |
-			 (((unsigned char *)&res->ip.addr.ipv4)[1] << 8)  |
-			 (((unsigned char *)&res->ip.addr.ipv4)[2] << 16) |
-			 (((unsigned char *)&res->ip.addr.ipv4)[3] << 24);
-	rte_eth_tx_burst(BOND_PORT, 0, &created_pkt, 1);
-
-	rte_delay_ms(100);
-	cmdline_printf(cl, "\n");
-}
-
-cmdline_parse_token_string_t cmd_obj_action_send =
-	TOKEN_STRING_INITIALIZER(struct cmd_obj_send_result, action, "send");
-cmdline_parse_token_ipaddr_t cmd_obj_ip =
-	TOKEN_IPV4_INITIALIZER(struct cmd_obj_send_result, ip);
-
-cmdline_parse_inst_t cmd_obj_send = {
-	.f = cmd_obj_send_parsed,  /* function to call */
-	.data = NULL,      /* 2nd arg of func */
-	.help_str = "send client_ip",
-	.tokens = {        /* token list, NULL terminated */
-		(void *)&cmd_obj_action_send,
-		(void *)&cmd_obj_ip,
-		NULL,
-	},
-};
-
-struct cmd_start_result {
-	cmdline_fixed_string_t start;
-};
-
-static void cmd_start_parsed(__attribute__((unused)) void *parsed_result,
-			       struct cmdline *cl,
-			       __attribute__((unused)) void *data)
-{
-	int slave_core_id = rte_lcore_id();
-
-	rte_spinlock_trylock(&global_flag_stru_p->lock);
-	if (global_flag_stru_p->LcoreMainIsRunning == 0)	{
-		if (lcore_config[global_flag_stru_p->LcoreMainCore].state != WAIT)	{
-			rte_spinlock_unlock(&global_flag_stru_p->lock);
-			return;
-		}
-		rte_spinlock_unlock(&global_flag_stru_p->lock);
-	} else {
-		cmdline_printf(cl, "lcore_main already running on core:%d\n",
-				global_flag_stru_p->LcoreMainCore);
-		rte_spinlock_unlock(&global_flag_stru_p->lock);
-		return;
-	}
-
-	/* start lcore main on core != master_core - ARP response thread */
-	slave_core_id = rte_get_next_lcore(rte_lcore_id(), 1, 0);
-	if ((slave_core_id >= RTE_MAX_LCORE) || (slave_core_id == 0))
-		return;
-
-	rte_spinlock_trylock(&global_flag_stru_p->lock);
-	global_flag_stru_p->LcoreMainIsRunning = 1;
-	rte_spinlock_unlock(&global_flag_stru_p->lock);
-	cmdline_printf(cl,
-			"Starting lcore_main on core %d:%d "
-			"Our IP:%d.%d.%d.%d\n",
-			slave_core_id,
-			rte_eal_remote_launch(lcore_main, NULL, slave_core_id),
-			BOND_IP_1,
-			BOND_IP_2,
-			BOND_IP_3,
-			BOND_IP_4
-		);
-}
-
-cmdline_parse_token_string_t cmd_start_start =
-	TOKEN_STRING_INITIALIZER(struct cmd_start_result, start, "start");
-
-cmdline_parse_inst_t cmd_start = {
-	.f = cmd_start_parsed,  /* function to call */
-	.data = NULL,      /* 2nd arg of func */
-	.help_str = "starts listening if not started at startup",
-	.tokens = {        /* token list, NULL terminated */
-		(void *)&cmd_start_start,
-		NULL,
-	},
-};
-
-struct cmd_help_result {
-	cmdline_fixed_string_t help;
-};
-
-static void cmd_help_parsed(__attribute__((unused)) void *parsed_result,
-			    struct cmdline *cl,
-			    __attribute__((unused)) void *data)
-{
-	cmdline_printf(cl,
-			"ALB - link bonding mode 6 example\n"
-			"send IP	- sends one ARPrequest through bonding for IP.\n"
-			"start		- starts listening ARPs.\n"
-			"stop		- stops lcore_main.\n"
-			"show		- shows some bond info: ex. active slaves etc.\n"
-			"help		- prints help.\n"
-			"quit		- terminate all threads and quit.\n"
-		       );
-}
-
-cmdline_parse_token_string_t cmd_help_help =
-	TOKEN_STRING_INITIALIZER(struct cmd_help_result, help, "help");
-
-cmdline_parse_inst_t cmd_help = {
-	.f = cmd_help_parsed,  /* function to call */
-	.data = NULL,      /* 2nd arg of func */
-	.help_str = "show help",
-	.tokens = {        /* token list, NULL terminated */
-		(void *)&cmd_help_help,
-		NULL,
-	},
-};
-
-struct cmd_stop_result {
-	cmdline_fixed_string_t stop;
-};
-
-static void cmd_stop_parsed(__attribute__((unused)) void *parsed_result,
-			    struct cmdline *cl,
-			    __attribute__((unused)) void *data)
-{
-	rte_spinlock_trylock(&global_flag_stru_p->lock);
-	if (global_flag_stru_p->LcoreMainIsRunning == 0)	{
-		cmdline_printf(cl,
-					"lcore_main not running on core:%d\n",
-					global_flag_stru_p->LcoreMainCore);
-		rte_spinlock_unlock(&global_flag_stru_p->lock);
-		return;
-	}
-	global_flag_stru_p->LcoreMainIsRunning = 0;
-	if (rte_eal_wait_lcore(global_flag_stru_p->LcoreMainCore) < 0)
-		cmdline_printf(cl,
-				"error: lcore_main can not stop on core:%d\n",
-				global_flag_stru_p->LcoreMainCore);
-	else
-		cmdline_printf(cl,
-				"lcore_main stopped on core:%d\n",
-				global_flag_stru_p->LcoreMainCore);
-	rte_spinlock_unlock(&global_flag_stru_p->lock);
-}
-
-cmdline_parse_token_string_t cmd_stop_stop =
-	TOKEN_STRING_INITIALIZER(struct cmd_stop_result, stop, "stop");
-
-cmdline_parse_inst_t cmd_stop = {
-	.f = cmd_stop_parsed,  /* function to call */
-	.data = NULL,      /* 2nd arg of func */
-	.help_str = "this command do not handle any arguments",
-	.tokens = {        /* token list, NULL terminated */
-		(void *)&cmd_stop_stop,
-		NULL,
-	},
-};
-
-struct cmd_quit_result {
-	cmdline_fixed_string_t quit;
-};
-
-static void cmd_quit_parsed(__attribute__((unused)) void *parsed_result,
-			    struct cmdline *cl,
-			    __attribute__((unused)) void *data)
-{
-	rte_spinlock_trylock(&global_flag_stru_p->lock);
-	if (global_flag_stru_p->LcoreMainIsRunning == 0)	{
-		cmdline_printf(cl,
-					"lcore_main not running on core:%d\n",
-					global_flag_stru_p->LcoreMainCore);
-		rte_spinlock_unlock(&global_flag_stru_p->lock);
-		cmdline_quit(cl);
-		return;
-	}
-	global_flag_stru_p->LcoreMainIsRunning = 0;
-	if (rte_eal_wait_lcore(global_flag_stru_p->LcoreMainCore) < 0)
-		cmdline_printf(cl,
-				"error: lcore_main can not stop on core:%d\n",
-				global_flag_stru_p->LcoreMainCore);
-	else
-		cmdline_printf(cl,
-				"lcore_main stopped on core:%d\n",
-				global_flag_stru_p->LcoreMainCore);
-	rte_spinlock_unlock(&global_flag_stru_p->lock);
-	cmdline_quit(cl);
-}
-
-cmdline_parse_token_string_t cmd_quit_quit =
-	TOKEN_STRING_INITIALIZER(struct cmd_quit_result, quit, "quit");
-
-cmdline_parse_inst_t cmd_quit = {
-	.f = cmd_quit_parsed,  /* function to call */
-	.data = NULL,      /* 2nd arg of func */
-	.help_str = "this command do not handle any arguments",
-	.tokens = {        /* token list, NULL terminated */
-		(void *)&cmd_quit_quit,
-		NULL,
-	},
-};
-
-struct cmd_show_result {
-	cmdline_fixed_string_t show;
-};
-
-static void cmd_show_parsed(__attribute__((unused)) void *parsed_result,
-			    struct cmdline *cl,
-			    __attribute__((unused)) void *data)
-{
-	uint16_t slaves[16] = {0};
-	uint8_t len = 16;
-	struct ether_addr addr;
-	uint16_t i = 0;
-
-	while (i < slaves_count)	{
-		rte_eth_macaddr_get(i, &addr);
-		PRINT_MAC(addr);
-		printf("\n");
-		i++;
-	}
-
-	rte_spinlock_trylock(&global_flag_stru_p->lock);
-	cmdline_printf(cl,
-			"Active_slaves:%d "
-			"packets received:Tot:%d Arp:%d IPv4:%d\n",
-			rte_eth_bond_active_slaves_get(BOND_PORT, slaves, len),
-			global_flag_stru_p->port_packets[0],
-			global_flag_stru_p->port_packets[1],
-			global_flag_stru_p->port_packets[2]);
-	rte_spinlock_unlock(&global_flag_stru_p->lock);
-}
-
-cmdline_parse_token_string_t cmd_show_show =
-	TOKEN_STRING_INITIALIZER(struct cmd_show_result, show, "show");
-
-cmdline_parse_inst_t cmd_show = {
-	.f = cmd_show_parsed,  /* function to call */
-	.data = NULL,      /* 2nd arg of func */
-	.help_str = "this command do not handle any arguments",
-	.tokens = {        /* token list, NULL terminated */
-		(void *)&cmd_show_show,
-		NULL,
-	},
-};
-
-/****** CONTEXT (list of instruction) */
-
-cmdline_parse_ctx_t main_ctx[] = {
-	(cmdline_parse_inst_t *)&cmd_start,
-	(cmdline_parse_inst_t *)&cmd_obj_send,
-	(cmdline_parse_inst_t *)&cmd_stop,
-	(cmdline_parse_inst_t *)&cmd_show,
-	(cmdline_parse_inst_t *)&cmd_quit,
-	(cmdline_parse_inst_t *)&cmd_help,
-	NULL,
-};
-
-/* prompt function, called from main on MASTER lcore */
-static void prompt(__attribute__((unused)) void *arg1)
-{
-	struct cmdline *cl;
-
-	cl = cmdline_stdin_new(main_ctx, "bond6>");
-	if (cl != NULL) {
-		cmdline_interact(cl);
-		cmdline_stdin_exit(cl);
-	}
-}
-
-/* Main function, does initialisation and calls the per-lcore functions */
-int
-main(int argc, char *argv[])
-{
-	int ret;
-	uint16_t nb_ports, i;
-
-	/* init EAL */
-	ret = rte_eal_init(argc, argv);
-	rte_eal_devargs_dump(stdout);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Error with EAL initialization\n");
-	argc -= ret;
-	argv += ret;
-
-	nb_ports = rte_eth_dev_count();
-	if (nb_ports == 0)
-		rte_exit(EXIT_FAILURE, "Give at least one port\n");
-	else if (nb_ports > MAX_PORTS)
-		rte_exit(EXIT_FAILURE, "You can have max 4 ports\n");
-
-	mbuf_pool = rte_pktmbuf_pool_create("MBUF_POOL", NB_MBUF, 32,
-		0, RTE_MBUF_DEFAULT_BUF_SIZE, rte_socket_id());
-	if (mbuf_pool == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot create mbuf pool\n");
-
-	/* initialize all ports */
-	slaves_count = nb_ports;
-	RTE_ETH_FOREACH_DEV(i) {
-		slave_port_init(i, mbuf_pool);
-		slaves[i] = i;
-	}
-
-	bond_port_init(mbuf_pool);
-
-	rte_spinlock_init(&global_flag_stru_p->lock);
-	int slave_core_id = rte_lcore_id();
-
-	/* check state of lcores */
-	RTE_LCORE_FOREACH_SLAVE(slave_core_id) {
-	if (lcore_config[slave_core_id].state != WAIT)
-		return -EBUSY;
-	}
-	/* start lcore main on core != master_core - ARP response thread */
-	slave_core_id = rte_get_next_lcore(rte_lcore_id(), 1, 0);
-	if ((slave_core_id >= RTE_MAX_LCORE) || (slave_core_id == 0))
-		return -EPERM;
-
-	global_flag_stru_p->LcoreMainIsRunning = 1;
-	global_flag_stru_p->LcoreMainCore = slave_core_id;
-	printf("Starting lcore_main on core %d:%d Our IP:%d.%d.%d.%d\n",
-			slave_core_id,
-			rte_eal_remote_launch((lcore_function_t *)lcore_main,
-					NULL,
-					slave_core_id),
-			BOND_IP_1,
-			BOND_IP_2,
-			BOND_IP_3,
-			BOND_IP_4
-		);
-
-	/* Start prompt for user interact */
-	prompt(NULL);
-
-	rte_delay_ms(100);
-	return 0;
-}
diff --git a/examples/bond/main.h b/examples/bond/main.h
deleted file mode 100644
index f91ed9c..0000000
--- a/examples/bond/main.h
+++ /dev/null
@@ -1,10 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#ifndef _MAIN_H_
-#define _MAIN_H_
-
-int main(int argc, char *argv[]);
-
-#endif /* ifndef _MAIN_H_ */
diff --git a/examples/bond/meson.build b/examples/bond/meson.build
deleted file mode 100644
index 82e355a..0000000
--- a/examples/bond/meson.build
+++ /dev/null
@@ -1,13 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-deps += 'pmd_bond'
-allow_experimental_apis = true
-sources = files(
-	'main.c'
-)
diff --git a/examples/cmdline/Makefile b/examples/cmdline/Makefile
deleted file mode 100644
index 7893c85..0000000
--- a/examples/cmdline/Makefile
+++ /dev/null
@@ -1,63 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-# binary name
-APP = cmdline
-
-# all source are stored in SRCS-y
-SRCS-y := main.c commands.c parse_obj_list.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-# binary name
-APP = cmdline
-
-# all source are stored in SRCS-y
-SRCS-y := main.c commands.c parse_obj_list.c
-
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-CFLAGS_parse_obj_list.o := -D_GNU_SOURCE
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-
-endif
diff --git a/examples/cmdline/commands.c b/examples/cmdline/commands.c
deleted file mode 100644
index 06916d7..0000000
--- a/examples/cmdline/commands.c
+++ /dev/null
@@ -1,229 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation.
- * Copyright (c) 2009, Olivier MATZ <zer0@droids-corp.org>
- * All rights reserved.
- */
-
-#include <stdio.h>
-#include <stdint.h>
-#include <string.h>
-#include <stdlib.h>
-#include <stdarg.h>
-#include <errno.h>
-#include <netinet/in.h>
-#include <termios.h>
-#ifndef __linux__
-	#ifdef __FreeBSD__
-		#include <sys/socket.h>
-	#else
-		#include <net/socket.h>
-	#endif
-#endif
-
-#include <cmdline_rdline.h>
-#include <cmdline_parse.h>
-#include <cmdline_parse_ipaddr.h>
-#include <cmdline_parse_num.h>
-#include <cmdline_parse_string.h>
-#include <cmdline.h>
-
-#include <rte_string_fns.h>
-
-#include "parse_obj_list.h"
-
-struct object_list global_obj_list;
-
-/* not defined under linux */
-#ifndef NIPQUAD
-#define NIPQUAD_FMT "%u.%u.%u.%u"
-#define NIPQUAD(addr)				\
-	(unsigned)((unsigned char *)&addr)[0],	\
-	(unsigned)((unsigned char *)&addr)[1],	\
-	(unsigned)((unsigned char *)&addr)[2],	\
-	(unsigned)((unsigned char *)&addr)[3]
-#endif
-
-#ifndef NIP6
-#define NIP6_FMT "%02x%02x:%02x%02x:%02x%02x:%02x%02x:%02x%02x:%02x%02x:%02x%02x:%02x%02x"
-#define NIP6(addr)					\
-	(unsigned)((addr).s6_addr[0]),			\
-	(unsigned)((addr).s6_addr[1]),			\
-	(unsigned)((addr).s6_addr[2]),			\
-	(unsigned)((addr).s6_addr[3]),			\
-	(unsigned)((addr).s6_addr[4]),			\
-	(unsigned)((addr).s6_addr[5]),			\
-	(unsigned)((addr).s6_addr[6]),			\
-	(unsigned)((addr).s6_addr[7]),			\
-	(unsigned)((addr).s6_addr[8]),			\
-	(unsigned)((addr).s6_addr[9]),			\
-	(unsigned)((addr).s6_addr[10]),			\
-	(unsigned)((addr).s6_addr[11]),			\
-	(unsigned)((addr).s6_addr[12]),			\
-	(unsigned)((addr).s6_addr[13]),			\
-	(unsigned)((addr).s6_addr[14]),			\
-	(unsigned)((addr).s6_addr[15])
-#endif
-
-
-/**********************************************************/
-
-struct cmd_obj_del_show_result {
-	cmdline_fixed_string_t action;
-	struct object *obj;
-};
-
-static void cmd_obj_del_show_parsed(void *parsed_result,
-				    struct cmdline *cl,
-				    __attribute__((unused)) void *data)
-{
-	struct cmd_obj_del_show_result *res = parsed_result;
-	char ip_str[INET6_ADDRSTRLEN];
-
-	if (res->obj->ip.family == AF_INET)
-		snprintf(ip_str, sizeof(ip_str), NIPQUAD_FMT,
-			 NIPQUAD(res->obj->ip.addr.ipv4));
-	else
-		snprintf(ip_str, sizeof(ip_str), NIP6_FMT,
-			 NIP6(res->obj->ip.addr.ipv6));
-
-	if (strcmp(res->action, "del") == 0) {
-		SLIST_REMOVE(&global_obj_list, res->obj, object, next);
-		cmdline_printf(cl, "Object %s removed, ip=%s\n",
-			       res->obj->name, ip_str);
-		free(res->obj);
-	}
-	else if (strcmp(res->action, "show") == 0) {
-		cmdline_printf(cl, "Object %s, ip=%s\n",
-			       res->obj->name, ip_str);
-	}
-}
-
-cmdline_parse_token_string_t cmd_obj_action =
-	TOKEN_STRING_INITIALIZER(struct cmd_obj_del_show_result,
-				 action, "show#del");
-parse_token_obj_list_t cmd_obj_obj =
-	TOKEN_OBJ_LIST_INITIALIZER(struct cmd_obj_del_show_result, obj,
-				   &global_obj_list);
-
-cmdline_parse_inst_t cmd_obj_del_show = {
-	.f = cmd_obj_del_show_parsed,  /* function to call */
-	.data = NULL,      /* 2nd arg of func */
-	.help_str = "Show/del an object",
-	.tokens = {        /* token list, NULL terminated */
-		(void *)&cmd_obj_action,
-		(void *)&cmd_obj_obj,
-		NULL,
-	},
-};
-
-/**********************************************************/
-
-struct cmd_obj_add_result {
-	cmdline_fixed_string_t action;
-	cmdline_fixed_string_t name;
-	cmdline_ipaddr_t ip;
-};
-
-static void cmd_obj_add_parsed(void *parsed_result,
-			       struct cmdline *cl,
-			       __attribute__((unused)) void *data)
-{
-	struct cmd_obj_add_result *res = parsed_result;
-	struct object *o;
-	char ip_str[INET6_ADDRSTRLEN];
-
-	SLIST_FOREACH(o, &global_obj_list, next) {
-		if (!strcmp(res->name, o->name)) {
-			cmdline_printf(cl, "Object %s already exist\n", res->name);
-			return;
-		}
-		break;
-	}
-
-	o = malloc(sizeof(*o));
-	if (!o) {
-		cmdline_printf(cl, "mem error\n");
-		return;
-	}
-	snprintf(o->name, sizeof(o->name), "%s", res->name);
-	o->ip = res->ip;
-	SLIST_INSERT_HEAD(&global_obj_list, o, next);
-
-	if (o->ip.family == AF_INET)
-		snprintf(ip_str, sizeof(ip_str), NIPQUAD_FMT,
-			 NIPQUAD(o->ip.addr.ipv4));
-	else
-		snprintf(ip_str, sizeof(ip_str), NIP6_FMT,
-			 NIP6(o->ip.addr.ipv6));
-
-	cmdline_printf(cl, "Object %s added, ip=%s\n",
-		       o->name, ip_str);
-}
-
-cmdline_parse_token_string_t cmd_obj_action_add =
-	TOKEN_STRING_INITIALIZER(struct cmd_obj_add_result, action, "add");
-cmdline_parse_token_string_t cmd_obj_name =
-	TOKEN_STRING_INITIALIZER(struct cmd_obj_add_result, name, NULL);
-cmdline_parse_token_ipaddr_t cmd_obj_ip =
-	TOKEN_IPADDR_INITIALIZER(struct cmd_obj_add_result, ip);
-
-cmdline_parse_inst_t cmd_obj_add = {
-	.f = cmd_obj_add_parsed,  /* function to call */
-	.data = NULL,      /* 2nd arg of func */
-	.help_str = "Add an object (name, val)",
-	.tokens = {        /* token list, NULL terminated */
-		(void *)&cmd_obj_action_add,
-		(void *)&cmd_obj_name,
-		(void *)&cmd_obj_ip,
-		NULL,
-	},
-};
-
-/**********************************************************/
-
-struct cmd_help_result {
-	cmdline_fixed_string_t help;
-};
-
-static void cmd_help_parsed(__attribute__((unused)) void *parsed_result,
-			    struct cmdline *cl,
-			    __attribute__((unused)) void *data)
-{
-	cmdline_printf(cl,
-		       "Demo example of command line interface in RTE\n\n"
-		       "This is a readline-like interface that can be used to\n"
-		       "debug your RTE application. It supports some features\n"
-		       "of GNU readline like completion, cut/paste, and some\n"
-		       "other special bindings.\n\n"
-		       "This demo shows how rte_cmdline library can be\n"
-		       "extended to handle a list of objects. There are\n"
-		       "3 commands:\n"
-		       "- add obj_name IP\n"
-		       "- del obj_name\n"
-		       "- show obj_name\n\n");
-}
-
-cmdline_parse_token_string_t cmd_help_help =
-	TOKEN_STRING_INITIALIZER(struct cmd_help_result, help, "help");
-
-cmdline_parse_inst_t cmd_help = {
-	.f = cmd_help_parsed,  /* function to call */
-	.data = NULL,      /* 2nd arg of func */
-	.help_str = "show help",
-	.tokens = {        /* token list, NULL terminated */
-		(void *)&cmd_help_help,
-		NULL,
-	},
-};
-
-
-/**********************************************************/
-/**********************************************************/
-/****** CONTEXT (list of instruction) */
-
-cmdline_parse_ctx_t main_ctx[] = {
-	(cmdline_parse_inst_t *)&cmd_obj_del_show,
-	(cmdline_parse_inst_t *)&cmd_obj_add,
-	(cmdline_parse_inst_t *)&cmd_help,
-	NULL,
-};
diff --git a/examples/cmdline/commands.h b/examples/cmdline/commands.h
deleted file mode 100644
index 7912045..0000000
--- a/examples/cmdline/commands.h
+++ /dev/null
@@ -1,10 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#ifndef _COMMANDS_H_
-#define _COMMANDS_H_
-
-extern cmdline_parse_ctx_t main_ctx[];
-
-#endif /* _COMMANDS_H_ */
diff --git a/examples/cmdline/main.c b/examples/cmdline/main.c
deleted file mode 100644
index f2f2e5a..0000000
--- a/examples/cmdline/main.c
+++ /dev/null
@@ -1,41 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation.
- * Copyright (c) 2009, Olivier MATZ <zer0@droids-corp.org>
- * All rights reserved.
- */
-
-#include <stdio.h>
-#include <string.h>
-#include <stdint.h>
-#include <errno.h>
-#include <termios.h>
-#include <sys/queue.h>
-
-#include <cmdline_rdline.h>
-#include <cmdline_parse.h>
-#include <cmdline_socket.h>
-#include <cmdline.h>
-
-#include <rte_memory.h>
-#include <rte_eal.h>
-#include <rte_debug.h>
-
-#include "commands.h"
-
-int main(int argc, char **argv)
-{
-	int ret;
-	struct cmdline *cl;
-
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_panic("Cannot init EAL\n");
-
-	cl = cmdline_stdin_new(main_ctx, "example> ");
-	if (cl == NULL)
-		rte_panic("Cannot create cmdline instance\n");
-	cmdline_interact(cl);
-	cmdline_stdin_exit(cl);
-
-	return 0;
-}
diff --git a/examples/cmdline/meson.build b/examples/cmdline/meson.build
deleted file mode 100644
index a8608c2..0000000
--- a/examples/cmdline/meson.build
+++ /dev/null
@@ -1,11 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-sources = files(
-	'commands.c', 'main.c', 'parse_obj_list.c'
-)
diff --git a/examples/cmdline/parse_obj_list.c b/examples/cmdline/parse_obj_list.c
deleted file mode 100644
index 69eb448..0000000
--- a/examples/cmdline/parse_obj_list.c
+++ /dev/null
@@ -1,112 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation.
- * Copyright (c) 2009, Olivier MATZ <zer0@droids-corp.org>
- * All rights reserved.
- */
-
-#include <stdio.h>
-#include <inttypes.h>
-#include <stdarg.h>
-#include <errno.h>
-#include <ctype.h>
-#include <string.h>
-#include <netinet/in.h>
-
-#include <cmdline_parse.h>
-#include <cmdline_parse_ipaddr.h>
-
-#include <rte_string_fns.h>
-
-#include "parse_obj_list.h"
-
-/* This file is an example of extension of libcmdline. It provides an
- * example of objects stored in a list. */
-
-struct cmdline_token_ops token_obj_list_ops = {
-	.parse = parse_obj_list,
-	.complete_get_nb = complete_get_nb_obj_list,
-	.complete_get_elt = complete_get_elt_obj_list,
-	.get_help = get_help_obj_list,
-};
-
-int
-parse_obj_list(cmdline_parse_token_hdr_t *tk, const char *buf, void *res,
-	unsigned ressize)
-{
-	struct token_obj_list *tk2 = (struct token_obj_list *)tk;
-	struct token_obj_list_data *tkd = &tk2->obj_list_data;
-	struct object *o;
-	unsigned int token_len = 0;
-
-	if (*buf == 0)
-		return -1;
-
-	if (res && ressize < sizeof(struct object *))
-		return -1;
-
-	while(!cmdline_isendoftoken(buf[token_len]))
-		token_len++;
-
-	SLIST_FOREACH(o, tkd->list, next) {
-		if (token_len != strnlen(o->name, OBJ_NAME_LEN_MAX))
-			continue;
-		if (strncmp(buf, o->name, token_len))
-			continue;
-		break;
-	}
-	if (!o) /* not found */
-		return -1;
-
-	/* store the address of object in structure */
-	if (res)
-		*(struct object **)res = o;
-
-	return token_len;
-}
-
-int complete_get_nb_obj_list(cmdline_parse_token_hdr_t *tk)
-{
-	struct token_obj_list *tk2 = (struct token_obj_list *)tk;
-	struct token_obj_list_data *tkd = &tk2->obj_list_data;
-	struct object *o;
-	int ret = 0;
-
-	SLIST_FOREACH(o, tkd->list, next) {
-		ret ++;
-	}
-	return ret;
-}
-
-int complete_get_elt_obj_list(cmdline_parse_token_hdr_t *tk,
-			      int idx, char *dstbuf, unsigned int size)
-{
-	struct token_obj_list *tk2 = (struct token_obj_list *)tk;
-	struct token_obj_list_data *tkd = &tk2->obj_list_data;
-	struct object *o;
-	int i = 0;
-	unsigned len;
-
-	SLIST_FOREACH(o, tkd->list, next) {
-		if (i++ == idx)
-			break;
-	}
-	if (!o)
-		return -1;
-
-	len = strnlen(o->name, OBJ_NAME_LEN_MAX);
-	if ((len + 1) > size)
-		return -1;
-
-	if (dstbuf)
-		snprintf(dstbuf, size, "%s", o->name);
-
-	return 0;
-}
-
-
-int get_help_obj_list(__attribute__((unused)) cmdline_parse_token_hdr_t *tk,
-		      char *dstbuf, unsigned int size)
-{
-	snprintf(dstbuf, size, "Obj-List");
-	return 0;
-}
diff --git a/examples/cmdline/parse_obj_list.h b/examples/cmdline/parse_obj_list.h
deleted file mode 100644
index 6516d3e..0000000
--- a/examples/cmdline/parse_obj_list.h
+++ /dev/null
@@ -1,58 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation.
- * Copyright (c) 2009, Olivier MATZ <zer0@droids-corp.org>
- * All rights reserved.
- */
-
-#ifndef _PARSE_OBJ_LIST_H_
-#define _PARSE_OBJ_LIST_H_
-
-/* This file is an example of extension of libcmdline. It provides an
- * example of objects stored in a list. */
-
-#include <sys/queue.h>
-#include <cmdline_parse.h>
-
-#define OBJ_NAME_LEN_MAX 64
-
-struct object {
-	SLIST_ENTRY(object) next;
-	char name[OBJ_NAME_LEN_MAX];
-	cmdline_ipaddr_t ip;
-};
-
-/* define struct object_list */
-SLIST_HEAD(object_list, object);
-
-/* data is a pointer to a list */
-struct token_obj_list_data {
-	struct object_list *list;
-};
-
-struct token_obj_list {
-	struct cmdline_token_hdr hdr;
-	struct token_obj_list_data obj_list_data;
-};
-typedef struct token_obj_list parse_token_obj_list_t;
-
-extern struct cmdline_token_ops token_obj_list_ops;
-
-int parse_obj_list(cmdline_parse_token_hdr_t *tk, const char *srcbuf, void *res,
-	unsigned ressize);
-int complete_get_nb_obj_list(cmdline_parse_token_hdr_t *tk);
-int complete_get_elt_obj_list(cmdline_parse_token_hdr_t *tk, int idx,
-			      char *dstbuf, unsigned int size);
-int get_help_obj_list(cmdline_parse_token_hdr_t *tk, char *dstbuf, unsigned int size);
-
-#define TOKEN_OBJ_LIST_INITIALIZER(structure, field, obj_list_ptr)  \
-{								    \
-	.hdr = {						    \
-		.ops = &token_obj_list_ops,			    \
-		.offset = offsetof(structure, field),		    \
-	},							    \
-		.obj_list_data = {				    \
-		.list = obj_list_ptr,				    \
-	},							    \
-}
-
-#endif /* _PARSE_OBJ_LIST_H_ */
diff --git a/examples/distributor/Makefile b/examples/distributor/Makefile
deleted file mode 100644
index cb1bd21..0000000
--- a/examples/distributor/Makefile
+++ /dev/null
@@ -1,66 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-# binary name
-APP = distributor_app
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += $(WERROR_FLAGS)
-
-# workaround for a gcc bug with noreturn attribute
-# http://gcc.gnu.org/bugzilla/show_bug.cgi?id=12603
-ifeq ($(CONFIG_RTE_TOOLCHAIN_GCC),y)
-CFLAGS_main.o += -Wno-return-type
-endif
-
-EXTRA_CFLAGS += -O3 -Wfatal-errors
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-
-endif
diff --git a/examples/distributor/main.c b/examples/distributor/main.c
deleted file mode 100644
index 2e6b09d..0000000
--- a/examples/distributor/main.c
+++ /dev/null
@@ -1,801 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2017 Intel Corporation
- */
-
-#include <stdint.h>
-#include <inttypes.h>
-#include <unistd.h>
-#include <signal.h>
-#include <getopt.h>
-
-#include <rte_eal.h>
-#include <rte_ethdev.h>
-#include <rte_cycles.h>
-#include <rte_malloc.h>
-#include <rte_debug.h>
-#include <rte_prefetch.h>
-#include <rte_distributor.h>
-#include <rte_pause.h>
-
-#define RX_RING_SIZE 1024
-#define TX_RING_SIZE 1024
-#define NUM_MBUFS ((64*1024)-1)
-#define MBUF_CACHE_SIZE 128
-#define BURST_SIZE 64
-#define SCHED_RX_RING_SZ 8192
-#define SCHED_TX_RING_SZ 65536
-#define BURST_SIZE_TX 32
-
-#define RTE_LOGTYPE_DISTRAPP RTE_LOGTYPE_USER1
-
-#define ANSI_COLOR_RED     "\x1b[31m"
-#define ANSI_COLOR_RESET   "\x1b[0m"
-
-/* mask of enabled ports */
-static uint32_t enabled_port_mask;
-volatile uint8_t quit_signal;
-volatile uint8_t quit_signal_rx;
-volatile uint8_t quit_signal_dist;
-volatile uint8_t quit_signal_work;
-
-static volatile struct app_stats {
-	struct {
-		uint64_t rx_pkts;
-		uint64_t returned_pkts;
-		uint64_t enqueued_pkts;
-		uint64_t enqdrop_pkts;
-	} rx __rte_cache_aligned;
-	int pad1 __rte_cache_aligned;
-
-	struct {
-		uint64_t in_pkts;
-		uint64_t ret_pkts;
-		uint64_t sent_pkts;
-		uint64_t enqdrop_pkts;
-	} dist __rte_cache_aligned;
-	int pad2 __rte_cache_aligned;
-
-	struct {
-		uint64_t dequeue_pkts;
-		uint64_t tx_pkts;
-		uint64_t enqdrop_pkts;
-	} tx __rte_cache_aligned;
-	int pad3 __rte_cache_aligned;
-
-	uint64_t worker_pkts[64] __rte_cache_aligned;
-
-	int pad4 __rte_cache_aligned;
-
-	uint64_t worker_bursts[64][8] __rte_cache_aligned;
-
-	int pad5 __rte_cache_aligned;
-
-	uint64_t port_rx_pkts[64] __rte_cache_aligned;
-	uint64_t port_tx_pkts[64] __rte_cache_aligned;
-} app_stats;
-
-struct app_stats prev_app_stats;
-
-static const struct rte_eth_conf port_conf_default = {
-	.rxmode = {
-		.mq_mode = ETH_MQ_RX_RSS,
-		.max_rx_pkt_len = ETHER_MAX_LEN,
-		.ignore_offload_bitfield = 1,
-	},
-	.txmode = {
-		.mq_mode = ETH_MQ_TX_NONE,
-	},
-	.rx_adv_conf = {
-		.rss_conf = {
-			.rss_hf = ETH_RSS_IP | ETH_RSS_UDP |
-				ETH_RSS_TCP | ETH_RSS_SCTP,
-		}
-	},
-};
-
-struct output_buffer {
-	unsigned count;
-	struct rte_mbuf *mbufs[BURST_SIZE];
-};
-
-static void print_stats(void);
-
-/*
- * Initialises a given port using global settings and with the rx buffers
- * coming from the mbuf_pool passed as parameter
- */
-static inline int
-port_init(uint16_t port, struct rte_mempool *mbuf_pool)
-{
-	struct rte_eth_conf port_conf = port_conf_default;
-	const uint16_t rxRings = 1, txRings = rte_lcore_count() - 1;
-	int retval;
-	uint16_t q;
-	uint16_t nb_rxd = RX_RING_SIZE;
-	uint16_t nb_txd = TX_RING_SIZE;
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_txconf txconf;
-
-	if (!rte_eth_dev_is_valid_port(port))
-		return -1;
-
-	rte_eth_dev_info_get(port, &dev_info);
-	if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-		port_conf.txmode.offloads |=
-			DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-
-	retval = rte_eth_dev_configure(port, rxRings, txRings, &port_conf);
-	if (retval != 0)
-		return retval;
-
-	retval = rte_eth_dev_adjust_nb_rx_tx_desc(port, &nb_rxd, &nb_txd);
-	if (retval != 0)
-		return retval;
-
-	for (q = 0; q < rxRings; q++) {
-		retval = rte_eth_rx_queue_setup(port, q, nb_rxd,
-						rte_eth_dev_socket_id(port),
-						NULL, mbuf_pool);
-		if (retval < 0)
-			return retval;
-	}
-
-	txconf = dev_info.default_txconf;
-	txconf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-	txconf.offloads = port_conf.txmode.offloads;
-	for (q = 0; q < txRings; q++) {
-		retval = rte_eth_tx_queue_setup(port, q, nb_txd,
-						rte_eth_dev_socket_id(port),
-						&txconf);
-		if (retval < 0)
-			return retval;
-	}
-
-	retval = rte_eth_dev_start(port);
-	if (retval < 0)
-		return retval;
-
-	struct rte_eth_link link;
-	rte_eth_link_get_nowait(port, &link);
-	while (!link.link_status) {
-		printf("Waiting for Link up on port %"PRIu16"\n", port);
-		sleep(1);
-		rte_eth_link_get_nowait(port, &link);
-	}
-
-	if (!link.link_status) {
-		printf("Link down on port %"PRIu16"\n", port);
-		return 0;
-	}
-
-	struct ether_addr addr;
-	rte_eth_macaddr_get(port, &addr);
-	printf("Port %u MAC: %02"PRIx8" %02"PRIx8" %02"PRIx8
-			" %02"PRIx8" %02"PRIx8" %02"PRIx8"\n",
-			port,
-			addr.addr_bytes[0], addr.addr_bytes[1],
-			addr.addr_bytes[2], addr.addr_bytes[3],
-			addr.addr_bytes[4], addr.addr_bytes[5]);
-
-	rte_eth_promiscuous_enable(port);
-
-	return 0;
-}
-
-struct lcore_params {
-	unsigned worker_id;
-	struct rte_distributor *d;
-	struct rte_ring *rx_dist_ring;
-	struct rte_ring *dist_tx_ring;
-	struct rte_mempool *mem_pool;
-};
-
-static int
-lcore_rx(struct lcore_params *p)
-{
-	const uint16_t nb_ports = rte_eth_dev_count();
-	const int socket_id = rte_socket_id();
-	uint16_t port;
-	struct rte_mbuf *bufs[BURST_SIZE*2];
-
-	RTE_ETH_FOREACH_DEV(port) {
-		/* skip ports that are not enabled */
-		if ((enabled_port_mask & (1 << port)) == 0)
-			continue;
-
-		if (rte_eth_dev_socket_id(port) > 0 &&
-				rte_eth_dev_socket_id(port) != socket_id)
-			printf("WARNING, port %u is on remote NUMA node to "
-					"RX thread.\n\tPerformance will not "
-					"be optimal.\n", port);
-	}
-
-	printf("\nCore %u doing packet RX.\n", rte_lcore_id());
-	port = 0;
-	while (!quit_signal_rx) {
-
-		/* skip ports that are not enabled */
-		if ((enabled_port_mask & (1 << port)) == 0) {
-			if (++port == nb_ports)
-				port = 0;
-			continue;
-		}
-		const uint16_t nb_rx = rte_eth_rx_burst(port, 0, bufs,
-				BURST_SIZE);
-		if (unlikely(nb_rx == 0)) {
-			if (++port == nb_ports)
-				port = 0;
-			continue;
-		}
-		app_stats.rx.rx_pkts += nb_rx;
-
-/*
- * You can run the distributor on the rx core with this code. Returned
- * packets are then send straight to the tx core.
- */
-#if 0
-	rte_distributor_process(d, bufs, nb_rx);
-	const uint16_t nb_ret = rte_distributor_returned_pktsd,
-			bufs, BURST_SIZE*2);
-
-		app_stats.rx.returned_pkts += nb_ret;
-		if (unlikely(nb_ret == 0)) {
-			if (++port == nb_ports)
-				port = 0;
-			continue;
-		}
-
-		struct rte_ring *tx_ring = p->dist_tx_ring;
-		uint16_t sent = rte_ring_enqueue_burst(tx_ring,
-				(void *)bufs, nb_ret, NULL);
-#else
-		uint16_t nb_ret = nb_rx;
-		/*
-		 * Swap the following two lines if you want the rx traffic
-		 * to go directly to tx, no distribution.
-		 */
-		struct rte_ring *out_ring = p->rx_dist_ring;
-		/* struct rte_ring *out_ring = p->dist_tx_ring; */
-
-		uint16_t sent = rte_ring_enqueue_burst(out_ring,
-				(void *)bufs, nb_ret, NULL);
-#endif
-
-		app_stats.rx.enqueued_pkts += sent;
-		if (unlikely(sent < nb_ret)) {
-			app_stats.rx.enqdrop_pkts +=  nb_ret - sent;
-			RTE_LOG_DP(DEBUG, DISTRAPP,
-				"%s:Packet loss due to full ring\n", __func__);
-			while (sent < nb_ret)
-				rte_pktmbuf_free(bufs[sent++]);
-		}
-		if (++port == nb_ports)
-			port = 0;
-	}
-	/* set worker & tx threads quit flag */
-	printf("\nCore %u exiting rx task.\n", rte_lcore_id());
-	quit_signal = 1;
-	return 0;
-}
-
-static inline void
-flush_one_port(struct output_buffer *outbuf, uint8_t outp)
-{
-	unsigned int nb_tx = rte_eth_tx_burst(outp, 0,
-			outbuf->mbufs, outbuf->count);
-	app_stats.tx.tx_pkts += outbuf->count;
-
-	if (unlikely(nb_tx < outbuf->count)) {
-		app_stats.tx.enqdrop_pkts +=  outbuf->count - nb_tx;
-		do {
-			rte_pktmbuf_free(outbuf->mbufs[nb_tx]);
-		} while (++nb_tx < outbuf->count);
-	}
-	outbuf->count = 0;
-}
-
-static inline void
-flush_all_ports(struct output_buffer *tx_buffers)
-{
-	uint16_t outp;
-
-	RTE_ETH_FOREACH_DEV(outp) {
-		/* skip ports that are not enabled */
-		if ((enabled_port_mask & (1 << outp)) == 0)
-			continue;
-
-		if (tx_buffers[outp].count == 0)
-			continue;
-
-		flush_one_port(&tx_buffers[outp], outp);
-	}
-}
-
-
-
-static int
-lcore_distributor(struct lcore_params *p)
-{
-	struct rte_ring *in_r = p->rx_dist_ring;
-	struct rte_ring *out_r = p->dist_tx_ring;
-	struct rte_mbuf *bufs[BURST_SIZE * 4];
-	struct rte_distributor *d = p->d;
-
-	printf("\nCore %u acting as distributor core.\n", rte_lcore_id());
-	while (!quit_signal_dist) {
-		const uint16_t nb_rx = rte_ring_dequeue_burst(in_r,
-				(void *)bufs, BURST_SIZE*1, NULL);
-		if (nb_rx) {
-			app_stats.dist.in_pkts += nb_rx;
-
-			/* Distribute the packets */
-			rte_distributor_process(d, bufs, nb_rx);
-			/* Handle Returns */
-			const uint16_t nb_ret =
-				rte_distributor_returned_pkts(d,
-					bufs, BURST_SIZE*2);
-
-			if (unlikely(nb_ret == 0))
-				continue;
-			app_stats.dist.ret_pkts += nb_ret;
-
-			uint16_t sent = rte_ring_enqueue_burst(out_r,
-					(void *)bufs, nb_ret, NULL);
-			app_stats.dist.sent_pkts += sent;
-			if (unlikely(sent < nb_ret)) {
-				app_stats.dist.enqdrop_pkts += nb_ret - sent;
-				RTE_LOG(DEBUG, DISTRAPP,
-					"%s:Packet loss due to full out ring\n",
-					__func__);
-				while (sent < nb_ret)
-					rte_pktmbuf_free(bufs[sent++]);
-			}
-		}
-	}
-	printf("\nCore %u exiting distributor task.\n", rte_lcore_id());
-	quit_signal_work = 1;
-
-	rte_distributor_flush(d);
-	/* Unblock any returns so workers can exit */
-	rte_distributor_clear_returns(d);
-	quit_signal_rx = 1;
-	return 0;
-}
-
-
-static int
-lcore_tx(struct rte_ring *in_r)
-{
-	static struct output_buffer tx_buffers[RTE_MAX_ETHPORTS];
-	const int socket_id = rte_socket_id();
-	uint16_t port;
-
-	RTE_ETH_FOREACH_DEV(port) {
-		/* skip ports that are not enabled */
-		if ((enabled_port_mask & (1 << port)) == 0)
-			continue;
-
-		if (rte_eth_dev_socket_id(port) > 0 &&
-				rte_eth_dev_socket_id(port) != socket_id)
-			printf("WARNING, port %u is on remote NUMA node to "
-					"TX thread.\n\tPerformance will not "
-					"be optimal.\n", port);
-	}
-
-	printf("\nCore %u doing packet TX.\n", rte_lcore_id());
-	while (!quit_signal) {
-
-		RTE_ETH_FOREACH_DEV(port) {
-			/* skip ports that are not enabled */
-			if ((enabled_port_mask & (1 << port)) == 0)
-				continue;
-
-			struct rte_mbuf *bufs[BURST_SIZE_TX];
-			const uint16_t nb_rx = rte_ring_dequeue_burst(in_r,
-					(void *)bufs, BURST_SIZE_TX, NULL);
-			app_stats.tx.dequeue_pkts += nb_rx;
-
-			/* if we get no traffic, flush anything we have */
-			if (unlikely(nb_rx == 0)) {
-				flush_all_ports(tx_buffers);
-				continue;
-			}
-
-			/* for traffic we receive, queue it up for transmit */
-			uint16_t i;
-			rte_prefetch_non_temporal((void *)bufs[0]);
-			rte_prefetch_non_temporal((void *)bufs[1]);
-			rte_prefetch_non_temporal((void *)bufs[2]);
-			for (i = 0; i < nb_rx; i++) {
-				struct output_buffer *outbuf;
-				uint8_t outp;
-				rte_prefetch_non_temporal((void *)bufs[i + 3]);
-				/*
-				 * workers should update in_port to hold the
-				 * output port value
-				 */
-				outp = bufs[i]->port;
-				/* skip ports that are not enabled */
-				if ((enabled_port_mask & (1 << outp)) == 0)
-					continue;
-
-				outbuf = &tx_buffers[outp];
-				outbuf->mbufs[outbuf->count++] = bufs[i];
-				if (outbuf->count == BURST_SIZE_TX)
-					flush_one_port(outbuf, outp);
-			}
-		}
-	}
-	printf("\nCore %u exiting tx task.\n", rte_lcore_id());
-	return 0;
-}
-
-static void
-int_handler(int sig_num)
-{
-	printf("Exiting on signal %d\n", sig_num);
-	/* set quit flag for rx thread to exit */
-	quit_signal_dist = 1;
-}
-
-static void
-print_stats(void)
-{
-	struct rte_eth_stats eth_stats;
-	unsigned int i, j;
-	const unsigned int num_workers = rte_lcore_count() - 4;
-
-	RTE_ETH_FOREACH_DEV(i) {
-		rte_eth_stats_get(i, &eth_stats);
-		app_stats.port_rx_pkts[i] = eth_stats.ipackets;
-		app_stats.port_tx_pkts[i] = eth_stats.opackets;
-	}
-
-	printf("\n\nRX Thread:\n");
-	RTE_ETH_FOREACH_DEV(i) {
-		printf("Port %u Pktsin : %5.2f\n", i,
-				(app_stats.port_rx_pkts[i] -
-				prev_app_stats.port_rx_pkts[i])/1000000.0);
-		prev_app_stats.port_rx_pkts[i] = app_stats.port_rx_pkts[i];
-	}
-	printf(" - Received:    %5.2f\n",
-			(app_stats.rx.rx_pkts -
-			prev_app_stats.rx.rx_pkts)/1000000.0);
-	printf(" - Returned:    %5.2f\n",
-			(app_stats.rx.returned_pkts -
-			prev_app_stats.rx.returned_pkts)/1000000.0);
-	printf(" - Enqueued:    %5.2f\n",
-			(app_stats.rx.enqueued_pkts -
-			prev_app_stats.rx.enqueued_pkts)/1000000.0);
-	printf(" - Dropped:     %s%5.2f%s\n", ANSI_COLOR_RED,
-			(app_stats.rx.enqdrop_pkts -
-			prev_app_stats.rx.enqdrop_pkts)/1000000.0,
-			ANSI_COLOR_RESET);
-
-	printf("Distributor thread:\n");
-	printf(" - In:          %5.2f\n",
-			(app_stats.dist.in_pkts -
-			prev_app_stats.dist.in_pkts)/1000000.0);
-	printf(" - Returned:    %5.2f\n",
-			(app_stats.dist.ret_pkts -
-			prev_app_stats.dist.ret_pkts)/1000000.0);
-	printf(" - Sent:        %5.2f\n",
-			(app_stats.dist.sent_pkts -
-			prev_app_stats.dist.sent_pkts)/1000000.0);
-	printf(" - Dropped      %s%5.2f%s\n", ANSI_COLOR_RED,
-			(app_stats.dist.enqdrop_pkts -
-			prev_app_stats.dist.enqdrop_pkts)/1000000.0,
-			ANSI_COLOR_RESET);
-
-	printf("TX thread:\n");
-	printf(" - Dequeued:    %5.2f\n",
-			(app_stats.tx.dequeue_pkts -
-			prev_app_stats.tx.dequeue_pkts)/1000000.0);
-	RTE_ETH_FOREACH_DEV(i) {
-		printf("Port %u Pktsout: %5.2f\n",
-				i, (app_stats.port_tx_pkts[i] -
-				prev_app_stats.port_tx_pkts[i])/1000000.0);
-		prev_app_stats.port_tx_pkts[i] = app_stats.port_tx_pkts[i];
-	}
-	printf(" - Transmitted: %5.2f\n",
-			(app_stats.tx.tx_pkts -
-			prev_app_stats.tx.tx_pkts)/1000000.0);
-	printf(" - Dropped:     %s%5.2f%s\n", ANSI_COLOR_RED,
-			(app_stats.tx.enqdrop_pkts -
-			prev_app_stats.tx.enqdrop_pkts)/1000000.0,
-			ANSI_COLOR_RESET);
-
-	prev_app_stats.rx.rx_pkts = app_stats.rx.rx_pkts;
-	prev_app_stats.rx.returned_pkts = app_stats.rx.returned_pkts;
-	prev_app_stats.rx.enqueued_pkts = app_stats.rx.enqueued_pkts;
-	prev_app_stats.rx.enqdrop_pkts = app_stats.rx.enqdrop_pkts;
-	prev_app_stats.dist.in_pkts = app_stats.dist.in_pkts;
-	prev_app_stats.dist.ret_pkts = app_stats.dist.ret_pkts;
-	prev_app_stats.dist.sent_pkts = app_stats.dist.sent_pkts;
-	prev_app_stats.dist.enqdrop_pkts = app_stats.dist.enqdrop_pkts;
-	prev_app_stats.tx.dequeue_pkts = app_stats.tx.dequeue_pkts;
-	prev_app_stats.tx.tx_pkts = app_stats.tx.tx_pkts;
-	prev_app_stats.tx.enqdrop_pkts = app_stats.tx.enqdrop_pkts;
-
-	for (i = 0; i < num_workers; i++) {
-		printf("Worker %02u Pkts: %5.2f. Bursts(1-8): ", i,
-				(app_stats.worker_pkts[i] -
-				prev_app_stats.worker_pkts[i])/1000000.0);
-		for (j = 0; j < 8; j++) {
-			printf("%"PRIu64" ", app_stats.worker_bursts[i][j]);
-			app_stats.worker_bursts[i][j] = 0;
-		}
-		printf("\n");
-		prev_app_stats.worker_pkts[i] = app_stats.worker_pkts[i];
-	}
-}
-
-static int
-lcore_worker(struct lcore_params *p)
-{
-	struct rte_distributor *d = p->d;
-	const unsigned id = p->worker_id;
-	unsigned int num = 0;
-	unsigned int i;
-
-	/*
-	 * for single port, xor_val will be zero so we won't modify the output
-	 * port, otherwise we send traffic from 0 to 1, 2 to 3, and vice versa
-	 */
-	const unsigned xor_val = (rte_eth_dev_count() > 1);
-	struct rte_mbuf *buf[8] __rte_cache_aligned;
-
-	for (i = 0; i < 8; i++)
-		buf[i] = NULL;
-
-	app_stats.worker_pkts[p->worker_id] = 1;
-
-	printf("\nCore %u acting as worker core.\n", rte_lcore_id());
-	while (!quit_signal_work) {
-		num = rte_distributor_get_pkt(d, id, buf, buf, num);
-		/* Do a little bit of work for each packet */
-		for (i = 0; i < num; i++) {
-			uint64_t t = rte_rdtsc()+100;
-
-			while (rte_rdtsc() < t)
-				rte_pause();
-			buf[i]->port ^= xor_val;
-		}
-
-		app_stats.worker_pkts[p->worker_id] += num;
-		if (num > 0)
-			app_stats.worker_bursts[p->worker_id][num-1]++;
-	}
-	return 0;
-}
-
-/* display usage */
-static void
-print_usage(const char *prgname)
-{
-	printf("%s [EAL options] -- -p PORTMASK\n"
-			"  -p PORTMASK: hexadecimal bitmask of ports to configure\n",
-			prgname);
-}
-
-static int
-parse_portmask(const char *portmask)
-{
-	char *end = NULL;
-	unsigned long pm;
-
-	/* parse hexadecimal string */
-	pm = strtoul(portmask, &end, 16);
-	if ((portmask[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (pm == 0)
-		return -1;
-
-	return pm;
-}
-
-/* Parse the argument given in the command line of the application */
-static int
-parse_args(int argc, char **argv)
-{
-	int opt;
-	char **argvopt;
-	int option_index;
-	char *prgname = argv[0];
-	static struct option lgopts[] = {
-		{NULL, 0, 0, 0}
-	};
-
-	argvopt = argv;
-
-	while ((opt = getopt_long(argc, argvopt, "p:",
-			lgopts, &option_index)) != EOF) {
-
-		switch (opt) {
-		/* portmask */
-		case 'p':
-			enabled_port_mask = parse_portmask(optarg);
-			if (enabled_port_mask == 0) {
-				printf("invalid portmask\n");
-				print_usage(prgname);
-				return -1;
-			}
-			break;
-
-		default:
-			print_usage(prgname);
-			return -1;
-		}
-	}
-
-	if (optind <= 1) {
-		print_usage(prgname);
-		return -1;
-	}
-
-	argv[optind-1] = prgname;
-
-	optind = 1; /* reset getopt lib */
-	return 0;
-}
-
-/* Main function, does initialization and calls the per-lcore functions */
-int
-main(int argc, char *argv[])
-{
-	struct rte_mempool *mbuf_pool;
-	struct rte_distributor *d;
-	struct rte_ring *dist_tx_ring;
-	struct rte_ring *rx_dist_ring;
-	unsigned lcore_id, worker_id = 0;
-	unsigned nb_ports;
-	uint16_t portid;
-	uint16_t nb_ports_available;
-	uint64_t t, freq;
-
-	/* catch ctrl-c so we can print on exit */
-	signal(SIGINT, int_handler);
-
-	/* init EAL */
-	int ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Error with EAL initialization\n");
-	argc -= ret;
-	argv += ret;
-
-	/* parse application arguments (after the EAL ones) */
-	ret = parse_args(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid distributor parameters\n");
-
-	if (rte_lcore_count() < 5)
-		rte_exit(EXIT_FAILURE, "Error, This application needs at "
-				"least 5 logical cores to run:\n"
-				"1 lcore for stats (can be core 0)\n"
-				"1 lcore for packet RX\n"
-				"1 lcore for distribution\n"
-				"1 lcore for packet TX\n"
-				"and at least 1 lcore for worker threads\n");
-
-	nb_ports = rte_eth_dev_count();
-	if (nb_ports == 0)
-		rte_exit(EXIT_FAILURE, "Error: no ethernet ports detected\n");
-	if (nb_ports != 1 && (nb_ports & 1))
-		rte_exit(EXIT_FAILURE, "Error: number of ports must be even, except "
-				"when using a single port\n");
-
-	mbuf_pool = rte_pktmbuf_pool_create("MBUF_POOL",
-		NUM_MBUFS * nb_ports, MBUF_CACHE_SIZE, 0,
-		RTE_MBUF_DEFAULT_BUF_SIZE, rte_socket_id());
-	if (mbuf_pool == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot create mbuf pool\n");
-	nb_ports_available = nb_ports;
-
-	/* initialize all ports */
-	RTE_ETH_FOREACH_DEV(portid) {
-		/* skip ports that are not enabled */
-		if ((enabled_port_mask & (1 << portid)) == 0) {
-			printf("\nSkipping disabled port %d\n", portid);
-			nb_ports_available--;
-			continue;
-		}
-		/* init port */
-		printf("Initializing port %u... done\n", portid);
-
-		if (port_init(portid, mbuf_pool) != 0)
-			rte_exit(EXIT_FAILURE, "Cannot initialize port %u\n",
-					portid);
-	}
-
-	if (!nb_ports_available) {
-		rte_exit(EXIT_FAILURE,
-				"All available ports are disabled. Please set portmask.\n");
-	}
-
-	d = rte_distributor_create("PKT_DIST", rte_socket_id(),
-			rte_lcore_count() - 4,
-			RTE_DIST_ALG_BURST);
-	if (d == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot create distributor\n");
-
-	/*
-	 * scheduler ring is read by the transmitter core, and written to
-	 * by scheduler core
-	 */
-	dist_tx_ring = rte_ring_create("Output_ring", SCHED_TX_RING_SZ,
-			rte_socket_id(), RING_F_SC_DEQ | RING_F_SP_ENQ);
-	if (dist_tx_ring == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot create output ring\n");
-
-	rx_dist_ring = rte_ring_create("Input_ring", SCHED_RX_RING_SZ,
-			rte_socket_id(), RING_F_SC_DEQ | RING_F_SP_ENQ);
-	if (rx_dist_ring == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot create output ring\n");
-
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		if (worker_id == rte_lcore_count() - 3) {
-			printf("Starting distributor on lcore_id %d\n",
-					lcore_id);
-			/* distributor core */
-			struct lcore_params *p =
-					rte_malloc(NULL, sizeof(*p), 0);
-			if (!p)
-				rte_panic("malloc failure\n");
-			*p = (struct lcore_params){worker_id, d,
-				rx_dist_ring, dist_tx_ring, mbuf_pool};
-			rte_eal_remote_launch(
-				(lcore_function_t *)lcore_distributor,
-				p, lcore_id);
-		} else if (worker_id == rte_lcore_count() - 4) {
-			printf("Starting tx  on worker_id %d, lcore_id %d\n",
-					worker_id, lcore_id);
-			/* tx core */
-			rte_eal_remote_launch((lcore_function_t *)lcore_tx,
-					dist_tx_ring, lcore_id);
-		} else if (worker_id == rte_lcore_count() - 2) {
-			printf("Starting rx on worker_id %d, lcore_id %d\n",
-					worker_id, lcore_id);
-			/* rx core */
-			struct lcore_params *p =
-					rte_malloc(NULL, sizeof(*p), 0);
-			if (!p)
-				rte_panic("malloc failure\n");
-			*p = (struct lcore_params){worker_id, d, rx_dist_ring,
-					dist_tx_ring, mbuf_pool};
-			rte_eal_remote_launch((lcore_function_t *)lcore_rx,
-					p, lcore_id);
-		} else {
-			printf("Starting worker on worker_id %d, lcore_id %d\n",
-					worker_id, lcore_id);
-			struct lcore_params *p =
-					rte_malloc(NULL, sizeof(*p), 0);
-			if (!p)
-				rte_panic("malloc failure\n");
-			*p = (struct lcore_params){worker_id, d, rx_dist_ring,
-					dist_tx_ring, mbuf_pool};
-
-			rte_eal_remote_launch((lcore_function_t *)lcore_worker,
-					p, lcore_id);
-		}
-		worker_id++;
-	}
-
-	freq = rte_get_timer_hz();
-	t = rte_rdtsc() + freq;
-	while (!quit_signal_dist) {
-		if (t < rte_rdtsc()) {
-			print_stats();
-			t = rte_rdtsc() + freq;
-		}
-		usleep(1000);
-	}
-
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		if (rte_eal_wait_lcore(lcore_id) < 0)
-			return -1;
-	}
-
-	print_stats();
-	return 0;
-}
diff --git a/examples/distributor/meson.build b/examples/distributor/meson.build
deleted file mode 100644
index d036ea0..0000000
--- a/examples/distributor/meson.build
+++ /dev/null
@@ -1,13 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-deps += 'distributor'
-allow_experimental_apis = true
-sources = files(
-	'main.c'
-)
diff --git a/examples/ethtool/Makefile b/examples/ethtool/Makefile
deleted file mode 100644
index 2b40b4b..0000000
--- a/examples/ethtool/Makefile
+++ /dev/null
@@ -1,23 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2015 Intel Corporation
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overwritten by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-ifneq ($(CONFIG_RTE_EXEC_ENV),"linuxapp")
-$(info This application can only operate in a linuxapp environment, \
-please change the definition of the RTE_TARGET environment variable)
-else
-
-DIRS-y += lib ethtool-app
-endif
-
-DEPDIRS-ethtool-app := lib
-
-include $(RTE_SDK)/mk/rte.extsubdir.mk
diff --git a/examples/ethtool/ethtool-app/Makefile b/examples/ethtool/ethtool-app/Makefile
deleted file mode 100644
index 1d400f1..0000000
--- a/examples/ethtool/ethtool-app/Makefile
+++ /dev/null
@@ -1,32 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-# binary name
-APP = ethtool
-
-# all source are stored in SRCS-y
-SRCS-y := main.c ethapp.c
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -O3 -D_GNU_SOURCE -pthread -I$(SRCDIR)/../lib
-CFLAGS += $(WERROR_FLAGS)
-
-LDLIBS += -L$(subst ethtool-app,lib,$(RTE_OUTPUT))/lib
-LDLIBS += -lrte_ethtool
-
-ifeq ($(CONFIG_RTE_BUILD_SHARED_LIB),y)
-ifeq ($(CONFIG_RTE_LIBRTE_IXGBE_PMD),y)
-LDLIBS += -lrte_pmd_ixgbe
-endif
-endif
-
-include $(RTE_SDK)/mk/rte.extapp.mk
diff --git a/examples/ethtool/ethtool-app/ethapp.c b/examples/ethtool/ethtool-app/ethapp.c
deleted file mode 100644
index 4d62f4c..0000000
--- a/examples/ethtool/ethtool-app/ethapp.c
+++ /dev/null
@@ -1,846 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2015 Intel Corporation
- */
-
-#include <cmdline_parse.h>
-#include <cmdline_parse_num.h>
-#include <cmdline_parse_string.h>
-#include <cmdline_parse_etheraddr.h>
-#include <cmdline_socket.h>
-#include <cmdline.h>
-
-#include "rte_ethtool.h"
-#include "ethapp.h"
-
-#define EEPROM_DUMP_CHUNKSIZE 1024
-
-
-struct pcmd_get_params {
-	cmdline_fixed_string_t cmd;
-};
-struct pcmd_int_params {
-	cmdline_fixed_string_t cmd;
-	uint16_t port;
-};
-struct pcmd_intstr_params {
-	cmdline_fixed_string_t cmd;
-	uint16_t port;
-	cmdline_fixed_string_t opt;
-};
-struct pcmd_intmac_params {
-	cmdline_fixed_string_t cmd;
-	uint16_t port;
-	struct ether_addr mac;
-};
-struct pcmd_str_params {
-	cmdline_fixed_string_t cmd;
-	cmdline_fixed_string_t opt;
-};
-struct pcmd_vlan_params {
-	cmdline_fixed_string_t cmd;
-	uint16_t port;
-	cmdline_fixed_string_t mode;
-	uint16_t vid;
-};
-struct pcmd_intintint_params {
-	cmdline_fixed_string_t cmd;
-	uint16_t port;
-	uint16_t tx;
-	uint16_t rx;
-};
-
-
-/* Parameter-less commands */
-cmdline_parse_token_string_t pcmd_quit_token_cmd =
-	TOKEN_STRING_INITIALIZER(struct pcmd_get_params, cmd, "quit");
-cmdline_parse_token_string_t pcmd_stats_token_cmd =
-	TOKEN_STRING_INITIALIZER(struct pcmd_get_params, cmd, "stats");
-cmdline_parse_token_string_t pcmd_drvinfo_token_cmd =
-	TOKEN_STRING_INITIALIZER(struct pcmd_get_params, cmd, "drvinfo");
-cmdline_parse_token_string_t pcmd_link_token_cmd =
-	TOKEN_STRING_INITIALIZER(struct pcmd_get_params, cmd, "link");
-
-/* Commands taking just port id */
-cmdline_parse_token_string_t pcmd_open_token_cmd =
-	TOKEN_STRING_INITIALIZER(struct pcmd_int_params, cmd, "open");
-cmdline_parse_token_string_t pcmd_stop_token_cmd =
-	TOKEN_STRING_INITIALIZER(struct pcmd_int_params, cmd, "stop");
-cmdline_parse_token_string_t pcmd_rxmode_token_cmd =
-	TOKEN_STRING_INITIALIZER(struct pcmd_int_params, cmd, "rxmode");
-cmdline_parse_token_string_t pcmd_portstats_token_cmd =
-	TOKEN_STRING_INITIALIZER(struct pcmd_int_params, cmd, "portstats");
-cmdline_parse_token_num_t pcmd_int_token_port =
-	TOKEN_NUM_INITIALIZER(struct pcmd_int_params, port, UINT16);
-
-/* Commands taking port id and string */
-cmdline_parse_token_string_t pcmd_eeprom_token_cmd =
-	TOKEN_STRING_INITIALIZER(struct pcmd_intstr_params, cmd, "eeprom");
-cmdline_parse_token_string_t pcmd_mtu_token_cmd =
-	TOKEN_STRING_INITIALIZER(struct pcmd_intstr_params, cmd, "mtu");
-cmdline_parse_token_string_t pcmd_regs_token_cmd =
-	TOKEN_STRING_INITIALIZER(struct pcmd_intstr_params, cmd, "regs");
-
-cmdline_parse_token_num_t pcmd_intstr_token_port =
-	TOKEN_NUM_INITIALIZER(struct pcmd_intstr_params, port, UINT16);
-cmdline_parse_token_string_t pcmd_intstr_token_opt =
-	TOKEN_STRING_INITIALIZER(struct pcmd_intstr_params, opt, NULL);
-
-/* Commands taking port id and a MAC address string */
-cmdline_parse_token_string_t pcmd_macaddr_token_cmd =
-	TOKEN_STRING_INITIALIZER(struct pcmd_intmac_params, cmd, "macaddr");
-cmdline_parse_token_num_t pcmd_intmac_token_port =
-	TOKEN_NUM_INITIALIZER(struct pcmd_intmac_params, port, UINT16);
-cmdline_parse_token_etheraddr_t pcmd_intmac_token_mac =
-	TOKEN_ETHERADDR_INITIALIZER(struct pcmd_intmac_params, mac);
-
-/* Command taking just a MAC address */
-cmdline_parse_token_string_t pcmd_validate_token_cmd =
-	TOKEN_STRING_INITIALIZER(struct pcmd_intmac_params, cmd, "validate");
-
-
-/* Commands taking port id and two integers */
-cmdline_parse_token_string_t pcmd_ringparam_token_cmd =
-	TOKEN_STRING_INITIALIZER(struct pcmd_intintint_params, cmd,
-		"ringparam");
-cmdline_parse_token_num_t pcmd_intintint_token_port =
-	TOKEN_NUM_INITIALIZER(struct pcmd_intintint_params, port, UINT16);
-cmdline_parse_token_num_t pcmd_intintint_token_tx =
-	TOKEN_NUM_INITIALIZER(struct pcmd_intintint_params, tx, UINT16);
-cmdline_parse_token_num_t pcmd_intintint_token_rx =
-	TOKEN_NUM_INITIALIZER(struct pcmd_intintint_params, rx, UINT16);
-
-
-/* Pause commands */
-cmdline_parse_token_string_t pcmd_pause_token_cmd =
-	TOKEN_STRING_INITIALIZER(struct pcmd_intstr_params, cmd, "pause");
-cmdline_parse_token_num_t pcmd_pause_token_port =
-	TOKEN_NUM_INITIALIZER(struct pcmd_intstr_params, port, UINT16);
-cmdline_parse_token_string_t pcmd_pause_token_opt =
-	TOKEN_STRING_INITIALIZER(struct pcmd_intstr_params,
-		opt, "all#tx#rx#none");
-
-/* VLAN commands */
-cmdline_parse_token_string_t pcmd_vlan_token_cmd =
-	TOKEN_STRING_INITIALIZER(struct pcmd_vlan_params, cmd, "vlan");
-cmdline_parse_token_num_t pcmd_vlan_token_port =
-	TOKEN_NUM_INITIALIZER(struct pcmd_vlan_params, port, UINT16);
-cmdline_parse_token_string_t pcmd_vlan_token_mode =
-	TOKEN_STRING_INITIALIZER(struct pcmd_vlan_params, mode, "add#del");
-cmdline_parse_token_num_t pcmd_vlan_token_vid =
-	TOKEN_NUM_INITIALIZER(struct pcmd_vlan_params, vid, UINT16);
-
-
-static void
-pcmd_quit_callback(__rte_unused void *ptr_params,
-	struct cmdline *ctx,
-	__rte_unused void *ptr_data)
-{
-	cmdline_quit(ctx);
-}
-
-
-static void
-pcmd_drvinfo_callback(__rte_unused void *ptr_params,
-	__rte_unused struct cmdline *ctx,
-	__rte_unused void *ptr_data)
-{
-	struct ethtool_drvinfo info;
-	uint16_t id_port;
-
-	RTE_ETH_FOREACH_DEV(id_port) {
-		memset(&info, 0, sizeof(info));
-		if (rte_ethtool_get_drvinfo(id_port, &info)) {
-			printf("Error getting info for port %i\n", id_port);
-			return;
-		}
-		printf("Port %i driver: %s (ver: %s)\n",
-			id_port, info.driver, info.version
-		      );
-		printf("firmware-version: %s\n", info.fw_version);
-		printf("bus-info: %s\n", info.bus_info);
-	}
-}
-
-
-static void
-pcmd_link_callback(__rte_unused void *ptr_params,
-	__rte_unused struct cmdline *ctx,
-	__rte_unused void *ptr_data)
-{
-	uint16_t id_port;
-	int stat_port;
-
-	RTE_ETH_FOREACH_DEV(id_port) {
-		if (!rte_eth_dev_is_valid_port(id_port))
-			continue;
-		stat_port = rte_ethtool_get_link(id_port);
-		switch (stat_port) {
-		case 0:
-			printf("Port %i: Down\n", id_port);
-			break;
-		case 1:
-			printf("Port %i: Up\n", id_port);
-			break;
-		default:
-			printf("Port %i: Error getting link status\n",
-				id_port
-				);
-			break;
-		}
-	}
-	printf("\n");
-}
-
-
-static void
-pcmd_regs_callback(void *ptr_params,
-	__rte_unused struct cmdline *ctx,
-	__rte_unused void *ptr_data)
-{
-	struct pcmd_intstr_params *params = ptr_params;
-	int len_regs;
-	struct ethtool_regs regs;
-	unsigned char *buf_data;
-	FILE *fp_regs;
-
-	if (!rte_eth_dev_is_valid_port(params->port)) {
-		printf("Error: Invalid port number %i\n", params->port);
-		return;
-	}
-	len_regs = rte_ethtool_get_regs_len(params->port);
-	if (len_regs > 0) {
-		printf("Port %i: %i bytes\n", params->port, len_regs);
-		buf_data = malloc(len_regs);
-		if (buf_data == NULL) {
-			printf("Error allocating %i bytes for buffer\n",
-				len_regs);
-			return;
-		}
-		if (!rte_ethtool_get_regs(params->port, &regs, buf_data)) {
-			fp_regs = fopen(params->opt, "wb");
-			if (fp_regs == NULL) {
-				printf("Error opening '%s' for writing\n",
-					params->opt);
-			} else {
-				if ((int)fwrite(buf_data,
-						1, len_regs,
-						fp_regs) != len_regs)
-					printf("Error writing '%s'\n",
-						params->opt);
-				fclose(fp_regs);
-			}
-		}
-		free(buf_data);
-	} else if (len_regs == -ENOTSUP)
-		printf("Port %i: Operation not supported\n", params->port);
-	else
-		printf("Port %i: Error getting registers\n", params->port);
-}
-
-
-static void
-pcmd_eeprom_callback(void *ptr_params,
-	__rte_unused struct cmdline *ctx,
-	__rte_unused void *ptr_data)
-{
-	struct pcmd_intstr_params *params = ptr_params;
-	struct ethtool_eeprom info_eeprom;
-	int len_eeprom;
-	int pos_eeprom;
-	int stat;
-	unsigned char bytes_eeprom[EEPROM_DUMP_CHUNKSIZE];
-	FILE *fp_eeprom;
-
-	if (!rte_eth_dev_is_valid_port(params->port)) {
-		printf("Error: Invalid port number %i\n", params->port);
-		return;
-	}
-	len_eeprom = rte_ethtool_get_eeprom_len(params->port);
-	if (len_eeprom > 0) {
-		fp_eeprom = fopen(params->opt, "wb");
-		if (fp_eeprom == NULL) {
-			printf("Error opening '%s' for writing\n",
-				params->opt);
-			return;
-		}
-		printf("Total EEPROM length: %i bytes\n", len_eeprom);
-		info_eeprom.len = EEPROM_DUMP_CHUNKSIZE;
-		for (pos_eeprom = 0;
-				pos_eeprom < len_eeprom;
-				pos_eeprom += EEPROM_DUMP_CHUNKSIZE) {
-			info_eeprom.offset = pos_eeprom;
-			if (pos_eeprom + EEPROM_DUMP_CHUNKSIZE > len_eeprom)
-				info_eeprom.len = len_eeprom - pos_eeprom;
-			else
-				info_eeprom.len = EEPROM_DUMP_CHUNKSIZE;
-			stat = rte_ethtool_get_eeprom(
-				params->port, &info_eeprom, bytes_eeprom
-				);
-			if (stat != 0) {
-				printf("EEPROM read error %i\n", stat);
-				break;
-			}
-			if (fwrite(bytes_eeprom,
-					1, info_eeprom.len,
-					fp_eeprom) != info_eeprom.len) {
-				printf("Error writing '%s'\n", params->opt);
-				break;
-			}
-		}
-		fclose(fp_eeprom);
-	} else if (len_eeprom == 0)
-		printf("Port %i: Device does not have EEPROM\n", params->port);
-	else if (len_eeprom == -ENOTSUP)
-		printf("Port %i: Operation not supported\n", params->port);
-	else
-		printf("Port %i: Error getting EEPROM\n", params->port);
-}
-
-
-static void
-pcmd_pause_callback(void *ptr_params,
-	__rte_unused struct cmdline *ctx,
-	void *ptr_data)
-{
-	struct pcmd_intstr_params *params = ptr_params;
-	struct ethtool_pauseparam info;
-	int stat;
-
-	if (!rte_eth_dev_is_valid_port(params->port)) {
-		printf("Error: Invalid port number %i\n", params->port);
-		return;
-	}
-	if (ptr_data != NULL) {
-		stat = rte_ethtool_get_pauseparam(params->port, &info);
-	} else {
-		memset(&info, 0, sizeof(info));
-		if (strcasecmp("all", params->opt) == 0) {
-			info.tx_pause = 1;
-			info.rx_pause = 1;
-		} else if (strcasecmp("tx", params->opt) == 0) {
-			info.tx_pause = 1;
-			info.rx_pause = 0;
-		} else if (strcasecmp("rx", params->opt) == 0) {
-			info.tx_pause = 0;
-			info.rx_pause = 1;
-		} else {
-			info.tx_pause = 0;
-			info.rx_pause = 0;
-		}
-		/* Assume auto-negotiation wanted */
-		info.autoneg = 1;
-		stat = rte_ethtool_set_pauseparam(params->port, &info);
-	}
-	if (stat == 0) {
-		if (info.rx_pause && info.tx_pause)
-			printf("Port %i: Tx & Rx Paused\n", params->port);
-		else if (info.rx_pause)
-			printf("Port %i: Rx Paused\n", params->port);
-		else if (info.tx_pause)
-			printf("Port %i: Tx Paused\n", params->port);
-		else
-			printf("Port %i: Tx & Rx not paused\n", params->port);
-	} else if (stat == -ENOTSUP)
-		printf("Port %i: Operation not supported\n", params->port);
-	else
-		printf("Port %i: Error %i\n", params->port, stat);
-}
-
-
-static void
-pcmd_open_callback(__rte_unused void *ptr_params,
-	__rte_unused struct cmdline *ctx,
-	__rte_unused void *ptr_data)
-{
-	struct pcmd_int_params *params = ptr_params;
-	int stat;
-
-	if (!rte_eth_dev_is_valid_port(params->port)) {
-		printf("Error: Invalid port number %i\n", params->port);
-		return;
-	}
-	lock_port(params->port);
-	stat = rte_ethtool_net_open(params->port);
-	mark_port_active(params->port);
-	unlock_port(params->port);
-	if (stat == 0)
-		return;
-	else if (stat == -ENOTSUP)
-		printf("Port %i: Operation not supported\n", params->port);
-	else
-		printf("Port %i: Error opening device\n", params->port);
-}
-
-static void
-pcmd_stop_callback(__rte_unused void *ptr_params,
-	__rte_unused struct cmdline *ctx,
-	__rte_unused void *ptr_data)
-{
-	struct pcmd_int_params *params = ptr_params;
-	int stat;
-
-	if (!rte_eth_dev_is_valid_port(params->port)) {
-		printf("Error: Invalid port number %i\n", params->port);
-		return;
-	}
-	lock_port(params->port);
-	stat = rte_ethtool_net_stop(params->port);
-	mark_port_inactive(params->port);
-	unlock_port(params->port);
-	if (stat == 0)
-		return;
-	else if (stat == -ENOTSUP)
-		printf("Port %i: Operation not supported\n", params->port);
-	else
-		printf("Port %i: Error stopping device\n", params->port);
-}
-
-
-static void
-pcmd_rxmode_callback(void *ptr_params,
-	__rte_unused struct cmdline *ctx,
-	__rte_unused void *ptr_data)
-{
-	struct pcmd_intstr_params *params = ptr_params;
-	int stat;
-
-	if (!rte_eth_dev_is_valid_port(params->port)) {
-		printf("Error: Invalid port number %i\n", params->port);
-		return;
-	}
-	stat = rte_ethtool_net_set_rx_mode(params->port);
-	if (stat == 0)
-		return;
-	else if (stat == -ENOTSUP)
-		printf("Port %i: Operation not supported\n", params->port);
-	else
-		printf("Port %i: Error setting rx mode\n", params->port);
-}
-
-
-static void
-pcmd_macaddr_callback(void *ptr_params,
-	__rte_unused struct cmdline *ctx,
-	void *ptr_data)
-{
-	struct pcmd_intmac_params *params = ptr_params;
-	struct ether_addr mac_addr;
-	int stat;
-
-	stat = 0;
-	if (!rte_eth_dev_is_valid_port(params->port)) {
-		printf("Error: Invalid port number %i\n", params->port);
-		return;
-	}
-	if (ptr_data != NULL) {
-		lock_port(params->port);
-		stat = rte_ethtool_net_set_mac_addr(params->port,
-			&params->mac);
-		mark_port_newmac(params->port);
-		unlock_port(params->port);
-		if (stat == 0) {
-			printf("MAC address changed\n");
-			return;
-		}
-	} else {
-		stat = rte_ethtool_net_get_mac_addr(params->port, &mac_addr);
-		if (stat == 0) {
-			printf(
-				"Port %i MAC Address: %02x:%02x:%02x:%02x:%02x:%02x\n",
-				params->port,
-				mac_addr.addr_bytes[0],
-				mac_addr.addr_bytes[1],
-				mac_addr.addr_bytes[2],
-				mac_addr.addr_bytes[3],
-				mac_addr.addr_bytes[4],
-				mac_addr.addr_bytes[5]);
-			return;
-		}
-	}
-
-	printf("Port %i: Error %s\n", params->port,
-	       strerror(-stat));
-}
-
-static void
-pcmd_mtu_callback(void *ptr_params,
-	__rte_unused struct cmdline *ctx,
-	__rte_unused void *ptr_data)
-{
-	struct pcmd_intstr_params *params = ptr_params;
-	int stat;
-	int new_mtu;
-	char *ptr_parse_end;
-
-	if (!rte_eth_dev_is_valid_port(params->port)) {
-		printf("Error: Invalid port number %i\n", params->port);
-		return;
-	}
-	new_mtu = atoi(params->opt);
-	new_mtu = strtoul(params->opt, &ptr_parse_end, 10);
-	if (*ptr_parse_end != '\0' ||
-			new_mtu < ETHER_MIN_MTU ||
-			new_mtu > ETHER_MAX_JUMBO_FRAME_LEN) {
-		printf("Port %i: Invalid MTU value\n", params->port);
-		return;
-	}
-	stat = rte_ethtool_net_change_mtu(params->port, new_mtu);
-	if (stat == 0)
-		printf("Port %i: MTU set to %i\n", params->port, new_mtu);
-	else if (stat == -ENOTSUP)
-		printf("Port %i: Operation not supported\n", params->port);
-	else
-		printf("Port %i: Error setting MTU\n", params->port);
-}
-
-
-
-static void pcmd_portstats_callback(__rte_unused void *ptr_params,
-	__rte_unused struct cmdline *ctx,
-	__rte_unused void *ptr_data)
-{
-	struct pcmd_int_params *params = ptr_params;
-	struct rte_eth_stats stat_info;
-	int stat;
-
-	if (!rte_eth_dev_is_valid_port(params->port)) {
-		printf("Error: Invalid port number %i\n", params->port);
-		return;
-	}
-	stat = rte_ethtool_net_get_stats64(params->port, &stat_info);
-	if (stat == 0) {
-		printf("Port %i stats\n", params->port);
-		printf("   In: %" PRIu64 " (%" PRIu64 " bytes)\n"
-			"  Out: %"PRIu64" (%"PRIu64 " bytes)\n"
-			"  Err: %"PRIu64"\n",
-			stat_info.ipackets,
-			stat_info.ibytes,
-			stat_info.opackets,
-			stat_info.obytes,
-			stat_info.ierrors+stat_info.oerrors
-		      );
-	} else if (stat == -ENOTSUP)
-		printf("Port %i: Operation not supported\n", params->port);
-	else
-		printf("Port %i: Error fetching statistics\n", params->port);
-}
-
-static void pcmd_ringparam_callback(__rte_unused void *ptr_params,
-	__rte_unused struct cmdline *ctx,
-	void *ptr_data)
-{
-	struct pcmd_intintint_params *params = ptr_params;
-	struct ethtool_ringparam ring_data;
-	struct ethtool_ringparam ring_params;
-	int stat;
-
-	if (!rte_eth_dev_is_valid_port(params->port)) {
-		printf("Error: Invalid port number %i\n", params->port);
-		return;
-	}
-	if (ptr_data == NULL) {
-		stat = rte_ethtool_get_ringparam(params->port, &ring_data);
-		if (stat == 0) {
-			printf("Port %i ring parameters\n"
-				"  Rx Pending: %i (%i max)\n"
-				"  Tx Pending: %i (%i max)\n",
-				params->port,
-				ring_data.rx_pending,
-				ring_data.rx_max_pending,
-				ring_data.tx_pending,
-				ring_data.tx_max_pending);
-		}
-	} else {
-		if (params->tx < 1 || params->rx < 1) {
-			printf("Error: Invalid parameters\n");
-			return;
-		}
-		memset(&ring_params, 0, sizeof(struct ethtool_ringparam));
-		ring_params.tx_pending = params->tx;
-		ring_params.rx_pending = params->rx;
-		lock_port(params->port);
-		stat = rte_ethtool_set_ringparam(params->port, &ring_params);
-		unlock_port(params->port);
-	}
-	if (stat == 0)
-		return;
-	else if (stat == -ENOTSUP)
-		printf("Port %i: Operation not supported\n", params->port);
-	else
-		printf("Port %i: Error fetching statistics\n", params->port);
-}
-
-static void pcmd_validate_callback(void *ptr_params,
-	__rte_unused struct cmdline *ctx,
-	__rte_unused void *ptr_data)
-{
-	struct pcmd_intmac_params *params = ptr_params;
-
-	if (rte_ethtool_net_validate_addr(0, &params->mac))
-		printf("Address is unicast\n");
-	else
-		printf("Address is not unicast\n");
-}
-
-
-static void pcmd_vlan_callback(__rte_unused void *ptr_params,
-	__rte_unused struct cmdline *ctx,
-	__rte_unused void *ptr_data)
-{
-	struct pcmd_vlan_params *params = ptr_params;
-	int stat;
-
-	if (!rte_eth_dev_is_valid_port(params->port)) {
-		printf("Error: Invalid port number %i\n", params->port);
-		return;
-	}
-	stat = 0;
-
-	if (strcasecmp("add", params->mode) == 0) {
-		stat = rte_ethtool_net_vlan_rx_add_vid(
-			params->port, params->vid
-			);
-		if (stat == 0)
-			printf("VLAN vid %i added\n", params->vid);
-
-	} else if (strcasecmp("del", params->mode) == 0) {
-		stat = rte_ethtool_net_vlan_rx_kill_vid(
-			params->port, params->vid
-			);
-		if (stat == 0)
-			printf("VLAN vid %i removed\n", params->vid);
-	} else {
-		/* Should not happen! */
-		printf("Error: Bad mode %s\n", params->mode);
-	}
-	if (stat == -ENOTSUP)
-		printf("Port %i: Operation not supported\n", params->port);
-	else if (stat == -ENOSYS)
-		printf("Port %i: VLAN filtering disabled\n", params->port);
-	else if (stat != 0)
-		printf("Port %i: Error changing VLAN setup (code %i)\n",
-			params->port, -stat);
-}
-
-
-cmdline_parse_inst_t pcmd_quit = {
-	.f = pcmd_quit_callback,
-	.data = NULL,
-	.help_str = "quit\n     Exit program",
-	.tokens = {(void *)&pcmd_quit_token_cmd, NULL},
-};
-cmdline_parse_inst_t pcmd_drvinfo = {
-	.f = pcmd_drvinfo_callback,
-	.data = NULL,
-	.help_str = "drvinfo\n     Print driver info",
-	.tokens = {(void *)&pcmd_drvinfo_token_cmd, NULL},
-};
-cmdline_parse_inst_t pcmd_link = {
-	.f = pcmd_link_callback,
-	.data = NULL,
-	.help_str = "link\n     Print port link states",
-	.tokens = {(void *)&pcmd_link_token_cmd, NULL},
-};
-cmdline_parse_inst_t pcmd_regs = {
-	.f = pcmd_regs_callback,
-	.data = NULL,
-	.help_str = "regs <port_id> <filename>\n"
-		"     Dump port register(s) to file",
-	.tokens = {
-		(void *)&pcmd_regs_token_cmd,
-		(void *)&pcmd_intstr_token_port,
-		(void *)&pcmd_intstr_token_opt,
-		NULL
-	},
-};
-cmdline_parse_inst_t pcmd_eeprom = {
-	.f = pcmd_eeprom_callback,
-	.data = NULL,
-	.help_str = "eeprom <port_id> <filename>\n    Dump EEPROM to file",
-	.tokens = {
-		(void *)&pcmd_eeprom_token_cmd,
-		(void *)&pcmd_intstr_token_port,
-		(void *)&pcmd_intstr_token_opt,
-		NULL
-	},
-};
-cmdline_parse_inst_t pcmd_pause_noopt = {
-	.f = pcmd_pause_callback,
-	.data = (void *)0x01,
-	.help_str = "pause <port_id>\n     Print port pause state",
-	.tokens = {
-		(void *)&pcmd_pause_token_cmd,
-		(void *)&pcmd_pause_token_port,
-		NULL
-	},
-};
-cmdline_parse_inst_t pcmd_pause = {
-	.f = pcmd_pause_callback,
-	.data = NULL,
-	.help_str =
-		"pause <port_id> <all|tx|rx|none>\n     Pause/unpause port",
-	.tokens = {
-		(void *)&pcmd_pause_token_cmd,
-		(void *)&pcmd_pause_token_port,
-		(void *)&pcmd_pause_token_opt,
-		NULL
-	},
-};
-cmdline_parse_inst_t pcmd_open = {
-	.f = pcmd_open_callback,
-	.data = NULL,
-	.help_str = "open <port_id>\n     Open port",
-	.tokens = {
-		(void *)&pcmd_open_token_cmd,
-		(void *)&pcmd_int_token_port,
-		NULL
-	},
-};
-cmdline_parse_inst_t pcmd_stop = {
-	.f = pcmd_stop_callback,
-	.data = NULL,
-	.help_str = "stop <port_id>\n     Stop port",
-	.tokens = {
-		(void *)&pcmd_stop_token_cmd,
-		(void *)&pcmd_int_token_port,
-		NULL
-	},
-};
-cmdline_parse_inst_t pcmd_rxmode = {
-	.f = pcmd_rxmode_callback,
-	.data = NULL,
-	.help_str = "rxmode <port_id>\n     Toggle port Rx mode",
-	.tokens = {
-		(void *)&pcmd_rxmode_token_cmd,
-		(void *)&pcmd_int_token_port,
-		NULL
-	},
-};
-cmdline_parse_inst_t pcmd_macaddr_get = {
-	.f = pcmd_macaddr_callback,
-	.data = NULL,
-	.help_str = "macaddr <port_id>\n"
-		"     Get MAC address",
-	.tokens = {
-		(void *)&pcmd_macaddr_token_cmd,
-		(void *)&pcmd_intstr_token_port,
-		NULL
-	},
-};
-cmdline_parse_inst_t pcmd_macaddr = {
-	.f = pcmd_macaddr_callback,
-	.data = (void *)0x01,
-	.help_str =
-		"macaddr <port_id> <mac_addr>\n"
-		"     Set MAC address",
-	.tokens = {
-		(void *)&pcmd_macaddr_token_cmd,
-		(void *)&pcmd_intmac_token_port,
-		(void *)&pcmd_intmac_token_mac,
-		NULL
-	},
-};
-cmdline_parse_inst_t pcmd_mtu = {
-	.f = pcmd_mtu_callback,
-	.data = NULL,
-	.help_str = "mtu <port_id> <mtu_value>\n"
-		"     Change MTU",
-	.tokens = {
-		(void *)&pcmd_mtu_token_cmd,
-		(void *)&pcmd_intstr_token_port,
-		(void *)&pcmd_intstr_token_opt,
-		NULL
-	},
-};
-cmdline_parse_inst_t pcmd_portstats = {
-	.f = pcmd_portstats_callback,
-	.data = NULL,
-	.help_str = "portstats <port_id>\n"
-		"     Print port eth statistics",
-	.tokens = {
-		(void *)&pcmd_portstats_token_cmd,
-		(void *)&pcmd_int_token_port,
-		NULL
-	},
-};
-cmdline_parse_inst_t pcmd_ringparam = {
-	.f = pcmd_ringparam_callback,
-	.data = NULL,
-	.help_str = "ringparam <port_id>\n"
-		"     Print ring parameters",
-	.tokens = {
-		(void *)&pcmd_ringparam_token_cmd,
-		(void *)&pcmd_intintint_token_port,
-		NULL
-	},
-};
-cmdline_parse_inst_t pcmd_ringparam_set = {
-	.f = pcmd_ringparam_callback,
-	.data = (void *)1,
-	.help_str = "ringparam <port_id> <tx_param> <rx_param>\n"
-		"     Set ring parameters",
-	.tokens = {
-		(void *)&pcmd_ringparam_token_cmd,
-		(void *)&pcmd_intintint_token_port,
-		(void *)&pcmd_intintint_token_tx,
-		(void *)&pcmd_intintint_token_rx,
-		NULL
-	},
-};
-cmdline_parse_inst_t pcmd_validate = {
-	.f = pcmd_validate_callback,
-	.data = NULL,
-	.help_str = "validate <mac_addr>\n"
-		"     Check that MAC address is valid unicast address",
-	.tokens = {
-		(void *)&pcmd_validate_token_cmd,
-		(void *)&pcmd_intmac_token_mac,
-		NULL
-	},
-};
-cmdline_parse_inst_t pcmd_vlan = {
-	.f = pcmd_vlan_callback,
-	.data = NULL,
-	.help_str = "vlan <port_id> <add|del> <vlan_id>\n"
-		"     Add/remove VLAN id",
-	.tokens = {
-		(void *)&pcmd_vlan_token_cmd,
-		(void *)&pcmd_vlan_token_port,
-		(void *)&pcmd_vlan_token_mode,
-		(void *)&pcmd_vlan_token_vid,
-		NULL
-	},
-};
-
-
-cmdline_parse_ctx_t list_prompt_commands[] = {
-	(cmdline_parse_inst_t *)&pcmd_drvinfo,
-	(cmdline_parse_inst_t *)&pcmd_eeprom,
-	(cmdline_parse_inst_t *)&pcmd_link,
-	(cmdline_parse_inst_t *)&pcmd_macaddr_get,
-	(cmdline_parse_inst_t *)&pcmd_macaddr,
-	(cmdline_parse_inst_t *)&pcmd_mtu,
-	(cmdline_parse_inst_t *)&pcmd_open,
-	(cmdline_parse_inst_t *)&pcmd_pause_noopt,
-	(cmdline_parse_inst_t *)&pcmd_pause,
-	(cmdline_parse_inst_t *)&pcmd_portstats,
-	(cmdline_parse_inst_t *)&pcmd_regs,
-	(cmdline_parse_inst_t *)&pcmd_ringparam,
-	(cmdline_parse_inst_t *)&pcmd_ringparam_set,
-	(cmdline_parse_inst_t *)&pcmd_rxmode,
-	(cmdline_parse_inst_t *)&pcmd_stop,
-	(cmdline_parse_inst_t *)&pcmd_validate,
-	(cmdline_parse_inst_t *)&pcmd_vlan,
-	(cmdline_parse_inst_t *)&pcmd_quit,
-	NULL
-};
-
-
-void ethapp_main(void)
-{
-	struct cmdline *ctx_cmdline;
-
-	ctx_cmdline = cmdline_stdin_new(list_prompt_commands, "EthApp> ");
-	cmdline_interact(ctx_cmdline);
-	cmdline_stdin_exit(ctx_cmdline);
-}
diff --git a/examples/ethtool/ethtool-app/ethapp.h b/examples/ethtool/ethtool-app/ethapp.h
deleted file mode 100644
index 7a70480..0000000
--- a/examples/ethtool/ethtool-app/ethapp.h
+++ /dev/null
@@ -1,12 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2015 Intel Corporation
- */
-
-
-void ethapp_main(void);
-void print_stats(void);
-void lock_port(int idx_port);
-void unlock_port(int idx_port);
-void mark_port_inactive(int idx_port);
-void mark_port_active(int idx_port);
-void mark_port_newmac(int idx_port);
diff --git a/examples/ethtool/ethtool-app/main.c b/examples/ethtool/ethtool-app/main.c
deleted file mode 100644
index 702feab..0000000
--- a/examples/ethtool/ethtool-app/main.c
+++ /dev/null
@@ -1,286 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2015 Intel Corporation
- */
-
-
-#include <stdio.h>
-#include <stdlib.h>
-
-#include <rte_common.h>
-#include <rte_spinlock.h>
-#include <rte_eal.h>
-#include <rte_ethdev.h>
-#include <rte_ether.h>
-#include <rte_ip.h>
-#include <rte_memory.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-
-#include "ethapp.h"
-
-#define MAX_PORTS RTE_MAX_ETHPORTS
-#define MAX_BURST_LENGTH 32
-#define PORT_RX_QUEUE_SIZE 1024
-#define PORT_TX_QUEUE_SIZE 1024
-#define PKTPOOL_EXTRA_SIZE 512
-#define PKTPOOL_CACHE 32
-
-
-struct txq_port {
-	uint16_t cnt_unsent;
-	struct rte_mbuf *buf_frames[MAX_BURST_LENGTH];
-};
-
-struct app_port {
-	struct ether_addr mac_addr;
-	struct txq_port txq;
-	rte_spinlock_t lock;
-	int port_active;
-	int port_dirty;
-	int idx_port;
-	struct rte_mempool *pkt_pool;
-};
-
-struct app_config {
-	struct app_port ports[MAX_PORTS];
-	int cnt_ports;
-	int exit_now;
-};
-
-
-struct app_config app_cfg;
-
-
-void lock_port(int idx_port)
-{
-	struct app_port *ptr_port = &app_cfg.ports[idx_port];
-
-	rte_spinlock_lock(&ptr_port->lock);
-}
-
-void unlock_port(int idx_port)
-{
-	struct app_port *ptr_port = &app_cfg.ports[idx_port];
-
-	rte_spinlock_unlock(&ptr_port->lock);
-}
-
-void mark_port_active(int idx_port)
-{
-	struct app_port *ptr_port = &app_cfg.ports[idx_port];
-
-	ptr_port->port_active = 1;
-}
-
-void mark_port_inactive(int idx_port)
-{
-	struct app_port *ptr_port = &app_cfg.ports[idx_port];
-
-	ptr_port->port_active = 0;
-}
-
-void mark_port_newmac(int idx_port)
-{
-	struct app_port *ptr_port = &app_cfg.ports[idx_port];
-
-	ptr_port->port_dirty = 1;
-}
-
-static void setup_ports(struct app_config *app_cfg, int cnt_ports)
-{
-	int idx_port;
-	int size_pktpool;
-	struct rte_eth_conf cfg_port;
-	struct rte_eth_dev_info dev_info;
-	char str_name[16];
-	uint16_t nb_rxd = PORT_RX_QUEUE_SIZE;
-	uint16_t nb_txd = PORT_TX_QUEUE_SIZE;
-	struct rte_eth_txconf txconf;
-
-	memset(&cfg_port, 0, sizeof(cfg_port));
-	cfg_port.txmode.mq_mode = ETH_MQ_TX_NONE;
-	cfg_port.rxmode.ignore_offload_bitfield = 1;
-
-	for (idx_port = 0; idx_port < cnt_ports; idx_port++) {
-		struct app_port *ptr_port = &app_cfg->ports[idx_port];
-
-		rte_eth_dev_info_get(idx_port, &dev_info);
-		size_pktpool = dev_info.rx_desc_lim.nb_max +
-			dev_info.tx_desc_lim.nb_max + PKTPOOL_EXTRA_SIZE;
-
-		snprintf(str_name, 16, "pkt_pool%i", idx_port);
-		ptr_port->pkt_pool = rte_pktmbuf_pool_create(
-			str_name,
-			size_pktpool, PKTPOOL_CACHE,
-			0,
-			RTE_MBUF_DEFAULT_BUF_SIZE,
-			rte_socket_id()
-			);
-		if (ptr_port->pkt_pool == NULL)
-			rte_exit(EXIT_FAILURE,
-				"rte_pktmbuf_pool_create failed"
-				);
-
-		printf("Init port %i..\n", idx_port);
-		ptr_port->port_active = 1;
-		ptr_port->port_dirty = 0;
-		ptr_port->idx_port = idx_port;
-
-		if (rte_eth_dev_configure(idx_port, 1, 1, &cfg_port) < 0)
-			rte_exit(EXIT_FAILURE,
-				 "rte_eth_dev_configure failed");
-		if (rte_eth_dev_adjust_nb_rx_tx_desc(idx_port, &nb_rxd,
-						     &nb_txd) < 0)
-			rte_exit(EXIT_FAILURE,
-				 "rte_eth_dev_adjust_nb_rx_tx_desc failed");
-
-		if (rte_eth_rx_queue_setup(
-			    idx_port, 0, nb_rxd,
-			    rte_eth_dev_socket_id(idx_port), NULL,
-			    ptr_port->pkt_pool) < 0)
-			rte_exit(EXIT_FAILURE,
-				 "rte_eth_rx_queue_setup failed"
-				);
-		txconf = dev_info.default_txconf;
-		txconf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-		if (rte_eth_tx_queue_setup(
-			    idx_port, 0, nb_txd,
-			    rte_eth_dev_socket_id(idx_port), &txconf) < 0)
-			rte_exit(EXIT_FAILURE,
-				 "rte_eth_tx_queue_setup failed"
-				);
-		if (rte_eth_dev_start(idx_port) < 0)
-			rte_exit(EXIT_FAILURE,
-				 "%s:%i: rte_eth_dev_start failed",
-				 __FILE__, __LINE__
-				);
-		rte_eth_macaddr_get(idx_port, &ptr_port->mac_addr);
-		rte_spinlock_init(&ptr_port->lock);
-	}
-}
-
-static void process_frame(struct app_port *ptr_port,
-	struct rte_mbuf *ptr_frame)
-{
-	struct ether_hdr *ptr_mac_hdr;
-
-	ptr_mac_hdr = rte_pktmbuf_mtod(ptr_frame, struct ether_hdr *);
-	ether_addr_copy(&ptr_mac_hdr->s_addr, &ptr_mac_hdr->d_addr);
-	ether_addr_copy(&ptr_port->mac_addr, &ptr_mac_hdr->s_addr);
-}
-
-static int slave_main(__attribute__((unused)) void *ptr_data)
-{
-	struct app_port *ptr_port;
-	struct rte_mbuf *ptr_frame;
-	struct txq_port *txq;
-
-	uint16_t cnt_recv_frames;
-	uint16_t idx_frame;
-	uint16_t cnt_sent;
-	uint16_t idx_port;
-	uint16_t lock_result;
-
-	while (app_cfg.exit_now == 0) {
-		for (idx_port = 0; idx_port < app_cfg.cnt_ports; idx_port++) {
-			/* Check that port is active and unlocked */
-			ptr_port = &app_cfg.ports[idx_port];
-			lock_result = rte_spinlock_trylock(&ptr_port->lock);
-			if (lock_result == 0)
-				continue;
-			if (ptr_port->port_active == 0) {
-				rte_spinlock_unlock(&ptr_port->lock);
-				continue;
-			}
-			txq = &ptr_port->txq;
-
-			/* MAC address was updated */
-			if (ptr_port->port_dirty == 1) {
-				rte_eth_macaddr_get(ptr_port->idx_port,
-					&ptr_port->mac_addr);
-				ptr_port->port_dirty = 0;
-			}
-
-			/* Incoming frames */
-			cnt_recv_frames = rte_eth_rx_burst(
-				ptr_port->idx_port, 0,
-				&txq->buf_frames[txq->cnt_unsent],
-				RTE_DIM(txq->buf_frames) - txq->cnt_unsent
-				);
-			if (cnt_recv_frames > 0) {
-				for (idx_frame = 0;
-					idx_frame < cnt_recv_frames;
-					idx_frame++) {
-					ptr_frame = txq->buf_frames[
-						idx_frame + txq->cnt_unsent];
-					process_frame(ptr_port, ptr_frame);
-				}
-				txq->cnt_unsent += cnt_recv_frames;
-			}
-
-			/* Outgoing frames */
-			if (txq->cnt_unsent > 0) {
-				cnt_sent = rte_eth_tx_burst(
-					ptr_port->idx_port, 0,
-					txq->buf_frames,
-					txq->cnt_unsent
-					);
-				/* Shuffle up unsent frame pointers */
-				for (idx_frame = cnt_sent;
-					idx_frame < txq->cnt_unsent;
-					idx_frame++)
-					txq->buf_frames[idx_frame - cnt_sent] =
-						txq->buf_frames[idx_frame];
-				txq->cnt_unsent -= cnt_sent;
-			}
-			rte_spinlock_unlock(&ptr_port->lock);
-		} /* end for( idx_port ) */
-	} /* end for(;;) */
-
-	return 0;
-}
-
-int main(int argc, char **argv)
-{
-	int cnt_args_parsed;
-	uint32_t id_core;
-	uint32_t cnt_ports;
-
-	/* Init runtime environment */
-	cnt_args_parsed = rte_eal_init(argc, argv);
-	if (cnt_args_parsed < 0)
-		rte_exit(EXIT_FAILURE, "rte_eal_init(): Failed");
-
-	cnt_ports = rte_eth_dev_count();
-	printf("Number of NICs: %i\n", cnt_ports);
-	if (cnt_ports == 0)
-		rte_exit(EXIT_FAILURE, "No available NIC ports!\n");
-	if (cnt_ports > MAX_PORTS) {
-		printf("Info: Using only %i of %i ports\n",
-			cnt_ports, MAX_PORTS
-			);
-		cnt_ports = MAX_PORTS;
-	}
-
-	setup_ports(&app_cfg, cnt_ports);
-
-	app_cfg.exit_now = 0;
-	app_cfg.cnt_ports = cnt_ports;
-
-	if (rte_lcore_count() < 2)
-		rte_exit(EXIT_FAILURE, "No available slave core!\n");
-	/* Assume there is an available slave.. */
-	id_core = rte_lcore_id();
-	id_core = rte_get_next_lcore(id_core, 1, 1);
-	rte_eal_remote_launch(slave_main, NULL, id_core);
-
-	ethapp_main();
-
-	app_cfg.exit_now = 1;
-	RTE_LCORE_FOREACH_SLAVE(id_core) {
-		if (rte_eal_wait_lcore(id_core) < 0)
-			return -1;
-	}
-
-	return 0;
-}
diff --git a/examples/ethtool/lib/Makefile b/examples/ethtool/lib/Makefile
deleted file mode 100644
index fbafa6d..0000000
--- a/examples/ethtool/lib/Makefile
+++ /dev/null
@@ -1,36 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2015 Intel Corporation
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overwritten by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-ifneq ($(CONFIG_RTE_EXEC_ENV),"linuxapp")
-$(error This application can only operate in a linuxapp environment, \
-please change the definition of the RTE_TARGET environment variable)
-endif
-
-# library name
-LIB = librte_ethtool.a
-
-LIBABIVER := 1
-
-# all source are stored in SRC-Y
-SRCS-y := rte_ethtool.c
-
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-
-ifeq ($(CONFIG_RTE_BUILD_SHARED_LIB),y)
-ifeq ($(CONFIG_RTE_LIBRTE_IXGBE_PMD),y)
-LDLIBS += -lrte_pmd_ixgbe
-endif
-endif
-LDLIBS += -lrte_eal -lrte_ethdev
-
-include $(RTE_SDK)/mk/rte.extlib.mk
diff --git a/examples/ethtool/lib/rte_ethtool.c b/examples/ethtool/lib/rte_ethtool.c
deleted file mode 100644
index 90dfbb7..0000000
--- a/examples/ethtool/lib/rte_ethtool.c
+++ /dev/null
@@ -1,419 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-#include <stdio.h>
-#include <string.h>
-#include <stdint.h>
-#include <rte_version.h>
-#include <rte_ethdev.h>
-#include <rte_ether.h>
-#include <rte_bus_pci.h>
-#ifdef RTE_LIBRTE_IXGBE_PMD
-#include <rte_pmd_ixgbe.h>
-#endif
-#include "rte_ethtool.h"
-
-#define PKTPOOL_SIZE 512
-#define PKTPOOL_CACHE 32
-
-
-int
-rte_ethtool_get_drvinfo(uint16_t port_id, struct ethtool_drvinfo *drvinfo)
-{
-	struct rte_eth_dev_info dev_info;
-	struct rte_dev_reg_info reg_info;
-	int n;
-	int ret;
-
-	if (drvinfo == NULL)
-		return -EINVAL;
-
-	RTE_ETH_VALID_PORTID_OR_ERR_RET(port_id, -ENODEV);
-
-	ret = rte_eth_dev_fw_version_get(port_id, drvinfo->fw_version,
-			      sizeof(drvinfo->fw_version));
-	if (ret < 0)
-		printf("firmware version get error: (%s)\n", strerror(-ret));
-	else if (ret > 0)
-		printf("Insufficient fw version buffer size, "
-		       "the minimum size should be %d\n", ret);
-
-	memset(&dev_info, 0, sizeof(dev_info));
-	rte_eth_dev_info_get(port_id, &dev_info);
-
-	snprintf(drvinfo->driver, sizeof(drvinfo->driver), "%s",
-		dev_info.driver_name);
-	snprintf(drvinfo->version, sizeof(drvinfo->version), "%s",
-		rte_version());
-	/* TODO: replace bus_info by rte_devargs.name */
-	if (dev_info.pci_dev)
-		snprintf(drvinfo->bus_info, sizeof(drvinfo->bus_info),
-			"%04x:%02x:%02x.%x",
-			dev_info.pci_dev->addr.domain,
-			dev_info.pci_dev->addr.bus,
-			dev_info.pci_dev->addr.devid,
-			dev_info.pci_dev->addr.function);
-	else
-		snprintf(drvinfo->bus_info, sizeof(drvinfo->bus_info), "N/A");
-
-	memset(&reg_info, 0, sizeof(reg_info));
-	rte_eth_dev_get_reg_info(port_id, &reg_info);
-	n = reg_info.length;
-	if (n > 0)
-		drvinfo->regdump_len = n;
-	else
-		drvinfo->regdump_len = 0;
-
-	n = rte_eth_dev_get_eeprom_length(port_id);
-	if (n > 0)
-		drvinfo->eedump_len = n;
-	else
-		drvinfo->eedump_len = 0;
-
-	drvinfo->n_stats = sizeof(struct rte_eth_stats) / sizeof(uint64_t);
-	drvinfo->testinfo_len = 0;
-
-	return 0;
-}
-
-int
-rte_ethtool_get_regs_len(uint16_t port_id)
-{
-	struct rte_dev_reg_info reg_info;
-	int ret;
-
-	memset(&reg_info, 0, sizeof(reg_info));
-
-	ret = rte_eth_dev_get_reg_info(port_id, &reg_info);
-	if (ret)
-		return ret;
-
-	return reg_info.length * reg_info.width;
-}
-
-int
-rte_ethtool_get_regs(uint16_t port_id, struct ethtool_regs *regs, void *data)
-{
-	struct rte_dev_reg_info reg_info;
-	int status;
-
-	if (regs == NULL || data == NULL)
-		return -EINVAL;
-
-	reg_info.data = data;
-	reg_info.length = 0;
-
-	status = rte_eth_dev_get_reg_info(port_id, &reg_info);
-	if (status)
-		return status;
-	regs->version = reg_info.version;
-
-	return 0;
-}
-
-int
-rte_ethtool_get_link(uint16_t port_id)
-{
-	struct rte_eth_link link;
-
-	RTE_ETH_VALID_PORTID_OR_ERR_RET(port_id, -ENODEV);
-	rte_eth_link_get(port_id, &link);
-	return link.link_status;
-}
-
-int
-rte_ethtool_get_eeprom_len(uint16_t port_id)
-{
-	return rte_eth_dev_get_eeprom_length(port_id);
-}
-
-int
-rte_ethtool_get_eeprom(uint16_t port_id, struct ethtool_eeprom *eeprom,
-	void *words)
-{
-	struct rte_dev_eeprom_info eeprom_info;
-	int status;
-
-	if (eeprom == NULL || words == NULL)
-		return -EINVAL;
-
-	eeprom_info.offset = eeprom->offset;
-	eeprom_info.length = eeprom->len;
-	eeprom_info.data = words;
-
-	status = rte_eth_dev_get_eeprom(port_id, &eeprom_info);
-	if (status)
-		return status;
-
-	eeprom->magic = eeprom_info.magic;
-
-	return 0;
-}
-
-int
-rte_ethtool_set_eeprom(uint16_t port_id, struct ethtool_eeprom *eeprom,
-	void *words)
-{
-	struct rte_dev_eeprom_info eeprom_info;
-	int status;
-
-	if (eeprom == NULL || words == NULL || eeprom->offset >= eeprom->len)
-		return -EINVAL;
-
-	eeprom_info.offset = eeprom->offset;
-	eeprom_info.length = eeprom->len;
-	eeprom_info.data = words;
-
-	status = rte_eth_dev_set_eeprom(port_id, &eeprom_info);
-	if (status)
-		return status;
-
-	eeprom->magic = eeprom_info.magic;
-
-	return 0;
-}
-
-int
-rte_ethtool_get_pauseparam(uint16_t port_id,
-	struct ethtool_pauseparam *pause_param)
-{
-	struct rte_eth_fc_conf fc_conf;
-	int status;
-
-	if (pause_param == NULL)
-		return -EINVAL;
-
-	status = rte_eth_dev_flow_ctrl_get(port_id, &fc_conf);
-	if (status)
-		return status;
-
-	pause_param->tx_pause = 0;
-	pause_param->rx_pause = 0;
-	switch (fc_conf.mode) {
-	case RTE_FC_RX_PAUSE:
-		pause_param->rx_pause = 1;
-		break;
-	case RTE_FC_TX_PAUSE:
-		pause_param->tx_pause = 1;
-		break;
-	case RTE_FC_FULL:
-		pause_param->rx_pause = 1;
-		pause_param->tx_pause = 1;
-	default:
-		/* dummy block to avoid compiler warning */
-		break;
-	}
-	pause_param->autoneg = (uint32_t)fc_conf.autoneg;
-
-	return 0;
-}
-
-int
-rte_ethtool_set_pauseparam(uint16_t port_id,
-	struct ethtool_pauseparam *pause_param)
-{
-	struct rte_eth_fc_conf fc_conf;
-	int status;
-
-	if (pause_param == NULL)
-		return -EINVAL;
-
-	/*
-	 * Read device flow control parameter first since
-	 * ethtool set_pauseparam op doesn't have all the information.
-	 * as defined in struct rte_eth_fc_conf.
-	 * This API requires the device to support both
-	 * rte_eth_dev_flow_ctrl_get and rte_eth_dev_flow_ctrl_set, otherwise
-	 * return -ENOTSUP
-	 */
-	status = rte_eth_dev_flow_ctrl_get(port_id, &fc_conf);
-	if (status)
-		return status;
-
-	fc_conf.autoneg = (uint8_t)pause_param->autoneg;
-
-	if (pause_param->tx_pause) {
-		if (pause_param->rx_pause)
-			fc_conf.mode = RTE_FC_FULL;
-		else
-			fc_conf.mode = RTE_FC_TX_PAUSE;
-	} else {
-		if (pause_param->rx_pause)
-			fc_conf.mode = RTE_FC_RX_PAUSE;
-		else
-			fc_conf.mode = RTE_FC_NONE;
-	}
-
-	status = rte_eth_dev_flow_ctrl_set(port_id, &fc_conf);
-	if (status)
-		return status;
-
-	return 0;
-}
-
-int
-rte_ethtool_net_open(uint16_t port_id)
-{
-	rte_eth_dev_stop(port_id);
-
-	return rte_eth_dev_start(port_id);
-}
-
-int
-rte_ethtool_net_stop(uint16_t port_id)
-{
-	RTE_ETH_VALID_PORTID_OR_ERR_RET(port_id, -ENODEV);
-	rte_eth_dev_stop(port_id);
-
-	return 0;
-}
-
-int
-rte_ethtool_net_get_mac_addr(uint16_t port_id, struct ether_addr *addr)
-{
-	RTE_ETH_VALID_PORTID_OR_ERR_RET(port_id, -ENODEV);
-	if (addr == NULL)
-		return -EINVAL;
-	rte_eth_macaddr_get(port_id, addr);
-
-	return 0;
-}
-
-int
-rte_ethtool_net_set_mac_addr(uint16_t port_id, struct ether_addr *addr)
-{
-	if (addr == NULL)
-		return -EINVAL;
-	return rte_eth_dev_default_mac_addr_set(port_id, addr);
-}
-
-int
-rte_ethtool_net_validate_addr(uint16_t port_id __rte_unused,
-	struct ether_addr *addr)
-{
-	if (addr == NULL)
-		return -EINVAL;
-	return is_valid_assigned_ether_addr(addr);
-}
-
-int
-rte_ethtool_net_change_mtu(uint16_t port_id, int mtu)
-{
-	if (mtu < 0 || mtu > UINT16_MAX)
-		return -EINVAL;
-	return rte_eth_dev_set_mtu(port_id, (uint16_t)mtu);
-}
-
-int
-rte_ethtool_net_get_stats64(uint16_t port_id, struct rte_eth_stats *stats)
-{
-	if (stats == NULL)
-		return -EINVAL;
-	return rte_eth_stats_get(port_id, stats);
-}
-
-int
-rte_ethtool_net_vlan_rx_add_vid(uint16_t port_id, uint16_t vid)
-{
-	return rte_eth_dev_vlan_filter(port_id, vid, 1);
-}
-
-int
-rte_ethtool_net_vlan_rx_kill_vid(uint16_t port_id, uint16_t vid)
-{
-	return rte_eth_dev_vlan_filter(port_id, vid, 0);
-}
-
-/*
- * The set_rx_mode provides driver-specific rx mode setting.
- * This implementation implements rx mode setting based upon
- * ixgbe/igb drivers. Further improvement is to provide a
- * callback op field over struct rte_eth_dev::dev_ops so each
- * driver can register device-specific implementation
- */
-int
-rte_ethtool_net_set_rx_mode(uint16_t port_id)
-{
-	uint16_t num_vfs;
-	struct rte_eth_dev_info dev_info;
-	uint16_t vf;
-
-	memset(&dev_info, 0, sizeof(dev_info));
-	rte_eth_dev_info_get(port_id, &dev_info);
-	num_vfs = dev_info.max_vfs;
-
-	/* Set VF vf_rx_mode, VF unsupport status is discard */
-	for (vf = 0; vf < num_vfs; vf++) {
-#ifdef RTE_LIBRTE_IXGBE_PMD
-		rte_pmd_ixgbe_set_vf_rxmode(port_id, vf,
-			ETH_VMDQ_ACCEPT_UNTAG, 0);
-#endif
-	}
-
-	/* Enable Rx vlan filter, VF unspport status is discard */
-	rte_eth_dev_set_vlan_offload(port_id, ETH_VLAN_FILTER_MASK);
-
-	return 0;
-}
-
-
-int
-rte_ethtool_get_ringparam(uint16_t port_id,
-	struct ethtool_ringparam *ring_param)
-{
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_rxq_info rx_qinfo;
-	struct rte_eth_txq_info tx_qinfo;
-	int stat;
-
-	if (ring_param == NULL)
-		return -EINVAL;
-
-	rte_eth_dev_info_get(port_id, &dev_info);
-
-	stat = rte_eth_rx_queue_info_get(port_id, 0, &rx_qinfo);
-	if (stat != 0)
-		return stat;
-
-	stat = rte_eth_tx_queue_info_get(port_id, 0, &tx_qinfo);
-	if (stat != 0)
-		return stat;
-
-	memset(ring_param, 0, sizeof(*ring_param));
-	ring_param->rx_pending = rx_qinfo.nb_desc;
-	ring_param->rx_max_pending = dev_info.rx_desc_lim.nb_max;
-	ring_param->tx_pending = tx_qinfo.nb_desc;
-	ring_param->tx_max_pending = dev_info.tx_desc_lim.nb_max;
-
-	return 0;
-}
-
-
-int
-rte_ethtool_set_ringparam(uint16_t port_id,
-	struct ethtool_ringparam *ring_param)
-{
-	struct rte_eth_rxq_info rx_qinfo;
-	int stat;
-
-	if (ring_param == NULL)
-		return -EINVAL;
-
-	stat = rte_eth_rx_queue_info_get(port_id, 0, &rx_qinfo);
-	if (stat != 0)
-		return stat;
-
-	rte_eth_dev_stop(port_id);
-
-	stat = rte_eth_tx_queue_setup(port_id, 0, ring_param->tx_pending,
-		rte_socket_id(), NULL);
-	if (stat != 0)
-		return stat;
-
-	stat = rte_eth_rx_queue_setup(port_id, 0, ring_param->rx_pending,
-		rte_socket_id(), NULL, rx_qinfo.mp);
-	if (stat != 0)
-		return stat;
-
-	return rte_eth_dev_start(port_id);
-}
diff --git a/examples/ethtool/lib/rte_ethtool.h b/examples/ethtool/lib/rte_ethtool.h
deleted file mode 100644
index c962396..0000000
--- a/examples/ethtool/lib/rte_ethtool.h
+++ /dev/null
@@ -1,381 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#ifndef _RTE_ETHTOOL_H_
-#define _RTE_ETHTOOL_H_
-
-/*
- * This new interface is designed to provide a user-space shim layer for
- * Ethtool and Netdevice op API.
- *
- * rte_ethtool_get_driver:          ethtool_ops::get_driverinfo
- * rte_ethtool_get_link:            ethtool_ops::get_link
- * rte_ethtool_get_regs_len:        ethtool_ops::get_regs_len
- * rte_ethtool_get_regs:            ethtool_ops::get_regs
- * rte_ethtool_get_eeprom_len:      ethtool_ops::get_eeprom_len
- * rte_ethtool_get_eeprom:          ethtool_ops::get_eeprom
- * rte_ethtool_set_eeprom:          ethtool_ops::set_eeprom
- * rte_ethtool_get_pauseparam:      ethtool_ops::get_pauseparam
- * rte_ethtool_set_pauseparam:      ethtool_ops::set_pauseparam
- *
- * rte_ethtool_net_open:            net_device_ops::ndo_open
- * rte_ethtool_net_stop:            net_device_ops::ndo_stop
- * rte_ethtool_net_set_mac_addr:    net_device_ops::ndo_set_mac_address
- * rte_ethtool_net_validate_addr:   net_device_ops::ndo_validate_addr
- * rte_ethtool_net_change_mtu:      net_device_ops::rte_net_change_mtu
- * rte_ethtool_net_get_stats64:     net_device_ops::ndo_get_stats64
- * rte_ethtool_net_vlan_rx_add_vid  net_device_ops::ndo_vlan_rx_add_vid
- * rte_ethtool_net_vlan_rx_kill_vid net_device_ops::ndo_vlan_rx_kill_vid
- * rte_ethtool_net_set_rx_mode      net_device_ops::ndo_set_rx_mode
- *
- */
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-#include <stdint.h>
-#include <rte_ethdev.h>
-#include <linux/ethtool.h>
-
-/**
- * Retrieve the Ethernet device driver information according to
- * attributes described by ethtool data structure, ethtool_drvinfo.
- *
- * @param port_id
- *   The port identifier of the Ethernet device.
- * @param drvinfo
- *   A pointer to get driver information
- * @return
- *   - (0) if successful.
- *   - (-ENODEV) if *port_id* invalid.
- */
-int rte_ethtool_get_drvinfo(uint16_t port_id, struct ethtool_drvinfo *drvinfo);
-
-/**
- * Retrieve the Ethernet device register length in bytes.
- *
- * @param port_id
- *   The port identifier of the Ethernet device.
- * @return
- *   - (> 0) # of device registers (in bytes) available for dump
- *   - (0) no registers available for dump.
- *   - (-ENOTSUP) if hardware doesn't support.
- *   - (-ENODEV) if *port_id* invalid.
- *   - others depends on the specific operations implementation.
- */
-int rte_ethtool_get_regs_len(uint16_t port_id);
-
-/**
- * Retrieve the Ethernet device register information according to
- * attributes described by ethtool data structure, ethtool_regs
- *
- * @param port_id
- *   The port identifier of the Ethernet device.
- * @param reg
- *   A pointer to ethtool_regs that has register information
- * @param data
- *   A pointer to a buffer that is used to retrieve device register content
- * @return
- *   - (0) if successful.
- *   - (-ENOTSUP) if hardware doesn't support.
- *   - (-ENODEV) if *port_id* invalid.
- *   - others depends on the specific operations implementation.
- */
-int rte_ethtool_get_regs(uint16_t port_id, struct ethtool_regs *regs,
-			    void *data);
-
-/**
- * Retrieve the Ethernet device link status
- *
- * @param port_id
- *   The port identifier of the Ethernet device.
- * @return
- *   - (1) if link up.
- *   - (0) if link down.
- *   - (-ENOTSUP) if hardware doesn't support.
- *   - (-ENODEV) if *port_id* invalid.
- *   - (-EINVAL) if parameters invalid.
- *   - others depends on the specific operations implementation.
- */
-int rte_ethtool_get_link(uint16_t port_id);
-
-/**
- * Retrieve the Ethernet device EEPROM size
- *
- * @param port_id
- *   The port identifier of the Ethernet device.
- * @return
- *	 - (> 0) device EEPROM size in bytes
- *   - (0) device has NO EEPROM
- *   - (-ENOTSUP) if hardware doesn't support.
- *   - (-ENODEV) if *port_id* invalid.
- *   - others depends on the specific operations implementation.
- */
-int rte_ethtool_get_eeprom_len(uint16_t port_id);
-
-/**
- * Retrieve EEPROM content based upon eeprom range described in ethtool
- * data structure, ethtool_eeprom
- *
- * @param port_id
- *   The port identifier of the Ethernet device.
- * @param eeprom
- *	 The pointer of ethtool_eeprom that provides eeprom range
- * @param words
- *	 A buffer that holds data read from eeprom
- * @return
- *   - (0) if successful.
- *   - (-ENOTSUP) if hardware doesn't support.
- *   - (-ENODEV) if *port_id* invalid.
- *   - others depends on the specific operations implementation.
- */
-int rte_ethtool_get_eeprom(uint16_t port_id, struct ethtool_eeprom *eeprom,
-			      void *words);
-
-/**
- * Setting EEPROM content based upon eeprom range described in ethtool
- * data structure, ethtool_eeprom
- *
- * @param port_id
- *   The port identifier of the Ethernet device.
- * @param eeprom
- *	 The pointer of ethtool_eeprom that provides eeprom range
- * @param words
- *	 A buffer that holds data to be written into eeprom
- * @return
- *   - (0) if successful.
- *   - (-ENOTSUP) if hardware doesn't support.
- *   - (-ENODEV) if *port_id* invalid.
- *   - (-EINVAL) if parameters invalid.
- *   - others depends on the specific operations implementation.
- */
-int rte_ethtool_set_eeprom(uint16_t port_id, struct ethtool_eeprom *eeprom,
-			      void *words);
-
-/**
- * Retrieve the Ethernet device pause frame configuration according to
- * parameter attributes desribed by ethtool data structure,
- * ethtool_pauseparam.
- *
- * @param port_id
- *   The port identifier of the Ethernet device.
- * @param pause_param
- *	 The pointer of ethtool_coalesce that gets pause frame
- *	 configuration parameters
- * @return
- *   - (0) if successful.
- *   - (-ENOTSUP) if hardware doesn't support.
- *   - (-ENODEV) if *port_id* invalid.
- *   - (-EINVAL) if parameters invalid.
- *   - others depends on the specific operations implementation.
- */
-int rte_ethtool_get_pauseparam(uint16_t port_id,
-				   struct ethtool_pauseparam *pause_param);
-
-/**
- * Setting the Ethernet device pause frame configuration according to
- * parameter attributes desribed by ethtool data structure, ethtool_pauseparam.
- *
- * @param port_id
- *   The port identifier of the Ethernet device.
- * @param pause_param
- *	 The pointer of ethtool_coalesce that gets ring configuration parameters
- * @return
- *   - (0) if successful.
- *   - (-ENOTSUP) if hardware doesn't support.
- *   - (-ENODEV) if *port_id* invalid.
- *   - (-EINVAL) if parameters invalid.
- *   - others depends on the specific operations implementation.
- */
-int rte_ethtool_set_pauseparam(uint16_t port_id,
-				   struct ethtool_pauseparam *param);
-
-/**
- * Start the Ethernet device.
- *
- * @param port_id
- *   The port identifier of the Ethernet device.
- * @return
- *   - (0) if successful.
- *   - (-ENOTSUP) if hardware doesn't support.
- *   - (-ENODEV) if *port_id* invalid.
- *   - others depends on the specific operations implementation.
- */
-int rte_ethtool_net_open(uint16_t port_id);
-
-/**
- * Stop the Ethernet device.
- *
- * @param port_id
- *   The port identifier of the Ethernet device.
- * @return
- *   - (0) if successful.
- *   - (-ENODEV) if *port_id* invalid.
- */
-int rte_ethtool_net_stop(uint16_t port_id);
-
-/**
- * Get the Ethernet device MAC address.
- *
- * @param port_id
- *   The port identifier of the Ethernet device.
- * @param addr
- *	 MAC address of the Ethernet device.
- * @return
- *   - (0) if successful.
- *   - (-ENODEV) if *port_id* invalid.
- */
-int rte_ethtool_net_get_mac_addr(uint16_t port_id, struct ether_addr *addr);
-
-/**
- * Setting the Ethernet device MAC address.
- *
- * @param port_id
- *   The port identifier of the Ethernet device.
- * @param addr
- *	 The new MAC addr.
- * @return
- *   - (0) if successful.
- *   - (-ENOTSUP) if hardware doesn't support.
- *   - (-ENODEV) if *port_id* invalid.
- *   - (-EINVAL) if parameters invalid.
- *   - others depends on the specific operations implementation.
- */
-int rte_ethtool_net_set_mac_addr(uint16_t port_id, struct ether_addr *addr);
-
-/**
- * Validate if the provided MAC address is valid unicast address
- *
- * @param port_id
- *   The port identifier of the Ethernet device.
- * @param addr
- *	 A pointer to a buffer (6-byte, 48bit) for the target MAC address
- * @return
- *   - (0) if successful.
- *   - (-ENOTSUP) if hardware doesn't support.
- *   - (-ENODEV) if *port_id* invalid.
- *   - (-EINVAL) if parameters invalid.
- *   - others depends on the specific operations implementation.
- */
-int rte_ethtool_net_validate_addr(uint16_t port_id, struct ether_addr *addr);
-
-/**
- * Setting the Ethernet device maximum Tx unit.
- *
- * @param port_id
- *   The port identifier of the Ethernet device.
- * @param mtu
- *	 New MTU
- * @return
- *   - (0) if successful.
- *   - (-ENOTSUP) if hardware doesn't support.
- *   - (-ENODEV) if *port_id* invalid.
- *   - (-EINVAL) if parameters invalid.
- *   - others depends on the specific operations implementation.
- */
-int rte_ethtool_net_change_mtu(uint16_t port_id, int mtu);
-
-/**
- * Retrieve the Ethernet device traffic statistics
- *
- * @param port_id
- *   The port identifier of the Ethernet device.
- * @param stats
- *	 A pointer to struct rte_eth_stats for statistics parameters
- * @return
- *   - (0) if successful.
- *   - (-ENOTSUP) if hardware doesn't support.
- *   - (-ENODEV) if *port_id* invalid.
- *   - (-EINVAL) if parameters invalid.
- *   - others depends on the specific operations implementation.
- */
-int rte_ethtool_net_get_stats64(uint16_t port_id, struct rte_eth_stats *stats);
-
-/**
- * Update the Ethernet device VLAN filter with new vid
- *
- * @param port_id
- *   The port identifier of the Ethernet device.
- * @param vid
- *	 A new VLAN id
- * @return
- *   - (0) if successful.
- *   - (-ENOTSUP) if hardware doesn't support.
- *   - (-ENODEV) if *port_id* invalid.
- *   - others depends on the specific operations implementation.
- */
-int rte_ethtool_net_vlan_rx_add_vid(uint16_t port_id, uint16_t vid);
-
-/**
- * Remove VLAN id from Ethernet device.
- *
- * @param port_id
- *   The port identifier of the Ethernet device.
- * @param vid
- *	 A new VLAN id
- * @return
- *   - (0) if successful.
- *   - (-ENOTSUP) if hardware doesn't support.
- *   - (-ENODEV) if *port_id* invalid.
- *   - others depends on the specific operations implementation.
- */
-int rte_ethtool_net_vlan_rx_kill_vid(uint16_t port_id, uint16_t vid);
-
-/**
- * Setting the Ethernet device rx mode.
- *
- * @param port_id
- *   The port identifier of the Ethernet device.
- * @return
- *   - (0) if successful.
- *   - (-ENOTSUP) if hardware doesn't support.
- *   - (-ENODEV) if *port_id* invalid.
- *   - others depends on the specific operations implementation.
- */
-int rte_ethtool_net_set_rx_mode(uint16_t port_id);
-
-/**
- * Getting ring parameters for Ethernet device.
- *
- * @param port_id
- *   The port identifier of the Ethernet device.
- * @param ring_param
- *   Pointer to struct ethrool_ringparam to receive parameters.
- * @return
- *   - (0) if successful.
- *   - (-ENOTSUP) if hardware doesn't support.
- *   - (-ENODEV) if *port_id* invalid.
- *   - others depends on the specific operations implementation.
- * @note
- *   Only the tx_pending and rx_pending fields of struct ethtool_ringparam
- *   are used, and the function only gets parameters for queue 0.
- */
-int rte_ethtool_get_ringparam(uint16_t port_id,
-	struct ethtool_ringparam *ring_param);
-
-/**
- * Setting ring parameters for Ethernet device.
- *
- * @param port_id
- *   The port identifier of the Ethernet device.
- * @param ring_param
- *   Pointer to struct ethrool_ringparam with parameters to set.
- * @return
- *   - (0) if successful.
- *   - (-ENOTSUP) if hardware doesn't support.
- *   - (-ENODEV) if *port_id* invalid.
- *   - others depends on the specific operations implementation.
- * @note
- *   Only the tx_pending and rx_pending fields of struct ethtool_ringparam
- *   are used, and the function only sets parameters for queue 0.
- */
-int rte_ethtool_set_ringparam(uint16_t port_id,
-	struct ethtool_ringparam *ring_param);
-
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif /* _RTE_ETHTOOL_H_ */
diff --git a/examples/eventdev_pipeline/Makefile b/examples/eventdev_pipeline/Makefile
deleted file mode 100644
index 1a789cc..0000000
--- a/examples/eventdev_pipeline/Makefile
+++ /dev/null
@@ -1,61 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2016-2017 Intel Corporation
-
-# binary name
-APP = eventdev_pipeline
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-SRCS-y += pipeline_worker_generic.c
-SRCS-y += pipeline_worker_tx.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-
-endif
diff --git a/examples/eventdev_pipeline/main.c b/examples/eventdev_pipeline/main.c
deleted file mode 100644
index 48358a7..0000000
--- a/examples/eventdev_pipeline/main.c
+++ /dev/null
@@ -1,573 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016-2017 Intel Corporation
- */
-
-#include <getopt.h>
-#include <stdint.h>
-#include <stdio.h>
-#include <signal.h>
-#include <sched.h>
-
-#include "pipeline_common.h"
-
-struct config_data cdata = {
-	.num_packets = (1L << 25), /* do ~32M packets */
-	.num_fids = 512,
-	.queue_type = RTE_SCHED_TYPE_ATOMIC,
-	.next_qid = {-1},
-	.qid = {-1},
-	.num_stages = 1,
-	.worker_cq_depth = 16
-};
-
-static bool
-core_in_use(unsigned int lcore_id) {
-	return (fdata->rx_core[lcore_id] || fdata->sched_core[lcore_id] ||
-		fdata->tx_core[lcore_id] || fdata->worker_core[lcore_id]);
-}
-
-static void
-eth_tx_buffer_retry(struct rte_mbuf **pkts, uint16_t unsent,
-			void *userdata)
-{
-	int port_id = (uintptr_t) userdata;
-	unsigned int _sent = 0;
-
-	do {
-		/* Note: hard-coded TX queue */
-		_sent += rte_eth_tx_burst(port_id, 0, &pkts[_sent],
-					  unsent - _sent);
-	} while (_sent != unsent);
-}
-
-/*
- * Parse the coremask given as argument (hexadecimal string) and fill
- * the global configuration (core role and core count) with the parsed
- * value.
- */
-static int xdigit2val(unsigned char c)
-{
-	int val;
-
-	if (isdigit(c))
-		val = c - '0';
-	else if (isupper(c))
-		val = c - 'A' + 10;
-	else
-		val = c - 'a' + 10;
-	return val;
-}
-
-static uint64_t
-parse_coremask(const char *coremask)
-{
-	int i, j, idx = 0;
-	unsigned int count = 0;
-	char c;
-	int val;
-	uint64_t mask = 0;
-	const int32_t BITS_HEX = 4;
-
-	if (coremask == NULL)
-		return -1;
-	/* Remove all blank characters ahead and after .
-	 * Remove 0x/0X if exists.
-	 */
-	while (isblank(*coremask))
-		coremask++;
-	if (coremask[0] == '0' && ((coremask[1] == 'x')
-		|| (coremask[1] == 'X')))
-		coremask += 2;
-	i = strlen(coremask);
-	while ((i > 0) && isblank(coremask[i - 1]))
-		i--;
-	if (i == 0)
-		return -1;
-
-	for (i = i - 1; i >= 0 && idx < MAX_NUM_CORE; i--) {
-		c = coremask[i];
-		if (isxdigit(c) == 0) {
-			/* invalid characters */
-			return -1;
-		}
-		val = xdigit2val(c);
-		for (j = 0; j < BITS_HEX && idx < MAX_NUM_CORE; j++, idx++) {
-			if ((1 << j) & val) {
-				mask |= (1UL << idx);
-				count++;
-			}
-		}
-	}
-	for (; i >= 0; i--)
-		if (coremask[i] != '0')
-			return -1;
-	if (count == 0)
-		return -1;
-	return mask;
-}
-
-static struct option long_options[] = {
-	{"workers", required_argument, 0, 'w'},
-	{"packets", required_argument, 0, 'n'},
-	{"atomic-flows", required_argument, 0, 'f'},
-	{"num_stages", required_argument, 0, 's'},
-	{"rx-mask", required_argument, 0, 'r'},
-	{"tx-mask", required_argument, 0, 't'},
-	{"sched-mask", required_argument, 0, 'e'},
-	{"cq-depth", required_argument, 0, 'c'},
-	{"work-cycles", required_argument, 0, 'W'},
-	{"mempool-size", required_argument, 0, 'm'},
-	{"queue-priority", no_argument, 0, 'P'},
-	{"parallel", no_argument, 0, 'p'},
-	{"ordered", no_argument, 0, 'o'},
-	{"quiet", no_argument, 0, 'q'},
-	{"use-atq", no_argument, 0, 'a'},
-	{"dump", no_argument, 0, 'D'},
-	{0, 0, 0, 0}
-};
-
-static void
-usage(void)
-{
-	const char *usage_str =
-		"  Usage: eventdev_demo [options]\n"
-		"  Options:\n"
-		"  -n, --packets=N              Send N packets (default ~32M), 0 implies no limit\n"
-		"  -f, --atomic-flows=N         Use N random flows from 1 to N (default 16)\n"
-		"  -s, --num_stages=N           Use N atomic stages (default 1)\n"
-		"  -r, --rx-mask=core mask      Run NIC rx on CPUs in core mask\n"
-		"  -w, --worker-mask=core mask  Run worker on CPUs in core mask\n"
-		"  -t, --tx-mask=core mask      Run NIC tx on CPUs in core mask\n"
-		"  -e  --sched-mask=core mask   Run scheduler on CPUs in core mask\n"
-		"  -c  --cq-depth=N             Worker CQ depth (default 16)\n"
-		"  -W  --work-cycles=N          Worker cycles (default 0)\n"
-		"  -P  --queue-priority         Enable scheduler queue prioritization\n"
-		"  -o, --ordered                Use ordered scheduling\n"
-		"  -p, --parallel               Use parallel scheduling\n"
-		"  -q, --quiet                  Minimize printed output\n"
-		"  -a, --use-atq                Use all type queues\n"
-		"  -m, --mempool-size=N         Dictate the mempool size\n"
-		"  -D, --dump                   Print detailed statistics before exit"
-		"\n";
-	fprintf(stderr, "%s", usage_str);
-	exit(1);
-}
-
-static void
-parse_app_args(int argc, char **argv)
-{
-	/* Parse cli options*/
-	int option_index;
-	int c;
-	opterr = 0;
-	uint64_t rx_lcore_mask = 0;
-	uint64_t tx_lcore_mask = 0;
-	uint64_t sched_lcore_mask = 0;
-	uint64_t worker_lcore_mask = 0;
-	int i;
-
-	for (;;) {
-		c = getopt_long(argc, argv, "r:t:e:c:w:n:f:s:m:paoPqDW:",
-				long_options, &option_index);
-		if (c == -1)
-			break;
-
-		int popcnt = 0;
-		switch (c) {
-		case 'n':
-			cdata.num_packets = (int64_t)atol(optarg);
-			if (cdata.num_packets == 0)
-				cdata.num_packets = INT64_MAX;
-			break;
-		case 'f':
-			cdata.num_fids = (unsigned int)atoi(optarg);
-			break;
-		case 's':
-			cdata.num_stages = (unsigned int)atoi(optarg);
-			break;
-		case 'c':
-			cdata.worker_cq_depth = (unsigned int)atoi(optarg);
-			break;
-		case 'W':
-			cdata.worker_cycles = (unsigned int)atoi(optarg);
-			break;
-		case 'P':
-			cdata.enable_queue_priorities = 1;
-			break;
-		case 'o':
-			cdata.queue_type = RTE_SCHED_TYPE_ORDERED;
-			break;
-		case 'p':
-			cdata.queue_type = RTE_SCHED_TYPE_PARALLEL;
-			break;
-		case 'a':
-			cdata.all_type_queues = 1;
-			break;
-		case 'q':
-			cdata.quiet = 1;
-			break;
-		case 'D':
-			cdata.dump_dev = 1;
-			break;
-		case 'w':
-			worker_lcore_mask = parse_coremask(optarg);
-			break;
-		case 'r':
-			rx_lcore_mask = parse_coremask(optarg);
-			popcnt = __builtin_popcountll(rx_lcore_mask);
-			fdata->rx_single = (popcnt == 1);
-			break;
-		case 't':
-			tx_lcore_mask = parse_coremask(optarg);
-			popcnt = __builtin_popcountll(tx_lcore_mask);
-			fdata->tx_single = (popcnt == 1);
-			break;
-		case 'e':
-			sched_lcore_mask = parse_coremask(optarg);
-			popcnt = __builtin_popcountll(sched_lcore_mask);
-			fdata->sched_single = (popcnt == 1);
-			break;
-		case 'm':
-			cdata.num_mbuf = (uint64_t)atol(optarg);
-			break;
-		default:
-			usage();
-		}
-	}
-
-	cdata.worker_lcore_mask = worker_lcore_mask;
-	cdata.sched_lcore_mask = sched_lcore_mask;
-	cdata.rx_lcore_mask = rx_lcore_mask;
-	cdata.tx_lcore_mask = tx_lcore_mask;
-
-	if (cdata.num_stages == 0 || cdata.num_stages > MAX_NUM_STAGES)
-		usage();
-
-	for (i = 0; i < MAX_NUM_CORE; i++) {
-		fdata->rx_core[i] = !!(rx_lcore_mask & (1UL << i));
-		fdata->tx_core[i] = !!(tx_lcore_mask & (1UL << i));
-		fdata->sched_core[i] = !!(sched_lcore_mask & (1UL << i));
-		fdata->worker_core[i] = !!(worker_lcore_mask & (1UL << i));
-
-		if (fdata->worker_core[i])
-			cdata.num_workers++;
-		if (core_in_use(i))
-			cdata.active_cores++;
-	}
-}
-
-/*
- * Initializes a given port using global settings and with the RX buffers
- * coming from the mbuf_pool passed as a parameter.
- */
-static inline int
-port_init(uint8_t port, struct rte_mempool *mbuf_pool)
-{
-	static const struct rte_eth_conf port_conf_default = {
-		.rxmode = {
-			.mq_mode = ETH_MQ_RX_RSS,
-			.max_rx_pkt_len = ETHER_MAX_LEN,
-			.ignore_offload_bitfield = 1,
-		},
-		.rx_adv_conf = {
-			.rss_conf = {
-				.rss_hf = ETH_RSS_IP |
-					  ETH_RSS_TCP |
-					  ETH_RSS_UDP,
-			}
-		}
-	};
-	const uint16_t rx_rings = 1, tx_rings = 1;
-	const uint16_t rx_ring_size = 512, tx_ring_size = 512;
-	struct rte_eth_conf port_conf = port_conf_default;
-	int retval;
-	uint16_t q;
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_txconf txconf;
-
-	if (!rte_eth_dev_is_valid_port(port))
-		return -1;
-
-	rte_eth_dev_info_get(port, &dev_info);
-	if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-		port_conf.txmode.offloads |=
-			DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-
-	/* Configure the Ethernet device. */
-	retval = rte_eth_dev_configure(port, rx_rings, tx_rings, &port_conf);
-	if (retval != 0)
-		return retval;
-
-	/* Allocate and set up 1 RX queue per Ethernet port. */
-	for (q = 0; q < rx_rings; q++) {
-		retval = rte_eth_rx_queue_setup(port, q, rx_ring_size,
-				rte_eth_dev_socket_id(port), NULL, mbuf_pool);
-		if (retval < 0)
-			return retval;
-	}
-
-	txconf = dev_info.default_txconf;
-	txconf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-	txconf.offloads = port_conf_default.txmode.offloads;
-	/* Allocate and set up 1 TX queue per Ethernet port. */
-	for (q = 0; q < tx_rings; q++) {
-		retval = rte_eth_tx_queue_setup(port, q, tx_ring_size,
-				rte_eth_dev_socket_id(port), &txconf);
-		if (retval < 0)
-			return retval;
-	}
-
-	/* Start the Ethernet port. */
-	retval = rte_eth_dev_start(port);
-	if (retval < 0)
-		return retval;
-
-	/* Display the port MAC address. */
-	struct ether_addr addr;
-	rte_eth_macaddr_get(port, &addr);
-	printf("Port %u MAC: %02" PRIx8 " %02" PRIx8 " %02" PRIx8
-			   " %02" PRIx8 " %02" PRIx8 " %02" PRIx8 "\n",
-			(unsigned int)port,
-			addr.addr_bytes[0], addr.addr_bytes[1],
-			addr.addr_bytes[2], addr.addr_bytes[3],
-			addr.addr_bytes[4], addr.addr_bytes[5]);
-
-	/* Enable RX in promiscuous mode for the Ethernet device. */
-	rte_eth_promiscuous_enable(port);
-
-	return 0;
-}
-
-static int
-init_ports(uint16_t num_ports)
-{
-	uint16_t portid, i;
-
-	if (!cdata.num_mbuf)
-		cdata.num_mbuf = 16384 * num_ports;
-
-	struct rte_mempool *mp = rte_pktmbuf_pool_create("packet_pool",
-			/* mbufs */ cdata.num_mbuf,
-			/* cache_size */ 512,
-			/* priv_size*/ 0,
-			/* data_room_size */ RTE_MBUF_DEFAULT_BUF_SIZE,
-			rte_socket_id());
-
-	RTE_ETH_FOREACH_DEV(portid)
-		if (port_init(portid, mp) != 0)
-			rte_exit(EXIT_FAILURE, "Cannot init port %"PRIu16 "\n",
-					portid);
-
-	RTE_ETH_FOREACH_DEV(i) {
-		void *userdata = (void *)(uintptr_t) i;
-		fdata->tx_buf[i] =
-			rte_malloc(NULL, RTE_ETH_TX_BUFFER_SIZE(32), 0);
-		if (fdata->tx_buf[i] == NULL)
-			rte_panic("Out of memory\n");
-		rte_eth_tx_buffer_init(fdata->tx_buf[i], 32);
-		rte_eth_tx_buffer_set_err_callback(fdata->tx_buf[i],
-						   eth_tx_buffer_retry,
-						   userdata);
-	}
-
-	return 0;
-}
-
-static void
-do_capability_setup(uint8_t eventdev_id)
-{
-	uint16_t i;
-	uint8_t mt_unsafe = 0;
-	uint8_t burst = 0;
-
-	RTE_ETH_FOREACH_DEV(i) {
-		struct rte_eth_dev_info dev_info;
-		memset(&dev_info, 0, sizeof(struct rte_eth_dev_info));
-
-		rte_eth_dev_info_get(i, &dev_info);
-		/* Check if it is safe ask worker to tx. */
-		mt_unsafe |= !(dev_info.tx_offload_capa &
-				DEV_TX_OFFLOAD_MT_LOCKFREE);
-	}
-
-	struct rte_event_dev_info eventdev_info;
-	memset(&eventdev_info, 0, sizeof(struct rte_event_dev_info));
-
-	rte_event_dev_info_get(eventdev_id, &eventdev_info);
-	burst = eventdev_info.event_dev_cap & RTE_EVENT_DEV_CAP_BURST_MODE ? 1 :
-		0;
-
-	if (mt_unsafe)
-		set_worker_generic_setup_data(&fdata->cap, burst);
-	else
-		set_worker_tx_setup_data(&fdata->cap, burst);
-}
-
-static void
-signal_handler(int signum)
-{
-	if (fdata->done)
-		rte_exit(1, "Exiting on signal %d\n", signum);
-	if (signum == SIGINT || signum == SIGTERM) {
-		printf("\n\nSignal %d received, preparing to exit...\n",
-				signum);
-		fdata->done = 1;
-	}
-	if (signum == SIGTSTP)
-		rte_event_dev_dump(0, stdout);
-}
-
-static inline uint64_t
-port_stat(int dev_id, int32_t p)
-{
-	char statname[64];
-	snprintf(statname, sizeof(statname), "port_%u_rx", p);
-	return rte_event_dev_xstats_by_name_get(dev_id, statname, NULL);
-}
-
-int
-main(int argc, char **argv)
-{
-	struct worker_data *worker_data;
-	unsigned int num_ports;
-	int lcore_id;
-	int err;
-
-	signal(SIGINT, signal_handler);
-	signal(SIGTERM, signal_handler);
-	signal(SIGTSTP, signal_handler);
-
-	err = rte_eal_init(argc, argv);
-	if (err < 0)
-		rte_panic("Invalid EAL arguments\n");
-
-	argc -= err;
-	argv += err;
-
-	fdata = rte_malloc(NULL, sizeof(struct fastpath_data), 0);
-	if (fdata == NULL)
-		rte_panic("Out of memory\n");
-
-	/* Parse cli options*/
-	parse_app_args(argc, argv);
-
-	num_ports = rte_eth_dev_count();
-	if (num_ports == 0)
-		rte_panic("No ethernet ports found\n");
-
-	const unsigned int cores_needed = cdata.active_cores;
-
-	if (!cdata.quiet) {
-		printf("  Config:\n");
-		printf("\tports: %u\n", num_ports);
-		printf("\tworkers: %u\n", cdata.num_workers);
-		printf("\tpackets: %"PRIi64"\n", cdata.num_packets);
-		printf("\tQueue-prio: %u\n", cdata.enable_queue_priorities);
-		if (cdata.queue_type == RTE_SCHED_TYPE_ORDERED)
-			printf("\tqid0 type: ordered\n");
-		if (cdata.queue_type == RTE_SCHED_TYPE_ATOMIC)
-			printf("\tqid0 type: atomic\n");
-		printf("\tCores available: %u\n", rte_lcore_count());
-		printf("\tCores used: %u\n", cores_needed);
-	}
-
-	if (rte_lcore_count() < cores_needed)
-		rte_panic("Too few cores (%d < %d)\n", rte_lcore_count(),
-				cores_needed);
-
-	const unsigned int ndevs = rte_event_dev_count();
-	if (ndevs == 0)
-		rte_panic("No dev_id devs found. Pasl in a --vdev eventdev.\n");
-	if (ndevs > 1)
-		fprintf(stderr, "Warning: More than one eventdev, using idx 0");
-
-
-	do_capability_setup(0);
-	fdata->cap.check_opt();
-
-	worker_data = rte_calloc(0, cdata.num_workers,
-			sizeof(worker_data[0]), 0);
-	if (worker_data == NULL)
-		rte_panic("rte_calloc failed\n");
-
-	int dev_id = fdata->cap.evdev_setup(&cons_data, worker_data);
-	if (dev_id < 0)
-		rte_exit(EXIT_FAILURE, "Error setting up eventdev\n");
-
-	init_ports(num_ports);
-	fdata->cap.adptr_setup(num_ports);
-
-	int worker_idx = 0;
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		if (lcore_id >= MAX_NUM_CORE)
-			break;
-
-		if (!fdata->rx_core[lcore_id] &&
-			!fdata->worker_core[lcore_id] &&
-			!fdata->tx_core[lcore_id] &&
-			!fdata->sched_core[lcore_id])
-			continue;
-
-		if (fdata->rx_core[lcore_id])
-			printf(
-				"[%s()] lcore %d executing NIC Rx\n",
-				__func__, lcore_id);
-
-		if (fdata->tx_core[lcore_id])
-			printf(
-				"[%s()] lcore %d executing NIC Tx, and using eventdev port %u\n",
-				__func__, lcore_id, cons_data.port_id);
-
-		if (fdata->sched_core[lcore_id])
-			printf("[%s()] lcore %d executing scheduler\n",
-					__func__, lcore_id);
-
-		if (fdata->worker_core[lcore_id])
-			printf(
-				"[%s()] lcore %d executing worker, using eventdev port %u\n",
-				__func__, lcore_id,
-				worker_data[worker_idx].port_id);
-
-		err = rte_eal_remote_launch(fdata->cap.worker,
-				&worker_data[worker_idx], lcore_id);
-		if (err) {
-			rte_panic("Failed to launch worker on core %d\n",
-					lcore_id);
-			continue;
-		}
-		if (fdata->worker_core[lcore_id])
-			worker_idx++;
-	}
-
-	lcore_id = rte_lcore_id();
-
-	if (core_in_use(lcore_id))
-		fdata->cap.worker(&worker_data[worker_idx++]);
-
-	rte_eal_mp_wait_lcore();
-
-	if (cdata.dump_dev)
-		rte_event_dev_dump(dev_id, stdout);
-
-	if (!cdata.quiet && (port_stat(dev_id, worker_data[0].port_id) !=
-			(uint64_t)-ENOTSUP)) {
-		printf("\nPort Workload distribution:\n");
-		uint32_t i;
-		uint64_t tot_pkts = 0;
-		uint64_t pkts_per_wkr[RTE_MAX_LCORE] = {0};
-		for (i = 0; i < cdata.num_workers; i++) {
-			pkts_per_wkr[i] =
-				port_stat(dev_id, worker_data[i].port_id);
-			tot_pkts += pkts_per_wkr[i];
-		}
-		for (i = 0; i < cdata.num_workers; i++) {
-			float pc = pkts_per_wkr[i]  * 100 /
-				((float)tot_pkts);
-			printf("worker %i :\t%.1f %% (%"PRIu64" pkts)\n",
-					i, pc, pkts_per_wkr[i]);
-		}
-
-	}
-
-	return 0;
-}
diff --git a/examples/eventdev_pipeline/meson.build b/examples/eventdev_pipeline/meson.build
deleted file mode 100644
index 0fc916b..0000000
--- a/examples/eventdev_pipeline/meson.build
+++ /dev/null
@@ -1,15 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-deps += 'eventdev'
-allow_experimental_apis = true
-sources = files(
-	'main.c',
-	'pipeline_worker_generic.c',
-	'pipeline_worker_tx.c'
-)
diff --git a/examples/eventdev_pipeline/pipeline_common.h b/examples/eventdev_pipeline/pipeline_common.h
deleted file mode 100644
index 9703396..0000000
--- a/examples/eventdev_pipeline/pipeline_common.h
+++ /dev/null
@@ -1,153 +0,0 @@
-/*
- * SPDX-License-Identifier: BSD-3-Clause
- * Copyright 2016 Intel Corporation.
- * Copyright 2017 Cavium, Inc.
- */
-
-#include <stdbool.h>
-
-#include <rte_eal.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-#include <rte_launch.h>
-#include <rte_malloc.h>
-#include <rte_random.h>
-#include <rte_cycles.h>
-#include <rte_ethdev.h>
-#include <rte_eventdev.h>
-#include <rte_event_eth_rx_adapter.h>
-#include <rte_service.h>
-#include <rte_service_component.h>
-
-#define MAX_NUM_STAGES 8
-#define BATCH_SIZE 16
-#define MAX_NUM_CORE 64
-
-struct cons_data {
-	uint8_t dev_id;
-	uint8_t port_id;
-	uint8_t release;
-} __rte_cache_aligned;
-
-struct worker_data {
-	uint8_t dev_id;
-	uint8_t port_id;
-} __rte_cache_aligned;
-
-typedef int (*worker_loop)(void *);
-typedef int (*consumer_loop)(void);
-typedef void (*schedule_loop)(unsigned int);
-typedef int (*eventdev_setup)(struct cons_data *, struct worker_data *);
-typedef void (*rx_adapter_setup)(uint16_t nb_ports);
-typedef void (*opt_check)(void);
-
-struct setup_data {
-	worker_loop worker;
-	consumer_loop consumer;
-	schedule_loop scheduler;
-	eventdev_setup evdev_setup;
-	rx_adapter_setup adptr_setup;
-	opt_check check_opt;
-};
-
-struct fastpath_data {
-	volatile int done;
-	uint32_t tx_lock;
-	uint32_t evdev_service_id;
-	uint32_t rxadptr_service_id;
-	bool rx_single;
-	bool tx_single;
-	bool sched_single;
-	unsigned int rx_core[MAX_NUM_CORE];
-	unsigned int tx_core[MAX_NUM_CORE];
-	unsigned int sched_core[MAX_NUM_CORE];
-	unsigned int worker_core[MAX_NUM_CORE];
-	struct rte_eth_dev_tx_buffer *tx_buf[RTE_MAX_ETHPORTS];
-	struct setup_data cap;
-} __rte_cache_aligned;
-
-struct config_data {
-	unsigned int active_cores;
-	unsigned int num_workers;
-	int64_t num_packets;
-	uint64_t num_mbuf;
-	unsigned int num_fids;
-	int queue_type;
-	int worker_cycles;
-	int enable_queue_priorities;
-	int quiet;
-	int dump_dev;
-	int dump_dev_signal;
-	int all_type_queues;
-	unsigned int num_stages;
-	unsigned int worker_cq_depth;
-	unsigned int rx_stride;
-	/* Use rx stride value to reduce congestion in entry queue when using
-	 * multiple eth ports by forming multiple event queue pipelines.
-	 */
-	int16_t next_qid[MAX_NUM_STAGES+2];
-	int16_t qid[MAX_NUM_STAGES];
-	uint8_t rx_adapter_id;
-	uint64_t worker_lcore_mask;
-	uint64_t rx_lcore_mask;
-	uint64_t tx_lcore_mask;
-	uint64_t sched_lcore_mask;
-};
-
-struct port_link {
-	uint8_t queue_id;
-	uint8_t priority;
-};
-
-struct cons_data cons_data;
-
-struct fastpath_data *fdata;
-struct config_data cdata;
-
-static __rte_always_inline void
-exchange_mac(struct rte_mbuf *m)
-{
-	struct ether_hdr *eth;
-	struct ether_addr addr;
-
-	/* change mac addresses on packet (to use mbuf data) */
-	eth = rte_pktmbuf_mtod(m, struct ether_hdr *);
-	ether_addr_copy(&eth->d_addr, &addr);
-	ether_addr_copy(&addr, &eth->d_addr);
-}
-
-static __rte_always_inline void
-work(void)
-{
-	/* do a number of cycles of work per packet */
-	volatile uint64_t start_tsc = rte_rdtsc();
-	while (rte_rdtsc() < start_tsc + cdata.worker_cycles)
-		rte_pause();
-}
-
-static __rte_always_inline void
-schedule_devices(unsigned int lcore_id)
-{
-	if (fdata->rx_core[lcore_id]) {
-		rte_service_run_iter_on_app_lcore(fdata->rxadptr_service_id,
-				!fdata->rx_single);
-	}
-
-	if (fdata->sched_core[lcore_id]) {
-		rte_service_run_iter_on_app_lcore(fdata->evdev_service_id,
-				!fdata->sched_single);
-		if (cdata.dump_dev_signal) {
-			rte_event_dev_dump(0, stdout);
-			cdata.dump_dev_signal = 0;
-		}
-	}
-
-	if (fdata->tx_core[lcore_id] && (fdata->tx_single ||
-			 rte_atomic32_cmpset(&(fdata->tx_lock), 0, 1))) {
-		fdata->cap.consumer();
-		rte_atomic32_clear((rte_atomic32_t *)&(fdata->tx_lock));
-	}
-}
-
-void set_worker_generic_setup_data(struct setup_data *caps, bool burst);
-void set_worker_tx_setup_data(struct setup_data *caps, bool burst);
diff --git a/examples/eventdev_pipeline/pipeline_worker_generic.c b/examples/eventdev_pipeline/pipeline_worker_generic.c
deleted file mode 100644
index 2215e9e..0000000
--- a/examples/eventdev_pipeline/pipeline_worker_generic.c
+++ /dev/null
@@ -1,568 +0,0 @@
-/*
- * SPDX-License-Identifier: BSD-3-Clause
- * Copyright 2016 Intel Corporation.
- * Copyright 2017 Cavium, Inc.
- */
-
-#include "pipeline_common.h"
-
-static __rte_always_inline int
-worker_generic(void *arg)
-{
-	struct rte_event ev;
-
-	struct worker_data *data = (struct worker_data *)arg;
-	uint8_t dev_id = data->dev_id;
-	uint8_t port_id = data->port_id;
-	size_t sent = 0, received = 0;
-	unsigned int lcore_id = rte_lcore_id();
-
-	while (!fdata->done) {
-
-		if (fdata->cap.scheduler)
-			fdata->cap.scheduler(lcore_id);
-
-		if (!fdata->worker_core[lcore_id]) {
-			rte_pause();
-			continue;
-		}
-
-		const uint16_t nb_rx = rte_event_dequeue_burst(dev_id, port_id,
-				&ev, 1, 0);
-
-		if (nb_rx == 0) {
-			rte_pause();
-			continue;
-		}
-		received++;
-
-		/* The first worker stage does classification */
-		if (ev.queue_id == cdata.qid[0])
-			ev.flow_id = ev.mbuf->hash.rss
-						% cdata.num_fids;
-
-		ev.queue_id = cdata.next_qid[ev.queue_id];
-		ev.op = RTE_EVENT_OP_FORWARD;
-		ev.sched_type = cdata.queue_type;
-
-		work();
-
-		while (rte_event_enqueue_burst(dev_id, port_id, &ev, 1) != 1)
-			rte_pause();
-		sent++;
-	}
-
-	if (!cdata.quiet)
-		printf("  worker %u thread done. RX=%zu TX=%zu\n",
-				rte_lcore_id(), received, sent);
-
-	return 0;
-}
-
-static int
-worker_generic_burst(void *arg)
-{
-	struct rte_event events[BATCH_SIZE];
-
-	struct worker_data *data = (struct worker_data *)arg;
-	uint8_t dev_id = data->dev_id;
-	uint8_t port_id = data->port_id;
-	size_t sent = 0, received = 0;
-	unsigned int lcore_id = rte_lcore_id();
-
-	while (!fdata->done) {
-		uint16_t i;
-
-		if (fdata->cap.scheduler)
-			fdata->cap.scheduler(lcore_id);
-
-		if (!fdata->worker_core[lcore_id]) {
-			rte_pause();
-			continue;
-		}
-
-		const uint16_t nb_rx = rte_event_dequeue_burst(dev_id, port_id,
-				events, RTE_DIM(events), 0);
-
-		if (nb_rx == 0) {
-			rte_pause();
-			continue;
-		}
-		received += nb_rx;
-
-		for (i = 0; i < nb_rx; i++) {
-
-			/* The first worker stage does classification */
-			if (events[i].queue_id == cdata.qid[0])
-				events[i].flow_id = events[i].mbuf->hash.rss
-							% cdata.num_fids;
-
-			events[i].queue_id = cdata.next_qid[events[i].queue_id];
-			events[i].op = RTE_EVENT_OP_FORWARD;
-			events[i].sched_type = cdata.queue_type;
-
-			work();
-		}
-		uint16_t nb_tx = rte_event_enqueue_burst(dev_id, port_id,
-				events, nb_rx);
-		while (nb_tx < nb_rx && !fdata->done)
-			nb_tx += rte_event_enqueue_burst(dev_id, port_id,
-							events + nb_tx,
-							nb_rx - nb_tx);
-		sent += nb_tx;
-	}
-
-	if (!cdata.quiet)
-		printf("  worker %u thread done. RX=%zu TX=%zu\n",
-				rte_lcore_id(), received, sent);
-
-	return 0;
-}
-
-static __rte_always_inline int
-consumer(void)
-{
-	const uint64_t freq_khz = rte_get_timer_hz() / 1000;
-	struct rte_event packet;
-
-	static uint64_t received;
-	static uint64_t last_pkts;
-	static uint64_t last_time;
-	static uint64_t start_time;
-	int i;
-	uint8_t dev_id = cons_data.dev_id;
-	uint8_t port_id = cons_data.port_id;
-
-	do {
-		uint16_t n = rte_event_dequeue_burst(dev_id, port_id,
-				&packet, 1, 0);
-
-		if (n == 0) {
-			RTE_ETH_FOREACH_DEV(i)
-				rte_eth_tx_buffer_flush(i, 0, fdata->tx_buf[i]);
-			return 0;
-		}
-		if (start_time == 0)
-			last_time = start_time = rte_get_timer_cycles();
-
-		received++;
-		uint8_t outport = packet.mbuf->port;
-
-		exchange_mac(packet.mbuf);
-		rte_eth_tx_buffer(outport, 0, fdata->tx_buf[outport],
-				packet.mbuf);
-
-		if (cons_data.release)
-			rte_event_enqueue_burst(dev_id, port_id,
-								&packet, n);
-
-		/* Print out mpps every 1<22 packets */
-		if (!cdata.quiet && received >= last_pkts + (1<<22)) {
-			const uint64_t now = rte_get_timer_cycles();
-			const uint64_t total_ms = (now - start_time) / freq_khz;
-			const uint64_t delta_ms = (now - last_time) / freq_khz;
-			uint64_t delta_pkts = received - last_pkts;
-
-			printf("# %s RX=%"PRIu64", time %"PRIu64 "ms, "
-					"avg %.3f mpps [current %.3f mpps]\n",
-					__func__,
-					received,
-					total_ms,
-					received / (total_ms * 1000.0),
-					delta_pkts / (delta_ms * 1000.0));
-			last_pkts = received;
-			last_time = now;
-		}
-
-		cdata.num_packets--;
-		if (cdata.num_packets <= 0)
-			fdata->done = 1;
-	/* Be stuck in this loop if single. */
-	} while (!fdata->done && fdata->tx_single);
-
-	return 0;
-}
-
-static __rte_always_inline int
-consumer_burst(void)
-{
-	const uint64_t freq_khz = rte_get_timer_hz() / 1000;
-	struct rte_event packets[BATCH_SIZE];
-
-	static uint64_t received;
-	static uint64_t last_pkts;
-	static uint64_t last_time;
-	static uint64_t start_time;
-	unsigned int i, j;
-	uint8_t dev_id = cons_data.dev_id;
-	uint8_t port_id = cons_data.port_id;
-
-	do {
-		uint16_t n = rte_event_dequeue_burst(dev_id, port_id,
-				packets, RTE_DIM(packets), 0);
-
-		if (n == 0) {
-			RTE_ETH_FOREACH_DEV(j)
-				rte_eth_tx_buffer_flush(j, 0, fdata->tx_buf[j]);
-			return 0;
-		}
-		if (start_time == 0)
-			last_time = start_time = rte_get_timer_cycles();
-
-		received += n;
-		for (i = 0; i < n; i++) {
-			uint8_t outport = packets[i].mbuf->port;
-
-			exchange_mac(packets[i].mbuf);
-			rte_eth_tx_buffer(outport, 0, fdata->tx_buf[outport],
-					packets[i].mbuf);
-
-			packets[i].op = RTE_EVENT_OP_RELEASE;
-		}
-
-		if (cons_data.release) {
-			uint16_t nb_tx;
-
-			nb_tx = rte_event_enqueue_burst(dev_id, port_id,
-								packets, n);
-			while (nb_tx < n)
-				nb_tx += rte_event_enqueue_burst(dev_id,
-						port_id, packets + nb_tx,
-						n - nb_tx);
-		}
-
-		/* Print out mpps every 1<22 packets */
-		if (!cdata.quiet && received >= last_pkts + (1<<22)) {
-			const uint64_t now = rte_get_timer_cycles();
-			const uint64_t total_ms = (now - start_time) / freq_khz;
-			const uint64_t delta_ms = (now - last_time) / freq_khz;
-			uint64_t delta_pkts = received - last_pkts;
-
-			printf("# consumer RX=%"PRIu64", time %"PRIu64 "ms, "
-					"avg %.3f mpps [current %.3f mpps]\n",
-					received,
-					total_ms,
-					received / (total_ms * 1000.0),
-					delta_pkts / (delta_ms * 1000.0));
-			last_pkts = received;
-			last_time = now;
-		}
-
-		cdata.num_packets -= n;
-		if (cdata.num_packets <= 0)
-			fdata->done = 1;
-	/* Be stuck in this loop if single. */
-	} while (!fdata->done && fdata->tx_single);
-
-	return 0;
-}
-
-static int
-setup_eventdev_generic(struct cons_data *cons_data,
-		struct worker_data *worker_data)
-{
-	const uint8_t dev_id = 0;
-	/* +1 stages is for a SINGLE_LINK TX stage */
-	const uint8_t nb_queues = cdata.num_stages + 1;
-	/* + 1 is one port for consumer */
-	const uint8_t nb_ports = cdata.num_workers + 1;
-	struct rte_event_dev_config config = {
-			.nb_event_queues = nb_queues,
-			.nb_event_ports = nb_ports,
-			.nb_events_limit  = 4096,
-			.nb_event_queue_flows = 1024,
-			.nb_event_port_dequeue_depth = 128,
-			.nb_event_port_enqueue_depth = 128,
-	};
-	struct rte_event_port_conf wkr_p_conf = {
-			.dequeue_depth = cdata.worker_cq_depth,
-			.enqueue_depth = 64,
-			.new_event_threshold = 4096,
-	};
-	struct rte_event_queue_conf wkr_q_conf = {
-			.schedule_type = cdata.queue_type,
-			.priority = RTE_EVENT_DEV_PRIORITY_NORMAL,
-			.nb_atomic_flows = 1024,
-		.nb_atomic_order_sequences = 1024,
-	};
-	struct rte_event_port_conf tx_p_conf = {
-			.dequeue_depth = 128,
-			.enqueue_depth = 128,
-			.new_event_threshold = 4096,
-	};
-	struct rte_event_queue_conf tx_q_conf = {
-			.priority = RTE_EVENT_DEV_PRIORITY_HIGHEST,
-			.event_queue_cfg = RTE_EVENT_QUEUE_CFG_SINGLE_LINK,
-	};
-
-	struct port_link worker_queues[MAX_NUM_STAGES];
-	uint8_t disable_implicit_release;
-	struct port_link tx_queue;
-	unsigned int i;
-
-	int ret, ndev = rte_event_dev_count();
-	if (ndev < 1) {
-		printf("%d: No Eventdev Devices Found\n", __LINE__);
-		return -1;
-	}
-
-	struct rte_event_dev_info dev_info;
-	ret = rte_event_dev_info_get(dev_id, &dev_info);
-	printf("\tEventdev %d: %s\n", dev_id, dev_info.driver_name);
-
-	disable_implicit_release = (dev_info.event_dev_cap &
-			RTE_EVENT_DEV_CAP_IMPLICIT_RELEASE_DISABLE);
-
-	wkr_p_conf.disable_implicit_release = disable_implicit_release;
-	tx_p_conf.disable_implicit_release = disable_implicit_release;
-
-	if (dev_info.max_event_port_dequeue_depth <
-			config.nb_event_port_dequeue_depth)
-		config.nb_event_port_dequeue_depth =
-				dev_info.max_event_port_dequeue_depth;
-	if (dev_info.max_event_port_enqueue_depth <
-			config.nb_event_port_enqueue_depth)
-		config.nb_event_port_enqueue_depth =
-				dev_info.max_event_port_enqueue_depth;
-
-	ret = rte_event_dev_configure(dev_id, &config);
-	if (ret < 0) {
-		printf("%d: Error configuring device\n", __LINE__);
-		return -1;
-	}
-
-	/* Q creation - one load balanced per pipeline stage*/
-	printf("  Stages:\n");
-	for (i = 0; i < cdata.num_stages; i++) {
-		if (rte_event_queue_setup(dev_id, i, &wkr_q_conf) < 0) {
-			printf("%d: error creating qid %d\n", __LINE__, i);
-			return -1;
-		}
-		cdata.qid[i] = i;
-		cdata.next_qid[i] = i+1;
-		worker_queues[i].queue_id = i;
-		if (cdata.enable_queue_priorities) {
-			/* calculate priority stepping for each stage, leaving
-			 * headroom of 1 for the SINGLE_LINK TX below
-			 */
-			const uint32_t prio_delta =
-				(RTE_EVENT_DEV_PRIORITY_LOWEST-1) /  nb_queues;
-
-			/* higher priority for queues closer to tx */
-			wkr_q_conf.priority =
-				RTE_EVENT_DEV_PRIORITY_LOWEST - prio_delta * i;
-		}
-
-		const char *type_str = "Atomic";
-		switch (wkr_q_conf.schedule_type) {
-		case RTE_SCHED_TYPE_ORDERED:
-			type_str = "Ordered";
-			break;
-		case RTE_SCHED_TYPE_PARALLEL:
-			type_str = "Parallel";
-			break;
-		}
-		printf("\tStage %d, Type %s\tPriority = %d\n", i, type_str,
-				wkr_q_conf.priority);
-	}
-	printf("\n");
-
-	/* final queue for sending to TX core */
-	if (rte_event_queue_setup(dev_id, i, &tx_q_conf) < 0) {
-		printf("%d: error creating qid %d\n", __LINE__, i);
-		return -1;
-	}
-	tx_queue.queue_id = i;
-	tx_queue.priority = RTE_EVENT_DEV_PRIORITY_HIGHEST;
-
-	if (wkr_p_conf.dequeue_depth > config.nb_event_port_dequeue_depth)
-		wkr_p_conf.dequeue_depth = config.nb_event_port_dequeue_depth;
-	if (wkr_p_conf.enqueue_depth > config.nb_event_port_enqueue_depth)
-		wkr_p_conf.enqueue_depth = config.nb_event_port_enqueue_depth;
-
-	/* set up one port per worker, linking to all stage queues */
-	for (i = 0; i < cdata.num_workers; i++) {
-		struct worker_data *w = &worker_data[i];
-		w->dev_id = dev_id;
-		if (rte_event_port_setup(dev_id, i, &wkr_p_conf) < 0) {
-			printf("Error setting up port %d\n", i);
-			return -1;
-		}
-
-		uint32_t s;
-		for (s = 0; s < cdata.num_stages; s++) {
-			if (rte_event_port_link(dev_id, i,
-						&worker_queues[s].queue_id,
-						&worker_queues[s].priority,
-						1) != 1) {
-				printf("%d: error creating link for port %d\n",
-						__LINE__, i);
-				return -1;
-			}
-		}
-		w->port_id = i;
-	}
-
-	if (tx_p_conf.dequeue_depth > config.nb_event_port_dequeue_depth)
-		tx_p_conf.dequeue_depth = config.nb_event_port_dequeue_depth;
-	if (tx_p_conf.enqueue_depth > config.nb_event_port_enqueue_depth)
-		tx_p_conf.enqueue_depth = config.nb_event_port_enqueue_depth;
-
-	/* port for consumer, linked to TX queue */
-	if (rte_event_port_setup(dev_id, i, &tx_p_conf) < 0) {
-		printf("Error setting up port %d\n", i);
-		return -1;
-	}
-	if (rte_event_port_link(dev_id, i, &tx_queue.queue_id,
-				&tx_queue.priority, 1) != 1) {
-		printf("%d: error creating link for port %d\n",
-				__LINE__, i);
-		return -1;
-	}
-	*cons_data = (struct cons_data){.dev_id = dev_id,
-					.port_id = i,
-					.release = disable_implicit_release };
-
-	ret = rte_event_dev_service_id_get(dev_id,
-				&fdata->evdev_service_id);
-	if (ret != -ESRCH && ret != 0) {
-		printf("Error getting the service ID for sw eventdev\n");
-		return -1;
-	}
-	rte_service_runstate_set(fdata->evdev_service_id, 1);
-	rte_service_set_runstate_mapped_check(fdata->evdev_service_id, 0);
-	if (rte_event_dev_start(dev_id) < 0) {
-		printf("Error starting eventdev\n");
-		return -1;
-	}
-
-	return dev_id;
-}
-
-static void
-init_rx_adapter(uint16_t nb_ports)
-{
-	int i;
-	int ret;
-	uint8_t evdev_id = 0;
-	struct rte_event_dev_info dev_info;
-
-	ret = rte_event_dev_info_get(evdev_id, &dev_info);
-
-	struct rte_event_port_conf rx_p_conf = {
-		.dequeue_depth = 8,
-		.enqueue_depth = 8,
-		.new_event_threshold = 1200,
-	};
-
-	if (rx_p_conf.dequeue_depth > dev_info.max_event_port_dequeue_depth)
-		rx_p_conf.dequeue_depth = dev_info.max_event_port_dequeue_depth;
-	if (rx_p_conf.enqueue_depth > dev_info.max_event_port_enqueue_depth)
-		rx_p_conf.enqueue_depth = dev_info.max_event_port_enqueue_depth;
-
-	/* Create one adapter for all the ethernet ports. */
-	ret = rte_event_eth_rx_adapter_create(cdata.rx_adapter_id, evdev_id,
-			&rx_p_conf);
-	if (ret)
-		rte_exit(EXIT_FAILURE, "failed to create rx adapter[%d]",
-				cdata.rx_adapter_id);
-
-	struct rte_event_eth_rx_adapter_queue_conf queue_conf;
-	memset(&queue_conf, 0, sizeof(queue_conf));
-	queue_conf.ev.sched_type = cdata.queue_type;
-	queue_conf.ev.queue_id = cdata.qid[0];
-
-	for (i = 0; i < nb_ports; i++) {
-		uint32_t cap;
-
-		ret = rte_event_eth_rx_adapter_caps_get(evdev_id, i, &cap);
-		if (ret)
-			rte_exit(EXIT_FAILURE,
-					"failed to get event rx adapter "
-					"capabilities");
-
-		ret = rte_event_eth_rx_adapter_queue_add(cdata.rx_adapter_id, i,
-				-1, &queue_conf);
-		if (ret)
-			rte_exit(EXIT_FAILURE,
-					"Failed to add queues to Rx adapter");
-	}
-
-	ret = rte_event_eth_rx_adapter_service_id_get(cdata.rx_adapter_id,
-				&fdata->rxadptr_service_id);
-	if (ret != -ESRCH && ret != 0) {
-		rte_exit(EXIT_FAILURE,
-			"Error getting the service ID for sw eventdev\n");
-	}
-	rte_service_runstate_set(fdata->rxadptr_service_id, 1);
-	rte_service_set_runstate_mapped_check(fdata->rxadptr_service_id, 0);
-
-	ret = rte_event_eth_rx_adapter_start(cdata.rx_adapter_id);
-	if (ret)
-		rte_exit(EXIT_FAILURE, "Rx adapter[%d] start failed",
-				cdata.rx_adapter_id);
-}
-
-static void
-generic_opt_check(void)
-{
-	int i;
-	int ret;
-	uint32_t cap = 0;
-	uint8_t rx_needed = 0;
-	struct rte_event_dev_info eventdev_info;
-
-	memset(&eventdev_info, 0, sizeof(struct rte_event_dev_info));
-	rte_event_dev_info_get(0, &eventdev_info);
-
-	if (cdata.all_type_queues && !(eventdev_info.event_dev_cap &
-				RTE_EVENT_DEV_CAP_QUEUE_ALL_TYPES))
-		rte_exit(EXIT_FAILURE,
-				"Event dev doesn't support all type queues\n");
-
-	RTE_ETH_FOREACH_DEV(i) {
-		ret = rte_event_eth_rx_adapter_caps_get(0, i, &cap);
-		if (ret)
-			rte_exit(EXIT_FAILURE,
-				"failed to get event rx adapter capabilities");
-		rx_needed |=
-			!(cap & RTE_EVENT_ETH_RX_ADAPTER_CAP_INTERNAL_PORT);
-	}
-
-	if (cdata.worker_lcore_mask == 0 ||
-			(rx_needed && cdata.rx_lcore_mask == 0) ||
-			cdata.tx_lcore_mask == 0 || (cdata.sched_lcore_mask == 0
-				&& !(eventdev_info.event_dev_cap &
-					RTE_EVENT_DEV_CAP_DISTRIBUTED_SCHED))) {
-		printf("Core part of pipeline was not assigned any cores. "
-			"This will stall the pipeline, please check core masks "
-			"(use -h for details on setting core masks):\n"
-			"\trx: %"PRIu64"\n\ttx: %"PRIu64"\n\tsched: %"PRIu64
-			"\n\tworkers: %"PRIu64"\n",
-			cdata.rx_lcore_mask, cdata.tx_lcore_mask,
-			cdata.sched_lcore_mask,
-			cdata.worker_lcore_mask);
-		rte_exit(-1, "Fix core masks\n");
-	}
-
-	if (eventdev_info.event_dev_cap & RTE_EVENT_DEV_CAP_DISTRIBUTED_SCHED)
-		memset(fdata->sched_core, 0,
-				sizeof(unsigned int) * MAX_NUM_CORE);
-}
-
-void
-set_worker_generic_setup_data(struct setup_data *caps, bool burst)
-{
-	if (burst) {
-		caps->consumer = consumer_burst;
-		caps->worker = worker_generic_burst;
-	} else {
-		caps->consumer = consumer;
-		caps->worker = worker_generic;
-	}
-
-	caps->adptr_setup = init_rx_adapter;
-	caps->scheduler = schedule_devices;
-	caps->evdev_setup = setup_eventdev_generic;
-	caps->check_opt = generic_opt_check;
-}
diff --git a/examples/eventdev_pipeline/pipeline_worker_tx.c b/examples/eventdev_pipeline/pipeline_worker_tx.c
deleted file mode 100644
index fc98128..0000000
--- a/examples/eventdev_pipeline/pipeline_worker_tx.c
+++ /dev/null
@@ -1,838 +0,0 @@
-/*
- * SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- * Copyright 2017 Cavium, Inc.
- */
-
-#include "pipeline_common.h"
-
-static __rte_always_inline void
-worker_fwd_event(struct rte_event *ev, uint8_t sched)
-{
-	ev->event_type = RTE_EVENT_TYPE_CPU;
-	ev->op = RTE_EVENT_OP_FORWARD;
-	ev->sched_type = sched;
-}
-
-static __rte_always_inline void
-worker_event_enqueue(const uint8_t dev, const uint8_t port,
-		struct rte_event *ev)
-{
-	while (rte_event_enqueue_burst(dev, port, ev, 1) != 1)
-		rte_pause();
-}
-
-static __rte_always_inline void
-worker_event_enqueue_burst(const uint8_t dev, const uint8_t port,
-		struct rte_event *ev, const uint16_t nb_rx)
-{
-	uint16_t enq;
-
-	enq = rte_event_enqueue_burst(dev, port, ev, nb_rx);
-	while (enq < nb_rx) {
-		enq += rte_event_enqueue_burst(dev, port,
-						ev + enq, nb_rx - enq);
-	}
-}
-
-static __rte_always_inline void
-worker_tx_pkt(struct rte_mbuf *mbuf)
-{
-	exchange_mac(mbuf);
-	while (rte_eth_tx_burst(mbuf->port, 0, &mbuf, 1) != 1)
-		rte_pause();
-}
-
-/* Single stage pipeline workers */
-
-static int
-worker_do_tx_single(void *arg)
-{
-	struct worker_data *data = (struct worker_data *)arg;
-	const uint8_t dev = data->dev_id;
-	const uint8_t port = data->port_id;
-	size_t fwd = 0, received = 0, tx = 0;
-	struct rte_event ev;
-
-	while (!fdata->done) {
-
-		if (!rte_event_dequeue_burst(dev, port, &ev, 1, 0)) {
-			rte_pause();
-			continue;
-		}
-
-		received++;
-
-		if (ev.sched_type == RTE_SCHED_TYPE_ATOMIC) {
-			worker_tx_pkt(ev.mbuf);
-			tx++;
-			continue;
-		}
-		work();
-		ev.queue_id++;
-		worker_fwd_event(&ev, RTE_SCHED_TYPE_ATOMIC);
-		worker_event_enqueue(dev, port, &ev);
-		fwd++;
-	}
-
-	if (!cdata.quiet)
-		printf("  worker %u thread done. RX=%zu FWD=%zu TX=%zu\n",
-				rte_lcore_id(), received, fwd, tx);
-	return 0;
-}
-
-static int
-worker_do_tx_single_atq(void *arg)
-{
-	struct worker_data *data = (struct worker_data *)arg;
-	const uint8_t dev = data->dev_id;
-	const uint8_t port = data->port_id;
-	size_t fwd = 0, received = 0, tx = 0;
-	struct rte_event ev;
-
-	while (!fdata->done) {
-
-		if (!rte_event_dequeue_burst(dev, port, &ev, 1, 0)) {
-			rte_pause();
-			continue;
-		}
-
-		received++;
-
-		if (ev.sched_type == RTE_SCHED_TYPE_ATOMIC) {
-			worker_tx_pkt(ev.mbuf);
-			tx++;
-			continue;
-		}
-		work();
-		worker_fwd_event(&ev, RTE_SCHED_TYPE_ATOMIC);
-		worker_event_enqueue(dev, port, &ev);
-		fwd++;
-	}
-
-	if (!cdata.quiet)
-		printf("  worker %u thread done. RX=%zu FWD=%zu TX=%zu\n",
-				rte_lcore_id(), received, fwd, tx);
-	return 0;
-}
-
-static int
-worker_do_tx_single_burst(void *arg)
-{
-	struct rte_event ev[BATCH_SIZE + 1];
-
-	struct worker_data *data = (struct worker_data *)arg;
-	const uint8_t dev = data->dev_id;
-	const uint8_t port = data->port_id;
-	size_t fwd = 0, received = 0, tx = 0;
-
-	while (!fdata->done) {
-		uint16_t i;
-		uint16_t nb_rx = rte_event_dequeue_burst(dev, port, ev,
-				BATCH_SIZE, 0);
-
-		if (!nb_rx) {
-			rte_pause();
-			continue;
-		}
-		received += nb_rx;
-
-		for (i = 0; i < nb_rx; i++) {
-			rte_prefetch0(ev[i + 1].mbuf);
-			if (ev[i].sched_type == RTE_SCHED_TYPE_ATOMIC) {
-
-				worker_tx_pkt(ev[i].mbuf);
-				ev[i].op = RTE_EVENT_OP_RELEASE;
-				tx++;
-
-			} else {
-				ev[i].queue_id++;
-				worker_fwd_event(&ev[i], RTE_SCHED_TYPE_ATOMIC);
-			}
-			work();
-		}
-
-		worker_event_enqueue_burst(dev, port, ev, nb_rx);
-		fwd += nb_rx;
-	}
-
-	if (!cdata.quiet)
-		printf("  worker %u thread done. RX=%zu FWD=%zu TX=%zu\n",
-				rte_lcore_id(), received, fwd, tx);
-	return 0;
-}
-
-static int
-worker_do_tx_single_burst_atq(void *arg)
-{
-	struct rte_event ev[BATCH_SIZE + 1];
-
-	struct worker_data *data = (struct worker_data *)arg;
-	const uint8_t dev = data->dev_id;
-	const uint8_t port = data->port_id;
-	size_t fwd = 0, received = 0, tx = 0;
-
-	while (!fdata->done) {
-		uint16_t i;
-		uint16_t nb_rx = rte_event_dequeue_burst(dev, port, ev,
-				BATCH_SIZE, 0);
-
-		if (!nb_rx) {
-			rte_pause();
-			continue;
-		}
-
-		received += nb_rx;
-
-		for (i = 0; i < nb_rx; i++) {
-			rte_prefetch0(ev[i + 1].mbuf);
-			if (ev[i].sched_type == RTE_SCHED_TYPE_ATOMIC) {
-
-				worker_tx_pkt(ev[i].mbuf);
-				ev[i].op = RTE_EVENT_OP_RELEASE;
-				tx++;
-			} else
-				worker_fwd_event(&ev[i], RTE_SCHED_TYPE_ATOMIC);
-			work();
-		}
-
-		worker_event_enqueue_burst(dev, port, ev, nb_rx);
-		fwd += nb_rx;
-	}
-
-	if (!cdata.quiet)
-		printf("  worker %u thread done. RX=%zu FWD=%zu TX=%zu\n",
-				rte_lcore_id(), received, fwd, tx);
-	return 0;
-}
-
-/* Multi stage Pipeline Workers */
-
-static int
-worker_do_tx(void *arg)
-{
-	struct rte_event ev;
-
-	struct worker_data *data = (struct worker_data *)arg;
-	const uint8_t dev = data->dev_id;
-	const uint8_t port = data->port_id;
-	const uint8_t lst_qid = cdata.num_stages - 1;
-	size_t fwd = 0, received = 0, tx = 0;
-
-
-	while (!fdata->done) {
-
-		if (!rte_event_dequeue_burst(dev, port, &ev, 1, 0)) {
-			rte_pause();
-			continue;
-		}
-
-		received++;
-		const uint8_t cq_id = ev.queue_id % cdata.num_stages;
-
-		if (cq_id >= lst_qid) {
-			if (ev.sched_type == RTE_SCHED_TYPE_ATOMIC) {
-				worker_tx_pkt(ev.mbuf);
-				tx++;
-				continue;
-			}
-
-			worker_fwd_event(&ev, RTE_SCHED_TYPE_ATOMIC);
-			ev.queue_id = (cq_id == lst_qid) ?
-				cdata.next_qid[ev.queue_id] : ev.queue_id;
-		} else {
-			ev.queue_id = cdata.next_qid[ev.queue_id];
-			worker_fwd_event(&ev, cdata.queue_type);
-		}
-		work();
-
-		worker_event_enqueue(dev, port, &ev);
-		fwd++;
-	}
-
-	if (!cdata.quiet)
-		printf("  worker %u thread done. RX=%zu FWD=%zu TX=%zu\n",
-				rte_lcore_id(), received, fwd, tx);
-
-	return 0;
-}
-
-static int
-worker_do_tx_atq(void *arg)
-{
-	struct rte_event ev;
-
-	struct worker_data *data = (struct worker_data *)arg;
-	const uint8_t dev = data->dev_id;
-	const uint8_t port = data->port_id;
-	const uint8_t lst_qid = cdata.num_stages - 1;
-	size_t fwd = 0, received = 0, tx = 0;
-
-	while (!fdata->done) {
-
-		if (!rte_event_dequeue_burst(dev, port, &ev, 1, 0)) {
-			rte_pause();
-			continue;
-		}
-
-		received++;
-		const uint8_t cq_id = ev.sub_event_type % cdata.num_stages;
-
-		if (cq_id == lst_qid) {
-			if (ev.sched_type == RTE_SCHED_TYPE_ATOMIC) {
-				worker_tx_pkt(ev.mbuf);
-				tx++;
-				continue;
-			}
-
-			worker_fwd_event(&ev, RTE_SCHED_TYPE_ATOMIC);
-		} else {
-			ev.sub_event_type++;
-			worker_fwd_event(&ev, cdata.queue_type);
-		}
-		work();
-
-		worker_event_enqueue(dev, port, &ev);
-		fwd++;
-	}
-
-	if (!cdata.quiet)
-		printf("  worker %u thread done. RX=%zu FWD=%zu TX=%zu\n",
-				rte_lcore_id(), received, fwd, tx);
-
-	return 0;
-}
-
-static int
-worker_do_tx_burst(void *arg)
-{
-	struct rte_event ev[BATCH_SIZE];
-
-	struct worker_data *data = (struct worker_data *)arg;
-	uint8_t dev = data->dev_id;
-	uint8_t port = data->port_id;
-	uint8_t lst_qid = cdata.num_stages - 1;
-	size_t fwd = 0, received = 0, tx = 0;
-
-	while (!fdata->done) {
-		uint16_t i;
-		const uint16_t nb_rx = rte_event_dequeue_burst(dev, port,
-				ev, BATCH_SIZE, 0);
-
-		if (nb_rx == 0) {
-			rte_pause();
-			continue;
-		}
-		received += nb_rx;
-
-		for (i = 0; i < nb_rx; i++) {
-			const uint8_t cq_id = ev[i].queue_id % cdata.num_stages;
-
-			if (cq_id >= lst_qid) {
-				if (ev[i].sched_type == RTE_SCHED_TYPE_ATOMIC) {
-					worker_tx_pkt(ev[i].mbuf);
-					tx++;
-					ev[i].op = RTE_EVENT_OP_RELEASE;
-					continue;
-				}
-				ev[i].queue_id = (cq_id == lst_qid) ?
-					cdata.next_qid[ev[i].queue_id] :
-					ev[i].queue_id;
-
-				worker_fwd_event(&ev[i], RTE_SCHED_TYPE_ATOMIC);
-			} else {
-				ev[i].queue_id = cdata.next_qid[ev[i].queue_id];
-				worker_fwd_event(&ev[i], cdata.queue_type);
-			}
-			work();
-		}
-		worker_event_enqueue_burst(dev, port, ev, nb_rx);
-
-		fwd += nb_rx;
-	}
-
-	if (!cdata.quiet)
-		printf("  worker %u thread done. RX=%zu FWD=%zu TX=%zu\n",
-				rte_lcore_id(), received, fwd, tx);
-
-	return 0;
-}
-
-static int
-worker_do_tx_burst_atq(void *arg)
-{
-	struct rte_event ev[BATCH_SIZE];
-
-	struct worker_data *data = (struct worker_data *)arg;
-	uint8_t dev = data->dev_id;
-	uint8_t port = data->port_id;
-	uint8_t lst_qid = cdata.num_stages - 1;
-	size_t fwd = 0, received = 0, tx = 0;
-
-	while (!fdata->done) {
-		uint16_t i;
-
-		const uint16_t nb_rx = rte_event_dequeue_burst(dev, port,
-				ev, BATCH_SIZE, 0);
-
-		if (nb_rx == 0) {
-			rte_pause();
-			continue;
-		}
-		received += nb_rx;
-
-		for (i = 0; i < nb_rx; i++) {
-			const uint8_t cq_id = ev[i].sub_event_type %
-				cdata.num_stages;
-
-			if (cq_id == lst_qid) {
-				if (ev[i].sched_type == RTE_SCHED_TYPE_ATOMIC) {
-					worker_tx_pkt(ev[i].mbuf);
-					tx++;
-					ev[i].op = RTE_EVENT_OP_RELEASE;
-					continue;
-				}
-
-				worker_fwd_event(&ev[i], RTE_SCHED_TYPE_ATOMIC);
-			} else {
-				ev[i].sub_event_type++;
-				worker_fwd_event(&ev[i], cdata.queue_type);
-			}
-			work();
-		}
-
-		worker_event_enqueue_burst(dev, port, ev, nb_rx);
-		fwd += nb_rx;
-	}
-
-	if (!cdata.quiet)
-		printf("  worker %u thread done. RX=%zu FWD=%zu TX=%zu\n",
-				rte_lcore_id(), received, fwd, tx);
-
-	return 0;
-}
-
-static int
-setup_eventdev_worker_tx(struct cons_data *cons_data,
-		struct worker_data *worker_data)
-{
-	RTE_SET_USED(cons_data);
-	uint8_t i;
-	const uint8_t atq = cdata.all_type_queues ? 1 : 0;
-	const uint8_t dev_id = 0;
-	const uint8_t nb_ports = cdata.num_workers;
-	uint8_t nb_slots = 0;
-	uint8_t nb_queues = rte_eth_dev_count();
-
-	/*
-	 * In case where all type queues are not enabled, use queues equal to
-	 * number of stages * eth_dev_count and one extra queue per pipeline
-	 * for Tx.
-	 */
-	if (!atq) {
-		nb_queues *= cdata.num_stages;
-		nb_queues += rte_eth_dev_count();
-	}
-
-	struct rte_event_dev_config config = {
-			.nb_event_queues = nb_queues,
-			.nb_event_ports = nb_ports,
-			.nb_events_limit  = 4096,
-			.nb_event_queue_flows = 1024,
-			.nb_event_port_dequeue_depth = 128,
-			.nb_event_port_enqueue_depth = 128,
-	};
-	struct rte_event_port_conf wkr_p_conf = {
-			.dequeue_depth = cdata.worker_cq_depth,
-			.enqueue_depth = 64,
-			.new_event_threshold = 4096,
-	};
-	struct rte_event_queue_conf wkr_q_conf = {
-			.schedule_type = cdata.queue_type,
-			.priority = RTE_EVENT_DEV_PRIORITY_NORMAL,
-			.nb_atomic_flows = 1024,
-			.nb_atomic_order_sequences = 1024,
-	};
-
-	int ret, ndev = rte_event_dev_count();
-
-	if (ndev < 1) {
-		printf("%d: No Eventdev Devices Found\n", __LINE__);
-		return -1;
-	}
-
-
-	struct rte_event_dev_info dev_info;
-	ret = rte_event_dev_info_get(dev_id, &dev_info);
-	printf("\tEventdev %d: %s\n", dev_id, dev_info.driver_name);
-
-	if (dev_info.max_event_port_dequeue_depth <
-			config.nb_event_port_dequeue_depth)
-		config.nb_event_port_dequeue_depth =
-				dev_info.max_event_port_dequeue_depth;
-	if (dev_info.max_event_port_enqueue_depth <
-			config.nb_event_port_enqueue_depth)
-		config.nb_event_port_enqueue_depth =
-				dev_info.max_event_port_enqueue_depth;
-
-	ret = rte_event_dev_configure(dev_id, &config);
-	if (ret < 0) {
-		printf("%d: Error configuring device\n", __LINE__);
-		return -1;
-	}
-
-	printf("  Stages:\n");
-	for (i = 0; i < nb_queues; i++) {
-
-		if (atq) {
-
-			nb_slots = cdata.num_stages;
-			wkr_q_conf.event_queue_cfg =
-				RTE_EVENT_QUEUE_CFG_ALL_TYPES;
-		} else {
-			uint8_t slot;
-
-			nb_slots = cdata.num_stages + 1;
-			slot = i % nb_slots;
-			wkr_q_conf.schedule_type = slot == cdata.num_stages ?
-				RTE_SCHED_TYPE_ATOMIC : cdata.queue_type;
-		}
-
-		if (rte_event_queue_setup(dev_id, i, &wkr_q_conf) < 0) {
-			printf("%d: error creating qid %d\n", __LINE__, i);
-			return -1;
-		}
-		cdata.qid[i] = i;
-		cdata.next_qid[i] = i+1;
-		if (cdata.enable_queue_priorities) {
-			const uint32_t prio_delta =
-				(RTE_EVENT_DEV_PRIORITY_LOWEST) /
-				nb_slots;
-
-			/* higher priority for queues closer to tx */
-			wkr_q_conf.priority =
-				RTE_EVENT_DEV_PRIORITY_LOWEST - prio_delta *
-				(i % nb_slots);
-		}
-
-		const char *type_str = "Atomic";
-		switch (wkr_q_conf.schedule_type) {
-		case RTE_SCHED_TYPE_ORDERED:
-			type_str = "Ordered";
-			break;
-		case RTE_SCHED_TYPE_PARALLEL:
-			type_str = "Parallel";
-			break;
-		}
-		printf("\tStage %d, Type %s\tPriority = %d\n", i, type_str,
-				wkr_q_conf.priority);
-	}
-
-	printf("\n");
-	if (wkr_p_conf.dequeue_depth > config.nb_event_port_dequeue_depth)
-		wkr_p_conf.dequeue_depth = config.nb_event_port_dequeue_depth;
-	if (wkr_p_conf.enqueue_depth > config.nb_event_port_enqueue_depth)
-		wkr_p_conf.enqueue_depth = config.nb_event_port_enqueue_depth;
-
-	/* set up one port per worker, linking to all stage queues */
-	for (i = 0; i < cdata.num_workers; i++) {
-		struct worker_data *w = &worker_data[i];
-		w->dev_id = dev_id;
-		if (rte_event_port_setup(dev_id, i, &wkr_p_conf) < 0) {
-			printf("Error setting up port %d\n", i);
-			return -1;
-		}
-
-		if (rte_event_port_link(dev_id, i, NULL, NULL, 0)
-				!= nb_queues) {
-			printf("%d: error creating link for port %d\n",
-					__LINE__, i);
-			return -1;
-		}
-		w->port_id = i;
-	}
-	/*
-	 * Reduce the load on ingress event queue by splitting the traffic
-	 * across multiple event queues.
-	 * for example, nb_stages =  2 and nb_ethdev = 2 then
-	 *
-	 *	nb_queues = (2 * 2) + 2 = 6 (non atq)
-	 *	rx_stride = 3
-	 *
-	 * So, traffic is split across queue 0 and queue 3 since queue id for
-	 * rx adapter is chosen <ethport_id> * <rx_stride> i.e in the above
-	 * case eth port 0, 1 will inject packets into event queue 0, 3
-	 * respectively.
-	 *
-	 * This forms two set of queue pipelines 0->1->2->tx and 3->4->5->tx.
-	 */
-	cdata.rx_stride = atq ? 1 : nb_slots;
-	ret = rte_event_dev_service_id_get(dev_id,
-				&fdata->evdev_service_id);
-	if (ret != -ESRCH && ret != 0) {
-		printf("Error getting the service ID\n");
-		return -1;
-	}
-	rte_service_runstate_set(fdata->evdev_service_id, 1);
-	rte_service_set_runstate_mapped_check(fdata->evdev_service_id, 0);
-	if (rte_event_dev_start(dev_id) < 0) {
-		printf("Error starting eventdev\n");
-		return -1;
-	}
-
-	return dev_id;
-}
-
-
-struct rx_adptr_services {
-	uint16_t nb_rx_adptrs;
-	uint32_t *rx_adpt_arr;
-};
-
-static int32_t
-service_rx_adapter(void *arg)
-{
-	int i;
-	struct rx_adptr_services *adptr_services = arg;
-
-	for (i = 0; i < adptr_services->nb_rx_adptrs; i++)
-		rte_service_run_iter_on_app_lcore(
-				adptr_services->rx_adpt_arr[i], 1);
-	return 0;
-}
-
-static void
-init_rx_adapter(uint16_t nb_ports)
-{
-	int i;
-	int ret;
-	uint8_t evdev_id = 0;
-	struct rx_adptr_services *adptr_services = NULL;
-	struct rte_event_dev_info dev_info;
-
-	ret = rte_event_dev_info_get(evdev_id, &dev_info);
-	adptr_services = rte_zmalloc(NULL, sizeof(struct rx_adptr_services), 0);
-
-	struct rte_event_port_conf rx_p_conf = {
-		.dequeue_depth = 8,
-		.enqueue_depth = 8,
-		.new_event_threshold = 1200,
-	};
-
-	if (rx_p_conf.dequeue_depth > dev_info.max_event_port_dequeue_depth)
-		rx_p_conf.dequeue_depth = dev_info.max_event_port_dequeue_depth;
-	if (rx_p_conf.enqueue_depth > dev_info.max_event_port_enqueue_depth)
-		rx_p_conf.enqueue_depth = dev_info.max_event_port_enqueue_depth;
-
-
-	struct rte_event_eth_rx_adapter_queue_conf queue_conf;
-	memset(&queue_conf, 0, sizeof(queue_conf));
-	queue_conf.ev.sched_type = cdata.queue_type;
-
-	for (i = 0; i < nb_ports; i++) {
-		uint32_t cap;
-		uint32_t service_id;
-
-		ret = rte_event_eth_rx_adapter_create(i, evdev_id, &rx_p_conf);
-		if (ret)
-			rte_exit(EXIT_FAILURE,
-					"failed to create rx adapter[%d]",
-					cdata.rx_adapter_id);
-
-		ret = rte_event_eth_rx_adapter_caps_get(evdev_id, i, &cap);
-		if (ret)
-			rte_exit(EXIT_FAILURE,
-					"failed to get event rx adapter "
-					"capabilities");
-
-		queue_conf.ev.queue_id = cdata.rx_stride ?
-			(i * cdata.rx_stride)
-			: (uint8_t)cdata.qid[0];
-
-		ret = rte_event_eth_rx_adapter_queue_add(i, i, -1, &queue_conf);
-		if (ret)
-			rte_exit(EXIT_FAILURE,
-					"Failed to add queues to Rx adapter");
-
-
-		/* Producer needs to be scheduled. */
-		if (!(cap & RTE_EVENT_ETH_RX_ADAPTER_CAP_INTERNAL_PORT)) {
-			ret = rte_event_eth_rx_adapter_service_id_get(i,
-					&service_id);
-			if (ret != -ESRCH && ret != 0) {
-				rte_exit(EXIT_FAILURE,
-				"Error getting the service ID for rx adptr\n");
-			}
-
-			rte_service_runstate_set(service_id, 1);
-			rte_service_set_runstate_mapped_check(service_id, 0);
-
-			adptr_services->nb_rx_adptrs++;
-			adptr_services->rx_adpt_arr = rte_realloc(
-					adptr_services->rx_adpt_arr,
-					adptr_services->nb_rx_adptrs *
-					sizeof(uint32_t), 0);
-			adptr_services->rx_adpt_arr[
-				adptr_services->nb_rx_adptrs - 1] =
-				service_id;
-		}
-
-		ret = rte_event_eth_rx_adapter_start(i);
-		if (ret)
-			rte_exit(EXIT_FAILURE, "Rx adapter[%d] start failed",
-					cdata.rx_adapter_id);
-	}
-
-	if (adptr_services->nb_rx_adptrs) {
-		struct rte_service_spec service;
-
-		memset(&service, 0, sizeof(struct rte_service_spec));
-		snprintf(service.name, sizeof(service.name), "rx_service");
-		service.callback = service_rx_adapter;
-		service.callback_userdata = (void *)adptr_services;
-
-		int32_t ret = rte_service_component_register(&service,
-				&fdata->rxadptr_service_id);
-		if (ret)
-			rte_exit(EXIT_FAILURE,
-				"Rx adapter[%d] service register failed",
-				cdata.rx_adapter_id);
-
-		rte_service_runstate_set(fdata->rxadptr_service_id, 1);
-		rte_service_component_runstate_set(fdata->rxadptr_service_id,
-				1);
-		rte_service_set_runstate_mapped_check(fdata->rxadptr_service_id,
-				0);
-	} else {
-		memset(fdata->rx_core, 0, sizeof(unsigned int) * MAX_NUM_CORE);
-		rte_free(adptr_services);
-	}
-
-	if (!adptr_services->nb_rx_adptrs && fdata->cap.consumer == NULL &&
-			(dev_info.event_dev_cap &
-			 RTE_EVENT_DEV_CAP_DISTRIBUTED_SCHED))
-		fdata->cap.scheduler = NULL;
-
-	if (dev_info.event_dev_cap & RTE_EVENT_DEV_CAP_DISTRIBUTED_SCHED)
-		memset(fdata->sched_core, 0,
-				sizeof(unsigned int) * MAX_NUM_CORE);
-}
-
-static void
-worker_tx_opt_check(void)
-{
-	int i;
-	int ret;
-	uint32_t cap = 0;
-	uint8_t rx_needed = 0;
-	struct rte_event_dev_info eventdev_info;
-
-	memset(&eventdev_info, 0, sizeof(struct rte_event_dev_info));
-	rte_event_dev_info_get(0, &eventdev_info);
-
-	if (cdata.all_type_queues && !(eventdev_info.event_dev_cap &
-				RTE_EVENT_DEV_CAP_QUEUE_ALL_TYPES))
-		rte_exit(EXIT_FAILURE,
-				"Event dev doesn't support all type queues\n");
-
-	RTE_ETH_FOREACH_DEV(i) {
-		ret = rte_event_eth_rx_adapter_caps_get(0, i, &cap);
-		if (ret)
-			rte_exit(EXIT_FAILURE,
-					"failed to get event rx adapter "
-					"capabilities");
-		rx_needed |=
-			!(cap & RTE_EVENT_ETH_RX_ADAPTER_CAP_INTERNAL_PORT);
-	}
-
-	if (cdata.worker_lcore_mask == 0 ||
-			(rx_needed && cdata.rx_lcore_mask == 0) ||
-			(cdata.sched_lcore_mask == 0 &&
-			 !(eventdev_info.event_dev_cap &
-				 RTE_EVENT_DEV_CAP_DISTRIBUTED_SCHED))) {
-		printf("Core part of pipeline was not assigned any cores. "
-			"This will stall the pipeline, please check core masks "
-			"(use -h for details on setting core masks):\n"
-			"\trx: %"PRIu64"\n\ttx: %"PRIu64"\n\tsched: %"PRIu64
-			"\n\tworkers: %"PRIu64"\n",
-			cdata.rx_lcore_mask, cdata.tx_lcore_mask,
-			cdata.sched_lcore_mask,
-			cdata.worker_lcore_mask);
-		rte_exit(-1, "Fix core masks\n");
-	}
-}
-
-static worker_loop
-get_worker_loop_single_burst(uint8_t atq)
-{
-	if (atq)
-		return worker_do_tx_single_burst_atq;
-
-	return worker_do_tx_single_burst;
-}
-
-static worker_loop
-get_worker_loop_single_non_burst(uint8_t atq)
-{
-	if (atq)
-		return worker_do_tx_single_atq;
-
-	return worker_do_tx_single;
-}
-
-static worker_loop
-get_worker_loop_burst(uint8_t atq)
-{
-	if (atq)
-		return worker_do_tx_burst_atq;
-
-	return worker_do_tx_burst;
-}
-
-static worker_loop
-get_worker_loop_non_burst(uint8_t atq)
-{
-	if (atq)
-		return worker_do_tx_atq;
-
-	return worker_do_tx;
-}
-
-static worker_loop
-get_worker_single_stage(bool burst)
-{
-	uint8_t atq = cdata.all_type_queues ? 1 : 0;
-
-	if (burst)
-		return get_worker_loop_single_burst(atq);
-
-	return get_worker_loop_single_non_burst(atq);
-}
-
-static worker_loop
-get_worker_multi_stage(bool burst)
-{
-	uint8_t atq = cdata.all_type_queues ? 1 : 0;
-
-	if (burst)
-		return get_worker_loop_burst(atq);
-
-	return get_worker_loop_non_burst(atq);
-}
-
-void
-set_worker_tx_setup_data(struct setup_data *caps, bool burst)
-{
-	if (cdata.num_stages == 1)
-		caps->worker = get_worker_single_stage(burst);
-	else
-		caps->worker = get_worker_multi_stage(burst);
-
-	memset(fdata->tx_core, 0, sizeof(unsigned int) * MAX_NUM_CORE);
-
-	caps->check_opt = worker_tx_opt_check;
-	caps->consumer = NULL;
-	caps->scheduler = schedule_devices;
-	caps->evdev_setup = setup_eventdev_worker_tx;
-	caps->adptr_setup = init_rx_adapter;
-}
diff --git a/examples/exception_path/Makefile b/examples/exception_path/Makefile
deleted file mode 100644
index 88f709e..0000000
--- a/examples/exception_path/Makefile
+++ /dev/null
@@ -1,59 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-# binary name
-APP = exception_path
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-
-endif
diff --git a/examples/exception_path/main.c b/examples/exception_path/main.c
deleted file mode 100644
index 996f493..0000000
--- a/examples/exception_path/main.c
+++ /dev/null
@@ -1,591 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <string.h>
-#include <sys/queue.h>
-#include <stdarg.h>
-#include <errno.h>
-#include <getopt.h>
-
-#include <netinet/in.h>
-#include <net/if.h>
-#ifdef RTE_EXEC_ENV_LINUXAPP
-#include <linux/if_tun.h>
-#endif
-#include <fcntl.h>
-#include <sys/ioctl.h>
-#include <unistd.h>
-#include <signal.h>
-
-#include <rte_common.h>
-#include <rte_log.h>
-#include <rte_memory.h>
-#include <rte_memcpy.h>
-#include <rte_eal.h>
-#include <rte_per_lcore.h>
-#include <rte_launch.h>
-#include <rte_atomic.h>
-#include <rte_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_interrupts.h>
-#include <rte_debug.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-#include <rte_string_fns.h>
-#include <rte_cycles.h>
-
-#ifndef APP_MAX_LCORE
-#if (RTE_MAX_LCORE > 64)
-#define APP_MAX_LCORE 64
-#else
-#define APP_MAX_LCORE RTE_MAX_LCORE
-#endif
-#endif
-
-/* Macros for printing using RTE_LOG */
-#define RTE_LOGTYPE_APP RTE_LOGTYPE_USER1
-#define FATAL_ERROR(fmt, args...)       rte_exit(EXIT_FAILURE, fmt "\n", ##args)
-#define PRINT_INFO(fmt, args...)        RTE_LOG(INFO, APP, fmt "\n", ##args)
-
-/* Max ports than can be used (each port is associated with two lcores) */
-#define MAX_PORTS               (APP_MAX_LCORE / 2)
-
-/* Max size of a single packet */
-#define MAX_PACKET_SZ (2048)
-
-/* Size of the data buffer in each mbuf */
-#define MBUF_DATA_SZ (MAX_PACKET_SZ + RTE_PKTMBUF_HEADROOM)
-
-/* Number of mbufs in mempool that is created */
-#define NB_MBUF                 8192
-
-/* How many packets to attempt to read from NIC in one go */
-#define PKT_BURST_SZ            32
-
-/* How many objects (mbufs) to keep in per-lcore mempool cache */
-#define MEMPOOL_CACHE_SZ        PKT_BURST_SZ
-
-/* Number of RX ring descriptors */
-#define NB_RXD                  1024
-
-/* Number of TX ring descriptors */
-#define NB_TXD                  1024
-
-/*
- * RX and TX Prefetch, Host, and Write-back threshold values should be
- * carefully set for optimal performance. Consult the network
- * controller's datasheet and supporting DPDK documentation for guidance
- * on how these parameters should be set.
- */
-
-/* Options for configuring ethernet port */
-static struct rte_eth_conf port_conf = {
-	.rxmode = {
-		.ignore_offload_bitfield = 1,
-		.offloads = DEV_RX_OFFLOAD_CRC_STRIP,
-	},
-	.txmode = {
-		.mq_mode = ETH_MQ_TX_NONE,
-	},
-};
-
-/* Mempool for mbufs */
-static struct rte_mempool * pktmbuf_pool = NULL;
-
-/* Mask of enabled ports */
-static uint32_t ports_mask = 0;
-
-/* Mask of cores that read from NIC and write to tap */
-static uint64_t input_cores_mask = 0;
-
-/* Mask of cores that read from tap and write to NIC */
-static uint64_t output_cores_mask = 0;
-
-/* Array storing port_id that is associated with each lcore */
-static uint16_t port_ids[APP_MAX_LCORE];
-
-/* Structure type for recording lcore-specific stats */
-struct stats {
-	uint64_t rx;
-	uint64_t tx;
-	uint64_t dropped;
-} __rte_cache_aligned;
-
-/* Array of lcore-specific stats */
-static struct stats lcore_stats[APP_MAX_LCORE];
-
-/* Print out statistics on packets handled */
-static void
-print_stats(void)
-{
-	unsigned i;
-
-	printf("\n**Exception-Path example application statistics**\n"
-	       "=======  ======  ============  ============  ===============\n"
-	       " Lcore    Port            RX            TX    Dropped on TX\n"
-	       "-------  ------  ------------  ------------  ---------------\n");
-	RTE_LCORE_FOREACH(i) {
-		printf("%6u %7u %13"PRIu64" %13"PRIu64" %16"PRIu64"\n",
-		       i, (unsigned)port_ids[i],
-		       lcore_stats[i].rx, lcore_stats[i].tx,
-		       lcore_stats[i].dropped);
-	}
-	printf("=======  ======  ============  ============  ===============\n");
-}
-
-/* Custom handling of signals to handle stats */
-static void
-signal_handler(int signum)
-{
-	/* When we receive a USR1 signal, print stats */
-	if (signum == SIGUSR1) {
-		print_stats();
-	}
-
-	/* When we receive a USR2 signal, reset stats */
-	if (signum == SIGUSR2) {
-		memset(&lcore_stats, 0, sizeof(lcore_stats));
-		printf("\n**Statistics have been reset**\n");
-		return;
-	}
-}
-
-#ifdef RTE_EXEC_ENV_LINUXAPP
-/*
- * Create a tap network interface, or use existing one with same name.
- * If name[0]='\0' then a name is automatically assigned and returned in name.
- */
-static int tap_create(char *name)
-{
-	struct ifreq ifr;
-	int fd, ret;
-
-	fd = open("/dev/net/tun", O_RDWR);
-	if (fd < 0)
-		return fd;
-
-	memset(&ifr, 0, sizeof(ifr));
-
-	/* TAP device without packet information */
-	ifr.ifr_flags = IFF_TAP | IFF_NO_PI;
-
-	if (name && *name)
-		snprintf(ifr.ifr_name, IFNAMSIZ, "%s", name);
-
-	ret = ioctl(fd, TUNSETIFF, (void *) &ifr);
-	if (ret < 0) {
-		close(fd);
-		return ret;
-	}
-
-	if (name)
-		snprintf(name, IFNAMSIZ, "%s", ifr.ifr_name);
-
-	return fd;
-}
-#else
-/*
- * Find a free tap network interface, or create a new one.
- * The name is automatically assigned and returned in name.
- */
-static int tap_create(char *name)
-{
-	int i, fd = -1;
-	char devname[PATH_MAX];
-
-	for (i = 0; i < 255; i++) {
-		snprintf(devname, sizeof(devname), "/dev/tap%d", i);
-		fd = open(devname, O_RDWR);
-		if (fd >= 0 || errno != EBUSY)
-			break;
-	}
-
-	if (name)
-		snprintf(name, IFNAMSIZ, "tap%d", i);
-
-	return fd;
-}
-#endif
-
-/* Main processing loop */
-static int
-main_loop(__attribute__((unused)) void *arg)
-{
-	const unsigned lcore_id = rte_lcore_id();
-	char tap_name[IFNAMSIZ];
-	int tap_fd;
-
-	if ((1ULL << lcore_id) & input_cores_mask) {
-		/* Create new tap interface */
-		snprintf(tap_name, IFNAMSIZ, "tap_dpdk_%.2u", lcore_id);
-		tap_fd = tap_create(tap_name);
-		if (tap_fd < 0)
-			FATAL_ERROR("Could not create tap interface \"%s\" (%d)",
-					tap_name, tap_fd);
-
-		PRINT_INFO("Lcore %u is reading from port %u and writing to %s",
-		           lcore_id, (unsigned)port_ids[lcore_id], tap_name);
-		fflush(stdout);
-		/* Loop forever reading from NIC and writing to tap */
-		for (;;) {
-			struct rte_mbuf *pkts_burst[PKT_BURST_SZ];
-			unsigned i;
-			const unsigned nb_rx =
-					rte_eth_rx_burst(port_ids[lcore_id], 0,
-					    pkts_burst, PKT_BURST_SZ);
-			lcore_stats[lcore_id].rx += nb_rx;
-			for (i = 0; likely(i < nb_rx); i++) {
-				struct rte_mbuf *m = pkts_burst[i];
-				/* Ignore return val from write() */
-				int ret = write(tap_fd,
-				                rte_pktmbuf_mtod(m, void*),
-				                rte_pktmbuf_data_len(m));
-				rte_pktmbuf_free(m);
-				if (unlikely(ret < 0))
-					lcore_stats[lcore_id].dropped++;
-				else
-					lcore_stats[lcore_id].tx++;
-			}
-		}
-	}
-	else if ((1ULL << lcore_id) & output_cores_mask) {
-		/* Create new tap interface */
-		snprintf(tap_name, IFNAMSIZ, "tap_dpdk_%.2u", lcore_id);
-		tap_fd = tap_create(tap_name);
-		if (tap_fd < 0)
-			FATAL_ERROR("Could not create tap interface \"%s\" (%d)",
-					tap_name, tap_fd);
-
-		PRINT_INFO("Lcore %u is reading from %s and writing to port %u",
-		           lcore_id, tap_name, (unsigned)port_ids[lcore_id]);
-		fflush(stdout);
-		/* Loop forever reading from tap and writing to NIC */
-		for (;;) {
-			int ret;
-			struct rte_mbuf *m = rte_pktmbuf_alloc(pktmbuf_pool);
-			if (m == NULL)
-				continue;
-
-			ret = read(tap_fd, rte_pktmbuf_mtod(m, void *),
-				MAX_PACKET_SZ);
-			lcore_stats[lcore_id].rx++;
-			if (unlikely(ret < 0)) {
-				FATAL_ERROR("Reading from %s interface failed",
-				            tap_name);
-			}
-			m->nb_segs = 1;
-			m->next = NULL;
-			m->pkt_len = (uint16_t)ret;
-			m->data_len = (uint16_t)ret;
-			ret = rte_eth_tx_burst(port_ids[lcore_id], 0, &m, 1);
-			if (unlikely(ret < 1)) {
-				rte_pktmbuf_free(m);
-				lcore_stats[lcore_id].dropped++;
-			}
-			else {
-				lcore_stats[lcore_id].tx++;
-			}
-		}
-	}
-	else {
-		PRINT_INFO("Lcore %u has nothing to do", lcore_id);
-		return 0;
-	}
-	/*
-	 * Tap file is closed automatically when program exits. Putting close()
-	 * here will cause the compiler to give an error about unreachable code.
-	 */
-}
-
-/* Display usage instructions */
-static void
-print_usage(const char *prgname)
-{
-	PRINT_INFO("\nUsage: %s [EAL options] -- -p PORTMASK -i IN_CORES -o OUT_CORES\n"
-	           "    -p PORTMASK: hex bitmask of ports to use\n"
-	           "    -i IN_CORES: hex bitmask of cores which read from NIC\n"
-	           "    -o OUT_CORES: hex bitmask of cores which write to NIC",
-	           prgname);
-}
-
-/* Convert string to unsigned number. 0 is returned if error occurs */
-static uint64_t
-parse_unsigned(const char *portmask)
-{
-	char *end = NULL;
-	uint64_t num;
-
-	num = strtoull(portmask, &end, 16);
-	if ((portmask[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return 0;
-
-	return (uint64_t)num;
-}
-
-/* Record affinities between ports and lcores in global port_ids[] array */
-static void
-setup_port_lcore_affinities(void)
-{
-	unsigned long i;
-	uint16_t tx_port = 0;
-	uint16_t rx_port = 0;
-
-	/* Setup port_ids[] array, and check masks were ok */
-	for (i = 0; i < APP_MAX_LCORE; i++) {
-		if (!rte_lcore_is_enabled(i))
-			continue;
-		if (input_cores_mask & (1ULL << i)) {
-			/* Skip ports that are not enabled */
-			while ((ports_mask & (1 << rx_port)) == 0) {
-				rx_port++;
-				if (rx_port > (sizeof(ports_mask) * 8))
-					goto fail; /* not enough ports */
-			}
-
-			port_ids[i] = rx_port++;
-		} else if (output_cores_mask & (1ULL << (i & 0x3f))) {
-			/* Skip ports that are not enabled */
-			while ((ports_mask & (1 << tx_port)) == 0) {
-				tx_port++;
-				if (tx_port > (sizeof(ports_mask) * 8))
-					goto fail; /* not enough ports */
-			}
-
-			port_ids[i] = tx_port++;
-		}
-	}
-
-	if (rx_port != tx_port)
-		goto fail; /* uneven number of cores in masks */
-
-	if (ports_mask & (~((1 << rx_port) - 1)))
-		goto fail; /* unused ports */
-
-	return;
-fail:
-	FATAL_ERROR("Invalid core/port masks specified on command line");
-}
-
-/* Parse the arguments given in the command line of the application */
-static void
-parse_args(int argc, char **argv)
-{
-	int opt;
-	const char *prgname = argv[0];
-
-	/* Disable printing messages within getopt() */
-	opterr = 0;
-
-	/* Parse command line */
-	while ((opt = getopt(argc, argv, "i:o:p:")) != EOF) {
-		switch (opt) {
-		case 'i':
-			input_cores_mask = parse_unsigned(optarg);
-			break;
-		case 'o':
-			output_cores_mask = parse_unsigned(optarg);
-			break;
-		case 'p':
-			ports_mask = parse_unsigned(optarg);
-			break;
-		default:
-			print_usage(prgname);
-			FATAL_ERROR("Invalid option specified");
-		}
-	}
-
-	/* Check that options were parsed ok */
-	if (input_cores_mask == 0) {
-		print_usage(prgname);
-		FATAL_ERROR("IN_CORES not specified correctly");
-	}
-	if (output_cores_mask == 0) {
-		print_usage(prgname);
-		FATAL_ERROR("OUT_CORES not specified correctly");
-	}
-	if (ports_mask == 0) {
-		print_usage(prgname);
-		FATAL_ERROR("PORTMASK not specified correctly");
-	}
-
-	setup_port_lcore_affinities();
-}
-
-/* Initialise a single port on an Ethernet device */
-static void
-init_port(uint16_t port)
-{
-	int ret;
-	uint16_t nb_rxd = NB_RXD;
-	uint16_t nb_txd = NB_TXD;
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_rxconf rxq_conf;
-	struct rte_eth_txconf txq_conf;
-	struct rte_eth_conf local_port_conf = port_conf;
-
-	/* Initialise device and RX/TX queues */
-	PRINT_INFO("Initialising port %u ...", port);
-	fflush(stdout);
-	rte_eth_dev_info_get(port, &dev_info);
-	if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-		local_port_conf.txmode.offloads |=
-			DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-	ret = rte_eth_dev_configure(port, 1, 1, &local_port_conf);
-	if (ret < 0)
-		FATAL_ERROR("Could not configure port%u (%d)", port, ret);
-
-	ret = rte_eth_dev_adjust_nb_rx_tx_desc(port, &nb_rxd, &nb_txd);
-	if (ret < 0)
-		FATAL_ERROR("Could not adjust number of descriptors for port%u (%d)",
-			    port, ret);
-
-	rxq_conf = dev_info.default_rxconf;
-	rxq_conf.offloads = local_port_conf.rxmode.offloads;
-	ret = rte_eth_rx_queue_setup(port, 0, nb_rxd,
-				rte_eth_dev_socket_id(port),
-				&rxq_conf,
-				pktmbuf_pool);
-	if (ret < 0)
-		FATAL_ERROR("Could not setup up RX queue for port%u (%d)",
-				port, ret);
-
-	txq_conf = dev_info.default_txconf;
-	txq_conf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-	txq_conf.offloads = local_port_conf.txmode.offloads;
-	ret = rte_eth_tx_queue_setup(port, 0, nb_txd,
-				rte_eth_dev_socket_id(port),
-				&txq_conf);
-	if (ret < 0)
-		FATAL_ERROR("Could not setup up TX queue for port%u (%d)",
-				port, ret);
-
-	ret = rte_eth_dev_start(port);
-	if (ret < 0)
-		FATAL_ERROR("Could not start port%u (%d)", port, ret);
-
-	rte_eth_promiscuous_enable(port);
-}
-
-/* Check the link status of all ports in up to 9s, and print them finally */
-static void
-check_all_ports_link_status(uint32_t port_mask)
-{
-#define CHECK_INTERVAL 100 /* 100ms */
-#define MAX_CHECK_TIME 90 /* 9s (90 * 100ms) in total */
-	uint16_t portid;
-	uint8_t count, all_ports_up, print_flag = 0;
-	struct rte_eth_link link;
-
-	printf("\nChecking link status");
-	fflush(stdout);
-	for (count = 0; count <= MAX_CHECK_TIME; count++) {
-		all_ports_up = 1;
-		RTE_ETH_FOREACH_DEV(portid) {
-			if ((port_mask & (1 << portid)) == 0)
-				continue;
-			memset(&link, 0, sizeof(link));
-			rte_eth_link_get_nowait(portid, &link);
-			/* print link status if flag set */
-			if (print_flag == 1) {
-				if (link.link_status)
-					printf(
-					"Port%d Link Up. Speed %u Mbps - %s\n",
-						portid, link.link_speed,
-				(link.link_duplex == ETH_LINK_FULL_DUPLEX) ?
-					("full-duplex") : ("half-duplex\n"));
-				else
-					printf("Port %d Link Down\n", portid);
-				continue;
-			}
-			/* clear all_ports_up flag if any link down */
-			if (link.link_status == ETH_LINK_DOWN) {
-				all_ports_up = 0;
-				break;
-			}
-		}
-		/* after finally printing all link status, get out */
-		if (print_flag == 1)
-			break;
-
-		if (all_ports_up == 0) {
-			printf(".");
-			fflush(stdout);
-			rte_delay_ms(CHECK_INTERVAL);
-		}
-
-		/* set the print_flag if all ports up or timeout */
-		if (all_ports_up == 1 || count == (MAX_CHECK_TIME - 1)) {
-			print_flag = 1;
-			printf("done\n");
-		}
-	}
-}
-
-/* Initialise ports/queues etc. and start main loop on each core */
-int
-main(int argc, char** argv)
-{
-	int ret;
-	unsigned i,high_port;
-	uint16_t nb_sys_ports, port;
-
-	/* Associate signal_hanlder function with USR signals */
-	signal(SIGUSR1, signal_handler);
-	signal(SIGUSR2, signal_handler);
-
-	/* Initialise EAL */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		FATAL_ERROR("Could not initialise EAL (%d)", ret);
-	argc -= ret;
-	argv += ret;
-
-	/* Parse application arguments (after the EAL ones) */
-	parse_args(argc, argv);
-
-	/* Create the mbuf pool */
-	pktmbuf_pool = rte_pktmbuf_pool_create("mbuf_pool", NB_MBUF,
-			MEMPOOL_CACHE_SZ, 0, MBUF_DATA_SZ, rte_socket_id());
-	if (pktmbuf_pool == NULL) {
-		FATAL_ERROR("Could not initialise mbuf pool");
-		return -1;
-	}
-
-	/* Get number of ports found in scan */
-	nb_sys_ports = rte_eth_dev_count();
-	if (nb_sys_ports == 0)
-		FATAL_ERROR("No supported Ethernet device found");
-	/* Find highest port set in portmask */
-	for (high_port = (sizeof(ports_mask) * 8) - 1;
-			(high_port != 0) && !(ports_mask & (1 << high_port));
-			high_port--)
-		; /* empty body */
-	if (high_port > nb_sys_ports)
-		FATAL_ERROR("Port mask requires more ports than available");
-
-	/* Initialise each port */
-	RTE_ETH_FOREACH_DEV(port) {
-		/* Skip ports that are not enabled */
-		if ((ports_mask & (1 << port)) == 0) {
-			continue;
-		}
-		init_port(port);
-	}
-	check_all_ports_link_status(ports_mask);
-
-	/* Launch per-lcore function on every lcore */
-	rte_eal_mp_remote_launch(main_loop, NULL, CALL_MASTER);
-	RTE_LCORE_FOREACH_SLAVE(i) {
-		if (rte_eal_wait_lcore(i) < 0)
-			return -1;
-	}
-
-	return 0;
-}
diff --git a/examples/exception_path/meson.build b/examples/exception_path/meson.build
deleted file mode 100644
index 2b0a250..0000000
--- a/examples/exception_path/meson.build
+++ /dev/null
@@ -1,12 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-allow_experimental_apis = true
-sources = files(
-	'main.c'
-)
diff --git a/examples/flow_classify/Makefile b/examples/flow_classify/Makefile
deleted file mode 100644
index f1fa4df..0000000
--- a/examples/flow_classify/Makefile
+++ /dev/null
@@ -1,65 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# binary name
-APP = flow_classify
-
-# all source are stored in SRCS-y
-SRCS-y := flow_classify.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-
-# workaround for a gcc bug with noreturn attribute
-# http://gcc.gnu.org/bugzilla/show_bug.cgi?id=12603
-ifeq ($(CONFIG_RTE_TOOLCHAIN_GCC),y)
-CFLAGS_main.o += -Wno-return-type
-endif
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-
-endif
diff --git a/examples/flow_classify/flow_classify.c b/examples/flow_classify/flow_classify.c
deleted file mode 100644
index b690034..0000000
--- a/examples/flow_classify/flow_classify.c
+++ /dev/null
@@ -1,848 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2017 Intel Corporation
- */
-
-#include <stdint.h>
-#include <inttypes.h>
-#include <getopt.h>
-
-#include <rte_eal.h>
-#include <rte_ethdev.h>
-#include <rte_cycles.h>
-#include <rte_lcore.h>
-#include <rte_mbuf.h>
-#include <rte_flow.h>
-#include <rte_flow_classify.h>
-#include <rte_table_acl.h>
-
-#define RX_RING_SIZE 1024
-#define TX_RING_SIZE 1024
-
-#define NUM_MBUFS 8191
-#define MBUF_CACHE_SIZE 250
-#define BURST_SIZE 32
-
-#define MAX_NUM_CLASSIFY 30
-#define FLOW_CLASSIFY_MAX_RULE_NUM 91
-#define FLOW_CLASSIFY_MAX_PRIORITY 8
-#define FLOW_CLASSIFIER_NAME_SIZE 64
-
-#define COMMENT_LEAD_CHAR	('#')
-#define OPTION_RULE_IPV4	"rule_ipv4"
-#define RTE_LOGTYPE_FLOW_CLASSIFY	RTE_LOGTYPE_USER3
-#define flow_classify_log(format, ...) \
-		RTE_LOG(ERR, FLOW_CLASSIFY, format, ##__VA_ARGS__)
-
-#define uint32_t_to_char(ip, a, b, c, d) do {\
-		*a = (unsigned char)(ip >> 24 & 0xff);\
-		*b = (unsigned char)(ip >> 16 & 0xff);\
-		*c = (unsigned char)(ip >> 8 & 0xff);\
-		*d = (unsigned char)(ip & 0xff);\
-	} while (0)
-
-enum {
-	CB_FLD_SRC_ADDR,
-	CB_FLD_DST_ADDR,
-	CB_FLD_SRC_PORT,
-	CB_FLD_SRC_PORT_DLM,
-	CB_FLD_SRC_PORT_MASK,
-	CB_FLD_DST_PORT,
-	CB_FLD_DST_PORT_DLM,
-	CB_FLD_DST_PORT_MASK,
-	CB_FLD_PROTO,
-	CB_FLD_PRIORITY,
-	CB_FLD_NUM,
-};
-
-static struct{
-	const char *rule_ipv4_name;
-} parm_config;
-const char cb_port_delim[] = ":";
-
-static const struct rte_eth_conf port_conf_default = {
-	.rxmode = {
-		.max_rx_pkt_len = ETHER_MAX_LEN,
-		.ignore_offload_bitfield = 1,
-	},
-};
-
-struct flow_classifier {
-	struct rte_flow_classifier *cls;
-};
-
-struct flow_classifier_acl {
-	struct flow_classifier cls;
-} __rte_cache_aligned;
-
-/* ACL field definitions for IPv4 5 tuple rule */
-
-enum {
-	PROTO_FIELD_IPV4,
-	SRC_FIELD_IPV4,
-	DST_FIELD_IPV4,
-	SRCP_FIELD_IPV4,
-	DSTP_FIELD_IPV4,
-	NUM_FIELDS_IPV4
-};
-
-enum {
-	PROTO_INPUT_IPV4,
-	SRC_INPUT_IPV4,
-	DST_INPUT_IPV4,
-	SRCP_DESTP_INPUT_IPV4
-};
-
-static struct rte_acl_field_def ipv4_defs[NUM_FIELDS_IPV4] = {
-	/* first input field - always one byte long. */
-	{
-		.type = RTE_ACL_FIELD_TYPE_BITMASK,
-		.size = sizeof(uint8_t),
-		.field_index = PROTO_FIELD_IPV4,
-		.input_index = PROTO_INPUT_IPV4,
-		.offset = sizeof(struct ether_hdr) +
-			offsetof(struct ipv4_hdr, next_proto_id),
-	},
-	/* next input field (IPv4 source address) - 4 consecutive bytes. */
-	{
-		/* rte_flow uses a bit mask for IPv4 addresses */
-		.type = RTE_ACL_FIELD_TYPE_BITMASK,
-		.size = sizeof(uint32_t),
-		.field_index = SRC_FIELD_IPV4,
-		.input_index = SRC_INPUT_IPV4,
-		.offset = sizeof(struct ether_hdr) +
-			offsetof(struct ipv4_hdr, src_addr),
-	},
-	/* next input field (IPv4 destination address) - 4 consecutive bytes. */
-	{
-		/* rte_flow uses a bit mask for IPv4 addresses */
-		.type = RTE_ACL_FIELD_TYPE_BITMASK,
-		.size = sizeof(uint32_t),
-		.field_index = DST_FIELD_IPV4,
-		.input_index = DST_INPUT_IPV4,
-		.offset = sizeof(struct ether_hdr) +
-			offsetof(struct ipv4_hdr, dst_addr),
-	},
-	/*
-	 * Next 2 fields (src & dst ports) form 4 consecutive bytes.
-	 * They share the same input index.
-	 */
-	{
-		/* rte_flow uses a bit mask for protocol ports */
-		.type = RTE_ACL_FIELD_TYPE_BITMASK,
-		.size = sizeof(uint16_t),
-		.field_index = SRCP_FIELD_IPV4,
-		.input_index = SRCP_DESTP_INPUT_IPV4,
-		.offset = sizeof(struct ether_hdr) +
-			sizeof(struct ipv4_hdr) +
-			offsetof(struct tcp_hdr, src_port),
-	},
-	{
-		/* rte_flow uses a bit mask for protocol ports */
-		.type = RTE_ACL_FIELD_TYPE_BITMASK,
-		.size = sizeof(uint16_t),
-		.field_index = DSTP_FIELD_IPV4,
-		.input_index = SRCP_DESTP_INPUT_IPV4,
-		.offset = sizeof(struct ether_hdr) +
-			sizeof(struct ipv4_hdr) +
-			offsetof(struct tcp_hdr, dst_port),
-	},
-};
-
-/* flow classify data */
-static int num_classify_rules;
-static struct rte_flow_classify_rule *rules[MAX_NUM_CLASSIFY];
-static struct rte_flow_classify_ipv4_5tuple_stats ntuple_stats;
-static struct rte_flow_classify_stats classify_stats = {
-		.stats = (void **)&ntuple_stats
-};
-
-/* parameters for rte_flow_classify_validate and
- * rte_flow_classify_table_entry_add functions
- */
-
-static struct rte_flow_item  eth_item = { RTE_FLOW_ITEM_TYPE_ETH,
-	0, 0, 0 };
-static struct rte_flow_item  end_item = { RTE_FLOW_ITEM_TYPE_END,
-	0, 0, 0 };
-
-/* sample actions:
- * "actions count / end"
- */
-struct rte_flow_query_count count = {
-	.reset = 1,
-	.hits_set = 1,
-	.bytes_set = 1,
-	.hits = 0,
-	.bytes = 0,
-};
-static struct rte_flow_action count_action = { RTE_FLOW_ACTION_TYPE_COUNT,
-	&count};
-static struct rte_flow_action end_action = { RTE_FLOW_ACTION_TYPE_END, 0};
-static struct rte_flow_action actions[2];
-
-/* sample attributes */
-static struct rte_flow_attr attr;
-
-/* flow_classify.c: * Based on DPDK skeleton forwarding example. */
-
-/*
- * Initializes a given port using global settings and with the RX buffers
- * coming from the mbuf_pool passed as a parameter.
- */
-static inline int
-port_init(uint8_t port, struct rte_mempool *mbuf_pool)
-{
-	struct rte_eth_conf port_conf = port_conf_default;
-	struct ether_addr addr;
-	const uint16_t rx_rings = 1, tx_rings = 1;
-	int retval;
-	uint16_t q;
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_txconf txconf;
-
-	if (!rte_eth_dev_is_valid_port(port))
-		return -1;
-
-	rte_eth_dev_info_get(port, &dev_info);
-	if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-		port_conf.txmode.offloads |=
-			DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-
-	/* Configure the Ethernet device. */
-	retval = rte_eth_dev_configure(port, rx_rings, tx_rings, &port_conf);
-	if (retval != 0)
-		return retval;
-
-	/* Allocate and set up 1 RX queue per Ethernet port. */
-	for (q = 0; q < rx_rings; q++) {
-		retval = rte_eth_rx_queue_setup(port, q, RX_RING_SIZE,
-				rte_eth_dev_socket_id(port), NULL, mbuf_pool);
-		if (retval < 0)
-			return retval;
-	}
-
-	txconf = dev_info.default_txconf;
-	txconf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-	txconf.offloads = port_conf.txmode.offloads;
-	/* Allocate and set up 1 TX queue per Ethernet port. */
-	for (q = 0; q < tx_rings; q++) {
-		retval = rte_eth_tx_queue_setup(port, q, TX_RING_SIZE,
-				rte_eth_dev_socket_id(port), &txconf);
-		if (retval < 0)
-			return retval;
-	}
-
-	/* Start the Ethernet port. */
-	retval = rte_eth_dev_start(port);
-	if (retval < 0)
-		return retval;
-
-	/* Display the port MAC address. */
-	rte_eth_macaddr_get(port, &addr);
-	printf("Port %u MAC: %02" PRIx8 " %02" PRIx8 " %02" PRIx8
-			   " %02" PRIx8 " %02" PRIx8 " %02" PRIx8 "\n",
-			port,
-			addr.addr_bytes[0], addr.addr_bytes[1],
-			addr.addr_bytes[2], addr.addr_bytes[3],
-			addr.addr_bytes[4], addr.addr_bytes[5]);
-
-	/* Enable RX in promiscuous mode for the Ethernet device. */
-	rte_eth_promiscuous_enable(port);
-
-	return 0;
-}
-
-/*
- * The lcore main. This is the main thread that does the work, reading from
- * an input port classifying the packets and writing to an output port.
- */
-static __attribute__((noreturn)) void
-lcore_main(struct flow_classifier *cls_app)
-{
-	uint16_t port;
-	int ret;
-	int i = 0;
-
-	ret = rte_flow_classify_table_entry_delete(cls_app->cls,
-			rules[7]);
-	if (ret)
-		printf("table_entry_delete failed [7] %d\n\n", ret);
-	else
-		printf("table_entry_delete succeeded [7]\n\n");
-
-	/*
-	 * Check that the port is on the same NUMA node as the polling thread
-	 * for best performance.
-	 */
-	RTE_ETH_FOREACH_DEV(port)
-		if (rte_eth_dev_socket_id(port) > 0 &&
-			rte_eth_dev_socket_id(port) != (int)rte_socket_id()) {
-			printf("\n\n");
-			printf("WARNING: port %u is on remote NUMA node\n",
-			       port);
-			printf("to polling thread.\n");
-			printf("Performance will not be optimal.\n");
-		}
-	printf("\nCore %u forwarding packets. ", rte_lcore_id());
-	printf("[Ctrl+C to quit]\n");
-
-	/* Run until the application is quit or killed. */
-	for (;;) {
-		/*
-		 * Receive packets on a port, classify them and forward them
-		 * on the paired port.
-		 * The mapping is 0 -> 1, 1 -> 0, 2 -> 3, 3 -> 2, etc.
-		 */
-		RTE_ETH_FOREACH_DEV(port) {
-			/* Get burst of RX packets, from first port of pair. */
-			struct rte_mbuf *bufs[BURST_SIZE];
-			const uint16_t nb_rx = rte_eth_rx_burst(port, 0,
-					bufs, BURST_SIZE);
-
-			if (unlikely(nb_rx == 0))
-				continue;
-
-			for (i = 0; i < MAX_NUM_CLASSIFY; i++) {
-				if (rules[i]) {
-					ret = rte_flow_classifier_query(
-						cls_app->cls,
-						bufs, nb_rx, rules[i],
-						&classify_stats);
-					if (ret)
-						printf(
-							"rule [%d] query failed ret [%d]\n\n",
-							i, ret);
-					else {
-						printf(
-						"rule[%d] count=%"PRIu64"\n",
-						i, ntuple_stats.counter1);
-
-						printf("proto = %d\n",
-						ntuple_stats.ipv4_5tuple.proto);
-					}
-				}
-			}
-
-			/* Send burst of TX packets, to second port of pair. */
-			const uint16_t nb_tx = rte_eth_tx_burst(port ^ 1, 0,
-					bufs, nb_rx);
-
-			/* Free any unsent packets. */
-			if (unlikely(nb_tx < nb_rx)) {
-				uint16_t buf;
-
-				for (buf = nb_tx; buf < nb_rx; buf++)
-					rte_pktmbuf_free(bufs[buf]);
-			}
-		}
-	}
-}
-
-/*
- * Parse IPv4 5 tuple rules file, ipv4_rules_file.txt.
- * Expected format:
- * <src_ipv4_addr>'/'<masklen> <space> \
- * <dst_ipv4_addr>'/'<masklen> <space> \
- * <src_port> <space> ":" <src_port_mask> <space> \
- * <dst_port> <space> ":" <dst_port_mask> <space> \
- * <proto>'/'<proto_mask> <space> \
- * <priority>
- */
-
-static int
-get_cb_field(char **in, uint32_t *fd, int base, unsigned long lim,
-		char dlm)
-{
-	unsigned long val;
-	char *end;
-
-	errno = 0;
-	val = strtoul(*in, &end, base);
-	if (errno != 0 || end[0] != dlm || val > lim)
-		return -EINVAL;
-	*fd = (uint32_t)val;
-	*in = end + 1;
-	return 0;
-}
-
-static int
-parse_ipv4_net(char *in, uint32_t *addr, uint32_t *mask_len)
-{
-	uint32_t a, b, c, d, m;
-
-	if (get_cb_field(&in, &a, 0, UINT8_MAX, '.'))
-		return -EINVAL;
-	if (get_cb_field(&in, &b, 0, UINT8_MAX, '.'))
-		return -EINVAL;
-	if (get_cb_field(&in, &c, 0, UINT8_MAX, '.'))
-		return -EINVAL;
-	if (get_cb_field(&in, &d, 0, UINT8_MAX, '/'))
-		return -EINVAL;
-	if (get_cb_field(&in, &m, 0, sizeof(uint32_t) * CHAR_BIT, 0))
-		return -EINVAL;
-
-	addr[0] = IPv4(a, b, c, d);
-	mask_len[0] = m;
-	return 0;
-}
-
-static int
-parse_ipv4_5tuple_rule(char *str, struct rte_eth_ntuple_filter *ntuple_filter)
-{
-	int i, ret;
-	char *s, *sp, *in[CB_FLD_NUM];
-	static const char *dlm = " \t\n";
-	int dim = CB_FLD_NUM;
-	uint32_t temp;
-
-	s = str;
-	for (i = 0; i != dim; i++, s = NULL) {
-		in[i] = strtok_r(s, dlm, &sp);
-		if (in[i] == NULL)
-			return -EINVAL;
-	}
-
-	ret = parse_ipv4_net(in[CB_FLD_SRC_ADDR],
-			&ntuple_filter->src_ip,
-			&ntuple_filter->src_ip_mask);
-	if (ret != 0) {
-		flow_classify_log("failed to read source address/mask: %s\n",
-			in[CB_FLD_SRC_ADDR]);
-		return ret;
-	}
-
-	ret = parse_ipv4_net(in[CB_FLD_DST_ADDR],
-			&ntuple_filter->dst_ip,
-			&ntuple_filter->dst_ip_mask);
-	if (ret != 0) {
-		flow_classify_log("failed to read source address/mask: %s\n",
-			in[CB_FLD_DST_ADDR]);
-		return ret;
-	}
-
-	if (get_cb_field(&in[CB_FLD_SRC_PORT], &temp, 0, UINT16_MAX, 0))
-		return -EINVAL;
-	ntuple_filter->src_port = (uint16_t)temp;
-
-	if (strncmp(in[CB_FLD_SRC_PORT_DLM], cb_port_delim,
-			sizeof(cb_port_delim)) != 0)
-		return -EINVAL;
-
-	if (get_cb_field(&in[CB_FLD_SRC_PORT_MASK], &temp, 0, UINT16_MAX, 0))
-		return -EINVAL;
-	ntuple_filter->src_port_mask = (uint16_t)temp;
-
-	if (get_cb_field(&in[CB_FLD_DST_PORT], &temp, 0, UINT16_MAX, 0))
-		return -EINVAL;
-	ntuple_filter->dst_port = (uint16_t)temp;
-
-	if (strncmp(in[CB_FLD_DST_PORT_DLM], cb_port_delim,
-			sizeof(cb_port_delim)) != 0)
-		return -EINVAL;
-
-	if (get_cb_field(&in[CB_FLD_DST_PORT_MASK], &temp, 0, UINT16_MAX, 0))
-		return -EINVAL;
-	ntuple_filter->dst_port_mask = (uint16_t)temp;
-
-	if (get_cb_field(&in[CB_FLD_PROTO], &temp, 0, UINT8_MAX, '/'))
-		return -EINVAL;
-	ntuple_filter->proto = (uint8_t)temp;
-
-	if (get_cb_field(&in[CB_FLD_PROTO], &temp, 0, UINT8_MAX, 0))
-		return -EINVAL;
-	ntuple_filter->proto_mask = (uint8_t)temp;
-
-	if (get_cb_field(&in[CB_FLD_PRIORITY], &temp, 0, UINT16_MAX, 0))
-		return -EINVAL;
-	ntuple_filter->priority = (uint16_t)temp;
-	if (ntuple_filter->priority > FLOW_CLASSIFY_MAX_PRIORITY)
-		ret = -EINVAL;
-
-	return ret;
-}
-
-/* Bypass comment and empty lines */
-static inline int
-is_bypass_line(char *buff)
-{
-	int i = 0;
-
-	/* comment line */
-	if (buff[0] == COMMENT_LEAD_CHAR)
-		return 1;
-	/* empty line */
-	while (buff[i] != '\0') {
-		if (!isspace(buff[i]))
-			return 0;
-		i++;
-	}
-	return 1;
-}
-
-static uint32_t
-convert_depth_to_bitmask(uint32_t depth_val)
-{
-	uint32_t bitmask = 0;
-	int i, j;
-
-	for (i = depth_val, j = 0; i > 0; i--, j++)
-		bitmask |= (1 << (31 - j));
-	return bitmask;
-}
-
-static int
-add_classify_rule(struct rte_eth_ntuple_filter *ntuple_filter,
-		struct flow_classifier *cls_app)
-{
-	int ret = -1;
-	int key_found;
-	struct rte_flow_error error;
-	struct rte_flow_item_ipv4 ipv4_spec;
-	struct rte_flow_item_ipv4 ipv4_mask;
-	struct rte_flow_item ipv4_udp_item;
-	struct rte_flow_item ipv4_tcp_item;
-	struct rte_flow_item ipv4_sctp_item;
-	struct rte_flow_item_udp udp_spec;
-	struct rte_flow_item_udp udp_mask;
-	struct rte_flow_item udp_item;
-	struct rte_flow_item_tcp tcp_spec;
-	struct rte_flow_item_tcp tcp_mask;
-	struct rte_flow_item tcp_item;
-	struct rte_flow_item_sctp sctp_spec;
-	struct rte_flow_item_sctp sctp_mask;
-	struct rte_flow_item sctp_item;
-	struct rte_flow_item pattern_ipv4_5tuple[4];
-	struct rte_flow_classify_rule *rule;
-	uint8_t ipv4_proto;
-
-	if (num_classify_rules >= MAX_NUM_CLASSIFY) {
-		printf(
-			"\nINFO:  classify rule capacity %d reached\n",
-			num_classify_rules);
-		return ret;
-	}
-
-	/* set up parameters for validate and add */
-	memset(&ipv4_spec, 0, sizeof(ipv4_spec));
-	ipv4_spec.hdr.next_proto_id = ntuple_filter->proto;
-	ipv4_spec.hdr.src_addr = ntuple_filter->src_ip;
-	ipv4_spec.hdr.dst_addr = ntuple_filter->dst_ip;
-	ipv4_proto = ipv4_spec.hdr.next_proto_id;
-
-	memset(&ipv4_mask, 0, sizeof(ipv4_mask));
-	ipv4_mask.hdr.next_proto_id = ntuple_filter->proto_mask;
-	ipv4_mask.hdr.src_addr = ntuple_filter->src_ip_mask;
-	ipv4_mask.hdr.src_addr =
-		convert_depth_to_bitmask(ipv4_mask.hdr.src_addr);
-	ipv4_mask.hdr.dst_addr = ntuple_filter->dst_ip_mask;
-	ipv4_mask.hdr.dst_addr =
-		convert_depth_to_bitmask(ipv4_mask.hdr.dst_addr);
-
-	switch (ipv4_proto) {
-	case IPPROTO_UDP:
-		ipv4_udp_item.type = RTE_FLOW_ITEM_TYPE_IPV4;
-		ipv4_udp_item.spec = &ipv4_spec;
-		ipv4_udp_item.mask = &ipv4_mask;
-		ipv4_udp_item.last = NULL;
-
-		udp_spec.hdr.src_port = ntuple_filter->src_port;
-		udp_spec.hdr.dst_port = ntuple_filter->dst_port;
-		udp_spec.hdr.dgram_len = 0;
-		udp_spec.hdr.dgram_cksum = 0;
-
-		udp_mask.hdr.src_port = ntuple_filter->src_port_mask;
-		udp_mask.hdr.dst_port = ntuple_filter->dst_port_mask;
-		udp_mask.hdr.dgram_len = 0;
-		udp_mask.hdr.dgram_cksum = 0;
-
-		udp_item.type = RTE_FLOW_ITEM_TYPE_UDP;
-		udp_item.spec = &udp_spec;
-		udp_item.mask = &udp_mask;
-		udp_item.last = NULL;
-
-		attr.priority = ntuple_filter->priority;
-		pattern_ipv4_5tuple[1] = ipv4_udp_item;
-		pattern_ipv4_5tuple[2] = udp_item;
-		break;
-	case IPPROTO_TCP:
-		ipv4_tcp_item.type = RTE_FLOW_ITEM_TYPE_IPV4;
-		ipv4_tcp_item.spec = &ipv4_spec;
-		ipv4_tcp_item.mask = &ipv4_mask;
-		ipv4_tcp_item.last = NULL;
-
-		memset(&tcp_spec, 0, sizeof(tcp_spec));
-		tcp_spec.hdr.src_port = ntuple_filter->src_port;
-		tcp_spec.hdr.dst_port = ntuple_filter->dst_port;
-
-		memset(&tcp_mask, 0, sizeof(tcp_mask));
-		tcp_mask.hdr.src_port = ntuple_filter->src_port_mask;
-		tcp_mask.hdr.dst_port = ntuple_filter->dst_port_mask;
-
-		tcp_item.type = RTE_FLOW_ITEM_TYPE_TCP;
-		tcp_item.spec = &tcp_spec;
-		tcp_item.mask = &tcp_mask;
-		tcp_item.last = NULL;
-
-		attr.priority = ntuple_filter->priority;
-		pattern_ipv4_5tuple[1] = ipv4_tcp_item;
-		pattern_ipv4_5tuple[2] = tcp_item;
-		break;
-	case IPPROTO_SCTP:
-		ipv4_sctp_item.type = RTE_FLOW_ITEM_TYPE_IPV4;
-		ipv4_sctp_item.spec = &ipv4_spec;
-		ipv4_sctp_item.mask = &ipv4_mask;
-		ipv4_sctp_item.last = NULL;
-
-		sctp_spec.hdr.src_port = ntuple_filter->src_port;
-		sctp_spec.hdr.dst_port = ntuple_filter->dst_port;
-		sctp_spec.hdr.cksum = 0;
-		sctp_spec.hdr.tag = 0;
-
-		sctp_mask.hdr.src_port = ntuple_filter->src_port_mask;
-		sctp_mask.hdr.dst_port = ntuple_filter->dst_port_mask;
-		sctp_mask.hdr.cksum = 0;
-		sctp_mask.hdr.tag = 0;
-
-		sctp_item.type = RTE_FLOW_ITEM_TYPE_SCTP;
-		sctp_item.spec = &sctp_spec;
-		sctp_item.mask = &sctp_mask;
-		sctp_item.last = NULL;
-
-		attr.priority = ntuple_filter->priority;
-		pattern_ipv4_5tuple[1] = ipv4_sctp_item;
-		pattern_ipv4_5tuple[2] = sctp_item;
-		break;
-	default:
-		return ret;
-	}
-
-	attr.ingress = 1;
-	pattern_ipv4_5tuple[0] = eth_item;
-	pattern_ipv4_5tuple[3] = end_item;
-	actions[0] = count_action;
-	actions[1] = end_action;
-
-	/* Validate and add rule */
-	ret = rte_flow_classify_validate(cls_app->cls, &attr,
-			pattern_ipv4_5tuple, actions, &error);
-	if (ret) {
-		printf("table entry validate failed ipv4_proto = %u\n",
-			ipv4_proto);
-		return ret;
-	}
-
-	rule = rte_flow_classify_table_entry_add(
-			cls_app->cls, &attr, pattern_ipv4_5tuple,
-			actions, &key_found, &error);
-	if (rule == NULL) {
-		printf("table entry add failed ipv4_proto = %u\n",
-			ipv4_proto);
-		ret = -1;
-		return ret;
-	}
-
-	rules[num_classify_rules] = rule;
-	num_classify_rules++;
-	return 0;
-}
-
-static int
-add_rules(const char *rule_path, struct flow_classifier *cls_app)
-{
-	FILE *fh;
-	char buff[LINE_MAX];
-	unsigned int i = 0;
-	unsigned int total_num = 0;
-	struct rte_eth_ntuple_filter ntuple_filter;
-	int ret;
-
-	fh = fopen(rule_path, "rb");
-	if (fh == NULL)
-		rte_exit(EXIT_FAILURE, "%s: fopen %s failed\n", __func__,
-			rule_path);
-
-	ret = fseek(fh, 0, SEEK_SET);
-	if (ret)
-		rte_exit(EXIT_FAILURE, "%s: fseek %d failed\n", __func__,
-			ret);
-
-	i = 0;
-	while (fgets(buff, LINE_MAX, fh) != NULL) {
-		i++;
-
-		if (is_bypass_line(buff))
-			continue;
-
-		if (total_num >= FLOW_CLASSIFY_MAX_RULE_NUM - 1) {
-			printf("\nINFO: classify rule capacity %d reached\n",
-				total_num);
-			break;
-		}
-
-		if (parse_ipv4_5tuple_rule(buff, &ntuple_filter) != 0)
-			rte_exit(EXIT_FAILURE,
-				"%s Line %u: parse rules error\n",
-				rule_path, i);
-
-		if (add_classify_rule(&ntuple_filter, cls_app) != 0)
-			rte_exit(EXIT_FAILURE, "add rule error\n");
-
-		total_num++;
-	}
-
-	fclose(fh);
-	return 0;
-}
-
-/* display usage */
-static void
-print_usage(const char *prgname)
-{
-	printf("%s usage:\n", prgname);
-	printf("[EAL options] --  --"OPTION_RULE_IPV4"=FILE: ");
-	printf("specify the ipv4 rules file.\n");
-	printf("Each rule occupies one line in the file.\n");
-}
-
-/* Parse the argument given in the command line of the application */
-static int
-parse_args(int argc, char **argv)
-{
-	int opt, ret;
-	char **argvopt;
-	int option_index;
-	char *prgname = argv[0];
-	static struct option lgopts[] = {
-		{OPTION_RULE_IPV4, 1, 0, 0},
-		{NULL, 0, 0, 0}
-	};
-
-	argvopt = argv;
-
-	while ((opt = getopt_long(argc, argvopt, "",
-				lgopts, &option_index)) != EOF) {
-
-		switch (opt) {
-		/* long options */
-		case 0:
-			if (!strncmp(lgopts[option_index].name,
-					OPTION_RULE_IPV4,
-					sizeof(OPTION_RULE_IPV4)))
-				parm_config.rule_ipv4_name = optarg;
-			break;
-		default:
-			print_usage(prgname);
-			return -1;
-		}
-	}
-
-	if (optind >= 0)
-		argv[optind-1] = prgname;
-
-	ret = optind-1;
-	optind = 1; /* reset getopt lib */
-	return ret;
-}
-
-/*
- * The main function, which does initialization and calls the lcore_main
- * function.
- */
-int
-main(int argc, char *argv[])
-{
-	struct rte_mempool *mbuf_pool;
-	uint8_t nb_ports;
-	uint16_t portid;
-	int ret;
-	int socket_id;
-	struct rte_table_acl_params table_acl_params;
-	struct rte_flow_classify_table_params cls_table_params;
-	struct flow_classifier *cls_app;
-	struct rte_flow_classifier_params cls_params;
-	uint32_t size;
-
-	/* Initialize the Environment Abstraction Layer (EAL). */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Error with EAL initialization\n");
-
-	argc -= ret;
-	argv += ret;
-
-	/* parse application arguments (after the EAL ones) */
-	ret = parse_args(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid flow_classify parameters\n");
-
-	/* Check that there is an even number of ports to send/receive on. */
-	nb_ports = rte_eth_dev_count();
-	if (nb_ports < 2 || (nb_ports & 1))
-		rte_exit(EXIT_FAILURE, "Error: number of ports must be even\n");
-
-	/* Creates a new mempool in memory to hold the mbufs. */
-	mbuf_pool = rte_pktmbuf_pool_create("MBUF_POOL", NUM_MBUFS * nb_ports,
-		MBUF_CACHE_SIZE, 0, RTE_MBUF_DEFAULT_BUF_SIZE, rte_socket_id());
-
-	if (mbuf_pool == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot create mbuf pool\n");
-
-	/* Initialize all ports. */
-	RTE_ETH_FOREACH_DEV(portid)
-		if (port_init(portid, mbuf_pool) != 0)
-			rte_exit(EXIT_FAILURE, "Cannot init port %"PRIu8 "\n",
-					portid);
-
-	if (rte_lcore_count() > 1)
-		printf("\nWARNING: Too many lcores enabled. Only 1 used.\n");
-
-	socket_id = rte_eth_dev_socket_id(0);
-
-	/* Memory allocation */
-	size = RTE_CACHE_LINE_ROUNDUP(sizeof(struct flow_classifier_acl));
-	cls_app = rte_zmalloc(NULL, size, RTE_CACHE_LINE_SIZE);
-	if (cls_app == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot allocate classifier memory\n");
-
-	cls_params.name = "flow_classifier";
-	cls_params.socket_id = socket_id;
-
-	cls_app->cls = rte_flow_classifier_create(&cls_params);
-	if (cls_app->cls == NULL) {
-		rte_free(cls_app);
-		rte_exit(EXIT_FAILURE, "Cannot create classifier\n");
-	}
-
-	/* initialise ACL table params */
-	table_acl_params.name = "table_acl_ipv4_5tuple";
-	table_acl_params.n_rules = FLOW_CLASSIFY_MAX_RULE_NUM;
-	table_acl_params.n_rule_fields = RTE_DIM(ipv4_defs);
-	memcpy(table_acl_params.field_format, ipv4_defs, sizeof(ipv4_defs));
-
-	/* initialise table create params */
-	cls_table_params.ops = &rte_table_acl_ops;
-	cls_table_params.arg_create = &table_acl_params;
-	cls_table_params.type = RTE_FLOW_CLASSIFY_TABLE_ACL_IP4_5TUPLE;
-
-	ret = rte_flow_classify_table_create(cls_app->cls, &cls_table_params);
-	if (ret) {
-		rte_flow_classifier_free(cls_app->cls);
-		rte_free(cls_app);
-		rte_exit(EXIT_FAILURE, "Failed to create classifier table\n");
-	}
-
-	/* read file of IPv4 5 tuple rules and initialize parameters
-	 * for rte_flow_classify_validate and rte_flow_classify_table_entry_add
-	 * API's.
-	 */
-	if (add_rules(parm_config.rule_ipv4_name, cls_app)) {
-		rte_flow_classifier_free(cls_app->cls);
-		rte_free(cls_app);
-		rte_exit(EXIT_FAILURE, "Failed to add rules\n");
-	}
-
-	/* Call lcore_main on the master core only. */
-	lcore_main(cls_app);
-
-	return 0;
-}
diff --git a/examples/flow_classify/ipv4_rules_file.txt b/examples/flow_classify/ipv4_rules_file.txt
deleted file mode 100644
index dfa0631..0000000
--- a/examples/flow_classify/ipv4_rules_file.txt
+++ /dev/null
@@ -1,14 +0,0 @@
-#file format:
-#src_ip/masklen dst_ip/masklen src_port : mask dst_port : mask proto/mask priority
-#
-2.2.2.3/24 2.2.2.7/24 32 : 0xffff 33 : 0xffff 17/0xff 0
-9.9.9.3/24 9.9.9.7/24 32 : 0xffff 33 : 0xffff 17/0xff 1
-9.9.9.3/24 9.9.9.7/24 32 : 0xffff 33 : 0xffff 6/0xff 2
-9.9.8.3/24 9.9.8.7/24 32 : 0xffff 33 : 0xffff 6/0xff 3
-6.7.8.9/24 2.3.4.5/24 32 : 0x0000 33 : 0x0000 132/0xff 4
-6.7.8.9/32 192.168.0.36/32 10 : 0xffff 11 : 0xffff 6/0xfe 5
-6.7.8.9/24 192.168.0.36/24 10 : 0xffff 11 : 0xffff 6/0xfe 6
-6.7.8.9/16 192.168.0.36/16 10 : 0xffff 11 : 0xffff 6/0xfe 7
-6.7.8.9/8 192.168.0.36/8 10 : 0xffff 11 : 0xffff 6/0xfe 8
-#error rules
-#9.8.7.6/8 192.168.0.36/8 10 : 0xffff 11 : 0xffff 6/0xfe 9
\ No newline at end of file
diff --git a/examples/flow_classify/meson.build b/examples/flow_classify/meson.build
deleted file mode 100644
index 56472e6..0000000
--- a/examples/flow_classify/meson.build
+++ /dev/null
@@ -1,13 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-deps += 'flow_classify'
-allow_experimental_apis = true
-sources = files(
-	'flow_classify.c'
-)
diff --git a/examples/flow_filtering/Makefile b/examples/flow_filtering/Makefile
deleted file mode 100644
index 01bb4cd..0000000
--- a/examples/flow_filtering/Makefile
+++ /dev/null
@@ -1,83 +0,0 @@
-#
-#   BSD LICENSE
-#
-#   Copyright 2017 Mellanox.
-#
-#   Redistribution and use in source and binary forms, with or without
-#   modification, are permitted provided that the following conditions
-#   are met:
-#
-#     * Redistributions of source code must retain the above copyright
-#       notice, this list of conditions and the following disclaimer.
-#     * Redistributions in binary form must reproduce the above copyright
-#       notice, this list of conditions and the following disclaimer in
-#       the documentation and/or other materials provided with the
-#       distribution.
-#     * Neither the name of Mellanox nor the names of its
-#       contributors may be used to endorse or promote products derived
-#       from this software without specific prior written permission.
-#
-#   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-#   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-#   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-#   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-#   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-#   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-#   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-#   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-#   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-#   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-#   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-#
-
-APP = flow
-
-SRCS-y := main.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-
-endif
diff --git a/examples/flow_filtering/flow_blocks.c b/examples/flow_filtering/flow_blocks.c
deleted file mode 100644
index 61b045a..0000000
--- a/examples/flow_filtering/flow_blocks.c
+++ /dev/null
@@ -1,150 +0,0 @@
-/*-
- *   BSD LICENSE
- *
- *   Copyright 2017 Mellanox.
- *
- *   Redistribution and use in source and binary forms, with or without
- *   modification, are permitted provided that the following conditions
- *   are met:
- *
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above copyright
- *       notice, this list of conditions and the following disclaimer in
- *       the documentation and/or other materials provided with the
- *       distribution.
- *     * Neither the name of Mellanox nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#define MAX_PATTERN_NUM		4
-
-struct rte_flow *
-generate_ipv4_flow(uint16_t port_id, uint16_t rx_q,
-		uint32_t src_ip, uint32_t src_mask,
-		uint32_t dest_ip, uint32_t dest_mask,
-		struct rte_flow_error *error);
-
-
-/**
- * create a flow rule that sends packets with matching src and dest ip
- * to selected queue.
- *
- * @param port_id
- *   The selected port.
- * @param rx_q
- *   The selected target queue.
- * @param src_ip
- *   The src ip value to match the input packet.
- * @param src_mask
- *   The mask to apply to the src ip.
- * @param dest_ip
- *   The dest ip value to match the input packet.
- * @param dest_mask
- *   The mask to apply to the dest ip.
- * @param[out] error
- *   Perform verbose error reporting if not NULL.
- *
- * @return
- *   A flow if the rule could be created else return NULL.
- */
-struct rte_flow *
-generate_ipv4_flow(uint16_t port_id, uint16_t rx_q,
-		uint32_t src_ip, uint32_t src_mask,
-		uint32_t dest_ip, uint32_t dest_mask,
-		struct rte_flow_error *error)
-{
-	struct rte_flow_attr attr;
-	struct rte_flow_item pattern[MAX_PATTERN_NUM];
-	struct rte_flow_action action[MAX_PATTERN_NUM];
-	struct rte_flow *flow = NULL;
-	struct rte_flow_action_queue queue = { .index = rx_q };
-	struct rte_flow_item_eth eth_spec;
-	struct rte_flow_item_eth eth_mask;
-	struct rte_flow_item_vlan vlan_spec;
-	struct rte_flow_item_vlan vlan_mask;
-	struct rte_flow_item_ipv4 ip_spec;
-	struct rte_flow_item_ipv4 ip_mask;
-	int res;
-
-	memset(pattern, 0, sizeof(pattern));
-	memset(action, 0, sizeof(action));
-
-	/*
-	 * set the rule attribute.
-	 * in this case only ingress packets will be checked.
-	 */
-	memset(&attr, 0, sizeof(struct rte_flow_attr));
-	attr.ingress = 1;
-
-	/*
-	 * create the action sequence.
-	 * one action only,  move packet to queue
-	 */
-
-	action[0].type = RTE_FLOW_ACTION_TYPE_QUEUE;
-	action[0].conf = &queue;
-	action[1].type = RTE_FLOW_ACTION_TYPE_END;
-
-	/*
-	 * set the first level of the pattern (eth).
-	 * since in this example we just want to get the
-	 * ipv4 we set this level to allow all.
-	 */
-	memset(&eth_spec, 0, sizeof(struct rte_flow_item_eth));
-	memset(&eth_mask, 0, sizeof(struct rte_flow_item_eth));
-	eth_spec.type = 0;
-	eth_mask.type = 0;
-	pattern[0].type = RTE_FLOW_ITEM_TYPE_ETH;
-	pattern[0].spec = &eth_spec;
-	pattern[0].mask = &eth_mask;
-
-	/*
-	 * setting the second level of the pattern (vlan).
-	 * since in this example we just want to get the
-	 * ipv4 we also set this level to allow all.
-	 */
-	memset(&vlan_spec, 0, sizeof(struct rte_flow_item_vlan));
-	memset(&vlan_mask, 0, sizeof(struct rte_flow_item_vlan));
-	pattern[1].type = RTE_FLOW_ITEM_TYPE_VLAN;
-	pattern[1].spec = &vlan_spec;
-	pattern[1].mask = &vlan_mask;
-
-	/*
-	 * setting the third level of the pattern (ip).
-	 * in this example this is the level we care about
-	 * so we set it according to the parameters.
-	 */
-	memset(&ip_spec, 0, sizeof(struct rte_flow_item_ipv4));
-	memset(&ip_mask, 0, sizeof(struct rte_flow_item_ipv4));
-	ip_spec.hdr.dst_addr = htonl(dest_ip);
-	ip_mask.hdr.dst_addr = dest_mask;
-	ip_spec.hdr.src_addr = htonl(src_ip);
-	ip_mask.hdr.src_addr = src_mask;
-	pattern[2].type = RTE_FLOW_ITEM_TYPE_IPV4;
-	pattern[2].spec = &ip_spec;
-	pattern[2].mask = &ip_mask;
-
-	/* the final level must be always type end */
-	pattern[3].type = RTE_FLOW_ITEM_TYPE_END;
-
-	res = rte_flow_validate(port_id, &attr, pattern, action, error);
-	if (!res)
-		flow = rte_flow_create(port_id, &attr, pattern, action, error);
-
-	return flow;
-}
-
diff --git a/examples/flow_filtering/main.c b/examples/flow_filtering/main.c
deleted file mode 100644
index 0bb81a8..0000000
--- a/examples/flow_filtering/main.c
+++ /dev/null
@@ -1,276 +0,0 @@
-/*-
- *   BSD LICENSE
- *
- *   Copyright 2017 Mellanox.
- *
- *   Redistribution and use in source and binary forms, with or without
- *   modification, are permitted provided that the following conditions
- *   are met:
- *
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above copyright
- *       notice, this list of conditions and the following disclaimer in
- *       the documentation and/or other materials provided with the
- *       distribution.
- *     * Neither the name of Mellanox. nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <string.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <sys/types.h>
-#include <sys/queue.h>
-#include <netinet/in.h>
-#include <setjmp.h>
-#include <stdarg.h>
-#include <ctype.h>
-#include <errno.h>
-#include <getopt.h>
-#include <signal.h>
-#include <stdbool.h>
-
-#include <rte_eal.h>
-#include <rte_common.h>
-#include <rte_malloc.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-#include <rte_net.h>
-#include <rte_flow.h>
-#include <rte_cycles.h>
-
-static volatile bool force_quit;
-
-static uint16_t port_id;
-static uint16_t nr_queues = 5;
-static uint8_t selected_queue = 1;
-struct rte_mempool *mbuf_pool;
-struct rte_flow *flow;
-
-#define SRC_IP ((0<<24) + (0<<16) + (0<<8) + 0) /* src ip = 0.0.0.0 */
-#define DEST_IP ((192<<24) + (168<<16) + (1<<8) + 1) /* dest ip = 192.168.1.1 */
-#define FULL_MASK 0xffffffff /* full mask */
-#define EMPTY_MASK 0x0 /* empty mask */
-
-#include "flow_blocks.c"
-
-static inline void
-print_ether_addr(const char *what, struct ether_addr *eth_addr)
-{
-	char buf[ETHER_ADDR_FMT_SIZE];
-	ether_format_addr(buf, ETHER_ADDR_FMT_SIZE, eth_addr);
-	printf("%s%s", what, buf);
-}
-
-static void
-main_loop(void)
-{
-	struct rte_mbuf *mbufs[32];
-	struct ether_hdr *eth_hdr;
-	struct rte_flow_error error;
-	uint16_t nb_rx;
-	uint16_t i;
-	uint16_t j;
-
-	while (!force_quit) {
-		for (i = 0; i < nr_queues; i++) {
-			nb_rx = rte_eth_rx_burst(port_id,
-						i, mbufs, 32);
-			if (nb_rx) {
-				for (j = 0; j < nb_rx; j++) {
-					struct rte_mbuf *m = mbufs[j];
-
-					eth_hdr = rte_pktmbuf_mtod(m,
-							struct ether_hdr *);
-					print_ether_addr("src=",
-							&eth_hdr->s_addr);
-					print_ether_addr(" - dst=",
-							&eth_hdr->d_addr);
-					printf(" - queue=0x%x",
-							(unsigned int)i);
-					printf("\n");
-
-					rte_pktmbuf_free(m);
-				}
-			}
-		}
-	}
-
-	/* closing and releasing resources */
-	rte_flow_flush(port_id, &error);
-	rte_eth_dev_stop(port_id);
-	rte_eth_dev_close(port_id);
-}
-
-#define CHECK_INTERVAL 1000  /* 100ms */
-#define MAX_REPEAT_TIMES 90  /* 9s (90 * 100ms) in total */
-
-static void
-assert_link_status(void)
-{
-	struct rte_eth_link link;
-	uint8_t rep_cnt = MAX_REPEAT_TIMES;
-
-	memset(&link, 0, sizeof(link));
-	do {
-		rte_eth_link_get(port_id, &link);
-		if (link.link_status == ETH_LINK_UP)
-			break;
-		rte_delay_ms(CHECK_INTERVAL);
-	} while (--rep_cnt);
-
-	if (link.link_status == ETH_LINK_DOWN)
-		rte_exit(EXIT_FAILURE, ":: error: link is still down\n");
-}
-
-static void
-init_port(void)
-{
-	int ret;
-	uint16_t i;
-	struct rte_eth_conf port_conf = {
-		.rxmode = {
-			.split_hdr_size = 0,
-			.ignore_offload_bitfield = 1,
-			.offloads = DEV_RX_OFFLOAD_CRC_STRIP,
-		},
-		.txmode = {
-			.offloads =
-				DEV_TX_OFFLOAD_VLAN_INSERT |
-				DEV_TX_OFFLOAD_IPV4_CKSUM  |
-				DEV_TX_OFFLOAD_UDP_CKSUM   |
-				DEV_TX_OFFLOAD_TCP_CKSUM   |
-				DEV_TX_OFFLOAD_SCTP_CKSUM  |
-				DEV_TX_OFFLOAD_TCP_TSO,
-		},
-	};
-	struct rte_eth_txconf txq_conf;
-	struct rte_eth_rxconf rxq_conf;
-	struct rte_eth_dev_info dev_info;
-
-	printf(":: initializing port: %d\n", port_id);
-	ret = rte_eth_dev_configure(port_id,
-				nr_queues, nr_queues, &port_conf);
-	if (ret < 0) {
-		rte_exit(EXIT_FAILURE,
-			":: cannot configure device: err=%d, port=%u\n",
-			ret, port_id);
-	}
-
-	rte_eth_dev_info_get(port_id, &dev_info);
-	rxq_conf = dev_info.default_rxconf;
-	rxq_conf.offloads = port_conf.rxmode.offloads;
-	/* only set Rx queues: something we care only so far */
-	for (i = 0; i < nr_queues; i++) {
-		ret = rte_eth_rx_queue_setup(port_id, i, 512,
-				     rte_eth_dev_socket_id(port_id),
-				     &rxq_conf,
-				     mbuf_pool);
-		if (ret < 0) {
-			rte_exit(EXIT_FAILURE,
-				":: Rx queue setup failed: err=%d, port=%u\n",
-				ret, port_id);
-		}
-	}
-
-	txq_conf = dev_info.default_txconf;
-	txq_conf.offloads = port_conf.txmode.offloads;
-
-	for (i = 0; i < nr_queues; i++) {
-		ret = rte_eth_tx_queue_setup(port_id, i, 512,
-				rte_eth_dev_socket_id(port_id),
-				&txq_conf);
-		if (ret < 0) {
-			rte_exit(EXIT_FAILURE,
-				":: Tx queue setup failed: err=%d, port=%u\n",
-				ret, port_id);
-		}
-	}
-
-	rte_eth_promiscuous_enable(port_id);
-	ret = rte_eth_dev_start(port_id);
-	if (ret < 0) {
-		rte_exit(EXIT_FAILURE,
-			"rte_eth_dev_start:err=%d, port=%u\n",
-			ret, port_id);
-	}
-
-	assert_link_status();
-
-	printf(":: initializing port: %d done\n", port_id);
-}
-
-static void
-signal_handler(int signum)
-{
-	if (signum == SIGINT || signum == SIGTERM) {
-		printf("\n\nSignal %d received, preparing to exit...\n",
-				signum);
-		force_quit = true;
-	}
-}
-
-int
-main(int argc, char **argv)
-{
-	int ret;
-	uint8_t nr_ports;
-	struct rte_flow_error error;
-
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, ":: invalid EAL arguments\n");
-
-	force_quit = false;
-	signal(SIGINT, signal_handler);
-	signal(SIGTERM, signal_handler);
-
-	nr_ports = rte_eth_dev_count();
-	if (nr_ports == 0)
-		rte_exit(EXIT_FAILURE, ":: no Ethernet ports found\n");
-	port_id = 0;
-	if (nr_ports != 1) {
-		printf(":: warn: %d ports detected, but we use only one: port %u\n",
-			nr_ports, port_id);
-	}
-	mbuf_pool = rte_pktmbuf_pool_create("mbuf_pool", 4096, 128, 0,
-					    RTE_MBUF_DEFAULT_BUF_SIZE,
-					    rte_socket_id());
-	if (mbuf_pool == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot init mbuf pool\n");
-
-	init_port();
-
-	/* create flow for send packet with */
-	flow = generate_ipv4_flow(port_id, selected_queue,
-				SRC_IP, EMPTY_MASK,
-				DEST_IP, FULL_MASK, &error);
-	if (!flow) {
-		printf("Flow can't be created %d message: %s\n",
-			error.type,
-			error.message ? error.message : "(no stated reason)");
-		rte_exit(EXIT_FAILURE, "error in creating flow");
-	}
-
-	main_loop();
-
-	return 0;
-}
diff --git a/examples/flow_filtering/meson.build b/examples/flow_filtering/meson.build
deleted file mode 100644
index 407795c..0000000
--- a/examples/flow_filtering/meson.build
+++ /dev/null
@@ -1,11 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-sources = files(
-	'main.c',
-)
diff --git a/examples/helloworld/Makefile b/examples/helloworld/Makefile
deleted file mode 100644
index d66b526..0000000
--- a/examples/helloworld/Makefile
+++ /dev/null
@@ -1,56 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-# binary name
-APP = helloworld
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-
-endif
diff --git a/examples/helloworld/main.c b/examples/helloworld/main.c
deleted file mode 100644
index c922cfb..0000000
--- a/examples/helloworld/main.c
+++ /dev/null
@@ -1,47 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdio.h>
-#include <string.h>
-#include <stdint.h>
-#include <errno.h>
-#include <sys/queue.h>
-
-#include <rte_memory.h>
-#include <rte_launch.h>
-#include <rte_eal.h>
-#include <rte_per_lcore.h>
-#include <rte_lcore.h>
-#include <rte_debug.h>
-
-static int
-lcore_hello(__attribute__((unused)) void *arg)
-{
-	unsigned lcore_id;
-	lcore_id = rte_lcore_id();
-	printf("hello from core %u\n", lcore_id);
-	return 0;
-}
-
-int
-main(int argc, char **argv)
-{
-	int ret;
-	unsigned lcore_id;
-
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_panic("Cannot init EAL\n");
-
-	/* call lcore_hello() on every slave lcore */
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		rte_eal_remote_launch(lcore_hello, NULL, lcore_id);
-	}
-
-	/* call it on master lcore too */
-	lcore_hello(NULL);
-
-	rte_eal_mp_wait_lcore();
-	return 0;
-}
diff --git a/examples/helloworld/meson.build b/examples/helloworld/meson.build
deleted file mode 100644
index c34e11e..0000000
--- a/examples/helloworld/meson.build
+++ /dev/null
@@ -1,11 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-sources = files(
-	'main.c'
-)
diff --git a/examples/ip_fragmentation/Makefile b/examples/ip_fragmentation/Makefile
deleted file mode 100644
index 3b58ced..0000000
--- a/examples/ip_fragmentation/Makefile
+++ /dev/null
@@ -1,66 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-#
-
-# binary name
-APP = ip_fragmentation
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-
-# workaround for a gcc bug with noreturn attribute
-# http://gcc.gnu.org/bugzilla/show_bug.cgi?id=12603
-ifeq ($(CONFIG_RTE_TOOLCHAIN_GCC),y)
-CFLAGS_main.o += -Wno-return-type
-endif
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-
-endif
diff --git a/examples/ip_fragmentation/main.c b/examples/ip_fragmentation/main.c
deleted file mode 100644
index f525c3a..0000000
--- a/examples/ip_fragmentation/main.c
+++ /dev/null
@@ -1,1029 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <sys/types.h>
-#include <sys/param.h>
-#include <string.h>
-#include <sys/queue.h>
-#include <stdarg.h>
-#include <errno.h>
-#include <getopt.h>
-
-#include <rte_common.h>
-#include <rte_byteorder.h>
-#include <rte_log.h>
-#include <rte_memory.h>
-#include <rte_memcpy.h>
-#include <rte_eal.h>
-#include <rte_launch.h>
-#include <rte_atomic.h>
-#include <rte_cycles.h>
-#include <rte_prefetch.h>
-#include <rte_lcore.h>
-#include <rte_per_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_interrupts.h>
-#include <rte_random.h>
-#include <rte_debug.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-#include <rte_lpm.h>
-#include <rte_lpm6.h>
-#include <rte_ip.h>
-#include <rte_string_fns.h>
-
-#include <rte_ip_frag.h>
-
-#define RTE_LOGTYPE_IP_FRAG RTE_LOGTYPE_USER1
-
-/* allow max jumbo frame 9.5 KB */
-#define JUMBO_FRAME_MAX_SIZE	0x2600
-
-#define	ROUNDUP_DIV(a, b)	(((a) + (b) - 1) / (b))
-
-/*
- * Default byte size for the IPv6 Maximum Transfer Unit (MTU).
- * This value includes the size of IPv6 header.
- */
-#define	IPV4_MTU_DEFAULT	ETHER_MTU
-#define	IPV6_MTU_DEFAULT	ETHER_MTU
-
-/*
- * Default payload in bytes for the IPv6 packet.
- */
-#define	IPV4_DEFAULT_PAYLOAD	(IPV4_MTU_DEFAULT - sizeof(struct ipv4_hdr))
-#define	IPV6_DEFAULT_PAYLOAD	(IPV6_MTU_DEFAULT - sizeof(struct ipv6_hdr))
-
-/*
- * Max number of fragments per packet expected - defined by config file.
- */
-#define	MAX_PACKET_FRAG RTE_LIBRTE_IP_FRAG_MAX_FRAG
-
-#define NB_MBUF   8192
-
-#define MAX_PKT_BURST	32
-#define BURST_TX_DRAIN_US 100 /* TX drain every ~100us */
-
-/* Configure how many packets ahead to prefetch, when reading packets */
-#define PREFETCH_OFFSET	3
-
-/*
- * Configurable number of RX/TX ring descriptors
- */
-#define RTE_TEST_RX_DESC_DEFAULT 1024
-#define RTE_TEST_TX_DESC_DEFAULT 1024
-static uint16_t nb_rxd = RTE_TEST_RX_DESC_DEFAULT;
-static uint16_t nb_txd = RTE_TEST_TX_DESC_DEFAULT;
-
-/* ethernet addresses of ports */
-static struct ether_addr ports_eth_addr[RTE_MAX_ETHPORTS];
-
-#ifndef IPv4_BYTES
-#define IPv4_BYTES_FMT "%" PRIu8 ".%" PRIu8 ".%" PRIu8 ".%" PRIu8
-#define IPv4_BYTES(addr) \
-		(uint8_t) (((addr) >> 24) & 0xFF),\
-		(uint8_t) (((addr) >> 16) & 0xFF),\
-		(uint8_t) (((addr) >> 8) & 0xFF),\
-		(uint8_t) ((addr) & 0xFF)
-#endif
-
-#ifndef IPv6_BYTES
-#define IPv6_BYTES_FMT "%02x%02x:%02x%02x:%02x%02x:%02x%02x:"\
-                       "%02x%02x:%02x%02x:%02x%02x:%02x%02x"
-#define IPv6_BYTES(addr) \
-	addr[0],  addr[1], addr[2],  addr[3], \
-	addr[4],  addr[5], addr[6],  addr[7], \
-	addr[8],  addr[9], addr[10], addr[11],\
-	addr[12], addr[13],addr[14], addr[15]
-#endif
-
-#define IPV6_ADDR_LEN 16
-
-/* mask of enabled ports */
-static int enabled_port_mask = 0;
-
-static int rx_queue_per_lcore = 1;
-
-#define MBUF_TABLE_SIZE  (2 * MAX(MAX_PKT_BURST, MAX_PACKET_FRAG))
-
-struct mbuf_table {
-	uint16_t len;
-	struct rte_mbuf *m_table[MBUF_TABLE_SIZE];
-};
-
-struct rx_queue {
-	struct rte_mempool *direct_pool;
-	struct rte_mempool *indirect_pool;
-	struct rte_lpm *lpm;
-	struct rte_lpm6 *lpm6;
-	uint16_t portid;
-};
-
-#define MAX_RX_QUEUE_PER_LCORE 16
-#define MAX_TX_QUEUE_PER_PORT 16
-struct lcore_queue_conf {
-	uint16_t n_rx_queue;
-	uint16_t tx_queue_id[RTE_MAX_ETHPORTS];
-	struct rx_queue rx_queue_list[MAX_RX_QUEUE_PER_LCORE];
-	struct mbuf_table tx_mbufs[RTE_MAX_ETHPORTS];
-} __rte_cache_aligned;
-struct lcore_queue_conf lcore_queue_conf[RTE_MAX_LCORE];
-
-static struct rte_eth_conf port_conf = {
-	.rxmode = {
-		.max_rx_pkt_len = JUMBO_FRAME_MAX_SIZE,
-		.split_hdr_size = 0,
-		.ignore_offload_bitfield = 1,
-		.offloads = (DEV_RX_OFFLOAD_CHECKSUM |
-			     DEV_RX_OFFLOAD_JUMBO_FRAME |
-			     DEV_RX_OFFLOAD_CRC_STRIP),
-	},
-	.txmode = {
-		.mq_mode = ETH_MQ_TX_NONE,
-		.offloads = (DEV_TX_OFFLOAD_IPV4_CKSUM |
-			     DEV_TX_OFFLOAD_MULTI_SEGS),
-	},
-};
-
-/*
- * IPv4 forwarding table
- */
-struct l3fwd_ipv4_route {
-	uint32_t ip;
-	uint8_t  depth;
-	uint8_t  if_out;
-};
-
-struct l3fwd_ipv4_route l3fwd_ipv4_route_array[] = {
-		{IPv4(100,10,0,0), 16, 0},
-		{IPv4(100,20,0,0), 16, 1},
-		{IPv4(100,30,0,0), 16, 2},
-		{IPv4(100,40,0,0), 16, 3},
-		{IPv4(100,50,0,0), 16, 4},
-		{IPv4(100,60,0,0), 16, 5},
-		{IPv4(100,70,0,0), 16, 6},
-		{IPv4(100,80,0,0), 16, 7},
-};
-
-/*
- * IPv6 forwarding table
- */
-
-struct l3fwd_ipv6_route {
-	uint8_t ip[IPV6_ADDR_LEN];
-	uint8_t depth;
-	uint8_t if_out;
-};
-
-static struct l3fwd_ipv6_route l3fwd_ipv6_route_array[] = {
-	{{1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1}, 48, 0},
-	{{2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1}, 48, 1},
-	{{3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1}, 48, 2},
-	{{4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1}, 48, 3},
-	{{5,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1}, 48, 4},
-	{{6,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1}, 48, 5},
-	{{7,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1}, 48, 6},
-	{{8,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1}, 48, 7},
-};
-
-#define LPM_MAX_RULES         1024
-#define LPM6_MAX_RULES         1024
-#define LPM6_NUMBER_TBL8S (1 << 16)
-
-struct rte_lpm6_config lpm6_config = {
-		.max_rules = LPM6_MAX_RULES,
-		.number_tbl8s = LPM6_NUMBER_TBL8S,
-		.flags = 0
-};
-
-static struct rte_mempool *socket_direct_pool[RTE_MAX_NUMA_NODES];
-static struct rte_mempool *socket_indirect_pool[RTE_MAX_NUMA_NODES];
-static struct rte_lpm *socket_lpm[RTE_MAX_NUMA_NODES];
-static struct rte_lpm6 *socket_lpm6[RTE_MAX_NUMA_NODES];
-
-/* Send burst of packets on an output interface */
-static inline int
-send_burst(struct lcore_queue_conf *qconf, uint16_t n, uint16_t port)
-{
-	struct rte_mbuf **m_table;
-	int ret;
-	uint16_t queueid;
-
-	queueid = qconf->tx_queue_id[port];
-	m_table = (struct rte_mbuf **)qconf->tx_mbufs[port].m_table;
-
-	ret = rte_eth_tx_burst(port, queueid, m_table, n);
-	if (unlikely(ret < n)) {
-		do {
-			rte_pktmbuf_free(m_table[ret]);
-		} while (++ret < n);
-	}
-
-	return 0;
-}
-
-static inline void
-l3fwd_simple_forward(struct rte_mbuf *m, struct lcore_queue_conf *qconf,
-		uint8_t queueid, uint16_t port_in)
-{
-	struct rx_queue *rxq;
-	uint32_t i, len, next_hop;
-	uint8_t ipv6;
-	uint16_t port_out;
-	int32_t len2;
-
-	ipv6 = 0;
-	rxq = &qconf->rx_queue_list[queueid];
-
-	/* by default, send everything back to the source port */
-	port_out = port_in;
-
-	/* Remove the Ethernet header and trailer from the input packet */
-	rte_pktmbuf_adj(m, (uint16_t)sizeof(struct ether_hdr));
-
-	/* Build transmission burst */
-	len = qconf->tx_mbufs[port_out].len;
-
-	/* if this is an IPv4 packet */
-	if (RTE_ETH_IS_IPV4_HDR(m->packet_type)) {
-		struct ipv4_hdr *ip_hdr;
-		uint32_t ip_dst;
-		/* Read the lookup key (i.e. ip_dst) from the input packet */
-		ip_hdr = rte_pktmbuf_mtod(m, struct ipv4_hdr *);
-		ip_dst = rte_be_to_cpu_32(ip_hdr->dst_addr);
-
-		/* Find destination port */
-		if (rte_lpm_lookup(rxq->lpm, ip_dst, &next_hop) == 0 &&
-				(enabled_port_mask & 1 << next_hop) != 0) {
-			port_out = next_hop;
-
-			/* Build transmission burst for new port */
-			len = qconf->tx_mbufs[port_out].len;
-		}
-
-		/* if we don't need to do any fragmentation */
-		if (likely (IPV4_MTU_DEFAULT >= m->pkt_len)) {
-			qconf->tx_mbufs[port_out].m_table[len] = m;
-			len2 = 1;
-		} else {
-			len2 = rte_ipv4_fragment_packet(m,
-				&qconf->tx_mbufs[port_out].m_table[len],
-				(uint16_t)(MBUF_TABLE_SIZE - len),
-				IPV4_MTU_DEFAULT,
-				rxq->direct_pool, rxq->indirect_pool);
-
-			/* Free input packet */
-			rte_pktmbuf_free(m);
-
-			/* If we fail to fragment the packet */
-			if (unlikely (len2 < 0))
-				return;
-		}
-	} else if (RTE_ETH_IS_IPV6_HDR(m->packet_type)) {
-		/* if this is an IPv6 packet */
-		struct ipv6_hdr *ip_hdr;
-
-		ipv6 = 1;
-
-		/* Read the lookup key (i.e. ip_dst) from the input packet */
-		ip_hdr = rte_pktmbuf_mtod(m, struct ipv6_hdr *);
-
-		/* Find destination port */
-		if (rte_lpm6_lookup(rxq->lpm6, ip_hdr->dst_addr,
-						&next_hop) == 0 &&
-				(enabled_port_mask & 1 << next_hop) != 0) {
-			port_out = next_hop;
-
-			/* Build transmission burst for new port */
-			len = qconf->tx_mbufs[port_out].len;
-		}
-
-		/* if we don't need to do any fragmentation */
-		if (likely (IPV6_MTU_DEFAULT >= m->pkt_len)) {
-			qconf->tx_mbufs[port_out].m_table[len] = m;
-			len2 = 1;
-		} else {
-			len2 = rte_ipv6_fragment_packet(m,
-				&qconf->tx_mbufs[port_out].m_table[len],
-				(uint16_t)(MBUF_TABLE_SIZE - len),
-				IPV6_MTU_DEFAULT,
-				rxq->direct_pool, rxq->indirect_pool);
-
-			/* Free input packet */
-			rte_pktmbuf_free(m);
-
-			/* If we fail to fragment the packet */
-			if (unlikely (len2 < 0))
-				return;
-		}
-	}
-	/* else, just forward the packet */
-	else {
-		qconf->tx_mbufs[port_out].m_table[len] = m;
-		len2 = 1;
-	}
-
-	for (i = len; i < len + len2; i ++) {
-		void *d_addr_bytes;
-
-		m = qconf->tx_mbufs[port_out].m_table[i];
-		struct ether_hdr *eth_hdr = (struct ether_hdr *)
-			rte_pktmbuf_prepend(m, (uint16_t)sizeof(struct ether_hdr));
-		if (eth_hdr == NULL) {
-			rte_panic("No headroom in mbuf.\n");
-		}
-
-		m->l2_len = sizeof(struct ether_hdr);
-
-		/* 02:00:00:00:00:xx */
-		d_addr_bytes = &eth_hdr->d_addr.addr_bytes[0];
-		*((uint64_t *)d_addr_bytes) = 0x000000000002 + ((uint64_t)port_out << 40);
-
-		/* src addr */
-		ether_addr_copy(&ports_eth_addr[port_out], &eth_hdr->s_addr);
-		if (ipv6)
-			eth_hdr->ether_type = rte_be_to_cpu_16(ETHER_TYPE_IPv6);
-		else
-			eth_hdr->ether_type = rte_be_to_cpu_16(ETHER_TYPE_IPv4);
-	}
-
-	len += len2;
-
-	if (likely(len < MAX_PKT_BURST)) {
-		qconf->tx_mbufs[port_out].len = (uint16_t)len;
-		return;
-	}
-
-	/* Transmit packets */
-	send_burst(qconf, (uint16_t)len, port_out);
-	qconf->tx_mbufs[port_out].len = 0;
-}
-
-/* main processing loop */
-static int
-main_loop(__attribute__((unused)) void *dummy)
-{
-	struct rte_mbuf *pkts_burst[MAX_PKT_BURST];
-	unsigned lcore_id;
-	uint64_t prev_tsc, diff_tsc, cur_tsc;
-	int i, j, nb_rx;
-	uint16_t portid;
-	struct lcore_queue_conf *qconf;
-	const uint64_t drain_tsc = (rte_get_tsc_hz() + US_PER_S - 1) / US_PER_S * BURST_TX_DRAIN_US;
-
-	prev_tsc = 0;
-
-	lcore_id = rte_lcore_id();
-	qconf = &lcore_queue_conf[lcore_id];
-
-	if (qconf->n_rx_queue == 0) {
-		RTE_LOG(INFO, IP_FRAG, "lcore %u has nothing to do\n", lcore_id);
-		return 0;
-	}
-
-	RTE_LOG(INFO, IP_FRAG, "entering main loop on lcore %u\n", lcore_id);
-
-	for (i = 0; i < qconf->n_rx_queue; i++) {
-
-		portid = qconf->rx_queue_list[i].portid;
-		RTE_LOG(INFO, IP_FRAG, " -- lcoreid=%u portid=%d\n", lcore_id,
-				portid);
-	}
-
-	while (1) {
-
-		cur_tsc = rte_rdtsc();
-
-		/*
-		 * TX burst queue drain
-		 */
-		diff_tsc = cur_tsc - prev_tsc;
-		if (unlikely(diff_tsc > drain_tsc)) {
-
-			/*
-			 * This could be optimized (use queueid instead of
-			 * portid), but it is not called so often
-			 */
-			for (portid = 0; portid < RTE_MAX_ETHPORTS; portid++) {
-				if (qconf->tx_mbufs[portid].len == 0)
-					continue;
-				send_burst(&lcore_queue_conf[lcore_id],
-					   qconf->tx_mbufs[portid].len,
-					   portid);
-				qconf->tx_mbufs[portid].len = 0;
-			}
-
-			prev_tsc = cur_tsc;
-		}
-
-		/*
-		 * Read packet from RX queues
-		 */
-		for (i = 0; i < qconf->n_rx_queue; i++) {
-
-			portid = qconf->rx_queue_list[i].portid;
-			nb_rx = rte_eth_rx_burst(portid, 0, pkts_burst,
-						 MAX_PKT_BURST);
-
-			/* Prefetch first packets */
-			for (j = 0; j < PREFETCH_OFFSET && j < nb_rx; j++) {
-				rte_prefetch0(rte_pktmbuf_mtod(
-						pkts_burst[j], void *));
-			}
-
-			/* Prefetch and forward already prefetched packets */
-			for (j = 0; j < (nb_rx - PREFETCH_OFFSET); j++) {
-				rte_prefetch0(rte_pktmbuf_mtod(pkts_burst[
-						j + PREFETCH_OFFSET], void *));
-				l3fwd_simple_forward(pkts_burst[j], qconf, i, portid);
-			}
-
-			/* Forward remaining prefetched packets */
-			for (; j < nb_rx; j++) {
-				l3fwd_simple_forward(pkts_burst[j], qconf, i, portid);
-			}
-		}
-	}
-}
-
-/* display usage */
-static void
-print_usage(const char *prgname)
-{
-	printf("%s [EAL options] -- -p PORTMASK [-q NQ]\n"
-	       "  -p PORTMASK: hexadecimal bitmask of ports to configure\n"
-	       "  -q NQ: number of queue (=ports) per lcore (default is 1)\n",
-	       prgname);
-}
-
-static int
-parse_portmask(const char *portmask)
-{
-	char *end = NULL;
-	unsigned long pm;
-
-	/* parse hexadecimal string */
-	pm = strtoul(portmask, &end, 16);
-	if ((portmask[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (pm == 0)
-		return -1;
-
-	return pm;
-}
-
-static int
-parse_nqueue(const char *q_arg)
-{
-	char *end = NULL;
-	unsigned long n;
-
-	/* parse hexadecimal string */
-	n = strtoul(q_arg, &end, 10);
-	if ((q_arg[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-	if (n == 0)
-		return -1;
-	if (n >= MAX_RX_QUEUE_PER_LCORE)
-		return -1;
-
-	return n;
-}
-
-/* Parse the argument given in the command line of the application */
-static int
-parse_args(int argc, char **argv)
-{
-	int opt, ret;
-	char **argvopt;
-	int option_index;
-	char *prgname = argv[0];
-	static struct option lgopts[] = {
-		{NULL, 0, 0, 0}
-	};
-
-	argvopt = argv;
-
-	while ((opt = getopt_long(argc, argvopt, "p:q:",
-				  lgopts, &option_index)) != EOF) {
-
-		switch (opt) {
-		/* portmask */
-		case 'p':
-			enabled_port_mask = parse_portmask(optarg);
-			if (enabled_port_mask < 0) {
-				printf("invalid portmask\n");
-				print_usage(prgname);
-				return -1;
-			}
-			break;
-
-		/* nqueue */
-		case 'q':
-			rx_queue_per_lcore = parse_nqueue(optarg);
-			if (rx_queue_per_lcore < 0) {
-				printf("invalid queue number\n");
-				print_usage(prgname);
-				return -1;
-			}
-			break;
-
-		/* long options */
-		case 0:
-			print_usage(prgname);
-			return -1;
-
-		default:
-			print_usage(prgname);
-			return -1;
-		}
-	}
-
-	if (enabled_port_mask == 0) {
-		printf("portmask not specified\n");
-		print_usage(prgname);
-		return -1;
-	}
-
-	if (optind >= 0)
-		argv[optind-1] = prgname;
-
-	ret = optind-1;
-	optind = 1; /* reset getopt lib */
-	return ret;
-}
-
-static void
-print_ethaddr(const char *name, struct ether_addr *eth_addr)
-{
-	char buf[ETHER_ADDR_FMT_SIZE];
-	ether_format_addr(buf, ETHER_ADDR_FMT_SIZE, eth_addr);
-	printf("%s%s", name, buf);
-}
-
-/* Check the link status of all ports in up to 9s, and print them finally */
-static void
-check_all_ports_link_status(uint32_t port_mask)
-{
-#define CHECK_INTERVAL 100 /* 100ms */
-#define MAX_CHECK_TIME 90 /* 9s (90 * 100ms) in total */
-	uint16_t portid;
-	uint8_t count, all_ports_up, print_flag = 0;
-	struct rte_eth_link link;
-
-	printf("\nChecking link status");
-	fflush(stdout);
-	for (count = 0; count <= MAX_CHECK_TIME; count++) {
-		all_ports_up = 1;
-		RTE_ETH_FOREACH_DEV(portid) {
-			if ((port_mask & (1 << portid)) == 0)
-				continue;
-			memset(&link, 0, sizeof(link));
-			rte_eth_link_get_nowait(portid, &link);
-			/* print link status if flag set */
-			if (print_flag == 1) {
-				if (link.link_status)
-					printf(
-					"Port%d Link Up .Speed %u Mbps - %s\n",
-						portid, link.link_speed,
-				(link.link_duplex == ETH_LINK_FULL_DUPLEX) ?
-					("full-duplex") : ("half-duplex\n"));
-				else
-					printf("Port %d Link Down\n", portid);
-				continue;
-			}
-			/* clear all_ports_up flag if any link down */
-			if (link.link_status == ETH_LINK_DOWN) {
-				all_ports_up = 0;
-				break;
-			}
-		}
-		/* after finally printing all link status, get out */
-		if (print_flag == 1)
-			break;
-
-		if (all_ports_up == 0) {
-			printf(".");
-			fflush(stdout);
-			rte_delay_ms(CHECK_INTERVAL);
-		}
-
-		/* set the print_flag if all ports up or timeout */
-		if (all_ports_up == 1 || count == (MAX_CHECK_TIME - 1)) {
-			print_flag = 1;
-			printf("\ndone\n");
-		}
-	}
-}
-
-/* Check L3 packet type detection capablity of the NIC port */
-static int
-check_ptype(int portid)
-{
-	int i, ret;
-	int ptype_l3_ipv4 = 0, ptype_l3_ipv6 = 0;
-	uint32_t ptype_mask = RTE_PTYPE_L3_MASK;
-
-	ret = rte_eth_dev_get_supported_ptypes(portid, ptype_mask, NULL, 0);
-	if (ret <= 0)
-		return 0;
-
-	uint32_t ptypes[ret];
-
-	ret = rte_eth_dev_get_supported_ptypes(portid, ptype_mask, ptypes, ret);
-	for (i = 0; i < ret; ++i) {
-		if (ptypes[i] & RTE_PTYPE_L3_IPV4)
-			ptype_l3_ipv4 = 1;
-		if (ptypes[i] & RTE_PTYPE_L3_IPV6)
-			ptype_l3_ipv6 = 1;
-	}
-
-	if (ptype_l3_ipv4 == 0)
-		printf("port %d cannot parse RTE_PTYPE_L3_IPV4\n", portid);
-
-	if (ptype_l3_ipv6 == 0)
-		printf("port %d cannot parse RTE_PTYPE_L3_IPV6\n", portid);
-
-	if (ptype_l3_ipv4 && ptype_l3_ipv6)
-		return 1;
-
-	return 0;
-
-}
-
-/* Parse packet type of a packet by SW */
-static inline void
-parse_ptype(struct rte_mbuf *m)
-{
-	struct ether_hdr *eth_hdr;
-	uint32_t packet_type = RTE_PTYPE_UNKNOWN;
-	uint16_t ether_type;
-
-	eth_hdr = rte_pktmbuf_mtod(m, struct ether_hdr *);
-	ether_type = eth_hdr->ether_type;
-	if (ether_type == rte_cpu_to_be_16(ETHER_TYPE_IPv4))
-		packet_type |= RTE_PTYPE_L3_IPV4_EXT_UNKNOWN;
-	else if (ether_type == rte_cpu_to_be_16(ETHER_TYPE_IPv6))
-		packet_type |= RTE_PTYPE_L3_IPV6_EXT_UNKNOWN;
-
-	m->packet_type = packet_type;
-}
-
-/* callback function to detect packet type for a queue of a port */
-static uint16_t
-cb_parse_ptype(uint16_t port __rte_unused, uint16_t queue __rte_unused,
-		   struct rte_mbuf *pkts[], uint16_t nb_pkts,
-		   uint16_t max_pkts __rte_unused,
-		   void *user_param __rte_unused)
-{
-	uint16_t i;
-
-	for (i = 0; i < nb_pkts; ++i)
-		parse_ptype(pkts[i]);
-
-	return nb_pkts;
-}
-
-static int
-init_routing_table(void)
-{
-	struct rte_lpm *lpm;
-	struct rte_lpm6 *lpm6;
-	int socket, ret;
-	unsigned i;
-
-	for (socket = 0; socket < RTE_MAX_NUMA_NODES; socket++) {
-		if (socket_lpm[socket]) {
-			lpm = socket_lpm[socket];
-			/* populate the LPM table */
-			for (i = 0; i < RTE_DIM(l3fwd_ipv4_route_array); i++) {
-				ret = rte_lpm_add(lpm,
-					l3fwd_ipv4_route_array[i].ip,
-					l3fwd_ipv4_route_array[i].depth,
-					l3fwd_ipv4_route_array[i].if_out);
-
-				if (ret < 0) {
-					RTE_LOG(ERR, IP_FRAG, "Unable to add entry %i to the l3fwd "
-						"LPM table\n", i);
-					return -1;
-				}
-
-				RTE_LOG(INFO, IP_FRAG, "Socket %i: adding route " IPv4_BYTES_FMT
-						"/%d (port %d)\n",
-					socket,
-					IPv4_BYTES(l3fwd_ipv4_route_array[i].ip),
-					l3fwd_ipv4_route_array[i].depth,
-					l3fwd_ipv4_route_array[i].if_out);
-			}
-		}
-
-		if (socket_lpm6[socket]) {
-			lpm6 = socket_lpm6[socket];
-			/* populate the LPM6 table */
-			for (i = 0; i < RTE_DIM(l3fwd_ipv6_route_array); i++) {
-				ret = rte_lpm6_add(lpm6,
-					l3fwd_ipv6_route_array[i].ip,
-					l3fwd_ipv6_route_array[i].depth,
-					l3fwd_ipv6_route_array[i].if_out);
-
-				if (ret < 0) {
-					RTE_LOG(ERR, IP_FRAG, "Unable to add entry %i to the l3fwd "
-						"LPM6 table\n", i);
-					return -1;
-				}
-
-				RTE_LOG(INFO, IP_FRAG, "Socket %i: adding route " IPv6_BYTES_FMT
-						"/%d (port %d)\n",
-					socket,
-					IPv6_BYTES(l3fwd_ipv6_route_array[i].ip),
-					l3fwd_ipv6_route_array[i].depth,
-					l3fwd_ipv6_route_array[i].if_out);
-			}
-		}
-	}
-	return 0;
-}
-
-static int
-init_mem(void)
-{
-	char buf[PATH_MAX];
-	struct rte_mempool *mp;
-	struct rte_lpm *lpm;
-	struct rte_lpm6 *lpm6;
-	struct rte_lpm_config lpm_config;
-	int socket;
-	unsigned lcore_id;
-
-	/* traverse through lcores and initialize structures on each socket */
-
-	for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-
-		if (rte_lcore_is_enabled(lcore_id) == 0)
-			continue;
-
-		socket = rte_lcore_to_socket_id(lcore_id);
-
-		if (socket == SOCKET_ID_ANY)
-			socket = 0;
-
-		if (socket_direct_pool[socket] == NULL) {
-			RTE_LOG(INFO, IP_FRAG, "Creating direct mempool on socket %i\n",
-					socket);
-			snprintf(buf, sizeof(buf), "pool_direct_%i", socket);
-
-			mp = rte_pktmbuf_pool_create(buf, NB_MBUF, 32,
-				0, RTE_MBUF_DEFAULT_BUF_SIZE, socket);
-			if (mp == NULL) {
-				RTE_LOG(ERR, IP_FRAG, "Cannot create direct mempool\n");
-				return -1;
-			}
-			socket_direct_pool[socket] = mp;
-		}
-
-		if (socket_indirect_pool[socket] == NULL) {
-			RTE_LOG(INFO, IP_FRAG, "Creating indirect mempool on socket %i\n",
-					socket);
-			snprintf(buf, sizeof(buf), "pool_indirect_%i", socket);
-
-			mp = rte_pktmbuf_pool_create(buf, NB_MBUF, 32, 0, 0,
-				socket);
-			if (mp == NULL) {
-				RTE_LOG(ERR, IP_FRAG, "Cannot create indirect mempool\n");
-				return -1;
-			}
-			socket_indirect_pool[socket] = mp;
-		}
-
-		if (socket_lpm[socket] == NULL) {
-			RTE_LOG(INFO, IP_FRAG, "Creating LPM table on socket %i\n", socket);
-			snprintf(buf, sizeof(buf), "IP_FRAG_LPM_%i", socket);
-
-			lpm_config.max_rules = LPM_MAX_RULES;
-			lpm_config.number_tbl8s = 256;
-			lpm_config.flags = 0;
-
-			lpm = rte_lpm_create(buf, socket, &lpm_config);
-			if (lpm == NULL) {
-				RTE_LOG(ERR, IP_FRAG, "Cannot create LPM table\n");
-				return -1;
-			}
-			socket_lpm[socket] = lpm;
-		}
-
-		if (socket_lpm6[socket] == NULL) {
-			RTE_LOG(INFO, IP_FRAG, "Creating LPM6 table on socket %i\n", socket);
-			snprintf(buf, sizeof(buf), "IP_FRAG_LPM_%i", socket);
-
-			lpm6 = rte_lpm6_create(buf, socket, &lpm6_config);
-			if (lpm6 == NULL) {
-				RTE_LOG(ERR, IP_FRAG, "Cannot create LPM table\n");
-				return -1;
-			}
-			socket_lpm6[socket] = lpm6;
-		}
-	}
-
-	return 0;
-}
-
-int
-main(int argc, char **argv)
-{
-	struct lcore_queue_conf *qconf;
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_txconf *txconf;
-	struct rx_queue *rxq;
-	int socket, ret;
-	unsigned nb_ports;
-	uint16_t queueid = 0;
-	unsigned lcore_id = 0, rx_lcore_id = 0;
-	uint32_t n_tx_queue, nb_lcores;
-	uint16_t portid;
-
-	/* init EAL */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "rte_eal_init failed");
-	argc -= ret;
-	argv += ret;
-
-	/* parse application arguments (after the EAL ones) */
-	ret = parse_args(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid arguments");
-
-	nb_ports = rte_eth_dev_count();
-	if (nb_ports == 0)
-		rte_exit(EXIT_FAILURE, "No ports found!\n");
-
-	nb_lcores = rte_lcore_count();
-
-	/* initialize structures (mempools, lpm etc.) */
-	if (init_mem() < 0)
-		rte_panic("Cannot initialize memory structures!\n");
-
-	/* check if portmask has non-existent ports */
-	if (enabled_port_mask & ~(RTE_LEN2MASK(nb_ports, unsigned)))
-		rte_exit(EXIT_FAILURE, "Non-existent ports in portmask!\n");
-
-	/* initialize all ports */
-	RTE_ETH_FOREACH_DEV(portid) {
-		struct rte_eth_conf local_port_conf = port_conf;
-		struct rte_eth_rxconf rxq_conf;
-
-		/* skip ports that are not enabled */
-		if ((enabled_port_mask & (1 << portid)) == 0) {
-			printf("Skipping disabled port %d\n", portid);
-			continue;
-		}
-
-		qconf = &lcore_queue_conf[rx_lcore_id];
-
-		/* limit the frame size to the maximum supported by NIC */
-		rte_eth_dev_info_get(portid, &dev_info);
-		local_port_conf.rxmode.max_rx_pkt_len = RTE_MIN(
-		    dev_info.max_rx_pktlen,
-		    local_port_conf.rxmode.max_rx_pkt_len);
-
-		/* get the lcore_id for this port */
-		while (rte_lcore_is_enabled(rx_lcore_id) == 0 ||
-		       qconf->n_rx_queue == (unsigned)rx_queue_per_lcore) {
-
-			rx_lcore_id ++;
-			if (rx_lcore_id >= RTE_MAX_LCORE)
-				rte_exit(EXIT_FAILURE, "Not enough cores\n");
-
-			qconf = &lcore_queue_conf[rx_lcore_id];
-		}
-
-		socket = (int) rte_lcore_to_socket_id(rx_lcore_id);
-		if (socket == SOCKET_ID_ANY)
-			socket = 0;
-
-		rxq = &qconf->rx_queue_list[qconf->n_rx_queue];
-		rxq->portid = portid;
-		rxq->direct_pool = socket_direct_pool[socket];
-		rxq->indirect_pool = socket_indirect_pool[socket];
-		rxq->lpm = socket_lpm[socket];
-		rxq->lpm6 = socket_lpm6[socket];
-		qconf->n_rx_queue++;
-
-		/* init port */
-		printf("Initializing port %d on lcore %u...", portid,
-		       rx_lcore_id);
-		fflush(stdout);
-
-		n_tx_queue = nb_lcores;
-		if (n_tx_queue > MAX_TX_QUEUE_PER_PORT)
-			n_tx_queue = MAX_TX_QUEUE_PER_PORT;
-		if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-			local_port_conf.txmode.offloads |=
-				DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-		ret = rte_eth_dev_configure(portid, 1, (uint16_t)n_tx_queue,
-					    &local_port_conf);
-		if (ret < 0) {
-			printf("\n");
-			rte_exit(EXIT_FAILURE, "Cannot configure device: "
-				"err=%d, port=%d\n",
-				ret, portid);
-		}
-
-		ret = rte_eth_dev_adjust_nb_rx_tx_desc(portid, &nb_rxd,
-					    &nb_txd);
-		if (ret < 0) {
-			printf("\n");
-			rte_exit(EXIT_FAILURE, "Cannot adjust number of "
-				"descriptors: err=%d, port=%d\n", ret, portid);
-		}
-
-		/* init one RX queue */
-		rxq_conf = dev_info.default_rxconf;
-		rxq_conf.offloads = local_port_conf.rxmode.offloads;
-		ret = rte_eth_rx_queue_setup(portid, 0, nb_rxd,
-					     socket, &rxq_conf,
-					     socket_direct_pool[socket]);
-		if (ret < 0) {
-			printf("\n");
-			rte_exit(EXIT_FAILURE, "rte_eth_rx_queue_setup: "
-				"err=%d, port=%d\n",
-				ret, portid);
-		}
-
-		rte_eth_macaddr_get(portid, &ports_eth_addr[portid]);
-		print_ethaddr(" Address:", &ports_eth_addr[portid]);
-		printf("\n");
-
-		/* init one TX queue per couple (lcore,port) */
-		queueid = 0;
-		for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-			if (rte_lcore_is_enabled(lcore_id) == 0)
-				continue;
-
-			socket = (int) rte_lcore_to_socket_id(lcore_id);
-			printf("txq=%u,%d ", lcore_id, queueid);
-			fflush(stdout);
-
-			txconf = &dev_info.default_txconf;
-			txconf->txq_flags = ETH_TXQ_FLAGS_IGNORE;
-			txconf->offloads = local_port_conf.txmode.offloads;
-			ret = rte_eth_tx_queue_setup(portid, queueid, nb_txd,
-						     socket, txconf);
-			if (ret < 0) {
-				printf("\n");
-				rte_exit(EXIT_FAILURE, "rte_eth_tx_queue_setup: "
-					"err=%d, port=%d\n", ret, portid);
-			}
-
-			qconf = &lcore_queue_conf[lcore_id];
-			qconf->tx_queue_id[portid] = queueid;
-			queueid++;
-		}
-
-		printf("\n");
-	}
-
-	printf("\n");
-
-	/* start ports */
-	RTE_ETH_FOREACH_DEV(portid) {
-		if ((enabled_port_mask & (1 << portid)) == 0) {
-			continue;
-		}
-		/* Start device */
-		ret = rte_eth_dev_start(portid);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "rte_eth_dev_start: err=%d, port=%d\n",
-				ret, portid);
-
-		rte_eth_promiscuous_enable(portid);
-
-		if (check_ptype(portid) == 0) {
-			rte_eth_add_rx_callback(portid, 0, cb_parse_ptype, NULL);
-			printf("Add Rx callback function to detect L3 packet type by SW :"
-				" port = %d\n", portid);
-		}
-	}
-
-	if (init_routing_table() < 0)
-		rte_exit(EXIT_FAILURE, "Cannot init routing table\n");
-
-	check_all_ports_link_status(enabled_port_mask);
-
-	/* launch per-lcore init on every lcore */
-	rte_eal_mp_remote_launch(main_loop, NULL, CALL_MASTER);
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		if (rte_eal_wait_lcore(lcore_id) < 0)
-			return -1;
-	}
-
-	return 0;
-}
diff --git a/examples/ip_fragmentation/meson.build b/examples/ip_fragmentation/meson.build
deleted file mode 100644
index 9782a6a..0000000
--- a/examples/ip_fragmentation/meson.build
+++ /dev/null
@@ -1,13 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-deps +=  ['ip_frag', 'lpm']
-allow_experimental_apis = true
-sources = files(
-	'main.c'
-)
diff --git a/examples/ip_pipeline/Makefile b/examples/ip_pipeline/Makefile
deleted file mode 100644
index 27f7cc6..0000000
--- a/examples/ip_pipeline/Makefile
+++ /dev/null
@@ -1,94 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-# binary name
-APP = ip_pipeline
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-SRCS-y += config_parse.c
-SRCS-y += parser.c
-SRCS-y += config_parse_tm.c
-SRCS-y += config_check.c
-SRCS-y += init.c
-SRCS-y += thread.c
-SRCS-y += thread_fe.c
-SRCS-y += cpu_core_map.c
-
-SRCS-y += pipeline_common_be.c
-SRCS-y += pipeline_common_fe.c
-SRCS-y += pipeline_master_be.c
-SRCS-y += pipeline_master.c
-SRCS-y += pipeline_passthrough_be.c
-SRCS-y += pipeline_passthrough.c
-SRCS-y += pipeline_firewall_be.c
-SRCS-y += pipeline_firewall.c
-SRCS-y += pipeline_flow_classification_be.c
-SRCS-y += pipeline_flow_classification.c
-SRCS-y += pipeline_flow_actions_be.c
-SRCS-y += pipeline_flow_actions.c
-SRCS-y += pipeline_routing_be.c
-SRCS-y += pipeline_routing.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-VPATH += pipeline
-CFLAGS += -I. -I./pipeline/
-
-OBJS := $(patsubst %.c,build/%.o,$(SRCS-y))
-
-build/%.o: %.c Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) -c $< -o $@
-
-build/$(APP)-shared: $(OBJS)
-	$(CC) $(OBJS) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(OBJS)
-	$(CC) $(OBJS) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP)* build/*.o
-	rmdir --ignore-fail-on-non-empty build
-
-else
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-VPATH += $(SRCDIR)/pipeline
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-INC += $(sort $(wildcard *.h)) $(sort $(wildcard pipeline/*.h))
-
-SRCS-$(CONFIG_RTE_LIBRTE_PIPELINE) := $(SRCS-y)
-
-CFLAGS += -I$(SRCDIR) -I$(SRCDIR)/pipeline
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS) -Wno-error=unused-function -Wno-error=unused-variable
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-
-endif
diff --git a/examples/ip_pipeline/app.h b/examples/ip_pipeline/app.h
deleted file mode 100644
index 907d4e7..0000000
--- a/examples/ip_pipeline/app.h
+++ /dev/null
@@ -1,1401 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#ifndef __INCLUDE_APP_H__
-#define __INCLUDE_APP_H__
-
-#include <stdint.h>
-#include <string.h>
-
-#include <rte_common.h>
-#include <rte_mempool.h>
-#include <rte_ring.h>
-#include <rte_sched.h>
-#include <cmdline_parse.h>
-
-#include <rte_ethdev.h>
-#ifdef RTE_LIBRTE_KNI
-#include <rte_kni.h>
-#endif
-
-#include "cpu_core_map.h"
-#include "pipeline.h"
-
-#define APP_PARAM_NAME_SIZE                      PIPELINE_NAME_SIZE
-#define APP_LINK_PCI_BDF_SIZE                    16
-
-#ifndef APP_LINK_MAX_HWQ_IN
-#define APP_LINK_MAX_HWQ_IN                      128
-#endif
-
-#ifndef APP_LINK_MAX_HWQ_OUT
-#define APP_LINK_MAX_HWQ_OUT                     128
-#endif
-
-struct app_mempool_params {
-	char *name;
-	uint32_t parsed;
-	uint32_t buffer_size;
-	uint32_t pool_size;
-	uint32_t cache_size;
-	uint32_t cpu_socket_id;
-};
-
-struct app_link_params {
-	char *name;
-	uint32_t parsed;
-	uint32_t pmd_id; /* Generated based on port mask */
-	uint32_t arp_q; /* 0 = Disabled (packets go to default queue 0) */
-	uint32_t tcp_syn_q; /* 0 = Disabled (pkts go to default queue) */
-	uint32_t ip_local_q; /* 0 = Disabled (pkts go to default queue 0) */
-	uint32_t tcp_local_q; /* 0 = Disabled (pkts go to default queue 0) */
-	uint32_t udp_local_q; /* 0 = Disabled (pkts go to default queue 0) */
-	uint32_t sctp_local_q; /* 0 = Disabled (pkts go to default queue 0) */
-	uint32_t rss_qs[APP_LINK_MAX_HWQ_IN];
-	uint32_t n_rss_qs;
-	uint64_t rss_proto_ipv4;
-	uint64_t rss_proto_ipv6;
-	uint64_t rss_proto_l2;
-	uint32_t promisc;
-	uint32_t state; /* DOWN = 0, UP = 1 */
-	uint32_t ip; /* 0 = Invalid */
-	uint32_t depth; /* Valid only when IP is valid */
-	uint64_t mac_addr; /* Read from HW */
-	char pci_bdf[APP_LINK_PCI_BDF_SIZE];
-
-	struct rte_eth_conf conf;
-};
-
-struct app_pktq_hwq_in_params {
-	char *name;
-	uint32_t parsed;
-	uint32_t mempool_id; /* Position in the app->mempool_params */
-	uint32_t size;
-	uint32_t burst;
-
-	struct rte_eth_rxconf conf;
-};
-
-struct app_pktq_hwq_out_params {
-	char *name;
-	uint32_t parsed;
-	uint32_t size;
-	uint32_t burst;
-	uint32_t dropless;
-	uint64_t n_retries;
-	struct rte_eth_txconf conf;
-};
-
-struct app_pktq_swq_params {
-	char *name;
-	uint32_t parsed;
-	uint32_t size;
-	uint32_t burst_read;
-	uint32_t burst_write;
-	uint32_t dropless;
-	uint64_t n_retries;
-	uint32_t cpu_socket_id;
-	uint32_t ipv4_frag;
-	uint32_t ipv6_frag;
-	uint32_t ipv4_ras;
-	uint32_t ipv6_ras;
-	uint32_t mtu;
-	uint32_t metadata_size;
-	uint32_t mempool_direct_id;
-	uint32_t mempool_indirect_id;
-};
-
-struct app_pktq_kni_params {
-	char *name;
-	uint32_t parsed;
-
-	uint32_t socket_id;
-	uint32_t core_id;
-	uint32_t hyper_th_id;
-	uint32_t force_bind;
-
-	uint32_t mempool_id; /* Position in the app->mempool_params */
-	uint32_t burst_read;
-	uint32_t burst_write;
-	uint32_t dropless;
-	uint64_t n_retries;
-};
-
-#ifndef APP_FILE_NAME_SIZE
-#define APP_FILE_NAME_SIZE                       256
-#endif
-
-#ifndef APP_MAX_SCHED_SUBPORTS
-#define APP_MAX_SCHED_SUBPORTS                   8
-#endif
-
-#ifndef APP_MAX_SCHED_PIPES
-#define APP_MAX_SCHED_PIPES                      4096
-#endif
-
-struct app_pktq_tm_params {
-	char *name;
-	uint32_t parsed;
-	const char *file_name;
-	struct rte_sched_port_params sched_port_params;
-	struct rte_sched_subport_params
-		sched_subport_params[APP_MAX_SCHED_SUBPORTS];
-	struct rte_sched_pipe_params
-		sched_pipe_profiles[RTE_SCHED_PIPE_PROFILES_PER_PORT];
-	int sched_pipe_to_profile[APP_MAX_SCHED_SUBPORTS * APP_MAX_SCHED_PIPES];
-	uint32_t burst_read;
-	uint32_t burst_write;
-};
-
-struct app_pktq_tap_params {
-	char *name;
-	uint32_t parsed;
-	uint32_t burst_read;
-	uint32_t burst_write;
-	uint32_t dropless;
-	uint64_t n_retries;
-	uint32_t mempool_id; /* Position in the app->mempool_params */
-};
-
-struct app_pktq_source_params {
-	char *name;
-	uint32_t parsed;
-	uint32_t mempool_id; /* Position in the app->mempool_params array */
-	uint32_t burst;
-	const char *file_name; /* Full path of PCAP file to be copied to mbufs */
-	uint32_t n_bytes_per_pkt;
-};
-
-struct app_pktq_sink_params {
-	char *name;
-	uint8_t parsed;
-	const char *file_name; /* Full path of PCAP file to be copied to mbufs */
-	uint32_t n_pkts_to_dump;
-};
-
-struct app_msgq_params {
-	char *name;
-	uint32_t parsed;
-	uint32_t size;
-	uint32_t cpu_socket_id;
-};
-
-enum app_pktq_in_type {
-	APP_PKTQ_IN_HWQ,
-	APP_PKTQ_IN_SWQ,
-	APP_PKTQ_IN_TM,
-	APP_PKTQ_IN_TAP,
-	APP_PKTQ_IN_KNI,
-	APP_PKTQ_IN_SOURCE,
-};
-
-struct app_pktq_in_params {
-	enum app_pktq_in_type type;
-	uint32_t id; /* Position in the appropriate app array */
-};
-
-enum app_pktq_out_type {
-	APP_PKTQ_OUT_HWQ,
-	APP_PKTQ_OUT_SWQ,
-	APP_PKTQ_OUT_TM,
-	APP_PKTQ_OUT_TAP,
-	APP_PKTQ_OUT_KNI,
-	APP_PKTQ_OUT_SINK,
-};
-
-struct app_pktq_out_params {
-	enum app_pktq_out_type type;
-	uint32_t id; /* Position in the appropriate app array */
-};
-
-#define APP_PIPELINE_TYPE_SIZE                   PIPELINE_TYPE_SIZE
-
-#define APP_MAX_PIPELINE_PKTQ_IN                 PIPELINE_MAX_PORT_IN
-#define APP_MAX_PIPELINE_PKTQ_OUT                PIPELINE_MAX_PORT_OUT
-#define APP_MAX_PIPELINE_MSGQ_IN                 PIPELINE_MAX_MSGQ_IN
-#define APP_MAX_PIPELINE_MSGQ_OUT                PIPELINE_MAX_MSGQ_OUT
-
-#define APP_MAX_PIPELINE_ARGS                    PIPELINE_MAX_ARGS
-
-struct app_pipeline_params {
-	char *name;
-	uint8_t parsed;
-
-	char type[APP_PIPELINE_TYPE_SIZE];
-
-	uint32_t socket_id;
-	uint32_t core_id;
-	uint32_t hyper_th_id;
-
-	struct app_pktq_in_params pktq_in[APP_MAX_PIPELINE_PKTQ_IN];
-	struct app_pktq_out_params pktq_out[APP_MAX_PIPELINE_PKTQ_OUT];
-	uint32_t msgq_in[APP_MAX_PIPELINE_MSGQ_IN];
-	uint32_t msgq_out[APP_MAX_PIPELINE_MSGQ_OUT];
-
-	uint32_t n_pktq_in;
-	uint32_t n_pktq_out;
-	uint32_t n_msgq_in;
-	uint32_t n_msgq_out;
-
-	uint32_t timer_period;
-
-	char *args_name[APP_MAX_PIPELINE_ARGS];
-	char *args_value[APP_MAX_PIPELINE_ARGS];
-	uint32_t n_args;
-};
-
-struct app_params;
-
-typedef void (*app_link_op)(struct app_params *app,
-	uint32_t link_id,
-	uint32_t up,
-	void *arg);
-
-#ifndef APP_MAX_PIPELINES
-#define APP_MAX_PIPELINES                        64
-#endif
-
-struct app_link_data {
-	app_link_op f_link[APP_MAX_PIPELINES];
-	void *arg[APP_MAX_PIPELINES];
-};
-
-struct app_pipeline_data {
-	void *be;
-	void *fe;
-	struct pipeline_type *ptype;
-	uint64_t timer_period;
-	uint32_t enabled;
-};
-
-struct app_thread_pipeline_data {
-	uint32_t pipeline_id;
-	void *be;
-	pipeline_be_op_run f_run;
-	pipeline_be_op_timer f_timer;
-	uint64_t timer_period;
-	uint64_t deadline;
-};
-
-#ifndef APP_MAX_THREAD_PIPELINES
-#define APP_MAX_THREAD_PIPELINES                 64
-#endif
-
-#ifndef APP_THREAD_TIMER_PERIOD
-#define APP_THREAD_TIMER_PERIOD                  1
-#endif
-
-struct app_thread_data {
-	struct app_thread_pipeline_data regular[APP_MAX_THREAD_PIPELINES];
-	struct app_thread_pipeline_data custom[APP_MAX_THREAD_PIPELINES];
-
-	uint32_t n_regular;
-	uint32_t n_custom;
-
-	uint64_t timer_period;
-	uint64_t thread_req_deadline;
-
-	uint64_t deadline;
-
-	struct rte_ring *msgq_in;
-	struct rte_ring *msgq_out;
-
-	uint64_t headroom_time;
-	uint64_t headroom_cycles;
-	double headroom_ratio;
-} __rte_cache_aligned;
-
-#ifndef APP_MAX_LINKS
-#define APP_MAX_LINKS                            16
-#endif
-
-struct app_eal_params {
-	/* Map lcore set to physical cpu set */
-	char *coremap;
-
-	/* Core ID that is used as master */
-	uint32_t master_lcore_present;
-	uint32_t master_lcore;
-
-	/* Number of memory channels */
-	uint32_t channels_present;
-	uint32_t channels;
-
-	/* Memory to allocate (see also --socket-mem) */
-	uint32_t memory_present;
-	uint32_t memory;
-
-	/* Force number of memory ranks (don't detect) */
-	uint32_t ranks_present;
-	uint32_t ranks;
-
-	/* Add a PCI device in black list. */
-	char *pci_blacklist[APP_MAX_LINKS];
-
-	/* Add a PCI device in white list. */
-	char *pci_whitelist[APP_MAX_LINKS];
-
-	/* Add a virtual device. */
-	char *vdev[APP_MAX_LINKS];
-
-	 /* Use VMware TSC map instead of native RDTSC */
-	uint32_t vmware_tsc_map_present;
-	int vmware_tsc_map;
-
-	 /* Type of this process (primary|secondary|auto) */
-	char *proc_type;
-
-	 /* Set syslog facility */
-	char *syslog;
-
-	/* Set default log level */
-	uint32_t log_level_present;
-	uint32_t log_level;
-
-	/* Display version information on startup */
-	uint32_t version_present;
-	int version;
-
-	/* This help */
-	uint32_t help_present;
-	int help;
-
-	 /* Use malloc instead of hugetlbfs */
-	uint32_t no_huge_present;
-	int no_huge;
-
-	/* Disable PCI */
-	uint32_t no_pci_present;
-	int no_pci;
-
-	/* Disable HPET */
-	uint32_t no_hpet_present;
-	int no_hpet;
-
-	/* No shared config (mmap'd files) */
-	uint32_t no_shconf_present;
-	int no_shconf;
-
-	/* Add driver */
-	char *add_driver;
-
-	/*  Memory to allocate on sockets (comma separated values)*/
-	char *socket_mem;
-
-	/* Directory where hugetlbfs is mounted */
-	char *huge_dir;
-
-	/* Prefix for hugepage filenames */
-	char *file_prefix;
-
-	/* Base virtual address */
-	char *base_virtaddr;
-
-	/* Create /dev/uioX (usually done by hotplug) */
-	uint32_t create_uio_dev_present;
-	int create_uio_dev;
-
-	/* Interrupt mode for VFIO (legacy|msi|msix) */
-	char *vfio_intr;
-
-	uint32_t parsed;
-};
-
-#ifndef APP_APPNAME_SIZE
-#define APP_APPNAME_SIZE                         256
-#endif
-
-#ifndef APP_MAX_MEMPOOLS
-#define APP_MAX_MEMPOOLS                         8
-#endif
-
-#define APP_MAX_HWQ_IN                  (APP_MAX_LINKS * APP_LINK_MAX_HWQ_IN)
-
-#define APP_MAX_HWQ_OUT                 (APP_MAX_LINKS * APP_LINK_MAX_HWQ_OUT)
-
-#ifndef APP_MAX_PKTQ_SWQ
-#define APP_MAX_PKTQ_SWQ                         256
-#endif
-
-#define APP_MAX_PKTQ_TM                          APP_MAX_LINKS
-
-#ifndef APP_MAX_PKTQ_TAP
-#define APP_MAX_PKTQ_TAP                         APP_MAX_LINKS
-#endif
-
-#define APP_MAX_PKTQ_KNI                         APP_MAX_LINKS
-
-#ifndef APP_MAX_PKTQ_SOURCE
-#define APP_MAX_PKTQ_SOURCE                      64
-#endif
-
-#ifndef APP_MAX_PKTQ_SINK
-#define APP_MAX_PKTQ_SINK                        64
-#endif
-
-#ifndef APP_MAX_MSGQ
-#define APP_MAX_MSGQ                             256
-#endif
-
-#ifndef APP_EAL_ARGC
-#define APP_EAL_ARGC                             64
-#endif
-
-#ifndef APP_MAX_PIPELINE_TYPES
-#define APP_MAX_PIPELINE_TYPES                   64
-#endif
-
-#ifndef APP_MAX_THREADS
-#define APP_MAX_THREADS                          RTE_MAX_LCORE
-#endif
-
-#ifndef APP_MAX_CMDS
-#define APP_MAX_CMDS                             64
-#endif
-
-#ifndef APP_THREAD_HEADROOM_STATS_COLLECT
-#define APP_THREAD_HEADROOM_STATS_COLLECT        1
-#endif
-
-#define APP_CORE_MASK_SIZE					\
-	(RTE_MAX_LCORE / 64 + ((RTE_MAX_LCORE % 64) ? 1 : 0))
-
-struct app_params {
-	/* Config */
-	char app_name[APP_APPNAME_SIZE];
-	const char *config_file;
-	const char *script_file;
-	const char *parser_file;
-	const char *output_file;
-	const char *preproc;
-	const char *preproc_args;
-	uint64_t port_mask;
-	uint32_t log_level;
-
-	struct app_eal_params eal_params;
-	struct app_mempool_params mempool_params[APP_MAX_MEMPOOLS];
-	struct app_link_params link_params[APP_MAX_LINKS];
-	struct app_pktq_hwq_in_params hwq_in_params[APP_MAX_HWQ_IN];
-	struct app_pktq_hwq_out_params hwq_out_params[APP_MAX_HWQ_OUT];
-	struct app_pktq_swq_params swq_params[APP_MAX_PKTQ_SWQ];
-	struct app_pktq_tm_params tm_params[APP_MAX_PKTQ_TM];
-	struct app_pktq_tap_params tap_params[APP_MAX_PKTQ_TAP];
-	struct app_pktq_kni_params kni_params[APP_MAX_PKTQ_KNI];
-	struct app_pktq_source_params source_params[APP_MAX_PKTQ_SOURCE];
-	struct app_pktq_sink_params sink_params[APP_MAX_PKTQ_SINK];
-	struct app_msgq_params msgq_params[APP_MAX_MSGQ];
-	struct app_pipeline_params pipeline_params[APP_MAX_PIPELINES];
-
-	uint32_t n_mempools;
-	uint32_t n_links;
-	uint32_t n_pktq_hwq_in;
-	uint32_t n_pktq_hwq_out;
-	uint32_t n_pktq_swq;
-	uint32_t n_pktq_tm;
-	uint32_t n_pktq_tap;
-	uint32_t n_pktq_kni;
-	uint32_t n_pktq_source;
-	uint32_t n_pktq_sink;
-	uint32_t n_msgq;
-	uint32_t n_pipelines;
-
-	/* Init */
-	char *eal_argv[1 + APP_EAL_ARGC];
-	struct cpu_core_map *core_map;
-	uint64_t core_mask[APP_CORE_MASK_SIZE];
-	struct rte_mempool *mempool[APP_MAX_MEMPOOLS];
-	struct app_link_data link_data[APP_MAX_LINKS];
-	struct rte_ring *swq[APP_MAX_PKTQ_SWQ];
-	struct rte_sched_port *tm[APP_MAX_PKTQ_TM];
-	int tap[APP_MAX_PKTQ_TAP];
-#ifdef RTE_LIBRTE_KNI
-	struct rte_kni *kni[APP_MAX_PKTQ_KNI];
-#endif /* RTE_LIBRTE_KNI */
-	struct rte_ring *msgq[APP_MAX_MSGQ];
-	struct pipeline_type pipeline_type[APP_MAX_PIPELINE_TYPES];
-	struct app_pipeline_data pipeline_data[APP_MAX_PIPELINES];
-	struct app_thread_data thread_data[APP_MAX_THREADS];
-	cmdline_parse_ctx_t cmds[APP_MAX_CMDS + 1];
-
-	int eal_argc;
-	uint32_t n_pipeline_types;
-	uint32_t n_cmds;
-};
-
-#define APP_PARAM_VALID(obj) ((obj)->name != NULL)
-
-#define APP_PARAM_COUNT(obj_array, n_objs)				\
-{									\
-	size_t i;							\
-									\
-	n_objs = 0;							\
-	for (i = 0; i < RTE_DIM(obj_array); i++)			\
-		if (APP_PARAM_VALID(&((obj_array)[i])))			\
-			n_objs++;					\
-}
-
-#define APP_PARAM_FIND(obj_array, key)					\
-({									\
-	ssize_t obj_idx;						\
-	const ssize_t obj_count = RTE_DIM(obj_array);			\
-									\
-	for (obj_idx = 0; obj_idx < obj_count; obj_idx++) {		\
-		if (!APP_PARAM_VALID(&((obj_array)[obj_idx])))		\
-			continue;					\
-									\
-		if (strcmp(key, (obj_array)[obj_idx].name) == 0)	\
-			break;						\
-	}								\
-	obj_idx < obj_count ? obj_idx : -ENOENT;			\
-})
-
-#define APP_PARAM_FIND_BY_ID(obj_array, prefix, id, obj)		\
-do {									\
-	char name[APP_PARAM_NAME_SIZE];					\
-	ssize_t pos;							\
-									\
-	sprintf(name, prefix "%" PRIu32, id);				\
-	pos = APP_PARAM_FIND(obj_array, name);				\
-	obj = (pos < 0) ? NULL : &((obj_array)[pos]);			\
-} while (0)
-
-#define APP_PARAM_GET_ID(obj, prefix, id)				\
-do									\
-	sscanf(obj->name, prefix "%" SCNu32, &id);				\
-while (0)								\
-
-#define	APP_CHECK(exp, fmt, ...)					\
-do {									\
-	if (!(exp)) {							\
-		fprintf(stderr, fmt "\n", ## __VA_ARGS__);		\
-		abort();						\
-	}								\
-} while (0)
-
-enum app_log_level {
-	APP_LOG_LEVEL_HIGH = 1,
-	APP_LOG_LEVEL_LOW,
-	APP_LOG_LEVELS
-};
-
-#define APP_LOG(app, level, fmt, ...)					\
-do {									\
-	if (app->log_level >= APP_LOG_LEVEL_ ## level)			\
-		fprintf(stdout, "[APP] " fmt "\n", ## __VA_ARGS__);	\
-} while (0)
-
-static inline uint32_t
-app_link_get_n_rxq(struct app_params *app, struct app_link_params *link)
-{
-	uint32_t n_rxq = 0, link_id, i;
-	uint32_t n_pktq_hwq_in = RTE_MIN(app->n_pktq_hwq_in,
-		RTE_DIM(app->hwq_in_params));
-
-	APP_PARAM_GET_ID(link, "LINK", link_id);
-
-	for (i = 0; i < n_pktq_hwq_in; i++) {
-		struct app_pktq_hwq_in_params *p = &app->hwq_in_params[i];
-		uint32_t rxq_link_id, rxq_queue_id;
-
-		sscanf(p->name, "RXQ%" SCNu32 ".%" SCNu32,
-			&rxq_link_id, &rxq_queue_id);
-		if (rxq_link_id == link_id)
-			n_rxq++;
-	}
-
-	return n_rxq;
-}
-
-static inline uint32_t
-app_link_get_n_txq(struct app_params *app, struct app_link_params *link)
-{
-	uint32_t n_txq = 0, link_id, i;
-	uint32_t n_pktq_hwq_out = RTE_MIN(app->n_pktq_hwq_out,
-		RTE_DIM(app->hwq_out_params));
-
-	APP_PARAM_GET_ID(link, "LINK", link_id);
-
-	for (i = 0; i < n_pktq_hwq_out; i++) {
-		struct app_pktq_hwq_out_params *p = &app->hwq_out_params[i];
-		uint32_t txq_link_id, txq_queue_id;
-
-		sscanf(p->name, "TXQ%" SCNu32 ".%" SCNu32,
-			&txq_link_id, &txq_queue_id);
-		if (txq_link_id == link_id)
-			n_txq++;
-	}
-
-	return n_txq;
-}
-
-static inline uint32_t
-app_rxq_get_readers(struct app_params *app, struct app_pktq_hwq_in_params *rxq)
-{
-	uint32_t pos = rxq - app->hwq_in_params;
-	uint32_t n_pipelines = RTE_MIN(app->n_pipelines,
-		RTE_DIM(app->pipeline_params));
-	uint32_t n_readers = 0, i;
-
-	for (i = 0; i < n_pipelines; i++) {
-		struct app_pipeline_params *p = &app->pipeline_params[i];
-		uint32_t n_pktq_in = RTE_MIN(p->n_pktq_in, RTE_DIM(p->pktq_in));
-		uint32_t j;
-
-		for (j = 0; j < n_pktq_in; j++) {
-			struct app_pktq_in_params *pktq = &p->pktq_in[j];
-
-			if ((pktq->type == APP_PKTQ_IN_HWQ) &&
-				(pktq->id == pos))
-				n_readers++;
-		}
-	}
-
-	return n_readers;
-}
-
-static inline uint32_t
-app_swq_get_readers(struct app_params *app, struct app_pktq_swq_params *swq)
-{
-	uint32_t pos = swq - app->swq_params;
-	uint32_t n_pipelines = RTE_MIN(app->n_pipelines,
-		RTE_DIM(app->pipeline_params));
-	uint32_t n_readers = 0, i;
-
-	for (i = 0; i < n_pipelines; i++) {
-		struct app_pipeline_params *p = &app->pipeline_params[i];
-		uint32_t n_pktq_in = RTE_MIN(p->n_pktq_in, RTE_DIM(p->pktq_in));
-		uint32_t j;
-
-		for (j = 0; j < n_pktq_in; j++) {
-			struct app_pktq_in_params *pktq = &p->pktq_in[j];
-
-			if ((pktq->type == APP_PKTQ_IN_SWQ) &&
-				(pktq->id == pos))
-				n_readers++;
-		}
-	}
-
-	return n_readers;
-}
-
-static inline struct app_pipeline_params *
-app_swq_get_reader(struct app_params *app,
-	struct app_pktq_swq_params *swq,
-	uint32_t *pktq_in_id)
-{
-	struct app_pipeline_params *reader = NULL;
-	uint32_t pos = swq - app->swq_params;
-	uint32_t n_pipelines = RTE_MIN(app->n_pipelines,
-		RTE_DIM(app->pipeline_params));
-	uint32_t n_readers = 0, id = 0, i;
-
-	for (i = 0; i < n_pipelines; i++) {
-		struct app_pipeline_params *p = &app->pipeline_params[i];
-		uint32_t n_pktq_in = RTE_MIN(p->n_pktq_in, RTE_DIM(p->pktq_in));
-		uint32_t j;
-
-		for (j = 0; j < n_pktq_in; j++) {
-			struct app_pktq_in_params *pktq = &p->pktq_in[j];
-
-			if ((pktq->type == APP_PKTQ_IN_SWQ) &&
-				(pktq->id == pos)) {
-				n_readers++;
-				reader = p;
-				id = j;
-			}
-		}
-	}
-
-	if (n_readers != 1)
-		return NULL;
-
-	*pktq_in_id = id;
-	return reader;
-}
-
-static inline uint32_t
-app_tm_get_readers(struct app_params *app, struct app_pktq_tm_params *tm)
-{
-	uint32_t pos = tm - app->tm_params;
-	uint32_t n_pipelines = RTE_MIN(app->n_pipelines,
-		RTE_DIM(app->pipeline_params));
-	uint32_t n_readers = 0, i;
-
-	for (i = 0; i < n_pipelines; i++) {
-		struct app_pipeline_params *p = &app->pipeline_params[i];
-		uint32_t n_pktq_in = RTE_MIN(p->n_pktq_in, RTE_DIM(p->pktq_in));
-		uint32_t j;
-
-		for (j = 0; j < n_pktq_in; j++) {
-			struct app_pktq_in_params *pktq = &p->pktq_in[j];
-
-			if ((pktq->type == APP_PKTQ_IN_TM) &&
-				(pktq->id == pos))
-				n_readers++;
-		}
-	}
-
-	return n_readers;
-}
-
-static inline struct app_pipeline_params *
-app_tm_get_reader(struct app_params *app,
-	struct app_pktq_tm_params *tm,
-	uint32_t *pktq_in_id)
-{
-	struct app_pipeline_params *reader = NULL;
-	uint32_t pos = tm - app->tm_params;
-	uint32_t n_pipelines = RTE_MIN(app->n_pipelines,
-		RTE_DIM(app->pipeline_params));
-	uint32_t n_readers = 0, id = 0, i;
-
-	for (i = 0; i < n_pipelines; i++) {
-		struct app_pipeline_params *p = &app->pipeline_params[i];
-		uint32_t n_pktq_in = RTE_MIN(p->n_pktq_in, RTE_DIM(p->pktq_in));
-		uint32_t j;
-
-		for (j = 0; j < n_pktq_in; j++) {
-			struct app_pktq_in_params *pktq = &p->pktq_in[j];
-
-			if ((pktq->type == APP_PKTQ_IN_TM) &&
-				(pktq->id == pos)) {
-				n_readers++;
-				reader = p;
-				id = j;
-			}
-		}
-	}
-
-	if (n_readers != 1)
-		return NULL;
-
-	*pktq_in_id = id;
-	return reader;
-}
-
-static inline uint32_t
-app_tap_get_readers(struct app_params *app, struct app_pktq_tap_params *tap)
-{
-	uint32_t pos = tap - app->tap_params;
-	uint32_t n_pipelines = RTE_MIN(app->n_pipelines,
-		RTE_DIM(app->pipeline_params));
-	uint32_t n_readers = 0, i;
-
-	for (i = 0; i < n_pipelines; i++) {
-		struct app_pipeline_params *p = &app->pipeline_params[i];
-		uint32_t n_pktq_in = RTE_MIN(p->n_pktq_in, RTE_DIM(p->pktq_in));
-		uint32_t j;
-
-		for (j = 0; j < n_pktq_in; j++) {
-			struct app_pktq_in_params *pktq = &p->pktq_in[j];
-
-			if ((pktq->type == APP_PKTQ_IN_TAP) &&
-				(pktq->id == pos))
-				n_readers++;
-		}
-	}
-
-	return n_readers;
-}
-
-static inline struct app_pipeline_params *
-app_tap_get_reader(struct app_params *app,
-	struct app_pktq_tap_params *tap,
-	uint32_t *pktq_in_id)
-{
-	struct app_pipeline_params *reader = NULL;
-	uint32_t pos = tap - app->tap_params;
-	uint32_t n_pipelines = RTE_MIN(app->n_pipelines,
-		RTE_DIM(app->pipeline_params));
-	uint32_t n_readers = 0, id = 0, i;
-
-	for (i = 0; i < n_pipelines; i++) {
-		struct app_pipeline_params *p = &app->pipeline_params[i];
-		uint32_t n_pktq_in = RTE_MIN(p->n_pktq_in, RTE_DIM(p->pktq_in));
-		uint32_t j;
-
-		for (j = 0; j < n_pktq_in; j++) {
-			struct app_pktq_in_params *pktq = &p->pktq_in[j];
-
-			if ((pktq->type == APP_PKTQ_IN_TAP) &&
-				(pktq->id == pos)) {
-				n_readers++;
-				reader = p;
-				id = j;
-			}
-		}
-	}
-
-	if (n_readers != 1)
-		return NULL;
-
-	*pktq_in_id = id;
-	return reader;
-}
-
-static inline uint32_t
-app_kni_get_readers(struct app_params *app, struct app_pktq_kni_params *kni)
-{
-	uint32_t pos = kni - app->kni_params;
-	uint32_t n_pipelines = RTE_MIN(app->n_pipelines,
-		RTE_DIM(app->pipeline_params));
-	uint32_t n_readers = 0, i;
-
-	for (i = 0; i < n_pipelines; i++) {
-		struct app_pipeline_params *p = &app->pipeline_params[i];
-		uint32_t n_pktq_in = RTE_MIN(p->n_pktq_in, RTE_DIM(p->pktq_in));
-		uint32_t j;
-
-		for (j = 0; j < n_pktq_in; j++) {
-			struct app_pktq_in_params *pktq = &p->pktq_in[j];
-
-			if ((pktq->type == APP_PKTQ_IN_KNI) &&
-				(pktq->id == pos))
-				n_readers++;
-		}
-	}
-
-	return n_readers;
-}
-
-static inline struct app_pipeline_params *
-app_kni_get_reader(struct app_params *app,
-				  struct app_pktq_kni_params *kni,
-				  uint32_t *pktq_in_id)
-{
-	struct app_pipeline_params *reader = NULL;
-	uint32_t pos = kni - app->kni_params;
-	uint32_t n_pipelines = RTE_MIN(app->n_pipelines,
-		RTE_DIM(app->pipeline_params));
-	uint32_t n_readers = 0, id = 0, i;
-
-	for (i = 0; i < n_pipelines; i++) {
-		struct app_pipeline_params *p = &app->pipeline_params[i];
-		uint32_t n_pktq_in = RTE_MIN(p->n_pktq_in, RTE_DIM(p->pktq_in));
-		uint32_t j;
-
-		for (j = 0; j < n_pktq_in; j++) {
-			struct app_pktq_in_params *pktq = &p->pktq_in[j];
-
-			if ((pktq->type == APP_PKTQ_IN_KNI) &&
-				(pktq->id == pos)) {
-				n_readers++;
-				reader = p;
-				id = j;
-			}
-		}
-	}
-
-	if (n_readers != 1)
-		return NULL;
-
-	*pktq_in_id = id;
-	return reader;
-}
-
-static inline uint32_t
-app_source_get_readers(struct app_params *app,
-struct app_pktq_source_params *source)
-{
-	uint32_t pos = source - app->source_params;
-	uint32_t n_pipelines = RTE_MIN(app->n_pipelines,
-		RTE_DIM(app->pipeline_params));
-	uint32_t n_readers = 0, i;
-
-	for (i = 0; i < n_pipelines; i++) {
-		struct app_pipeline_params *p = &app->pipeline_params[i];
-		uint32_t n_pktq_in = RTE_MIN(p->n_pktq_in, RTE_DIM(p->pktq_in));
-		uint32_t j;
-
-		for (j = 0; j < n_pktq_in; j++) {
-			struct app_pktq_in_params *pktq = &p->pktq_in[j];
-
-			if ((pktq->type == APP_PKTQ_IN_SOURCE) &&
-				(pktq->id == pos))
-				n_readers++;
-		}
-	}
-
-	return n_readers;
-}
-
-static inline uint32_t
-app_msgq_get_readers(struct app_params *app, struct app_msgq_params *msgq)
-{
-	uint32_t pos = msgq - app->msgq_params;
-	uint32_t n_pipelines = RTE_MIN(app->n_pipelines,
-		RTE_DIM(app->pipeline_params));
-	uint32_t n_readers = 0, i;
-
-	for (i = 0; i < n_pipelines; i++) {
-		struct app_pipeline_params *p = &app->pipeline_params[i];
-		uint32_t n_msgq_in = RTE_MIN(p->n_msgq_in, RTE_DIM(p->msgq_in));
-		uint32_t j;
-
-		for (j = 0; j < n_msgq_in; j++)
-			if (p->msgq_in[j] == pos)
-				n_readers++;
-	}
-
-	return n_readers;
-}
-
-static inline uint32_t
-app_txq_get_writers(struct app_params *app, struct app_pktq_hwq_out_params *txq)
-{
-	uint32_t pos = txq - app->hwq_out_params;
-	uint32_t n_pipelines = RTE_MIN(app->n_pipelines,
-		RTE_DIM(app->pipeline_params));
-	uint32_t n_writers = 0, i;
-
-	for (i = 0; i < n_pipelines; i++) {
-		struct app_pipeline_params *p = &app->pipeline_params[i];
-		uint32_t n_pktq_out = RTE_MIN(p->n_pktq_out,
-			RTE_DIM(p->pktq_out));
-		uint32_t j;
-
-		for (j = 0; j < n_pktq_out; j++) {
-			struct app_pktq_out_params *pktq = &p->pktq_out[j];
-
-			if ((pktq->type == APP_PKTQ_OUT_HWQ) &&
-				(pktq->id == pos))
-				n_writers++;
-		}
-	}
-
-	return n_writers;
-}
-
-static inline uint32_t
-app_swq_get_writers(struct app_params *app, struct app_pktq_swq_params *swq)
-{
-	uint32_t pos = swq - app->swq_params;
-	uint32_t n_pipelines = RTE_MIN(app->n_pipelines,
-		RTE_DIM(app->pipeline_params));
-	uint32_t n_writers = 0, i;
-
-	for (i = 0; i < n_pipelines; i++) {
-		struct app_pipeline_params *p = &app->pipeline_params[i];
-		uint32_t n_pktq_out = RTE_MIN(p->n_pktq_out,
-			RTE_DIM(p->pktq_out));
-		uint32_t j;
-
-		for (j = 0; j < n_pktq_out; j++) {
-			struct app_pktq_out_params *pktq = &p->pktq_out[j];
-
-			if ((pktq->type == APP_PKTQ_OUT_SWQ) &&
-				(pktq->id == pos))
-				n_writers++;
-		}
-	}
-
-	return n_writers;
-}
-
-static inline struct app_pipeline_params *
-app_swq_get_writer(struct app_params *app,
-	struct app_pktq_swq_params *swq,
-	uint32_t *pktq_out_id)
-{
-	struct app_pipeline_params *writer = NULL;
-	uint32_t pos = swq - app->swq_params;
-	uint32_t n_pipelines = RTE_MIN(app->n_pipelines,
-		RTE_DIM(app->pipeline_params));
-	uint32_t n_writers = 0, id = 0, i;
-
-	for (i = 0; i < n_pipelines; i++) {
-		struct app_pipeline_params *p = &app->pipeline_params[i];
-		uint32_t n_pktq_out = RTE_MIN(p->n_pktq_out,
-			RTE_DIM(p->pktq_out));
-		uint32_t j;
-
-		for (j = 0; j < n_pktq_out; j++) {
-			struct app_pktq_out_params *pktq = &p->pktq_out[j];
-
-			if ((pktq->type == APP_PKTQ_OUT_SWQ) &&
-				(pktq->id == pos)) {
-				n_writers++;
-				writer = p;
-				id = j;
-			}
-		}
-	}
-
-	if (n_writers != 1)
-		return NULL;
-
-	*pktq_out_id = id;
-	return writer;
-}
-
-static inline uint32_t
-app_tm_get_writers(struct app_params *app, struct app_pktq_tm_params *tm)
-{
-	uint32_t pos = tm - app->tm_params;
-	uint32_t n_pipelines = RTE_MIN(app->n_pipelines,
-		RTE_DIM(app->pipeline_params));
-	uint32_t n_writers = 0, i;
-
-	for (i = 0; i < n_pipelines; i++) {
-		struct app_pipeline_params *p = &app->pipeline_params[i];
-		uint32_t n_pktq_out = RTE_MIN(p->n_pktq_out,
-			RTE_DIM(p->pktq_out));
-		uint32_t j;
-
-		for (j = 0; j < n_pktq_out; j++) {
-			struct app_pktq_out_params *pktq = &p->pktq_out[j];
-
-			if ((pktq->type == APP_PKTQ_OUT_TM) &&
-				(pktq->id == pos))
-				n_writers++;
-		}
-	}
-
-	return n_writers;
-}
-
-static inline struct app_pipeline_params *
-app_tm_get_writer(struct app_params *app,
-	struct app_pktq_tm_params *tm,
-	uint32_t *pktq_out_id)
-{
-	struct app_pipeline_params *writer = NULL;
-	uint32_t pos = tm - app->tm_params;
-	uint32_t n_pipelines = RTE_MIN(app->n_pipelines,
-		RTE_DIM(app->pipeline_params));
-	uint32_t n_writers = 0, id = 0, i;
-
-	for (i = 0; i < n_pipelines; i++) {
-		struct app_pipeline_params *p = &app->pipeline_params[i];
-		uint32_t n_pktq_out = RTE_MIN(p->n_pktq_out,
-			RTE_DIM(p->pktq_out));
-		uint32_t j;
-
-		for (j = 0; j < n_pktq_out; j++) {
-			struct app_pktq_out_params *pktq = &p->pktq_out[j];
-
-			if ((pktq->type == APP_PKTQ_OUT_TM) &&
-				(pktq->id == pos)) {
-				n_writers++;
-				writer = p;
-				id = j;
-			}
-		}
-	}
-
-	if (n_writers != 1)
-		return NULL;
-
-	*pktq_out_id = id;
-	return writer;
-}
-
-static inline uint32_t
-app_tap_get_writers(struct app_params *app, struct app_pktq_tap_params *tap)
-{
-	uint32_t pos = tap - app->tap_params;
-	uint32_t n_pipelines = RTE_MIN(app->n_pipelines,
-		RTE_DIM(app->pipeline_params));
-	uint32_t n_writers = 0, i;
-
-	for (i = 0; i < n_pipelines; i++) {
-		struct app_pipeline_params *p = &app->pipeline_params[i];
-		uint32_t n_pktq_out = RTE_MIN(p->n_pktq_out,
-			RTE_DIM(p->pktq_out));
-		uint32_t j;
-
-		for (j = 0; j < n_pktq_out; j++) {
-			struct app_pktq_out_params *pktq = &p->pktq_out[j];
-
-		if ((pktq->type == APP_PKTQ_OUT_TAP) &&
-			(pktq->id == pos))
-			n_writers++;
-		}
-	}
-
-	return n_writers;
-}
-
-static inline struct app_pipeline_params *
-app_tap_get_writer(struct app_params *app,
-	struct app_pktq_tap_params *tap,
-	uint32_t *pktq_out_id)
-{
-	struct app_pipeline_params *writer = NULL;
-	uint32_t pos = tap - app->tap_params;
-	uint32_t n_pipelines = RTE_MIN(app->n_pipelines,
-		RTE_DIM(app->pipeline_params));
-	uint32_t n_writers = 0, id = 0, i;
-
-	for (i = 0; i < n_pipelines; i++) {
-		struct app_pipeline_params *p = &app->pipeline_params[i];
-		uint32_t n_pktq_out = RTE_MIN(p->n_pktq_out,
-			RTE_DIM(p->pktq_out));
-		uint32_t j;
-
-		for (j = 0; j < n_pktq_out; j++) {
-			struct app_pktq_out_params *pktq = &p->pktq_out[j];
-
-			if ((pktq->type == APP_PKTQ_OUT_TAP) &&
-				(pktq->id == pos)) {
-				n_writers++;
-				writer = p;
-				id = j;
-			}
-		}
-	}
-
-	if (n_writers != 1)
-		return NULL;
-
-	*pktq_out_id = id;
-	return writer;
-}
-
-static inline uint32_t
-app_kni_get_writers(struct app_params *app, struct app_pktq_kni_params *kni)
-{
-	uint32_t pos = kni - app->kni_params;
-	uint32_t n_pipelines = RTE_MIN(app->n_pipelines,
-		RTE_DIM(app->pipeline_params));
-	uint32_t n_writers = 0, i;
-
-	for (i = 0; i < n_pipelines; i++) {
-		struct app_pipeline_params *p = &app->pipeline_params[i];
-		uint32_t n_pktq_out = RTE_MIN(p->n_pktq_out,
-			RTE_DIM(p->pktq_out));
-		uint32_t j;
-
-		for (j = 0; j < n_pktq_out; j++) {
-			struct app_pktq_out_params *pktq = &p->pktq_out[j];
-
-			if ((pktq->type == APP_PKTQ_OUT_KNI) &&
-				(pktq->id == pos))
-				n_writers++;
-		}
-	}
-
-	return n_writers;
-}
-
-static inline struct app_pipeline_params *
-app_kni_get_writer(struct app_params *app,
-				  struct app_pktq_kni_params *kni,
-				  uint32_t *pktq_out_id)
-{
-	struct app_pipeline_params *writer = NULL;
-	uint32_t pos = kni - app->kni_params;
-	uint32_t n_pipelines = RTE_MIN(app->n_pipelines,
-		RTE_DIM(app->pipeline_params));
-	uint32_t n_writers = 0, id = 0, i;
-
-	for (i = 0; i < n_pipelines; i++) {
-		struct app_pipeline_params *p = &app->pipeline_params[i];
-		uint32_t n_pktq_out = RTE_MIN(p->n_pktq_out,
-			RTE_DIM(p->pktq_out));
-		uint32_t j;
-
-		for (j = 0; j < n_pktq_out; j++) {
-			struct app_pktq_out_params *pktq = &p->pktq_out[j];
-
-			if ((pktq->type == APP_PKTQ_OUT_KNI) &&
-				(pktq->id == pos)) {
-				n_writers++;
-				writer = p;
-				id = j;
-			}
-		}
-	}
-
-	if (n_writers != 1)
-		return NULL;
-
-	*pktq_out_id = id;
-	return writer;
-}
-
-static inline uint32_t
-app_sink_get_writers(struct app_params *app, struct app_pktq_sink_params *sink)
-{
-	uint32_t pos = sink - app->sink_params;
-	uint32_t n_pipelines = RTE_MIN(app->n_pipelines,
-		RTE_DIM(app->pipeline_params));
-	uint32_t n_writers = 0, i;
-
-	for (i = 0; i < n_pipelines; i++) {
-		struct app_pipeline_params *p = &app->pipeline_params[i];
-		uint32_t n_pktq_out = RTE_MIN(p->n_pktq_out,
-			RTE_DIM(p->pktq_out));
-		uint32_t j;
-
-		for (j = 0; j < n_pktq_out; j++) {
-			struct app_pktq_out_params *pktq = &p->pktq_out[j];
-
-			if ((pktq->type == APP_PKTQ_OUT_SINK) &&
-				(pktq->id == pos))
-				n_writers++;
-		}
-	}
-
-	return n_writers;
-}
-
-static inline uint32_t
-app_msgq_get_writers(struct app_params *app, struct app_msgq_params *msgq)
-{
-	uint32_t pos = msgq - app->msgq_params;
-	uint32_t n_pipelines = RTE_MIN(app->n_pipelines,
-		RTE_DIM(app->pipeline_params));
-	uint32_t n_writers = 0, i;
-
-	for (i = 0; i < n_pipelines; i++) {
-		struct app_pipeline_params *p = &app->pipeline_params[i];
-		uint32_t n_msgq_out = RTE_MIN(p->n_msgq_out,
-			RTE_DIM(p->msgq_out));
-		uint32_t j;
-
-		for (j = 0; j < n_msgq_out; j++)
-			if (p->msgq_out[j] == pos)
-				n_writers++;
-	}
-
-	return n_writers;
-}
-
-static inline struct app_link_params *
-app_get_link_for_rxq(struct app_params *app, struct app_pktq_hwq_in_params *p)
-{
-	char link_name[APP_PARAM_NAME_SIZE];
-	ssize_t link_param_idx;
-	uint32_t rxq_link_id, rxq_queue_id;
-
-	sscanf(p->name, "RXQ%" SCNu32 ".%" SCNu32,
-		&rxq_link_id, &rxq_queue_id);
-	sprintf(link_name, "LINK%" PRIu32, rxq_link_id);
-	link_param_idx = APP_PARAM_FIND(app->link_params, link_name);
-	APP_CHECK((link_param_idx >= 0),
-		"Cannot find %s for %s", link_name, p->name);
-
-	return &app->link_params[link_param_idx];
-}
-
-static inline struct app_link_params *
-app_get_link_for_txq(struct app_params *app, struct app_pktq_hwq_out_params *p)
-{
-	char link_name[APP_PARAM_NAME_SIZE];
-	ssize_t link_param_idx;
-	uint32_t txq_link_id, txq_queue_id;
-
-	sscanf(p->name, "TXQ%" SCNu32 ".%" SCNu32,
-		&txq_link_id, &txq_queue_id);
-	sprintf(link_name, "LINK%" PRIu32, txq_link_id);
-	link_param_idx = APP_PARAM_FIND(app->link_params, link_name);
-	APP_CHECK((link_param_idx >= 0),
-		"Cannot find %s for %s", link_name, p->name);
-
-	return &app->link_params[link_param_idx];
-}
-
-static inline struct app_link_params *
-app_get_link_for_tm(struct app_params *app, struct app_pktq_tm_params *p_tm)
-{
-	char link_name[APP_PARAM_NAME_SIZE];
-	uint32_t link_id;
-	ssize_t link_param_idx;
-
-	sscanf(p_tm->name, "TM%" PRIu32, &link_id);
-	sprintf(link_name, "LINK%" PRIu32, link_id);
-	link_param_idx = APP_PARAM_FIND(app->link_params, link_name);
-	APP_CHECK((link_param_idx >= 0),
-		"Cannot find %s for %s", link_name, p_tm->name);
-
-	return &app->link_params[link_param_idx];
-}
-
-static inline struct app_link_params *
-app_get_link_for_kni(struct app_params *app, struct app_pktq_kni_params *p_kni)
-{
-	char link_name[APP_PARAM_NAME_SIZE];
-	uint32_t link_id;
-	ssize_t link_param_idx;
-
-	sscanf(p_kni->name, "KNI%" PRIu32, &link_id);
-	sprintf(link_name, "LINK%" PRIu32, link_id);
-	link_param_idx = APP_PARAM_FIND(app->link_params, link_name);
-	APP_CHECK((link_param_idx >= 0),
-			  "Cannot find %s for %s", link_name, p_kni->name);
-
-	return &app->link_params[link_param_idx];
-}
-
-static inline uint32_t
-app_core_is_enabled(struct app_params *app, uint32_t lcore_id)
-{
-	return(app->core_mask[lcore_id / 64] &
-		(1LLU << (lcore_id % 64)));
-}
-
-static inline void
-app_core_enable_in_core_mask(struct app_params *app, int lcore_id)
-{
-	app->core_mask[lcore_id / 64] |= 1LLU << (lcore_id % 64);
-
-}
-
-static inline void
-app_core_build_core_mask_string(struct app_params *app, char *mask_buffer)
-{
-	int i;
-
-	mask_buffer[0] = '\0';
-	for (i = (int)RTE_DIM(app->core_mask); i > 0; i--) {
-		/* For Hex representation of bits in uint64_t */
-		char buffer[(64 / 8) * 2 + 1];
-		memset(buffer, 0, sizeof(buffer));
-		snprintf(buffer, sizeof(buffer), "%016" PRIx64,
-			 app->core_mask[i-1]);
-		strcat(mask_buffer, buffer);
-	}
-}
-
-void app_pipeline_params_get(struct app_params *app,
-	struct app_pipeline_params *p_in,
-	struct pipeline_params *p_out);
-
-int app_config_init(struct app_params *app);
-
-int app_config_args(struct app_params *app,
-	int argc, char **argv);
-
-int app_config_preproc(struct app_params *app);
-
-int app_config_parse(struct app_params *app,
-	const char *file_name);
-
-int app_config_parse_tm(struct app_params *app);
-
-void app_config_save(struct app_params *app,
-	const char *file_name);
-
-int app_config_check(struct app_params *app);
-
-int app_init(struct app_params *app);
-
-int app_post_init(struct app_params *app);
-
-int app_thread(void *arg);
-
-int app_pipeline_type_register(struct app_params *app,
-	struct pipeline_type *ptype);
-
-struct pipeline_type *app_pipeline_type_find(struct app_params *app,
-	char *name);
-
-void app_link_up_internal(struct app_params *app,
-	struct app_link_params *cp);
-
-void app_link_down_internal(struct app_params *app,
-	struct app_link_params *cp);
-
-#endif
diff --git a/examples/ip_pipeline/config/action.cfg b/examples/ip_pipeline/config/action.cfg
deleted file mode 100644
index 994ae94..0000000
--- a/examples/ip_pipeline/config/action.cfg
+++ /dev/null
@@ -1,68 +0,0 @@
-;   BSD LICENSE
-;
-;   Copyright(c) 2016 Intel Corporation. All rights reserved.
-;   All rights reserved.
-;
-;   Redistribution and use in source and binary forms, with or without
-;   modification, are permitted provided that the following conditions
-;   are met:
-;
-;     * Redistributions of source code must retain the above copyright
-;       notice, this list of conditions and the following disclaimer.
-;     * Redistributions in binary form must reproduce the above copyright
-;       notice, this list of conditions and the following disclaimer in
-;       the documentation and/or other materials provided with the
-;       distribution.
-;     * Neither the name of Intel Corporation nor the names of its
-;       contributors may be used to endorse or promote products derived
-;       from this software without specific prior written permission.
-;
-;   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-;   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-;   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-;   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-;   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-;   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-;   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-;   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-;   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-;   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-;   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-;             ________________
-; RXQ0.0 --->|                |---> TXQ0.0
-;            |                |
-; RXQ1.0 --->|                |---> TXQ1.0
-;            |      Flow      |
-; RXQ2.0 --->|     Actions    |---> TXQ2.0
-;            |                |
-; RXQ3.0 --->|                |---> TXQ3.0
-;            |________________|
-;
-;
-; Input packet: Ethernet/IPv4
-;
-; Packet buffer layout:
-; #	Field Name		Offset (Bytes)	Size (Bytes)
-; 0	Mbuf			0 		128
-; 1	Headroom		128 		128
-; 2	Ethernet header		256 		14
-; 3	IPv4 header		270 		20
-
-[EAL]
-log_level = 0
-
-[PIPELINE0]
-type = MASTER
-core = 0
-
-[PIPELINE1]
-type = FLOW_ACTIONS
-core = 1
-pktq_in = RXQ0.0 RXQ1.0 RXQ2.0 RXQ3.0
-pktq_out = TXQ0.0 TXQ1.0 TXQ2.0 TXQ3.0
-n_flows = 65536
-n_meters_per_flow = 4
-flow_id_offset = 286; ipdaddr
-ip_hdr_offset = 270
-color_offset = 128
diff --git a/examples/ip_pipeline/config/action.sh b/examples/ip_pipeline/config/action.sh
deleted file mode 100644
index 2986ae6..0000000
--- a/examples/ip_pipeline/config/action.sh
+++ /dev/null
@@ -1,119 +0,0 @@
-#
-# run ./config/action.sh
-#
-
-p 1 action flow 0 meter 0 trtcm 1250000000 1250000000 1000000 1000000
-p 1 action flow 0 policer 0 g G y Y r R
-p 1 action flow 0 meter 1 trtcm 1250000000 1250000000 1000000 1000000
-p 1 action flow 0 policer 1 g G y Y r R
-p 1 action flow 0 meter 2 trtcm 1250000000 1250000000 1000000 1000000
-p 1 action flow 0 policer 2 g G y Y r R
-p 1 action flow 0 meter 3 trtcm 1250000000 1250000000 1000000 1000000
-p 1 action flow 0 policer 3 g G y Y r R
-p 1 action flow 0 port 0
-
-p 1 action flow 1 meter 0 trtcm 1250000000 1250000000 1000000 1000000
-p 1 action flow 1 policer 0 g G y Y r R
-p 1 action flow 1 meter 1 trtcm 1250000000 1250000000 1000000 1000000
-p 1 action flow 1 policer 1 g G y Y r R
-p 1 action flow 1 meter 2 trtcm 1250000000 1250000000 1000000 1000000
-p 1 action flow 1 policer 2 g G y Y r R
-p 1 action flow 1 meter 3 trtcm 1250000000 1250000000 1000000 1000000
-p 1 action flow 1 policer 3 g G y Y r R
-p 1 action flow 1 port 1
-
-p 1 action flow 2 meter 0 trtcm 1250000000 1250000000 1000000 1000000
-p 1 action flow 2 policer 0 g G y Y r R
-p 1 action flow 2 meter 1 trtcm 1250000000 1250000000 1000000 1000000
-p 1 action flow 2 policer 1 g G y Y r R
-p 1 action flow 2 meter 2 trtcm 1250000000 1250000000 1000000 1000000
-p 1 action flow 2 policer 2 g G y Y r R
-p 1 action flow 2 meter 3 trtcm 1250000000 1250000000 1000000 1000000
-p 1 action flow 2 policer 3 g G y Y r R
-p 1 action flow 2 port 2
-
-p 1 action flow 3 meter 0 trtcm 1250000000 1250000000 1000000 1000000
-p 1 action flow 3 policer 0 g G y Y r R
-p 1 action flow 3 meter 1 trtcm 1250000000 1250000000 1000000 1000000
-p 1 action flow 3 policer 1 g G y Y r R
-p 1 action flow 3 meter 2 trtcm 1250000000 1250000000 1000000 1000000
-p 1 action flow 3 policer 2 g G y Y r R
-p 1 action flow 3 meter 3 trtcm 1250000000 1250000000 1000000 1000000
-p 1 action flow 3 policer 3 g G y Y r R
-p 1 action flow 3 port 3
-
-#p 1 action flow bulk ./config/action.txt
-
-#p 1 action flow ls
-
-p 1 action flow 0 stats
-p 1 action flow 1 stats
-p 1 action flow 2 stats
-p 1 action flow 3 stats
-
-p 1 action dscp 0 class 0 color G
-p 1 action dscp 1 class 1 color G
-p 1 action dscp 2 class 2 color G
-p 1 action dscp 3 class 3 color G
-p 1 action dscp 4 class 0 color G
-p 1 action dscp 5 class 1 color G
-p 1 action dscp 6 class 2 color G
-p 1 action dscp 7 class 3 color G
-p 1 action dscp 8 class 0 color G
-p 1 action dscp 9 class 1 color G
-p 1 action dscp 10 class 2 color G
-p 1 action dscp 11 class 3 color G
-p 1 action dscp 12 class 0 color G
-p 1 action dscp 13 class 1 color G
-p 1 action dscp 14 class 2 color G
-p 1 action dscp 15 class 3 color G
-p 1 action dscp 16 class 0 color G
-p 1 action dscp 17 class 1 color G
-p 1 action dscp 18 class 2 color G
-p 1 action dscp 19 class 3 color G
-p 1 action dscp 20 class 0 color G
-p 1 action dscp 21 class 1 color G
-p 1 action dscp 22 class 2 color G
-p 1 action dscp 23 class 3 color G
-p 1 action dscp 24 class 0 color G
-p 1 action dscp 25 class 1 color G
-p 1 action dscp 26 class 2 color G
-p 1 action dscp 27 class 3 color G
-p 1 action dscp 27 class 0 color G
-p 1 action dscp 29 class 1 color G
-p 1 action dscp 30 class 2 color G
-p 1 action dscp 31 class 3 color G
-p 1 action dscp 32 class 0 color G
-p 1 action dscp 33 class 1 color G
-p 1 action dscp 34 class 2 color G
-p 1 action dscp 35 class 3 color G
-p 1 action dscp 36 class 0 color G
-p 1 action dscp 37 class 1 color G
-p 1 action dscp 38 class 2 color G
-p 1 action dscp 39 class 3 color G
-p 1 action dscp 40 class 0 color G
-p 1 action dscp 41 class 1 color G
-p 1 action dscp 42 class 2 color G
-p 1 action dscp 43 class 3 color G
-p 1 action dscp 44 class 0 color G
-p 1 action dscp 45 class 1 color G
-p 1 action dscp 46 class 2 color G
-p 1 action dscp 47 class 3 color G
-p 1 action dscp 48 class 0 color G
-p 1 action dscp 49 class 1 color G
-p 1 action dscp 50 class 2 color G
-p 1 action dscp 51 class 3 color G
-p 1 action dscp 52 class 0 color G
-p 1 action dscp 53 class 1 color G
-p 1 action dscp 54 class 2 color G
-p 1 action dscp 55 class 3 color G
-p 1 action dscp 56 class 0 color G
-p 1 action dscp 57 class 1 color G
-p 1 action dscp 58 class 2 color G
-p 1 action dscp 59 class 3 color G
-p 1 action dscp 60 class 0 color G
-p 1 action dscp 61 class 1 color G
-p 1 action dscp 62 class 2 color G
-p 1 action dscp 63 class 3 color G
-
-p 1 action dscp ls
diff --git a/examples/ip_pipeline/config/action.txt b/examples/ip_pipeline/config/action.txt
deleted file mode 100644
index f14207b..0000000
--- a/examples/ip_pipeline/config/action.txt
+++ /dev/null
@@ -1,8 +0,0 @@
-#
-# p <pipelineid> action flow bulk ./config/action.txt
-#
-
-flow 0 meter 0 trtcm 1250000000 1250000000 1000000 1000000 policer 0 g G y Y r R meter 1 trtcm 1250000000 1250000000 1000000 1000000 policer 1 g G y Y r R meter 2 trtcm 1250000000 1250000000 1000000 1000000 policer 2 g G y Y r R meter 3 trtcm 1250000000 1250000000 1000000 1000000 policer 3 g G y Y r R port 0
-flow 1 meter 0 trtcm 1250000000 1250000000 1000000 1000000 policer 0 g G y Y r R meter 1 trtcm 1250000000 1250000000 1000000 1000000 policer 1 g G y Y r R meter 2 trtcm 1250000000 1250000000 1000000 1000000 policer 2 g G y Y r R meter 3 trtcm 1250000000 1250000000 1000000 1000000 policer 3 g G y Y r R port 1
-flow 2 meter 0 trtcm 1250000000 1250000000 1000000 1000000 policer 0 g G y Y r R meter 1 trtcm 1250000000 1250000000 1000000 1000000 policer 1 g G y Y r R meter 2 trtcm 1250000000 1250000000 1000000 1000000 policer 2 g G y Y r R meter 3 trtcm 1250000000 1250000000 1000000 1000000 policer 3 g G y Y r R port 2
-flow 3 meter 0 trtcm 1250000000 1250000000 1000000 1000000 policer 0 g G y Y r R meter 1 trtcm 1250000000 1250000000 1000000 1000000 policer 1 g G y Y r R meter 2 trtcm 1250000000 1250000000 1000000 1000000 policer 2 g G y Y r R meter 3 trtcm 1250000000 1250000000 1000000 1000000 policer 3 g G y Y r R port 3
diff --git a/examples/ip_pipeline/config/diagram-generator.py b/examples/ip_pipeline/config/diagram-generator.py
deleted file mode 100755
index d9efc75..0000000
--- a/examples/ip_pipeline/config/diagram-generator.py
+++ /dev/null
@@ -1,317 +0,0 @@
-#!/usr/bin/env python
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2016 Intel Corporation
-
-#
-# This script creates a visual representation for a configuration file used by
-# the DPDK ip_pipeline application.
-#
-# The input configuration file is translated to an output file in DOT syntax,
-# which is then used to create the image file using graphviz
-# (www.graphviz.org).
-#
-
-from __future__ import print_function
-import argparse
-import re
-import os
-
-#
-# Command to generate the image file
-#
-DOT_COMMAND = 'dot -Gsize=20,30 -Tpng %s > %s'
-
-#
-# Layout of generated DOT file
-#
-DOT_INTRO = \
-    '#\n# Command to generate image file:\n# \t%s\n#\n\n'
-DOT_GRAPH_BEGIN = \
-    'digraph g {\n  graph [ splines = true rankdir = "LR" ]\n'
-DOT_NODE_LINK_RX = \
-    '  "%s RX" [ shape = box style = filled fillcolor = yellowgreen ]\n'
-DOT_NODE_LINK_TX = \
-    '  "%s TX" [ shape = box style = filled fillcolor = yellowgreen ]\n'
-DOT_NODE_KNI_RX = \
-    '  "%s RX" [ shape = box style = filled fillcolor = orange ]\n'
-DOT_NODE_KNI_TX = \
-    '  "%s TX" [ shape = box style = filled fillcolor = orange ]\n'
-DOT_NODE_TAP_RX = \
-    '  "%s RX" [ shape = box style = filled fillcolor = gold ]\n'
-DOT_NODE_TAP_TX = \
-    '  "%s TX" [ shape = box style = filled fillcolor = gold ]\n'
-DOT_NODE_SOURCE = \
-    '  "%s" [ shape = box style = filled fillcolor = darkgreen ]\n'
-DOT_NODE_SINK = \
-    '  "%s" [ shape = box style = filled fillcolor = peachpuff ]\n'
-DOT_NODE_PIPELINE = \
-    '  "%s" [ shape = box style = filled fillcolor = royalblue ]\n'
-DOT_EDGE_PKTQ = \
-    '  "%s" -> "%s" [ label = "%s" color = gray ]\n'
-DOT_GRAPH_END = \
-    '}\n'
-
-# Relationships between the graph nodes and the graph edges:
-#
-# Edge ID | Edge Label | Writer Node | Reader Node   | Dependencies
-# --------+------------+-------------+---------------+--------------
-# RXQx.y  | RXQx.y     | LINKx       | PIPELINEz     | LINKx
-# TXQx.y  | TXQx.y     | PIPELINEz   | LINKx         | LINKx
-# SWQx    | SWQx       | PIPELINEy   | PIPELINEz     | -
-# TMx     | TMx        | PIPELINEy   | PIPELINEz     | LINKx
-# KNIx RX | KNIx       | KNIx RX     | PIPELINEy     | KNIx, LINKx
-# KNIx TX | KNIx       | PIPELINEy   | KNIx TX       | KNIx, LINKx
-# TAPx RX | TAPx       | TAPx RX     | PIPELINEy     | TAPx
-# TAPx TX | TAPx       | PIPELINEy   | TAPx TX       | TAPx
-# SOURCEx | SOURCEx    | SOURCEx     | PIPELINEy     | SOURCEx
-# SINKx   | SINKx      | PIPELINEy   | SINKx         | SINKx
-
-
-#
-# Parse the input configuration file to detect the graph nodes and edges
-#
-def process_config_file(cfgfile):
-    edges = {}
-    links = set()
-    knis = set()
-    taps = set()
-    sources = set()
-    sinks = set()
-    pipelines = set()
-    pipeline = ''
-
-    dotfile = cfgfile + '.txt'
-    imgfile = cfgfile + '.png'
-
-    #
-    # Read configuration file
-    #
-    lines = open(cfgfile, 'r')
-    for line in lines:
-        # Remove any leading and trailing white space characters
-        line = line.strip()
-
-        # Remove any comment at end of line
-        line, sep, tail = line.partition(';')
-
-        # Look for next "PIPELINE" section
-        match = re.search(r'\[(PIPELINE\d+)\]', line)
-        if match:
-            pipeline = match.group(1)
-            continue
-
-        # Look for next "pktq_in" section entry
-        match = re.search(r'pktq_in\s*=\s*(.+)', line)
-        if match:
-            pipelines.add(pipeline)
-            for q in re.findall('\S+', match.group(1)):
-                match_rxq = re.search(r'^RXQ(\d+)\.\d+$', q)
-                match_swq = re.search(r'^SWQ\d+$', q)
-                match_tm = re.search(r'^TM(\d+)$', q)
-                match_kni = re.search(r'^KNI(\d+)$', q)
-                match_tap = re.search(r'^TAP\d+$', q)
-                match_source = re.search(r'^SOURCE\d+$', q)
-
-                # Set ID for the current packet queue (graph edge)
-                q_id = ''
-                if match_rxq or match_swq or match_tm or match_source:
-                    q_id = q
-                elif match_kni or match_tap:
-                    q_id = q + ' RX'
-                else:
-                    print('Error: Unrecognized pktq_in element "%s"' % q)
-                    return
-
-                # Add current packet queue to the set of graph edges
-                if q_id not in edges:
-                    edges[q_id] = {}
-                if 'label' not in edges[q_id]:
-                    edges[q_id]['label'] = q
-                if 'readers' not in edges[q_id]:
-                    edges[q_id]['readers'] = []
-                if 'writers' not in edges[q_id]:
-                    edges[q_id]['writers'] = []
-
-                # Add reader for the new edge
-                edges[q_id]['readers'].append(pipeline)
-
-                # Check for RXQ
-                if match_rxq:
-                    link = 'LINK' + str(match_rxq.group(1))
-                    edges[q_id]['writers'].append(link + ' RX')
-                    links.add(link)
-                    continue
-
-                # Check for SWQ
-                if match_swq:
-                    continue
-
-                # Check for TM
-                if match_tm:
-                    link = 'LINK' + str(match_tm.group(1))
-                    links.add(link)
-                    continue
-
-                # Check for KNI
-                if match_kni:
-                    link = 'LINK' + str(match_kni.group(1))
-                    edges[q_id]['writers'].append(q_id)
-                    knis.add(q)
-                    links.add(link)
-                    continue
-
-                # Check for TAP
-                if match_tap:
-                    edges[q_id]['writers'].append(q_id)
-                    taps.add(q)
-                    continue
-
-                # Check for SOURCE
-                if match_source:
-                    edges[q_id]['writers'].append(q)
-                    sources.add(q)
-                    continue
-
-                continue
-
-        # Look for next "pktq_out" section entry
-        match = re.search(r'pktq_out\s*=\s*(.+)', line)
-        if match:
-            for q in re.findall('\S+', match.group(1)):
-                match_txq = re.search(r'^TXQ(\d+)\.\d+$', q)
-                match_swq = re.search(r'^SWQ\d+$', q)
-                match_tm = re.search(r'^TM(\d+)$', q)
-                match_kni = re.search(r'^KNI(\d+)$', q)
-                match_tap = re.search(r'^TAP(\d+)$', q)
-                match_sink = re.search(r'^SINK(\d+)$', q)
-
-                # Set ID for the current packet queue (graph edge)
-                q_id = ''
-                if match_txq or match_swq or match_tm or match_sink:
-                    q_id = q
-                elif match_kni or match_tap:
-                    q_id = q + ' TX'
-                else:
-                    print('Error: Unrecognized pktq_out element "%s"' % q)
-                    return
-
-                # Add current packet queue to the set of graph edges
-                if q_id not in edges:
-                    edges[q_id] = {}
-                if 'label' not in edges[q_id]:
-                    edges[q_id]['label'] = q
-                if 'readers' not in edges[q_id]:
-                    edges[q_id]['readers'] = []
-                if 'writers' not in edges[q_id]:
-                    edges[q_id]['writers'] = []
-
-                # Add writer for the new edge
-                edges[q_id]['writers'].append(pipeline)
-
-                # Check for TXQ
-                if match_txq:
-                    link = 'LINK' + str(match_txq.group(1))
-                    edges[q_id]['readers'].append(link + ' TX')
-                    links.add(link)
-                    continue
-
-                # Check for SWQ
-                if match_swq:
-                    continue
-
-                # Check for TM
-                if match_tm:
-                    link = 'LINK' + str(match_tm.group(1))
-                    links.add(link)
-                    continue
-
-                # Check for KNI
-                if match_kni:
-                    link = 'LINK' + str(match_kni.group(1))
-                    edges[q_id]['readers'].append(q_id)
-                    knis.add(q)
-                    links.add(link)
-                    continue
-
-                # Check for TAP
-                if match_tap:
-                    edges[q_id]['readers'].append(q_id)
-                    taps.add(q)
-                    continue
-
-                # Check for SINK
-                if match_sink:
-                    edges[q_id]['readers'].append(q)
-                    sinks.add(q)
-                    continue
-
-                continue
-
-    #
-    # Write DOT file
-    #
-    print('Creating DOT file "%s" ...' % dotfile)
-    dot_cmd = DOT_COMMAND % (dotfile, imgfile)
-    file = open(dotfile, 'w')
-    file.write(DOT_INTRO % dot_cmd)
-    file.write(DOT_GRAPH_BEGIN)
-
-    # Write the graph nodes to the DOT file
-    for l in sorted(links):
-        file.write(DOT_NODE_LINK_RX % l)
-        file.write(DOT_NODE_LINK_TX % l)
-    for k in sorted(knis):
-        file.write(DOT_NODE_KNI_RX % k)
-        file.write(DOT_NODE_KNI_TX % k)
-    for t in sorted(taps):
-        file.write(DOT_NODE_TAP_RX % t)
-        file.write(DOT_NODE_TAP_TX % t)
-    for s in sorted(sources):
-        file.write(DOT_NODE_SOURCE % s)
-    for s in sorted(sinks):
-        file.write(DOT_NODE_SINK % s)
-    for p in sorted(pipelines):
-        file.write(DOT_NODE_PIPELINE % p)
-
-    # Write the graph edges to the DOT file
-    for q in sorted(edges.keys()):
-        rw = edges[q]
-        if 'writers' not in rw:
-            print('Error: "%s" has no writer' % q)
-            return
-        if 'readers' not in rw:
-            print('Error: "%s" has no reader' % q)
-            return
-        for w in rw['writers']:
-            for r in rw['readers']:
-                file.write(DOT_EDGE_PKTQ % (w, r, rw['label']))
-
-    file.write(DOT_GRAPH_END)
-    file.close()
-
-    #
-    # Execute the DOT command to create the image file
-    #
-    print('Creating image file "%s" ...' % imgfile)
-    if os.system('which dot > /dev/null'):
-        print('Error: Unable to locate "dot" executable.'
-              'Please install the "graphviz" package (www.graphviz.org).')
-        return
-
-    os.system(dot_cmd)
-
-
-if __name__ == '__main__':
-    parser = argparse.ArgumentParser(description='Create diagram for IP '
-                                                 'pipeline configuration '
-                                                 'file.')
-
-    parser.add_argument(
-        '-f',
-        '--file',
-        help='input configuration file (e.g. "ip_pipeline.cfg")',
-        required=True)
-
-    args = parser.parse_args()
-
-    process_config_file(args.file)
diff --git a/examples/ip_pipeline/config/edge_router_downstream.cfg b/examples/ip_pipeline/config/edge_router_downstream.cfg
deleted file mode 100644
index c6b4e1f..0000000
--- a/examples/ip_pipeline/config/edge_router_downstream.cfg
+++ /dev/null
@@ -1,97 +0,0 @@
-;   BSD LICENSE
-;
-;   Copyright(c) 2015-2016 Intel Corporation. All rights reserved.
-;   All rights reserved.
-;
-;   Redistribution and use in source and binary forms, with or without
-;   modification, are permitted provided that the following conditions
-;   are met:
-;
-;     * Redistributions of source code must retain the above copyright
-;       notice, this list of conditions and the following disclaimer.
-;     * Redistributions in binary form must reproduce the above copyright
-;       notice, this list of conditions and the following disclaimer in
-;       the documentation and/or other materials provided with the
-;       distribution.
-;     * Neither the name of Intel Corporation nor the names of its
-;       contributors may be used to endorse or promote products derived
-;       from this software without specific prior written permission.
-;
-;   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-;   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-;   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-;   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-;   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-;   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-;   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-;   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-;   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-;   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-;   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-
-;   An edge router typically sits between two networks such as the provider
-;   core network and the provider access network. A typical packet processing
-;   pipeline for the downstream traffic (i.e. traffic from core to access
-;   network) contains the following functional blocks: Packet RX & Routing,
-;   Traffic management and Packet TX. The input packets are assumed to be
-;   IPv4, while the output packets are Q-in-Q IPv4.
-;
-;  A simple implementation for this functional pipeline is presented below.
-;
-;                  Packet Rx &                Traffic Management               Packet Tx
-;                   Routing                    (Pass-Through)                (Pass-Through)
-;             _____________________  SWQ0  ______________________  SWQ4  _____________________
-; RXQ0.0 --->|                     |----->|                      |----->|                     |---> TXQ0.0
-;            |                     | SWQ1 |                      | SWQ5 |                     |
-; RXQ1.0 --->|                     |----->|                      |----->|                     |---> TXQ1.0
-;            |        (P1)         | SWQ2 |         (P2)         | SWQ6 |        (P3)         |
-; RXQ2.0 --->|                     |----->|                      |----->|                     |---> TXQ2.0
-;            |                     | SWQ3 |                      | SWQ7 |                     |
-; RXQ3.0 --->|                     |----->|                      |----->|                     |---> TXQ3.0
-;            |_____________________|      |______________________|      |_____________________|
-;                       |                  |  ^  |  ^  |  ^  |  ^
-;                       |                  |__|  |__|  |__|  |__|
-;                       +--> SINK0          TM0   TM1   TM2   TM3
-;                      (Default)
-;
-; Input packet: Ethernet/IPv4
-; Output packet: Ethernet/QinQ/IPv4
-;
-; Packet buffer layout:
-; #	Field Name		Offset (Bytes)	Size (Bytes)
-; 0	Mbuf			0 		128
-; 1	Headroom		128 		128
-; 2	Ethernet header		256 		14
-; 3	IPv4 header		270 		20
-
-[EAL]
-log_level = 0
-
-[PIPELINE0]
-type = MASTER
-core = 0
-
-[PIPELINE1]
-type = ROUTING
-core = 1
-pktq_in = RXQ0.0 RXQ1.0 RXQ2.0 RXQ3.0
-pktq_out = SWQ0 SWQ1 SWQ2 SWQ3 SINK0
-encap = ethernet_qinq
-qinq_sched = test
-ip_hdr_offset = 270
-
-[PIPELINE2]
-type = PASS-THROUGH
-core = 2
-pktq_in = SWQ0 SWQ1 SWQ2 SWQ3 TM0 TM1 TM2 TM3
-pktq_out = TM0 TM1 TM2 TM3 SWQ4 SWQ5 SWQ6 SWQ7
-
-[PIPELINE3]
-type = PASS-THROUGH
-core = 3
-pktq_in = SWQ4 SWQ5 SWQ6 SWQ7
-pktq_out = TXQ0.0 TXQ1.0 TXQ2.0 TXQ3.0
-
-[MEMPOOL0]
-pool_size = 2M
diff --git a/examples/ip_pipeline/config/edge_router_downstream.sh b/examples/ip_pipeline/config/edge_router_downstream.sh
deleted file mode 100644
index 67c3a0d..0000000
--- a/examples/ip_pipeline/config/edge_router_downstream.sh
+++ /dev/null
@@ -1,13 +0,0 @@
-#
-# run ./config/edge_router_downstream.sh
-#
-
-################################################################################
-# Routing: Ether QinQ, ARP off
-################################################################################
-p 1 route add default 4 #SINK0
-p 1 route add 0.0.0.0 10 port 0 ether a0:b0:c0:d0:e0:f0 qinq 256 257
-p 1 route add 0.64.0.0 10 port 1 ether a1:b1:c1:d1:e1:f1 qinq 258 259
-p 1 route add 0.128.0.0 10 port 2 ether a2:b2:c2:d2:e2:f2 qinq 260 261
-p 1 route add 0.192.0.0 10 port 3 ether a3:b3:c3:d3:e3:f3 qinq 262 263
-#p 1 route ls
diff --git a/examples/ip_pipeline/config/edge_router_upstream.cfg b/examples/ip_pipeline/config/edge_router_upstream.cfg
deleted file mode 100644
index dea42b9..0000000
--- a/examples/ip_pipeline/config/edge_router_upstream.cfg
+++ /dev/null
@@ -1,124 +0,0 @@
-;   BSD LICENSE
-;
-;   Copyright(c) 2015-2016 Intel Corporation. All rights reserved.
-;   All rights reserved.
-;
-;   Redistribution and use in source and binary forms, with or without
-;   modification, are permitted provided that the following conditions
-;   are met:
-;
-;     * Redistributions of source code must retain the above copyright
-;       notice, this list of conditions and the following disclaimer.
-;     * Redistributions in binary form must reproduce the above copyright
-;       notice, this list of conditions and the following disclaimer in
-;       the documentation and/or other materials provided with the
-;       distribution.
-;     * Neither the name of Intel Corporation nor the names of its
-;       contributors may be used to endorse or promote products derived
-;       from this software without specific prior written permission.
-;
-;   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-;   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-;   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-;   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-;   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-;   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-;   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-;   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-;   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-;   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-;   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-
-;   An edge router typically sits between two networks such as the provider
-;   core network and the provider access network. A typical packet processing
-;   pipeline for the upstream traffic (i.e. traffic from access to core
-;   network) contains the following functional blocks: Packet RX & Firewall,
-;   Flow classification, Metering, Routing and Packet TX. The input packets
-;   are assumed to be Q-in-Q IPv4, while the output packets are MPLS IPv4
-;  (with variable number of labels per route).
-;
-;   A simple implementation for this functional pipeline is presented below.
-;
-;             Packet RX &       Pass-Through    Flow Classification   Flow Actions         Routing
-:              Firewall
-;             __________  SWQ0   __________  SWQ4   __________  SWQ8   __________  SWQ12  __________
-; RXQ0.0 --->|          |------>|          |------>|          |------>|          |------>|          |------> TXQ0.0
-;            |          | SWQ1  |          | SWQ5  |          | SWQ9  |          | SWQ13 |          |
-; RXQ1.0 --->|          |------>|          |------>|          |------>|          |------>|          |------> TXQ1.0
-;            |   (P1)   | SWQ2  |  (P2)    | SWQ6  |   (P3)   | SWQ10 |   (P4)   | SWQ14 |   (P5)   |
-; RXQ2.0 --->|          |------>|          |------>|          |------>|          |------>|          |------> TXQ2.0
-;            |          | SWQ3  |          | SWQ7  |          | SWQ11 |          | SWQ15 |          |
-; RXQ3.0 --->|          |------>|          |------>|          |------>|          |------>|          |------> TXQ3.0
-;            |__________|       |__________|       |__________|       |__________|       |__________|
-;                 |                                     |                                     |
-;                 +--> SINK0 (Default)                  +--> SINK1 (Default)                  +--> SINK2 (Default)
-;
-; Input packet: Ethernet/QinQ/IPv4
-; Output packet: Ethernet/MPLS/IPv4
-;
-; Packet buffer layout:
-; #	Field Name		Offset (Bytes)	Size (Bytes)
-; 0	Mbuf			0 		128
-; 1	Headroom		128 		128
-; 2	Ethernet header		256 		14
-; 3     QinQ header             270             8
-; 4	IPv4 header		278 		20
-
-[EAL]
-log_level = 0
-
-[PIPELINE0]
-type = MASTER
-core = 0
-
-[PIPELINE1]
-type = FIREWALL
-core = 1
-pktq_in = RXQ0.0 RXQ1.0 RXQ2.0 RXQ3.0
-pktq_out = SWQ0 SWQ1 SWQ2 SWQ3 SINK0
-n_rules = 4096
-pkt_type = qinq_ipv4
-
-[PIPELINE2]
-type = PASS-THROUGH
-core = 2
-pktq_in = SWQ0 SWQ1 SWQ2 SWQ3
-pktq_out = SWQ4 SWQ5 SWQ6 SWQ7
-dma_size = 8
-dma_dst_offset = 128
-dma_src_offset = 268; 1st Ethertype offset
-dma_src_mask = 00000FFF00000FFF; qinq
-dma_hash_offset = 136; dma_dst_offset + dma_size
-
-[PIPELINE3]
-type = FLOW_CLASSIFICATION
-core = 2
-pktq_in = SWQ4 SWQ5 SWQ6 SWQ7
-pktq_out = SWQ8 SWQ9 SWQ10 SWQ11 SINK1
-n_flows = 65536
-key_size = 8; dma_size
-key_offset = 128; dma_dst_offset
-hash_offset = 136; dma_hash_offset
-flowid_offset = 192
-
-[PIPELINE4]
-type = FLOW_ACTIONS
-core = 3
-pktq_in = SWQ8 SWQ9 SWQ10 SWQ11
-pktq_out = SWQ12 SWQ13 SWQ14 SWQ15
-n_flows = 65536
-n_meters_per_flow = 1
-flow_id_offset = 192; flowid_offset
-ip_hdr_offset = 278
-color_offset = 196; flowid_offset + sizeof(flow_id)
-
-[PIPELINE5]
-type = ROUTING
-core = 4
-pktq_in = SWQ12 SWQ13 SWQ14 SWQ15
-pktq_out = TXQ0.0 TXQ1.0 TXQ2.0 TXQ3.0 SINK2
-encap = ethernet_mpls
-mpls_color_mark = yes
-ip_hdr_offset = 278
-color_offset = 196; flowid_offset + sizeof(flow_id)
diff --git a/examples/ip_pipeline/config/edge_router_upstream.sh b/examples/ip_pipeline/config/edge_router_upstream.sh
deleted file mode 100644
index 5d574c1..0000000
--- a/examples/ip_pipeline/config/edge_router_upstream.sh
+++ /dev/null
@@ -1,33 +0,0 @@
-#
-# run ./config/edge_router_upstream.sh
-#
-
-################################################################################
-# Firewall
-################################################################################
-p 1 firewall add default 4 #SINK0
-p 1 firewall add bulk ./config/edge_router_upstream_firewall.txt
-#p 1 firewall ls
-
-################################################################################
-# Flow Classification
-################################################################################
-p 3 flow add default 4 #SINK1
-p 3 flow add qinq bulk ./config/edge_router_upstream_flow.txt
-#p 3 flow ls
-
-################################################################################
-# Flow Actions - Metering and Policing
-################################################################################
-p 4 action flow bulk ./config/edge_router_upstream_action.txt
-#p 4 action flow ls
-
-################################################################################
-# Routing: Ether MPLS, ARP off
-################################################################################
-p 5 route add default 4 #SINK2
-p 5 route add 0.0.0.0 10 port 0 ether a0:b0:c0:d0:e0:f0 mpls 0:1
-p 5 route add 0.64.0.0 10 port 1 ether a1:b1:c1:d1:e1:f1 mpls 10:11
-p 5 route add 0.128.0.0 10 port 2 ether a2:b2:c2:d2:e2:f2 mpls 20:21
-p 5 route add 0.192.0.0 10 port 3 ether a3:b3:c3:d3:e3:f3 mpls 30:31
-#p 5 route ls
diff --git a/examples/ip_pipeline/config/firewall.cfg b/examples/ip_pipeline/config/firewall.cfg
deleted file mode 100644
index 2f5dd9f..0000000
--- a/examples/ip_pipeline/config/firewall.cfg
+++ /dev/null
@@ -1,68 +0,0 @@
-;   BSD LICENSE
-;
-;   Copyright(c) 2015-2016 Intel Corporation. All rights reserved.
-;   All rights reserved.
-;
-;   Redistribution and use in source and binary forms, with or without
-;   modification, are permitted provided that the following conditions
-;   are met:
-;
-;     * Redistributions of source code must retain the above copyright
-;       notice, this list of conditions and the following disclaimer.
-;     * Redistributions in binary form must reproduce the above copyright
-;       notice, this list of conditions and the following disclaimer in
-;       the documentation and/or other materials provided with the
-;       distribution.
-;     * Neither the name of Intel Corporation nor the names of its
-;       contributors may be used to endorse or promote products derived
-;       from this software without specific prior written permission.
-;
-;   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-;   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-;   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-;   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-;   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-;   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-;   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-;   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-;   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-;   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-;   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-;             _______________
-; RXQ0.0 --->|               |---> TXQ0.0
-;            |               |
-; RXQ1.0 --->|               |---> TXQ1.0
-;            |   Firewall    |
-; RXQ2.0 --->|               |---> TXQ2.0
-;            |               |
-; RXQ3.0 --->|               |---> TXQ3.0
-;            |_______________|
-;                    |
-;                    +-----------> SINK0 (default rule)
-;
-; Input packet: Ethernet/IPv4
-;
-; Packet buffer layout:
-; #	Field Name		Offset (Bytes)	Size (Bytes)
-; 0	Mbuf			0 		128
-; 1	Headroom		128 		128
-; 2	Ethernet header		256 		14
-; 3	IPv4 header		270 		20
-
-[EAL]
-log_level = 0
-
-[PIPELINE0]
-type = MASTER
-core = 0
-
-[PIPELINE1]
-type = FIREWALL
-core = 1
-pktq_in = RXQ0.0 RXQ1.0 RXQ2.0 RXQ3.0
-pktq_out = TXQ0.0 TXQ1.0 TXQ2.0 TXQ3.0 SINK0
-n_rules = 4096
-pkt_type = ipv4
-;pkt_type = vlan_ipv4
-;pkt_type = qinq_ipv4
diff --git a/examples/ip_pipeline/config/firewall.sh b/examples/ip_pipeline/config/firewall.sh
deleted file mode 100644
index c83857e..0000000
--- a/examples/ip_pipeline/config/firewall.sh
+++ /dev/null
@@ -1,13 +0,0 @@
-#
-# run ./config/firewall.sh
-#
-
-p 1 firewall add default 4 #SINK0
-p 1 firewall add priority 1 ipv4 0.0.0.0 0 100.0.0.0 10 0 65535 0 65535 6 0xF port 0
-p 1 firewall add priority 1 ipv4 0.0.0.0 0 100.64.0.0 10 0 65535 0 65535 6 0xF port 1
-p 1 firewall add priority 1 ipv4 0.0.0.0 0 100.128.0.0 10 0 65535 0 65535 6 0xF port 2
-p 1 firewall add priority 1 ipv4 0.0.0.0 0 100.192.0.0 10 0 65535 0 65535 6 0xF port 3
-
-#p 1 firewall add bulk ./config/firewall.txt
-
-p 1 firewall ls
diff --git a/examples/ip_pipeline/config/firewall.txt b/examples/ip_pipeline/config/firewall.txt
deleted file mode 100644
index 54cfffd..0000000
--- a/examples/ip_pipeline/config/firewall.txt
+++ /dev/null
@@ -1,9 +0,0 @@
-#
-# p <pipelineid> firewall add bulk ./config/firewall.txt
-# p <pipelineid> firewall del bulk ./config/firewall.txt
-#
-
-priority 1 ipv4 0.0.0.0 0 100.0.0.0 10 0 65535 0 65535 6 0xF port 0
-priority 1 ipv4 0.0.0.0 0 100.64.0.0 10 0 65535 0 65535 6 0xF port 1
-priority 1 ipv4 0.0.0.0 0 100.128.0.0 10 0 65535 0 65535 6 0xF port 2
-priority 1 ipv4 0.0.0.0 0 100.192.0.0 10 0 65535 0 65535 6 0xF port 3
diff --git a/examples/ip_pipeline/config/flow.cfg b/examples/ip_pipeline/config/flow.cfg
deleted file mode 100644
index cec990a..0000000
--- a/examples/ip_pipeline/config/flow.cfg
+++ /dev/null
@@ -1,72 +0,0 @@
-;   BSD LICENSE
-;
-;   Copyright(c) 2015-2016 Intel Corporation. All rights reserved.
-;   All rights reserved.
-;
-;   Redistribution and use in source and binary forms, with or without
-;   modification, are permitted provided that the following conditions
-;   are met:
-;
-;     * Redistributions of source code must retain the above copyright
-;       notice, this list of conditions and the following disclaimer.
-;     * Redistributions in binary form must reproduce the above copyright
-;       notice, this list of conditions and the following disclaimer in
-;       the documentation and/or other materials provided with the
-;       distribution.
-;     * Neither the name of Intel Corporation nor the names of its
-;       contributors may be used to endorse or promote products derived
-;       from this software without specific prior written permission.
-;
-;   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-;   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-;   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-;   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-;   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-;   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-;   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-;   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-;   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-;   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-;   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-;             ________________
-; RXQ0.0 --->|                |---> TXQ0.0
-;            |                |
-; RXQ1.0 --->|                |---> TXQ1.0
-;            |      Flow      |
-; RXQ2.0 --->| Classification |---> TXQ2.0
-;            |                |
-; RXQ3.0 --->|                |---> TXQ3.0
-;            |________________|
-;                    |
-;                    +-----------> SINK0 (flow lookup miss)
-;
-; Input packet: Ethernet/IPv4
-;
-; Packet buffer layout:
-; #	Field Name		Offset (Bytes)	Size (Bytes)
-; 0	Mbuf			0		128
-; 1	Headroom		128 		128
-; 2	Ethernet header		256 		14
-; 3	QinQ/IPv4/IPv6 header	270 		8/20/40
-
-[EAL]
-log_level = 0
-
-[PIPELINE0]
-type = MASTER
-core = 0
-
-[PIPELINE1]
-type = FLOW_CLASSIFICATION
-core = 1
-pktq_in = RXQ0.0 RXQ1.0 RXQ2.0 RXQ3.0
-pktq_out = TXQ0.0 TXQ1.0 TXQ2.0 TXQ3.0 SINK0
-n_flows = 65536
-;key_size = 8                ; QinQ key size
-;key_offset = 268            ; QinQ key offset
-;key_mask = 00000FFF00000FFF ; QinQ key mask
-key_size = 16                               ; IPv4 5-tuple key size
-key_offset = 278                            ; IPv4 5-tuple key offset
-key_mask = 00FF0000FFFFFFFFFFFFFFFFFFFFFFFF ; IPv4 5-tuple key mask
-flowid_offset = 128
diff --git a/examples/ip_pipeline/config/flow.sh b/examples/ip_pipeline/config/flow.sh
deleted file mode 100644
index 489c707..0000000
--- a/examples/ip_pipeline/config/flow.sh
+++ /dev/null
@@ -1,25 +0,0 @@
-#
-# run ./config/flow.sh
-#
-
-################################################################################
-# Flow classification (QinQ)
-################################################################################
-#p 1 flow add default 4 #SINK0
-#p 1 flow add qinq 100 200 port 0 id 0
-#p 1 flow add qinq 101 201 port 1 id 1
-#p 1 flow add qinq 102 202 port 2 id 2
-#p 1 flow add qinq 103 203 port 3 id 3
-
-#p 1 flow add qinq bulk ./config/flow.txt
-
-################################################################################
-# Flow classification (IPv4 5-tuple)
-################################################################################
-p 1 flow add default 4 #SINK0
-p 1 flow add ipv4 100.0.0.10 200.0.0.10 100 200 6 port 0 id 0
-p 1 flow add ipv4 100.0.0.11 200.0.0.11 101 201 6 port 1 id 1
-p 1 flow add ipv4 100.0.0.12 200.0.0.12 102 202 6 port 2 id 2
-p 1 flow add ipv4 100.0.0.13 200.0.0.13 103 203 6 port 3 id 3
-
-#p 1 flow add ipv4 bulk ./config/flow.txt
diff --git a/examples/ip_pipeline/config/flow.txt b/examples/ip_pipeline/config/flow.txt
deleted file mode 100644
index c1a141d..0000000
--- a/examples/ip_pipeline/config/flow.txt
+++ /dev/null
@@ -1,17 +0,0 @@
-#
-# p <pipelineid> flow add qinq bulk ./config/flow.txt
-#
-
-#qinq 100 200 port 0 id 0
-#qinq 101 201 port 1 id 1
-#qinq 102 202 port 2 id 2
-#qinq 103 203 port 3 id 3
-
-#
-# p <pipelineid> flow add ipv4 bulk ./config/flow.txt
-#
-
-ipv4 100.0.0.10 200.0.0.10 100 200 6 port 0 id 0
-ipv4 100.0.0.11 200.0.0.11 101 201 6 port 1 id 1
-ipv4 100.0.0.12 200.0.0.12 102 202 6 port 2 id 2
-ipv4 100.0.0.13 200.0.0.13 103 203 6 port 3 id 3
diff --git a/examples/ip_pipeline/config/ip_pipeline.cfg b/examples/ip_pipeline/config/ip_pipeline.cfg
deleted file mode 100644
index 095ed25..0000000
--- a/examples/ip_pipeline/config/ip_pipeline.cfg
+++ /dev/null
@@ -1,9 +0,0 @@
-[PIPELINE0]
-type = MASTER
-core = 0
-
-[PIPELINE1]
-type = PASS-THROUGH
-core = 1
-pktq_in = RXQ0.0 RXQ1.0 RXQ2.0 RXQ3.0
-pktq_out = TXQ0.0 TXQ1.0 TXQ2.0 TXQ3.0
diff --git a/examples/ip_pipeline/config/ip_pipeline.sh b/examples/ip_pipeline/config/ip_pipeline.sh
deleted file mode 100644
index 4fca259..0000000
--- a/examples/ip_pipeline/config/ip_pipeline.sh
+++ /dev/null
@@ -1,5 +0,0 @@
-#
-#run config/ip_pipeline.sh
-#
-
-p 1 ping
diff --git a/examples/ip_pipeline/config/kni.cfg b/examples/ip_pipeline/config/kni.cfg
deleted file mode 100644
index cea208b..0000000
--- a/examples/ip_pipeline/config/kni.cfg
+++ /dev/null
@@ -1,67 +0,0 @@
-;   BSD LICENSE
-;
-;   Copyright(c) 2016 Intel Corporation.
-;   All rights reserved.
-;
-;   Redistribution and use in source and binary forms, with or without
-;   modification, are permitted provided that the following conditions
-;   are met:
-;
-;     * Redistributions of source code must retain the above copyright
-;       notice, this list of conditions and the following disclaimer.
-;     * Redistributions in binary form must reproduce the above copyright
-;       notice, this list of conditions and the following disclaimer in
-;       the documentation and/or other materials provided with the
-;       distribution.
-;     * Neither the name of Intel Corporation nor the names of its
-;       contributors may be used to endorse or promote products derived
-;       from this software without specific prior written permission.
-;
-;   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-;   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-;   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-;   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-;   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-;   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-;   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-;   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-;   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-;   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-;   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-;
-;             ______________          ______________________
-;            |              |  KNI0  |                      |
-; RXQ0.0 --->|              |------->|--+                   |
-;            |              |  KNI1  |  | br0               |
-; TXQ1.0 <---|              |<-------|<-+                   |
-;            | Pass-through |        |     Linux Kernel     |
-;            |     (P1)     |        |     Network Stack    |
-;            |              |  KNI1  |                      |
-; RXQ1.0 --->|              |------->|--+                   |
-;            |              |  KNI0  |  | br0               |
-; TXQ0.0 <---|              |<-------|<-+                   |
-;            |______________|        |______________________|
-;
-; Insert Linux kernel KNI module:
-;    [Linux]$ insmod rte_kni.ko
-;
-; Configure Linux kernel bridge between KNI0 and KNI1 interfaces:
-;    [Linux]$ ifconfig KNI0 up
-;    [Linux]$ ifconfig KNI1 up
-;    [Linux]$ brctl addbr "br0"
-;    [Linux]$ brctl addif br0 KNI0
-;    [Linux]$ brctl addif br0 KNI1
-;    [Linux]$ ifconfig br0 up
-
-[EAL]
-log_level = 0
-
-[PIPELINE0]
-type = MASTER
-core = 0
-
-[PIPELINE1]
-type = PASS-THROUGH
-core = 1
-pktq_in = RXQ0.0 KNI1 RXQ1.0 KNI0
-pktq_out = KNI0 TXQ1.0 KNI1 TXQ0.0
diff --git a/examples/ip_pipeline/config/l2fwd.cfg b/examples/ip_pipeline/config/l2fwd.cfg
deleted file mode 100644
index a1df9e6..0000000
--- a/examples/ip_pipeline/config/l2fwd.cfg
+++ /dev/null
@@ -1,58 +0,0 @@
-;   BSD LICENSE
-;
-;   Copyright(c) 2015-2016 Intel Corporation. All rights reserved.
-;   All rights reserved.
-;
-;   Redistribution and use in source and binary forms, with or without
-;   modification, are permitted provided that the following conditions
-;   are met:
-;
-;     * Redistributions of source code must retain the above copyright
-;       notice, this list of conditions and the following disclaimer.
-;     * Redistributions in binary form must reproduce the above copyright
-;       notice, this list of conditions and the following disclaimer in
-;       the documentation and/or other materials provided with the
-;       distribution.
-;     * Neither the name of Intel Corporation nor the names of its
-;       contributors may be used to endorse or promote products derived
-;       from this software without specific prior written permission.
-;
-;   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-;   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-;   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-;   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-;   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-;   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-;   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-;   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-;   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-;   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-;   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-;
-; The pass-through pipeline below connects the input ports to the output ports
-; as follows: RXQ0.0 -> TXQ1.0, RXQ1.0 -> TXQ0.0, RXQ2.0 -> TXQ3.0 and
-; RXQ3.0 -> TXQ2.0.
-;             ________________
-; RXQ0.0 --->|................|---> TXQ1.0
-;            |                |
-; RXQ1.0 --->|................|---> TXQ0.0
-;            |  Pass-through  |
-; RXQ2.0 --->|................|---> TXQ3.0
-;            |                |
-; RXQ3.0 --->|................|---> TXQ2.0
-;            |________________|
-;
-
-[EAL]
-log_level = 0
-
-[PIPELINE0]
-type = MASTER
-core = 0
-
-[PIPELINE1]
-type = PASS-THROUGH
-core = 1
-pktq_in = RXQ0.0 RXQ1.0 RXQ2.0 RXQ3.0
-pktq_out = TXQ1.0 TXQ0.0 TXQ3.0 TXQ2.0
diff --git a/examples/ip_pipeline/config/l3fwd.cfg b/examples/ip_pipeline/config/l3fwd.cfg
deleted file mode 100644
index 02c8f36..0000000
--- a/examples/ip_pipeline/config/l3fwd.cfg
+++ /dev/null
@@ -1,68 +0,0 @@
-;   BSD LICENSE
-;
-;   Copyright(c) 2015-2016 Intel Corporation. All rights reserved.
-;   All rights reserved.
-;
-;   Redistribution and use in source and binary forms, with or without
-;   modification, are permitted provided that the following conditions
-;   are met:
-;
-;     * Redistributions of source code must retain the above copyright
-;       notice, this list of conditions and the following disclaimer.
-;     * Redistributions in binary form must reproduce the above copyright
-;       notice, this list of conditions and the following disclaimer in
-;       the documentation and/or other materials provided with the
-;       distribution.
-;     * Neither the name of Intel Corporation nor the names of its
-;       contributors may be used to endorse or promote products derived
-;       from this software without specific prior written permission.
-;
-;   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-;   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-;   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-;   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-;   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-;   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-;   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-;   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-;   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-;   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-;   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-;             _______________
-; RXQ0.0 --->|               |---> TXQ0.0
-;            |               |
-; RXQ1.0 --->|               |---> TXQ1.0
-;            |    Routing    |
-; RXQ2.0 --->|               |---> TXQ2.0
-;            |               |
-; RXQ3.0 --->|               |---> TXQ3.0
-;            |_______________|
-;                    |
-;                    +-----------> SINK0 (route miss)
-;
-; Input packet: Ethernet/IPv4
-;
-; Packet buffer layout:
-; #	Field Name		Offset (Bytes)	Size (Bytes)
-; 0	Mbuf			0 		128
-; 1	Headroom		128 		128
-; 2	Ethernet header		256 		14
-; 3	IPv4 header		270 		20
-
-[EAL]
-log_level = 0
-
-[PIPELINE0]
-type = MASTER
-core = 0
-
-[PIPELINE1]
-type = ROUTING
-core = 1
-pktq_in = RXQ0.0 RXQ1.0 RXQ2.0 RXQ3.0
-pktq_out = TXQ0.0 TXQ1.0 TXQ2.0 TXQ3.0 SINK0
-encap = ethernet
-;encap = ethernet_qinq
-;encap = ethernet_mpls
-ip_hdr_offset = 270
diff --git a/examples/ip_pipeline/config/l3fwd.sh b/examples/ip_pipeline/config/l3fwd.sh
deleted file mode 100644
index 47406aa..0000000
--- a/examples/ip_pipeline/config/l3fwd.sh
+++ /dev/null
@@ -1,33 +0,0 @@
-#
-# run ./config/l3fwd.sh
-#
-
-################################################################################
-# Routing: encap = ethernet, arp = off
-################################################################################
-p 1 route add default 4 #SINK0
-p 1 route add 100.0.0.0 10 port 0 ether a0:b0:c0:d0:e0:f0
-p 1 route add 100.64.0.0 10 port 1 ether a1:b1:c1:d1:e1:f1
-p 1 route add 100.128.0.0 10 port 2 ether a2:b2:c2:d2:e2:f2
-p 1 route add 100.192.0.0 10 port 3 ether a3:b3:c3:d3:e3:f3
-p 1 route ls
-
-################################################################################
-# Routing: encap = ethernet_qinq, arp = off
-################################################################################
-#p 1 route add default 4 #SINK0
-#p 1 route add 100.0.0.0 10 port 0 ether a0:b0:c0:d0:e0:f0 qinq 1000 2000
-#p 1 route add 100.64.0.0 10 port 1 ether a1:b1:c1:d1:e1:f1 qinq 1001 2001
-#p 1 route add 100.128.0.0 10 port 2 ether a2:b2:c2:d2:e2:f2 qinq 1002 2002
-#p 1 route add 100.192.0.0 10 port 3 ether a3:b3:c3:d3:e3:f3 qinq 1003 2003
-#p 1 route ls
-
-################################################################################
-# Routing: encap = ethernet_mpls, arp = off
-################################################################################
-#p 1 route add default 4 #SINK0
-#p 1 route add 100.0.0.0 10 port 0 ether a0:b0:c0:d0:e0:f0 mpls 1000:2000
-#p 1 route add 100.64.0.0 10 port 1 ether a1:b1:c1:d1:e1:f1 mpls 1001:2001
-#p 1 route add 100.128.0.0 10 port 2 ether a2:b2:c2:d2:e2:f2 mpls 1002:2002
-#p 1 route add 100.192.0.0 10 port 3 ether a3:b3:c3:d3:e3:f3 mpls 1003:2003
-#p 1 route ls
diff --git a/examples/ip_pipeline/config/l3fwd_arp.cfg b/examples/ip_pipeline/config/l3fwd_arp.cfg
deleted file mode 100644
index 2c63c8f..0000000
--- a/examples/ip_pipeline/config/l3fwd_arp.cfg
+++ /dev/null
@@ -1,70 +0,0 @@
-;   BSD LICENSE
-;
-;   Copyright(c) 2015-2016 Intel Corporation. All rights reserved.
-;   All rights reserved.
-;
-;   Redistribution and use in source and binary forms, with or without
-;   modification, are permitted provided that the following conditions
-;   are met:
-;
-;     * Redistributions of source code must retain the above copyright
-;       notice, this list of conditions and the following disclaimer.
-;     * Redistributions in binary form must reproduce the above copyright
-;       notice, this list of conditions and the following disclaimer in
-;       the documentation and/or other materials provided with the
-;       distribution.
-;     * Neither the name of Intel Corporation nor the names of its
-;       contributors may be used to endorse or promote products derived
-;       from this software without specific prior written permission.
-;
-;   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-;   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-;   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-;   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-;   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-;   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-;   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-;   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-;   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-;   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-;   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-;             _______________
-; RXQ0.0 --->|               |---> TXQ0.0
-;            |               |
-; RXQ1.0 --->|               |---> TXQ1.0
-;            |    Routing    |
-; RXQ2.0 --->|               |---> TXQ2.0
-;            |               |
-; RXQ3.0 --->|               |---> TXQ3.0
-;            |_______________|
-;                    |
-;                    +-----------> SINK0 (route miss)
-;
-; Input packet: Ethernet/IPv4
-;
-; Packet buffer layout:
-; #	Field Name		Offset (Bytes)	Size (Bytes)
-; 0	Mbuf			0 		128
-; 1	Headroom		128 		128
-; 2	Ethernet header		256 		14
-; 3	IPv4 header		270 		20
-
-[EAL]
-log_level = 0
-
-[PIPELINE0]
-type = MASTER
-core = 0
-
-[PIPELINE1]
-type = ROUTING
-core = 1
-pktq_in = RXQ0.0 RXQ1.0 RXQ2.0 RXQ3.0
-pktq_out = TXQ0.0 TXQ1.0 TXQ2.0 TXQ3.0 SINK0
-encap = ethernet
-;encap = ethernet_qinq
-;encap = ethernet_mpls
-n_arp_entries = 1024
-ip_hdr_offset = 270
-arp_key_offset = 128
diff --git a/examples/ip_pipeline/config/l3fwd_arp.sh b/examples/ip_pipeline/config/l3fwd_arp.sh
deleted file mode 100644
index 20bea58..0000000
--- a/examples/ip_pipeline/config/l3fwd_arp.sh
+++ /dev/null
@@ -1,43 +0,0 @@
-#
-# run ./config/l3fwd_arp.sh
-#
-
-################################################################################
-# ARP
-################################################################################
-p 1 arp add default 4 #SINK0
-p 1 arp add 0 10.0.0.1 a0:b0:c0:d0:e0:f0
-p 1 arp add 1 11.0.0.1 a1:b1:c1:d1:e1:f1
-p 1 arp add 2 12.0.0.1 a2:b2:c2:d2:e2:f2
-p 1 arp add 3 13.0.0.1 a3:b3:c3:d3:e3:f3
-p 1 arp ls
-
-################################################################################
-# Routing: encap = ethernet, arp = on
-################################################################################
-p 1 route add default 4 #SINK0
-p 1 route add 100.0.0.0 10 port 0 ether 10.0.0.1
-p 1 route add 100.64.0.0 10 port 1 ether 11.0.0.1
-p 1 route add 100.128.0.0 10 port 2 ether 12.0.0.1
-p 1 route add 100.192.0.0 10 port 3 ether 13.0.0.1
-p 1 route ls
-
-################################################################################
-# Routing: encap = ethernet_qinq, arp = on
-################################################################################
-#p 1 route add default 4 #SINK0
-#p 1 route add 100.0.0.0 10 port 0 ether 10.0.0.1 qinq 1000 2000
-#p 1 route add 100.64.0.0 10 port 1 ether 11.0.0.1 qinq 1001 2001
-#p 1 route add 100.128.0.0 10 port 2 ether 12.0.0.1 qinq 1002 2002
-#p 1 route add 100.192.0.0 10 port 3 ether 13.0.0.1 qinq 1003 2003
-#p 1 route ls
-
-################################################################################
-# Routing: encap = ethernet_mpls, arp = on
-################################################################################
-#p 1 route add default 4 #SINK0
-#p 1 route add 100.0.0.0 10 port 0 ether 10.0.0.1 mpls 1000:2000
-#p 1 route add 100.64.0.0 10 port 1 ether 11.0.0.1 mpls 1001:2001
-#p 1 route add 100.128.0.0 10 port 2 ether 12.0.0.1 mpls 1002:2002
-#p 1 route add 100.192.0.0 10 port 3 ether 13.0.0.1 mpls 1003:2003
-#p 1 route ls
diff --git a/examples/ip_pipeline/config/network_layers.cfg b/examples/ip_pipeline/config/network_layers.cfg
deleted file mode 100644
index 397b5d7..0000000
--- a/examples/ip_pipeline/config/network_layers.cfg
+++ /dev/null
@@ -1,227 +0,0 @@
-;   BSD LICENSE
-;
-;   Copyright(c) 2016 Intel Corporation. All rights reserved.
-;   All rights reserved.
-;
-;   Redistribution and use in source and binary forms, with or without
-;   modification, are permitted provided that the following conditions
-;   are met:
-;
-;     * Redistributions of source code must retain the above copyright
-;       notice, this list of conditions and the following disclaimer.
-;     * Redistributions in binary form must reproduce the above copyright
-;       notice, this list of conditions and the following disclaimer in
-;       the documentation and/or other materials provided with the
-;       distribution.
-;     * Neither the name of Intel Corporation nor the names of its
-;       contributors may be used to endorse or promote products derived
-;       from this software without specific prior written permission.
-;
-;   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-;   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-;   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-;   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-;   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-;   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-;   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-;   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-;   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-;   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-;   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-; The diagram below shows how additional protocol components can be plugged into
-; the IP layer implemented by the ip_pipeline application. Pick your favorite
-; open source components for dynamic ARP, ICMP, UDP or TCP termination, etc and
-; connect them through SWQs to the IP infrastructure.
-;
-; The input packets with local destination are sent to the UDP/TCP applications
-; while the input packets with remote destination are routed back to the
-; network. Additional features can easily be added to this setup:
-;  * IP Reassembly: add SWQs with IP reassembly enabled (typically required for
-;    the input traffic with local destination);
-;  * IP Fragmentation: add SWQs with IP fragmentation enabled (typically
-;    required to enforce the MTU for the routed output traffic);
-;  * Traffic Metering: add Flow Action pipeline instances (e.g. for metering the
-;    TCP connections or ICMP input traffic);
-;  * Traffic Management: add TMs for the required output LINKs;
-;  * Protocol encapsulations (QinQ, MPLS) for the output packets: part of the
-;    routing pipeline configuration.
-;
-;                     _________                       _________
-;                    |         |                     |         |
-;                    |   UDP   |                     |   TCP   |
-;                    |   App   |                     |   App   |
-;                    |_________|                     |_________|
-;                       ^   |                           ^   |
-;                     __|___V__                       __|___V__
-;                    |         |  SWQ0 (UDP TX)      |         |  SWQ1 (TCP TX)
-;                    |   UDP   |-------+             |   TCP   |------------+
-;                    |         |       |             |         |            |
-;                    |_________|       |             |_________|            |
-;                         ^            |                  ^                 |
-;                         | SWQ2       |                  | SWQ3            |
-;                         | (UDP RX)   |                  | (TCP RX)        |
-;                     ____|____        |              ____|____             |
-;                    |         |       |             |         |            |
-; RXQ<0..3>.1 ------>|Firewall +--->|  |     +------>|  Flow   +--->|       |
-; (UDP local dest)   |  (P2)   | SINK0 |     |       |  (P3)   |  SINK1     |
-;                    |_________| (Deny)|     |       |_________|  (RST)     |
-; RXQ<0..3>.2 -------------------------|-----+                              |
-; (TCP local dest)                     |                                    |
-;                                      |     +------------------------------+
-;                                      |     |
-;                                     _V_____V_
-;                                    |         |
-;                                    | Routing |                   TXQ<0..3>.0
-; RXQ<0..3>.0 ---------------------->|  & ARP  +----------------------------->
-; (IP remote dest)                   |  (P1)   |
-;                                    |_________|
-;                                      |  ^  |
-;                   SWQ4 +-------------+  |  |  SWQ5 (ARP miss)
-;           (Route miss) |                |  +------------+
-;                        |  +-------------+               |
-;                     ___V__|__   SWQ6                ____V____
-;                    |         |  (ICMP TX)          |         |   TXQ<0..3>.1
-; RXQ<0..3>.3 ------>|  ICMP   |             +------>| Dyn ARP +------------->
-; (IP local dest)    |         |             |       |         |
-;                    |_________|             |       |_________|
-; RXQ<0..3>.4 -------------------------------+
-; (ARP)
-;
-; This configuration file implements the diagram presented below, where the
-; dynamic ARP, ICMP, UDP and TCP components have been stubbed out and replaced
-; with loop-back and packet drop devices.
-;
-;                     _________                       _________
-;                    |         |  SWQ0 (UDP TX)      |         |  SWQ1 (TCP TX)
-;                    |Loobpack |-------+             |Loopback |------------+
-;                    |  (P4)   |       |             |  (P5)   |            |
-;                    |_________|       |             |_________|            |
-;                         ^            |                  ^                 |
-;                         | SWQ2       |                  | SWQ3            |
-;                         | (UDP RX)   |                  | (TCP RX)        |
-;                     ____|____        |              ____|____             |
-;                    |         |       |             |         |            |
-; RXQ<0..3>.1 ------>|Firewall +--->|  |     +------>|  Flow   +--->|       |
-; (UDP local dest)   |  (P2)   | SINK0 |     |       |  (P3)   |  SINK1     |
-;                    |_________| (Deny)|     |       |_________|  (RST)     |
-; RXQ<0..3>.2 -------------------------|-----+                              |
-; (TCP local dest)                     |                                    |
-;                                      |     +------------------------------+
-;                                      |     |
-;                                     _V_____V_
-;                                    |         |
-;                                    | Routing |                   TXQ<0..3>.0
-; RXQ<0..3>.0 ---------------------->|  & ARP  +----------------------------->
-; (IP remote dest)                   |  (P1)   |
-;                                    |_________|
-;                                      |     |
-;                           SINK2 |<---+     +--->| SINK3
-;                           (Route miss)            (ARP miss)
-;
-;                     _________                            _________
-;                    |         |                          |         |
-; RXQ<0..3>.3 ------>|  Drop   +--->| SINK<4..7>  +------>|  Drop   +--->| SINK<8..11>
-; (IP local dest)    |  (P6)   | (IP local dest)  |       |  (P7)   |     (ARP)
-;                    |_________|                  |       |_________|
-; RXQ<0..3>.4 ------------------------------------+
-; (ARP)
-;
-;
-; Input packet: Ethernet/IPv4 or Ethernet/ARP
-; Output packet: Ethernet/IPv4 or Ethernet/ARP
-;
-; Packet buffer layout (for input IPv4 packets):
-; #	Field Name			Offset (Bytes)	Size (Bytes)
-; 0	Mbuf				0				128
-; 1	Headroom			128				128
-; 2	Ethernet header		256				14
-; 3	IPv4 header			270				20
-; 4	ICMP/UDP/TCP header	290				8/8/20
-
-[EAL]
-log_level = 0
-
-[LINK0]
-udp_local_q = 1
-tcp_local_q = 2
-ip_local_q = 3
-arp_q = 4
-
-[LINK1]
-udp_local_q = 1
-tcp_local_q = 2
-ip_local_q = 3
-arp_q = 4
-
-[LINK2]
-udp_local_q = 1
-tcp_local_q = 2
-ip_local_q = 3
-arp_q = 4
-
-[LINK3]
-udp_local_q = 1
-tcp_local_q = 2
-ip_local_q = 3
-arp_q = 4
-
-[PIPELINE0]
-type = MASTER
-core = 0
-
-[PIPELINE1]
-type = ROUTING
-core = 1
-pktq_in = RXQ0.0 RXQ1.0 RXQ2.0 RXQ3.0 SWQ0 SWQ1
-pktq_out = TXQ0.0 TXQ1.0 TXQ2.0 TXQ3.0 SINK2 SINK3
-port_local_dest = 4 ; SINK2 (Drop)
-n_arp_entries = 1000
-ip_hdr_offset = 270
-arp_key_offset = 128
-
-[PIPELINE2]
-type = FIREWALL
-core = 1
-pktq_in = RXQ0.1 RXQ1.1 RXQ2.1 RXQ3.1
-pktq_out = SWQ2 SINK0
-n_rules = 4096
-
-[PIPELINE3]
-type = FLOW_CLASSIFICATION
-core = 1
-pktq_in = RXQ0.2 RXQ1.2 RXQ2.2 RXQ3.2
-pktq_out = SWQ3 SINK1
-n_flows = 65536
-key_size = 16                               ; IPv4 5-tuple key size
-key_offset = 278                            ; IPv4 5-tuple key offset
-key_mask = 00FF0000FFFFFFFFFFFFFFFFFFFFFFFF ; IPv4 5-tuple key mask
-flowid_offset = 128 ; Flow ID effectively acts as TCP socket ID
-
-[PIPELINE4]
-type = PASS-THROUGH ; Loop-back (UDP place-holder)
-core = 1
-pktq_in = SWQ2
-pktq_out = SWQ0
-swap = 282 286 ; IPSRC <-> IPDST
-swap = 290 292 ; PORTSRC <-> PORTDST
-
-[PIPELINE5]
-type = PASS-THROUGH ; Loop-back (TCP place-holder)
-core = 1
-pktq_in = SWQ3
-pktq_out = SWQ1
-swap = 282 286 ; IPSRC <-> IPDST
-swap = 290 292 ; PORTSRC <-> PORTDST
-
-[PIPELINE6]
-type = PASS-THROUGH ; Drop (ICMP place-holder)
-core = 1
-pktq_in = RXQ0.3 RXQ1.3 RXQ2.3 RXQ3.3
-pktq_out = SINK4 SINK5 SINK6 SINK7
-
-[PIPELINE7]
-type = PASS-THROUGH ; Drop (Dynamic ARP place-holder)
-core = 1
-pktq_in = RXQ0.4 RXQ1.4 RXQ2.4 RXQ3.4
-pktq_out = SINK8 SINK9 SINK10 SINK11
diff --git a/examples/ip_pipeline/config/network_layers.sh b/examples/ip_pipeline/config/network_layers.sh
deleted file mode 100644
index 449b006..0000000
--- a/examples/ip_pipeline/config/network_layers.sh
+++ /dev/null
@@ -1,79 +0,0 @@
-#
-# run ./config/network_layers.sh
-#
-
-################################################################################
-# Link configuration
-################################################################################
-# Routes added implicitly when links are brought UP:
-# IP Prefix = 10.0.0.1/16 => (Port 0, Local)
-# IP Prefix = 10.0.0.1/32 => (Port 4, Local)
-# IP Prefix = 10.1.0.1/16 => (Port 1, Local)
-# IP Prefix = 10.1.0.1/32 => (Port 4, Local)
-# IP Prefix = 10.2.0.1/16 => (Port 2, Local)
-# IP Prefix = 10.2.0.1/32 => (Port 4, Local)
-# IP Prefix = 10.3.0.1/16 => (Port 3, Local)
-# IP Prefix = 10.3.0.1/32 => (Port 4, Local)
-link 0 down
-link 1 down
-link 2 down
-link 3 down
-link 0 config 10.0.0.1 16
-link 1 config 10.1.0.1 16
-link 2 config 10.2.0.1 16
-link 3 config 10.3.0.1 16
-link 0 up
-link 1 up
-link 2 up
-link 3 up
-#link ls
-
-################################################################################
-# Static ARP
-################################################################################
-p 1 arp add default 5 #SINK3
-p 1 arp add 0 10.0.0.2 a0:b0:c0:d0:e0:f0
-p 1 arp add 1 10.1.0.2 a1:b1:c1:d1:e1:f1
-p 1 arp add 2 10.2.0.2 a2:b2:c2:d2:e2:f2
-p 1 arp add 3 10.3.0.2 a3:b3:c3:d3:e3:f3
-#p 1 arp ls
-
-################################################################################
-# Routes
-################################################################################
-p 1 route add default 4 #SINK2
-p 1 route add 100.0.0.0 16 port 0 ether 10.0.0.2
-p 1 route add 100.1.0.0 16 port 1 ether 10.1.0.2
-p 1 route add 100.2.0.0 16 port 2 ether 10.2.0.2
-p 1 route add 100.3.0.0 16 port 3 ether 10.3.0.2
-#p 1 route ls
-
-################################################################################
-# Local destination UDP traffic
-################################################################################
-# Prio = Lowest: [SA = ANY, DA = ANY, SP = ANY, DP = ANY, PROTO = ANY] => Drop
-# Prio = 1 (High): [SA = ANY, DA = 10.0.0.1, SP = ANY, DP = 1000, PROTO = UDP] => Allow
-# Prio = 1 (High): [SA = ANY, DA = 10.1.0.1, SP = ANY, DP = 1001, PROTO = UDP] => Allow
-# Prio = 1 (High): [SA = ANY, DA = 10.2.0.1, SP = ANY, DP = 1002, PROTO = UDP] => Allow
-# Prio = 1 (High): [SA = ANY, DA = 10.3.0.1, SP = ANY, DP = 1003, PROTO = UDP] => Allow
-p 2 firewall add default 1 #SINK0
-p 2 firewall add priority 1 ipv4 0.0.0.0 0 10.0.0.1 32 0 65535 1000 1000 17 0xF port 0
-p 2 firewall add priority 1 ipv4 0.0.0.0 0 10.1.0.1 32 0 65535 1001 1001 17 0xF port 0
-p 2 firewall add priority 1 ipv4 0.0.0.0 0 10.2.0.1 32 0 65535 1002 1002 17 0xF port 0
-p 2 firewall add priority 1 ipv4 0.0.0.0 0 10.3.0.1 32 0 65535 1003 1003 17 0xF port 0
-#p 2 firewall ls
-
-################################################################################
-# Local destination TCP traffic
-################################################################################
-# Unknown connection => Drop
-# TCP [SA = 100.0.0.10, DA = 10.0.0.1, SP = 1000, DP = 80] => socket ID = 0
-# TCP [SA = 100.1.0.10, DA = 10.1.0.1, SP = 1001, DP = 80] => socket ID = 1
-# TCP [SA = 100.2.0.10, DA = 10.2.0.1, SP = 1002, DP = 80] => socket ID = 2
-# TCP [SA = 100.3.0.10, DA = 10.3.0.1, SP = 1003, DP = 80] => socket ID = 3
-p 3 flow add default 1 #SINK1
-p 3 flow add ipv4 100.0.0.10 10.0.0.1 1000 80 6 port 0 id 0
-p 3 flow add ipv4 100.1.0.10 10.1.0.1 1001 80 6 port 0 id 1
-p 3 flow add ipv4 100.2.0.10 10.2.0.1 1002 80 6 port 0 id 2
-p 3 flow add ipv4 100.3.0.10 10.3.0.1 1003 80 6 port 0 id 3
-#p 3 flow ls
diff --git a/examples/ip_pipeline/config/pipeline-to-core-mapping.py b/examples/ip_pipeline/config/pipeline-to-core-mapping.py
deleted file mode 100755
index fc52b2b..0000000
--- a/examples/ip_pipeline/config/pipeline-to-core-mapping.py
+++ /dev/null
@@ -1,906 +0,0 @@
-#!/usr/bin/env python
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2016 Intel Corporation
-
-#
-# This script maps the set of pipelines identified (MASTER pipelines are
-# ignored) from the input configuration file to the set of cores
-# provided as input argument and creates configuration files for each of
-# the mapping combinations.
-#
-
-from __future__ import print_function
-from collections import namedtuple
-import argparse
-import array
-import errno
-import itertools
-import os
-import re
-import sys
-
-# default values
-enable_stage0_traceout = 1
-enable_stage1_traceout = 1
-enable_stage2_traceout = 1
-
-enable_stage1_fileout = 1
-enable_stage2_fileout = 1
-
-Constants = namedtuple('Constants', ['MAX_CORES', 'MAX_PIPELINES'])
-constants = Constants(16, 64)
-
-# pattern for physical core
-pattern_phycore = '^(s|S)\d(c|C)[1-9][0-9]*$'
-reg_phycore = re.compile(pattern_phycore)
-
-
-def popcount(mask):
-    return bin(mask).count("1")
-
-
-def len2mask(length):
-    if (length == 0):
-        return 0
-
-    if (length > 64):
-        sys.exit('error: len2mask - length %i > 64. exiting' % length)
-
-    return int('1' * length, 2)
-
-
-def bitstring_write(n, n_bits):
-    tmpstr = ""
-    if (n_bits > 64):
-        return
-
-    i = n_bits - 1
-    while (i >= 0):
-        cond = (n & (1 << i))
-        if (cond):
-            print('1', end='')
-            tmpstr += '1'
-        else:
-            print('0', end='')
-            tmpstr += '0'
-        i -= 1
-    return tmpstr
-
-
-class Cores0:
-
-    def __init__(self):
-        self.n_pipelines = 0
-
-
-class Cores1:
-
-    def __init__(self):
-        self.pipelines = 0
-        self.n_pipelines = 0
-
-
-class Cores2:
-
-    def __init__(self):
-        self.pipelines = 0
-        self.n_pipelines = 0
-        self.counter = 0
-        self.counter_max = 0
-        self.bitpos = array.array(
-            "L", itertools.repeat(0, constants.MAX_PIPELINES))
-
-
-class Context0:
-
-    def __init__(self):
-        self.cores = [Cores0() for i in range(0, constants.MAX_CORES)]
-        self.n_cores = 0
-        self.n_pipelines = 0
-        self.n_pipelines0 = 0
-        self.pos = 0
-        self.file_comment = ""
-        self.ctx1 = None
-        self.ctx2 = None
-
-    def stage0_print(self):
-        print('printing Context0 obj')
-        print('c0.cores(n_pipelines) = [ ', end='')
-        for cores_count in range(0, constants.MAX_CORES):
-            print(self.cores[cores_count].n_pipelines, end=' ')
-        print(']')
-        print('c0.n_cores = %d' % self.n_cores)
-        print('c0.n_pipelines = %d' % self.n_pipelines)
-        print('c0.n_pipelines0 = %d' % self.n_pipelines0)
-        print('c0.pos = %d' % self.pos)
-        print('c0.file_comment = %s' % self.file_comment)
-        if (self.ctx1 is not None):
-            print('c0.ctx1 = ', end='')
-            print(repr(self.ctx1))
-        else:
-            print('c0.ctx1 = None')
-
-        if (self.ctx2 is not None):
-            print('c0.ctx2 = ', end='')
-            print(repr(self.ctx2))
-        else:
-            print('c0.ctx2 = None')
-
-    def stage0_init(self, num_cores, num_pipelines, ctx1, ctx2):
-        self.n_cores = num_cores
-        self.n_pipelines = num_pipelines
-        self.ctx1 = ctx1
-        self.ctx2 = ctx2
-
-    def stage0_process(self):
-        # stage0 init
-        self.cores[0].n_pipelines = self.n_pipelines
-        self.n_pipelines0 = 0
-        self.pos = 1
-
-        while True:
-            # go forward
-            while True:
-                if ((self.pos < self.n_cores) and (self.n_pipelines0 > 0)):
-                    self.cores[self.pos].n_pipelines = min(
-                        self.cores[self.pos - 1].n_pipelines,
-                        self.n_pipelines0)
-                    self.n_pipelines0 -= self.cores[self.pos].n_pipelines
-                    self.pos += 1
-                else:
-                    break
-
-            # check solution
-            if (self.n_pipelines0 == 0):
-                self.stage0_log()
-                self.ctx1.stage1_init(self, self.ctx2)  # self is object c0
-                self.ctx1.stage1_process()
-
-            # go backward
-            while True:
-                if (self.pos == 0):
-                    return
-
-                self.pos -= 1
-                if ((self.cores[self.pos].n_pipelines > 1) and
-                        (self.pos != (self.n_cores - 1))):
-                    break
-
-                self.n_pipelines0 += self.cores[self.pos].n_pipelines
-                self.cores[self.pos].n_pipelines = 0
-
-            # rearm
-            self.cores[self.pos].n_pipelines -= 1
-            self.n_pipelines0 += 1
-            self.pos += 1
-
-    def stage0_log(self):
-        tmp_file_comment = ""
-        if(enable_stage0_traceout != 1):
-            return
-
-        print('STAGE0: ', end='')
-        tmp_file_comment += 'STAGE0: '
-        for cores_count in range(0, self.n_cores):
-            print('C%d = %d\t'
-                  % (cores_count,
-                      self.cores[cores_count].n_pipelines), end='')
-            tmp_file_comment += "C{} = {}\t".format(
-                cores_count, self.cores[cores_count].n_pipelines)
-        # end for
-        print('')
-        self.ctx1.stage0_file_comment = tmp_file_comment
-        self.ctx2.stage0_file_comment = tmp_file_comment
-
-
-class Context1:
-    _fileTrace = None
-
-    def __init__(self):
-        self.cores = [Cores1() for i in range(constants.MAX_CORES)]
-        self.n_cores = 0
-        self.n_pipelines = 0
-        self.pos = 0
-        self.stage0_file_comment = ""
-        self.stage1_file_comment = ""
-
-        self.ctx2 = None
-        self.arr_pipelines2cores = []
-
-    def stage1_reset(self):
-        for i in range(constants.MAX_CORES):
-            self.cores[i].pipelines = 0
-            self.cores[i].n_pipelines = 0
-
-        self.n_cores = 0
-        self.n_pipelines = 0
-        self.pos = 0
-        self.ctx2 = None
-        # clear list
-        del self.arr_pipelines2cores[:]
-
-    def stage1_print(self):
-        print('printing Context1 obj')
-        print('ctx1.cores(pipelines,n_pipelines) = [ ', end='')
-        for cores_count in range(0, constants.MAX_CORES):
-            print('(%d,%d)' % (self.cores[cores_count].pipelines,
-                               self.cores[cores_count].n_pipelines), end=' ')
-        print(']')
-        print('ctx1.n_cores = %d' % self.n_cores)
-        print('ctx1.n_pipelines = %d' % self.n_pipelines)
-        print('ctx1.pos = %d' % self.pos)
-        print('ctx1.stage0_file_comment = %s' % self.stage0_file_comment)
-        print('ctx1.stage1_file_comment = %s' % self.stage1_file_comment)
-        if (self.ctx2 is not None):
-            print('ctx1.ctx2 = ', end='')
-            print(self.ctx2)
-        else:
-            print('ctx1.ctx2 = None')
-
-    def stage1_init(self, c0, ctx2):
-        self.stage1_reset()
-        self.n_cores = 0
-        while (c0.cores[self.n_cores].n_pipelines > 0):
-            self.n_cores += 1
-
-        self.n_pipelines = c0.n_pipelines
-        self.ctx2 = ctx2
-
-        self.arr_pipelines2cores = [0] * self.n_pipelines
-
-        i = 0
-        while (i < self.n_cores):
-            self.cores[i].n_pipelines = c0.cores[i].n_pipelines
-            i += 1
-
-    def stage1_process(self):
-        pipelines_max = len2mask(self.n_pipelines)
-        while True:
-            pos = 0
-            overlap = 0
-
-            if (self.cores[self.pos].pipelines == pipelines_max):
-                if (self.pos == 0):
-                    return
-
-                self.cores[self.pos].pipelines = 0
-                self.pos -= 1
-                continue
-
-            self.cores[self.pos].pipelines += 1
-            if (popcount(self.cores[self.pos].pipelines) !=
-                    self.cores[self.pos].n_pipelines):
-                continue
-
-            overlap = 0
-            pos = 0
-            while (pos < self.pos):
-                if ((self.cores[self.pos].pipelines) &
-                        (self.cores[pos].pipelines)):
-                    overlap = 1
-                    break
-                pos += 1
-
-            if (overlap):
-                continue
-
-            if ((self.pos > 0) and
-                ((self.cores[self.pos].n_pipelines) ==
-                    (self.cores[self.pos - 1].n_pipelines)) and
-                    ((self.cores[self.pos].pipelines) <
-                        (self.cores[self.pos - 1].pipelines))):
-                continue
-
-            if (self.pos == self.n_cores - 1):
-                self.stage1_log()
-                self.ctx2.stage2_init(self)
-                self.ctx2.stage2_process()
-
-                if (self.pos == 0):
-                    return
-
-                self.cores[self.pos].pipelines = 0
-                self.pos -= 1
-                continue
-
-            self.pos += 1
-
-    def stage1_log(self):
-        tmp_file_comment = ""
-        if(enable_stage1_traceout == 1):
-            print('STAGE1: ', end='')
-            tmp_file_comment += 'STAGE1: '
-            i = 0
-            while (i < self.n_cores):
-                print('C%d = [' % i, end='')
-                tmp_file_comment += "C{} = [".format(i)
-
-                j = self.n_pipelines - 1
-                while (j >= 0):
-                    cond = ((self.cores[i].pipelines) & (1 << j))
-                    if (cond):
-                        print('1', end='')
-                        tmp_file_comment += '1'
-                    else:
-                        print('0', end='')
-                        tmp_file_comment += '0'
-                    j -= 1
-
-                print(']\t', end='')
-                tmp_file_comment += ']\t'
-                i += 1
-
-            print('\n', end='')
-            self.stage1_file_comment = tmp_file_comment
-            self.ctx2.stage1_file_comment = tmp_file_comment
-
-        # check if file traceing is enabled
-        if(enable_stage1_fileout != 1):
-            return
-
-        # spit out the combination to file
-        self.stage1_process_file()
-
-    def stage1_updateCoresInBuf(self, nPipeline, sCore):
-        rePipeline = self._fileTrace.arr_pipelines[nPipeline]
-        rePipeline = rePipeline.replace("[", "\[").replace("]", "\]")
-        reCore = 'core\s*=\s*((\d*)|(((s|S)\d)?(c|C)[1-9][0-9]*)).*\n'
-        sSubs = 'core = ' + sCore + '\n'
-
-        reg_pipeline = re.compile(rePipeline)
-        search_match = reg_pipeline.search(self._fileTrace.in_buf)
-
-        if(search_match):
-            pos = search_match.start()
-            substr1 = self._fileTrace.in_buf[:pos]
-            substr2 = self._fileTrace.in_buf[pos:]
-            substr2 = re.sub(reCore, sSubs, substr2, 1)
-            self._fileTrace.in_buf = substr1 + substr2
-
-    def stage1_process_file(self):
-        outFileName = os.path.join(self._fileTrace.out_path,
-                                   self._fileTrace.prefix_outfile)
-        outFileName += "_{}CoReS".format(self.n_cores)
-
-        i = 0  # represents core number
-        while (i < self.n_cores):
-            j = self.n_pipelines - 1
-            pipeline_idx = 0
-            while(j >= 0):
-                cond = ((self.cores[i].pipelines) & (1 << j))
-                if (cond):
-                    # update the pipelines array to match the core
-                    # only in case of cond match
-                    self.arr_pipelines2cores[
-                        pipeline_idx] = fileTrace.in_physical_cores[i]
-
-                j -= 1
-                pipeline_idx += 1
-
-            i += 1
-
-        # update the in_buf as per the arr_pipelines2cores
-        for pipeline_idx in range(len(self.arr_pipelines2cores)):
-            outFileName += "_{}".format(self.arr_pipelines2cores[pipeline_idx])
-            self.stage1_updateCoresInBuf(
-                pipeline_idx, self.arr_pipelines2cores[pipeline_idx])
-
-        # by now the in_buf is all set to be written to file
-        outFileName += self._fileTrace.suffix_outfile
-        outputFile = open(outFileName, "w")
-
-        # write out the comments
-        strTruncated = ("", "(Truncated)")[self._fileTrace.ncores_truncated]
-        outputFile.write(
-            "; =============== Pipeline-to-Core Mapping ================\n"
-            "; Generated from file {}\n"
-            "; Input pipelines = {}\n"
-            "; Input cores = {}\n"
-            "; N_PIPELINES = {} N_CORES = {} {} hyper_thread = {}\n"
-            .format(
-                self._fileTrace.in_file_namepath,
-                fileTrace.arr_pipelines,
-                fileTrace.in_physical_cores,
-                self._fileTrace.n_pipelines,
-                self._fileTrace.n_cores,
-                strTruncated,
-                self._fileTrace.hyper_thread))
-
-        outputFile.write(
-            "; {stg0cmt}\n"
-            "; {stg1cmt}\n"
-            "; ========================================================\n"
-            "; \n"
-            .format(
-                stg0cmt=self.stage0_file_comment,
-                stg1cmt=self.stage1_file_comment))
-
-        # write buffer contents
-        outputFile.write(self._fileTrace.in_buf)
-        outputFile.flush()
-        outputFile.close()
-
-
-class Context2:
-    _fileTrace = None
-
-    def __init__(self):
-        self.cores = [Cores2() for i in range(constants.MAX_CORES)]
-        self.n_cores = 0
-        self.n_pipelines = 0
-        self.pos = 0
-        self.stage0_file_comment = ""
-        self.stage1_file_comment = ""
-        self.stage2_file_comment = ""
-
-        # each array entry is a pipeline mapped to core stored as string
-        # pipeline ranging from 1 to n, however stored in zero based array
-        self.arr2_pipelines2cores = []
-
-    def stage2_print(self):
-        print('printing Context2 obj')
-        print('ctx2.cores(pipelines, n_pipelines, counter, counter_max) =')
-        for cores_count in range(0, constants.MAX_CORES):
-            print('core[%d] = (%d,%d,%d,%d)' % (
-                cores_count,
-                self.cores[cores_count].pipelines,
-                self.cores[cores_count].n_pipelines,
-                self.cores[cores_count].counter,
-                self.cores[cores_count].counter_max))
-
-            print('ctx2.n_cores = %d' % self.n_cores, end='')
-            print('ctx2.n_pipelines = %d' % self.n_pipelines, end='')
-            print('ctx2.pos = %d' % self.pos)
-            print('ctx2.stage0_file_comment = %s' %
-                  self.self.stage0_file_comment)
-            print('ctx2.stage1_file_comment = %s' %
-                  self.self.stage1_file_comment)
-            print('ctx2.stage2_file_comment = %s' %
-                  self.self.stage2_file_comment)
-
-    def stage2_reset(self):
-        for i in range(0, constants.MAX_CORES):
-            self.cores[i].pipelines = 0
-            self.cores[i].n_pipelines = 0
-            self.cores[i].counter = 0
-            self.cores[i].counter_max = 0
-
-            for idx in range(0, constants.MAX_PIPELINES):
-                self.cores[i].bitpos[idx] = 0
-
-        self.n_cores = 0
-        self.n_pipelines = 0
-        self.pos = 0
-        # clear list
-        del self.arr2_pipelines2cores[:]
-
-    def bitpos_load(self, coreidx):
-        i = j = 0
-        while (i < self.n_pipelines):
-            if ((self.cores[coreidx].pipelines) &
-                    (1 << i)):
-                self.cores[coreidx].bitpos[j] = i
-                j += 1
-            i += 1
-        self.cores[coreidx].n_pipelines = j
-
-    def bitpos_apply(self, in_buf, pos, n_pos):
-        out = 0
-        for i in range(0, n_pos):
-            out |= (in_buf & (1 << i)) << (pos[i] - i)
-
-        return out
-
-    def stage2_init(self, ctx1):
-        self.stage2_reset()
-        self.n_cores = ctx1.n_cores
-        self.n_pipelines = ctx1.n_pipelines
-
-        self.arr2_pipelines2cores = [''] * self.n_pipelines
-
-        core_idx = 0
-        while (core_idx < self.n_cores):
-            self.cores[core_idx].pipelines = ctx1.cores[core_idx].pipelines
-
-            self.bitpos_load(core_idx)
-            core_idx += 1
-
-    def stage2_log(self):
-        tmp_file_comment = ""
-        if(enable_stage2_traceout == 1):
-            print('STAGE2: ', end='')
-            tmp_file_comment += 'STAGE2: '
-
-            for i in range(0, self.n_cores):
-                mask = len2mask(self.cores[i].n_pipelines)
-                pipelines_ht0 = self.bitpos_apply(
-                    (~self.cores[i].counter) & mask,
-                    self.cores[i].bitpos,
-                    self.cores[i].n_pipelines)
-
-                pipelines_ht1 = self.bitpos_apply(
-                    self.cores[i].counter,
-                    self.cores[i].bitpos,
-                    self.cores[i].n_pipelines)
-
-                print('C%dHT0 = [' % i, end='')
-                tmp_file_comment += "C{}HT0 = [".format(i)
-                tmp_file_comment += bitstring_write(
-                    pipelines_ht0, self.n_pipelines)
-
-                print(']\tC%dHT1 = [' % i, end='')
-                tmp_file_comment += "]\tC{}HT1 = [".format(i)
-                tmp_file_comment += bitstring_write(
-                    pipelines_ht1, self.n_pipelines)
-                print(']\t', end='')
-                tmp_file_comment += ']\t'
-
-            print('')
-            self.stage2_file_comment = tmp_file_comment
-
-        # check if file traceing is enabled
-        if(enable_stage2_fileout != 1):
-            return
-        # spit out the combination to file
-        self.stage2_process_file()
-
-    def stage2_updateCoresInBuf(self, nPipeline, sCore):
-        rePipeline = self._fileTrace.arr_pipelines[nPipeline]
-        rePipeline = rePipeline.replace("[", "\[").replace("]", "\]")
-        reCore = 'core\s*=\s*((\d*)|(((s|S)\d)?(c|C)[1-9][0-9]*)).*\n'
-        sSubs = 'core = ' + sCore + '\n'
-
-        reg_pipeline = re.compile(rePipeline)
-        search_match = reg_pipeline.search(self._fileTrace.in_buf)
-
-        if(search_match):
-            pos = search_match.start()
-            substr1 = self._fileTrace.in_buf[:pos]
-            substr2 = self._fileTrace.in_buf[pos:]
-            substr2 = re.sub(reCore, sSubs, substr2, 1)
-            self._fileTrace.in_buf = substr1 + substr2
-
-    def pipelines2cores(self, n, n_bits, nCore, bHT):
-        if (n_bits > 64):
-            return
-
-        i = n_bits - 1
-        pipeline_idx = 0
-        while (i >= 0):
-            cond = (n & (1 << i))
-            if (cond):
-                # update the pipelines array to match the core
-                # only in case of cond match
-                # PIPELINE0 and core 0 are reserved
-                if(bHT):
-                    tmpCore = fileTrace.in_physical_cores[nCore] + 'h'
-                    self.arr2_pipelines2cores[pipeline_idx] = tmpCore
-                else:
-                    self.arr2_pipelines2cores[pipeline_idx] = \
-                        fileTrace.in_physical_cores[nCore]
-
-            i -= 1
-            pipeline_idx += 1
-
-    def stage2_process_file(self):
-        outFileName = os.path.join(self._fileTrace.out_path,
-                                   self._fileTrace.prefix_outfile)
-        outFileName += "_{}CoReS".format(self.n_cores)
-
-        for i in range(0, self.n_cores):
-            mask = len2mask(self.cores[i].n_pipelines)
-            pipelines_ht0 = self.bitpos_apply((~self.cores[i].counter) & mask,
-                                              self.cores[i].bitpos,
-                                              self.cores[i].n_pipelines)
-
-            pipelines_ht1 = self.bitpos_apply(self.cores[i].counter,
-                                              self.cores[i].bitpos,
-                                              self.cores[i].n_pipelines)
-
-            # update pipelines to core mapping
-            self.pipelines2cores(pipelines_ht0, self.n_pipelines, i, False)
-            self.pipelines2cores(pipelines_ht1, self.n_pipelines, i, True)
-
-        # update the in_buf as per the arr_pipelines2cores
-        for pipeline_idx in range(len(self.arr2_pipelines2cores)):
-            outFileName += "_{}".format(
-                self.arr2_pipelines2cores[pipeline_idx])
-            self.stage2_updateCoresInBuf(
-                pipeline_idx, self.arr2_pipelines2cores[pipeline_idx])
-
-        # by now the in_buf is all set to be written to file
-        outFileName += self._fileTrace.suffix_outfile
-        outputFile = open(outFileName, "w")
-
-        # write the file comments
-        strTruncated = ("", "(Truncated)")[self._fileTrace.ncores_truncated]
-        outputFile.write(
-            "; =============== Pipeline-to-Core Mapping ================\n"
-            "; Generated from file {}\n"
-            "; Input pipelines = {}\n"
-            "; Input cores = {}\n"
-            "; N_PIPELINES = {}  N_CORES = {} {} hyper_thread = {} \n"
-            .format(
-                self._fileTrace.in_file_namepath,
-                fileTrace.arr_pipelines,
-                fileTrace.in_physical_cores,
-                self._fileTrace.n_pipelines,
-                self._fileTrace.n_cores,
-                strTruncated,
-                self._fileTrace.hyper_thread))
-
-        outputFile.write(
-            "; {stg0cmt}\n"
-            "; {stg1cmt}\n"
-            "; {stg2cmt}\n"
-            "; ========================================================\n"
-            "; \n"
-            .format(
-                stg0cmt=self.stage0_file_comment,
-                stg1cmt=self.stage1_file_comment,
-                stg2cmt=self.stage2_file_comment))
-
-        # write the buffer contents
-        outputFile.write(self._fileTrace.in_buf)
-        outputFile.flush()
-        outputFile.close()
-
-    def stage2_process(self):
-        i = 0
-        while(i < self.n_cores):
-            self.cores[i].counter_max = len2mask(
-                self.cores[i].n_pipelines - 1)
-            i += 1
-
-        self.pos = self.n_cores - 1
-        while True:
-            if (self.pos == self.n_cores - 1):
-                self.stage2_log()
-
-            if (self.cores[self.pos].counter ==
-                    self.cores[self.pos].counter_max):
-                if (self.pos == 0):
-                    return
-
-                self.cores[self.pos].counter = 0
-                self.pos -= 1
-                continue
-
-            self.cores[self.pos].counter += 1
-            if(self.pos < self.n_cores - 1):
-                self.pos += 1
-
-
-class FileTrace:
-
-    def __init__(self, filenamepath):
-        self.in_file_namepath = os.path.abspath(filenamepath)
-        self.in_filename = os.path.basename(self.in_file_namepath)
-        self.in_path = os.path.dirname(self.in_file_namepath)
-
-        filenamesplit = self.in_filename.split('.')
-        self.prefix_outfile = filenamesplit[0]
-        self.suffix_outfile = ".cfg"
-
-        # output folder:  in the same folder as input file
-        # create new folder in the name of input file
-        self.out_path = os.path.join(
-            os.path.abspath(os.path.dirname(__file__)),
-            self.prefix_outfile)
-
-        try:
-            os.makedirs(self.out_path)
-        except OSError as excep:
-            if excep.errno == errno.EEXIST and os.path.isdir(self.out_path):
-                pass
-            else:
-                raise
-
-        self.in_buf = None
-        self.arr_pipelines = []  # holds the positions of search
-
-        self.max_cores = 15
-        self.max_pipelines = 15
-
-        self.in_physical_cores = None
-        self.hyper_thread = None
-
-        # save the num of pipelines determined from input file
-        self.n_pipelines = 0
-        # save the num of cores input (or the truncated value)
-        self.n_cores = 0
-        self.ncores_truncated = False
-
-    def print_TraceFile(self):
-        print("self.in_file_namepath = ", self.in_file_namepath)
-        print("self.in_filename = ", self.in_filename)
-        print("self.in_path = ", self.in_path)
-        print("self.out_path = ", self.out_path)
-        print("self.prefix_outfile = ", self.prefix_outfile)
-        print("self.suffix_outfile = ", self.suffix_outfile)
-        print("self.in_buf = ", self.in_buf)
-        print("self.arr_pipelines =", self.arr_pipelines)
-        print("self.in_physical_cores", self.in_physical_cores)
-        print("self.hyper_thread", self.hyper_thread)
-
-
-def process(n_cores, n_pipelines, fileTrace):
-    '''process and map pipelines, cores.'''
-    if (n_cores == 0):
-        sys.exit('N_CORES is 0, exiting')
-
-    if (n_pipelines == 0):
-        sys.exit('N_PIPELINES is 0, exiting')
-
-    if (n_cores > n_pipelines):
-        print('\nToo many cores, truncating N_CORES to N_PIPELINES')
-        n_cores = n_pipelines
-        fileTrace.ncores_truncated = True
-
-    fileTrace.n_pipelines = n_pipelines
-    fileTrace.n_cores = n_cores
-
-    strTruncated = ("", "(Truncated)")[fileTrace.ncores_truncated]
-    print("N_PIPELINES = {}, N_CORES = {} {}"
-          .format(n_pipelines, n_cores, strTruncated))
-    print("---------------------------------------------------------------")
-
-    ctx0_inst = Context0()
-    ctx1_inst = Context1()
-    ctx2_inst = Context2()
-
-    # initialize the class variables
-    ctx1_inst._fileTrace = fileTrace
-    ctx2_inst._fileTrace = fileTrace
-
-    ctx0_inst.stage0_init(n_cores, n_pipelines, ctx1_inst, ctx2_inst)
-    ctx0_inst.stage0_process()
-
-
-def validate_core(core):
-    match = reg_phycore.match(core)
-    if(match):
-        return True
-    else:
-        return False
-
-
-def validate_phycores(phy_cores):
-    '''validate physical cores, check if unique.'''
-    # eat up whitespaces
-    phy_cores = phy_cores.strip().split(',')
-
-    # check if the core list is unique
-    if(len(phy_cores) != len(set(phy_cores))):
-        print('list of physical cores has duplicates')
-        return None
-
-    for core in phy_cores:
-        if not validate_core(core):
-            print('invalid physical core specified.')
-            return None
-    return phy_cores
-
-
-def scanconfigfile(fileTrace):
-    '''scan input file for pipelines, validate then process.'''
-    # open file
-    filetoscan = open(fileTrace.in_file_namepath, 'r')
-    fileTrace.in_buf = filetoscan.read()
-
-    # reset iterator on open file
-    filetoscan.seek(0)
-
-    # scan input file for pipelines
-    # master pipelines to be ignored
-    pattern_pipeline = r'\[PIPELINE\d*\]'
-    pattern_mastertype = r'type\s*=\s*MASTER'
-
-    pending_pipeline = False
-    for line in filetoscan:
-        match_pipeline = re.search(pattern_pipeline, line)
-        match_type = re.search('type\s*=', line)
-        match_mastertype = re.search(pattern_mastertype, line)
-
-        if(match_pipeline):
-            sPipeline = line[match_pipeline.start():match_pipeline.end()]
-            pending_pipeline = True
-        elif(match_type):
-            # found a type definition...
-            if(match_mastertype is None):
-                # and this is not a master pipeline...
-                if(pending_pipeline):
-                    # add it to the list of pipelines to be mapped
-                    fileTrace.arr_pipelines.append(sPipeline)
-                    pending_pipeline = False
-            else:
-                # and this is a master pipeline...
-                # ignore the current and move on to next
-                sPipeline = ""
-                pending_pipeline = False
-    filetoscan.close()
-
-    # validate if pipelines are unique
-    if(len(fileTrace.arr_pipelines) != len(set(fileTrace.arr_pipelines))):
-        sys.exit('Error: duplicate pipelines in input file')
-
-    num_pipelines = len(fileTrace.arr_pipelines)
-    num_cores = len(fileTrace.in_physical_cores)
-
-    print("-------------------Pipeline-to-core mapping--------------------")
-    print("Input pipelines = {}\nInput cores = {}"
-          .format(fileTrace.arr_pipelines, fileTrace.in_physical_cores))
-
-    # input configuration file validations goes here
-    if (num_cores > fileTrace.max_cores):
-        sys.exit('Error: number of cores specified > max_cores (%d)' %
-                 fileTrace.max_cores)
-
-    if (num_pipelines > fileTrace.max_pipelines):
-        sys.exit('Error: number of pipelines in input \
-                cfg file > max_pipelines (%d)' % fileTrace.max_pipelines)
-
-    # call process to generate pipeline-to-core mapping, trace and log
-    process(num_cores, num_pipelines, fileTrace)
-
-
-if __name__ == "__main__":
-    parser = argparse.ArgumentParser(description='mappipelines')
-
-    reqNamedGrp = parser.add_argument_group('required named args')
-    reqNamedGrp.add_argument(
-        '-i',
-        '--input-file',
-        type=argparse.FileType('r'),
-        help='Input config file',
-        required=True)
-
-    reqNamedGrp.add_argument(
-        '-pc',
-        '--physical-cores',
-        type=validate_phycores,
-        help='''Enter available CPU cores in
-                format:\"<core>,<core>,...\"
-                where each core format: \"s<SOCKETID>c<COREID>\"
-                where SOCKETID={0..9}, COREID={1-99}''',
-        required=True)
-
-    # add optional arguments
-    parser.add_argument(
-        '-ht',
-        '--hyper-thread',
-        help='enable/disable hyper threading. default is ON',
-        default='ON',
-        choices=['ON', 'OFF'])
-
-    parser.add_argument(
-        '-nO',
-        '--no-output-file',
-        help='''disable output config file generation.
-                Output file generation is enabled by default''',
-        action="store_true")
-
-    args = parser.parse_args()
-
-    if(args.physical_cores is None):
-        parser.error("invalid physical_cores specified")
-
-    # create object of FileTrace and initialise
-    fileTrace = FileTrace(args.input_file.name)
-    fileTrace.in_physical_cores = args.physical_cores
-    fileTrace.hyper_thread = args.hyper_thread
-
-    if(fileTrace.hyper_thread == 'OFF'):
-        print("!!!!disabling stage2 HT!!!!")
-        enable_stage2_traceout = 0
-        enable_stage2_fileout = 0
-    elif(fileTrace.hyper_thread == 'ON'):
-        print("!!!!HT enabled. disabling stage1 file generation.!!!!")
-        enable_stage1_fileout = 0
-
-    if(args.no_output_file is True):
-        print("!!!!disabling stage1 and stage2 fileout!!!!")
-        enable_stage1_fileout = 0
-        enable_stage2_fileout = 0
-
-    scanconfigfile(fileTrace)
diff --git a/examples/ip_pipeline/config/tap.cfg b/examples/ip_pipeline/config/tap.cfg
deleted file mode 100644
index 10d35eb..0000000
--- a/examples/ip_pipeline/config/tap.cfg
+++ /dev/null
@@ -1,64 +0,0 @@
-;   BSD LICENSE
-;
-;   Copyright(c) 2016 Intel Corporation. All rights reserved.
-;   All rights reserved.
-;
-;   Redistribution and use in source and binary forms, with or without
-;   modification, are permitted provided that the following conditions
-;   are met:
-;
-;     * Redistributions of source code must retain the above copyright
-;       notice, this list of conditions and the following disclaimer.
-;     * Redistributions in binary form must reproduce the above copyright
-;       notice, this list of conditions and the following disclaimer in
-;       the documentation and/or other materials provided with the
-;       distribution.
-;     * Neither the name of Intel Corporation nor the names of its
-;       contributors may be used to endorse or promote products derived
-;       from this software without specific prior written permission.
-;
-;   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-;   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-;   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-;   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-;   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-;   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-;   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-;   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-;   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-;   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-;   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-;             ______________          ______________________
-;            |              |  TAP0  |                      |
-; RXQ0.0 --->|              |------->|--+                   |
-;            |              |  TAP1  |  | br0               |
-; TXQ1.0 <---|              |<-------|<-+                   |
-;            | Pass-through |        |     Linux Kernel     |
-;            |     (P1)     |        |     Network Stack    |
-;            |              |  TAP1  |                      |
-; RXQ1.0 --->|              |------->|--+                   |
-;            |              |  TAP0  |  | br0               |
-; TXQ0.0 <---|              |<-------|<-+                   |
-;            |______________|        |______________________|
-;
-; Configure Linux kernel bridge between TAP0 and TAP1 interfaces:
-;    [Linux]$ ifconfig TAP0 up
-;    [Linux]$ ifconfig TAP1 up
-;    [Linux]$ brctl addbr "br0"
-;    [Linux]$ brctl addif br0 TAP0
-;    [Linux]$ brctl addif br0 TAP1
-;    [Linux]$ ifconfig br0 up
-
-[EAL]
-log_level = 0
-
-[PIPELINE0]
-type = MASTER
-core = 0
-
-[PIPELINE1]
-type = PASS-THROUGH
-core = 1
-pktq_in = RXQ0.0 TAP1 RXQ1.0 TAP0
-pktq_out = TAP0 TXQ1.0 TAP1 TXQ0.0
diff --git a/examples/ip_pipeline/config/tm_profile.cfg b/examples/ip_pipeline/config/tm_profile.cfg
deleted file mode 100644
index 2dfb215..0000000
--- a/examples/ip_pipeline/config/tm_profile.cfg
+++ /dev/null
@@ -1,105 +0,0 @@
-;   BSD LICENSE
-;
-;   Copyright(c) 2010-2014 Intel Corporation. All rights reserved.
-;   All rights reserved.
-;
-;   Redistribution and use in source and binary forms, with or without
-;   modification, are permitted provided that the following conditions
-;   are met:
-;
-;     * Redistributions of source code must retain the above copyright
-;       notice, this list of conditions and the following disclaimer.
-;     * Redistributions in binary form must reproduce the above copyright
-;       notice, this list of conditions and the following disclaimer in
-;       the documentation and/or other materials provided with the
-;       distribution.
-;     * Neither the name of Intel Corporation nor the names of its
-;       contributors may be used to endorse or promote products derived
-;       from this software without specific prior written permission.
-;
-;   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-;   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-;   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-;   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-;   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-;   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-;   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-;   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-;   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-;   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-;   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-; This file enables the following hierarchical scheduler configuration for each
-; 10GbE output port:
-;	* Single subport (subport 0):
-;		- Subport rate set to 100% of port rate
-;		- Each of the 4 traffic classes has rate set to 100% of port rate
-;	* 4K pipes per subport 0 (pipes 0 .. 4095) with identical configuration:
-;		- Pipe rate set to 1/4K of port rate
-;		- Each of the 4 traffic classes has rate set to 100% of pipe rate
-;		- Within each traffic class, the byte-level WRR weights for the 4 queues
-;         are set to 1:1:1:1
-;
-; For more details, please refer to chapter "Quality of Service (QoS) Framework"
-; of Data Plane Development Kit (DPDK) Programmer's Guide.
-
-; Port configuration
-[port]
-frame overhead = 24 ; frame overhead = Preamble (7) + SFD (1) + FCS (4) + IFG (12)
-mtu = 1522; mtu = Q-in-Q MTU (FCS not included)
-number of subports per port = 1
-number of pipes per subport = 4096
-queue sizes = 64 64 64 64
-
-; Subport configuration
-[subport 0]
-tb rate = 1250000000           ; Bytes per second
-tb size = 1000000              ; Bytes
-
-tc 0 rate = 1250000000         ; Bytes per second
-tc 1 rate = 1250000000         ; Bytes per second
-tc 2 rate = 1250000000         ; Bytes per second
-tc 3 rate = 1250000000         ; Bytes per second
-tc period = 10                 ; Milliseconds
-
-pipe 0-4095 = 0                ; These pipes are configured with pipe profile 0
-
-; Pipe configuration
-[pipe profile 0]
-tb rate = 305175               ; Bytes per second
-tb size = 1000000              ; Bytes
-
-tc 0 rate = 305175             ; Bytes per second
-tc 1 rate = 305175             ; Bytes per second
-tc 2 rate = 305175             ; Bytes per second
-tc 3 rate = 305175             ; Bytes per second
-tc period = 40                 ; Milliseconds
-
-tc 3 oversubscription weight = 1
-
-tc 0 wrr weights = 1 1 1 1
-tc 1 wrr weights = 1 1 1 1
-tc 2 wrr weights = 1 1 1 1
-tc 3 wrr weights = 1 1 1 1
-
-; RED params per traffic class and color (Green / Yellow / Red)
-[red]
-tc 0 wred min = 48 40 32
-tc 0 wred max = 64 64 64
-tc 0 wred inv prob = 10 10 10
-tc 0 wred weight = 9 9 9
-
-tc 1 wred min = 48 40 32
-tc 1 wred max = 64 64 64
-tc 1 wred inv prob = 10 10 10
-tc 1 wred weight = 9 9 9
-
-tc 2 wred min = 48 40 32
-tc 2 wred max = 64 64 64
-tc 2 wred inv prob = 10 10 10
-tc 2 wred weight = 9 9 9
-
-tc 3 wred min = 48 40 32
-tc 3 wred max = 64 64 64
-tc 3 wred inv prob = 10 10 10
-tc 3 wred weight = 9 9 9
diff --git a/examples/ip_pipeline/config_check.c b/examples/ip_pipeline/config_check.c
deleted file mode 100644
index 86d1191..0000000
--- a/examples/ip_pipeline/config_check.c
+++ /dev/null
@@ -1,488 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#include <stdio.h>
-
-#include <rte_ip.h>
-
-#include "app.h"
-
-static void
-check_mempools(struct app_params *app)
-{
-	uint32_t i;
-
-	for (i = 0; i < app->n_mempools; i++) {
-		struct app_mempool_params *p = &app->mempool_params[i];
-
-		APP_CHECK((p->pool_size > 0),
-			"Mempool %s size is 0\n", p->name);
-
-		APP_CHECK((p->cache_size > 0),
-			"Mempool %s cache size is 0\n", p->name);
-
-		APP_CHECK(rte_is_power_of_2(p->cache_size),
-			"Mempool %s cache size not a power of 2\n", p->name);
-	}
-}
-
-static inline uint32_t
-link_rxq_used(struct app_link_params *link, uint32_t q_id)
-{
-	uint32_t i;
-
-	if ((link->arp_q == q_id) ||
-		(link->tcp_syn_q == q_id) ||
-		(link->ip_local_q == q_id) ||
-		(link->tcp_local_q == q_id) ||
-		(link->udp_local_q == q_id) ||
-		(link->sctp_local_q == q_id))
-		return 1;
-
-	for (i = 0; i < link->n_rss_qs; i++)
-		if (link->rss_qs[i] == q_id)
-			return 1;
-
-	return 0;
-}
-
-static void
-check_links(struct app_params *app)
-{
-	uint32_t i;
-
-	/* Check that number of links matches the port mask */
-	if (app->port_mask) {
-		uint32_t n_links_port_mask =
-			__builtin_popcountll(app->port_mask);
-
-		APP_CHECK((app->n_links == n_links_port_mask),
-			"Not enough links provided in the PORT_MASK\n");
-	}
-
-	for (i = 0; i < app->n_links; i++) {
-		struct app_link_params *link = &app->link_params[i];
-		uint32_t rxq_max, n_rxq, n_txq, link_id, i;
-
-		APP_PARAM_GET_ID(link, "LINK", link_id);
-
-		/* Check that link RXQs are contiguous */
-		rxq_max = 0;
-		if (link->arp_q > rxq_max)
-			rxq_max = link->arp_q;
-		if (link->tcp_syn_q > rxq_max)
-			rxq_max = link->tcp_syn_q;
-		if (link->ip_local_q > rxq_max)
-			rxq_max = link->ip_local_q;
-		if (link->tcp_local_q > rxq_max)
-			rxq_max = link->tcp_local_q;
-		if (link->udp_local_q > rxq_max)
-			rxq_max = link->udp_local_q;
-		if (link->sctp_local_q > rxq_max)
-			rxq_max = link->sctp_local_q;
-		for (i = 0; i < link->n_rss_qs; i++)
-			if (link->rss_qs[i] > rxq_max)
-				rxq_max = link->rss_qs[i];
-
-		for (i = 1; i <= rxq_max; i++)
-			APP_CHECK((link_rxq_used(link, i)),
-				"%s RXQs are not contiguous (A)\n", link->name);
-
-		n_rxq = app_link_get_n_rxq(app, link);
-
-		APP_CHECK((n_rxq), "%s does not have any RXQ\n", link->name);
-
-		APP_CHECK((n_rxq == rxq_max + 1),
-			"%s RXQs are not contiguous (B)\n", link->name);
-
-		for (i = 0; i < n_rxq; i++) {
-			char name[APP_PARAM_NAME_SIZE];
-			int pos;
-
-			sprintf(name, "RXQ%" PRIu32 ".%" PRIu32,
-				link_id, i);
-			pos = APP_PARAM_FIND(app->hwq_in_params, name);
-			APP_CHECK((pos >= 0),
-				"%s RXQs are not contiguous (C)\n", link->name);
-		}
-
-		/* Check that link TXQs are contiguous */
-		n_txq = app_link_get_n_txq(app, link);
-
-		APP_CHECK((n_txq),  "%s does not have any TXQ\n", link->name);
-
-		for (i = 0; i < n_txq; i++) {
-			char name[APP_PARAM_NAME_SIZE];
-			int pos;
-
-			sprintf(name, "TXQ%" PRIu32 ".%" PRIu32,
-				link_id, i);
-			pos = APP_PARAM_FIND(app->hwq_out_params, name);
-			APP_CHECK((pos >= 0),
-				"%s TXQs are not contiguous\n", link->name);
-		}
-	}
-}
-
-static void
-check_rxqs(struct app_params *app)
-{
-	uint32_t i;
-
-	for (i = 0; i < app->n_pktq_hwq_in; i++) {
-		struct app_pktq_hwq_in_params *p = &app->hwq_in_params[i];
-		uint32_t n_readers = app_rxq_get_readers(app, p);
-
-		APP_CHECK((p->size > 0),
-			"%s size is 0\n", p->name);
-
-		APP_CHECK((rte_is_power_of_2(p->size)),
-			"%s size is not a power of 2\n", p->name);
-
-		APP_CHECK((p->burst > 0),
-			"%s burst size is 0\n", p->name);
-
-		APP_CHECK((p->burst <= p->size),
-			"%s burst size is bigger than its size\n", p->name);
-
-		APP_CHECK((n_readers != 0),
-			"%s has no reader\n", p->name);
-
-		APP_CHECK((n_readers == 1),
-			"%s has more than one reader\n", p->name);
-	}
-}
-
-static void
-check_txqs(struct app_params *app)
-{
-	uint32_t i;
-
-	for (i = 0; i < app->n_pktq_hwq_out; i++) {
-		struct app_pktq_hwq_out_params *p = &app->hwq_out_params[i];
-		uint32_t n_writers = app_txq_get_writers(app, p);
-
-		APP_CHECK((p->size > 0),
-			"%s size is 0\n", p->name);
-
-		APP_CHECK((rte_is_power_of_2(p->size)),
-			"%s size is not a power of 2\n", p->name);
-
-		APP_CHECK((p->burst > 0),
-			"%s burst size is 0\n", p->name);
-
-		APP_CHECK((p->burst <= p->size),
-			"%s burst size is bigger than its size\n", p->name);
-
-		APP_CHECK((n_writers != 0),
-			"%s has no writer\n", p->name);
-
-		APP_CHECK((n_writers == 1),
-			"%s has more than one writer\n", p->name);
-	}
-}
-
-static void
-check_swqs(struct app_params *app)
-{
-	uint32_t i;
-
-	for (i = 0; i < app->n_pktq_swq; i++) {
-		struct app_pktq_swq_params *p = &app->swq_params[i];
-		uint32_t n_readers = app_swq_get_readers(app, p);
-		uint32_t n_writers = app_swq_get_writers(app, p);
-		uint32_t n_flags;
-
-		APP_CHECK((p->size > 0),
-			"%s size is 0\n", p->name);
-
-		APP_CHECK((rte_is_power_of_2(p->size)),
-			"%s size is not a power of 2\n", p->name);
-
-		APP_CHECK((p->burst_read > 0),
-			"%s read burst size is 0\n", p->name);
-
-		APP_CHECK((p->burst_read <= p->size),
-			"%s read burst size is bigger than its size\n",
-			p->name);
-
-		APP_CHECK((p->burst_write > 0),
-			"%s write burst size is 0\n", p->name);
-
-		APP_CHECK((p->burst_write <= p->size),
-			"%s write burst size is bigger than its size\n",
-			p->name);
-
-		APP_CHECK((n_readers != 0),
-			"%s has no reader\n", p->name);
-
-		if (n_readers > 1)
-			APP_LOG(app, LOW, "%s has more than one reader", p->name);
-
-		APP_CHECK((n_writers != 0),
-			"%s has no writer\n", p->name);
-
-		if (n_writers > 1)
-			APP_LOG(app, LOW, "%s has more than one writer", p->name);
-
-		n_flags = p->ipv4_frag + p->ipv6_frag + p->ipv4_ras + p->ipv6_ras;
-
-		APP_CHECK((n_flags < 2),
-			"%s has more than one fragmentation or reassembly mode enabled\n",
-			p->name);
-
-		APP_CHECK((!((n_readers > 1) && (n_flags == 1))),
-			"%s has more than one reader when fragmentation or reassembly"
-			" mode enabled\n",
-			p->name);
-
-		APP_CHECK((!((n_writers > 1) && (n_flags == 1))),
-			"%s has more than one writer when fragmentation or reassembly"
-			" mode enabled\n",
-			p->name);
-
-		n_flags = p->ipv4_ras + p->ipv6_ras;
-
-		APP_CHECK((!((p->dropless == 1) && (n_flags == 1))),
-			"%s has dropless when reassembly mode enabled\n", p->name);
-
-		n_flags = p->ipv4_frag + p->ipv6_frag;
-
-		if (n_flags == 1) {
-			uint16_t ip_hdr_size = (p->ipv4_frag) ? sizeof(struct ipv4_hdr) :
-				sizeof(struct ipv6_hdr);
-
-			APP_CHECK((p->mtu > ip_hdr_size),
-				"%s mtu size is smaller than ip header\n", p->name);
-
-			APP_CHECK((!((p->mtu - ip_hdr_size) % 8)),
-				"%s mtu size is incorrect\n", p->name);
-		}
-	}
-}
-
-static void
-check_tms(struct app_params *app)
-{
-	uint32_t i;
-
-	for (i = 0; i < app->n_pktq_tm; i++) {
-		struct app_pktq_tm_params *p = &app->tm_params[i];
-		uint32_t n_readers = app_tm_get_readers(app, p);
-		uint32_t n_writers = app_tm_get_writers(app, p);
-
-		APP_CHECK((n_readers != 0),
-			"%s has no reader\n", p->name);
-
-		APP_CHECK((n_readers == 1),
-			"%s has more than one reader\n", p->name);
-
-		APP_CHECK((n_writers != 0),
-			"%s has no writer\n", p->name);
-
-		APP_CHECK((n_writers == 1),
-			"%s has more than one writer\n", p->name);
-	}
-}
-
-static void
-check_taps(struct app_params *app)
-{
-	uint32_t i;
-
-	for (i = 0; i < app->n_pktq_tap; i++) {
-		struct app_pktq_tap_params *p = &app->tap_params[i];
-		uint32_t n_readers = app_tap_get_readers(app, p);
-		uint32_t n_writers = app_tap_get_writers(app, p);
-
-		APP_CHECK((n_readers != 0),
-			"%s has no reader\n", p->name);
-
-		APP_CHECK((n_readers == 1),
-			"%s has more than one reader\n", p->name);
-
-		APP_CHECK((n_writers != 0),
-			"%s has no writer\n", p->name);
-
-		APP_CHECK((n_writers == 1),
-			"%s has more than one writer\n", p->name);
-
-		APP_CHECK((p->burst_read > 0),
-			"%s read burst size is 0\n", p->name);
-
-		APP_CHECK((p->burst_write > 0),
-			"%s write burst size is 0\n", p->name);
-	}
-}
-
-static void
-check_knis(struct app_params *app) {
-	uint32_t i;
-
-	for (i = 0; i < app->n_pktq_kni; i++) {
-		struct app_pktq_kni_params *p = &app->kni_params[i];
-		uint32_t n_readers = app_kni_get_readers(app, p);
-		uint32_t n_writers = app_kni_get_writers(app, p);
-
-		APP_CHECK((n_readers != 0),
-			"%s has no reader\n", p->name);
-
-		APP_CHECK((n_readers == 1),
-			"%s has more than one reader\n", p->name);
-
-		APP_CHECK((n_writers != 0),
-			"%s has no writer\n", p->name);
-
-		APP_CHECK((n_writers == 1),
-			"%s has more than one writer\n", p->name);
-	}
-}
-
-static void
-check_sources(struct app_params *app)
-{
-	uint32_t i;
-
-	for (i = 0; i < app->n_pktq_source; i++) {
-		struct app_pktq_source_params *p = &app->source_params[i];
-		uint32_t n_readers = app_source_get_readers(app, p);
-
-		APP_CHECK((n_readers != 0),
-			"%s has no reader\n", p->name);
-
-		APP_CHECK((n_readers == 1),
-			"%s has more than one reader\n", p->name);
-	}
-}
-
-static void
-check_sinks(struct app_params *app)
-{
-	uint32_t i;
-
-	for (i = 0; i < app->n_pktq_sink; i++) {
-		struct app_pktq_sink_params *p = &app->sink_params[i];
-		uint32_t n_writers = app_sink_get_writers(app, p);
-
-		APP_CHECK((n_writers != 0),
-			"%s has no writer\n", p->name);
-
-		APP_CHECK((n_writers == 1),
-			"%s has more than one writer\n", p->name);
-	}
-}
-
-static void
-check_msgqs(struct app_params *app)
-{
-	uint32_t i;
-
-	for (i = 0; i < app->n_msgq; i++) {
-		struct app_msgq_params *p = &app->msgq_params[i];
-		uint32_t n_readers = app_msgq_get_readers(app, p);
-		uint32_t n_writers = app_msgq_get_writers(app, p);
-		uint32_t msgq_req_pipeline, msgq_rsp_pipeline;
-		uint32_t msgq_req_core, msgq_rsp_core;
-
-		APP_CHECK((p->size > 0),
-			"%s size is 0\n", p->name);
-
-		APP_CHECK((rte_is_power_of_2(p->size)),
-			"%s size is not a power of 2\n", p->name);
-
-		msgq_req_pipeline = (strncmp(p->name, "MSGQ-REQ-PIPELINE",
-			strlen("MSGQ-REQ-PIPELINE")) == 0);
-
-		msgq_rsp_pipeline = (strncmp(p->name, "MSGQ-RSP-PIPELINE",
-			strlen("MSGQ-RSP-PIPELINE")) == 0);
-
-		msgq_req_core = (strncmp(p->name, "MSGQ-REQ-CORE",
-			strlen("MSGQ-REQ-CORE")) == 0);
-
-		msgq_rsp_core = (strncmp(p->name, "MSGQ-RSP-CORE",
-			strlen("MSGQ-RSP-CORE")) == 0);
-
-		if ((msgq_req_pipeline == 0) &&
-			(msgq_rsp_pipeline == 0) &&
-			(msgq_req_core == 0) &&
-			(msgq_rsp_core == 0)) {
-			APP_CHECK((n_readers != 0),
-				"%s has no reader\n", p->name);
-
-			APP_CHECK((n_readers == 1),
-				"%s has more than one reader\n", p->name);
-
-			APP_CHECK((n_writers != 0),
-				"%s has no writer\n", p->name);
-
-			APP_CHECK((n_writers == 1),
-				"%s has more than one writer\n", p->name);
-		}
-
-		if (msgq_req_pipeline) {
-			struct app_pipeline_params *pipeline;
-			uint32_t pipeline_id;
-
-			APP_PARAM_GET_ID(p, "MSGQ-REQ-PIPELINE", pipeline_id);
-
-			APP_PARAM_FIND_BY_ID(app->pipeline_params,
-				"PIPELINE",
-				pipeline_id,
-				pipeline);
-
-			APP_CHECK((pipeline != NULL),
-				"%s is not associated with a valid pipeline\n",
-				p->name);
-		}
-
-		if (msgq_rsp_pipeline) {
-			struct app_pipeline_params *pipeline;
-			uint32_t pipeline_id;
-
-			APP_PARAM_GET_ID(p, "MSGQ-RSP-PIPELINE", pipeline_id);
-
-			APP_PARAM_FIND_BY_ID(app->pipeline_params,
-				"PIPELINE",
-				pipeline_id,
-				pipeline);
-
-			APP_CHECK((pipeline != NULL),
-				"%s is not associated with a valid pipeline\n",
-				p->name);
-		}
-	}
-}
-
-static void
-check_pipelines(struct app_params *app)
-{
-	uint32_t i;
-
-	for (i = 0; i < app->n_pipelines; i++) {
-		struct app_pipeline_params *p = &app->pipeline_params[i];
-
-		APP_CHECK((p->n_msgq_in == p->n_msgq_out),
-			"%s number of input MSGQs does not match "
-			"the number of output MSGQs\n", p->name);
-	}
-}
-
-int
-app_config_check(struct app_params *app)
-{
-	check_mempools(app);
-	check_links(app);
-	check_rxqs(app);
-	check_txqs(app);
-	check_swqs(app);
-	check_tms(app);
-	check_taps(app);
-	check_knis(app);
-	check_sources(app);
-	check_sinks(app);
-	check_msgqs(app);
-	check_pipelines(app);
-
-	return 0;
-}
diff --git a/examples/ip_pipeline/config_parse.c b/examples/ip_pipeline/config_parse.c
deleted file mode 100644
index e90499e..0000000
--- a/examples/ip_pipeline/config_parse.c
+++ /dev/null
@@ -1,3395 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#include <stdint.h>
-#include <stdlib.h>
-#include <stdio.h>
-#include <ctype.h>
-#include <getopt.h>
-#include <errno.h>
-#include <stdarg.h>
-#include <string.h>
-#include <libgen.h>
-#include <unistd.h>
-#include <sys/wait.h>
-
-#include <rte_errno.h>
-#include <rte_cfgfile.h>
-#include <rte_string_fns.h>
-
-#include "app.h"
-#include "parser.h"
-
-/**
- * Default config values
- **/
-
-static struct app_params app_params_default = {
-	.config_file = "./config/ip_pipeline.cfg",
-	.log_level = APP_LOG_LEVEL_HIGH,
-	.port_mask = 0,
-
-	.eal_params = {
-		.channels = 4,
-	},
-};
-
-static const struct app_mempool_params mempool_params_default = {
-	.parsed = 0,
-	.buffer_size = 2048 + sizeof(struct rte_mbuf) + RTE_PKTMBUF_HEADROOM,
-	.pool_size = 32 * 1024,
-	.cache_size = 256,
-	.cpu_socket_id = 0,
-};
-
-static const struct app_link_params link_params_default = {
-	.parsed = 0,
-	.pmd_id = 0,
-	.arp_q = 0,
-	.tcp_syn_q = 0,
-	.ip_local_q = 0,
-	.tcp_local_q = 0,
-	.udp_local_q = 0,
-	.sctp_local_q = 0,
-	.rss_qs = {0},
-	.n_rss_qs = 0,
-	.rss_proto_ipv4 = ETH_RSS_IPV4,
-	.rss_proto_ipv6 = ETH_RSS_IPV6,
-	.rss_proto_l2 = 0,
-	.state = 0,
-	.ip = 0,
-	.depth = 0,
-	.mac_addr = 0,
-	.pci_bdf = {0},
-
-	.conf = {
-		.link_speeds = 0,
-		.rxmode = {
-			.mq_mode = ETH_MQ_RX_NONE,
-
-			.ignore_offload_bitfield = 1,
-			.offloads = DEV_RX_OFFLOAD_CRC_STRIP,
-
-			.max_rx_pkt_len = 9000, /* Jumbo frame max packet len */
-			.split_hdr_size = 0, /* Header split buffer size */
-		},
-		.rx_adv_conf = {
-			.rss_conf = {
-				.rss_key = NULL,
-				.rss_key_len = 40,
-				.rss_hf = 0,
-			},
-		},
-		.txmode = {
-			.mq_mode = ETH_MQ_TX_NONE,
-		},
-		.lpbk_mode = 0,
-	},
-
-	.promisc = 1,
-};
-
-static const struct app_pktq_hwq_in_params default_hwq_in_params = {
-	.parsed = 0,
-	.mempool_id = 0,
-	.size = 128,
-	.burst = 32,
-
-	.conf = {
-		.rx_thresh = {
-				.pthresh = 8,
-				.hthresh = 8,
-				.wthresh = 4,
-		},
-		.rx_free_thresh = 64,
-		.rx_drop_en = 0,
-		.rx_deferred_start = 0,
-	}
-};
-
-static const struct app_pktq_hwq_out_params default_hwq_out_params = {
-	.parsed = 0,
-	.size = 512,
-	.burst = 32,
-	.dropless = 0,
-	.n_retries = 0,
-
-	.conf = {
-		.tx_thresh = {
-			.pthresh = 36,
-			.hthresh = 0,
-			.wthresh = 0,
-		},
-		.tx_rs_thresh = 0,
-		.tx_free_thresh = 0,
-		.txq_flags = ETH_TXQ_FLAGS_IGNORE,
-		.tx_deferred_start = 0,
-	}
-};
-
-static const struct app_pktq_swq_params default_swq_params = {
-	.parsed = 0,
-	.size = 256,
-	.burst_read = 32,
-	.burst_write = 32,
-	.dropless = 0,
-	.n_retries = 0,
-	.cpu_socket_id = 0,
-	.ipv4_frag = 0,
-	.ipv6_frag = 0,
-	.ipv4_ras = 0,
-	.ipv6_ras = 0,
-	.mtu = 0,
-	.metadata_size = 0,
-	.mempool_direct_id = 0,
-	.mempool_indirect_id = 0,
-};
-
-struct app_pktq_tm_params default_tm_params = {
-	.parsed = 0,
-	.file_name = "./config/tm_profile.cfg",
-	.burst_read = 24,
-	.burst_write = 32,
-};
-
-struct app_pktq_tap_params default_tap_params = {
-	.parsed = 0,
-	.burst_read = 32,
-	.burst_write = 32,
-	.dropless = 0,
-	.n_retries = 0,
-	.mempool_id = 0,
-};
-
-struct app_pktq_kni_params default_kni_params = {
-	.parsed = 0,
-	.socket_id = 0,
-	.core_id = 0,
-	.hyper_th_id = 0,
-	.force_bind = 0,
-
-	.mempool_id = 0,
-	.burst_read = 32,
-	.burst_write = 32,
-	.dropless = 0,
-	.n_retries = 0,
-};
-
-struct app_pktq_source_params default_source_params = {
-	.parsed = 0,
-	.mempool_id = 0,
-	.burst = 32,
-	.file_name = "./config/packets.pcap",
-	.n_bytes_per_pkt = 0,
-};
-
-struct app_pktq_sink_params default_sink_params = {
-	.parsed = 0,
-	.file_name = NULL,
-	.n_pkts_to_dump = 0,
-};
-
-struct app_msgq_params default_msgq_params = {
-	.parsed = 0,
-	.size = 64,
-	.cpu_socket_id = 0,
-};
-
-struct app_pipeline_params default_pipeline_params = {
-	.parsed = 0,
-	.socket_id = 0,
-	.core_id = 0,
-	.hyper_th_id = 0,
-	.n_pktq_in = 0,
-	.n_pktq_out = 0,
-	.n_msgq_in = 0,
-	.n_msgq_out = 0,
-	.timer_period = 1,
-	.n_args = 0,
-};
-
-static const char app_usage[] =
-	"Usage: %s [-f CONFIG_FILE] [-s SCRIPT_FILE] [-p PORT_MASK] "
-	"[-l LOG_LEVEL] [--preproc PREPROCESSOR] [--preproc-args ARGS]\n"
-	"\n"
-	"Arguments:\n"
-	"\t-f CONFIG_FILE: Default config file is %s\n"
-	"\t-p PORT_MASK: Mask of NIC port IDs in hex format (generated from "
-		"config file when not provided)\n"
-	"\t-s SCRIPT_FILE: No CLI script file is run when not specified\n"
-	"\t-l LOG_LEVEL: 0 = NONE, 1 = HIGH PRIO (default), 2 = LOW PRIO\n"
-	"\t--preproc PREPROCESSOR: Configuration file pre-processor\n"
-	"\t--preproc-args ARGS: Arguments to be passed to pre-processor\n"
-	"\n";
-
-static void
-app_print_usage(char *prgname)
-{
-	rte_exit(0, app_usage, prgname, app_params_default.config_file);
-}
-
-#define APP_PARAM_ADD(set, key)						\
-({									\
-	ssize_t pos = APP_PARAM_FIND(set, key);				\
-	ssize_t size = RTE_DIM(set);					\
-									\
-	if (pos < 0) {							\
-		for (pos = 0; pos < size; pos++) {			\
-			if (!APP_PARAM_VALID(&((set)[pos])))		\
-				break;					\
-		}							\
-									\
-		APP_CHECK((pos < size),					\
-			"Parse error: size of %s is limited to %u elements",\
-			#set, (uint32_t) size);				\
-									\
-		(set)[pos].name = strdup(key);				\
-		APP_CHECK(((set)[pos].name),				\
-			"Parse error: no free memory");			\
-	}								\
-	pos;								\
-})
-
-#define APP_PARAM_ADD_LINK_FOR_RXQ(app, rxq_name)			\
-({									\
-	char link_name[APP_PARAM_NAME_SIZE];				\
-	ssize_t link_param_pos;						\
-	uint32_t link_id, queue_id;				\
-									\
-	sscanf((rxq_name), "RXQ%" SCNu32 ".%" SCNu32, &link_id, &queue_id);\
-	sprintf(link_name, "LINK%" PRIu32, link_id);			\
-	link_param_pos = APP_PARAM_ADD((app)->link_params, link_name);	\
-	link_param_pos;							\
-})
-
-#define APP_PARAM_ADD_LINK_FOR_TXQ(app, txq_name)			\
-({									\
-	char link_name[APP_PARAM_NAME_SIZE];				\
-	ssize_t link_param_pos;						\
-	uint32_t link_id, queue_id;					\
-									\
-	sscanf((txq_name), "TXQ%" SCNu32 ".%" SCNu32, &link_id, &queue_id);\
-	sprintf(link_name, "LINK%" PRIu32, link_id);			\
-	link_param_pos = APP_PARAM_ADD((app)->link_params, link_name);	\
-	link_param_pos;							\
-})
-
-#define APP_PARAM_ADD_LINK_FOR_TM(app, tm_name)				\
-({									\
-	char link_name[APP_PARAM_NAME_SIZE];				\
-	ssize_t link_param_pos;						\
-	uint32_t link_id;						\
-									\
-	sscanf((tm_name), "TM%" SCNu32, &link_id);			\
-	sprintf(link_name, "LINK%" PRIu32, link_id);			\
-	link_param_pos = APP_PARAM_ADD((app)->link_params, link_name);	\
-	link_param_pos;							\
-})
-
-#define APP_PARAM_ADD_LINK_FOR_KNI(app, kni_name)			\
-({									\
-	char link_name[APP_PARAM_NAME_SIZE];				\
-	ssize_t link_param_pos;						\
-	uint32_t link_id;						\
-									\
-	sscanf((kni_name), "KNI%" SCNu32, &link_id);		\
-	sprintf(link_name, "LINK%" PRIu32, link_id);			\
-	link_param_pos = APP_PARAM_ADD((app)->link_params, link_name);	\
-	link_param_pos;							\
-})
-
-#define PARSE_CHECK_DUPLICATE_SECTION(obj)				\
-do {									\
-	APP_CHECK(((obj)->parsed == 0),					\
-		"Parse error: duplicate \"%s\" section", (obj)->name);	\
-	(obj)->parsed++;					\
-} while (0)
-
-#define PARSE_CHECK_DUPLICATE_SECTION_EAL(obj)				\
-do {									\
-	APP_CHECK(((obj)->parsed == 0),					\
-		"Parse error: duplicate \"%s\" section", "EAL");	\
-	(obj)->parsed++;					\
-} while (0)
-
-#define PARSE_ERROR(exp, section, entry)				\
-APP_CHECK(exp, "Parse error in section \"%s\": entry \"%s\"", section, entry)
-
-#define PARSE_ERROR_MESSAGE(exp, section, entry, message)		\
-APP_CHECK(exp, "Parse error in section \"%s\", entry \"%s\": %s",	\
-	section, entry, message)
-
-#define PARSE_ERROR_NO_ELEMENTS(exp, section, entry)			\
-APP_CHECK(exp, "Parse error in section \"%s\", entry \"%s\": "		\
-	"no elements detected",						\
-	section, entry)
-
-#define PARSE_ERROR_TOO_MANY_ELEMENTS(exp, section, entry, max)		\
-APP_CHECK(exp, "Parse error in section \"%s\", entry \"%s\": "		\
-	"maximum number of elements allowed is %u",			\
-	section, entry, max)
-
-#define PARSE_ERROR_INVALID_ELEMENT(exp, section, entry, value)		\
-APP_CHECK(exp, "Parse error in section \"%s\", entry \"%s\": "		\
-	"Invalid element value \"%s\"",					\
-	section, entry, value)
-
-#define PARSE_ERROR_MALLOC(exp)						\
-APP_CHECK(exp, "Parse error: no free memory")
-
-#define PARSE_ERROR_SECTION(exp, section)				\
-APP_CHECK(exp, "Parse error in section \"%s\"", section)
-
-#define PARSE_ERROR_SECTION_NO_ENTRIES(exp, section)			\
-APP_CHECK(exp, "Parse error in section \"%s\": no entries", section)
-
-#define PARSE_WARNING_IGNORED(exp, section, entry)			\
-do									\
-if (!(exp))								\
-	fprintf(stderr, "Parse warning in section \"%s\": "		\
-		"entry \"%s\" is ignored", section, entry);		\
-while (0)
-
-#define PARSE_ERROR_INVALID(exp, section, entry)			\
-APP_CHECK(exp, "Parse error in section \"%s\": unrecognized entry \"%s\"",\
-	section, entry)
-
-#define PARSE_ERROR_DUPLICATE(exp, section, entry)			\
-APP_CHECK(exp, "Parse error in section \"%s\": duplicate entry \"%s\"",	\
-	section, entry)
-
-static int
-validate_name(const char *name, const char *prefix, int num)
-{
-	size_t i, j;
-
-	for (i = 0; (name[i] != '\0') && (prefix[i] != '\0'); i++) {
-		if (name[i] != prefix[i])
-			return -1;
-	}
-
-	if (prefix[i] != '\0')
-		return -1;
-
-	if (!num) {
-		if (name[i] != '\0')
-			return -1;
-		else
-			return 0;
-	}
-
-	if (num == 2) {
-		j = skip_digits(&name[i]);
-		i += j;
-		if ((j == 0) || (name[i] != '.'))
-			return -1;
-		i++;
-	}
-
-	if (num == 1) {
-		j = skip_digits(&name[i]);
-		i += j;
-		if ((j == 0) || (name[i] != '\0'))
-			return -1;
-	}
-
-	return 0;
-}
-
-static void
-parse_eal(struct app_params *app,
-	const char *section_name,
-	struct rte_cfgfile *cfg)
-{
-	struct app_eal_params *p = &app->eal_params;
-	struct rte_cfgfile_entry *entries;
-	int n_entries, i;
-
-	n_entries = rte_cfgfile_section_num_entries(cfg, section_name);
-	PARSE_ERROR_SECTION_NO_ENTRIES((n_entries > 0), section_name);
-
-	entries = malloc(n_entries * sizeof(struct rte_cfgfile_entry));
-	PARSE_ERROR_MALLOC(entries != NULL);
-
-	rte_cfgfile_section_entries(cfg, section_name, entries, n_entries);
-
-	PARSE_CHECK_DUPLICATE_SECTION_EAL(p);
-
-	for (i = 0; i < n_entries; i++) {
-		struct rte_cfgfile_entry *entry = &entries[i];
-
-		/* coremask */
-		if (strcmp(entry->name, "c") == 0) {
-			PARSE_WARNING_IGNORED(0, section_name, entry->name);
-			continue;
-		}
-
-		/* corelist */
-		if (strcmp(entry->name, "l") == 0) {
-			PARSE_WARNING_IGNORED(0, section_name, entry->name);
-			continue;
-		}
-
-		/* coremap */
-		if (strcmp(entry->name, "lcores") == 0) {
-			PARSE_ERROR_DUPLICATE((p->coremap == NULL),
-				section_name,
-				entry->name);
-			p->coremap = strdup(entry->value);
-			continue;
-		}
-
-		/* master_lcore */
-		if (strcmp(entry->name, "master_lcore") == 0) {
-			int status;
-
-			PARSE_ERROR_DUPLICATE((p->master_lcore_present == 0),
-				section_name,
-				entry->name);
-			p->master_lcore_present = 1;
-
-			status = parser_read_uint32(&p->master_lcore,
-				entry->value);
-			PARSE_ERROR((status == 0), section_name, entry->name);
-			continue;
-		}
-
-		/* channels */
-		if (strcmp(entry->name, "n") == 0) {
-			int status;
-
-			PARSE_ERROR_DUPLICATE((p->channels_present == 0),
-				section_name,
-				entry->name);
-			p->channels_present = 1;
-
-			status = parser_read_uint32(&p->channels, entry->value);
-			PARSE_ERROR((status == 0), section_name, entry->name);
-			continue;
-		}
-
-		/* memory */
-		if (strcmp(entry->name, "m") == 0) {
-			int status;
-
-			PARSE_ERROR_DUPLICATE((p->memory_present == 0),
-				section_name,
-				entry->name);
-			p->memory_present = 1;
-
-			status = parser_read_uint32(&p->memory, entry->value);
-			PARSE_ERROR((status == 0), section_name, entry->name);
-			continue;
-		}
-
-		/* ranks */
-		if (strcmp(entry->name, "r") == 0) {
-			int status;
-
-			PARSE_ERROR_DUPLICATE((p->ranks_present == 0),
-				section_name,
-				entry->name);
-			p->ranks_present = 1;
-
-			status = parser_read_uint32(&p->ranks, entry->value);
-			PARSE_ERROR((status == 0), section_name, entry->name);
-			continue;
-		}
-
-		/* pci_blacklist */
-		if ((strcmp(entry->name, "pci_blacklist") == 0) ||
-			(strcmp(entry->name, "b") == 0)) {
-			uint32_t i;
-
-			for (i = 0; i < APP_MAX_LINKS; i++) {
-				if (p->pci_blacklist[i])
-					continue;
-
-				p->pci_blacklist[i] =
-					strdup(entry->value);
-				PARSE_ERROR_MALLOC(p->pci_blacklist[i]);
-
-				break;
-			}
-
-			PARSE_ERROR_MESSAGE((i < APP_MAX_LINKS),
-				section_name, entry->name,
-				"too many elements");
-			continue;
-		}
-
-		/* pci_whitelist */
-		if ((strcmp(entry->name, "pci_whitelist") == 0) ||
-			(strcmp(entry->name, "w") == 0)) {
-			uint32_t i;
-
-			PARSE_ERROR_MESSAGE((app->port_mask != 0),
-				section_name, entry->name, "entry to be "
-				"generated by the application (port_mask "
-				"not provided)");
-
-			for (i = 0; i < APP_MAX_LINKS; i++) {
-				if (p->pci_whitelist[i])
-					continue;
-
-				p->pci_whitelist[i] = strdup(entry->value);
-				PARSE_ERROR_MALLOC(p->pci_whitelist[i]);
-
-				break;
-			}
-
-			PARSE_ERROR_MESSAGE((i < APP_MAX_LINKS),
-				section_name, entry->name,
-				"too many elements");
-			continue;
-		}
-
-		/* vdev */
-		if (strcmp(entry->name, "vdev") == 0) {
-			uint32_t i;
-
-			for (i = 0; i < APP_MAX_LINKS; i++) {
-				if (p->vdev[i])
-					continue;
-
-				p->vdev[i] = strdup(entry->value);
-				PARSE_ERROR_MALLOC(p->vdev[i]);
-
-				break;
-			}
-
-			PARSE_ERROR_MESSAGE((i < APP_MAX_LINKS),
-				section_name, entry->name,
-				"too many elements");
-			continue;
-		}
-
-		/* vmware_tsc_map */
-		if (strcmp(entry->name, "vmware_tsc_map") == 0) {
-			int val;
-
-			PARSE_ERROR_DUPLICATE((p->vmware_tsc_map_present == 0),
-				section_name,
-				entry->name);
-			p->vmware_tsc_map_present = 1;
-
-			val = parser_read_arg_bool(entry->value);
-			PARSE_ERROR((val >= 0), section_name, entry->name);
-			p->vmware_tsc_map = val;
-			continue;
-		}
-
-		/* proc_type */
-		if (strcmp(entry->name, "proc_type") == 0) {
-			PARSE_ERROR_DUPLICATE((p->proc_type == NULL),
-				section_name,
-				entry->name);
-			p->proc_type = strdup(entry->value);
-			continue;
-		}
-
-		/* syslog */
-		if (strcmp(entry->name, "syslog") == 0) {
-			PARSE_ERROR_DUPLICATE((p->syslog == NULL),
-				section_name,
-				entry->name);
-			p->syslog = strdup(entry->value);
-			continue;
-		}
-
-		/* log_level */
-		if (strcmp(entry->name, "log_level") == 0) {
-			int status;
-
-			PARSE_ERROR_DUPLICATE((p->log_level_present == 0),
-				section_name,
-				entry->name);
-			p->log_level_present = 1;
-
-			status = parser_read_uint32(&p->log_level,
-				entry->value);
-			PARSE_ERROR((status == 0), section_name, entry->name);
-			continue;
-		}
-
-		/* version */
-		if (strcmp(entry->name, "v") == 0) {
-			int val;
-
-			PARSE_ERROR_DUPLICATE((p->version_present == 0),
-				section_name,
-				entry->name);
-			p->version_present = 1;
-
-			val = parser_read_arg_bool(entry->value);
-			PARSE_ERROR((val >= 0), section_name, entry->name);
-			p->version = val;
-			continue;
-		}
-
-		/* help */
-		if ((strcmp(entry->name, "help") == 0) ||
-			(strcmp(entry->name, "h") == 0)) {
-			int val;
-
-			PARSE_ERROR_DUPLICATE((p->help_present == 0),
-				section_name,
-				entry->name);
-			p->help_present = 1;
-
-			val = parser_read_arg_bool(entry->value);
-			PARSE_ERROR((val >= 0), section_name, entry->name);
-			p->help = val;
-			continue;
-		}
-
-		/* no_huge */
-		if (strcmp(entry->name, "no_huge") == 0) {
-			int val;
-
-			PARSE_ERROR_DUPLICATE((p->no_huge_present == 0),
-				section_name,
-				entry->name);
-			p->no_huge_present = 1;
-
-			val = parser_read_arg_bool(entry->value);
-			PARSE_ERROR((val >= 0), section_name, entry->name);
-			p->no_huge = val;
-			continue;
-		}
-
-		/* no_pci */
-		if (strcmp(entry->name, "no_pci") == 0) {
-			int val;
-
-			PARSE_ERROR_DUPLICATE((p->no_pci_present == 0),
-				section_name,
-				entry->name);
-			p->no_pci_present = 1;
-
-			val = parser_read_arg_bool(entry->value);
-			PARSE_ERROR((val >= 0), section_name, entry->name);
-			p->no_pci = val;
-			continue;
-		}
-
-		/* no_hpet */
-		if (strcmp(entry->name, "no_hpet") == 0) {
-			int val;
-
-			PARSE_ERROR_DUPLICATE((p->no_hpet_present == 0),
-				section_name,
-				entry->name);
-			p->no_hpet_present = 1;
-
-			val = parser_read_arg_bool(entry->value);
-			PARSE_ERROR((val >= 0), section_name, entry->name);
-			p->no_hpet = val;
-			continue;
-		}
-
-		/* no_shconf */
-		if (strcmp(entry->name, "no_shconf") == 0) {
-			int val;
-
-			PARSE_ERROR_DUPLICATE((p->no_shconf_present == 0),
-				section_name,
-				entry->name);
-			p->no_shconf_present = 1;
-
-			val = parser_read_arg_bool(entry->value);
-			PARSE_ERROR((val >= 0), section_name, entry->name);
-			p->no_shconf = val;
-			continue;
-		}
-
-		/* add_driver */
-		if (strcmp(entry->name, "d") == 0) {
-			PARSE_ERROR_DUPLICATE((p->add_driver == NULL),
-				section_name,
-				entry->name);
-			p->add_driver = strdup(entry->value);
-			continue;
-		}
-
-		/* socket_mem */
-		if (strcmp(entry->name, "socket_mem") == 0) {
-			PARSE_ERROR_DUPLICATE((p->socket_mem == NULL),
-				section_name,
-				entry->name);
-			p->socket_mem = strdup(entry->value);
-			continue;
-		}
-
-		/* huge_dir */
-		if (strcmp(entry->name, "huge_dir") == 0) {
-			PARSE_ERROR_DUPLICATE((p->huge_dir == NULL),
-				section_name,
-				entry->name);
-			p->huge_dir = strdup(entry->value);
-			continue;
-		}
-
-		/* file_prefix */
-		if (strcmp(entry->name, "file_prefix") == 0) {
-			PARSE_ERROR_DUPLICATE((p->file_prefix == NULL),
-				section_name,
-				entry->name);
-			p->file_prefix = strdup(entry->value);
-			continue;
-		}
-
-		/* base_virtaddr */
-		if (strcmp(entry->name, "base_virtaddr") == 0) {
-			PARSE_ERROR_DUPLICATE((p->base_virtaddr == NULL),
-				section_name,
-				entry->name);
-			p->base_virtaddr = strdup(entry->value);
-			continue;
-		}
-
-		/* create_uio_dev */
-		if (strcmp(entry->name, "create_uio_dev") == 0) {
-			int val;
-
-			PARSE_ERROR_DUPLICATE((p->create_uio_dev_present == 0),
-				section_name,
-				entry->name);
-			p->create_uio_dev_present = 1;
-
-			val = parser_read_arg_bool(entry->value);
-			PARSE_ERROR((val >= 0), section_name, entry->name);
-			p->create_uio_dev = val;
-			continue;
-		}
-
-		/* vfio_intr */
-		if (strcmp(entry->name, "vfio_intr") == 0) {
-			PARSE_ERROR_DUPLICATE((p->vfio_intr == NULL),
-				section_name,
-				entry->name);
-			p->vfio_intr = strdup(entry->value);
-			continue;
-		}
-
-		/* unrecognized */
-		PARSE_ERROR_INVALID(0, section_name, entry->name);
-	}
-
-	free(entries);
-}
-
-static void
-parse_pipeline_pktq_in(struct app_params *app,
-	struct app_pipeline_params *p,
-	char *value)
-{
-	p->n_pktq_in = 0;
-
-	while (1) {
-		enum app_pktq_in_type type;
-		int id;
-		char *name = strtok_r(value, PARSE_DELIMITER, &value);
-
-		if (name == NULL)
-			break;
-
-		PARSE_ERROR_TOO_MANY_ELEMENTS(
-			(p->n_pktq_in < RTE_DIM(p->pktq_in)),
-			p->name, "pktq_in", (uint32_t)RTE_DIM(p->pktq_in));
-
-		if (validate_name(name, "RXQ", 2) == 0) {
-			type = APP_PKTQ_IN_HWQ;
-			id = APP_PARAM_ADD(app->hwq_in_params, name);
-			APP_PARAM_ADD_LINK_FOR_RXQ(app, name);
-		} else if (validate_name(name, "SWQ", 1) == 0) {
-			type = APP_PKTQ_IN_SWQ;
-			id = APP_PARAM_ADD(app->swq_params, name);
-		} else if (validate_name(name, "TM", 1) == 0) {
-			type = APP_PKTQ_IN_TM;
-			id = APP_PARAM_ADD(app->tm_params, name);
-			APP_PARAM_ADD_LINK_FOR_TM(app, name);
-		} else if (validate_name(name, "TAP", 1) == 0) {
-			type = APP_PKTQ_IN_TAP;
-			id = APP_PARAM_ADD(app->tap_params, name);
-		} else if (validate_name(name, "KNI", 1) == 0) {
-			type = APP_PKTQ_IN_KNI;
-			id = APP_PARAM_ADD(app->kni_params, name);
-			APP_PARAM_ADD_LINK_FOR_KNI(app, name);
-		} else if (validate_name(name, "SOURCE", 1) == 0) {
-			type = APP_PKTQ_IN_SOURCE;
-			id = APP_PARAM_ADD(app->source_params, name);
-		} else
-			PARSE_ERROR_INVALID_ELEMENT(0,
-				p->name, "pktq_in", name);
-
-		p->pktq_in[p->n_pktq_in].type = type;
-		p->pktq_in[p->n_pktq_in].id = (uint32_t) id;
-		p->n_pktq_in++;
-	}
-
-	PARSE_ERROR_NO_ELEMENTS((p->n_pktq_in > 0), p->name, "pktq_in");
-}
-
-static void
-parse_pipeline_pktq_out(struct app_params *app,
-	struct app_pipeline_params *p,
-	char *value)
-{
-	p->n_pktq_out = 0;
-
-	while (1) {
-		enum app_pktq_out_type type;
-		int id;
-		char *name = strtok_r(value, PARSE_DELIMITER, &value);
-
-		if (name == NULL)
-			break;
-
-		PARSE_ERROR_TOO_MANY_ELEMENTS(
-			(p->n_pktq_out < RTE_DIM(p->pktq_out)),
-			p->name, "pktq_out", (uint32_t)RTE_DIM(p->pktq_out));
-
-		if (validate_name(name, "TXQ", 2) == 0) {
-			type = APP_PKTQ_OUT_HWQ;
-			id = APP_PARAM_ADD(app->hwq_out_params, name);
-			APP_PARAM_ADD_LINK_FOR_TXQ(app, name);
-		} else if (validate_name(name, "SWQ", 1) == 0) {
-			type = APP_PKTQ_OUT_SWQ;
-			id = APP_PARAM_ADD(app->swq_params, name);
-		} else if (validate_name(name, "TM", 1) == 0) {
-			type = APP_PKTQ_OUT_TM;
-			id = APP_PARAM_ADD(app->tm_params, name);
-			APP_PARAM_ADD_LINK_FOR_TM(app, name);
-		} else if (validate_name(name, "TAP", 1) == 0) {
-			type = APP_PKTQ_OUT_TAP;
-			id = APP_PARAM_ADD(app->tap_params, name);
-		} else if (validate_name(name, "KNI", 1) == 0) {
-			type = APP_PKTQ_OUT_KNI;
-			id = APP_PARAM_ADD(app->kni_params, name);
-			APP_PARAM_ADD_LINK_FOR_KNI(app, name);
-		} else if (validate_name(name, "SINK", 1) == 0) {
-			type = APP_PKTQ_OUT_SINK;
-			id = APP_PARAM_ADD(app->sink_params, name);
-		} else
-			PARSE_ERROR_INVALID_ELEMENT(0,
-				p->name, "pktq_out", name);
-
-		p->pktq_out[p->n_pktq_out].type = type;
-		p->pktq_out[p->n_pktq_out].id = id;
-		p->n_pktq_out++;
-	}
-
-	PARSE_ERROR_NO_ELEMENTS((p->n_pktq_out > 0), p->name, "pktq_out");
-}
-
-static void
-parse_pipeline_msgq_in(struct app_params *app,
-	struct app_pipeline_params *p,
-	char *value)
-{
-	p->n_msgq_in = 0;
-
-	while (1) {
-		int idx;
-		char *name = strtok_r(value, PARSE_DELIMITER, &value);
-
-		if (name == NULL)
-			break;
-
-		PARSE_ERROR_TOO_MANY_ELEMENTS(
-			(p->n_msgq_in < RTE_DIM(p->msgq_in)),
-			p->name, "msgq_in", (uint32_t)(RTE_DIM(p->msgq_in)));
-
-		PARSE_ERROR_INVALID_ELEMENT(
-			(validate_name(name, "MSGQ", 1) == 0),
-			p->name, "msgq_in", name);
-
-		idx = APP_PARAM_ADD(app->msgq_params, name);
-		p->msgq_in[p->n_msgq_in] = idx;
-		p->n_msgq_in++;
-	}
-
-	PARSE_ERROR_NO_ELEMENTS((p->n_msgq_in > 0), p->name, "msgq_in");
-}
-
-static void
-parse_pipeline_msgq_out(struct app_params *app,
-	struct app_pipeline_params *p,
-	char *value)
-{
-	p->n_msgq_out = 0;
-
-	while (1) {
-		int idx;
-		char *name = strtok_r(value, PARSE_DELIMITER, &value);
-
-		if (name == NULL)
-			break;
-
-		PARSE_ERROR_TOO_MANY_ELEMENTS(
-			(p->n_msgq_out < RTE_DIM(p->msgq_out)),
-			p->name, "msgq_out", (uint32_t)RTE_DIM(p->msgq_out));
-
-		PARSE_ERROR_INVALID_ELEMENT(
-			(validate_name(name, "MSGQ", 1) == 0),
-			p->name, "msgq_out", name);
-
-		idx = APP_PARAM_ADD(app->msgq_params, name);
-		p->msgq_out[p->n_msgq_out] = idx;
-		p->n_msgq_out++;
-	}
-
-	PARSE_ERROR_NO_ELEMENTS((p->n_msgq_out > 0), p->name, "msgq_out");
-}
-
-static void
-parse_pipeline(struct app_params *app,
-	const char *section_name,
-	struct rte_cfgfile *cfg)
-{
-	char name[CFG_NAME_LEN];
-	struct app_pipeline_params *param;
-	struct rte_cfgfile_entry *entries;
-	ssize_t param_idx;
-	int n_entries, i;
-
-	n_entries = rte_cfgfile_section_num_entries(cfg, section_name);
-	PARSE_ERROR_SECTION_NO_ENTRIES((n_entries > 0), section_name);
-
-	entries = malloc(n_entries * sizeof(struct rte_cfgfile_entry));
-	PARSE_ERROR_MALLOC(entries != NULL);
-
-	rte_cfgfile_section_entries(cfg, section_name, entries, n_entries);
-
-	param_idx = APP_PARAM_ADD(app->pipeline_params, section_name);
-	param = &app->pipeline_params[param_idx];
-	PARSE_CHECK_DUPLICATE_SECTION(param);
-
-	for (i = 0; i < n_entries; i++) {
-		struct rte_cfgfile_entry *ent = &entries[i];
-
-		if (strcmp(ent->name, "type") == 0) {
-			int w_size = snprintf(param->type, RTE_DIM(param->type),
-					"%s", ent->value);
-
-			PARSE_ERROR(((w_size > 0) &&
-				(w_size < (int)RTE_DIM(param->type))),
-				section_name,
-				ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "core") == 0) {
-			int status = parse_pipeline_core(
-				&param->socket_id, &param->core_id,
-				&param->hyper_th_id, ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "pktq_in") == 0) {
-			parse_pipeline_pktq_in(app, param, ent->value);
-
-			continue;
-		}
-
-		if (strcmp(ent->name, "pktq_out") == 0) {
-			parse_pipeline_pktq_out(app, param, ent->value);
-
-			continue;
-		}
-
-		if (strcmp(ent->name, "msgq_in") == 0) {
-			parse_pipeline_msgq_in(app, param, ent->value);
-
-			continue;
-		}
-
-		if (strcmp(ent->name, "msgq_out") == 0) {
-			parse_pipeline_msgq_out(app, param, ent->value);
-
-			continue;
-		}
-
-		if (strcmp(ent->name, "timer_period") == 0) {
-			int status = parser_read_uint32(
-				&param->timer_period,
-				ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		/* pipeline type specific items */
-		APP_CHECK((param->n_args < APP_MAX_PIPELINE_ARGS),
-			"Parse error in section \"%s\": too many "
-			"pipeline specified parameters", section_name);
-
-		param->args_name[param->n_args] = strdup(ent->name);
-		param->args_value[param->n_args] = strdup(ent->value);
-
-		APP_CHECK((param->args_name[param->n_args] != NULL) &&
-			(param->args_value[param->n_args] != NULL),
-			"Parse error: no free memory");
-
-		param->n_args++;
-	}
-
-	snprintf(name, sizeof(name), "MSGQ-REQ-%s", section_name);
-	param_idx = APP_PARAM_ADD(app->msgq_params, name);
-	app->msgq_params[param_idx].cpu_socket_id = param->socket_id;
-	param->msgq_in[param->n_msgq_in++] = param_idx;
-
-	snprintf(name, sizeof(name), "MSGQ-RSP-%s", section_name);
-	param_idx = APP_PARAM_ADD(app->msgq_params, name);
-	app->msgq_params[param_idx].cpu_socket_id = param->socket_id;
-	param->msgq_out[param->n_msgq_out++] = param_idx;
-
-	snprintf(name, sizeof(name), "MSGQ-REQ-CORE-s%" PRIu32 "c%" PRIu32 "%s",
-		param->socket_id,
-		param->core_id,
-		(param->hyper_th_id) ? "h" : "");
-	param_idx = APP_PARAM_ADD(app->msgq_params, name);
-	app->msgq_params[param_idx].cpu_socket_id = param->socket_id;
-
-	snprintf(name, sizeof(name), "MSGQ-RSP-CORE-s%" PRIu32 "c%" PRIu32 "%s",
-		param->socket_id,
-		param->core_id,
-		(param->hyper_th_id) ? "h" : "");
-	param_idx = APP_PARAM_ADD(app->msgq_params, name);
-	app->msgq_params[param_idx].cpu_socket_id = param->socket_id;
-
-	free(entries);
-}
-
-static void
-parse_mempool(struct app_params *app,
-	const char *section_name,
-	struct rte_cfgfile *cfg)
-{
-	struct app_mempool_params *param;
-	struct rte_cfgfile_entry *entries;
-	ssize_t param_idx;
-	int n_entries, i;
-
-	n_entries = rte_cfgfile_section_num_entries(cfg, section_name);
-	PARSE_ERROR_SECTION_NO_ENTRIES((n_entries > 0), section_name);
-
-	entries = malloc(n_entries * sizeof(struct rte_cfgfile_entry));
-	PARSE_ERROR_MALLOC(entries != NULL);
-
-	rte_cfgfile_section_entries(cfg, section_name, entries, n_entries);
-
-	param_idx = APP_PARAM_ADD(app->mempool_params, section_name);
-	param = &app->mempool_params[param_idx];
-	PARSE_CHECK_DUPLICATE_SECTION(param);
-
-	for (i = 0; i < n_entries; i++) {
-		struct rte_cfgfile_entry *ent = &entries[i];
-
-		if (strcmp(ent->name, "buffer_size") == 0) {
-			int status = parser_read_uint32(
-				&param->buffer_size, ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "pool_size") == 0) {
-			int status = parser_read_uint32(
-				&param->pool_size, ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "cache_size") == 0) {
-			int status = parser_read_uint32(
-				&param->cache_size, ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "cpu") == 0) {
-			int status = parser_read_uint32(
-				&param->cpu_socket_id, ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		/* unrecognized */
-		PARSE_ERROR_INVALID(0, section_name, ent->name);
-	}
-
-	free(entries);
-}
-
-static int
-parse_link_rss_qs(struct app_link_params *p,
-	char *value)
-{
-	p->n_rss_qs = 0;
-
-	while (1) {
-		char *token = strtok_r(value, PARSE_DELIMITER, &value);
-
-		if (token == NULL)
-			break;
-
-		if (p->n_rss_qs == RTE_DIM(p->rss_qs))
-			return -ENOMEM;
-
-		if (parser_read_uint32(&p->rss_qs[p->n_rss_qs++], token))
-			return -EINVAL;
-	}
-
-	return 0;
-}
-
-static int
-parse_link_rss_proto_ipv4(struct app_link_params *p,
-	char *value)
-{
-	uint64_t mask = 0;
-
-	while (1) {
-		char *token = strtok_r(value, PARSE_DELIMITER, &value);
-
-		if (token == NULL)
-			break;
-
-		if (strcmp(token, "IP") == 0) {
-			mask |= ETH_RSS_IPV4;
-			continue;
-		}
-		if (strcmp(token, "FRAG") == 0) {
-			mask |= ETH_RSS_FRAG_IPV4;
-			continue;
-		}
-		if (strcmp(token, "TCP") == 0) {
-			mask |= ETH_RSS_NONFRAG_IPV4_TCP;
-			continue;
-		}
-		if (strcmp(token, "UDP") == 0) {
-			mask |= ETH_RSS_NONFRAG_IPV4_UDP;
-			continue;
-		}
-		if (strcmp(token, "SCTP") == 0) {
-			mask |= ETH_RSS_NONFRAG_IPV4_SCTP;
-			continue;
-		}
-		if (strcmp(token, "OTHER") == 0) {
-			mask |= ETH_RSS_NONFRAG_IPV4_OTHER;
-			continue;
-		}
-		return -EINVAL;
-	}
-
-	p->rss_proto_ipv4 = mask;
-	return 0;
-}
-
-static int
-parse_link_rss_proto_ipv6(struct app_link_params *p,
-	char *value)
-{
-	uint64_t mask = 0;
-
-	while (1) {
-		char *token = strtok_r(value, PARSE_DELIMITER, &value);
-
-		if (token == NULL)
-			break;
-
-		if (strcmp(token, "IP") == 0) {
-			mask |= ETH_RSS_IPV6;
-			continue;
-		}
-		if (strcmp(token, "FRAG") == 0) {
-			mask |= ETH_RSS_FRAG_IPV6;
-			continue;
-		}
-		if (strcmp(token, "TCP") == 0) {
-			mask |= ETH_RSS_NONFRAG_IPV6_TCP;
-			continue;
-		}
-		if (strcmp(token, "UDP") == 0) {
-			mask |= ETH_RSS_NONFRAG_IPV6_UDP;
-			continue;
-		}
-		if (strcmp(token, "SCTP") == 0) {
-			mask |= ETH_RSS_NONFRAG_IPV6_SCTP;
-			continue;
-		}
-		if (strcmp(token, "OTHER") == 0) {
-			mask |= ETH_RSS_NONFRAG_IPV6_OTHER;
-			continue;
-		}
-		if (strcmp(token, "IP_EX") == 0) {
-			mask |= ETH_RSS_IPV6_EX;
-			continue;
-		}
-		if (strcmp(token, "TCP_EX") == 0) {
-			mask |= ETH_RSS_IPV6_TCP_EX;
-			continue;
-		}
-		if (strcmp(token, "UDP_EX") == 0) {
-			mask |= ETH_RSS_IPV6_UDP_EX;
-			continue;
-		}
-		return -EINVAL;
-	}
-
-	p->rss_proto_ipv6 = mask;
-	return 0;
-}
-
-static int
-parse_link_rss_proto_l2(struct app_link_params *p,
-	char *value)
-{
-	uint64_t mask = 0;
-
-	while (1) {
-		char *token = strtok_r(value, PARSE_DELIMITER, &value);
-
-		if (token == NULL)
-			break;
-
-		if (strcmp(token, "L2") == 0) {
-			mask |= ETH_RSS_L2_PAYLOAD;
-			continue;
-		}
-		return -EINVAL;
-	}
-
-	p->rss_proto_l2 = mask;
-	return 0;
-}
-
-static void
-parse_link(struct app_params *app,
-	const char *section_name,
-	struct rte_cfgfile *cfg)
-{
-	struct app_link_params *param;
-	struct rte_cfgfile_entry *entries;
-	int n_entries, i;
-	int rss_qs_present = 0;
-	int rss_proto_ipv4_present = 0;
-	int rss_proto_ipv6_present = 0;
-	int rss_proto_l2_present = 0;
-	int pci_bdf_present = 0;
-	ssize_t param_idx;
-
-	n_entries = rte_cfgfile_section_num_entries(cfg, section_name);
-	PARSE_ERROR_SECTION_NO_ENTRIES((n_entries > 0), section_name);
-
-	entries = malloc(n_entries * sizeof(struct rte_cfgfile_entry));
-	PARSE_ERROR_MALLOC(entries != NULL);
-
-	rte_cfgfile_section_entries(cfg, section_name, entries, n_entries);
-
-	param_idx = APP_PARAM_ADD(app->link_params, section_name);
-	param = &app->link_params[param_idx];
-	PARSE_CHECK_DUPLICATE_SECTION(param);
-
-	for (i = 0; i < n_entries; i++) {
-		struct rte_cfgfile_entry *ent = &entries[i];
-
-		if (strcmp(ent->name, "promisc") == 0) {
-			int status = parser_read_arg_bool(ent->value);
-
-			PARSE_ERROR((status != -EINVAL), section_name,
-				ent->name);
-			param->promisc = status;
-			continue;
-		}
-
-		if (strcmp(ent->name, "arp_q") == 0) {
-			int status = parser_read_uint32(&param->arp_q,
-				ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "tcp_syn_q") == 0) {
-			int status = parser_read_uint32(
-				&param->tcp_syn_q, ent->value);
-
-			PARSE_ERROR((status == 0), section_name, ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "ip_local_q") == 0) {
-			int status = parser_read_uint32(
-				&param->ip_local_q, ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "tcp_local_q") == 0) {
-			int status = parser_read_uint32(
-				&param->tcp_local_q, ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "udp_local_q") == 0) {
-			int status = parser_read_uint32(
-				&param->udp_local_q, ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "sctp_local_q") == 0) {
-			int status = parser_read_uint32(
-				&param->sctp_local_q, ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "rss_qs") == 0) {
-			int status = parse_link_rss_qs(param, ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			rss_qs_present = 1;
-			continue;
-		}
-
-		if (strcmp(ent->name, "rss_proto_ipv4") == 0) {
-			int status =
-				parse_link_rss_proto_ipv4(param, ent->value);
-
-			PARSE_ERROR((status != -EINVAL), section_name,
-				ent->name);
-			rss_proto_ipv4_present = 1;
-			continue;
-		}
-
-		if (strcmp(ent->name, "rss_proto_ipv6") == 0) {
-			int status =
-				parse_link_rss_proto_ipv6(param, ent->value);
-
-			PARSE_ERROR((status != -EINVAL), section_name,
-				ent->name);
-			rss_proto_ipv6_present = 1;
-			continue;
-		}
-
-		if (strcmp(ent->name, "rss_proto_l2") == 0) {
-			int status = parse_link_rss_proto_l2(param, ent->value);
-
-			PARSE_ERROR((status != -EINVAL), section_name,
-				ent->name);
-			rss_proto_l2_present = 1;
-			continue;
-		}
-
-		if (strcmp(ent->name, "pci_bdf") == 0) {
-			PARSE_ERROR_DUPLICATE((pci_bdf_present == 0),
-				section_name, ent->name);
-
-			snprintf(param->pci_bdf, APP_LINK_PCI_BDF_SIZE,
-				"%s", ent->value);
-			pci_bdf_present = 1;
-			continue;
-		}
-
-		/* unrecognized */
-		PARSE_ERROR_INVALID(0, section_name, ent->name);
-	}
-
-	/* Check for mandatory fields */
-	if (app->port_mask)
-		PARSE_ERROR_MESSAGE((pci_bdf_present == 0),
-			section_name, "pci_bdf",
-			"entry not allowed (port_mask is provided)");
-	else
-		PARSE_ERROR_MESSAGE((pci_bdf_present),
-			section_name, "pci_bdf",
-			"this entry is mandatory (port_mask is not "
-			"provided)");
-
-	if (rss_proto_ipv4_present)
-		PARSE_ERROR_MESSAGE((rss_qs_present),
-			section_name, "rss_proto_ipv4",
-			"entry not allowed (rss_qs entry is not provided)");
-	if (rss_proto_ipv6_present)
-		PARSE_ERROR_MESSAGE((rss_qs_present),
-			section_name, "rss_proto_ipv6",
-			"entry not allowed (rss_qs entry is not provided)");
-	if (rss_proto_l2_present)
-		PARSE_ERROR_MESSAGE((rss_qs_present),
-			section_name, "rss_proto_l2",
-			"entry not allowed (rss_qs entry is not provided)");
-	if (rss_proto_ipv4_present |
-		rss_proto_ipv6_present |
-		rss_proto_l2_present){
-		if (rss_proto_ipv4_present == 0)
-			param->rss_proto_ipv4 = 0;
-		if (rss_proto_ipv6_present == 0)
-			param->rss_proto_ipv6 = 0;
-		if (rss_proto_l2_present == 0)
-			param->rss_proto_l2 = 0;
-	}
-
-	free(entries);
-}
-
-static void
-parse_rxq(struct app_params *app,
-	const char *section_name,
-	struct rte_cfgfile *cfg)
-{
-	struct app_pktq_hwq_in_params *param;
-	struct rte_cfgfile_entry *entries;
-	int n_entries, i;
-	ssize_t param_idx;
-
-	n_entries = rte_cfgfile_section_num_entries(cfg, section_name);
-	PARSE_ERROR_SECTION_NO_ENTRIES((n_entries > 0), section_name);
-
-	entries = malloc(n_entries * sizeof(struct rte_cfgfile_entry));
-	PARSE_ERROR_MALLOC(entries != NULL);
-
-	rte_cfgfile_section_entries(cfg, section_name, entries, n_entries);
-
-	param_idx = APP_PARAM_ADD(app->hwq_in_params, section_name);
-	param = &app->hwq_in_params[param_idx];
-	PARSE_CHECK_DUPLICATE_SECTION(param);
-
-	APP_PARAM_ADD_LINK_FOR_RXQ(app, section_name);
-
-	for (i = 0; i < n_entries; i++) {
-		struct rte_cfgfile_entry *ent = &entries[i];
-
-		if (strcmp(ent->name, "mempool") == 0) {
-			int status = validate_name(ent->value,
-				"MEMPOOL", 1);
-			ssize_t idx;
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-
-			idx = APP_PARAM_ADD(app->mempool_params, ent->value);
-			param->mempool_id = idx;
-			continue;
-		}
-
-		if (strcmp(ent->name, "size") == 0) {
-			int status = parser_read_uint32(&param->size,
-				ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "burst") == 0) {
-			int status = parser_read_uint32(&param->burst,
-				ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		/* unrecognized */
-		PARSE_ERROR_INVALID(0, section_name, ent->name);
-	}
-
-	free(entries);
-}
-
-static void
-parse_txq(struct app_params *app,
-	const char *section_name,
-	struct rte_cfgfile *cfg)
-{
-	struct app_pktq_hwq_out_params *param;
-	struct rte_cfgfile_entry *entries;
-	int n_entries, i;
-	ssize_t param_idx;
-
-	n_entries = rte_cfgfile_section_num_entries(cfg, section_name);
-	PARSE_ERROR_SECTION_NO_ENTRIES((n_entries > 0), section_name);
-
-	entries = malloc(n_entries * sizeof(struct rte_cfgfile_entry));
-	PARSE_ERROR_MALLOC(entries != NULL);
-
-	rte_cfgfile_section_entries(cfg, section_name, entries, n_entries);
-
-	param_idx = APP_PARAM_ADD(app->hwq_out_params, section_name);
-	param = &app->hwq_out_params[param_idx];
-	PARSE_CHECK_DUPLICATE_SECTION(param);
-
-	APP_PARAM_ADD_LINK_FOR_TXQ(app, section_name);
-
-	for (i = 0; i < n_entries; i++) {
-		struct rte_cfgfile_entry *ent = &entries[i];
-
-		if (strcmp(ent->name, "size") == 0) {
-			int status = parser_read_uint32(&param->size,
-				ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "burst") == 0) {
-			int status = parser_read_uint32(&param->burst,
-				ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "dropless") == 0) {
-			int status = parser_read_arg_bool(ent->value);
-
-
-			PARSE_ERROR((status != -EINVAL), section_name,
-				ent->name);
-			param->dropless = status;
-			continue;
-		}
-
-		if (strcmp(ent->name, "n_retries") == 0) {
-			int status = parser_read_uint64(&param->n_retries,
-				ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		/* unrecognized */
-		PARSE_ERROR_INVALID(0, section_name, ent->name);
-	}
-
-	free(entries);
-}
-
-static void
-parse_swq(struct app_params *app,
-	const char *section_name,
-	struct rte_cfgfile *cfg)
-{
-	struct app_pktq_swq_params *param;
-	struct rte_cfgfile_entry *entries;
-	int n_entries, i;
-	uint32_t mtu_present = 0;
-	uint32_t metadata_size_present = 0;
-	uint32_t mempool_direct_present = 0;
-	uint32_t mempool_indirect_present = 0;
-
-	ssize_t param_idx;
-
-	n_entries = rte_cfgfile_section_num_entries(cfg, section_name);
-	PARSE_ERROR_SECTION_NO_ENTRIES((n_entries > 0), section_name);
-
-	entries = malloc(n_entries * sizeof(struct rte_cfgfile_entry));
-	PARSE_ERROR_MALLOC(entries != NULL);
-
-	rte_cfgfile_section_entries(cfg, section_name, entries, n_entries);
-
-	param_idx = APP_PARAM_ADD(app->swq_params, section_name);
-	param = &app->swq_params[param_idx];
-	PARSE_CHECK_DUPLICATE_SECTION(param);
-
-	for (i = 0; i < n_entries; i++) {
-		struct rte_cfgfile_entry *ent = &entries[i];
-
-		if (strcmp(ent->name, "size") == 0) {
-			int status = parser_read_uint32(&param->size,
-				ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "burst_read") == 0) {
-			int status = parser_read_uint32(&
-				param->burst_read, ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "burst_write") == 0) {
-			int status = parser_read_uint32(
-				&param->burst_write, ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "dropless") == 0) {
-			int status = parser_read_arg_bool(ent->value);
-
-			PARSE_ERROR((status != -EINVAL), section_name,
-				ent->name);
-			param->dropless = status;
-			continue;
-		}
-
-		if (strcmp(ent->name, "n_retries") == 0) {
-			int status = parser_read_uint64(&param->n_retries,
-				ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "cpu") == 0) {
-			int status = parser_read_uint32(
-				&param->cpu_socket_id, ent->value);
-
-			PARSE_ERROR((status == 0), section_name, ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "ipv4_frag") == 0) {
-			int status = parser_read_arg_bool(ent->value);
-
-			PARSE_ERROR((status != -EINVAL), section_name,
-				ent->name);
-
-			param->ipv4_frag = status;
-			if (param->mtu == 0)
-				param->mtu = 1500;
-
-			continue;
-		}
-
-		if (strcmp(ent->name, "ipv6_frag") == 0) {
-			int status = parser_read_arg_bool(ent->value);
-
-			PARSE_ERROR((status != -EINVAL), section_name,
-				ent->name);
-			param->ipv6_frag = status;
-			if (param->mtu == 0)
-				param->mtu = 1320;
-			continue;
-		}
-
-		if (strcmp(ent->name, "ipv4_ras") == 0) {
-			int status = parser_read_arg_bool(ent->value);
-
-			PARSE_ERROR((status != -EINVAL), section_name,
-				ent->name);
-			param->ipv4_ras = status;
-			continue;
-		}
-
-		if (strcmp(ent->name, "ipv6_ras") == 0) {
-			int status = parser_read_arg_bool(ent->value);
-
-			PARSE_ERROR((status != -EINVAL), section_name,
-				ent->name);
-			param->ipv6_ras = status;
-			continue;
-		}
-
-		if (strcmp(ent->name, "mtu") == 0) {
-			int status = parser_read_uint32(&param->mtu,
-					ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			mtu_present = 1;
-			continue;
-		}
-
-		if (strcmp(ent->name, "metadata_size") == 0) {
-			int status = parser_read_uint32(
-				&param->metadata_size, ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			metadata_size_present = 1;
-			continue;
-		}
-
-		if (strcmp(ent->name, "mempool_direct") == 0) {
-			int status = validate_name(ent->value,
-				"MEMPOOL", 1);
-			ssize_t idx;
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-
-			idx = APP_PARAM_ADD(app->mempool_params, ent->value);
-			param->mempool_direct_id = idx;
-
-			mempool_direct_present = 1;
-			continue;
-		}
-
-		if (strcmp(ent->name, "mempool_indirect") == 0) {
-			int status = validate_name(ent->value,
-				"MEMPOOL", 1);
-			ssize_t idx;
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-
-			idx = APP_PARAM_ADD(app->mempool_params, ent->value);
-			param->mempool_indirect_id = idx;
-
-			mempool_indirect_present = 1;
-			continue;
-		}
-
-		/* unrecognized */
-		PARSE_ERROR_INVALID(0, section_name, ent->name);
-	}
-
-	APP_CHECK(((mtu_present == 0) ||
-		((param->ipv4_frag == 1) || (param->ipv6_frag == 1))),
-		"Parse error in section \"%s\": IPv4/IPv6 fragmentation "
-		"is off, therefore entry \"mtu\" is not allowed",
-		section_name);
-
-	APP_CHECK(((metadata_size_present == 0) ||
-		((param->ipv4_frag == 1) || (param->ipv6_frag == 1))),
-		"Parse error in section \"%s\": IPv4/IPv6 fragmentation "
-		"is off, therefore entry \"metadata_size\" is "
-		"not allowed", section_name);
-
-	APP_CHECK(((mempool_direct_present == 0) ||
-		((param->ipv4_frag == 1) || (param->ipv6_frag == 1))),
-		"Parse error in section \"%s\": IPv4/IPv6 fragmentation "
-		"is off, therefore entry \"mempool_direct\" is "
-		"not allowed", section_name);
-
-	APP_CHECK(((mempool_indirect_present == 0) ||
-		((param->ipv4_frag == 1) || (param->ipv6_frag == 1))),
-		"Parse error in section \"%s\": IPv4/IPv6 fragmentation "
-		"is off, therefore entry \"mempool_indirect\" is "
-		"not allowed", section_name);
-
-	free(entries);
-}
-
-static void
-parse_tm(struct app_params *app,
-	const char *section_name,
-	struct rte_cfgfile *cfg)
-{
-	struct app_pktq_tm_params *param;
-	struct rte_cfgfile_entry *entries;
-	int n_entries, i;
-	ssize_t param_idx;
-
-	n_entries = rte_cfgfile_section_num_entries(cfg, section_name);
-	PARSE_ERROR_SECTION_NO_ENTRIES((n_entries > 0), section_name);
-
-	entries = malloc(n_entries * sizeof(struct rte_cfgfile_entry));
-	PARSE_ERROR_MALLOC(entries != NULL);
-
-	rte_cfgfile_section_entries(cfg, section_name, entries, n_entries);
-
-	param_idx = APP_PARAM_ADD(app->tm_params, section_name);
-	param = &app->tm_params[param_idx];
-	PARSE_CHECK_DUPLICATE_SECTION(param);
-
-	APP_PARAM_ADD_LINK_FOR_TM(app, section_name);
-
-	for (i = 0; i < n_entries; i++) {
-		struct rte_cfgfile_entry *ent = &entries[i];
-
-		if (strcmp(ent->name, "cfg") == 0) {
-			param->file_name = strdup(ent->value);
-			PARSE_ERROR_MALLOC(param->file_name != NULL);
-			continue;
-		}
-
-		if (strcmp(ent->name, "burst_read") == 0) {
-			int status = parser_read_uint32(
-				&param->burst_read, ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "burst_write") == 0) {
-			int status = parser_read_uint32(
-				&param->burst_write, ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		/* unrecognized */
-		PARSE_ERROR_INVALID(0, section_name, ent->name);
-	}
-
-	free(entries);
-}
-
-static void
-parse_tap(struct app_params *app,
-	const char *section_name,
-	struct rte_cfgfile *cfg)
-{
-	struct app_pktq_tap_params *param;
-	struct rte_cfgfile_entry *entries;
-	int n_entries, i;
-	ssize_t param_idx;
-
-	n_entries = rte_cfgfile_section_num_entries(cfg, section_name);
-	PARSE_ERROR_SECTION_NO_ENTRIES((n_entries > 0), section_name);
-
-	entries = malloc(n_entries * sizeof(struct rte_cfgfile_entry));
-	PARSE_ERROR_MALLOC(entries != NULL);
-
-	rte_cfgfile_section_entries(cfg, section_name, entries, n_entries);
-
-	param_idx = APP_PARAM_ADD(app->tap_params, section_name);
-	param = &app->tap_params[param_idx];
-	PARSE_CHECK_DUPLICATE_SECTION(param);
-
-	for (i = 0; i < n_entries; i++) {
-		struct rte_cfgfile_entry *ent = &entries[i];
-
-		if (strcmp(ent->name, "burst_read") == 0) {
-			int status = parser_read_uint32(
-				&param->burst_read, ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "burst_write") == 0) {
-			int status = parser_read_uint32(
-				&param->burst_write, ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "dropless") == 0) {
-			int status = parser_read_arg_bool(ent->value);
-
-			PARSE_ERROR((status != -EINVAL), section_name,
-				ent->name);
-			param->dropless = status;
-			continue;
-		}
-
-		if (strcmp(ent->name, "n_retries") == 0) {
-			int status = parser_read_uint64(&param->n_retries,
-				ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "mempool") == 0) {
-			int status = validate_name(ent->value,
-				"MEMPOOL", 1);
-			ssize_t idx;
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-
-			idx = APP_PARAM_ADD(app->mempool_params, ent->value);
-			param->mempool_id = idx;
-
-			continue;
-		}
-
-		/* unrecognized */
-		PARSE_ERROR_INVALID(0, section_name, ent->name);
-	}
-
-	free(entries);
-}
-
-static void
-parse_kni(struct app_params *app,
-		  const char *section_name,
-		  struct rte_cfgfile *cfg)
-{
-	struct app_pktq_kni_params *param;
-	struct rte_cfgfile_entry *entries;
-	int n_entries, i;
-	ssize_t param_idx;
-
-	n_entries = rte_cfgfile_section_num_entries(cfg, section_name);
-	PARSE_ERROR_SECTION_NO_ENTRIES((n_entries > 0), section_name);
-
-	entries = malloc(n_entries * sizeof(struct rte_cfgfile_entry));
-	PARSE_ERROR_MALLOC(entries != NULL);
-
-	rte_cfgfile_section_entries(cfg, section_name, entries, n_entries);
-
-	param_idx = APP_PARAM_ADD(app->kni_params, section_name);
-	param = &app->kni_params[param_idx];
-	PARSE_CHECK_DUPLICATE_SECTION(param);
-
-	APP_PARAM_ADD_LINK_FOR_KNI(app, section_name);
-
-	for (i = 0; i < n_entries; i++) {
-		struct rte_cfgfile_entry *ent = &entries[i];
-
-		if (strcmp(ent->name, "core") == 0) {
-			int status = parse_pipeline_core(
-					&param->socket_id,
-					&param->core_id,
-					&param->hyper_th_id,
-					ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-						ent->name);
-			param->force_bind = 1;
-			continue;
-		}
-
-		if (strcmp(ent->name, "mempool") == 0) {
-			int status = validate_name(ent->value,
-				"MEMPOOL", 1);
-			ssize_t idx;
-
-			PARSE_ERROR((status == 0), section_name,
-						ent->name);
-
-			idx = APP_PARAM_ADD(app->mempool_params, ent->value);
-			param->mempool_id = idx;
-			continue;
-		}
-
-		if (strcmp(ent->name, "burst_read") == 0) {
-			int status = parser_read_uint32(&param->burst_read,
-						ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-						ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "burst_write") == 0) {
-			int status = parser_read_uint32(&param->burst_write,
-						ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-						ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "dropless") == 0) {
-			int status = parser_read_arg_bool(ent->value);
-
-			PARSE_ERROR((status != -EINVAL), section_name,
-						ent->name);
-			param->dropless = status;
-			continue;
-		}
-
-		if (strcmp(ent->name, "n_retries") == 0) {
-			int status = parser_read_uint64(&param->n_retries,
-						ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-						ent->name);
-			continue;
-		}
-
-		/* unrecognized */
-		PARSE_ERROR_INVALID(0, section_name, ent->name);
-	}
-
-	free(entries);
-}
-
-static void
-parse_source(struct app_params *app,
-	const char *section_name,
-	struct rte_cfgfile *cfg)
-{
-	struct app_pktq_source_params *param;
-	struct rte_cfgfile_entry *entries;
-	int n_entries, i;
-	ssize_t param_idx;
-	uint32_t pcap_file_present = 0;
-	uint32_t pcap_size_present = 0;
-
-	n_entries = rte_cfgfile_section_num_entries(cfg, section_name);
-	PARSE_ERROR_SECTION_NO_ENTRIES((n_entries > 0), section_name);
-
-	entries = malloc(n_entries * sizeof(struct rte_cfgfile_entry));
-	PARSE_ERROR_MALLOC(entries != NULL);
-
-	rte_cfgfile_section_entries(cfg, section_name, entries, n_entries);
-
-	param_idx = APP_PARAM_ADD(app->source_params, section_name);
-	param = &app->source_params[param_idx];
-	PARSE_CHECK_DUPLICATE_SECTION(param);
-
-	for (i = 0; i < n_entries; i++) {
-		struct rte_cfgfile_entry *ent = &entries[i];
-
-		if (strcmp(ent->name, "mempool") == 0) {
-			int status = validate_name(ent->value,
-				"MEMPOOL", 1);
-			ssize_t idx;
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-
-			idx = APP_PARAM_ADD(app->mempool_params, ent->value);
-			param->mempool_id = idx;
-			continue;
-		}
-
-		if (strcmp(ent->name, "burst") == 0) {
-			int status = parser_read_uint32(&param->burst,
-				ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "pcap_file_rd") == 0) {
-			PARSE_ERROR_DUPLICATE((pcap_file_present == 0),
-				section_name, ent->name);
-
-			param->file_name = strdup(ent->value);
-
-			PARSE_ERROR_MALLOC(param->file_name != NULL);
-			pcap_file_present = 1;
-
-			continue;
-		}
-
-		if (strcmp(ent->name, "pcap_bytes_rd_per_pkt") == 0) {
-			int status;
-
-			PARSE_ERROR_DUPLICATE((pcap_size_present == 0),
-				section_name, ent->name);
-
-			status = parser_read_uint32(
-				&param->n_bytes_per_pkt, ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			pcap_size_present = 1;
-
-			continue;
-		}
-
-		/* unrecognized */
-		PARSE_ERROR_INVALID(0, section_name, ent->name);
-	}
-
-	free(entries);
-}
-
-static void
-parse_sink(struct app_params *app,
-	const char *section_name,
-	struct rte_cfgfile *cfg)
-{
-	struct app_pktq_sink_params *param;
-	struct rte_cfgfile_entry *entries;
-	int n_entries, i;
-	ssize_t param_idx;
-	uint32_t pcap_file_present = 0;
-	uint32_t pcap_n_pkt_present = 0;
-
-	n_entries = rte_cfgfile_section_num_entries(cfg, section_name);
-	PARSE_ERROR_SECTION_NO_ENTRIES((n_entries > 0), section_name);
-
-	entries = malloc(n_entries * sizeof(struct rte_cfgfile_entry));
-	PARSE_ERROR_MALLOC(entries != NULL);
-
-	rte_cfgfile_section_entries(cfg, section_name, entries, n_entries);
-
-	param_idx = APP_PARAM_ADD(app->sink_params, section_name);
-	param = &app->sink_params[param_idx];
-	PARSE_CHECK_DUPLICATE_SECTION(param);
-
-	for (i = 0; i < n_entries; i++) {
-		struct rte_cfgfile_entry *ent = &entries[i];
-
-		if (strcmp(ent->name, "pcap_file_wr") == 0) {
-			PARSE_ERROR_DUPLICATE((pcap_file_present == 0),
-				section_name, ent->name);
-
-			param->file_name = strdup(ent->value);
-
-			PARSE_ERROR_MALLOC((param->file_name != NULL));
-
-			continue;
-		}
-
-		if (strcmp(ent->name, "pcap_n_pkt_wr") == 0) {
-			int status;
-
-			PARSE_ERROR_DUPLICATE((pcap_n_pkt_present == 0),
-				section_name, ent->name);
-
-			status = parser_read_uint32(
-				&param->n_pkts_to_dump, ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-
-			continue;
-		}
-
-		/* unrecognized */
-		PARSE_ERROR_INVALID(0, section_name, ent->name);
-	}
-
-	free(entries);
-}
-
-static void
-parse_msgq_req_pipeline(struct app_params *app,
-	const char *section_name,
-	struct rte_cfgfile *cfg)
-{
-	struct app_msgq_params *param;
-	struct rte_cfgfile_entry *entries;
-	int n_entries, i;
-	ssize_t param_idx;
-
-	n_entries = rte_cfgfile_section_num_entries(cfg, section_name);
-	PARSE_ERROR_SECTION_NO_ENTRIES((n_entries > 0), section_name);
-
-	entries = malloc(n_entries * sizeof(struct rte_cfgfile_entry));
-	PARSE_ERROR_MALLOC(entries != NULL);
-
-	rte_cfgfile_section_entries(cfg, section_name, entries, n_entries);
-
-	param_idx = APP_PARAM_ADD(app->msgq_params, section_name);
-	param = &app->msgq_params[param_idx];
-	PARSE_CHECK_DUPLICATE_SECTION(param);
-
-	for (i = 0; i < n_entries; i++) {
-		struct rte_cfgfile_entry *ent = &entries[i];
-
-		if (strcmp(ent->name, "size") == 0) {
-			int status = parser_read_uint32(&param->size,
-				ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		/* unrecognized */
-		PARSE_ERROR_INVALID(0, section_name, ent->name);
-	}
-
-	free(entries);
-}
-
-static void
-parse_msgq_rsp_pipeline(struct app_params *app,
-	const char *section_name,
-	struct rte_cfgfile *cfg)
-{
-	struct app_msgq_params *param;
-	struct rte_cfgfile_entry *entries;
-	int n_entries, i;
-	ssize_t param_idx;
-
-	n_entries = rte_cfgfile_section_num_entries(cfg, section_name);
-	PARSE_ERROR_SECTION_NO_ENTRIES((n_entries > 0), section_name);
-
-	entries = malloc(n_entries * sizeof(struct rte_cfgfile_entry));
-	PARSE_ERROR_MALLOC(entries != NULL);
-
-	rte_cfgfile_section_entries(cfg, section_name, entries, n_entries);
-
-	param_idx = APP_PARAM_ADD(app->msgq_params, section_name);
-	param = &app->msgq_params[param_idx];
-	PARSE_CHECK_DUPLICATE_SECTION(param);
-
-	for (i = 0; i < n_entries; i++) {
-		struct rte_cfgfile_entry *ent = &entries[i];
-
-		if (strcmp(ent->name, "size") == 0) {
-			int status = parser_read_uint32(&param->size,
-				ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		/* unrecognized */
-		PARSE_ERROR_INVALID(0, section_name, ent->name);
-	}
-
-	free(entries);
-}
-
-static void
-parse_msgq(struct app_params *app,
-	const char *section_name,
-	struct rte_cfgfile *cfg)
-{
-	struct app_msgq_params *param;
-	struct rte_cfgfile_entry *entries;
-	int n_entries, i;
-	ssize_t param_idx;
-
-	n_entries = rte_cfgfile_section_num_entries(cfg, section_name);
-	PARSE_ERROR_SECTION_NO_ENTRIES((n_entries > 0), section_name);
-
-	entries = malloc(n_entries * sizeof(struct rte_cfgfile_entry));
-	PARSE_ERROR_MALLOC(entries != NULL);
-
-	rte_cfgfile_section_entries(cfg, section_name, entries, n_entries);
-
-	param_idx = APP_PARAM_ADD(app->msgq_params, section_name);
-	param = &app->msgq_params[param_idx];
-	PARSE_CHECK_DUPLICATE_SECTION(param);
-
-	for (i = 0; i < n_entries; i++) {
-		struct rte_cfgfile_entry *ent = &entries[i];
-
-		if (strcmp(ent->name, "size") == 0) {
-			int status = parser_read_uint32(&param->size,
-				ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		if (strcmp(ent->name, "cpu") == 0) {
-			int status = parser_read_uint32(
-				&param->cpu_socket_id, ent->value);
-
-			PARSE_ERROR((status == 0), section_name,
-				ent->name);
-			continue;
-		}
-
-		/* unrecognized */
-		PARSE_ERROR_INVALID(0, section_name, ent->name);
-	}
-
-	free(entries);
-}
-
-typedef void (*config_section_load)(struct app_params *p,
-	const char *section_name,
-	struct rte_cfgfile *cfg);
-
-struct config_section {
-	const char prefix[CFG_NAME_LEN];
-	int numbers;
-	config_section_load load;
-};
-
-static const struct config_section cfg_file_scheme[] = {
-	{"EAL", 0, parse_eal},
-	{"PIPELINE", 1, parse_pipeline},
-	{"MEMPOOL", 1, parse_mempool},
-	{"LINK", 1, parse_link},
-	{"RXQ", 2, parse_rxq},
-	{"TXQ", 2, parse_txq},
-	{"SWQ", 1, parse_swq},
-	{"TM", 1, parse_tm},
-	{"TAP", 1, parse_tap},
-	{"KNI", 1, parse_kni},
-	{"SOURCE", 1, parse_source},
-	{"SINK", 1, parse_sink},
-	{"MSGQ-REQ-PIPELINE", 1, parse_msgq_req_pipeline},
-	{"MSGQ-RSP-PIPELINE", 1, parse_msgq_rsp_pipeline},
-	{"MSGQ", 1, parse_msgq},
-};
-
-static void
-create_implicit_mempools(struct app_params *app)
-{
-	APP_PARAM_ADD(app->mempool_params, "MEMPOOL0");
-}
-
-static void
-create_implicit_links_from_port_mask(struct app_params *app,
-	uint64_t port_mask)
-{
-	uint32_t pmd_id, link_id;
-
-	link_id = 0;
-	for (pmd_id = 0; pmd_id < RTE_MAX_ETHPORTS; pmd_id++) {
-		char name[APP_PARAM_NAME_SIZE];
-		ssize_t idx;
-
-		if ((port_mask & (1LLU << pmd_id)) == 0)
-			continue;
-
-		snprintf(name, sizeof(name), "LINK%" PRIu32, link_id);
-		idx = APP_PARAM_ADD(app->link_params, name);
-
-		app->link_params[idx].pmd_id = pmd_id;
-		link_id++;
-	}
-}
-
-static void
-assign_link_pmd_id_from_pci_bdf(struct app_params *app)
-{
-	uint32_t i;
-
-	for (i = 0; i < app->n_links; i++) {
-		struct app_link_params *link = &app->link_params[i];
-
-		APP_CHECK((strlen(link->pci_bdf)),
-			"Parse error: %s pci_bdf is not configured "
-			"(port_mask is not provided)",
-			link->name);
-
-		link->pmd_id = i;
-	}
-}
-
-int
-app_config_parse(struct app_params *app, const char *file_name)
-{
-	struct rte_cfgfile *cfg;
-	char **section_names;
-	int i, j, sect_count;
-
-	/* Implicit mempools */
-	create_implicit_mempools(app);
-
-	/* Port mask */
-	if (app->port_mask)
-		create_implicit_links_from_port_mask(app, app->port_mask);
-
-	/* Load application configuration file */
-	cfg = rte_cfgfile_load(file_name, 0);
-	APP_CHECK((cfg != NULL), "Parse error: Unable to load config "
-		"file %s", file_name);
-
-	sect_count = rte_cfgfile_num_sections(cfg, NULL, 0);
-	APP_CHECK((sect_count > 0), "Parse error: number of sections "
-		"in file \"%s\" return %d", file_name,
-		sect_count);
-
-	section_names = malloc(sect_count * sizeof(char *));
-	PARSE_ERROR_MALLOC(section_names != NULL);
-
-	for (i = 0; i < sect_count; i++)
-		section_names[i] = malloc(CFG_NAME_LEN);
-
-	rte_cfgfile_sections(cfg, section_names, sect_count);
-
-	for (i = 0; i < sect_count; i++) {
-		const struct config_section *sch_s;
-		int len, cfg_name_len;
-
-		cfg_name_len = strlen(section_names[i]);
-
-		/* Find section type */
-		for (j = 0; j < (int)RTE_DIM(cfg_file_scheme); j++) {
-			sch_s = &cfg_file_scheme[j];
-			len = strlen(sch_s->prefix);
-
-			if (cfg_name_len < len)
-				continue;
-
-			/* After section name we expect only '\0' or digit or
-			 * digit dot digit, so protect against false matching,
-			 * for example: "ABC" should match section name
-			 * "ABC0.0", but it should not match section_name
-			 * "ABCDEF".
-			 */
-			if ((section_names[i][len] != '\0') &&
-				!isdigit(section_names[i][len]))
-				continue;
-
-			if (strncmp(sch_s->prefix, section_names[i], len) == 0)
-				break;
-		}
-
-		APP_CHECK(j < (int)RTE_DIM(cfg_file_scheme),
-			"Parse error: unknown section %s",
-			section_names[i]);
-
-		APP_CHECK(validate_name(section_names[i],
-			sch_s->prefix,
-			sch_s->numbers) == 0,
-			"Parse error: invalid section name \"%s\"",
-			section_names[i]);
-
-		sch_s->load(app, section_names[i], cfg);
-	}
-
-	for (i = 0; i < sect_count; i++)
-		free(section_names[i]);
-
-	free(section_names);
-
-	rte_cfgfile_close(cfg);
-
-	APP_PARAM_COUNT(app->mempool_params, app->n_mempools);
-	APP_PARAM_COUNT(app->link_params, app->n_links);
-	APP_PARAM_COUNT(app->hwq_in_params, app->n_pktq_hwq_in);
-	APP_PARAM_COUNT(app->hwq_out_params, app->n_pktq_hwq_out);
-	APP_PARAM_COUNT(app->swq_params, app->n_pktq_swq);
-	APP_PARAM_COUNT(app->tm_params, app->n_pktq_tm);
-	APP_PARAM_COUNT(app->tap_params, app->n_pktq_tap);
-	APP_PARAM_COUNT(app->kni_params, app->n_pktq_kni);
-	APP_PARAM_COUNT(app->source_params, app->n_pktq_source);
-	APP_PARAM_COUNT(app->sink_params, app->n_pktq_sink);
-	APP_PARAM_COUNT(app->msgq_params, app->n_msgq);
-	APP_PARAM_COUNT(app->pipeline_params, app->n_pipelines);
-
-	if (app->port_mask == 0)
-		assign_link_pmd_id_from_pci_bdf(app);
-
-	/* Save configuration to output file */
-	app_config_save(app, app->output_file);
-
-	/* Load TM configuration files */
-	app_config_parse_tm(app);
-
-	return 0;
-}
-
-static void
-save_eal_params(struct app_params *app, FILE *f)
-{
-	struct app_eal_params *p = &app->eal_params;
-	uint32_t i;
-
-	fprintf(f, "[EAL]\n");
-
-	if (p->coremap)
-		fprintf(f, "%s = %s\n", "lcores", p->coremap);
-
-	if (p->master_lcore_present)
-		fprintf(f, "%s = %" PRIu32 "\n",
-			"master_lcore", p->master_lcore);
-
-	fprintf(f, "%s = %" PRIu32 "\n", "n", p->channels);
-
-	if (p->memory_present)
-		fprintf(f, "%s = %" PRIu32 "\n", "m", p->memory);
-
-	if (p->ranks_present)
-		fprintf(f, "%s = %" PRIu32 "\n", "r", p->ranks);
-
-	for (i = 0; i < APP_MAX_LINKS; i++) {
-		if (p->pci_blacklist[i] == NULL)
-			break;
-
-		fprintf(f, "%s = %s\n", "pci_blacklist",
-			p->pci_blacklist[i]);
-	}
-
-	for (i = 0; i < APP_MAX_LINKS; i++) {
-		if (p->pci_whitelist[i] == NULL)
-			break;
-
-		fprintf(f, "%s = %s\n", "pci_whitelist",
-			p->pci_whitelist[i]);
-	}
-
-	for (i = 0; i < APP_MAX_LINKS; i++) {
-		if (p->vdev[i] == NULL)
-			break;
-
-		fprintf(f, "%s = %s\n", "vdev",
-			p->vdev[i]);
-	}
-
-	if (p->vmware_tsc_map_present)
-		fprintf(f, "%s = %s\n", "vmware_tsc_map",
-			(p->vmware_tsc_map) ? "yes" : "no");
-
-	if (p->proc_type)
-		fprintf(f, "%s = %s\n", "proc_type", p->proc_type);
-
-	if (p->syslog)
-		fprintf(f, "%s = %s\n", "syslog", p->syslog);
-
-	if (p->log_level_present)
-		fprintf(f, "%s = %" PRIu32 "\n", "log_level", p->log_level);
-
-	if (p->version_present)
-		fprintf(f, "%s = %s\n",	"v", (p->version) ? "yes" : "no");
-
-	if (p->help_present)
-		fprintf(f, "%s = %s\n",	"help", (p->help) ? "yes" : "no");
-
-	if (p->no_huge_present)
-		fprintf(f, "%s = %s\n",	"no_huge", (p->no_huge) ? "yes" : "no");
-
-	if (p->no_pci_present)
-		fprintf(f, "%s = %s\n",	"no_pci", (p->no_pci) ? "yes" : "no");
-
-	if (p->no_hpet_present)
-		fprintf(f, "%s = %s\n",	"no_hpet", (p->no_hpet) ? "yes" : "no");
-
-	if (p->no_shconf_present)
-		fprintf(f, "%s = %s\n", "no_shconf",
-			(p->no_shconf) ? "yes" : "no");
-
-	if (p->add_driver)
-		fprintf(f, "%s = %s\n",	"d", p->add_driver);
-
-	if (p->socket_mem)
-		fprintf(f, "%s = %s\n",	"socket_mem", p->socket_mem);
-
-	if (p->huge_dir)
-		fprintf(f, "%s = %s\n", "huge_dir", p->huge_dir);
-
-	if (p->file_prefix)
-		fprintf(f, "%s = %s\n", "file_prefix", p->file_prefix);
-
-	if (p->base_virtaddr)
-		fprintf(f, "%s = %s\n",	"base_virtaddr", p->base_virtaddr);
-
-	if (p->create_uio_dev_present)
-		fprintf(f, "%s = %s\n", "create_uio_dev",
-			(p->create_uio_dev) ? "yes" : "no");
-
-	if (p->vfio_intr)
-		fprintf(f, "%s = %s\n", "vfio_intr", p->vfio_intr);
-
-	fputc('\n', f);
-}
-
-static void
-save_mempool_params(struct app_params *app, FILE *f)
-{
-	struct app_mempool_params *p;
-	size_t i, count;
-
-	count = RTE_DIM(app->mempool_params);
-	for (i = 0; i < count; i++) {
-		p = &app->mempool_params[i];
-		if (!APP_PARAM_VALID(p))
-			continue;
-
-		fprintf(f, "[%s]\n", p->name);
-		fprintf(f, "%s = %" PRIu32 "\n", "buffer_size", p->buffer_size);
-		fprintf(f, "%s = %" PRIu32 "\n", "pool_size", p->pool_size);
-		fprintf(f, "%s = %" PRIu32 "\n", "cache_size", p->cache_size);
-		fprintf(f, "%s = %" PRIu32 "\n", "cpu", p->cpu_socket_id);
-
-		fputc('\n', f);
-	}
-}
-
-static void
-save_links_params(struct app_params *app, FILE *f)
-{
-	struct app_link_params *p;
-	size_t i, count;
-
-	count = RTE_DIM(app->link_params);
-	for (i = 0; i < count; i++) {
-		p = &app->link_params[i];
-		if (!APP_PARAM_VALID(p))
-			continue;
-
-		fprintf(f, "[%s]\n", p->name);
-		fprintf(f, "; %s = %" PRIu32 "\n", "pmd_id", p->pmd_id);
-		fprintf(f, "%s = %s\n", "promisc", p->promisc ? "yes" : "no");
-		fprintf(f, "%s = %" PRIu32 "\n", "arp_q", p->arp_q);
-		fprintf(f, "%s = %" PRIu32 "\n", "tcp_syn_q",
-			p->tcp_syn_q);
-		fprintf(f, "%s = %" PRIu32 "\n", "ip_local_q", p->ip_local_q);
-		fprintf(f, "%s = %" PRIu32 "\n", "tcp_local_q", p->tcp_local_q);
-		fprintf(f, "%s = %" PRIu32 "\n", "udp_local_q", p->udp_local_q);
-		fprintf(f, "%s = %" PRIu32 "\n", "sctp_local_q",
-			p->sctp_local_q);
-
-		if (p->n_rss_qs) {
-			uint32_t j;
-
-			/* rss_qs */
-			fprintf(f, "rss_qs = ");
-			for (j = 0; j < p->n_rss_qs; j++)
-				fprintf(f, "%" PRIu32 " ",	p->rss_qs[j]);
-			fputc('\n', f);
-
-			/* rss_proto_ipv4 */
-			if (p->rss_proto_ipv4) {
-				fprintf(f, "rss_proto_ipv4 = ");
-				if (p->rss_proto_ipv4 & ETH_RSS_IPV4)
-					fprintf(f, "IP ");
-				if (p->rss_proto_ipv4 & ETH_RSS_FRAG_IPV4)
-					fprintf(f, "FRAG ");
-				if (p->rss_proto_ipv4 &
-					ETH_RSS_NONFRAG_IPV4_TCP)
-					fprintf(f, "TCP ");
-				if (p->rss_proto_ipv4 &
-					ETH_RSS_NONFRAG_IPV4_UDP)
-					fprintf(f, "UDP ");
-				if (p->rss_proto_ipv4 &
-					ETH_RSS_NONFRAG_IPV4_SCTP)
-					fprintf(f, "SCTP ");
-				if (p->rss_proto_ipv4 &
-					ETH_RSS_NONFRAG_IPV4_OTHER)
-					fprintf(f, "OTHER ");
-				fprintf(f, "\n");
-			} else
-				fprintf(f, "; rss_proto_ipv4 = <NONE>\n");
-
-			/* rss_proto_ipv6 */
-			if (p->rss_proto_ipv6) {
-				fprintf(f, "rss_proto_ipv6 = ");
-				if (p->rss_proto_ipv6 & ETH_RSS_IPV6)
-					fprintf(f, "IP ");
-				if (p->rss_proto_ipv6 & ETH_RSS_FRAG_IPV6)
-					fprintf(f, "FRAG ");
-				if (p->rss_proto_ipv6 &
-					ETH_RSS_NONFRAG_IPV6_TCP)
-					fprintf(f, "TCP ");
-				if (p->rss_proto_ipv6 &
-					ETH_RSS_NONFRAG_IPV6_UDP)
-					fprintf(f, "UDP ");
-				if (p->rss_proto_ipv6 &
-					ETH_RSS_NONFRAG_IPV6_SCTP)
-					fprintf(f, "SCTP ");
-				if (p->rss_proto_ipv6 &
-					ETH_RSS_NONFRAG_IPV6_OTHER)
-					fprintf(f, "OTHER ");
-				if (p->rss_proto_ipv6 & ETH_RSS_IPV6_EX)
-					fprintf(f, "IP_EX ");
-				if (p->rss_proto_ipv6 &
-					ETH_RSS_IPV6_TCP_EX)
-					fprintf(f, "TCP_EX ");
-				if (p->rss_proto_ipv6 &
-					ETH_RSS_IPV6_UDP_EX)
-					fprintf(f, "UDP_EX ");
-				fprintf(f, "\n");
-			} else
-				fprintf(f, "; rss_proto_ipv6 = <NONE>\n");
-
-			/* rss_proto_l2 */
-			if (p->rss_proto_l2) {
-				fprintf(f, "rss_proto_l2 = ");
-				if (p->rss_proto_l2 & ETH_RSS_L2_PAYLOAD)
-					fprintf(f, "L2 ");
-				fprintf(f, "\n");
-			} else
-				fprintf(f, "; rss_proto_l2 = <NONE>\n");
-		} else {
-			fprintf(f, "; rss_qs = <NONE>\n");
-			fprintf(f, "; rss_proto_ipv4 = <NONE>\n");
-			fprintf(f, "; rss_proto_ipv6 = <NONE>\n");
-			fprintf(f, "; rss_proto_l2 = <NONE>\n");
-		}
-
-		if (strlen(p->pci_bdf))
-			fprintf(f, "%s = %s\n", "pci_bdf", p->pci_bdf);
-
-		fputc('\n', f);
-	}
-}
-
-static void
-save_rxq_params(struct app_params *app, FILE *f)
-{
-	struct app_pktq_hwq_in_params *p;
-	size_t i, count;
-
-	count = RTE_DIM(app->hwq_in_params);
-	for (i = 0; i < count; i++) {
-		p = &app->hwq_in_params[i];
-		if (!APP_PARAM_VALID(p))
-			continue;
-
-		fprintf(f, "[%s]\n", p->name);
-		fprintf(f, "%s = %s\n",
-			"mempool",
-			app->mempool_params[p->mempool_id].name);
-		fprintf(f, "%s = %" PRIu32 "\n", "size", p->size);
-		fprintf(f, "%s = %" PRIu32 "\n", "burst", p->burst);
-
-		fputc('\n', f);
-	}
-}
-
-static void
-save_txq_params(struct app_params *app, FILE *f)
-{
-	struct app_pktq_hwq_out_params *p;
-	size_t i, count;
-
-	count = RTE_DIM(app->hwq_out_params);
-	for (i = 0; i < count; i++) {
-		p = &app->hwq_out_params[i];
-		if (!APP_PARAM_VALID(p))
-			continue;
-
-		fprintf(f, "[%s]\n", p->name);
-		fprintf(f, "%s = %" PRIu32 "\n", "size", p->size);
-		fprintf(f, "%s = %" PRIu32 "\n", "burst", p->burst);
-		fprintf(f, "%s = %s\n",
-			"dropless",
-			p->dropless ? "yes" : "no");
-		fprintf(f, "%s = %" PRIu64 "\n", "n_retries", p->n_retries);
-
-		fputc('\n', f);
-	}
-}
-
-static void
-save_swq_params(struct app_params *app, FILE *f)
-{
-	struct app_pktq_swq_params *p;
-	size_t i, count;
-
-	count = RTE_DIM(app->swq_params);
-	for (i = 0; i < count; i++) {
-		p = &app->swq_params[i];
-		if (!APP_PARAM_VALID(p))
-			continue;
-
-		fprintf(f, "[%s]\n", p->name);
-		fprintf(f, "%s = %" PRIu32 "\n", "size", p->size);
-		fprintf(f, "%s = %" PRIu32 "\n", "burst_read", p->burst_read);
-		fprintf(f, "%s = %" PRIu32 "\n", "burst_write", p->burst_write);
-		fprintf(f, "%s = %s\n", "dropless", p->dropless ? "yes" : "no");
-		fprintf(f, "%s = %" PRIu64 "\n", "n_retries", p->n_retries);
-		fprintf(f, "%s = %" PRIu32 "\n", "cpu", p->cpu_socket_id);
-		fprintf(f, "%s = %s\n", "ipv4_frag", p->ipv4_frag ? "yes" : "no");
-		fprintf(f, "%s = %s\n", "ipv6_frag", p->ipv6_frag ? "yes" : "no");
-		fprintf(f, "%s = %s\n", "ipv4_ras", p->ipv4_ras ? "yes" : "no");
-		fprintf(f, "%s = %s\n", "ipv6_ras", p->ipv6_ras ? "yes" : "no");
-		if ((p->ipv4_frag == 1) || (p->ipv6_frag == 1)) {
-			fprintf(f, "%s = %" PRIu32 "\n", "mtu", p->mtu);
-			fprintf(f, "%s = %" PRIu32 "\n", "metadata_size", p->metadata_size);
-			fprintf(f, "%s = %s\n",
-				"mempool_direct",
-				app->mempool_params[p->mempool_direct_id].name);
-			fprintf(f, "%s = %s\n",
-				"mempool_indirect",
-				app->mempool_params[p->mempool_indirect_id].name);
-		}
-
-		fputc('\n', f);
-	}
-}
-
-static void
-save_tm_params(struct app_params *app, FILE *f)
-{
-	struct app_pktq_tm_params *p;
-	size_t i, count;
-
-	count = RTE_DIM(app->tm_params);
-	for (i = 0; i < count; i++) {
-		p = &app->tm_params[i];
-		if (!APP_PARAM_VALID(p))
-			continue;
-
-		fprintf(f, "[%s]\n", p->name);
-		fprintf(f, "%s = %s\n", "cfg", p->file_name);
-		fprintf(f, "%s = %" PRIu32 "\n", "burst_read", p->burst_read);
-		fprintf(f, "%s = %" PRIu32 "\n", "burst_write", p->burst_write);
-
-		fputc('\n', f);
-	}
-}
-
-static void
-save_tap_params(struct app_params *app, FILE *f)
-{
-	struct app_pktq_tap_params *p;
-	size_t i, count;
-
-	count = RTE_DIM(app->tap_params);
-	for (i = 0; i < count; i++) {
-		p = &app->tap_params[i];
-		if (!APP_PARAM_VALID(p))
-			continue;
-
-		fprintf(f, "[%s]\n", p->name);
-		fprintf(f, "%s = %" PRIu32 "\n", "burst_read", p->burst_read);
-		fprintf(f, "%s = %" PRIu32 "\n", "burst_write", p->burst_write);
-		fprintf(f, "%s = %s\n", "dropless", p->dropless ? "yes" : "no");
-		fprintf(f, "%s = %" PRIu64 "\n", "n_retries", p->n_retries);
-		fprintf(f, "%s = %s\n", "mempool",
-			app->mempool_params[p->mempool_id].name);
-
-		fputc('\n', f);
-	}
-}
-
-static void
-save_kni_params(struct app_params *app, FILE *f)
-{
-	struct app_pktq_kni_params *p;
-	size_t i, count;
-
-	count = RTE_DIM(app->kni_params);
-	for (i = 0; i < count; i++) {
-		p = &app->kni_params[i];
-		if (!APP_PARAM_VALID(p))
-			continue;
-
-		/* section name */
-		fprintf(f, "[%s]\n", p->name);
-
-		/* core */
-		if (p->force_bind) {
-			fprintf(f, "; force_bind = 1\n");
-			fprintf(f, "core = s%" PRIu32 "c%" PRIu32 "%s\n",
-					p->socket_id,
-					p->core_id,
-					(p->hyper_th_id) ? "h" : "");
-		} else
-			fprintf(f, "; force_bind = 0\n");
-
-		/* mempool */
-		fprintf(f, "%s = %s\n", "mempool",
-				app->mempool_params[p->mempool_id].name);
-
-		/* burst_read */
-		fprintf(f, "%s = %" PRIu32 "\n", "burst_read", p->burst_read);
-
-		/* burst_write */
-		fprintf(f, "%s = %" PRIu32 "\n", "burst_write", p->burst_write);
-
-		/* dropless */
-		fprintf(f, "%s = %s\n",
-				"dropless",
-				p->dropless ? "yes" : "no");
-
-		/* n_retries */
-		fprintf(f, "%s = %" PRIu64 "\n", "n_retries", p->n_retries);
-
-		fputc('\n', f);
-	}
-}
-
-static void
-save_source_params(struct app_params *app, FILE *f)
-{
-	struct app_pktq_source_params *p;
-	size_t i, count;
-
-	count = RTE_DIM(app->source_params);
-	for (i = 0; i < count; i++) {
-		p = &app->source_params[i];
-		if (!APP_PARAM_VALID(p))
-			continue;
-
-		fprintf(f, "[%s]\n", p->name);
-		fprintf(f, "%s = %s\n",
-			"mempool",
-			app->mempool_params[p->mempool_id].name);
-		fprintf(f, "%s = %" PRIu32 "\n", "burst", p->burst);
-		fprintf(f, "%s = %s\n", "pcap_file_rd", p->file_name);
-		fprintf(f, "%s = %" PRIu32 "\n", "pcap_bytes_rd_per_pkt",
-			p->n_bytes_per_pkt);
-		fputc('\n', f);
-	}
-}
-
-static void
-save_sink_params(struct app_params *app, FILE *f)
-{
-	struct app_pktq_sink_params *p;
-	size_t i, count;
-
-	count = RTE_DIM(app->sink_params);
-	for (i = 0; i < count; i++) {
-		p = &app->sink_params[i];
-		if (!APP_PARAM_VALID(p))
-			continue;
-
-		fprintf(f, "[%s]\n", p->name);
-		fprintf(f, "%s = %s\n", "pcap_file_wr", p->file_name);
-		fprintf(f, "%s = %" PRIu32 "\n",
-				"pcap_n_pkt_wr", p->n_pkts_to_dump);
-		fputc('\n', f);
-	}
-}
-
-static void
-save_msgq_params(struct app_params *app, FILE *f)
-{
-	struct app_msgq_params *p;
-	size_t i, count;
-
-	count = RTE_DIM(app->msgq_params);
-	for (i = 0; i < count; i++) {
-		p = &app->msgq_params[i];
-		if (!APP_PARAM_VALID(p))
-			continue;
-
-		fprintf(f, "[%s]\n", p->name);
-		fprintf(f, "%s = %" PRIu32 "\n", "size", p->size);
-		fprintf(f, "%s = %" PRIu32 "\n", "cpu", p->cpu_socket_id);
-
-		fputc('\n', f);
-	}
-}
-
-static void
-save_pipeline_params(struct app_params *app, FILE *f)
-{
-	size_t i, count;
-
-	count = RTE_DIM(app->pipeline_params);
-	for (i = 0; i < count; i++) {
-		struct app_pipeline_params *p = &app->pipeline_params[i];
-
-		if (!APP_PARAM_VALID(p))
-			continue;
-
-		/* section name */
-		fprintf(f, "[%s]\n", p->name);
-
-		/* type */
-		fprintf(f, "type = %s\n", p->type);
-
-		/* core */
-		fprintf(f, "core = s%" PRIu32 "c%" PRIu32 "%s\n",
-			p->socket_id,
-			p->core_id,
-			(p->hyper_th_id) ? "h" : "");
-
-		/* pktq_in */
-		if (p->n_pktq_in) {
-			uint32_t j;
-
-			fprintf(f, "pktq_in =");
-			for (j = 0; j < p->n_pktq_in; j++) {
-				struct app_pktq_in_params *pp = &p->pktq_in[j];
-				char *name;
-
-				switch (pp->type) {
-				case APP_PKTQ_IN_HWQ:
-					name = app->hwq_in_params[pp->id].name;
-					break;
-				case APP_PKTQ_IN_SWQ:
-					name = app->swq_params[pp->id].name;
-					break;
-				case APP_PKTQ_IN_TM:
-					name = app->tm_params[pp->id].name;
-					break;
-				case APP_PKTQ_IN_TAP:
-					name = app->tap_params[pp->id].name;
-					break;
-				case APP_PKTQ_IN_KNI:
-					name = app->kni_params[pp->id].name;
-					break;
-				case APP_PKTQ_IN_SOURCE:
-					name = app->source_params[pp->id].name;
-					break;
-				default:
-					APP_CHECK(0, "System error "
-						"occurred while saving "
-						"parameter to file");
-				}
-
-				fprintf(f, " %s", name);
-			}
-			fprintf(f, "\n");
-		}
-
-		/* pktq_in */
-		if (p->n_pktq_out) {
-			uint32_t j;
-
-			fprintf(f, "pktq_out =");
-			for (j = 0; j < p->n_pktq_out; j++) {
-				struct app_pktq_out_params *pp =
-					&p->pktq_out[j];
-				char *name;
-
-				switch (pp->type) {
-				case APP_PKTQ_OUT_HWQ:
-					name = app->hwq_out_params[pp->id].name;
-					break;
-				case APP_PKTQ_OUT_SWQ:
-					name = app->swq_params[pp->id].name;
-					break;
-				case APP_PKTQ_OUT_TM:
-					name = app->tm_params[pp->id].name;
-					break;
-				case APP_PKTQ_OUT_TAP:
-					name = app->tap_params[pp->id].name;
-					break;
-				case APP_PKTQ_OUT_KNI:
-					name = app->kni_params[pp->id].name;
-					break;
-				case APP_PKTQ_OUT_SINK:
-					name = app->sink_params[pp->id].name;
-					break;
-				default:
-					APP_CHECK(0, "System error "
-						"occurred while saving "
-						"parameter to file");
-				}
-
-				fprintf(f, " %s", name);
-			}
-			fprintf(f, "\n");
-		}
-
-		/* msgq_in */
-		if (p->n_msgq_in) {
-			uint32_t j;
-
-			fprintf(f, "msgq_in =");
-			for (j = 0; j < p->n_msgq_in; j++) {
-				uint32_t id = p->msgq_in[j];
-				char *name = app->msgq_params[id].name;
-
-				fprintf(f, " %s", name);
-			}
-			fprintf(f, "\n");
-		}
-
-		/* msgq_out */
-		if (p->n_msgq_out) {
-			uint32_t j;
-
-			fprintf(f, "msgq_out =");
-			for (j = 0; j < p->n_msgq_out; j++) {
-				uint32_t id = p->msgq_out[j];
-				char *name = app->msgq_params[id].name;
-
-				fprintf(f, " %s", name);
-			}
-			fprintf(f, "\n");
-		}
-
-		/* timer_period */
-		fprintf(f, "timer_period = %" PRIu32 "\n", p->timer_period);
-
-		/* args */
-		if (p->n_args) {
-			uint32_t j;
-
-			for (j = 0; j < p->n_args; j++)
-				fprintf(f, "%s = %s\n", p->args_name[j],
-					p->args_value[j]);
-		}
-
-		fprintf(f, "\n");
-	}
-}
-
-void
-app_config_save(struct app_params *app, const char *file_name)
-{
-	FILE *file;
-	char *name, *dir_name;
-	int status;
-
-	name = strdup(file_name);
-	dir_name = dirname(name);
-	status = access(dir_name, W_OK);
-	APP_CHECK((status == 0),
-		"Error: need write access privilege to directory "
-		"\"%s\" to save configuration\n", dir_name);
-
-	file = fopen(file_name, "w");
-	APP_CHECK((file != NULL),
-		"Error: failed to save configuration to file \"%s\"",
-		file_name);
-
-	save_eal_params(app, file);
-	save_pipeline_params(app, file);
-	save_mempool_params(app, file);
-	save_links_params(app, file);
-	save_rxq_params(app, file);
-	save_txq_params(app, file);
-	save_swq_params(app, file);
-	save_tm_params(app, file);
-	save_tap_params(app, file);
-	save_kni_params(app, file);
-	save_source_params(app, file);
-	save_sink_params(app, file);
-	save_msgq_params(app, file);
-
-	fclose(file);
-	free(name);
-}
-
-int
-app_config_init(struct app_params *app)
-{
-	size_t i;
-
-	memcpy(app, &app_params_default, sizeof(struct app_params));
-
-	for (i = 0; i < RTE_DIM(app->mempool_params); i++)
-		memcpy(&app->mempool_params[i],
-			&mempool_params_default,
-			sizeof(struct app_mempool_params));
-
-	for (i = 0; i < RTE_DIM(app->link_params); i++)
-		memcpy(&app->link_params[i],
-			&link_params_default,
-			sizeof(struct app_link_params));
-
-	for (i = 0; i < RTE_DIM(app->hwq_in_params); i++)
-		memcpy(&app->hwq_in_params[i],
-			&default_hwq_in_params,
-			sizeof(default_hwq_in_params));
-
-	for (i = 0; i < RTE_DIM(app->hwq_out_params); i++)
-		memcpy(&app->hwq_out_params[i],
-			&default_hwq_out_params,
-			sizeof(default_hwq_out_params));
-
-	for (i = 0; i < RTE_DIM(app->swq_params); i++)
-		memcpy(&app->swq_params[i],
-			&default_swq_params,
-			sizeof(default_swq_params));
-
-	for (i = 0; i < RTE_DIM(app->tm_params); i++)
-		memcpy(&app->tm_params[i],
-			&default_tm_params,
-			sizeof(default_tm_params));
-
-	for (i = 0; i < RTE_DIM(app->tap_params); i++)
-		memcpy(&app->tap_params[i],
-			&default_tap_params,
-			sizeof(default_tap_params));
-
-	for (i = 0; i < RTE_DIM(app->kni_params); i++)
-		memcpy(&app->kni_params[i],
-			   &default_kni_params,
-			   sizeof(default_kni_params));
-
-	for (i = 0; i < RTE_DIM(app->source_params); i++)
-		memcpy(&app->source_params[i],
-			&default_source_params,
-			sizeof(default_source_params));
-
-	for (i = 0; i < RTE_DIM(app->sink_params); i++)
-		memcpy(&app->sink_params[i],
-			&default_sink_params,
-			sizeof(default_sink_params));
-
-	for (i = 0; i < RTE_DIM(app->msgq_params); i++)
-		memcpy(&app->msgq_params[i],
-			&default_msgq_params,
-			sizeof(default_msgq_params));
-
-	for (i = 0; i < RTE_DIM(app->pipeline_params); i++)
-		memcpy(&app->pipeline_params[i],
-			&default_pipeline_params,
-			sizeof(default_pipeline_params));
-
-	return 0;
-}
-
-static char *
-filenamedup(const char *filename, const char *suffix)
-{
-	char *s = malloc(strlen(filename) + strlen(suffix) + 1);
-
-	if (!s)
-		return NULL;
-
-	sprintf(s, "%s%s", filename, suffix);
-	return s;
-}
-
-int
-app_config_args(struct app_params *app, int argc, char **argv)
-{
-	const char *optname;
-	int opt, option_index;
-	int f_present, s_present, p_present, l_present;
-	int preproc_present, preproc_params_present;
-	int scaned = 0;
-
-	static struct option lgopts[] = {
-		{ "preproc", 1, 0, 0 },
-		{ "preproc-args", 1, 0, 0 },
-		{ NULL,  0, 0, 0 }
-	};
-
-	/* Copy application name */
-	strncpy(app->app_name, argv[0], APP_APPNAME_SIZE - 1);
-
-	f_present = 0;
-	s_present = 0;
-	p_present = 0;
-	l_present = 0;
-	preproc_present = 0;
-	preproc_params_present = 0;
-
-	while ((opt = getopt_long(argc, argv, "f:s:p:l:", lgopts,
-			&option_index)) != EOF)
-		switch (opt) {
-		case 'f':
-			if (f_present)
-				rte_panic("Error: Config file is provided "
-					"more than once\n");
-			f_present = 1;
-
-			if (!strlen(optarg))
-				rte_panic("Error: Config file name is null\n");
-
-			app->config_file = strdup(optarg);
-			if (app->config_file == NULL)
-				rte_panic("Error: Memory allocation failure\n");
-
-			break;
-
-		case 's':
-			if (s_present)
-				rte_panic("Error: Script file is provided "
-					"more than once\n");
-			s_present = 1;
-
-			if (!strlen(optarg))
-				rte_panic("Error: Script file name is null\n");
-
-			app->script_file = strdup(optarg);
-			if (app->script_file == NULL)
-				rte_panic("Error: Memory allocation failure\n");
-
-			break;
-
-		case 'p':
-			if (p_present)
-				rte_panic("Error: PORT_MASK is provided "
-					"more than once\n");
-			p_present = 1;
-
-			if ((sscanf(optarg, "%" SCNx64 "%n", &app->port_mask,
-				&scaned) != 1) ||
-				((size_t) scaned != strlen(optarg)))
-				rte_panic("Error: PORT_MASK is not "
-					"a hexadecimal integer\n");
-
-			if (app->port_mask == 0)
-				rte_panic("Error: PORT_MASK is null\n");
-
-			break;
-
-		case 'l':
-			if (l_present)
-				rte_panic("Error: LOG_LEVEL is provided "
-					"more than once\n");
-			l_present = 1;
-
-			if ((sscanf(optarg, "%" SCNu32 "%n", &app->log_level,
-				&scaned) != 1) ||
-				((size_t) scaned != strlen(optarg)) ||
-				(app->log_level >= APP_LOG_LEVELS))
-				rte_panic("Error: LOG_LEVEL invalid value\n");
-
-			break;
-
-		case 0:
-			optname = lgopts[option_index].name;
-
-			if (strcmp(optname, "preproc") == 0) {
-				if (preproc_present)
-					rte_panic("Error: Preprocessor argument "
-						"is provided more than once\n");
-				preproc_present = 1;
-
-				app->preproc = strdup(optarg);
-				break;
-			}
-
-			if (strcmp(optname, "preproc-args") == 0) {
-				if (preproc_params_present)
-					rte_panic("Error: Preprocessor args "
-						"are provided more than once\n");
-				preproc_params_present = 1;
-
-				app->preproc_args = strdup(optarg);
-				break;
-			}
-
-			app_print_usage(argv[0]);
-			break;
-
-		default:
-			app_print_usage(argv[0]);
-		}
-
-	optind = 1; /* reset getopt lib */
-
-	/* Check dependencies between args */
-	if (preproc_params_present && (preproc_present == 0))
-		rte_panic("Error: Preprocessor args specified while "
-			"preprocessor is not defined\n");
-
-	app->parser_file = preproc_present ?
-		filenamedup(app->config_file, ".preproc") :
-		strdup(app->config_file);
-	app->output_file = filenamedup(app->config_file, ".out");
-
-	return 0;
-}
-
-int
-app_config_preproc(struct app_params *app)
-{
-	char buffer[256];
-	int status;
-
-	if (app->preproc == NULL)
-		return 0;
-
-	status = access(app->config_file, F_OK | R_OK);
-	APP_CHECK((status == 0), "Error: Unable to open file %s",
-		app->config_file);
-
-	snprintf(buffer, sizeof(buffer), "%s %s %s > %s",
-		app->preproc,
-		app->preproc_args ? app->preproc_args : "",
-		app->config_file,
-		app->parser_file);
-
-	status = system(buffer);
-	APP_CHECK((WIFEXITED(status) && (WEXITSTATUS(status) == 0)),
-		"Error occurred while pre-processing file \"%s\"\n",
-		app->config_file);
-
-	return status;
-}
diff --git a/examples/ip_pipeline/config_parse_tm.c b/examples/ip_pipeline/config_parse_tm.c
deleted file mode 100644
index 6edd2ca..0000000
--- a/examples/ip_pipeline/config_parse_tm.c
+++ /dev/null
@@ -1,419 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-#include <stdint.h>
-#include <stdlib.h>
-#include <stdio.h>
-#include <ctype.h>
-#include <getopt.h>
-#include <errno.h>
-#include <stdarg.h>
-#include <string.h>
-#include <libgen.h>
-#include <unistd.h>
-
-#include <rte_errno.h>
-#include <rte_cfgfile.h>
-#include <rte_string_fns.h>
-
-#include "app.h"
-
-static int
-tm_cfgfile_load_sched_port(
-	struct rte_cfgfile *file,
-	struct rte_sched_port_params *port_params)
-{
-	const char *entry;
-	int j;
-
-	entry = rte_cfgfile_get_entry(file, "port", "frame overhead");
-	if (entry)
-		port_params->frame_overhead = (uint32_t)atoi(entry);
-
-	entry = rte_cfgfile_get_entry(file, "port", "mtu");
-	if (entry)
-		port_params->mtu = (uint32_t)atoi(entry);
-
-	entry = rte_cfgfile_get_entry(file,
-		"port",
-		"number of subports per port");
-	if (entry)
-		port_params->n_subports_per_port = (uint32_t) atoi(entry);
-
-	entry = rte_cfgfile_get_entry(file,
-		"port",
-		"number of pipes per subport");
-	if (entry)
-		port_params->n_pipes_per_subport = (uint32_t) atoi(entry);
-
-	entry = rte_cfgfile_get_entry(file, "port", "queue sizes");
-	if (entry) {
-		char *next;
-
-		for (j = 0; j < RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE; j++) {
-			port_params->qsize[j] = (uint16_t)
-				strtol(entry, &next, 10);
-			if (next == NULL)
-				break;
-			entry = next;
-		}
-	}
-
-#ifdef RTE_SCHED_RED
-	for (j = 0; j < RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE; j++) {
-		char str[32];
-
-		/* Parse WRED min thresholds */
-		snprintf(str, sizeof(str), "tc %" PRId32 " wred min", j);
-		entry = rte_cfgfile_get_entry(file, "red", str);
-		if (entry) {
-			char *next;
-			int k;
-
-			/* for each packet colour (green, yellow, red) */
-			for (k = 0; k < e_RTE_METER_COLORS; k++) {
-				port_params->red_params[j][k].min_th
-					= (uint16_t)strtol(entry, &next, 10);
-				if (next == NULL)
-					break;
-				entry = next;
-			}
-		}
-
-		/* Parse WRED max thresholds */
-		snprintf(str, sizeof(str), "tc %" PRId32 " wred max", j);
-		entry = rte_cfgfile_get_entry(file, "red", str);
-		if (entry) {
-			char *next;
-			int k;
-
-			/* for each packet colour (green, yellow, red) */
-			for (k = 0; k < e_RTE_METER_COLORS; k++) {
-				port_params->red_params[j][k].max_th
-					= (uint16_t)strtol(entry, &next, 10);
-				if (next == NULL)
-					break;
-				entry = next;
-			}
-		}
-
-		/* Parse WRED inverse mark probabilities */
-		snprintf(str, sizeof(str), "tc %" PRId32 " wred inv prob", j);
-		entry = rte_cfgfile_get_entry(file, "red", str);
-		if (entry) {
-			char *next;
-			int k;
-
-			/* for each packet colour (green, yellow, red) */
-			for (k = 0; k < e_RTE_METER_COLORS; k++) {
-				port_params->red_params[j][k].maxp_inv
-					= (uint8_t)strtol(entry, &next, 10);
-
-				if (next == NULL)
-					break;
-				entry = next;
-			}
-		}
-
-		/* Parse WRED EWMA filter weights */
-		snprintf(str, sizeof(str), "tc %" PRId32 " wred weight", j);
-		entry = rte_cfgfile_get_entry(file, "red", str);
-		if (entry) {
-			char *next;
-			int k;
-
-			/* for each packet colour (green, yellow, red) */
-			for (k = 0; k < e_RTE_METER_COLORS; k++) {
-				port_params->red_params[j][k].wq_log2
-					= (uint8_t)strtol(entry, &next, 10);
-				if (next == NULL)
-					break;
-				entry = next;
-			}
-		}
-	}
-#endif /* RTE_SCHED_RED */
-
-	return 0;
-}
-
-static int
-tm_cfgfile_load_sched_pipe(
-	struct rte_cfgfile *file,
-	struct rte_sched_port_params *port_params,
-	struct rte_sched_pipe_params *pipe_params)
-{
-	int i, j;
-	char *next;
-	const char *entry;
-	int profiles;
-
-	profiles = rte_cfgfile_num_sections(file,
-		"pipe profile", sizeof("pipe profile") - 1);
-	port_params->n_pipe_profiles = profiles;
-
-	for (j = 0; j < profiles; j++) {
-		char pipe_name[32];
-
-		snprintf(pipe_name, sizeof(pipe_name),
-			"pipe profile %" PRId32, j);
-
-		entry = rte_cfgfile_get_entry(file, pipe_name, "tb rate");
-		if (entry)
-			pipe_params[j].tb_rate = (uint32_t) atoi(entry);
-
-		entry = rte_cfgfile_get_entry(file, pipe_name, "tb size");
-		if (entry)
-			pipe_params[j].tb_size = (uint32_t) atoi(entry);
-
-		entry = rte_cfgfile_get_entry(file, pipe_name, "tc period");
-		if (entry)
-			pipe_params[j].tc_period = (uint32_t) atoi(entry);
-
-		entry = rte_cfgfile_get_entry(file, pipe_name, "tc 0 rate");
-		if (entry)
-			pipe_params[j].tc_rate[0] = (uint32_t) atoi(entry);
-
-		entry = rte_cfgfile_get_entry(file, pipe_name, "tc 1 rate");
-		if (entry)
-			pipe_params[j].tc_rate[1] = (uint32_t) atoi(entry);
-
-		entry = rte_cfgfile_get_entry(file, pipe_name, "tc 2 rate");
-		if (entry)
-			pipe_params[j].tc_rate[2] = (uint32_t) atoi(entry);
-
-		entry = rte_cfgfile_get_entry(file, pipe_name, "tc 3 rate");
-		if (entry)
-			pipe_params[j].tc_rate[3] = (uint32_t) atoi(entry);
-
-#ifdef RTE_SCHED_SUBPORT_TC_OV
-		entry = rte_cfgfile_get_entry(file, pipe_name,
-			"tc 3 oversubscription weight");
-		if (entry)
-			pipe_params[j].tc_ov_weight = (uint8_t)atoi(entry);
-#endif
-
-		entry = rte_cfgfile_get_entry(file,
-			pipe_name,
-			"tc 0 wrr weights");
-		if (entry)
-			for (i = 0; i < RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS; i++) {
-				pipe_params[j].wrr_weights[RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE*0 + i] =
-					(uint8_t) strtol(entry, &next, 10);
-				if (next == NULL)
-					break;
-				entry = next;
-			}
-
-		entry = rte_cfgfile_get_entry(file, pipe_name, "tc 1 wrr weights");
-		if (entry)
-			for (i = 0; i < RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS; i++) {
-				pipe_params[j].wrr_weights[RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE*1 + i] =
-					(uint8_t) strtol(entry, &next, 10);
-				if (next == NULL)
-					break;
-				entry = next;
-			}
-
-		entry = rte_cfgfile_get_entry(file, pipe_name, "tc 2 wrr weights");
-		if (entry)
-			for (i = 0; i < RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS; i++) {
-				pipe_params[j].wrr_weights[RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE*2 + i] =
-					(uint8_t) strtol(entry, &next, 10);
-				if (next == NULL)
-					break;
-				entry = next;
-			}
-
-		entry = rte_cfgfile_get_entry(file, pipe_name, "tc 3 wrr weights");
-		if (entry)
-			for (i = 0; i < RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS; i++) {
-				pipe_params[j].wrr_weights[RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE*3 + i] =
-					(uint8_t) strtol(entry, &next, 10);
-				if (next == NULL)
-					break;
-				entry = next;
-			}
-	}
-	return 0;
-}
-
-static int
-tm_cfgfile_load_sched_subport(
-	struct rte_cfgfile *file,
-	struct rte_sched_subport_params *subport_params,
-	int *pipe_to_profile)
-{
-	const char *entry;
-	int i, j, k;
-
-	for (i = 0; i < APP_MAX_SCHED_SUBPORTS; i++) {
-		char sec_name[CFG_NAME_LEN];
-
-		snprintf(sec_name, sizeof(sec_name),
-			"subport %" PRId32, i);
-
-		if (rte_cfgfile_has_section(file, sec_name)) {
-			entry = rte_cfgfile_get_entry(file,
-				sec_name,
-				"tb rate");
-			if (entry)
-				subport_params[i].tb_rate =
-					(uint32_t) atoi(entry);
-
-			entry = rte_cfgfile_get_entry(file,
-				sec_name,
-				"tb size");
-			if (entry)
-				subport_params[i].tb_size =
-					(uint32_t) atoi(entry);
-
-			entry = rte_cfgfile_get_entry(file,
-				sec_name,
-				"tc period");
-			if (entry)
-				subport_params[i].tc_period =
-					(uint32_t) atoi(entry);
-
-			entry = rte_cfgfile_get_entry(file,
-				sec_name,
-				"tc 0 rate");
-			if (entry)
-				subport_params[i].tc_rate[0] =
-					(uint32_t) atoi(entry);
-
-			entry = rte_cfgfile_get_entry(file,
-				sec_name,
-				"tc 1 rate");
-			if (entry)
-				subport_params[i].tc_rate[1] =
-					(uint32_t) atoi(entry);
-
-			entry = rte_cfgfile_get_entry(file,
-				sec_name,
-				"tc 2 rate");
-			if (entry)
-				subport_params[i].tc_rate[2] =
-					(uint32_t) atoi(entry);
-
-			entry = rte_cfgfile_get_entry(file,
-				sec_name,
-				"tc 3 rate");
-			if (entry)
-				subport_params[i].tc_rate[3] =
-					(uint32_t) atoi(entry);
-
-			int n_entries = rte_cfgfile_section_num_entries(file,
-				sec_name);
-			struct rte_cfgfile_entry entries[n_entries];
-
-			rte_cfgfile_section_entries(file,
-				sec_name,
-				entries,
-				n_entries);
-
-			for (j = 0; j < n_entries; j++)
-				if (strncmp("pipe",
-					entries[j].name,
-					sizeof("pipe") - 1) == 0) {
-					int profile;
-					char *tokens[2] = {NULL, NULL};
-					int n_tokens;
-					int begin, end;
-					char name[CFG_NAME_LEN + 1];
-
-					profile = atoi(entries[j].value);
-					strncpy(name,
-						entries[j].name,
-						sizeof(name));
-					n_tokens = rte_strsplit(
-						&name[sizeof("pipe")],
-						strnlen(name, CFG_NAME_LEN),
-							tokens, 2, '-');
-
-					begin =  atoi(tokens[0]);
-					if (n_tokens == 2)
-						end = atoi(tokens[1]);
-					else
-						end = begin;
-
-					if ((end >= APP_MAX_SCHED_PIPES) ||
-						(begin > end))
-						return -1;
-
-					for (k = begin; k <= end; k++) {
-						char profile_name[CFG_NAME_LEN];
-
-						snprintf(profile_name,
-							sizeof(profile_name),
-							"pipe profile %" PRId32,
-							profile);
-						if (rte_cfgfile_has_section(file, profile_name))
-							pipe_to_profile[i * APP_MAX_SCHED_PIPES + k] = profile;
-						else
-							rte_exit(EXIT_FAILURE,
-								"Wrong pipe profile %s\n",
-								entries[j].value);
-					}
-				}
-		}
-	}
-
-	return 0;
-}
-
-static int
-tm_cfgfile_load(struct app_pktq_tm_params *tm)
-{
-	struct rte_cfgfile *file;
-	uint32_t i;
-
-	memset(tm->sched_subport_params, 0, sizeof(tm->sched_subport_params));
-	memset(tm->sched_pipe_profiles, 0, sizeof(tm->sched_pipe_profiles));
-	memset(&tm->sched_port_params, 0, sizeof(tm->sched_port_params));
-	for (i = 0; i < APP_MAX_SCHED_SUBPORTS * APP_MAX_SCHED_PIPES; i++)
-		tm->sched_pipe_to_profile[i] = -1;
-
-	tm->sched_port_params.pipe_profiles = &tm->sched_pipe_profiles[0];
-
-	if (tm->file_name[0] == '\0')
-		return -1;
-
-	file = rte_cfgfile_load(tm->file_name, 0);
-	if (file == NULL)
-		return -1;
-
-	tm_cfgfile_load_sched_port(file,
-		&tm->sched_port_params);
-	tm_cfgfile_load_sched_subport(file,
-		tm->sched_subport_params,
-		tm->sched_pipe_to_profile);
-	tm_cfgfile_load_sched_pipe(file,
-		&tm->sched_port_params,
-		tm->sched_pipe_profiles);
-
-	rte_cfgfile_close(file);
-	return 0;
-}
-
-int
-app_config_parse_tm(struct app_params *app)
-{
-	uint32_t i;
-
-	for (i = 0; i < RTE_DIM(app->tm_params); i++) {
-		struct app_pktq_tm_params *p = &app->tm_params[i];
-		int status;
-
-		if (!APP_PARAM_VALID(p))
-			break;
-
-		status = tm_cfgfile_load(p);
-		APP_CHECK(status == 0,
-			"Parse error for %s configuration file \"%s\"\n",
-			p->name,
-			p->file_name);
-	}
-
-	return 0;
-}
diff --git a/examples/ip_pipeline/cpu_core_map.c b/examples/ip_pipeline/cpu_core_map.c
deleted file mode 100644
index 231f38e..0000000
--- a/examples/ip_pipeline/cpu_core_map.c
+++ /dev/null
@@ -1,471 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#include <inttypes.h>
-#include <stdlib.h>
-#include <stdio.h>
-#include <string.h>
-
-#include <rte_lcore.h>
-
-#include "cpu_core_map.h"
-
-struct cpu_core_map {
-	uint32_t n_max_sockets;
-	uint32_t n_max_cores_per_socket;
-	uint32_t n_max_ht_per_core;
-	uint32_t n_sockets;
-	uint32_t n_cores_per_socket;
-	uint32_t n_ht_per_core;
-	int map[0];
-};
-
-static inline uint32_t
-cpu_core_map_pos(struct cpu_core_map *map,
-	uint32_t socket_id,
-	uint32_t core_id,
-	uint32_t ht_id)
-{
-	return (socket_id * map->n_max_cores_per_socket + core_id) *
-		map->n_max_ht_per_core + ht_id;
-}
-
-static int
-cpu_core_map_compute_eal(struct cpu_core_map *map);
-
-static int
-cpu_core_map_compute_linux(struct cpu_core_map *map);
-
-static int
-cpu_core_map_compute_and_check(struct cpu_core_map *map);
-
-struct cpu_core_map *
-cpu_core_map_init(uint32_t n_max_sockets,
-	uint32_t n_max_cores_per_socket,
-	uint32_t n_max_ht_per_core,
-	uint32_t eal_initialized)
-{
-	uint32_t map_size, map_mem_size, i;
-	struct cpu_core_map *map;
-	int status;
-
-	/* Check input arguments */
-	if ((n_max_sockets == 0) ||
-		(n_max_cores_per_socket == 0) ||
-		(n_max_ht_per_core == 0))
-		return NULL;
-
-	/* Memory allocation */
-	map_size = n_max_sockets * n_max_cores_per_socket * n_max_ht_per_core;
-	map_mem_size = sizeof(struct cpu_core_map) + map_size * sizeof(int);
-	map = (struct cpu_core_map *) malloc(map_mem_size);
-	if (map == NULL)
-		return NULL;
-
-	/* Initialization */
-	map->n_max_sockets = n_max_sockets;
-	map->n_max_cores_per_socket = n_max_cores_per_socket;
-	map->n_max_ht_per_core = n_max_ht_per_core;
-	map->n_sockets = 0;
-	map->n_cores_per_socket = 0;
-	map->n_ht_per_core = 0;
-
-	for (i = 0; i < map_size; i++)
-		map->map[i] = -1;
-
-	status = (eal_initialized) ?
-		cpu_core_map_compute_eal(map) :
-		cpu_core_map_compute_linux(map);
-
-	if (status) {
-		free(map);
-		return NULL;
-	}
-
-	status = cpu_core_map_compute_and_check(map);
-	if (status) {
-		free(map);
-		return NULL;
-	}
-
-	return map;
-}
-
-int
-cpu_core_map_compute_eal(struct cpu_core_map *map)
-{
-	uint32_t socket_id, core_id, ht_id;
-
-	/* Compute map */
-	for (socket_id = 0; socket_id < map->n_max_sockets; socket_id++) {
-		uint32_t n_detected, core_id_contig;
-		int lcore_id;
-
-		n_detected = 0;
-		for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-			struct lcore_config *p = &lcore_config[lcore_id];
-
-			if ((p->detected) && (p->socket_id == socket_id))
-				n_detected++;
-		}
-
-		core_id_contig = 0;
-
-		for (core_id = 0; n_detected ; core_id++) {
-			ht_id = 0;
-
-			for (lcore_id = 0;
-				lcore_id < RTE_MAX_LCORE;
-				lcore_id++) {
-				struct lcore_config *p =
-					&lcore_config[lcore_id];
-
-				if ((p->detected) &&
-					(p->socket_id == socket_id) &&
-					(p->core_id == core_id)) {
-					uint32_t pos = cpu_core_map_pos(map,
-						socket_id,
-						core_id_contig,
-						ht_id);
-
-					map->map[pos] = lcore_id;
-					ht_id++;
-					n_detected--;
-				}
-			}
-
-			if (ht_id) {
-				core_id_contig++;
-				if (core_id_contig ==
-					map->n_max_cores_per_socket)
-					return -1;
-			}
-		}
-	}
-
-	return 0;
-}
-
-int
-cpu_core_map_compute_and_check(struct cpu_core_map *map)
-{
-	uint32_t socket_id, core_id, ht_id;
-
-	/* Compute n_ht_per_core, n_cores_per_socket, n_sockets */
-	for (ht_id = 0; ht_id < map->n_max_ht_per_core; ht_id++) {
-		if (map->map[ht_id] == -1)
-			break;
-
-		map->n_ht_per_core++;
-	}
-
-	if (map->n_ht_per_core == 0)
-		return -1;
-
-	for (core_id = 0; core_id < map->n_max_cores_per_socket; core_id++) {
-		uint32_t pos = core_id * map->n_max_ht_per_core;
-
-		if (map->map[pos] == -1)
-			break;
-
-		map->n_cores_per_socket++;
-	}
-
-	if (map->n_cores_per_socket == 0)
-		return -1;
-
-	for (socket_id = 0; socket_id < map->n_max_sockets; socket_id++) {
-		uint32_t pos = socket_id * map->n_max_cores_per_socket *
-			map->n_max_ht_per_core;
-
-		if (map->map[pos] == -1)
-			break;
-
-		map->n_sockets++;
-	}
-
-	if (map->n_sockets == 0)
-		return -1;
-
-	/* Check that each socket has exactly the same number of cores
-	and that each core has exactly the same number of hyper-threads */
-	for (socket_id = 0; socket_id < map->n_sockets; socket_id++) {
-		for (core_id = 0; core_id < map->n_cores_per_socket; core_id++)
-			for (ht_id = 0;
-				ht_id < map->n_max_ht_per_core;
-				ht_id++) {
-				uint32_t pos = (socket_id *
-					map->n_max_cores_per_socket + core_id) *
-					map->n_max_ht_per_core + ht_id;
-
-				if (((ht_id < map->n_ht_per_core) &&
-					(map->map[pos] == -1)) ||
-					((ht_id >= map->n_ht_per_core) &&
-					(map->map[pos] != -1)))
-					return -1;
-			}
-
-		for ( ; core_id < map->n_max_cores_per_socket; core_id++)
-			for (ht_id = 0;
-				ht_id < map->n_max_ht_per_core;
-				ht_id++) {
-				uint32_t pos = cpu_core_map_pos(map,
-					socket_id,
-					core_id,
-					ht_id);
-
-				if (map->map[pos] != -1)
-					return -1;
-			}
-	}
-
-	return 0;
-}
-
-#define FILE_LINUX_CPU_N_LCORES \
-	"/sys/devices/system/cpu/present"
-
-static int
-cpu_core_map_get_n_lcores_linux(void)
-{
-	char buffer[64], *string;
-	FILE *fd;
-
-	fd = fopen(FILE_LINUX_CPU_N_LCORES, "r");
-	if (fd == NULL)
-		return -1;
-
-	if (fgets(buffer, sizeof(buffer), fd) == NULL) {
-		fclose(fd);
-		return -1;
-	}
-
-	fclose(fd);
-
-	string = index(buffer, '-');
-	if (string == NULL)
-		return -1;
-
-	return atoi(++string) + 1;
-}
-
-#define FILE_LINUX_CPU_CORE_ID \
-	"/sys/devices/system/cpu/cpu%" PRIu32 "/topology/core_id"
-
-static int
-cpu_core_map_get_core_id_linux(int lcore_id)
-{
-	char buffer[64];
-	FILE *fd;
-	int core_id;
-
-	snprintf(buffer, sizeof(buffer), FILE_LINUX_CPU_CORE_ID, lcore_id);
-	fd = fopen(buffer, "r");
-	if (fd == NULL)
-		return -1;
-
-	if (fgets(buffer, sizeof(buffer), fd) == NULL) {
-		fclose(fd);
-		return -1;
-	}
-
-	fclose(fd);
-
-	core_id = atoi(buffer);
-	return core_id;
-}
-
-#define FILE_LINUX_CPU_SOCKET_ID \
-	"/sys/devices/system/cpu/cpu%" PRIu32 "/topology/physical_package_id"
-
-static int
-cpu_core_map_get_socket_id_linux(int lcore_id)
-{
-	char buffer[64];
-	FILE *fd;
-	int socket_id;
-
-	snprintf(buffer, sizeof(buffer), FILE_LINUX_CPU_SOCKET_ID, lcore_id);
-	fd = fopen(buffer, "r");
-	if (fd == NULL)
-		return -1;
-
-	if (fgets(buffer, sizeof(buffer), fd) == NULL) {
-		fclose(fd);
-		return -1;
-	}
-
-	fclose(fd);
-
-	socket_id = atoi(buffer);
-	return socket_id;
-}
-
-int
-cpu_core_map_compute_linux(struct cpu_core_map *map)
-{
-	uint32_t socket_id, core_id, ht_id;
-	int n_lcores;
-
-	n_lcores = cpu_core_map_get_n_lcores_linux();
-	if (n_lcores <= 0)
-		return -1;
-
-	/* Compute map */
-	for (socket_id = 0; socket_id < map->n_max_sockets; socket_id++) {
-		uint32_t n_detected, core_id_contig;
-		int lcore_id;
-
-		n_detected = 0;
-		for (lcore_id = 0; lcore_id < n_lcores; lcore_id++) {
-			int lcore_socket_id =
-				cpu_core_map_get_socket_id_linux(lcore_id);
-
-#if !defined(RTE_ARCH_PPC_64)
-			if (lcore_socket_id < 0)
-				return -1;
-#endif
-
-			if (((uint32_t) lcore_socket_id) == socket_id)
-				n_detected++;
-		}
-
-		core_id_contig = 0;
-
-		for (core_id = 0; n_detected ; core_id++) {
-			ht_id = 0;
-
-			for (lcore_id = 0; lcore_id < n_lcores; lcore_id++) {
-				int lcore_socket_id =
-					cpu_core_map_get_socket_id_linux(
-					lcore_id);
-
-#if !defined(RTE_ARCH_PPC_64)
-				if (lcore_socket_id < 0)
-					return -1;
-
-				int lcore_core_id =
-					cpu_core_map_get_core_id_linux(
-						lcore_id);
-
-				if (lcore_core_id < 0)
-					return -1;
-#endif
-
-#if !defined(RTE_ARCH_PPC_64)
-				if (((uint32_t) lcore_socket_id == socket_id) &&
-					((uint32_t) lcore_core_id == core_id)) {
-#else
-				if (((uint32_t) lcore_socket_id == socket_id)) {
-#endif
-					uint32_t pos = cpu_core_map_pos(map,
-						socket_id,
-						core_id_contig,
-						ht_id);
-
-					map->map[pos] = lcore_id;
-					ht_id++;
-					n_detected--;
-				}
-			}
-
-			if (ht_id) {
-				core_id_contig++;
-				if (core_id_contig ==
-					map->n_max_cores_per_socket)
-					return -1;
-			}
-		}
-	}
-
-	return 0;
-}
-
-void
-cpu_core_map_print(struct cpu_core_map *map)
-{
-	uint32_t socket_id, core_id, ht_id;
-
-	if (map == NULL)
-		return;
-
-	for (socket_id = 0; socket_id < map->n_sockets; socket_id++) {
-		printf("Socket %" PRIu32 ":\n", socket_id);
-
-		for (core_id = 0;
-			core_id < map->n_cores_per_socket;
-			core_id++) {
-			printf("[%" PRIu32 "] = [", core_id);
-
-			for (ht_id = 0; ht_id < map->n_ht_per_core; ht_id++) {
-				int lcore_id = cpu_core_map_get_lcore_id(map,
-					socket_id,
-					core_id,
-					ht_id);
-
-				uint32_t core_id_noncontig =
-					cpu_core_map_get_core_id_linux(
-						lcore_id);
-
-				printf(" %" PRId32 " (%" PRIu32 ") ",
-					lcore_id,
-					core_id_noncontig);
-			}
-
-			printf("]\n");
-		}
-	}
-}
-
-uint32_t
-cpu_core_map_get_n_sockets(struct cpu_core_map *map)
-{
-	if (map == NULL)
-		return 0;
-
-	return map->n_sockets;
-}
-
-uint32_t
-cpu_core_map_get_n_cores_per_socket(struct cpu_core_map *map)
-{
-	if (map == NULL)
-		return 0;
-
-	return map->n_cores_per_socket;
-}
-
-uint32_t
-cpu_core_map_get_n_ht_per_core(struct cpu_core_map *map)
-{
-	if (map == NULL)
-		return 0;
-
-	return map->n_ht_per_core;
-}
-
-int
-cpu_core_map_get_lcore_id(struct cpu_core_map *map,
-	uint32_t socket_id,
-	uint32_t core_id,
-	uint32_t ht_id)
-{
-	uint32_t pos;
-
-	if ((map == NULL) ||
-		(socket_id >= map->n_sockets) ||
-		(core_id >= map->n_cores_per_socket) ||
-		(ht_id >= map->n_ht_per_core))
-		return -1;
-
-	pos = cpu_core_map_pos(map, socket_id, core_id, ht_id);
-
-	return map->map[pos];
-}
-
-void
-cpu_core_map_free(struct cpu_core_map *map)
-{
-	free(map);
-}
diff --git a/examples/ip_pipeline/cpu_core_map.h b/examples/ip_pipeline/cpu_core_map.h
deleted file mode 100644
index 5e50f6e..0000000
--- a/examples/ip_pipeline/cpu_core_map.h
+++ /dev/null
@@ -1,40 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#ifndef __INCLUDE_CPU_CORE_MAP_H__
-#define __INCLUDE_CPU_CORE_MAP_H__
-
-#include <stdio.h>
-
-#include <rte_lcore.h>
-
-struct cpu_core_map;
-
-struct cpu_core_map *
-cpu_core_map_init(uint32_t n_max_sockets,
-	uint32_t n_max_cores_per_socket,
-	uint32_t n_max_ht_per_core,
-	uint32_t eal_initialized);
-
-uint32_t
-cpu_core_map_get_n_sockets(struct cpu_core_map *map);
-
-uint32_t
-cpu_core_map_get_n_cores_per_socket(struct cpu_core_map *map);
-
-uint32_t
-cpu_core_map_get_n_ht_per_core(struct cpu_core_map *map);
-
-int
-cpu_core_map_get_lcore_id(struct cpu_core_map *map,
-	uint32_t socket_id,
-	uint32_t core_id,
-	uint32_t ht_id);
-
-void cpu_core_map_print(struct cpu_core_map *map);
-
-void
-cpu_core_map_free(struct cpu_core_map *map);
-
-#endif
diff --git a/examples/ip_pipeline/init.c b/examples/ip_pipeline/init.c
deleted file mode 100644
index bb07efa..0000000
--- a/examples/ip_pipeline/init.c
+++ /dev/null
@@ -1,1927 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#include <inttypes.h>
-#include <stdio.h>
-#include <string.h>
-#include <netinet/in.h>
-#ifdef RTE_EXEC_ENV_LINUXAPP
-#include <linux/if.h>
-#include <linux/if_tun.h>
-#endif
-#include <fcntl.h>
-#include <sys/ioctl.h>
-#include <unistd.h>
-
-#include <rte_cycles.h>
-#include <rte_ethdev.h>
-#include <rte_ether.h>
-#include <rte_ip.h>
-#include <rte_eal.h>
-#include <rte_malloc.h>
-#include <rte_bus_pci.h>
-
-#include "app.h"
-#include "pipeline.h"
-#include "pipeline_common_fe.h"
-#include "pipeline_master.h"
-#include "pipeline_passthrough.h"
-#include "pipeline_firewall.h"
-#include "pipeline_flow_classification.h"
-#include "pipeline_flow_actions.h"
-#include "pipeline_routing.h"
-#include "thread_fe.h"
-
-#define APP_NAME_SIZE	32
-
-#define APP_RETA_SIZE_MAX     (ETH_RSS_RETA_SIZE_512 / RTE_RETA_GROUP_SIZE)
-
-static void
-app_init_core_map(struct app_params *app)
-{
-	APP_LOG(app, HIGH, "Initializing CPU core map ...");
-	app->core_map = cpu_core_map_init(RTE_MAX_NUMA_NODES, RTE_MAX_LCORE,
-				4, 0);
-
-	if (app->core_map == NULL)
-		rte_panic("Cannot create CPU core map\n");
-
-	if (app->log_level >= APP_LOG_LEVEL_LOW)
-		cpu_core_map_print(app->core_map);
-}
-
-/* Core Mask String in Hex Representation */
-#define APP_CORE_MASK_STRING_SIZE ((64 * APP_CORE_MASK_SIZE) / 8 * 2 + 1)
-
-static void
-app_init_core_mask(struct app_params *app)
-{
-	uint32_t i;
-	char core_mask_str[APP_CORE_MASK_STRING_SIZE];
-
-	for (i = 0; i < app->n_pipelines; i++) {
-		struct app_pipeline_params *p = &app->pipeline_params[i];
-		int lcore_id;
-
-		lcore_id = cpu_core_map_get_lcore_id(app->core_map,
-			p->socket_id,
-			p->core_id,
-			p->hyper_th_id);
-
-		if (lcore_id < 0)
-			rte_panic("Cannot create CPU core mask\n");
-
-		app_core_enable_in_core_mask(app, lcore_id);
-	}
-
-	app_core_build_core_mask_string(app, core_mask_str);
-	APP_LOG(app, HIGH, "CPU core mask = 0x%s", core_mask_str);
-}
-
-static void
-app_init_eal(struct app_params *app)
-{
-	char buffer[256];
-	char core_mask_str[APP_CORE_MASK_STRING_SIZE];
-	struct app_eal_params *p = &app->eal_params;
-	uint32_t n_args = 0;
-	uint32_t i;
-	int status;
-
-	app->eal_argv[n_args++] = strdup(app->app_name);
-
-	app_core_build_core_mask_string(app, core_mask_str);
-	snprintf(buffer, sizeof(buffer), "-c%s", core_mask_str);
-	app->eal_argv[n_args++] = strdup(buffer);
-
-	if (p->coremap) {
-		snprintf(buffer, sizeof(buffer), "--lcores=%s", p->coremap);
-		app->eal_argv[n_args++] = strdup(buffer);
-	}
-
-	if (p->master_lcore_present) {
-		snprintf(buffer,
-			sizeof(buffer),
-			"--master-lcore=%" PRIu32,
-			p->master_lcore);
-		app->eal_argv[n_args++] = strdup(buffer);
-	}
-
-	snprintf(buffer, sizeof(buffer), "-n%" PRIu32, p->channels);
-	app->eal_argv[n_args++] = strdup(buffer);
-
-	if (p->memory_present) {
-		snprintf(buffer, sizeof(buffer), "-m%" PRIu32, p->memory);
-		app->eal_argv[n_args++] = strdup(buffer);
-	}
-
-	if (p->ranks_present) {
-		snprintf(buffer, sizeof(buffer), "-r%" PRIu32, p->ranks);
-		app->eal_argv[n_args++] = strdup(buffer);
-	}
-
-	for (i = 0; i < APP_MAX_LINKS; i++) {
-		if (p->pci_blacklist[i] == NULL)
-			break;
-
-		snprintf(buffer,
-			sizeof(buffer),
-			"--pci-blacklist=%s",
-			p->pci_blacklist[i]);
-		app->eal_argv[n_args++] = strdup(buffer);
-	}
-
-	if (app->port_mask != 0)
-		for (i = 0; i < APP_MAX_LINKS; i++) {
-			if (p->pci_whitelist[i] == NULL)
-				break;
-
-			snprintf(buffer,
-				sizeof(buffer),
-				"--pci-whitelist=%s",
-				p->pci_whitelist[i]);
-			app->eal_argv[n_args++] = strdup(buffer);
-		}
-	else
-		for (i = 0; i < app->n_links; i++) {
-			char *pci_bdf = app->link_params[i].pci_bdf;
-
-			snprintf(buffer,
-				sizeof(buffer),
-				"--pci-whitelist=%s",
-				pci_bdf);
-			app->eal_argv[n_args++] = strdup(buffer);
-		}
-
-	for (i = 0; i < APP_MAX_LINKS; i++) {
-		if (p->vdev[i] == NULL)
-			break;
-
-		snprintf(buffer,
-			sizeof(buffer),
-			"--vdev=%s",
-			p->vdev[i]);
-		app->eal_argv[n_args++] = strdup(buffer);
-	}
-
-	if ((p->vmware_tsc_map_present) && p->vmware_tsc_map) {
-		snprintf(buffer, sizeof(buffer), "--vmware-tsc-map");
-		app->eal_argv[n_args++] = strdup(buffer);
-	}
-
-	if (p->proc_type) {
-		snprintf(buffer,
-			sizeof(buffer),
-			"--proc-type=%s",
-			p->proc_type);
-		app->eal_argv[n_args++] = strdup(buffer);
-	}
-
-	if (p->syslog) {
-		snprintf(buffer, sizeof(buffer), "--syslog=%s", p->syslog);
-		app->eal_argv[n_args++] = strdup(buffer);
-	}
-
-	if (p->log_level_present) {
-		snprintf(buffer,
-			sizeof(buffer),
-			"--log-level=%" PRIu32,
-			p->log_level);
-		app->eal_argv[n_args++] = strdup(buffer);
-	}
-
-	if ((p->version_present) && p->version) {
-		snprintf(buffer, sizeof(buffer), "-v");
-		app->eal_argv[n_args++] = strdup(buffer);
-	}
-
-	if ((p->help_present) && p->help) {
-		snprintf(buffer, sizeof(buffer), "--help");
-		app->eal_argv[n_args++] = strdup(buffer);
-	}
-
-	if ((p->no_huge_present) && p->no_huge) {
-		snprintf(buffer, sizeof(buffer), "--no-huge");
-		app->eal_argv[n_args++] = strdup(buffer);
-	}
-
-	if ((p->no_pci_present) && p->no_pci) {
-		snprintf(buffer, sizeof(buffer), "--no-pci");
-		app->eal_argv[n_args++] = strdup(buffer);
-	}
-
-	if ((p->no_hpet_present) && p->no_hpet) {
-		snprintf(buffer, sizeof(buffer), "--no-hpet");
-		app->eal_argv[n_args++] = strdup(buffer);
-	}
-
-	if ((p->no_shconf_present) && p->no_shconf) {
-		snprintf(buffer, sizeof(buffer), "--no-shconf");
-		app->eal_argv[n_args++] = strdup(buffer);
-	}
-
-	if (p->add_driver) {
-		snprintf(buffer, sizeof(buffer), "-d%s", p->add_driver);
-		app->eal_argv[n_args++] = strdup(buffer);
-	}
-
-	if (p->socket_mem) {
-		snprintf(buffer,
-			sizeof(buffer),
-			"--socket-mem=%s",
-			p->socket_mem);
-		app->eal_argv[n_args++] = strdup(buffer);
-	}
-
-	if (p->huge_dir) {
-		snprintf(buffer, sizeof(buffer), "--huge-dir=%s", p->huge_dir);
-		app->eal_argv[n_args++] = strdup(buffer);
-	}
-
-	if (p->file_prefix) {
-		snprintf(buffer,
-			sizeof(buffer),
-			"--file-prefix=%s",
-			p->file_prefix);
-		app->eal_argv[n_args++] = strdup(buffer);
-	}
-
-	if (p->base_virtaddr) {
-		snprintf(buffer,
-			sizeof(buffer),
-			"--base-virtaddr=%s",
-			p->base_virtaddr);
-		app->eal_argv[n_args++] = strdup(buffer);
-	}
-
-	if ((p->create_uio_dev_present) && p->create_uio_dev) {
-		snprintf(buffer, sizeof(buffer), "--create-uio-dev");
-		app->eal_argv[n_args++] = strdup(buffer);
-	}
-
-	if (p->vfio_intr) {
-		snprintf(buffer,
-			sizeof(buffer),
-			"--vfio-intr=%s",
-			p->vfio_intr);
-		app->eal_argv[n_args++] = strdup(buffer);
-	}
-
-	snprintf(buffer, sizeof(buffer), "--");
-	app->eal_argv[n_args++] = strdup(buffer);
-
-	app->eal_argc = n_args;
-
-	APP_LOG(app, HIGH, "Initializing EAL ...");
-	if (app->log_level >= APP_LOG_LEVEL_LOW) {
-		int i;
-
-		fprintf(stdout, "[APP] EAL arguments: \"");
-		for (i = 1; i < app->eal_argc; i++)
-			fprintf(stdout, "%s ", app->eal_argv[i]);
-		fprintf(stdout, "\"\n");
-	}
-
-	status = rte_eal_init(app->eal_argc, app->eal_argv);
-	if (status < 0)
-		rte_panic("EAL init error\n");
-}
-
-static void
-app_init_mempool(struct app_params *app)
-{
-	uint32_t i;
-
-	for (i = 0; i < app->n_mempools; i++) {
-		struct app_mempool_params *p = &app->mempool_params[i];
-
-		APP_LOG(app, HIGH, "Initializing %s ...", p->name);
-		app->mempool[i] = rte_pktmbuf_pool_create(
-			p->name,
-			p->pool_size,
-			p->cache_size,
-			0, /* priv_size */
-			p->buffer_size -
-				sizeof(struct rte_mbuf), /* mbuf data size */
-			p->cpu_socket_id);
-
-		if (app->mempool[i] == NULL)
-			rte_panic("%s init error\n", p->name);
-	}
-}
-
-static inline int
-app_link_filter_arp_add(struct app_link_params *link)
-{
-	struct rte_eth_ethertype_filter filter = {
-		.ether_type = ETHER_TYPE_ARP,
-		.flags = 0,
-		.queue = link->arp_q,
-	};
-
-	return rte_eth_dev_filter_ctrl(link->pmd_id,
-		RTE_ETH_FILTER_ETHERTYPE,
-		RTE_ETH_FILTER_ADD,
-		&filter);
-}
-
-static inline int
-app_link_filter_tcp_syn_add(struct app_link_params *link)
-{
-	struct rte_eth_syn_filter filter = {
-		.hig_pri = 1,
-		.queue = link->tcp_syn_q,
-	};
-
-	return rte_eth_dev_filter_ctrl(link->pmd_id,
-		RTE_ETH_FILTER_SYN,
-		RTE_ETH_FILTER_ADD,
-		&filter);
-}
-
-static inline int
-app_link_filter_ip_add(struct app_link_params *l1, struct app_link_params *l2)
-{
-	struct rte_eth_ntuple_filter filter = {
-		.flags = RTE_5TUPLE_FLAGS,
-		.dst_ip = rte_bswap32(l2->ip),
-		.dst_ip_mask = UINT32_MAX, /* Enable */
-		.src_ip = 0,
-		.src_ip_mask = 0, /* Disable */
-		.dst_port = 0,
-		.dst_port_mask = 0, /* Disable */
-		.src_port = 0,
-		.src_port_mask = 0, /* Disable */
-		.proto = 0,
-		.proto_mask = 0, /* Disable */
-		.tcp_flags = 0,
-		.priority = 1, /* Lowest */
-		.queue = l1->ip_local_q,
-	};
-
-	return rte_eth_dev_filter_ctrl(l1->pmd_id,
-		RTE_ETH_FILTER_NTUPLE,
-		RTE_ETH_FILTER_ADD,
-		&filter);
-}
-
-static inline int
-app_link_filter_ip_del(struct app_link_params *l1, struct app_link_params *l2)
-{
-	struct rte_eth_ntuple_filter filter = {
-		.flags = RTE_5TUPLE_FLAGS,
-		.dst_ip = rte_bswap32(l2->ip),
-		.dst_ip_mask = UINT32_MAX, /* Enable */
-		.src_ip = 0,
-		.src_ip_mask = 0, /* Disable */
-		.dst_port = 0,
-		.dst_port_mask = 0, /* Disable */
-		.src_port = 0,
-		.src_port_mask = 0, /* Disable */
-		.proto = 0,
-		.proto_mask = 0, /* Disable */
-		.tcp_flags = 0,
-		.priority = 1, /* Lowest */
-		.queue = l1->ip_local_q,
-	};
-
-	return rte_eth_dev_filter_ctrl(l1->pmd_id,
-		RTE_ETH_FILTER_NTUPLE,
-		RTE_ETH_FILTER_DELETE,
-		&filter);
-}
-
-static inline int
-app_link_filter_tcp_add(struct app_link_params *l1, struct app_link_params *l2)
-{
-	struct rte_eth_ntuple_filter filter = {
-		.flags = RTE_5TUPLE_FLAGS,
-		.dst_ip = rte_bswap32(l2->ip),
-		.dst_ip_mask = UINT32_MAX, /* Enable */
-		.src_ip = 0,
-		.src_ip_mask = 0, /* Disable */
-		.dst_port = 0,
-		.dst_port_mask = 0, /* Disable */
-		.src_port = 0,
-		.src_port_mask = 0, /* Disable */
-		.proto = IPPROTO_TCP,
-		.proto_mask = UINT8_MAX, /* Enable */
-		.tcp_flags = 0,
-		.priority = 2, /* Higher priority than IP */
-		.queue = l1->tcp_local_q,
-	};
-
-	return rte_eth_dev_filter_ctrl(l1->pmd_id,
-		RTE_ETH_FILTER_NTUPLE,
-		RTE_ETH_FILTER_ADD,
-		&filter);
-}
-
-static inline int
-app_link_filter_tcp_del(struct app_link_params *l1, struct app_link_params *l2)
-{
-	struct rte_eth_ntuple_filter filter = {
-		.flags = RTE_5TUPLE_FLAGS,
-		.dst_ip = rte_bswap32(l2->ip),
-		.dst_ip_mask = UINT32_MAX, /* Enable */
-		.src_ip = 0,
-		.src_ip_mask = 0, /* Disable */
-		.dst_port = 0,
-		.dst_port_mask = 0, /* Disable */
-		.src_port = 0,
-		.src_port_mask = 0, /* Disable */
-		.proto = IPPROTO_TCP,
-		.proto_mask = UINT8_MAX, /* Enable */
-		.tcp_flags = 0,
-		.priority = 2, /* Higher priority than IP */
-		.queue = l1->tcp_local_q,
-	};
-
-	return rte_eth_dev_filter_ctrl(l1->pmd_id,
-		RTE_ETH_FILTER_NTUPLE,
-		RTE_ETH_FILTER_DELETE,
-		&filter);
-}
-
-static inline int
-app_link_filter_udp_add(struct app_link_params *l1, struct app_link_params *l2)
-{
-	struct rte_eth_ntuple_filter filter = {
-		.flags = RTE_5TUPLE_FLAGS,
-		.dst_ip = rte_bswap32(l2->ip),
-		.dst_ip_mask = UINT32_MAX, /* Enable */
-		.src_ip = 0,
-		.src_ip_mask = 0, /* Disable */
-		.dst_port = 0,
-		.dst_port_mask = 0, /* Disable */
-		.src_port = 0,
-		.src_port_mask = 0, /* Disable */
-		.proto = IPPROTO_UDP,
-		.proto_mask = UINT8_MAX, /* Enable */
-		.tcp_flags = 0,
-		.priority = 2, /* Higher priority than IP */
-		.queue = l1->udp_local_q,
-	};
-
-	return rte_eth_dev_filter_ctrl(l1->pmd_id,
-		RTE_ETH_FILTER_NTUPLE,
-		RTE_ETH_FILTER_ADD,
-		&filter);
-}
-
-static inline int
-app_link_filter_udp_del(struct app_link_params *l1, struct app_link_params *l2)
-{
-	struct rte_eth_ntuple_filter filter = {
-		.flags = RTE_5TUPLE_FLAGS,
-		.dst_ip = rte_bswap32(l2->ip),
-		.dst_ip_mask = UINT32_MAX, /* Enable */
-		.src_ip = 0,
-		.src_ip_mask = 0, /* Disable */
-		.dst_port = 0,
-		.dst_port_mask = 0, /* Disable */
-		.src_port = 0,
-		.src_port_mask = 0, /* Disable */
-		.proto = IPPROTO_UDP,
-		.proto_mask = UINT8_MAX, /* Enable */
-		.tcp_flags = 0,
-		.priority = 2, /* Higher priority than IP */
-		.queue = l1->udp_local_q,
-	};
-
-	return rte_eth_dev_filter_ctrl(l1->pmd_id,
-		RTE_ETH_FILTER_NTUPLE,
-		RTE_ETH_FILTER_DELETE,
-		&filter);
-}
-
-static inline int
-app_link_filter_sctp_add(struct app_link_params *l1, struct app_link_params *l2)
-{
-	struct rte_eth_ntuple_filter filter = {
-		.flags = RTE_5TUPLE_FLAGS,
-		.dst_ip = rte_bswap32(l2->ip),
-		.dst_ip_mask = UINT32_MAX, /* Enable */
-		.src_ip = 0,
-		.src_ip_mask = 0, /* Disable */
-		.dst_port = 0,
-		.dst_port_mask = 0, /* Disable */
-		.src_port = 0,
-		.src_port_mask = 0, /* Disable */
-		.proto = IPPROTO_SCTP,
-		.proto_mask = UINT8_MAX, /* Enable */
-		.tcp_flags = 0,
-		.priority = 2, /* Higher priority than IP */
-		.queue = l1->sctp_local_q,
-	};
-
-	return rte_eth_dev_filter_ctrl(l1->pmd_id,
-		RTE_ETH_FILTER_NTUPLE,
-		RTE_ETH_FILTER_ADD,
-		&filter);
-}
-
-static inline int
-app_link_filter_sctp_del(struct app_link_params *l1, struct app_link_params *l2)
-{
-	struct rte_eth_ntuple_filter filter = {
-		.flags = RTE_5TUPLE_FLAGS,
-		.dst_ip = rte_bswap32(l2->ip),
-		.dst_ip_mask = UINT32_MAX, /* Enable */
-		.src_ip = 0,
-		.src_ip_mask = 0, /* Disable */
-		.dst_port = 0,
-		.dst_port_mask = 0, /* Disable */
-		.src_port = 0,
-		.src_port_mask = 0, /* Disable */
-		.proto = IPPROTO_SCTP,
-		.proto_mask = UINT8_MAX, /* Enable */
-		.tcp_flags = 0,
-		.priority = 2, /* Higher priority than IP */
-		.queue = l1->sctp_local_q,
-	};
-
-	return rte_eth_dev_filter_ctrl(l1->pmd_id,
-		RTE_ETH_FILTER_NTUPLE,
-		RTE_ETH_FILTER_DELETE,
-		&filter);
-}
-
-static void
-app_link_set_arp_filter(struct app_params *app, struct app_link_params *cp)
-{
-	if (cp->arp_q != 0) {
-		int status = app_link_filter_arp_add(cp);
-
-		APP_LOG(app, LOW, "%s (%" PRIu32 "): "
-			"Adding ARP filter (queue = %" PRIu32 ")",
-			cp->name, cp->pmd_id, cp->arp_q);
-
-		if (status)
-			rte_panic("%s (%" PRIu32 "): "
-				"Error adding ARP filter "
-				"(queue = %" PRIu32 ") (%" PRId32 ")\n",
-				cp->name, cp->pmd_id, cp->arp_q, status);
-	}
-}
-
-static void
-app_link_set_tcp_syn_filter(struct app_params *app, struct app_link_params *cp)
-{
-	if (cp->tcp_syn_q != 0) {
-		int status = app_link_filter_tcp_syn_add(cp);
-
-		APP_LOG(app, LOW, "%s (%" PRIu32 "): "
-			"Adding TCP SYN filter (queue = %" PRIu32 ")",
-			cp->name, cp->pmd_id, cp->tcp_syn_q);
-
-		if (status)
-			rte_panic("%s (%" PRIu32 "): "
-				"Error adding TCP SYN filter "
-				"(queue = %" PRIu32 ") (%" PRId32 ")\n",
-				cp->name, cp->pmd_id, cp->tcp_syn_q,
-				status);
-	}
-}
-
-void
-app_link_up_internal(struct app_params *app, struct app_link_params *cp)
-{
-	uint32_t i;
-	int status;
-
-	/* For each link, add filters for IP of current link */
-	if (cp->ip != 0) {
-		for (i = 0; i < app->n_links; i++) {
-			struct app_link_params *p = &app->link_params[i];
-
-			/* IP */
-			if (p->ip_local_q != 0) {
-				int status = app_link_filter_ip_add(p, cp);
-
-				APP_LOG(app, LOW, "%s (%" PRIu32 "): "
-					"Adding IP filter (queue= %" PRIu32
-					", IP = 0x%08" PRIx32 ")",
-					p->name, p->pmd_id, p->ip_local_q,
-					cp->ip);
-
-				if (status)
-					rte_panic("%s (%" PRIu32 "): "
-						"Error adding IP "
-						"filter (queue= %" PRIu32 ", "
-						"IP = 0x%08" PRIx32
-						") (%" PRId32 ")\n",
-						p->name, p->pmd_id,
-						p->ip_local_q, cp->ip, status);
-			}
-
-			/* TCP */
-			if (p->tcp_local_q != 0) {
-				int status = app_link_filter_tcp_add(p, cp);
-
-				APP_LOG(app, LOW, "%s (%" PRIu32 "): "
-					"Adding TCP filter "
-					"(queue = %" PRIu32
-					", IP = 0x%08" PRIx32 ")",
-					p->name, p->pmd_id, p->tcp_local_q,
-					cp->ip);
-
-				if (status)
-					rte_panic("%s (%" PRIu32 "): "
-						"Error adding TCP "
-						"filter (queue = %" PRIu32 ", "
-						"IP = 0x%08" PRIx32
-						") (%" PRId32 ")\n",
-						p->name, p->pmd_id,
-						p->tcp_local_q, cp->ip, status);
-			}
-
-			/* UDP */
-			if (p->udp_local_q != 0) {
-				int status = app_link_filter_udp_add(p, cp);
-
-				APP_LOG(app, LOW, "%s (%" PRIu32 "): "
-					"Adding UDP filter "
-					"(queue = %" PRIu32
-					", IP = 0x%08" PRIx32 ")",
-					p->name, p->pmd_id, p->udp_local_q,
-					cp->ip);
-
-				if (status)
-					rte_panic("%s (%" PRIu32 "): "
-						"Error adding UDP "
-						"filter (queue = %" PRIu32 ", "
-						"IP = 0x%08" PRIx32
-						") (%" PRId32 ")\n",
-						p->name, p->pmd_id,
-						p->udp_local_q, cp->ip, status);
-			}
-
-			/* SCTP */
-			if (p->sctp_local_q != 0) {
-				int status = app_link_filter_sctp_add(p, cp);
-
-				APP_LOG(app, LOW, "%s (%" PRIu32
-					"): Adding SCTP filter "
-					"(queue = %" PRIu32
-					", IP = 0x%08" PRIx32 ")",
-					p->name, p->pmd_id, p->sctp_local_q,
-					cp->ip);
-
-				if (status)
-					rte_panic("%s (%" PRIu32 "): "
-						"Error adding SCTP "
-						"filter (queue = %" PRIu32 ", "
-						"IP = 0x%08" PRIx32
-						") (%" PRId32 ")\n",
-						p->name, p->pmd_id,
-						p->sctp_local_q, cp->ip,
-						status);
-			}
-		}
-	}
-
-	/* PMD link up */
-	status = rte_eth_dev_set_link_up(cp->pmd_id);
-	/* Do not panic if PMD does not provide link up functionality */
-	if (status < 0 && status != -ENOTSUP)
-		rte_panic("%s (%" PRIu32 "): PMD set link up error %"
-			PRId32 "\n", cp->name, cp->pmd_id, status);
-
-	/* Mark link as UP */
-	cp->state = 1;
-}
-
-void
-app_link_down_internal(struct app_params *app, struct app_link_params *cp)
-{
-	uint32_t i;
-	int status;
-
-	/* PMD link down */
-	status = rte_eth_dev_set_link_down(cp->pmd_id);
-	/* Do not panic if PMD does not provide link down functionality */
-	if (status < 0 && status != -ENOTSUP)
-		rte_panic("%s (%" PRIu32 "): PMD set link down error %"
-			PRId32 "\n", cp->name, cp->pmd_id, status);
-
-	/* Mark link as DOWN */
-	cp->state = 0;
-
-	/* Return if current link IP is not valid */
-	if (cp->ip == 0)
-		return;
-
-	/* For each link, remove filters for IP of current link */
-	for (i = 0; i < app->n_links; i++) {
-		struct app_link_params *p = &app->link_params[i];
-
-		/* IP */
-		if (p->ip_local_q != 0) {
-			int status = app_link_filter_ip_del(p, cp);
-
-			APP_LOG(app, LOW, "%s (%" PRIu32
-				"): Deleting IP filter "
-				"(queue = %" PRIu32 ", IP = 0x%" PRIx32 ")",
-				p->name, p->pmd_id, p->ip_local_q, cp->ip);
-
-			if (status)
-				rte_panic("%s (%" PRIu32
-					"): Error deleting IP filter "
-					"(queue = %" PRIu32
-					", IP = 0x%" PRIx32
-					") (%" PRId32 ")\n",
-					p->name, p->pmd_id, p->ip_local_q,
-					cp->ip, status);
-		}
-
-		/* TCP */
-		if (p->tcp_local_q != 0) {
-			int status = app_link_filter_tcp_del(p, cp);
-
-			APP_LOG(app, LOW, "%s (%" PRIu32
-				"): Deleting TCP filter "
-				"(queue = %" PRIu32
-				", IP = 0x%" PRIx32 ")",
-				p->name, p->pmd_id, p->tcp_local_q, cp->ip);
-
-			if (status)
-				rte_panic("%s (%" PRIu32
-					"): Error deleting TCP filter "
-					"(queue = %" PRIu32
-					", IP = 0x%" PRIx32
-					") (%" PRId32 ")\n",
-					p->name, p->pmd_id, p->tcp_local_q,
-					cp->ip, status);
-		}
-
-		/* UDP */
-		if (p->udp_local_q != 0) {
-			int status = app_link_filter_udp_del(p, cp);
-
-			APP_LOG(app, LOW, "%s (%" PRIu32
-				"): Deleting UDP filter "
-				"(queue = %" PRIu32 ", IP = 0x%" PRIx32 ")",
-				p->name, p->pmd_id, p->udp_local_q, cp->ip);
-
-			if (status)
-				rte_panic("%s (%" PRIu32
-					"): Error deleting UDP filter "
-					"(queue = %" PRIu32
-					", IP = 0x%" PRIx32
-					") (%" PRId32 ")\n",
-					p->name, p->pmd_id, p->udp_local_q,
-					cp->ip, status);
-		}
-
-		/* SCTP */
-		if (p->sctp_local_q != 0) {
-			int status = app_link_filter_sctp_del(p, cp);
-
-			APP_LOG(app, LOW, "%s (%" PRIu32
-				"): Deleting SCTP filter "
-				"(queue = %" PRIu32
-				", IP = 0x%" PRIx32 ")",
-				p->name, p->pmd_id, p->sctp_local_q, cp->ip);
-
-			if (status)
-				rte_panic("%s (%" PRIu32
-					"): Error deleting SCTP filter "
-					"(queue = %" PRIu32
-					", IP = 0x%" PRIx32
-					") (%" PRId32 ")\n",
-					p->name, p->pmd_id, p->sctp_local_q,
-					cp->ip, status);
-		}
-	}
-}
-
-static void
-app_check_link(struct app_params *app)
-{
-	uint32_t all_links_up, i;
-
-	all_links_up = 1;
-
-	for (i = 0; i < app->n_links; i++) {
-		struct app_link_params *p = &app->link_params[i];
-		struct rte_eth_link link_params;
-
-		memset(&link_params, 0, sizeof(link_params));
-		rte_eth_link_get(p->pmd_id, &link_params);
-
-		APP_LOG(app, HIGH, "%s (%" PRIu32 ") (%" PRIu32 " Gbps) %s",
-			p->name,
-			p->pmd_id,
-			link_params.link_speed / 1000,
-			link_params.link_status ? "UP" : "DOWN");
-
-		if (link_params.link_status == ETH_LINK_DOWN)
-			all_links_up = 0;
-	}
-
-	if (all_links_up == 0)
-		rte_panic("Some links are DOWN\n");
-}
-
-static uint32_t
-is_any_swq_frag_or_ras(struct app_params *app)
-{
-	uint32_t i;
-
-	for (i = 0; i < app->n_pktq_swq; i++) {
-		struct app_pktq_swq_params *p = &app->swq_params[i];
-
-		if ((p->ipv4_frag == 1) || (p->ipv6_frag == 1) ||
-			(p->ipv4_ras == 1) || (p->ipv6_ras == 1))
-			return 1;
-	}
-
-	return 0;
-}
-
-static void
-app_init_link_frag_ras(struct app_params *app)
-{
-	uint32_t i;
-
-	if (is_any_swq_frag_or_ras(app)) {
-		for (i = 0; i < app->n_links; i++) {
-			struct app_link_params *p_link = &app->link_params[i];
-				p_link->conf.txmode.offloads |=
-						DEV_TX_OFFLOAD_MULTI_SEGS;
-		}
-	}
-}
-
-static inline int
-app_get_cpu_socket_id(uint32_t pmd_id)
-{
-	int status = rte_eth_dev_socket_id(pmd_id);
-
-	return (status != SOCKET_ID_ANY) ? status : 0;
-}
-
-static inline int
-app_link_rss_enabled(struct app_link_params *cp)
-{
-	return (cp->n_rss_qs) ? 1 : 0;
-}
-
-static void
-app_link_rss_setup(struct app_link_params *cp)
-{
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_rss_reta_entry64 reta_conf[APP_RETA_SIZE_MAX];
-	uint32_t i;
-	int status;
-
-    /* Get RETA size */
-	memset(&dev_info, 0, sizeof(dev_info));
-	rte_eth_dev_info_get(cp->pmd_id, &dev_info);
-
-	if (dev_info.reta_size == 0)
-		rte_panic("%s (%u): RSS setup error (null RETA size)\n",
-			cp->name, cp->pmd_id);
-
-	if (dev_info.reta_size > ETH_RSS_RETA_SIZE_512)
-		rte_panic("%s (%u): RSS setup error (RETA size too big)\n",
-			cp->name, cp->pmd_id);
-
-	/* Setup RETA contents */
-	memset(reta_conf, 0, sizeof(reta_conf));
-
-	for (i = 0; i < dev_info.reta_size; i++)
-		reta_conf[i / RTE_RETA_GROUP_SIZE].mask = UINT64_MAX;
-
-	for (i = 0; i < dev_info.reta_size; i++) {
-		uint32_t reta_id = i / RTE_RETA_GROUP_SIZE;
-		uint32_t reta_pos = i % RTE_RETA_GROUP_SIZE;
-		uint32_t rss_qs_pos = i % cp->n_rss_qs;
-
-		reta_conf[reta_id].reta[reta_pos] =
-			(uint16_t) cp->rss_qs[rss_qs_pos];
-	}
-
-	/* RETA update */
-	status = rte_eth_dev_rss_reta_update(cp->pmd_id,
-		reta_conf,
-		dev_info.reta_size);
-	if (status != 0)
-		rte_panic("%s (%u): RSS setup error (RETA update failed)\n",
-			cp->name, cp->pmd_id);
-}
-
-static void
-app_init_link_set_config(struct app_link_params *p)
-{
-	if (p->n_rss_qs) {
-		p->conf.rxmode.mq_mode = ETH_MQ_RX_RSS;
-		p->conf.rx_adv_conf.rss_conf.rss_hf = p->rss_proto_ipv4 |
-			p->rss_proto_ipv6 |
-			p->rss_proto_l2;
-	}
-}
-
-static void
-app_init_link(struct app_params *app)
-{
-	uint32_t i;
-
-	app_init_link_frag_ras(app);
-
-	for (i = 0; i < app->n_links; i++) {
-		struct app_link_params *p_link = &app->link_params[i];
-		struct rte_eth_dev_info dev_info;
-		uint32_t link_id, n_hwq_in, n_hwq_out, j;
-		int status;
-
-		sscanf(p_link->name, "LINK%" PRIu32, &link_id);
-		n_hwq_in = app_link_get_n_rxq(app, p_link);
-		n_hwq_out = app_link_get_n_txq(app, p_link);
-		app_init_link_set_config(p_link);
-
-		APP_LOG(app, HIGH, "Initializing %s (%" PRIu32") "
-			"(%" PRIu32 " RXQ, %" PRIu32 " TXQ) ...",
-			p_link->name,
-			p_link->pmd_id,
-			n_hwq_in,
-			n_hwq_out);
-
-		/* LINK */
-		rte_eth_dev_info_get(p_link->pmd_id, &dev_info);
-		if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-			p_link->conf.txmode.offloads |=
-				DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-		status = rte_eth_dev_configure(
-			p_link->pmd_id,
-			n_hwq_in,
-			n_hwq_out,
-			&p_link->conf);
-		if (status < 0)
-			rte_panic("%s (%" PRId32 "): "
-				"init error (%" PRId32 ")\n",
-				p_link->name, p_link->pmd_id, status);
-
-		rte_eth_macaddr_get(p_link->pmd_id,
-			(struct ether_addr *) &p_link->mac_addr);
-
-		if (p_link->promisc)
-			rte_eth_promiscuous_enable(p_link->pmd_id);
-
-		/* RXQ */
-		for (j = 0; j < app->n_pktq_hwq_in; j++) {
-			struct app_pktq_hwq_in_params *p_rxq =
-				&app->hwq_in_params[j];
-			uint32_t rxq_link_id, rxq_queue_id;
-			uint16_t nb_rxd = p_rxq->size;
-
-			sscanf(p_rxq->name, "RXQ%" PRIu32 ".%" PRIu32,
-				&rxq_link_id, &rxq_queue_id);
-			if (rxq_link_id != link_id)
-				continue;
-
-			status = rte_eth_dev_adjust_nb_rx_tx_desc(
-				p_link->pmd_id,
-				&nb_rxd,
-				NULL);
-			if (status < 0)
-				rte_panic("%s (%" PRIu32 "): "
-					"%s adjust number of Rx descriptors "
-					"error (%" PRId32 ")\n",
-					p_link->name,
-					p_link->pmd_id,
-					p_rxq->name,
-					status);
-
-			p_rxq->conf.offloads = p_link->conf.rxmode.offloads;
-			status = rte_eth_rx_queue_setup(
-				p_link->pmd_id,
-				rxq_queue_id,
-				nb_rxd,
-				app_get_cpu_socket_id(p_link->pmd_id),
-				&p_rxq->conf,
-				app->mempool[p_rxq->mempool_id]);
-			if (status < 0)
-				rte_panic("%s (%" PRIu32 "): "
-					"%s init error (%" PRId32 ")\n",
-					p_link->name,
-					p_link->pmd_id,
-					p_rxq->name,
-					status);
-		}
-
-		/* TXQ */
-		for (j = 0; j < app->n_pktq_hwq_out; j++) {
-			struct app_pktq_hwq_out_params *p_txq =
-				&app->hwq_out_params[j];
-			uint32_t txq_link_id, txq_queue_id;
-			uint16_t nb_txd = p_txq->size;
-
-			sscanf(p_txq->name, "TXQ%" PRIu32 ".%" PRIu32,
-				&txq_link_id, &txq_queue_id);
-			if (txq_link_id != link_id)
-				continue;
-
-			status = rte_eth_dev_adjust_nb_rx_tx_desc(
-				p_link->pmd_id,
-				NULL,
-				&nb_txd);
-			if (status < 0)
-				rte_panic("%s (%" PRIu32 "): "
-					"%s adjust number of Tx descriptors "
-					"error (%" PRId32 ")\n",
-					p_link->name,
-					p_link->pmd_id,
-					p_txq->name,
-					status);
-
-			p_txq->conf.offloads = p_link->conf.txmode.offloads;
-			status = rte_eth_tx_queue_setup(
-				p_link->pmd_id,
-				txq_queue_id,
-				nb_txd,
-				app_get_cpu_socket_id(p_link->pmd_id),
-				&p_txq->conf);
-			if (status < 0)
-				rte_panic("%s (%" PRIu32 "): "
-					"%s init error (%" PRId32 ")\n",
-					p_link->name,
-					p_link->pmd_id,
-					p_txq->name,
-					status);
-		}
-
-		/* LINK START */
-		status = rte_eth_dev_start(p_link->pmd_id);
-		if (status < 0)
-			rte_panic("Cannot start %s (error %" PRId32 ")\n",
-				p_link->name, status);
-
-		/* LINK FILTERS */
-		app_link_set_arp_filter(app, p_link);
-		app_link_set_tcp_syn_filter(app, p_link);
-		if (app_link_rss_enabled(p_link))
-			app_link_rss_setup(p_link);
-
-		/* LINK UP */
-		app_link_up_internal(app, p_link);
-	}
-
-	app_check_link(app);
-}
-
-static void
-app_init_swq(struct app_params *app)
-{
-	uint32_t i;
-
-	for (i = 0; i < app->n_pktq_swq; i++) {
-		struct app_pktq_swq_params *p = &app->swq_params[i];
-		unsigned flags = 0;
-
-		if (app_swq_get_readers(app, p) == 1)
-			flags |= RING_F_SC_DEQ;
-		if (app_swq_get_writers(app, p) == 1)
-			flags |= RING_F_SP_ENQ;
-
-		APP_LOG(app, HIGH, "Initializing %s...", p->name);
-		app->swq[i] = rte_ring_create(
-				p->name,
-				p->size,
-				p->cpu_socket_id,
-				flags);
-
-		if (app->swq[i] == NULL)
-			rte_panic("%s init error\n", p->name);
-	}
-}
-
-static void
-app_init_tm(struct app_params *app)
-{
-	uint32_t i;
-
-	for (i = 0; i < app->n_pktq_tm; i++) {
-		struct app_pktq_tm_params *p_tm = &app->tm_params[i];
-		struct app_link_params *p_link;
-		struct rte_eth_link link_eth_params;
-		struct rte_sched_port *sched;
-		uint32_t n_subports, subport_id;
-		int status;
-
-		p_link = app_get_link_for_tm(app, p_tm);
-		/* LINK */
-		rte_eth_link_get(p_link->pmd_id, &link_eth_params);
-
-		/* TM */
-		p_tm->sched_port_params.name = p_tm->name;
-		p_tm->sched_port_params.socket =
-			app_get_cpu_socket_id(p_link->pmd_id);
-		p_tm->sched_port_params.rate =
-			(uint64_t) link_eth_params.link_speed * 1000 * 1000 / 8;
-
-		APP_LOG(app, HIGH, "Initializing %s ...", p_tm->name);
-		sched = rte_sched_port_config(&p_tm->sched_port_params);
-		if (sched == NULL)
-			rte_panic("%s init error\n", p_tm->name);
-		app->tm[i] = sched;
-
-		/* Subport */
-		n_subports = p_tm->sched_port_params.n_subports_per_port;
-		for (subport_id = 0; subport_id < n_subports; subport_id++) {
-			uint32_t n_pipes_per_subport, pipe_id;
-
-			status = rte_sched_subport_config(sched,
-				subport_id,
-				&p_tm->sched_subport_params[subport_id]);
-			if (status)
-				rte_panic("%s subport %" PRIu32
-					" init error (%" PRId32 ")\n",
-					p_tm->name, subport_id, status);
-
-			/* Pipe */
-			n_pipes_per_subport =
-				p_tm->sched_port_params.n_pipes_per_subport;
-			for (pipe_id = 0;
-				pipe_id < n_pipes_per_subport;
-				pipe_id++) {
-				int profile_id = p_tm->sched_pipe_to_profile[
-					subport_id * APP_MAX_SCHED_PIPES +
-					pipe_id];
-
-				if (profile_id == -1)
-					continue;
-
-				status = rte_sched_pipe_config(sched,
-					subport_id,
-					pipe_id,
-					profile_id);
-				if (status)
-					rte_panic("%s subport %" PRIu32
-						" pipe %" PRIu32
-						" (profile %" PRId32 ") "
-						"init error (% " PRId32 ")\n",
-						p_tm->name, subport_id, pipe_id,
-						profile_id, status);
-			}
-		}
-	}
-}
-
-#ifndef RTE_EXEC_ENV_LINUXAPP
-static void
-app_init_tap(struct app_params *app) {
-	if (app->n_pktq_tap == 0)
-		return;
-
-	rte_panic("TAP device not supported.\n");
-}
-#else
-static void
-app_init_tap(struct app_params *app)
-{
-	uint32_t i;
-
-	for (i = 0; i < app->n_pktq_tap; i++) {
-		struct app_pktq_tap_params *p_tap = &app->tap_params[i];
-		struct ifreq ifr;
-		int fd, status;
-
-		APP_LOG(app, HIGH, "Initializing %s ...", p_tap->name);
-
-		fd = open("/dev/net/tun", O_RDWR | O_NONBLOCK);
-		if (fd < 0)
-			rte_panic("Cannot open file /dev/net/tun\n");
-
-		memset(&ifr, 0, sizeof(ifr));
-		ifr.ifr_flags = IFF_TAP | IFF_NO_PI; /* No packet information */
-		snprintf(ifr.ifr_name, IFNAMSIZ, "%s", p_tap->name);
-
-		status = ioctl(fd, TUNSETIFF, (void *) &ifr);
-		if (status < 0)
-			rte_panic("TAP setup error\n");
-
-		app->tap[i] = fd;
-	}
-}
-#endif
-
-#ifdef RTE_LIBRTE_KNI
-static int
-kni_config_network_interface(uint16_t port_id, uint8_t if_up) {
-	int ret = 0;
-
-	if (port_id >= rte_eth_dev_count())
-		return -EINVAL;
-
-	ret = (if_up) ?
-		rte_eth_dev_set_link_up(port_id) :
-		rte_eth_dev_set_link_down(port_id);
-
-	return ret;
-}
-
-static int
-kni_change_mtu(uint16_t port_id, unsigned int new_mtu) {
-	int ret;
-
-	if (port_id >= rte_eth_dev_count())
-		return -EINVAL;
-
-	if (new_mtu > ETHER_MAX_LEN)
-		return -EINVAL;
-
-	/* Set new MTU */
-	ret = rte_eth_dev_set_mtu(port_id, new_mtu);
-	if (ret < 0)
-		return ret;
-
-	return 0;
-}
-#endif /* RTE_LIBRTE_KNI */
-
-#ifndef RTE_LIBRTE_KNI
-static void
-app_init_kni(struct app_params *app) {
-	if (app->n_pktq_kni == 0)
-		return;
-
-	rte_panic("Can not init KNI without librte_kni support.\n");
-}
-#else
-static void
-app_init_kni(struct app_params *app) {
-	uint32_t i;
-
-	if (app->n_pktq_kni == 0)
-		return;
-
-	rte_kni_init(app->n_pktq_kni);
-
-	for (i = 0; i < app->n_pktq_kni; i++) {
-		struct app_pktq_kni_params *p_kni = &app->kni_params[i];
-		struct app_link_params *p_link;
-		struct rte_eth_dev_info dev_info;
-		struct app_mempool_params *mempool_params;
-		struct rte_mempool *mempool;
-		struct rte_kni_conf conf;
-		struct rte_kni_ops ops;
-
-		/* LINK */
-		p_link = app_get_link_for_kni(app, p_kni);
-		memset(&dev_info, 0, sizeof(dev_info));
-		rte_eth_dev_info_get(p_link->pmd_id, &dev_info);
-
-		/* MEMPOOL */
-		mempool_params = &app->mempool_params[p_kni->mempool_id];
-		mempool = app->mempool[p_kni->mempool_id];
-
-		/* KNI */
-		memset(&conf, 0, sizeof(conf));
-		snprintf(conf.name, RTE_KNI_NAMESIZE, "%s", p_kni->name);
-		conf.force_bind = p_kni->force_bind;
-		if (conf.force_bind) {
-			int lcore_id;
-
-			lcore_id = cpu_core_map_get_lcore_id(app->core_map,
-				p_kni->socket_id,
-				p_kni->core_id,
-				p_kni->hyper_th_id);
-
-			if (lcore_id < 0)
-				rte_panic("%s invalid CPU core\n", p_kni->name);
-
-			conf.core_id = (uint32_t) lcore_id;
-		}
-		conf.group_id = p_link->pmd_id;
-		conf.mbuf_size = mempool_params->buffer_size;
-		conf.addr = dev_info.pci_dev->addr;
-		conf.id = dev_info.pci_dev->id;
-
-		memset(&ops, 0, sizeof(ops));
-		ops.port_id = (uint8_t) p_link->pmd_id;
-		ops.change_mtu = kni_change_mtu;
-		ops.config_network_if = kni_config_network_interface;
-
-		APP_LOG(app, HIGH, "Initializing %s ...", p_kni->name);
-		app->kni[i] = rte_kni_alloc(mempool, &conf, &ops);
-		if (!app->kni[i])
-			rte_panic("%s init error\n", p_kni->name);
-	}
-}
-#endif /* RTE_LIBRTE_KNI */
-
-static void
-app_init_msgq(struct app_params *app)
-{
-	uint32_t i;
-
-	for (i = 0; i < app->n_msgq; i++) {
-		struct app_msgq_params *p = &app->msgq_params[i];
-
-		APP_LOG(app, HIGH, "Initializing %s ...", p->name);
-		app->msgq[i] = rte_ring_create(
-				p->name,
-				p->size,
-				p->cpu_socket_id,
-				RING_F_SP_ENQ | RING_F_SC_DEQ);
-
-		if (app->msgq[i] == NULL)
-			rte_panic("%s init error\n", p->name);
-	}
-}
-
-void app_pipeline_params_get(struct app_params *app,
-	struct app_pipeline_params *p_in,
-	struct pipeline_params *p_out)
-{
-	uint32_t i;
-
-	snprintf(p_out->name, PIPELINE_NAME_SIZE, "%s", p_in->name);
-
-	snprintf(p_out->type, PIPELINE_TYPE_SIZE, "%s", p_in->type);
-
-	p_out->socket_id = (int) p_in->socket_id;
-
-	p_out->log_level = app->log_level;
-
-	/* pktq_in */
-	p_out->n_ports_in = p_in->n_pktq_in;
-	for (i = 0; i < p_in->n_pktq_in; i++) {
-		struct app_pktq_in_params *in = &p_in->pktq_in[i];
-		struct pipeline_port_in_params *out = &p_out->port_in[i];
-
-		switch (in->type) {
-		case APP_PKTQ_IN_HWQ:
-		{
-			struct app_pktq_hwq_in_params *p_hwq_in =
-				&app->hwq_in_params[in->id];
-			struct app_link_params *p_link =
-				app_get_link_for_rxq(app, p_hwq_in);
-			uint32_t rxq_link_id, rxq_queue_id;
-
-			sscanf(p_hwq_in->name, "RXQ%" SCNu32 ".%" SCNu32,
-				&rxq_link_id,
-				&rxq_queue_id);
-
-			out->type = PIPELINE_PORT_IN_ETHDEV_READER;
-			out->params.ethdev.port_id = p_link->pmd_id;
-			out->params.ethdev.queue_id = rxq_queue_id;
-			out->burst_size = p_hwq_in->burst;
-			break;
-		}
-		case APP_PKTQ_IN_SWQ:
-		{
-			struct app_pktq_swq_params *swq_params = &app->swq_params[in->id];
-
-			if ((swq_params->ipv4_frag == 0) && (swq_params->ipv6_frag == 0)) {
-				if (app_swq_get_readers(app, swq_params) == 1) {
-					out->type = PIPELINE_PORT_IN_RING_READER;
-					out->params.ring.ring = app->swq[in->id];
-					out->burst_size = app->swq_params[in->id].burst_read;
-				} else {
-					out->type = PIPELINE_PORT_IN_RING_MULTI_READER;
-					out->params.ring_multi.ring = app->swq[in->id];
-					out->burst_size = swq_params->burst_read;
-				}
-			} else {
-				if (swq_params->ipv4_frag == 1) {
-					struct rte_port_ring_reader_ipv4_frag_params *params =
-						&out->params.ring_ipv4_frag;
-
-					out->type = PIPELINE_PORT_IN_RING_READER_IPV4_FRAG;
-					params->ring = app->swq[in->id];
-					params->mtu = swq_params->mtu;
-					params->metadata_size = swq_params->metadata_size;
-					params->pool_direct =
-						app->mempool[swq_params->mempool_direct_id];
-					params->pool_indirect =
-						app->mempool[swq_params->mempool_indirect_id];
-					out->burst_size = swq_params->burst_read;
-				} else {
-					struct rte_port_ring_reader_ipv6_frag_params *params =
-						&out->params.ring_ipv6_frag;
-
-					out->type = PIPELINE_PORT_IN_RING_READER_IPV6_FRAG;
-					params->ring = app->swq[in->id];
-					params->mtu = swq_params->mtu;
-					params->metadata_size = swq_params->metadata_size;
-					params->pool_direct =
-						app->mempool[swq_params->mempool_direct_id];
-					params->pool_indirect =
-						app->mempool[swq_params->mempool_indirect_id];
-					out->burst_size = swq_params->burst_read;
-				}
-			}
-			break;
-		}
-		case APP_PKTQ_IN_TM:
-		{
-			out->type = PIPELINE_PORT_IN_SCHED_READER;
-			out->params.sched.sched = app->tm[in->id];
-			out->burst_size = app->tm_params[in->id].burst_read;
-			break;
-		}
-#ifdef RTE_EXEC_ENV_LINUXAPP
-		case APP_PKTQ_IN_TAP:
-		{
-			struct app_pktq_tap_params *tap_params =
-				&app->tap_params[in->id];
-			struct app_mempool_params *mempool_params =
-				&app->mempool_params[tap_params->mempool_id];
-			struct rte_mempool *mempool =
-				app->mempool[tap_params->mempool_id];
-
-			out->type = PIPELINE_PORT_IN_FD_READER;
-			out->params.fd.fd = app->tap[in->id];
-			out->params.fd.mtu = mempool_params->buffer_size;
-			out->params.fd.mempool = mempool;
-			out->burst_size = app->tap_params[in->id].burst_read;
-			break;
-		}
-#endif
-#ifdef RTE_LIBRTE_KNI
-		case APP_PKTQ_IN_KNI:
-		{
-			out->type = PIPELINE_PORT_IN_KNI_READER;
-			out->params.kni.kni = app->kni[in->id];
-			out->burst_size = app->kni_params[in->id].burst_read;
-			break;
-		}
-#endif /* RTE_LIBRTE_KNI */
-		case APP_PKTQ_IN_SOURCE:
-		{
-			uint32_t mempool_id =
-				app->source_params[in->id].mempool_id;
-
-			out->type = PIPELINE_PORT_IN_SOURCE;
-			out->params.source.mempool = app->mempool[mempool_id];
-			out->burst_size = app->source_params[in->id].burst;
-			out->params.source.file_name =
-				app->source_params[in->id].file_name;
-			out->params.source.n_bytes_per_pkt =
-				app->source_params[in->id].n_bytes_per_pkt;
-			break;
-		}
-		default:
-			break;
-		}
-	}
-
-	/* pktq_out */
-	p_out->n_ports_out = p_in->n_pktq_out;
-	for (i = 0; i < p_in->n_pktq_out; i++) {
-		struct app_pktq_out_params *in = &p_in->pktq_out[i];
-		struct pipeline_port_out_params *out = &p_out->port_out[i];
-
-		switch (in->type) {
-		case APP_PKTQ_OUT_HWQ:
-		{
-			struct app_pktq_hwq_out_params *p_hwq_out =
-				&app->hwq_out_params[in->id];
-			struct app_link_params *p_link =
-				app_get_link_for_txq(app, p_hwq_out);
-			uint32_t txq_link_id, txq_queue_id;
-
-			sscanf(p_hwq_out->name,
-				"TXQ%" SCNu32 ".%" SCNu32,
-				&txq_link_id,
-				&txq_queue_id);
-
-			if (p_hwq_out->dropless == 0) {
-				struct rte_port_ethdev_writer_params *params =
-					&out->params.ethdev;
-
-				out->type = PIPELINE_PORT_OUT_ETHDEV_WRITER;
-				params->port_id = p_link->pmd_id;
-				params->queue_id = txq_queue_id;
-				params->tx_burst_sz =
-					app->hwq_out_params[in->id].burst;
-			} else {
-				struct rte_port_ethdev_writer_nodrop_params
-					*params = &out->params.ethdev_nodrop;
-
-				out->type =
-					PIPELINE_PORT_OUT_ETHDEV_WRITER_NODROP;
-				params->port_id = p_link->pmd_id;
-				params->queue_id = txq_queue_id;
-				params->tx_burst_sz = p_hwq_out->burst;
-				params->n_retries = p_hwq_out->n_retries;
-			}
-			break;
-		}
-		case APP_PKTQ_OUT_SWQ:
-		{
-			struct app_pktq_swq_params *swq_params = &app->swq_params[in->id];
-
-			if ((swq_params->ipv4_ras == 0) && (swq_params->ipv6_ras == 0)) {
-				if (app_swq_get_writers(app, swq_params) == 1) {
-					if (app->swq_params[in->id].dropless == 0) {
-						struct rte_port_ring_writer_params *params =
-							&out->params.ring;
-
-						out->type = PIPELINE_PORT_OUT_RING_WRITER;
-						params->ring = app->swq[in->id];
-						params->tx_burst_sz =
-							app->swq_params[in->id].burst_write;
-					} else {
-						struct rte_port_ring_writer_nodrop_params
-							*params = &out->params.ring_nodrop;
-
-						out->type =
-							PIPELINE_PORT_OUT_RING_WRITER_NODROP;
-						params->ring = app->swq[in->id];
-						params->tx_burst_sz =
-							app->swq_params[in->id].burst_write;
-						params->n_retries =
-							app->swq_params[in->id].n_retries;
-					}
-				} else {
-					if (swq_params->dropless == 0) {
-						struct rte_port_ring_multi_writer_params *params =
-							&out->params.ring_multi;
-
-						out->type = PIPELINE_PORT_OUT_RING_MULTI_WRITER;
-						params->ring = app->swq[in->id];
-						params->tx_burst_sz = swq_params->burst_write;
-					} else {
-						struct rte_port_ring_multi_writer_nodrop_params
-							*params = &out->params.ring_multi_nodrop;
-
-						out->type = PIPELINE_PORT_OUT_RING_MULTI_WRITER_NODROP;
-						params->ring = app->swq[in->id];
-						params->tx_burst_sz = swq_params->burst_write;
-						params->n_retries = swq_params->n_retries;
-					}
-				}
-			} else {
-				if (swq_params->ipv4_ras == 1) {
-					struct rte_port_ring_writer_ipv4_ras_params *params =
-						&out->params.ring_ipv4_ras;
-
-					out->type = PIPELINE_PORT_OUT_RING_WRITER_IPV4_RAS;
-					params->ring = app->swq[in->id];
-					params->tx_burst_sz = swq_params->burst_write;
-				} else {
-					struct rte_port_ring_writer_ipv6_ras_params *params =
-						&out->params.ring_ipv6_ras;
-
-					out->type = PIPELINE_PORT_OUT_RING_WRITER_IPV6_RAS;
-					params->ring = app->swq[in->id];
-					params->tx_burst_sz = swq_params->burst_write;
-				}
-			}
-			break;
-		}
-		case APP_PKTQ_OUT_TM:
-		{
-			struct rte_port_sched_writer_params *params =
-				&out->params.sched;
-
-			out->type = PIPELINE_PORT_OUT_SCHED_WRITER;
-			params->sched = app->tm[in->id];
-			params->tx_burst_sz =
-				app->tm_params[in->id].burst_write;
-			break;
-		}
-#ifdef RTE_EXEC_ENV_LINUXAPP
-		case APP_PKTQ_OUT_TAP:
-		{
-			struct rte_port_fd_writer_params *params =
-				&out->params.fd;
-
-			out->type = PIPELINE_PORT_OUT_FD_WRITER;
-			params->fd = app->tap[in->id];
-			params->tx_burst_sz =
-				app->tap_params[in->id].burst_write;
-			break;
-		}
-#endif
-#ifdef RTE_LIBRTE_KNI
-		case APP_PKTQ_OUT_KNI:
-		{
-			struct app_pktq_kni_params *p_kni =
-				&app->kni_params[in->id];
-
-			if (p_kni->dropless == 0) {
-				struct rte_port_kni_writer_params *params =
-					&out->params.kni;
-
-				out->type = PIPELINE_PORT_OUT_KNI_WRITER;
-				params->kni = app->kni[in->id];
-				params->tx_burst_sz =
-					app->kni_params[in->id].burst_write;
-			} else {
-				struct rte_port_kni_writer_nodrop_params
-					*params = &out->params.kni_nodrop;
-
-				out->type = PIPELINE_PORT_OUT_KNI_WRITER_NODROP;
-				params->kni = app->kni[in->id];
-				params->tx_burst_sz =
-					app->kni_params[in->id].burst_write;
-				params->n_retries =
-					app->kni_params[in->id].n_retries;
-			}
-			break;
-		}
-#endif /* RTE_LIBRTE_KNI */
-		case APP_PKTQ_OUT_SINK:
-		{
-			out->type = PIPELINE_PORT_OUT_SINK;
-			out->params.sink.file_name =
-				app->sink_params[in->id].file_name;
-			out->params.sink.max_n_pkts =
-				app->sink_params[in->id].
-				n_pkts_to_dump;
-
-			break;
-		}
-		default:
-			break;
-		}
-	}
-
-	/* msgq */
-	p_out->n_msgq = p_in->n_msgq_in;
-
-	for (i = 0; i < p_in->n_msgq_in; i++)
-		p_out->msgq_in[i] = app->msgq[p_in->msgq_in[i]];
-
-	for (i = 0; i < p_in->n_msgq_out; i++)
-		p_out->msgq_out[i] = app->msgq[p_in->msgq_out[i]];
-
-	/* args */
-	p_out->n_args = p_in->n_args;
-	for (i = 0; i < p_in->n_args; i++) {
-		p_out->args_name[i] = p_in->args_name[i];
-		p_out->args_value[i] = p_in->args_value[i];
-	}
-}
-
-static void
-app_init_pipelines(struct app_params *app)
-{
-	uint32_t p_id;
-
-	for (p_id = 0; p_id < app->n_pipelines; p_id++) {
-		struct app_pipeline_params *params =
-			&app->pipeline_params[p_id];
-		struct app_pipeline_data *data = &app->pipeline_data[p_id];
-		struct pipeline_type *ptype;
-		struct pipeline_params pp;
-
-		APP_LOG(app, HIGH, "Initializing %s ...", params->name);
-
-		ptype = app_pipeline_type_find(app, params->type);
-		if (ptype == NULL)
-			rte_panic("Init error: Unknown pipeline type \"%s\"\n",
-				params->type);
-
-		app_pipeline_params_get(app, params, &pp);
-
-		/* Back-end */
-		data->be = NULL;
-		if (ptype->be_ops->f_init) {
-			data->be = ptype->be_ops->f_init(&pp, (void *) app);
-
-			if (data->be == NULL)
-				rte_panic("Pipeline instance \"%s\" back-end "
-					"init error\n", params->name);
-		}
-
-		/* Front-end */
-		data->fe = NULL;
-		if (ptype->fe_ops->f_init) {
-			data->fe = ptype->fe_ops->f_init(&pp, (void *) app);
-
-			if (data->fe == NULL)
-				rte_panic("Pipeline instance \"%s\" front-end "
-				"init error\n", params->name);
-		}
-
-		data->ptype = ptype;
-
-		data->timer_period = (rte_get_tsc_hz() *
-			params->timer_period) / 1000;
-	}
-}
-
-static void
-app_post_init_pipelines(struct app_params *app)
-{
-	uint32_t p_id;
-
-	for (p_id = 0; p_id < app->n_pipelines; p_id++) {
-		struct app_pipeline_params *params =
-			&app->pipeline_params[p_id];
-		struct app_pipeline_data *data = &app->pipeline_data[p_id];
-		int status;
-
-		if (data->ptype->fe_ops->f_post_init == NULL)
-			continue;
-
-		status = data->ptype->fe_ops->f_post_init(data->fe);
-		if (status)
-			rte_panic("Pipeline instance \"%s\" front-end "
-				"post-init error\n", params->name);
-	}
-}
-
-static void
-app_init_threads(struct app_params *app)
-{
-	uint64_t time = rte_get_tsc_cycles();
-	uint32_t p_id;
-
-	for (p_id = 0; p_id < app->n_pipelines; p_id++) {
-		struct app_pipeline_params *params =
-			&app->pipeline_params[p_id];
-		struct app_pipeline_data *data = &app->pipeline_data[p_id];
-		struct pipeline_type *ptype;
-		struct app_thread_data *t;
-		struct app_thread_pipeline_data *p;
-		int lcore_id;
-
-		lcore_id = cpu_core_map_get_lcore_id(app->core_map,
-			params->socket_id,
-			params->core_id,
-			params->hyper_th_id);
-
-		if (lcore_id < 0)
-			rte_panic("Invalid core s%" PRIu32 "c%" PRIu32 "%s\n",
-				params->socket_id,
-				params->core_id,
-				(params->hyper_th_id) ? "h" : "");
-
-		t = &app->thread_data[lcore_id];
-
-		t->timer_period = (rte_get_tsc_hz() * APP_THREAD_TIMER_PERIOD) / 1000;
-		t->thread_req_deadline = time + t->timer_period;
-
-		t->headroom_cycles = 0;
-		t->headroom_time = rte_get_tsc_cycles();
-		t->headroom_ratio = 0.0;
-
-		t->msgq_in = app_thread_msgq_in_get(app,
-				params->socket_id,
-				params->core_id,
-				params->hyper_th_id);
-		if (t->msgq_in == NULL)
-			rte_panic("Init error: Cannot find MSGQ_IN for thread %" PRId32,
-				lcore_id);
-
-		t->msgq_out = app_thread_msgq_out_get(app,
-				params->socket_id,
-				params->core_id,
-				params->hyper_th_id);
-		if (t->msgq_out == NULL)
-			rte_panic("Init error: Cannot find MSGQ_OUT for thread %" PRId32,
-				lcore_id);
-
-		ptype = app_pipeline_type_find(app, params->type);
-		if (ptype == NULL)
-			rte_panic("Init error: Unknown pipeline "
-				"type \"%s\"\n", params->type);
-
-		p = (ptype->be_ops->f_run == NULL) ?
-			&t->regular[t->n_regular] :
-			&t->custom[t->n_custom];
-
-		p->pipeline_id = p_id;
-		p->be = data->be;
-		p->f_run = ptype->be_ops->f_run;
-		p->f_timer = ptype->be_ops->f_timer;
-		p->timer_period = data->timer_period;
-		p->deadline = time + data->timer_period;
-
-		data->enabled = 1;
-
-		if (ptype->be_ops->f_run == NULL)
-			t->n_regular++;
-		else
-			t->n_custom++;
-	}
-}
-
-int app_init(struct app_params *app)
-{
-	app_init_core_map(app);
-	app_init_core_mask(app);
-
-	app_init_eal(app);
-	app_init_mempool(app);
-	app_init_link(app);
-	app_init_swq(app);
-	app_init_tm(app);
-	app_init_tap(app);
-	app_init_kni(app);
-	app_init_msgq(app);
-
-	app_pipeline_common_cmd_push(app);
-	app_pipeline_thread_cmd_push(app);
-	app_pipeline_type_register(app, &pipeline_master);
-	app_pipeline_type_register(app, &pipeline_passthrough);
-	app_pipeline_type_register(app, &pipeline_flow_classification);
-	app_pipeline_type_register(app, &pipeline_flow_actions);
-	app_pipeline_type_register(app, &pipeline_firewall);
-	app_pipeline_type_register(app, &pipeline_routing);
-
-	app_init_pipelines(app);
-	app_init_threads(app);
-
-	return 0;
-}
-
-int app_post_init(struct app_params *app)
-{
-	app_post_init_pipelines(app);
-
-	return 0;
-}
-
-static int
-app_pipeline_type_cmd_push(struct app_params *app,
-	struct pipeline_type *ptype)
-{
-	cmdline_parse_ctx_t *cmds;
-	uint32_t n_cmds, i;
-
-	/* Check input arguments */
-	if ((app == NULL) ||
-		(ptype == NULL))
-		return -EINVAL;
-
-	n_cmds = pipeline_type_cmds_count(ptype);
-	if (n_cmds == 0)
-		return 0;
-
-	cmds = ptype->fe_ops->cmds;
-
-	/* Check for available slots in the application commands array */
-	if (n_cmds > APP_MAX_CMDS - app->n_cmds)
-		return -ENOMEM;
-
-	/* Push pipeline commands into the application */
-	memcpy(&app->cmds[app->n_cmds],
-		cmds,
-		n_cmds * sizeof(cmdline_parse_ctx_t));
-
-	for (i = 0; i < n_cmds; i++)
-		app->cmds[app->n_cmds + i]->data = app;
-
-	app->n_cmds += n_cmds;
-	app->cmds[app->n_cmds] = NULL;
-
-	return 0;
-}
-
-int
-app_pipeline_type_register(struct app_params *app, struct pipeline_type *ptype)
-{
-	uint32_t n_cmds, i;
-
-	/* Check input arguments */
-	if ((app == NULL) ||
-		(ptype == NULL) ||
-		(ptype->name == NULL) ||
-		(strlen(ptype->name) == 0) ||
-		(ptype->be_ops->f_init == NULL) ||
-		(ptype->be_ops->f_timer == NULL))
-		return -EINVAL;
-
-	/* Check for duplicate entry */
-	for (i = 0; i < app->n_pipeline_types; i++)
-		if (strcmp(app->pipeline_type[i].name, ptype->name) == 0)
-			return -EEXIST;
-
-	/* Check for resource availability */
-	n_cmds = pipeline_type_cmds_count(ptype);
-	if ((app->n_pipeline_types == APP_MAX_PIPELINE_TYPES) ||
-		(n_cmds > APP_MAX_CMDS - app->n_cmds))
-		return -ENOMEM;
-
-	/* Copy pipeline type */
-	memcpy(&app->pipeline_type[app->n_pipeline_types++],
-		ptype,
-		sizeof(struct pipeline_type));
-
-	/* Copy CLI commands */
-	if (n_cmds)
-		app_pipeline_type_cmd_push(app, ptype);
-
-	return 0;
-}
-
-struct
-pipeline_type *app_pipeline_type_find(struct app_params *app, char *name)
-{
-	uint32_t i;
-
-	for (i = 0; i < app->n_pipeline_types; i++)
-		if (strcmp(app->pipeline_type[i].name, name) == 0)
-			return &app->pipeline_type[i];
-
-	return NULL;
-}
diff --git a/examples/ip_pipeline/main.c b/examples/ip_pipeline/main.c
deleted file mode 100644
index a44cf9a..0000000
--- a/examples/ip_pipeline/main.c
+++ /dev/null
@@ -1,35 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#include "app.h"
-
-static struct app_params app;
-
-int
-main(int argc, char **argv)
-{
-	rte_openlog_stream(stderr);
-
-	/* Config */
-	app_config_init(&app);
-
-	app_config_args(&app, argc, argv);
-
-	app_config_preproc(&app);
-
-	app_config_parse(&app, app.parser_file);
-
-	app_config_check(&app);
-
-	/* Init */
-	app_init(&app);
-
-	/* Run-time */
-	rte_eal_mp_remote_launch(
-		app_thread,
-		(void *) &app,
-		CALL_MASTER);
-
-	return 0;
-}
diff --git a/examples/ip_pipeline/meson.build b/examples/ip_pipeline/meson.build
deleted file mode 100644
index 748c9ae..0000000
--- a/examples/ip_pipeline/meson.build
+++ /dev/null
@@ -1,35 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-deps += ['cfgfile', 'pipeline', 'bus_pci']
-includes += include_directories('pipeline')
-sources = files(
-	'config_check.c',
-	'config_parse.c',
-	'config_parse_tm.c',
-	'cpu_core_map.c',
-	'init.c',
-	'main.c',
-	'parser.c',
-	'thread.c',
-	'thread_fe.c',
-	'pipeline/pipeline_common_be.c',
-	'pipeline/pipeline_common_fe.c',
-	'pipeline/pipeline_firewall_be.c',
-	'pipeline/pipeline_firewall.c',
-	'pipeline/pipeline_flow_actions_be.c',
-	'pipeline/pipeline_flow_actions.c',
-	'pipeline/pipeline_flow_classification_be.c',
-	'pipeline/pipeline_flow_classification.c',
-	'pipeline/pipeline_master_be.c',
-	'pipeline/pipeline_master.c',
-	'pipeline/pipeline_passthrough_be.c',
-	'pipeline/pipeline_passthrough.c',
-	'pipeline/pipeline_routing_be.c',
-	'pipeline/pipeline_routing.c',
-)
diff --git a/examples/ip_pipeline/parser.c b/examples/ip_pipeline/parser.c
deleted file mode 100644
index 0901e9c..0000000
--- a/examples/ip_pipeline/parser.c
+++ /dev/null
@@ -1,689 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016 Intel Corporation.
- * Copyright (c) 2009, Olivier MATZ <zer0@droids-corp.org>
- * All rights reserved.
- */
-
-/*
- * For inet_pton4() and inet_pton6() functions:
- *
- * Copyright (c) 1996 by Internet Software Consortium.
- *
- * Permission to use, copy, modify, and distribute this software for any
- * purpose with or without fee is hereby granted, provided that the above
- * copyright notice and this permission notice appear in all copies.
- *
- * THE SOFTWARE IS PROVIDED "AS IS" AND INTERNET SOFTWARE CONSORTIUM DISCLAIMS
- * ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES
- * OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL INTERNET SOFTWARE
- * CONSORTIUM BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL
- * DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR
- * PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
- * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS
- * SOFTWARE.
- */
-
-#include <stdint.h>
-#include <stdlib.h>
-#include <stdio.h>
-#include <ctype.h>
-#include <getopt.h>
-#include <errno.h>
-#include <stdarg.h>
-#include <string.h>
-#include <libgen.h>
-#include <unistd.h>
-#include <sys/wait.h>
-
-#include <rte_errno.h>
-#include <rte_cfgfile.h>
-#include <rte_string_fns.h>
-
-#include "app.h"
-#include "parser.h"
-
-static uint32_t
-get_hex_val(char c)
-{
-	switch (c) {
-	case '0': case '1': case '2': case '3': case '4': case '5':
-	case '6': case '7': case '8': case '9':
-		return c - '0';
-	case 'A': case 'B': case 'C': case 'D': case 'E': case 'F':
-		return c - 'A' + 10;
-	case 'a': case 'b': case 'c': case 'd': case 'e': case 'f':
-		return c - 'a' + 10;
-	default:
-		return 0;
-	}
-}
-
-int
-parser_read_arg_bool(const char *p)
-{
-	p = skip_white_spaces(p);
-	int result = -EINVAL;
-
-	if (((p[0] == 'y') && (p[1] == 'e') && (p[2] == 's')) ||
-		((p[0] == 'Y') && (p[1] == 'E') && (p[2] == 'S'))) {
-		p += 3;
-		result = 1;
-	}
-
-	if (((p[0] == 'o') && (p[1] == 'n')) ||
-		((p[0] == 'O') && (p[1] == 'N'))) {
-		p += 2;
-		result = 1;
-	}
-
-	if (((p[0] == 'n') && (p[1] == 'o')) ||
-		((p[0] == 'N') && (p[1] == 'O'))) {
-		p += 2;
-		result = 0;
-	}
-
-	if (((p[0] == 'o') && (p[1] == 'f') && (p[2] == 'f')) ||
-		((p[0] == 'O') && (p[1] == 'F') && (p[2] == 'F'))) {
-		p += 3;
-		result = 0;
-	}
-
-	p = skip_white_spaces(p);
-
-	if (p[0] != '\0')
-		return -EINVAL;
-
-	return result;
-}
-
-int
-parser_read_uint64(uint64_t *value, const char *p)
-{
-	char *next;
-	uint64_t val;
-
-	p = skip_white_spaces(p);
-	if (!isdigit(*p))
-		return -EINVAL;
-
-	val = strtoul(p, &next, 10);
-	if (p == next)
-		return -EINVAL;
-
-	p = next;
-	switch (*p) {
-	case 'T':
-		val *= 1024ULL;
-		/* fall through */
-	case 'G':
-		val *= 1024ULL;
-		/* fall through */
-	case 'M':
-		val *= 1024ULL;
-		/* fall through */
-	case 'k':
-	case 'K':
-		val *= 1024ULL;
-		p++;
-		break;
-	}
-
-	p = skip_white_spaces(p);
-	if (*p != '\0')
-		return -EINVAL;
-
-	*value = val;
-	return 0;
-}
-
-int
-parser_read_uint64_hex(uint64_t *value, const char *p)
-{
-	char *next;
-	uint64_t val;
-
-	p = skip_white_spaces(p);
-
-	val = strtoul(p, &next, 16);
-	if (p == next)
-		return -EINVAL;
-
-	p = skip_white_spaces(next);
-	if (*p != '\0')
-		return -EINVAL;
-
-	*value = val;
-	return 0;
-}
-
-int
-parser_read_uint32(uint32_t *value, const char *p)
-{
-	uint64_t val = 0;
-	int ret = parser_read_uint64(&val, p);
-
-	if (ret < 0)
-		return ret;
-
-	if (val > UINT32_MAX)
-		return -ERANGE;
-
-	*value = val;
-	return 0;
-}
-
-int
-parser_read_uint32_hex(uint32_t *value, const char *p)
-{
-	uint64_t val = 0;
-	int ret = parser_read_uint64_hex(&val, p);
-
-	if (ret < 0)
-		return ret;
-
-	if (val > UINT32_MAX)
-		return -ERANGE;
-
-	*value = val;
-	return 0;
-}
-
-int
-parser_read_uint16(uint16_t *value, const char *p)
-{
-	uint64_t val = 0;
-	int ret = parser_read_uint64(&val, p);
-
-	if (ret < 0)
-		return ret;
-
-	if (val > UINT16_MAX)
-		return -ERANGE;
-
-	*value = val;
-	return 0;
-}
-
-int
-parser_read_uint16_hex(uint16_t *value, const char *p)
-{
-	uint64_t val = 0;
-	int ret = parser_read_uint64_hex(&val, p);
-
-	if (ret < 0)
-		return ret;
-
-	if (val > UINT16_MAX)
-		return -ERANGE;
-
-	*value = val;
-	return 0;
-}
-
-int
-parser_read_uint8(uint8_t *value, const char *p)
-{
-	uint64_t val = 0;
-	int ret = parser_read_uint64(&val, p);
-
-	if (ret < 0)
-		return ret;
-
-	if (val > UINT8_MAX)
-		return -ERANGE;
-
-	*value = val;
-	return 0;
-}
-
-int
-parser_read_uint8_hex(uint8_t *value, const char *p)
-{
-	uint64_t val = 0;
-	int ret = parser_read_uint64_hex(&val, p);
-
-	if (ret < 0)
-		return ret;
-
-	if (val > UINT8_MAX)
-		return -ERANGE;
-
-	*value = val;
-	return 0;
-}
-
-int
-parse_tokenize_string(char *string, char *tokens[], uint32_t *n_tokens)
-{
-	uint32_t i;
-
-	if ((string == NULL) ||
-		(tokens == NULL) ||
-		(*n_tokens < 1))
-		return -EINVAL;
-
-	for (i = 0; i < *n_tokens; i++) {
-		tokens[i] = strtok_r(string, PARSE_DELIMITER, &string);
-		if (tokens[i] == NULL)
-			break;
-	}
-
-	if ((i == *n_tokens) &&
-		(NULL != strtok_r(string, PARSE_DELIMITER, &string)))
-		return -E2BIG;
-
-	*n_tokens = i;
-	return 0;
-}
-
-int
-parse_hex_string(char *src, uint8_t *dst, uint32_t *size)
-{
-	char *c;
-	uint32_t len, i;
-
-	/* Check input parameters */
-	if ((src == NULL) ||
-		(dst == NULL) ||
-		(size == NULL) ||
-		(*size == 0))
-		return -1;
-
-	len = strlen(src);
-	if (((len & 3) != 0) ||
-		(len > (*size) * 2))
-		return -1;
-	*size = len / 2;
-
-	for (c = src; *c != 0; c++) {
-		if ((((*c) >= '0') && ((*c) <= '9')) ||
-			(((*c) >= 'A') && ((*c) <= 'F')) ||
-			(((*c) >= 'a') && ((*c) <= 'f')))
-			continue;
-
-		return -1;
-	}
-
-	/* Convert chars to bytes */
-	for (i = 0; i < *size; i++)
-		dst[i] = get_hex_val(src[2 * i]) * 16 +
-			get_hex_val(src[2 * i + 1]);
-
-	return 0;
-}
-
-int
-parse_mpls_labels(char *string, uint32_t *labels, uint32_t *n_labels)
-{
-	uint32_t n_max_labels = *n_labels, count = 0;
-
-	/* Check for void list of labels */
-	if (strcmp(string, "<void>") == 0) {
-		*n_labels = 0;
-		return 0;
-	}
-
-	/* At least one label should be present */
-	for ( ; (*string != '\0'); ) {
-		char *next;
-		int value;
-
-		if (count >= n_max_labels)
-			return -1;
-
-		if (count > 0) {
-			if (string[0] != ':')
-				return -1;
-
-			string++;
-		}
-
-		value = strtol(string, &next, 10);
-		if (next == string)
-			return -1;
-		string = next;
-
-		labels[count++] = (uint32_t) value;
-	}
-
-	*n_labels = count;
-	return 0;
-}
-
-#define INADDRSZ 4
-#define IN6ADDRSZ 16
-
-/* int
- * inet_pton4(src, dst)
- *      like inet_aton() but without all the hexadecimal and shorthand.
- * return:
- *      1 if `src' is a valid dotted quad, else 0.
- * notice:
- *      does not touch `dst' unless it's returning 1.
- * author:
- *      Paul Vixie, 1996.
- */
-static int
-inet_pton4(const char *src, unsigned char *dst)
-{
-	static const char digits[] = "0123456789";
-	int saw_digit, octets, ch;
-	unsigned char tmp[INADDRSZ], *tp;
-
-	saw_digit = 0;
-	octets = 0;
-	*(tp = tmp) = 0;
-	while ((ch = *src++) != '\0') {
-		const char *pch;
-
-		pch = strchr(digits, ch);
-		if (pch != NULL) {
-			unsigned int new = *tp * 10 + (pch - digits);
-
-			if (new > 255)
-				return 0;
-			if (!saw_digit) {
-				if (++octets > 4)
-					return 0;
-				saw_digit = 1;
-			}
-			*tp = (unsigned char)new;
-		} else if (ch == '.' && saw_digit) {
-			if (octets == 4)
-				return 0;
-			*++tp = 0;
-			saw_digit = 0;
-		} else
-			return 0;
-	}
-	if (octets < 4)
-		return 0;
-
-	memcpy(dst, tmp, INADDRSZ);
-	return 1;
-}
-
-/* int
- * inet_pton6(src, dst)
- *      convert presentation level address to network order binary form.
- * return:
- *      1 if `src' is a valid [RFC1884 2.2] address, else 0.
- * notice:
- *      (1) does not touch `dst' unless it's returning 1.
- *      (2) :: in a full address is silently ignored.
- * credit:
- *      inspired by Mark Andrews.
- * author:
- *      Paul Vixie, 1996.
- */
-static int
-inet_pton6(const char *src, unsigned char *dst)
-{
-	static const char xdigits_l[] = "0123456789abcdef",
-		xdigits_u[] = "0123456789ABCDEF";
-	unsigned char tmp[IN6ADDRSZ], *tp = 0, *endp = 0, *colonp = 0;
-	const char *xdigits = 0, *curtok = 0;
-	int ch = 0, saw_xdigit = 0, count_xdigit = 0;
-	unsigned int val = 0;
-	unsigned dbloct_count = 0;
-
-	memset((tp = tmp), '\0', IN6ADDRSZ);
-	endp = tp + IN6ADDRSZ;
-	colonp = NULL;
-	/* Leading :: requires some special handling. */
-	if (*src == ':')
-		if (*++src != ':')
-			return 0;
-	curtok = src;
-	saw_xdigit = count_xdigit = 0;
-	val = 0;
-
-	while ((ch = *src++) != '\0') {
-		const char *pch;
-
-		pch = strchr((xdigits = xdigits_l), ch);
-		if (pch == NULL)
-			pch = strchr((xdigits = xdigits_u), ch);
-		if (pch != NULL) {
-			if (count_xdigit >= 4)
-				return 0;
-			val <<= 4;
-			val |= (pch - xdigits);
-			if (val > 0xffff)
-				return 0;
-			saw_xdigit = 1;
-			count_xdigit++;
-			continue;
-		}
-		if (ch == ':') {
-			curtok = src;
-			if (!saw_xdigit) {
-				if (colonp)
-					return 0;
-				colonp = tp;
-				continue;
-			} else if (*src == '\0') {
-				return 0;
-			}
-			if (tp + sizeof(int16_t) > endp)
-				return 0;
-			*tp++ = (unsigned char) ((val >> 8) & 0xff);
-			*tp++ = (unsigned char) (val & 0xff);
-			saw_xdigit = 0;
-			count_xdigit = 0;
-			val = 0;
-			dbloct_count++;
-			continue;
-		}
-		if (ch == '.' && ((tp + INADDRSZ) <= endp) &&
-		    inet_pton4(curtok, tp) > 0) {
-			tp += INADDRSZ;
-			saw_xdigit = 0;
-			dbloct_count += 2;
-			break;  /* '\0' was seen by inet_pton4(). */
-		}
-		return 0;
-	}
-	if (saw_xdigit) {
-		if (tp + sizeof(int16_t) > endp)
-			return 0;
-		*tp++ = (unsigned char) ((val >> 8) & 0xff);
-		*tp++ = (unsigned char) (val & 0xff);
-		dbloct_count++;
-	}
-	if (colonp != NULL) {
-		/* if we already have 8 double octets, having a colon means error */
-		if (dbloct_count == 8)
-			return 0;
-
-		/*
-		 * Since some memmove()'s erroneously fail to handle
-		 * overlapping regions, we'll do the shift by hand.
-		 */
-		const int n = tp - colonp;
-		int i;
-
-		for (i = 1; i <= n; i++) {
-			endp[-i] = colonp[n - i];
-			colonp[n - i] = 0;
-		}
-		tp = endp;
-	}
-	if (tp != endp)
-		return 0;
-	memcpy(dst, tmp, IN6ADDRSZ);
-	return 1;
-}
-
-static struct ether_addr *
-my_ether_aton(const char *a)
-{
-	int i;
-	char *end;
-	unsigned long o[ETHER_ADDR_LEN];
-	static struct ether_addr ether_addr;
-
-	i = 0;
-	do {
-		errno = 0;
-		o[i] = strtoul(a, &end, 16);
-		if (errno != 0 || end == a || (end[0] != ':' && end[0] != 0))
-			return NULL;
-		a = end + 1;
-	} while (++i != sizeof(o) / sizeof(o[0]) && end[0] != 0);
-
-	/* Junk at the end of line */
-	if (end[0] != 0)
-		return NULL;
-
-	/* Support the format XX:XX:XX:XX:XX:XX */
-	if (i == ETHER_ADDR_LEN) {
-		while (i-- != 0) {
-			if (o[i] > UINT8_MAX)
-				return NULL;
-			ether_addr.addr_bytes[i] = (uint8_t)o[i];
-		}
-	/* Support the format XXXX:XXXX:XXXX */
-	} else if (i == ETHER_ADDR_LEN / 2) {
-		while (i-- != 0) {
-			if (o[i] > UINT16_MAX)
-				return NULL;
-			ether_addr.addr_bytes[i * 2] = (uint8_t)(o[i] >> 8);
-			ether_addr.addr_bytes[i * 2 + 1] = (uint8_t)(o[i] & 0xff);
-		}
-	/* unknown format */
-	} else
-		return NULL;
-
-	return (struct ether_addr *)&ether_addr;
-}
-
-int
-parse_ipv4_addr(const char *token, struct in_addr *ipv4)
-{
-	if (strlen(token) >= INET_ADDRSTRLEN)
-		return -EINVAL;
-
-	if (inet_pton4(token, (unsigned char *)ipv4) != 1)
-		return -EINVAL;
-
-	return 0;
-}
-
-int
-parse_ipv6_addr(const char *token, struct in6_addr *ipv6)
-{
-	if (strlen(token) >= INET6_ADDRSTRLEN)
-		return -EINVAL;
-
-	if (inet_pton6(token, (unsigned char *)ipv6) != 1)
-		return -EINVAL;
-
-	return 0;
-}
-
-int
-parse_mac_addr(const char *token, struct ether_addr *addr)
-{
-	struct ether_addr *tmp;
-
-	tmp = my_ether_aton(token);
-	if (tmp == NULL)
-		return -1;
-
-	memcpy(addr, tmp, sizeof(struct ether_addr));
-	return 0;
-}
-
-int
-parse_pipeline_core(uint32_t *socket,
-	uint32_t *core,
-	uint32_t *ht,
-	const char *entry)
-{
-	size_t num_len;
-	char num[8];
-
-	uint32_t s = 0, c = 0, h = 0, val;
-	uint8_t s_parsed = 0, c_parsed = 0, h_parsed = 0;
-	const char *next = skip_white_spaces(entry);
-	char type;
-
-	/* Expect <CORE> or [sX][cY][h]. At least one parameter is required. */
-	while (*next != '\0') {
-		/* If everything parsed nothing should left */
-		if (s_parsed && c_parsed && h_parsed)
-			return -EINVAL;
-
-		type = *next;
-		switch (type) {
-		case 's':
-		case 'S':
-			if (s_parsed || c_parsed || h_parsed)
-				return -EINVAL;
-			s_parsed = 1;
-			next++;
-			break;
-		case 'c':
-		case 'C':
-			if (c_parsed || h_parsed)
-				return -EINVAL;
-			c_parsed = 1;
-			next++;
-			break;
-		case 'h':
-		case 'H':
-			if (h_parsed)
-				return -EINVAL;
-			h_parsed = 1;
-			next++;
-			break;
-		default:
-			/* If it start from digit it must be only core id. */
-			if (!isdigit(*next) || s_parsed || c_parsed || h_parsed)
-				return -EINVAL;
-
-			type = 'C';
-		}
-
-		for (num_len = 0; *next != '\0'; next++, num_len++) {
-			if (num_len == RTE_DIM(num))
-				return -EINVAL;
-
-			if (!isdigit(*next))
-				break;
-
-			num[num_len] = *next;
-		}
-
-		if (num_len == 0 && type != 'h' && type != 'H')
-			return -EINVAL;
-
-		if (num_len != 0 && (type == 'h' || type == 'H'))
-			return -EINVAL;
-
-		num[num_len] = '\0';
-		val = strtol(num, NULL, 10);
-
-		h = 0;
-		switch (type) {
-		case 's':
-		case 'S':
-			s = val;
-			break;
-		case 'c':
-		case 'C':
-			c = val;
-			break;
-		case 'h':
-		case 'H':
-			h = 1;
-			break;
-		}
-	}
-
-	*socket = s;
-	*core = c;
-	*ht = h;
-	return 0;
-}
diff --git a/examples/ip_pipeline/parser.h b/examples/ip_pipeline/parser.h
deleted file mode 100644
index 5c421d2..0000000
--- a/examples/ip_pipeline/parser.h
+++ /dev/null
@@ -1,55 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#ifndef __INCLUDE_PARSER_H__
-#define __INCLUDE_PARSER_H__
-
-#include <stdint.h>
-
-#include <rte_ip.h>
-#include <rte_ether.h>
-
-#define PARSE_DELIMITER				" \f\n\r\t\v"
-
-#define skip_white_spaces(pos)			\
-({						\
-	__typeof__(pos) _p = (pos);		\
-	for ( ; isspace(*_p); _p++)		\
-		;				\
-	_p;					\
-})
-
-static inline size_t
-skip_digits(const char *src)
-{
-	size_t i;
-
-	for (i = 0; isdigit(src[i]); i++)
-		;
-
-	return i;
-}
-
-int parser_read_arg_bool(const char *p);
-
-int parser_read_uint64(uint64_t *value, const char *p);
-int parser_read_uint32(uint32_t *value, const char *p);
-int parser_read_uint16(uint16_t *value, const char *p);
-int parser_read_uint8(uint8_t *value, const char *p);
-
-int parser_read_uint64_hex(uint64_t *value, const char *p);
-int parser_read_uint32_hex(uint32_t *value, const char *p);
-int parser_read_uint16_hex(uint16_t *value, const char *p);
-int parser_read_uint8_hex(uint8_t *value, const char *p);
-
-int parse_hex_string(char *src, uint8_t *dst, uint32_t *size);
-
-int parse_ipv4_addr(const char *token, struct in_addr *ipv4);
-int parse_ipv6_addr(const char *token, struct in6_addr *ipv6);
-int parse_mac_addr(const char *token, struct ether_addr *addr);
-int parse_mpls_labels(char *string, uint32_t *labels, uint32_t *n_labels);
-
-int parse_tokenize_string(char *string, char *tokens[], uint32_t *n_tokens);
-
-#endif
diff --git a/examples/ip_pipeline/pipeline.h b/examples/ip_pipeline/pipeline.h
deleted file mode 100644
index 7ca9cad..0000000
--- a/examples/ip_pipeline/pipeline.h
+++ /dev/null
@@ -1,73 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#ifndef __INCLUDE_PIPELINE_H__
-#define __INCLUDE_PIPELINE_H__
-
-#include <cmdline_parse.h>
-
-#include "pipeline_be.h"
-
-/*
- * Pipeline type front-end operations
- */
-
-typedef void* (*pipeline_fe_op_init)(struct pipeline_params *params,
-	void *arg);
-
-typedef int (*pipeline_fe_op_post_init)(void *pipeline);
-
-typedef int (*pipeline_fe_op_free)(void *pipeline);
-
-typedef int (*pipeline_fe_op_track)(struct pipeline_params *params,
-	uint32_t port_in,
-	uint32_t *port_out);
-
-struct pipeline_fe_ops {
-	pipeline_fe_op_init f_init;
-	pipeline_fe_op_post_init f_post_init;
-	pipeline_fe_op_free f_free;
-	pipeline_fe_op_track f_track;
-	cmdline_parse_ctx_t *cmds;
-};
-
-/*
- * Pipeline type
- */
-
-struct pipeline_type {
-	const char *name;
-
-	/* pipeline back-end */
-	struct pipeline_be_ops *be_ops;
-
-	/* pipeline front-end */
-	struct pipeline_fe_ops *fe_ops;
-};
-
-static inline uint32_t
-pipeline_type_cmds_count(struct pipeline_type *ptype)
-{
-	cmdline_parse_ctx_t *cmds;
-	uint32_t n_cmds;
-
-	if (ptype->fe_ops == NULL)
-		return 0;
-
-	cmds = ptype->fe_ops->cmds;
-	if (cmds == NULL)
-		return 0;
-
-	for (n_cmds = 0; cmds[n_cmds]; n_cmds++);
-
-	return n_cmds;
-}
-
-int
-parse_pipeline_core(uint32_t *socket,
-	uint32_t *core,
-	uint32_t *ht,
-	const char *entry);
-
-#endif
diff --git a/examples/ip_pipeline/pipeline/hash_func.h b/examples/ip_pipeline/pipeline/hash_func.h
deleted file mode 100644
index 806ac22..0000000
--- a/examples/ip_pipeline/pipeline/hash_func.h
+++ /dev/null
@@ -1,356 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-#ifndef __INCLUDE_HASH_FUNC_H__
-#define __INCLUDE_HASH_FUNC_H__
-
-static inline uint64_t
-hash_xor_key8(void *key, void *mask, __rte_unused uint32_t key_size,
-	uint64_t seed)
-{
-	uint64_t *k = key;
-	uint64_t *m = mask;
-	uint64_t xor0;
-
-	xor0 = seed ^ (k[0] & m[0]);
-
-	return (xor0 >> 32) ^ xor0;
-}
-
-static inline uint64_t
-hash_xor_key16(void *key, void *mask, __rte_unused uint32_t key_size,
-	uint64_t seed)
-{
-	uint64_t *k = key;
-	uint64_t *m = mask;
-	uint64_t xor0;
-
-	xor0 = ((k[0] & m[0]) ^ seed) ^ (k[1] & m[1]);
-
-	return (xor0 >> 32) ^ xor0;
-}
-
-static inline uint64_t
-hash_xor_key24(void *key, void *mask, __rte_unused uint32_t key_size,
-	uint64_t seed)
-{
-	uint64_t *k = key;
-	uint64_t *m = mask;
-	uint64_t xor0;
-
-	xor0 = ((k[0] & m[0]) ^ seed) ^ (k[1] & m[1]);
-
-	xor0 ^= k[2] & m[2];
-
-	return (xor0 >> 32) ^ xor0;
-}
-
-static inline uint64_t
-hash_xor_key32(void *key, void *mask, __rte_unused uint32_t key_size,
-	uint64_t seed)
-{
-	uint64_t *k = key;
-	uint64_t *m = mask;
-	uint64_t xor0, xor1;
-
-	xor0 = ((k[0] & m[0]) ^ seed) ^ (k[1] & m[1]);
-	xor1 = (k[2] & m[2]) ^ (k[3] & m[3]);
-
-	xor0 ^= xor1;
-
-	return (xor0 >> 32) ^ xor0;
-}
-
-static inline uint64_t
-hash_xor_key40(void *key, void *mask, __rte_unused uint32_t key_size,
-	uint64_t seed)
-{
-	uint64_t *k = key;
-	uint64_t *m = mask;
-	uint64_t xor0, xor1;
-
-	xor0 = ((k[0] & m[0]) ^ seed) ^ (k[1] & m[1]);
-	xor1 = (k[2] & m[2]) ^ (k[3] & m[3]);
-
-	xor0 ^= xor1;
-
-	xor0 ^= k[4] & m[4];
-
-	return (xor0 >> 32) ^ xor0;
-}
-
-static inline uint64_t
-hash_xor_key48(void *key, void *mask, __rte_unused uint32_t key_size,
-	uint64_t seed)
-{
-	uint64_t *k = key;
-	uint64_t *m = mask;
-	uint64_t xor0, xor1, xor2;
-
-	xor0 = ((k[0] & m[0]) ^ seed) ^ (k[1] & m[1]);
-	xor1 = (k[2] & m[2]) ^ (k[3] & m[3]);
-	xor2 = (k[4] & m[4]) ^ (k[5] & m[5]);
-
-	xor0 ^= xor1;
-
-	xor0 ^= xor2;
-
-	return (xor0 >> 32) ^ xor0;
-}
-
-static inline uint64_t
-hash_xor_key56(void *key, void *mask, __rte_unused uint32_t key_size,
-	uint64_t seed)
-{
-	uint64_t *k = key;
-	uint64_t *m = mask;
-	uint64_t xor0, xor1, xor2;
-
-	xor0 = ((k[0] & m[0]) ^ seed) ^ (k[1] & m[1]);
-	xor1 = (k[2] & m[2]) ^ (k[3] & m[3]);
-	xor2 = (k[4] & m[4]) ^ (k[5] & m[5]);
-
-	xor0 ^= xor1;
-	xor2 ^= k[6] & m[6];
-
-	xor0 ^= xor2;
-
-	return (xor0 >> 32) ^ xor0;
-}
-
-static inline uint64_t
-hash_xor_key64(void *key, void *mask, __rte_unused uint32_t key_size,
-	uint64_t seed)
-{
-	uint64_t *k = key;
-	uint64_t *m = mask;
-	uint64_t xor0, xor1, xor2, xor3;
-
-	xor0 = ((k[0] & m[0]) ^ seed) ^ (k[1] & m[1]);
-	xor1 = (k[2] & m[2]) ^ (k[3] & m[3]);
-	xor2 = (k[4] & m[4]) ^ (k[5] & m[5]);
-	xor3 = (k[6] & m[6]) ^ (k[7] & m[7]);
-
-	xor0 ^= xor1;
-	xor2 ^= xor3;
-
-	xor0 ^= xor2;
-
-	return (xor0 >> 32) ^ xor0;
-}
-
-#if defined(RTE_ARCH_X86_64)
-
-#include <x86intrin.h>
-
-static inline uint64_t
-hash_crc_key8(void *key, void *mask, __rte_unused uint32_t key_size,
-	uint64_t seed)
-{
-	uint64_t *k = key;
-	uint64_t *m = mask;
-	uint64_t crc0;
-
-	crc0 = _mm_crc32_u64(seed, k[0] & m[0]);
-
-	return crc0;
-}
-
-static inline uint64_t
-hash_crc_key16(void *key, void *mask, __rte_unused uint32_t key_size,
-	uint64_t seed)
-{
-	uint64_t *k = key;
-	uint64_t *m = mask;
-	uint64_t k0, crc0, crc1;
-
-	k0 = k[0] & m[0];
-
-	crc0 = _mm_crc32_u64(k0, seed);
-	crc1 = _mm_crc32_u64(k0 >> 32, k[1] & m[1]);
-
-	crc0 ^= crc1;
-
-	return crc0;
-}
-
-static inline uint64_t
-hash_crc_key24(void *key, void *mask, __rte_unused uint32_t key_size,
-	uint64_t seed)
-{
-	uint64_t *k = key;
-	uint64_t *m = mask;
-	uint64_t k0, k2, crc0, crc1;
-
-	k0 = k[0] & m[0];
-	k2 = k[2] & m[2];
-
-	crc0 = _mm_crc32_u64(k0, seed);
-	crc1 = _mm_crc32_u64(k0 >> 32, k[1] & m[1]);
-
-	crc0 = _mm_crc32_u64(crc0, k2);
-
-	crc0 ^= crc1;
-
-	return crc0;
-}
-
-static inline uint64_t
-hash_crc_key32(void *key, void *mask, __rte_unused uint32_t key_size,
-	uint64_t seed)
-{
-	uint64_t *k = key;
-	uint64_t *m = mask;
-	uint64_t k0, k2, crc0, crc1, crc2, crc3;
-
-	k0 = k[0] & m[0];
-	k2 = k[2] & m[2];
-
-	crc0 = _mm_crc32_u64(k0, seed);
-	crc1 = _mm_crc32_u64(k0 >> 32, k[1] & m[1]);
-
-	crc2 = _mm_crc32_u64(k2, k[3] & m[3]);
-	crc3 = k2 >> 32;
-
-	crc0 = _mm_crc32_u64(crc0, crc1);
-	crc1 = _mm_crc32_u64(crc2, crc3);
-
-	crc0 ^= crc1;
-
-	return crc0;
-}
-
-static inline uint64_t
-hash_crc_key40(void *key, void *mask, __rte_unused uint32_t key_size,
-	uint64_t seed)
-{
-	uint64_t *k = key;
-	uint64_t *m = mask;
-	uint64_t k0, k2, crc0, crc1, crc2, crc3;
-
-	k0 = k[0] & m[0];
-	k2 = k[2] & m[2];
-
-	crc0 = _mm_crc32_u64(k0, seed);
-	crc1 = _mm_crc32_u64(k0 >> 32, k[1] & m[1]);
-
-	crc2 = _mm_crc32_u64(k2, k[3] & m[3]);
-	crc3 = _mm_crc32_u64(k2 >> 32, k[4] & m[4]);
-
-	crc0 = _mm_crc32_u64(crc0, crc1);
-	crc1 = _mm_crc32_u64(crc2, crc3);
-
-	crc0 ^= crc1;
-
-	return crc0;
-}
-
-static inline uint64_t
-hash_crc_key48(void *key, void *mask, __rte_unused uint32_t key_size,
-	uint64_t seed)
-{
-	uint64_t *k = key;
-	uint64_t *m = mask;
-	uint64_t k0, k2, k5, crc0, crc1, crc2, crc3;
-
-	k0 = k[0] & m[0];
-	k2 = k[2] & m[2];
-	k5 = k[5] & m[5];
-
-	crc0 = _mm_crc32_u64(k0, seed);
-	crc1 = _mm_crc32_u64(k0 >> 32, k[1] & m[1]);
-
-	crc2 = _mm_crc32_u64(k2, k[3] & m[3]);
-	crc3 = _mm_crc32_u64(k2 >> 32, k[4] & m[4]);
-
-	crc0 = _mm_crc32_u64(crc0, (crc1 << 32) ^ crc2);
-	crc1 = _mm_crc32_u64(crc3, k5);
-
-	crc0 ^= crc1;
-
-	return crc0;
-}
-
-static inline uint64_t
-hash_crc_key56(void *key, void *mask, __rte_unused uint32_t key_size,
-	uint64_t seed)
-{
-	uint64_t *k = key;
-	uint64_t *m = mask;
-	uint64_t k0, k2, k5, crc0, crc1, crc2, crc3, crc4, crc5;
-
-	k0 = k[0] & m[0];
-	k2 = k[2] & m[2];
-	k5 = k[5] & m[5];
-
-	crc0 = _mm_crc32_u64(k0, seed);
-	crc1 = _mm_crc32_u64(k0 >> 32, k[1] & m[1]);
-
-	crc2 = _mm_crc32_u64(k2, k[3] & m[3]);
-	crc3 = _mm_crc32_u64(k2 >> 32, k[4] & m[4]);
-
-	crc4 = _mm_crc32_u64(k5, k[6] & m[6]);
-	crc5 = k5 >> 32;
-
-	crc0 = _mm_crc32_u64(crc0, (crc1 << 32) ^ crc2);
-	crc1 = _mm_crc32_u64(crc3, (crc4 << 32) ^ crc5);
-
-	crc0 ^= crc1;
-
-	return crc0;
-}
-
-static inline uint64_t
-hash_crc_key64(void *key, void *mask, __rte_unused uint32_t key_size,
-	uint64_t seed)
-{
-	uint64_t *k = key;
-	uint64_t *m = mask;
-	uint64_t k0, k2, k5, crc0, crc1, crc2, crc3, crc4, crc5;
-
-	k0 = k[0] & m[0];
-	k2 = k[2] & m[2];
-	k5 = k[5] & m[5];
-
-	crc0 = _mm_crc32_u64(k0, seed);
-	crc1 = _mm_crc32_u64(k0 >> 32, k[1] & m[1]);
-
-	crc2 = _mm_crc32_u64(k2, k[3] & m[3]);
-	crc3 = _mm_crc32_u64(k2 >> 32, k[4] & m[4]);
-
-	crc4 = _mm_crc32_u64(k5, k[6] & m[6]);
-	crc5 = _mm_crc32_u64(k5 >> 32, k[7] & m[7]);
-
-	crc0 = _mm_crc32_u64(crc0, (crc1 << 32) ^ crc2);
-	crc1 = _mm_crc32_u64(crc3, (crc4 << 32) ^ crc5);
-
-	crc0 ^= crc1;
-
-	return crc0;
-}
-
-#define hash_default_key8			hash_crc_key8
-#define hash_default_key16			hash_crc_key16
-#define hash_default_key24			hash_crc_key24
-#define hash_default_key32			hash_crc_key32
-#define hash_default_key40			hash_crc_key40
-#define hash_default_key48			hash_crc_key48
-#define hash_default_key56			hash_crc_key56
-#define hash_default_key64			hash_crc_key64
-
-#elif defined(RTE_ARCH_ARM64)
-#include "hash_func_arm64.h"
-#else
-
-#define hash_default_key8			hash_xor_key8
-#define hash_default_key16			hash_xor_key16
-#define hash_default_key24			hash_xor_key24
-#define hash_default_key32			hash_xor_key32
-#define hash_default_key40			hash_xor_key40
-#define hash_default_key48			hash_xor_key48
-#define hash_default_key56			hash_xor_key56
-#define hash_default_key64			hash_xor_key64
-
-#endif
-
-#endif
diff --git a/examples/ip_pipeline/pipeline/hash_func_arm64.h b/examples/ip_pipeline/pipeline/hash_func_arm64.h
deleted file mode 100644
index ae6c0f4..0000000
--- a/examples/ip_pipeline/pipeline/hash_func_arm64.h
+++ /dev/null
@@ -1,261 +0,0 @@
-/*-
- *   BSD LICENSE
- *
- *   Copyright(c) 2017 Linaro Limited. All rights reserved.
- *   All rights reserved.
- *
- *   Redistribution and use in source and binary forms, with or without
- *   modification, are permitted provided that the following conditions
- *   are met:
- *
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above copyright
- *       notice, this list of conditions and the following disclaimer in
- *       the documentation and/or other materials provided with the
- *       distribution.
- *     * Neither the name of Intel Corporation nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-#ifndef __HASH_FUNC_ARM64_H__
-#define __HASH_FUNC_ARM64_H__
-
-#define _CRC32CX(crc, val)	\
-	__asm__("crc32cx %w[c], %w[c], %x[v]":[c] "+r" (crc):[v] "r" (val))
-
-static inline uint64_t
-hash_crc_key8(void *key, void *mask, __rte_unused uint32_t key_size,
-	uint64_t seed)
-{
-	uint64_t *k = key;
-	uint64_t *m = mask;
-	uint32_t crc0;
-
-	crc0 = seed;
-	_CRC32CX(crc0, k[0] & m[0]);
-
-	return crc0;
-}
-
-static inline uint64_t
-hash_crc_key16(void *key, void *mask, __rte_unused uint32_t key_size,
-	uint64_t seed)
-{
-	uint64_t *k = key, k0;
-	uint64_t *m = mask;
-	uint32_t crc0, crc1;
-
-	k0 = k[0] & m[0];
-
-	crc0 = k0;
-	_CRC32CX(crc0, seed);
-	crc1 = k0 >> 32;
-	_CRC32CX(crc1, k[1] & m[1]);
-
-	crc0 ^= crc1;
-
-	return crc0;
-}
-
-static inline uint64_t
-hash_crc_key24(void *key, void *mask, __rte_unused uint32_t key_size,
-	uint64_t seed)
-{
-	uint64_t *k = key, k0, k2;
-	uint64_t *m = mask;
-	uint32_t crc0, crc1;
-
-	k0 = k[0] & m[0];
-	k2 = k[2] & m[2];
-
-	crc0 = k0;
-	_CRC32CX(crc0, seed);
-	crc1 = k0 >> 32;
-	_CRC32CX(crc1, k[1] & m[1]);
-
-	_CRC32CX(crc0, k2);
-
-	crc0 ^= crc1;
-
-	return crc0;
-}
-
-static inline uint64_t
-hash_crc_key32(void *key, void *mask, __rte_unused uint32_t key_size,
-	uint64_t seed)
-{
-	uint64_t *k = key, k0, k2;
-	uint64_t *m = mask;
-	uint32_t crc0, crc1, crc2, crc3;
-
-	k0 = k[0] & m[0];
-	k2 = k[2] & m[2];
-
-	crc0 = k0;
-	_CRC32CX(crc0, seed);
-	crc1 = k0 >> 32;
-	_CRC32CX(crc1, k[1] & m[1]);
-
-	crc2 = k2;
-	_CRC32CX(crc2, k[3] & m[3]);
-	crc3 = k2 >> 32;
-
-	_CRC32CX(crc0, crc1);
-	_CRC32CX(crc2, crc3);
-
-	crc0 ^= crc2;
-
-	return crc0;
-}
-
-static inline uint64_t
-hash_crc_key40(void *key, void *mask, __rte_unused uint32_t key_size,
-	uint64_t seed)
-{
-	uint64_t *k = key, k0, k2;
-	uint64_t *m = mask;
-	uint32_t crc0, crc1, crc2, crc3;
-
-	k0 = k[0] & m[0];
-	k2 = k[2] & m[2];
-
-	crc0 = k0;
-	_CRC32CX(crc0, seed);
-	crc1 = k0 >> 32;
-	_CRC32CX(crc1, k[1] & m[1]);
-
-	crc2 = k2;
-	_CRC32CX(crc2, k[3] & m[3]);
-	crc3 = k2 >> 32;
-	_CRC32CX(crc3, k[4] & m[4]);
-
-	_CRC32CX(crc0, crc1);
-	_CRC32CX(crc2, crc3);
-
-	crc0 ^= crc2;
-
-	return crc0;
-}
-
-static inline uint64_t
-hash_crc_key48(void *key, void *mask, __rte_unused uint32_t key_size,
-	uint64_t seed)
-{
-	uint64_t *k = key, k0, k2, k5;
-	uint64_t *m = mask;
-	uint32_t crc0, crc1, crc2, crc3;
-
-	k0 = k[0] & m[0];
-	k2 = k[2] & m[2];
-	k5 = k[5] & m[5];
-
-	crc0 = k0;
-	_CRC32CX(crc0, seed);
-	crc1 = k0 >> 32;
-	_CRC32CX(crc1, k[1] & m[1]);
-
-	crc2 = k2;
-	_CRC32CX(crc2, k[3] & m[3]);
-	crc3 = k2 >> 32;
-	_CRC32CX(crc3, k[4] & m[4]);
-
-	_CRC32CX(crc0, ((uint64_t)crc1 << 32) ^ crc2);
-	_CRC32CX(crc3, k5);
-
-	crc0 ^= crc3;
-
-	return crc0;
-}
-
-static inline uint64_t
-hash_crc_key56(void *key, void *mask, __rte_unused uint32_t key_size,
-	uint64_t seed)
-{
-	uint64_t *k = key, k0, k2, k5;
-	uint64_t *m = mask;
-	uint32_t crc0, crc1, crc2, crc3, crc4, crc5;
-
-	k0 = k[0] & m[0];
-	k2 = k[2] & m[2];
-	k5 = k[5] & m[5];
-
-	crc0 = k0;
-	_CRC32CX(crc0, seed);
-	crc1 = k0 >> 32;
-	_CRC32CX(crc1, k[1] & m[1]);
-
-	crc2 = k2;
-	_CRC32CX(crc2, k[3] & m[3]);
-	crc3 = k2 >> 32;
-	_CRC32CX(crc3, k[4] & m[4]);
-
-	crc4 = k5;
-	 _CRC32CX(crc4, k[6] & m[6]);
-	crc5 = k5 >> 32;
-
-	_CRC32CX(crc0, ((uint64_t)crc1 << 32) ^ crc2);
-	_CRC32CX(crc3, ((uint64_t)crc4 << 32) ^ crc5);
-
-	crc0 ^= crc3;
-
-	return crc0;
-}
-
-static inline uint64_t
-hash_crc_key64(void *key, void *mask, __rte_unused uint32_t key_size,
-	uint64_t seed)
-{
-	uint64_t *k = key, k0, k2, k5;
-	uint64_t *m = mask;
-	uint32_t crc0, crc1, crc2, crc3, crc4, crc5;
-
-	k0 = k[0] & m[0];
-	k2 = k[2] & m[2];
-	k5 = k[5] & m[5];
-
-	crc0 = k0;
-	_CRC32CX(crc0, seed);
-	crc1 = k0 >> 32;
-	_CRC32CX(crc1, k[1] & m[1]);
-
-	crc2 = k2;
-	_CRC32CX(crc2, k[3] & m[3]);
-	crc3 = k2 >> 32;
-	_CRC32CX(crc3, k[4] & m[4]);
-
-	crc4 = k5;
-	 _CRC32CX(crc4, k[6] & m[6]);
-	crc5 = k5 >> 32;
-	_CRC32CX(crc5, k[7] & m[7]);
-
-	_CRC32CX(crc0, ((uint64_t)crc1 << 32) ^ crc2);
-	_CRC32CX(crc3, ((uint64_t)crc4 << 32) ^ crc5);
-
-	crc0 ^= crc3;
-
-	return crc0;
-}
-
-#define hash_default_key8			hash_crc_key8
-#define hash_default_key16			hash_crc_key16
-#define hash_default_key24			hash_crc_key24
-#define hash_default_key32			hash_crc_key32
-#define hash_default_key40			hash_crc_key40
-#define hash_default_key48			hash_crc_key48
-#define hash_default_key56			hash_crc_key56
-#define hash_default_key64			hash_crc_key64
-
-#endif
diff --git a/examples/ip_pipeline/pipeline/pipeline_actions_common.h b/examples/ip_pipeline/pipeline/pipeline_actions_common.h
deleted file mode 100644
index 23f8836..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_actions_common.h
+++ /dev/null
@@ -1,202 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-#ifndef __INCLUDE_PIPELINE_ACTIONS_COMMON_H__
-#define __INCLUDE_PIPELINE_ACTIONS_COMMON_H__
-
-#include <stdint.h>
-
-#include <rte_common.h>
-#include <rte_cycles.h>
-#include <rte_mbuf.h>
-#include <rte_pipeline.h>
-
-#define PIPELINE_PORT_IN_AH(f_ah, f_pkt_work, f_pkt4_work)		\
-static int								\
-f_ah(									\
-	__rte_unused struct rte_pipeline *p,				\
-	struct rte_mbuf **pkts,						\
-	uint32_t n_pkts,						\
-	void *arg)							\
-{									\
-	uint32_t i;							\
-									\
-	for (i = 0; i < (n_pkts & (~0x3LLU)); i += 4)			\
-		f_pkt4_work(&pkts[i], arg);				\
-									\
-	for ( ; i < n_pkts; i++)					\
-		f_pkt_work(pkts[i], arg);				\
-									\
-	return 0;							\
-}
-
-#define PIPELINE_PORT_IN_AH_HIJACK_ALL(f_ah, f_pkt_work, f_pkt4_work) \
-static int								\
-f_ah(									\
-	struct rte_pipeline *p,				\
-	struct rte_mbuf **pkts,					\
-	uint32_t n_pkts,						\
-	void *arg)						\
-{									\
-	uint64_t pkt_mask = RTE_LEN2MASK(n_pkts, uint64_t);	\
-	uint32_t i;							\
-									\
-	rte_pipeline_ah_packet_hijack(p, pkt_mask);	\
-									\
-	for (i = 0; i < (n_pkts & (~0x3LLU)); i += 4)	\
-		f_pkt4_work(&pkts[i], arg);				\
-									\
-	for ( ; i < n_pkts; i++)				\
-		f_pkt_work(pkts[i], arg);			\
-									\
-	return 0;							\
-}
-
-#define PIPELINE_TABLE_AH_HIT(f_ah, f_pkt_work, f_pkt4_work)		\
-static int								\
-f_ah(									\
-	__rte_unused struct rte_pipeline *p,				\
-	struct rte_mbuf **pkts,						\
-	uint64_t pkts_in_mask,						\
-	struct rte_pipeline_table_entry **entries,			\
-	void *arg)							\
-{									\
-	if ((pkts_in_mask & (pkts_in_mask + 1)) == 0) {			\
-		uint64_t n_pkts = __builtin_popcountll(pkts_in_mask);	\
-		uint32_t i;						\
-									\
-		for (i = 0; i < (n_pkts & (~0x3LLU)); i += 4)		\
-			f_pkt4_work(&pkts[i], &entries[i], arg);	\
-									\
-		for ( ; i < n_pkts; i++)				\
-			f_pkt_work(pkts[i], entries[i], arg);		\
-	} else								\
-		for ( ; pkts_in_mask; ) {				\
-			uint32_t pos = __builtin_ctzll(pkts_in_mask);	\
-			uint64_t pkt_mask = 1LLU << pos;		\
-									\
-			pkts_in_mask &= ~pkt_mask;			\
-			f_pkt_work(pkts[pos], entries[pos], arg);	\
-		}							\
-									\
-	return 0;							\
-}
-
-#define PIPELINE_TABLE_AH_MISS(f_ah, f_pkt_work, f_pkt4_work)		\
-static int								\
-f_ah(									\
-	__rte_unused struct rte_pipeline *p,				\
-	struct rte_mbuf **pkts,						\
-	uint64_t pkts_in_mask,						\
-	struct rte_pipeline_table_entry *entry,				\
-	void *arg)							\
-{									\
-	if ((pkts_in_mask & (pkts_in_mask + 1)) == 0) {			\
-		uint64_t n_pkts = __builtin_popcountll(pkts_in_mask);	\
-		uint32_t i;						\
-									\
-		for (i = 0; i < (n_pkts & (~0x3LLU)); i += 4)		\
-			f_pkt4_work(&pkts[i], entry, arg);		\
-									\
-		for ( ; i < n_pkts; i++)				\
-			f_pkt_work(pkts[i], entry, arg);		\
-	} else								\
-		for ( ; pkts_in_mask; ) {				\
-			uint32_t pos = __builtin_ctzll(pkts_in_mask);	\
-			uint64_t pkt_mask = 1LLU << pos;		\
-									\
-			pkts_in_mask &= ~pkt_mask;			\
-			f_pkt_work(pkts[pos], entry, arg);		\
-		}							\
-									\
-	return 0;							\
-}
-
-#define PIPELINE_TABLE_AH_HIT_DROP_TIME(f_ah, f_pkt_work, f_pkt4_work)	\
-static int								\
-f_ah(									\
-	struct rte_pipeline *p,						\
-	struct rte_mbuf **pkts,						\
-	uint64_t pkts_mask,						\
-	struct rte_pipeline_table_entry **entries,			\
-	void *arg)							\
-{									\
-	uint64_t pkts_in_mask = pkts_mask;				\
-	uint64_t pkts_out_mask = pkts_mask;				\
-	uint64_t time = rte_rdtsc();					\
-									\
-	if ((pkts_in_mask & (pkts_in_mask + 1)) == 0) {			\
-		uint64_t n_pkts = __builtin_popcountll(pkts_in_mask);	\
-		uint32_t i;						\
-									\
-		for (i = 0; i < (n_pkts & (~0x3LLU)); i += 4) {		\
-			uint64_t mask = f_pkt4_work(&pkts[i],		\
-				&entries[i], arg, time);		\
-			pkts_out_mask ^= mask << i;			\
-		}							\
-									\
-		for ( ; i < n_pkts; i++) {				\
-			uint64_t mask = f_pkt_work(pkts[i],		\
-				entries[i], arg, time);			\
-			pkts_out_mask ^= mask << i;			\
-		}							\
-	} else								\
-		for ( ; pkts_in_mask; ) {				\
-			uint32_t pos = __builtin_ctzll(pkts_in_mask);	\
-			uint64_t pkt_mask = 1LLU << pos;		\
-			uint64_t mask = f_pkt_work(pkts[pos],		\
-				entries[pos], arg, time);		\
-									\
-			pkts_in_mask &= ~pkt_mask;			\
-			pkts_out_mask ^= mask << pos;			\
-		}							\
-									\
-	rte_pipeline_ah_packet_drop(p, pkts_out_mask ^ pkts_mask);	\
-									\
-	return 0;							\
-}
-
-#define PIPELINE_TABLE_AH_MISS_DROP_TIME(f_ah, f_pkt_work, f_pkt4_work)	\
-static int								\
-f_ah(									\
-	struct rte_pipeline *p,						\
-	struct rte_mbuf **pkts,						\
-	uint64_t pkts_mask,						\
-	struct rte_pipeline_table_entry *entry,				\
-	void *arg)							\
-{									\
-	uint64_t pkts_in_mask = pkts_mask;				\
-	uint64_t pkts_out_mask = pkts_mask;				\
-	uint64_t time = rte_rdtsc();					\
-									\
-	if ((pkts_in_mask & (pkts_in_mask + 1)) == 0) {			\
-		uint64_t n_pkts = __builtin_popcountll(pkts_in_mask);	\
-		uint32_t i;						\
-									\
-		for (i = 0; i < (n_pkts & (~0x3LLU)); i += 4) {		\
-			uint64_t mask = f_pkt4_work(&pkts[i],		\
-				entry, arg, time);			\
-			pkts_out_mask ^= mask << i;			\
-		}							\
-									\
-		for ( ; i < n_pkts; i++) {				\
-			uint64_t mask = f_pkt_work(pkts[i], entry, arg, time);\
-			pkts_out_mask ^= mask << i;			\
-		}							\
-	} else								\
-		for ( ; pkts_in_mask; ) {				\
-			uint32_t pos = __builtin_ctzll(pkts_in_mask);	\
-			uint64_t pkt_mask = 1LLU << pos;		\
-			uint64_t mask = f_pkt_work(pkts[pos],		\
-				entry, arg, time);		\
-									\
-			pkts_in_mask &= ~pkt_mask;			\
-			pkts_out_mask ^= mask << pos;			\
-		}							\
-									\
-	rte_pipeline_ah_packet_drop(p, pkts_out_mask ^ pkts_mask);	\
-									\
-	return 0;							\
-}
-
-#endif
diff --git a/examples/ip_pipeline/pipeline/pipeline_common_be.c b/examples/ip_pipeline/pipeline/pipeline_common_be.c
deleted file mode 100644
index 5d84989..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_common_be.c
+++ /dev/null
@@ -1,176 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#include <rte_common.h>
-#include <rte_malloc.h>
-
-#include "pipeline_common_be.h"
-
-void *
-pipeline_msg_req_ping_handler(__rte_unused struct pipeline *p,
-	void *msg)
-{
-	struct pipeline_msg_rsp *rsp = msg;
-
-	rsp->status = 0; /* OK */
-
-	return rsp;
-}
-
-void *
-pipeline_msg_req_stats_port_in_handler(struct pipeline *p,
-	void *msg)
-{
-	struct pipeline_stats_msg_req *req = msg;
-	struct pipeline_stats_port_in_msg_rsp *rsp = msg;
-	uint32_t port_id;
-
-	/* Check request */
-	if (req->id >= p->n_ports_in) {
-		rsp->status = -1;
-		return rsp;
-	}
-	port_id = p->port_in_id[req->id];
-
-	/* Process request */
-	rsp->status = rte_pipeline_port_in_stats_read(p->p,
-		port_id,
-		&rsp->stats,
-		1);
-
-	return rsp;
-}
-
-void *
-pipeline_msg_req_stats_port_out_handler(struct pipeline *p,
-	void *msg)
-{
-	struct pipeline_stats_msg_req *req = msg;
-	struct pipeline_stats_port_out_msg_rsp *rsp = msg;
-	uint32_t port_id;
-
-	/* Check request */
-	if (req->id >= p->n_ports_out) {
-		rsp->status = -1;
-		return rsp;
-	}
-	port_id = p->port_out_id[req->id];
-
-	/* Process request */
-	rsp->status = rte_pipeline_port_out_stats_read(p->p,
-		port_id,
-		&rsp->stats,
-		1);
-
-	return rsp;
-}
-
-void *
-pipeline_msg_req_stats_table_handler(struct pipeline *p,
-	void *msg)
-{
-	struct pipeline_stats_msg_req *req = msg;
-	struct pipeline_stats_table_msg_rsp *rsp = msg;
-	uint32_t table_id;
-
-	/* Check request */
-	if (req->id >= p->n_tables) {
-		rsp->status = -1;
-		return rsp;
-	}
-	table_id = p->table_id[req->id];
-
-	/* Process request */
-	rsp->status = rte_pipeline_table_stats_read(p->p,
-		table_id,
-		&rsp->stats,
-		1);
-
-	return rsp;
-}
-
-void *
-pipeline_msg_req_port_in_enable_handler(struct pipeline *p,
-	void *msg)
-{
-	struct pipeline_port_in_msg_req *req = msg;
-	struct pipeline_msg_rsp *rsp = msg;
-	uint32_t port_id;
-
-	/* Check request */
-	if (req->port_id >= p->n_ports_in) {
-		rsp->status = -1;
-		return rsp;
-	}
-	port_id = p->port_in_id[req->port_id];
-
-	/* Process request */
-	rsp->status = rte_pipeline_port_in_enable(p->p,
-		port_id);
-
-	return rsp;
-}
-
-void *
-pipeline_msg_req_port_in_disable_handler(struct pipeline *p,
-	void *msg)
-{
-	struct pipeline_port_in_msg_req *req = msg;
-	struct pipeline_msg_rsp *rsp = msg;
-	uint32_t port_id;
-
-	/* Check request */
-	if (req->port_id >= p->n_ports_in) {
-		rsp->status = -1;
-		return rsp;
-	}
-	port_id = p->port_in_id[req->port_id];
-
-	/* Process request */
-	rsp->status = rte_pipeline_port_in_disable(p->p,
-		port_id);
-
-	return rsp;
-}
-
-void *
-pipeline_msg_req_invalid_handler(__rte_unused struct pipeline *p,
-	void *msg)
-{
-	struct pipeline_msg_rsp *rsp = msg;
-
-	rsp->status = -1; /* Error */
-
-	return rsp;
-}
-
-int
-pipeline_msg_req_handle(struct pipeline *p)
-{
-	uint32_t msgq_id;
-
-	for (msgq_id = 0; msgq_id < p->n_msgq; msgq_id++) {
-		for ( ; ; ) {
-			struct pipeline_msg_req *req;
-			pipeline_msg_req_handler f_handle;
-
-			req = pipeline_msg_recv(p, msgq_id);
-			if (req == NULL)
-				break;
-
-			f_handle = (req->type < PIPELINE_MSG_REQS) ?
-				p->handlers[req->type] :
-				pipeline_msg_req_invalid_handler;
-
-			if (f_handle == NULL)
-				f_handle = pipeline_msg_req_invalid_handler;
-
-			pipeline_msg_send(p,
-				msgq_id,
-				f_handle(p, (void *) req));
-		}
-	}
-
-	return 0;
-}
diff --git a/examples/ip_pipeline/pipeline/pipeline_common_be.h b/examples/ip_pipeline/pipeline/pipeline_common_be.h
deleted file mode 100644
index 83bd04e..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_common_be.h
+++ /dev/null
@@ -1,134 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#ifndef __INCLUDE_PIPELINE_COMMON_BE_H__
-#define __INCLUDE_PIPELINE_COMMON_BE_H__
-
-#include <rte_common.h>
-#include <rte_ring.h>
-#include <rte_pipeline.h>
-
-#include "pipeline_be.h"
-
-struct pipeline;
-
-enum pipeline_msg_req_type {
-	PIPELINE_MSG_REQ_PING = 0,
-	PIPELINE_MSG_REQ_STATS_PORT_IN,
-	PIPELINE_MSG_REQ_STATS_PORT_OUT,
-	PIPELINE_MSG_REQ_STATS_TABLE,
-	PIPELINE_MSG_REQ_PORT_IN_ENABLE,
-	PIPELINE_MSG_REQ_PORT_IN_DISABLE,
-	PIPELINE_MSG_REQ_CUSTOM,
-	PIPELINE_MSG_REQS
-};
-
-typedef void *(*pipeline_msg_req_handler)(struct pipeline *p, void *msg);
-
-struct pipeline {
-	struct rte_pipeline *p;
-	uint32_t port_in_id[PIPELINE_MAX_PORT_IN];
-	uint32_t port_out_id[PIPELINE_MAX_PORT_OUT];
-	uint32_t table_id[PIPELINE_MAX_TABLES];
-	struct rte_ring *msgq_in[PIPELINE_MAX_MSGQ_IN];
-	struct rte_ring *msgq_out[PIPELINE_MAX_MSGQ_OUT];
-
-	uint32_t n_ports_in;
-	uint32_t n_ports_out;
-	uint32_t n_tables;
-	uint32_t n_msgq;
-
-	pipeline_msg_req_handler handlers[PIPELINE_MSG_REQS];
-	char name[PIPELINE_NAME_SIZE];
-	uint32_t log_level;
-};
-
-enum pipeline_log_level {
-	PIPELINE_LOG_LEVEL_HIGH = 1,
-	PIPELINE_LOG_LEVEL_LOW,
-	PIPELINE_LOG_LEVELS
-};
-
-#define PLOG(p, level, fmt, ...)					\
-do {									\
-	if (p->log_level >= PIPELINE_LOG_LEVEL_ ## level)		\
-		fprintf(stdout, "[%s] " fmt "\n", p->name, ## __VA_ARGS__);\
-} while (0)
-
-static inline void *
-pipeline_msg_recv(struct pipeline *p,
-	uint32_t msgq_id)
-{
-	struct rte_ring *r = p->msgq_in[msgq_id];
-	void *msg;
-	int status = rte_ring_sc_dequeue(r, &msg);
-
-	if (status != 0)
-		return NULL;
-
-	return msg;
-}
-
-static inline void
-pipeline_msg_send(struct pipeline *p,
-	uint32_t msgq_id,
-	void *msg)
-{
-	struct rte_ring *r = p->msgq_out[msgq_id];
-	int status;
-
-	do {
-		status = rte_ring_sp_enqueue(r, msg);
-	} while (status == -ENOBUFS);
-}
-
-struct pipeline_msg_req {
-	enum pipeline_msg_req_type type;
-};
-
-struct pipeline_stats_msg_req {
-	enum pipeline_msg_req_type type;
-	uint32_t id;
-};
-
-struct pipeline_port_in_msg_req {
-	enum pipeline_msg_req_type type;
-	uint32_t port_id;
-};
-
-struct pipeline_custom_msg_req {
-	enum pipeline_msg_req_type type;
-	uint32_t subtype;
-};
-
-struct pipeline_msg_rsp {
-	int status;
-};
-
-struct pipeline_stats_port_in_msg_rsp {
-	int status;
-	struct rte_pipeline_port_in_stats stats;
-};
-
-struct pipeline_stats_port_out_msg_rsp {
-	int status;
-	struct rte_pipeline_port_out_stats stats;
-};
-
-struct pipeline_stats_table_msg_rsp {
-	int status;
-	struct rte_pipeline_table_stats stats;
-};
-
-void *pipeline_msg_req_ping_handler(struct pipeline *p, void *msg);
-void *pipeline_msg_req_stats_port_in_handler(struct pipeline *p, void *msg);
-void *pipeline_msg_req_stats_port_out_handler(struct pipeline *p, void *msg);
-void *pipeline_msg_req_stats_table_handler(struct pipeline *p, void *msg);
-void *pipeline_msg_req_port_in_enable_handler(struct pipeline *p, void *msg);
-void *pipeline_msg_req_port_in_disable_handler(struct pipeline *p, void *msg);
-void *pipeline_msg_req_invalid_handler(struct pipeline *p, void *msg);
-
-int pipeline_msg_req_handle(struct pipeline *p);
-
-#endif
diff --git a/examples/ip_pipeline/pipeline/pipeline_common_fe.c b/examples/ip_pipeline/pipeline/pipeline_common_fe.c
deleted file mode 100644
index cc5214c..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_common_fe.c
+++ /dev/null
@@ -1,1455 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#include <stdio.h>
-#include <fcntl.h>
-#include <unistd.h>
-
-#include <rte_common.h>
-#include <rte_malloc.h>
-#include <cmdline_rdline.h>
-#include <cmdline_parse.h>
-#include <cmdline_parse_num.h>
-#include <cmdline_parse_string.h>
-#include <cmdline.h>
-
-#include "pipeline_common_fe.h"
-#include "parser.h"
-
-struct app_link_params *
-app_pipeline_track_pktq_out_to_link(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t pktq_out_id)
-{
-	struct app_pipeline_params *p;
-
-	/* Check input arguments */
-	if (app == NULL)
-		return NULL;
-
-	APP_PARAM_FIND_BY_ID(app->pipeline_params, "PIPELINE", pipeline_id, p);
-	if (p == NULL)
-		return NULL;
-
-	for ( ; ; ) {
-		struct app_pktq_out_params *pktq_out =
-			&p->pktq_out[pktq_out_id];
-
-		switch (pktq_out->type) {
-		case APP_PKTQ_OUT_HWQ:
-		{
-			struct app_pktq_hwq_out_params *hwq_out;
-
-			hwq_out = &app->hwq_out_params[pktq_out->id];
-
-			return app_get_link_for_txq(app, hwq_out);
-		}
-
-		case APP_PKTQ_OUT_SWQ:
-		{
-			struct pipeline_params pp;
-			struct pipeline_type *ptype;
-			struct app_pktq_swq_params *swq;
-			uint32_t pktq_in_id;
-			int status;
-
-			swq = &app->swq_params[pktq_out->id];
-			p = app_swq_get_reader(app, swq, &pktq_in_id);
-			if (p == NULL)
-				return NULL;
-
-			ptype = app_pipeline_type_find(app, p->type);
-			if ((ptype == NULL) || (ptype->fe_ops->f_track == NULL))
-				return NULL;
-
-			app_pipeline_params_get(app, p, &pp);
-			status = ptype->fe_ops->f_track(&pp,
-				pktq_in_id,
-				&pktq_out_id);
-			if (status)
-				return NULL;
-
-			break;
-		}
-
-		case APP_PKTQ_OUT_TM:
-		{
-			struct pipeline_params pp;
-			struct pipeline_type *ptype;
-			struct app_pktq_tm_params *tm;
-			uint32_t pktq_in_id;
-			int status;
-
-			tm = &app->tm_params[pktq_out->id];
-			p = app_tm_get_reader(app, tm, &pktq_in_id);
-			if (p == NULL)
-				return NULL;
-
-			ptype = app_pipeline_type_find(app, p->type);
-			if ((ptype == NULL) || (ptype->fe_ops->f_track == NULL))
-				return NULL;
-
-			app_pipeline_params_get(app, p, &pp);
-			status = ptype->fe_ops->f_track(&pp,
-				pktq_in_id,
-				&pktq_out_id);
-			if (status)
-				return NULL;
-
-			break;
-		}
-
-		case APP_PKTQ_OUT_KNI:
-		{
-			struct pipeline_params pp;
-			struct pipeline_type *ptype;
-			struct app_pktq_kni_params *kni;
-			uint32_t pktq_in_id;
-			int status;
-
-			kni = &app->kni_params[pktq_out->id];
-			p = app_kni_get_reader(app, kni, &pktq_in_id);
-			if (p == NULL)
-				return NULL;
-
-			ptype = app_pipeline_type_find(app, p->type);
-			if ((ptype == NULL) || (ptype->fe_ops->f_track == NULL))
-				return NULL;
-
-			app_pipeline_params_get(app, p, &pp);
-			status = ptype->fe_ops->f_track(&pp,
-				pktq_in_id,
-				&pktq_out_id);
-			if (status)
-				return NULL;
-
-			break;
-		}
-
-		case APP_PKTQ_OUT_TAP:
-		case APP_PKTQ_OUT_SINK:
-		default:
-			return NULL;
-		}
-	}
-}
-
-int
-app_pipeline_track_default(struct pipeline_params *p,
-	uint32_t port_in,
-	uint32_t *port_out)
-{
-	/* Check input arguments */
-	if ((p == NULL) ||
-		(port_in >= p->n_ports_in) ||
-		(port_out == NULL))
-		return -1;
-
-	if (p->n_ports_out == 1) {
-		*port_out = 0;
-		return 0;
-	}
-
-	return -1;
-}
-
-int
-app_pipeline_ping(struct app_params *app,
-	uint32_t pipeline_id)
-{
-	struct app_pipeline_params *p;
-	struct pipeline_msg_req *req;
-	struct pipeline_msg_rsp *rsp;
-	int status = 0;
-
-	/* Check input arguments */
-	if (app == NULL)
-		return -1;
-
-	APP_PARAM_FIND_BY_ID(app->pipeline_params, "PIPELINE", pipeline_id, p);
-	if (p == NULL)
-		return -1;
-
-	/* Message buffer allocation */
-	req = app_msg_alloc(app);
-	if (req == NULL)
-		return -1;
-
-	/* Fill in request */
-	req->type = PIPELINE_MSG_REQ_PING;
-
-	/* Send request and wait for response */
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL)
-		return -1;
-
-	/* Check response */
-	status = rsp->status;
-
-	/* Message buffer free */
-	app_msg_free(app, rsp);
-
-	return status;
-}
-
-int
-app_pipeline_stats_port_in(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t port_id,
-	struct rte_pipeline_port_in_stats *stats)
-{
-	struct app_pipeline_params *p;
-	struct pipeline_stats_msg_req *req;
-	struct pipeline_stats_port_in_msg_rsp *rsp;
-	int status = 0;
-
-	/* Check input arguments */
-	if ((app == NULL) ||
-		(stats == NULL))
-		return -1;
-
-	APP_PARAM_FIND_BY_ID(app->pipeline_params, "PIPELINE", pipeline_id, p);
-	if ((p == NULL) ||
-		(port_id >= p->n_pktq_in))
-		return -1;
-
-	/* Message buffer allocation */
-	req = app_msg_alloc(app);
-	if (req == NULL)
-		return -1;
-
-	/* Fill in request */
-	req->type = PIPELINE_MSG_REQ_STATS_PORT_IN;
-	req->id = port_id;
-
-	/* Send request and wait for response */
-	rsp = (struct pipeline_stats_port_in_msg_rsp *)
-		app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL)
-		return -1;
-
-	/* Check response */
-	status = rsp->status;
-	if (status == 0)
-		memcpy(stats, &rsp->stats, sizeof(rsp->stats));
-
-	/* Message buffer free */
-	app_msg_free(app, rsp);
-
-	return status;
-}
-
-int
-app_pipeline_stats_port_out(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t port_id,
-	struct rte_pipeline_port_out_stats *stats)
-{
-	struct app_pipeline_params *p;
-	struct pipeline_stats_msg_req *req;
-	struct pipeline_stats_port_out_msg_rsp *rsp;
-	int status = 0;
-
-	/* Check input arguments */
-	if ((app == NULL) ||
-		(pipeline_id >= app->n_pipelines) ||
-		(stats == NULL))
-		return -1;
-
-	APP_PARAM_FIND_BY_ID(app->pipeline_params, "PIPELINE", pipeline_id, p);
-	if ((p == NULL) ||
-		(port_id >= p->n_pktq_out))
-		return -1;
-
-	/* Message buffer allocation */
-	req = app_msg_alloc(app);
-	if (req == NULL)
-		return -1;
-
-	/* Fill in request */
-	req->type = PIPELINE_MSG_REQ_STATS_PORT_OUT;
-	req->id = port_id;
-
-	/* Send request and wait for response */
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL)
-		return -1;
-
-	/* Check response */
-	status = rsp->status;
-	if (status == 0)
-		memcpy(stats, &rsp->stats, sizeof(rsp->stats));
-
-	/* Message buffer free */
-	app_msg_free(app, rsp);
-
-	return status;
-}
-
-int
-app_pipeline_stats_table(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t table_id,
-	struct rte_pipeline_table_stats *stats)
-{
-	struct app_pipeline_params *p;
-	struct pipeline_stats_msg_req *req;
-	struct pipeline_stats_table_msg_rsp *rsp;
-	int status = 0;
-
-	/* Check input arguments */
-	if ((app == NULL) ||
-		(stats == NULL))
-		return -1;
-
-	APP_PARAM_FIND_BY_ID(app->pipeline_params, "PIPELINE", pipeline_id, p);
-	if (p == NULL)
-		return -1;
-
-	/* Message buffer allocation */
-	req = app_msg_alloc(app);
-	if (req == NULL)
-		return -1;
-
-	/* Fill in request */
-	req->type = PIPELINE_MSG_REQ_STATS_TABLE;
-	req->id = table_id;
-
-	/* Send request and wait for response */
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL)
-		return -1;
-
-	/* Check response */
-	status = rsp->status;
-	if (status == 0)
-		memcpy(stats, &rsp->stats, sizeof(rsp->stats));
-
-	/* Message buffer free */
-	app_msg_free(app, rsp);
-
-	return status;
-}
-
-int
-app_pipeline_port_in_enable(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t port_id)
-{
-	struct app_pipeline_params *p;
-	struct pipeline_port_in_msg_req *req;
-	struct pipeline_msg_rsp *rsp;
-	int status = 0;
-
-	/* Check input arguments */
-	if (app == NULL)
-		return -1;
-
-	APP_PARAM_FIND_BY_ID(app->pipeline_params, "PIPELINE", pipeline_id, p);
-	if ((p == NULL) ||
-		(port_id >= p->n_pktq_in))
-		return -1;
-
-	/* Message buffer allocation */
-	req = app_msg_alloc(app);
-	if (req == NULL)
-		return -1;
-
-	/* Fill in request */
-	req->type = PIPELINE_MSG_REQ_PORT_IN_ENABLE;
-	req->port_id = port_id;
-
-	/* Send request and wait for response */
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL)
-		return -1;
-
-	/* Check response */
-	status = rsp->status;
-
-	/* Message buffer free */
-	app_msg_free(app, rsp);
-
-	return status;
-}
-
-int
-app_pipeline_port_in_disable(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t port_id)
-{
-	struct app_pipeline_params *p;
-	struct pipeline_port_in_msg_req *req;
-	struct pipeline_msg_rsp *rsp;
-	int status = 0;
-
-	/* Check input arguments */
-	if (app == NULL)
-		return -1;
-
-	APP_PARAM_FIND_BY_ID(app->pipeline_params, "PIPELINE", pipeline_id, p);
-	if ((p == NULL) ||
-		(port_id >= p->n_pktq_in))
-		return -1;
-
-	/* Message buffer allocation */
-	req = app_msg_alloc(app);
-	if (req == NULL)
-		return -1;
-
-	/* Fill in request */
-	req->type = PIPELINE_MSG_REQ_PORT_IN_DISABLE;
-	req->port_id = port_id;
-
-	/* Send request and wait for response */
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL)
-		return -1;
-
-	/* Check response */
-	status = rsp->status;
-
-	/* Message buffer free */
-	app_msg_free(app, rsp);
-
-	return status;
-}
-
-int
-app_link_set_op(struct app_params *app,
-	uint32_t link_id,
-	uint32_t pipeline_id,
-	app_link_op op,
-	void *arg)
-{
-	struct app_pipeline_params *pp;
-	struct app_link_params *lp;
-	struct app_link_data *ld;
-	uint32_t ppos, lpos;
-
-	/* Check input arguments */
-	if ((app == NULL) ||
-		(op == NULL))
-		return -1;
-
-	APP_PARAM_FIND_BY_ID(app->link_params, "LINK", link_id, lp);
-	if (lp == NULL)
-		return -1;
-	lpos = lp - app->link_params;
-	ld = &app->link_data[lpos];
-
-	APP_PARAM_FIND_BY_ID(app->pipeline_params, "PIPELINE", pipeline_id, pp);
-	if (pp == NULL)
-		return -1;
-	ppos = pp - app->pipeline_params;
-
-	ld->f_link[ppos] = op;
-	ld->arg[ppos] = arg;
-
-	return 0;
-}
-
-int
-app_link_config(struct app_params *app,
-	uint32_t link_id,
-	uint32_t ip,
-	uint32_t depth)
-{
-	struct app_link_params *p;
-	uint32_t i, netmask, host, bcast;
-
-	/* Check input arguments */
-	if (app == NULL)
-		return -1;
-
-	APP_PARAM_FIND_BY_ID(app->link_params, "LINK", link_id, p);
-	if (p == NULL) {
-		APP_LOG(app, HIGH, "LINK%" PRIu32 " is not a valid link",
-			link_id);
-		return -1;
-	}
-
-	if (p->state) {
-		APP_LOG(app, HIGH, "%s is UP, please bring it DOWN first",
-			p->name);
-		return -1;
-	}
-
-	netmask = (~0U) << (32 - depth);
-	host = ip & netmask;
-	bcast = host | (~netmask);
-
-	if ((ip == 0) ||
-		(ip == UINT32_MAX) ||
-		(ip == host) ||
-		(ip == bcast)) {
-		APP_LOG(app, HIGH, "Illegal IP address");
-		return -1;
-	}
-
-	for (i = 0; i < app->n_links; i++) {
-		struct app_link_params *link = &app->link_params[i];
-
-		if (strcmp(p->name, link->name) == 0)
-			continue;
-
-		if (link->ip == ip) {
-			APP_LOG(app, HIGH,
-				"%s is already assigned this IP address",
-				link->name);
-			return -1;
-		}
-	}
-
-	if ((depth == 0) || (depth > 32)) {
-		APP_LOG(app, HIGH, "Illegal value for depth parameter "
-			"(%" PRIu32 ")",
-			depth);
-		return -1;
-	}
-
-	/* Save link parameters */
-	p->ip = ip;
-	p->depth = depth;
-
-	return 0;
-}
-
-int
-app_link_up(struct app_params *app,
-	uint32_t link_id)
-{
-	struct app_link_params *p;
-	struct app_link_data *d;
-	int i;
-
-	/* Check input arguments */
-	if (app == NULL)
-		return -1;
-
-	APP_PARAM_FIND_BY_ID(app->link_params, "LINK", link_id, p);
-	if (p == NULL) {
-		APP_LOG(app, HIGH, "LINK%" PRIu32 " is not a valid link",
-			link_id);
-		return -1;
-	}
-
-	d = &app->link_data[p - app->link_params];
-
-	/* Check link state */
-	if (p->state) {
-		APP_LOG(app, HIGH, "%s is already UP", p->name);
-		return 0;
-	}
-
-	/* Check that IP address is valid */
-	if (p->ip == 0) {
-		APP_LOG(app, HIGH, "%s IP address is not set", p->name);
-		return 0;
-	}
-
-	app_link_up_internal(app, p);
-
-	/* Callbacks */
-	for (i = 0; i < APP_MAX_PIPELINES; i++)
-		if (d->f_link[i])
-			d->f_link[i](app, link_id, 1, d->arg[i]);
-
-	return 0;
-}
-
-int
-app_link_down(struct app_params *app,
-	uint32_t link_id)
-{
-	struct app_link_params *p;
-	struct app_link_data *d;
-	uint32_t i;
-
-	/* Check input arguments */
-	if (app == NULL)
-		return -1;
-
-	APP_PARAM_FIND_BY_ID(app->link_params, "LINK", link_id, p);
-	if (p == NULL) {
-		APP_LOG(app, HIGH, "LINK%" PRIu32 " is not a valid link",
-			link_id);
-		return -1;
-	}
-
-	d = &app->link_data[p - app->link_params];
-
-	/* Check link state */
-	if (p->state == 0) {
-		APP_LOG(app, HIGH, "%s is already DOWN", p->name);
-		return 0;
-	}
-
-	app_link_down_internal(app, p);
-
-	/* Callbacks */
-	for (i = 0; i < APP_MAX_PIPELINES; i++)
-		if (d->f_link[i])
-			d->f_link[i](app, link_id, 0, d->arg[i]);
-
-	return 0;
-}
-
-/*
- * ping
- */
-
-struct cmd_ping_result {
-	cmdline_fixed_string_t p_string;
-	uint32_t pipeline_id;
-	cmdline_fixed_string_t ping_string;
-};
-
-static void
-cmd_ping_parsed(
-	void *parsed_result,
-	__rte_unused struct cmdline *cl,
-	void *data)
-{
-	struct cmd_ping_result *params = parsed_result;
-	struct app_params *app = data;
-	int status;
-
-	status = app_pipeline_ping(app,	params->pipeline_id);
-	if (status != 0)
-		printf("Command failed\n");
-}
-
-static cmdline_parse_token_string_t cmd_ping_p_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_ping_result, p_string, "p");
-
-static cmdline_parse_token_num_t cmd_ping_pipeline_id =
-	TOKEN_NUM_INITIALIZER(struct cmd_ping_result, pipeline_id, UINT32);
-
-static cmdline_parse_token_string_t cmd_ping_ping_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_ping_result, ping_string, "ping");
-
-static cmdline_parse_inst_t cmd_ping = {
-	.f = cmd_ping_parsed,
-	.data = NULL,
-	.help_str = "Pipeline ping",
-	.tokens = {
-		(void *) &cmd_ping_p_string,
-		(void *) &cmd_ping_pipeline_id,
-		(void *) &cmd_ping_ping_string,
-		NULL,
-	},
-};
-
-/*
- * stats port in
- */
-
-struct cmd_stats_port_in_result {
-	cmdline_fixed_string_t p_string;
-	uint32_t pipeline_id;
-	cmdline_fixed_string_t stats_string;
-	cmdline_fixed_string_t port_string;
-	cmdline_fixed_string_t in_string;
-	uint32_t port_in_id;
-
-};
-
-static void
-cmd_stats_port_in_parsed(
-	void *parsed_result,
-	__rte_unused struct cmdline *cl,
-	void *data)
-{
-	struct cmd_stats_port_in_result *params = parsed_result;
-	struct app_params *app = data;
-	struct rte_pipeline_port_in_stats stats;
-	int status;
-
-	status = app_pipeline_stats_port_in(app,
-			params->pipeline_id,
-			params->port_in_id,
-			&stats);
-
-	if (status != 0) {
-		printf("Command failed\n");
-		return;
-	}
-
-	/* Display stats */
-	printf("Pipeline %" PRIu32 " - stats for input port %" PRIu32 ":\n"
-		"\tPkts in: %" PRIu64 "\n"
-		"\tPkts dropped by AH: %" PRIu64 "\n"
-		"\tPkts dropped by other: %" PRIu64 "\n",
-		params->pipeline_id,
-		params->port_in_id,
-		stats.stats.n_pkts_in,
-		stats.n_pkts_dropped_by_ah,
-		stats.stats.n_pkts_drop);
-}
-
-static cmdline_parse_token_string_t cmd_stats_port_in_p_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_stats_port_in_result, p_string,
-		"p");
-
-static cmdline_parse_token_num_t cmd_stats_port_in_pipeline_id =
-	TOKEN_NUM_INITIALIZER(struct cmd_stats_port_in_result, pipeline_id,
-		UINT32);
-
-static cmdline_parse_token_string_t cmd_stats_port_in_stats_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_stats_port_in_result, stats_string,
-		"stats");
-
-static cmdline_parse_token_string_t cmd_stats_port_in_port_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_stats_port_in_result, port_string,
-		"port");
-
-static cmdline_parse_token_string_t cmd_stats_port_in_in_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_stats_port_in_result, in_string,
-		"in");
-
-	cmdline_parse_token_num_t cmd_stats_port_in_port_in_id =
-	TOKEN_NUM_INITIALIZER(struct cmd_stats_port_in_result, port_in_id,
-		UINT32);
-
-static cmdline_parse_inst_t cmd_stats_port_in = {
-	.f = cmd_stats_port_in_parsed,
-	.data = NULL,
-	.help_str = "Pipeline input port stats",
-	.tokens = {
-		(void *) &cmd_stats_port_in_p_string,
-		(void *) &cmd_stats_port_in_pipeline_id,
-		(void *) &cmd_stats_port_in_stats_string,
-		(void *) &cmd_stats_port_in_port_string,
-		(void *) &cmd_stats_port_in_in_string,
-		(void *) &cmd_stats_port_in_port_in_id,
-		NULL,
-	},
-};
-
-/*
- * stats port out
- */
-
-struct cmd_stats_port_out_result {
-	cmdline_fixed_string_t p_string;
-	uint32_t pipeline_id;
-	cmdline_fixed_string_t stats_string;
-	cmdline_fixed_string_t port_string;
-	cmdline_fixed_string_t out_string;
-	uint32_t port_out_id;
-};
-
-static void
-cmd_stats_port_out_parsed(
-	void *parsed_result,
-	__rte_unused struct cmdline *cl,
-	void *data)
-{
-
-	struct cmd_stats_port_out_result *params = parsed_result;
-	struct app_params *app = data;
-	struct rte_pipeline_port_out_stats stats;
-	int status;
-
-	status = app_pipeline_stats_port_out(app,
-			params->pipeline_id,
-			params->port_out_id,
-			&stats);
-
-	if (status != 0) {
-		printf("Command failed\n");
-		return;
-	}
-
-	/* Display stats */
-	printf("Pipeline %" PRIu32 " - stats for output port %" PRIu32 ":\n"
-		"\tPkts in: %" PRIu64 "\n"
-		"\tPkts dropped by AH: %" PRIu64 "\n"
-		"\tPkts dropped by other: %" PRIu64 "\n",
-		params->pipeline_id,
-		params->port_out_id,
-		stats.stats.n_pkts_in,
-		stats.n_pkts_dropped_by_ah,
-		stats.stats.n_pkts_drop);
-}
-
-static cmdline_parse_token_string_t cmd_stats_port_out_p_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_stats_port_out_result, p_string,
-	"p");
-
-static cmdline_parse_token_num_t cmd_stats_port_out_pipeline_id =
-	TOKEN_NUM_INITIALIZER(struct cmd_stats_port_out_result, pipeline_id,
-		UINT32);
-
-static cmdline_parse_token_string_t cmd_stats_port_out_stats_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_stats_port_out_result, stats_string,
-		"stats");
-
-static cmdline_parse_token_string_t cmd_stats_port_out_port_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_stats_port_out_result, port_string,
-		"port");
-
-static cmdline_parse_token_string_t cmd_stats_port_out_out_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_stats_port_out_result, out_string,
-		"out");
-
-static cmdline_parse_token_num_t cmd_stats_port_out_port_out_id =
-	TOKEN_NUM_INITIALIZER(struct cmd_stats_port_out_result, port_out_id,
-		UINT32);
-
-static cmdline_parse_inst_t cmd_stats_port_out = {
-	.f = cmd_stats_port_out_parsed,
-	.data = NULL,
-	.help_str = "Pipeline output port stats",
-	.tokens = {
-		(void *) &cmd_stats_port_out_p_string,
-		(void *) &cmd_stats_port_out_pipeline_id,
-		(void *) &cmd_stats_port_out_stats_string,
-		(void *) &cmd_stats_port_out_port_string,
-		(void *) &cmd_stats_port_out_out_string,
-		(void *) &cmd_stats_port_out_port_out_id,
-		NULL,
-	},
-};
-
-/*
- * stats table
- */
-
-struct cmd_stats_table_result {
-	cmdline_fixed_string_t p_string;
-	uint32_t pipeline_id;
-	cmdline_fixed_string_t stats_string;
-	cmdline_fixed_string_t table_string;
-	uint32_t table_id;
-};
-
-static void
-cmd_stats_table_parsed(
-	void *parsed_result,
-	__rte_unused struct cmdline *cl,
-	void *data)
-{
-	struct cmd_stats_table_result *params = parsed_result;
-	struct app_params *app = data;
-	struct rte_pipeline_table_stats stats;
-	int status;
-
-	status = app_pipeline_stats_table(app,
-			params->pipeline_id,
-			params->table_id,
-			&stats);
-
-	if (status != 0) {
-		printf("Command failed\n");
-		return;
-	}
-
-	/* Display stats */
-	printf("Pipeline %" PRIu32 " - stats for table %" PRIu32 ":\n"
-		"\tPkts in: %" PRIu64 "\n"
-		"\tPkts in with lookup miss: %" PRIu64 "\n"
-		"\tPkts in with lookup hit dropped by AH: %" PRIu64 "\n"
-		"\tPkts in with lookup hit dropped by others: %" PRIu64 "\n"
-		"\tPkts in with lookup miss dropped by AH: %" PRIu64 "\n"
-		"\tPkts in with lookup miss dropped by others: %" PRIu64 "\n",
-		params->pipeline_id,
-		params->table_id,
-		stats.stats.n_pkts_in,
-		stats.stats.n_pkts_lookup_miss,
-		stats.n_pkts_dropped_by_lkp_hit_ah,
-		stats.n_pkts_dropped_lkp_hit,
-		stats.n_pkts_dropped_by_lkp_miss_ah,
-		stats.n_pkts_dropped_lkp_miss);
-}
-
-static cmdline_parse_token_string_t cmd_stats_table_p_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_stats_table_result, p_string,
-		"p");
-
-static cmdline_parse_token_num_t cmd_stats_table_pipeline_id =
-	TOKEN_NUM_INITIALIZER(struct cmd_stats_table_result, pipeline_id,
-		UINT32);
-
-static cmdline_parse_token_string_t cmd_stats_table_stats_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_stats_table_result, stats_string,
-		"stats");
-
-static cmdline_parse_token_string_t cmd_stats_table_table_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_stats_table_result, table_string,
-		"table");
-
-static cmdline_parse_token_num_t cmd_stats_table_table_id =
-	TOKEN_NUM_INITIALIZER(struct cmd_stats_table_result, table_id, UINT32);
-
-static cmdline_parse_inst_t cmd_stats_table = {
-	.f = cmd_stats_table_parsed,
-	.data = NULL,
-	.help_str = "Pipeline table stats",
-	.tokens = {
-		(void *) &cmd_stats_table_p_string,
-		(void *) &cmd_stats_table_pipeline_id,
-		(void *) &cmd_stats_table_stats_string,
-		(void *) &cmd_stats_table_table_string,
-		(void *) &cmd_stats_table_table_id,
-		NULL,
-	},
-};
-
-/*
- * port in enable
- */
-
-struct cmd_port_in_enable_result {
-	cmdline_fixed_string_t p_string;
-	uint32_t pipeline_id;
-	cmdline_fixed_string_t port_string;
-	cmdline_fixed_string_t in_string;
-	uint32_t port_in_id;
-	cmdline_fixed_string_t enable_string;
-};
-
-static void
-cmd_port_in_enable_parsed(
-	void *parsed_result,
-	__rte_unused struct cmdline *cl,
-	void *data)
-{
-	struct cmd_port_in_enable_result *params = parsed_result;
-	struct app_params *app = data;
-	int status;
-
-	status = app_pipeline_port_in_enable(app,
-			params->pipeline_id,
-			params->port_in_id);
-
-	if (status != 0)
-		printf("Command failed\n");
-}
-
-static cmdline_parse_token_string_t cmd_port_in_enable_p_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_port_in_enable_result, p_string,
-		"p");
-
-static cmdline_parse_token_num_t cmd_port_in_enable_pipeline_id =
-	TOKEN_NUM_INITIALIZER(struct cmd_port_in_enable_result, pipeline_id,
-		UINT32);
-
-static cmdline_parse_token_string_t cmd_port_in_enable_port_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_port_in_enable_result, port_string,
-	"port");
-
-static cmdline_parse_token_string_t cmd_port_in_enable_in_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_port_in_enable_result, in_string,
-		"in");
-
-static cmdline_parse_token_num_t cmd_port_in_enable_port_in_id =
-	TOKEN_NUM_INITIALIZER(struct cmd_port_in_enable_result, port_in_id,
-		UINT32);
-
-static cmdline_parse_token_string_t cmd_port_in_enable_enable_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_port_in_enable_result,
-		enable_string, "enable");
-
-static cmdline_parse_inst_t cmd_port_in_enable = {
-	.f = cmd_port_in_enable_parsed,
-	.data = NULL,
-	.help_str = "Pipeline input port enable",
-	.tokens = {
-		(void *) &cmd_port_in_enable_p_string,
-		(void *) &cmd_port_in_enable_pipeline_id,
-		(void *) &cmd_port_in_enable_port_string,
-		(void *) &cmd_port_in_enable_in_string,
-		(void *) &cmd_port_in_enable_port_in_id,
-		(void *) &cmd_port_in_enable_enable_string,
-		NULL,
-	},
-};
-
-/*
- * port in disable
- */
-
-struct cmd_port_in_disable_result {
-	cmdline_fixed_string_t p_string;
-	uint32_t pipeline_id;
-	cmdline_fixed_string_t port_string;
-	cmdline_fixed_string_t in_string;
-	uint32_t port_in_id;
-	cmdline_fixed_string_t disable_string;
-};
-
-static void
-cmd_port_in_disable_parsed(
-	void *parsed_result,
-	__rte_unused struct cmdline *cl,
-	void *data)
-{
-	struct cmd_port_in_disable_result *params = parsed_result;
-	struct app_params *app = data;
-	int status;
-
-	status = app_pipeline_port_in_disable(app,
-			params->pipeline_id,
-			params->port_in_id);
-
-	if (status != 0)
-		printf("Command failed\n");
-}
-
-static cmdline_parse_token_string_t cmd_port_in_disable_p_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_port_in_disable_result, p_string,
-		"p");
-
-static cmdline_parse_token_num_t cmd_port_in_disable_pipeline_id =
-	TOKEN_NUM_INITIALIZER(struct cmd_port_in_disable_result, pipeline_id,
-		UINT32);
-
-static cmdline_parse_token_string_t cmd_port_in_disable_port_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_port_in_disable_result, port_string,
-		"port");
-
-static cmdline_parse_token_string_t cmd_port_in_disable_in_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_port_in_disable_result, in_string,
-		"in");
-
-static cmdline_parse_token_num_t cmd_port_in_disable_port_in_id =
-	TOKEN_NUM_INITIALIZER(struct cmd_port_in_disable_result, port_in_id,
-		UINT32);
-
-static cmdline_parse_token_string_t cmd_port_in_disable_disable_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_port_in_disable_result,
-		disable_string, "disable");
-
-static cmdline_parse_inst_t cmd_port_in_disable = {
-	.f = cmd_port_in_disable_parsed,
-	.data = NULL,
-	.help_str = "Pipeline input port disable",
-	.tokens = {
-		(void *) &cmd_port_in_disable_p_string,
-		(void *) &cmd_port_in_disable_pipeline_id,
-		(void *) &cmd_port_in_disable_port_string,
-		(void *) &cmd_port_in_disable_in_string,
-		(void *) &cmd_port_in_disable_port_in_id,
-		(void *) &cmd_port_in_disable_disable_string,
-		NULL,
-	},
-};
-
-/*
- * link config
- */
-
-static void
-print_link_info(struct app_link_params *p)
-{
-	struct rte_eth_stats stats;
-	struct ether_addr *mac_addr;
-	uint32_t netmask = (~0U) << (32 - p->depth);
-	uint32_t host = p->ip & netmask;
-	uint32_t bcast = host | (~netmask);
-
-	memset(&stats, 0, sizeof(stats));
-	rte_eth_stats_get(p->pmd_id, &stats);
-
-	mac_addr = (struct ether_addr *) &p->mac_addr;
-
-	if (strlen(p->pci_bdf))
-		printf("%s(%s): flags=<%s>\n",
-			p->name,
-			p->pci_bdf,
-			(p->state) ? "UP" : "DOWN");
-	else
-		printf("%s: flags=<%s>\n",
-			p->name,
-			(p->state) ? "UP" : "DOWN");
-
-	if (p->ip)
-		printf("\tinet %" PRIu32 ".%" PRIu32
-			".%" PRIu32 ".%" PRIu32
-			" netmask %" PRIu32 ".%" PRIu32
-			".%" PRIu32 ".%" PRIu32 " "
-			"broadcast %" PRIu32 ".%" PRIu32
-			".%" PRIu32 ".%" PRIu32 "\n",
-			(p->ip >> 24) & 0xFF,
-			(p->ip >> 16) & 0xFF,
-			(p->ip >> 8) & 0xFF,
-			p->ip & 0xFF,
-			(netmask >> 24) & 0xFF,
-			(netmask >> 16) & 0xFF,
-			(netmask >> 8) & 0xFF,
-			netmask & 0xFF,
-			(bcast >> 24) & 0xFF,
-			(bcast >> 16) & 0xFF,
-			(bcast >> 8) & 0xFF,
-			bcast & 0xFF);
-
-	printf("\tether %02" PRIx32 ":%02" PRIx32 ":%02" PRIx32
-		":%02" PRIx32 ":%02" PRIx32 ":%02" PRIx32 "\n",
-		mac_addr->addr_bytes[0],
-		mac_addr->addr_bytes[1],
-		mac_addr->addr_bytes[2],
-		mac_addr->addr_bytes[3],
-		mac_addr->addr_bytes[4],
-		mac_addr->addr_bytes[5]);
-
-	printf("\tRX packets %" PRIu64
-		"  bytes %" PRIu64
-		"\n",
-		stats.ipackets,
-		stats.ibytes);
-
-	printf("\tRX errors %" PRIu64
-		"  missed %" PRIu64
-		"  no-mbuf %" PRIu64
-		"\n",
-		stats.ierrors,
-		stats.imissed,
-		stats.rx_nombuf);
-
-	printf("\tTX packets %" PRIu64
-		"  bytes %" PRIu64 "\n",
-		stats.opackets,
-		stats.obytes);
-
-	printf("\tTX errors %" PRIu64
-		"\n",
-		stats.oerrors);
-
-	printf("\n");
-}
-
-/*
- * link
- *
- * link config:
- *    link <linkid> config <ipaddr> <depth>
- *
- * link up:
- *    link <linkid> up
- *
- * link down:
- *    link <linkid> down
- *
- * link ls:
- *    link ls
- */
-
-struct cmd_link_result {
-	cmdline_fixed_string_t link_string;
-	cmdline_multi_string_t multi_string;
-};
-
-static void
-cmd_link_parsed(
-	void *parsed_result,
-	__attribute__((unused)) struct cmdline *cl,
-	 void *data)
-{
-	struct cmd_link_result *params = parsed_result;
-	struct app_params *app = data;
-
-	char *tokens[16];
-	uint32_t n_tokens = RTE_DIM(tokens);
-	int status;
-
-	uint32_t link_id;
-
-	status = parse_tokenize_string(params->multi_string, tokens, &n_tokens);
-	if (status != 0) {
-		printf(CMD_MSG_TOO_MANY_ARGS, "link");
-		return;
-	}
-
-	/* link ls */
-	if ((n_tokens == 1) && (strcmp(tokens[0], "ls") == 0)) {
-		for (link_id = 0; link_id < app->n_links; link_id++) {
-			struct app_link_params *p;
-
-			APP_PARAM_FIND_BY_ID(app->link_params, "LINK", link_id, p);
-			print_link_info(p);
-		}
-		return;
-	} /* link ls */
-
-	if (n_tokens < 2) {
-		printf(CMD_MSG_MISMATCH_ARGS, "link");
-		return;
-	}
-
-	if (parser_read_uint32(&link_id, tokens[0])) {
-		printf(CMD_MSG_INVALID_ARG, "linkid");
-		return;
-	}
-
-	/* link config */
-	if (strcmp(tokens[1], "config") == 0) {
-		struct in_addr ipaddr_ipv4;
-		uint32_t depth;
-
-		if (n_tokens != 4) {
-			printf(CMD_MSG_MISMATCH_ARGS, "link config");
-			return;
-		}
-
-		if (parse_ipv4_addr(tokens[2], &ipaddr_ipv4)) {
-			printf(CMD_MSG_INVALID_ARG, "ipaddr");
-			return;
-		}
-
-		if (parser_read_uint32(&depth, tokens[3])) {
-			printf(CMD_MSG_INVALID_ARG, "depth");
-			return;
-		}
-
-		status = app_link_config(app,
-			link_id,
-			rte_be_to_cpu_32(ipaddr_ipv4.s_addr),
-			depth);
-		if (status)
-			printf(CMD_MSG_FAIL, "link config");
-
-		return;
-	} /* link config */
-
-	/* link up */
-	if (strcmp(tokens[1], "up") == 0) {
-		if (n_tokens != 2) {
-			printf(CMD_MSG_MISMATCH_ARGS, "link up");
-			return;
-		}
-
-		status = app_link_up(app, link_id);
-		if (status)
-			printf(CMD_MSG_FAIL, "link up");
-
-		return;
-	} /* link up */
-
-	/* link down */
-	if (strcmp(tokens[1], "down") == 0) {
-		if (n_tokens != 2) {
-			printf(CMD_MSG_MISMATCH_ARGS, "link down");
-			return;
-		}
-
-		status = app_link_down(app, link_id);
-		if (status)
-			printf(CMD_MSG_FAIL, "link down");
-
-		return;
-	} /* link down */
-
-	printf(CMD_MSG_MISMATCH_ARGS, "link");
-}
-
-static cmdline_parse_token_string_t cmd_link_link_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_link_result, link_string, "link");
-
-static cmdline_parse_token_string_t cmd_link_multi_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_link_result, multi_string,
-	TOKEN_STRING_MULTI);
-
-static cmdline_parse_inst_t cmd_link = {
-	.f = cmd_link_parsed,
-	.data = NULL,
-	.help_str = "link config / up / down / ls",
-	.tokens = {
-		(void *) &cmd_link_link_string,
-		(void *) &cmd_link_multi_string,
-		NULL,
-	},
-};
-
-/*
- * quit
- */
-
-struct cmd_quit_result {
-	cmdline_fixed_string_t quit;
-};
-
-static void
-cmd_quit_parsed(
-	__rte_unused void *parsed_result,
-	struct cmdline *cl,
-	__rte_unused void *data)
-{
-	cmdline_quit(cl);
-}
-
-static cmdline_parse_token_string_t cmd_quit_quit =
-	TOKEN_STRING_INITIALIZER(struct cmd_quit_result, quit, "quit");
-
-static cmdline_parse_inst_t cmd_quit = {
-	.f = cmd_quit_parsed,
-	.data = NULL,
-	.help_str = "Quit",
-	.tokens = {
-		(void *) &cmd_quit_quit,
-		NULL,
-	},
-};
-
-/*
- * run
- *
- *    run <file>
- *    run <file> [<count> [<interval>]]
-	 <count> default is 1
- *       <interval> is measured in milliseconds, default is 1 second
- */
-
-static void
-app_run_file(
-	cmdline_parse_ctx_t *ctx,
-	const char *file_name)
-{
-	struct cmdline *file_cl;
-	int fd;
-
-	fd = open(file_name, O_RDONLY);
-	if (fd < 0) {
-		printf("Cannot open file \"%s\"\n", file_name);
-		return;
-	}
-
-	file_cl = cmdline_new(ctx, "", fd, 1);
-	cmdline_interact(file_cl);
-	close(fd);
-}
-
-struct cmd_run_result {
-	cmdline_fixed_string_t run_string;
-	cmdline_multi_string_t multi_string;
-};
-
-static void
-cmd_run_parsed(
-	void *parsed_result,
-	struct cmdline *cl,
-	__attribute__((unused)) void *data)
-{
-	struct cmd_run_result *params = parsed_result;
-
-	char *tokens[16];
-	uint32_t n_tokens = RTE_DIM(tokens);
-	int status;
-
-	char *file_name;
-	uint32_t count, interval, i;
-
-	status = parse_tokenize_string(params->multi_string, tokens, &n_tokens);
-	if (status) {
-		printf(CMD_MSG_TOO_MANY_ARGS, "run");
-		return;
-	}
-
-	switch (n_tokens) {
-	case 0:
-		printf(CMD_MSG_NOT_ENOUGH_ARGS, "run");
-		return;
-
-	case 1:
-		file_name = tokens[0];
-		count = 1;
-		interval = 1000;
-		break;
-
-	case 2:
-		file_name = tokens[0];
-
-		if (parser_read_uint32(&count, tokens[1]) ||
-			(count == 0)) {
-			printf(CMD_MSG_INVALID_ARG, "count");
-			return;
-		}
-
-		interval = 1000;
-		break;
-
-	case 3:
-		file_name = tokens[0];
-
-		if (parser_read_uint32(&count, tokens[1]) ||
-			(count == 0)) {
-			printf(CMD_MSG_INVALID_ARG, "count");
-			return;
-		}
-
-		if (parser_read_uint32(&interval, tokens[2]) ||
-			(interval == 0)) {
-			printf(CMD_MSG_INVALID_ARG, "interval");
-			return;
-		}
-		break;
-
-	default:
-		printf(CMD_MSG_MISMATCH_ARGS, "run");
-		return;
-	}
-
-	for (i = 0; i < count; i++) {
-		app_run_file(cl->ctx, file_name);
-		if (interval)
-			usleep(interval * 1000);
-	}
-}
-
-static cmdline_parse_token_string_t cmd_run_run_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_run_result, run_string, "run");
-
-static cmdline_parse_token_string_t cmd_run_multi_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_run_result, multi_string,
-	TOKEN_STRING_MULTI);
-
-
-static cmdline_parse_inst_t cmd_run = {
-	.f = cmd_run_parsed,
-	.data = NULL,
-	.help_str = "Run CLI script file",
-	.tokens = {
-		(void *) &cmd_run_run_string,
-		(void *) &cmd_run_multi_string,
-		NULL,
-	},
-};
-
-static cmdline_parse_ctx_t pipeline_common_cmds[] = {
-	(cmdline_parse_inst_t *) &cmd_quit,
-	(cmdline_parse_inst_t *) &cmd_run,
-	(cmdline_parse_inst_t *) &cmd_link,
-	(cmdline_parse_inst_t *) &cmd_ping,
-	(cmdline_parse_inst_t *) &cmd_stats_port_in,
-	(cmdline_parse_inst_t *) &cmd_stats_port_out,
-	(cmdline_parse_inst_t *) &cmd_stats_table,
-	(cmdline_parse_inst_t *) &cmd_port_in_enable,
-	(cmdline_parse_inst_t *) &cmd_port_in_disable,
-	NULL,
-};
-
-int
-app_pipeline_common_cmd_push(struct app_params *app)
-{
-	uint32_t n_cmds, i;
-
-	/* Check for available slots in the application commands array */
-	n_cmds = RTE_DIM(pipeline_common_cmds) - 1;
-	if (n_cmds > APP_MAX_CMDS - app->n_cmds)
-		return -ENOMEM;
-
-	/* Push pipeline commands into the application */
-	memcpy(&app->cmds[app->n_cmds],
-		pipeline_common_cmds,
-		n_cmds * sizeof(cmdline_parse_ctx_t));
-
-	for (i = 0; i < n_cmds; i++)
-		app->cmds[app->n_cmds + i]->data = app;
-
-	app->n_cmds += n_cmds;
-	app->cmds[app->n_cmds] = NULL;
-
-	return 0;
-}
diff --git a/examples/ip_pipeline/pipeline/pipeline_common_fe.h b/examples/ip_pipeline/pipeline/pipeline_common_fe.h
deleted file mode 100644
index 7227544..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_common_fe.h
+++ /dev/null
@@ -1,231 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#ifndef __INCLUDE_PIPELINE_COMMON_FE_H__
-#define __INCLUDE_PIPELINE_COMMON_FE_H__
-
-#include <rte_common.h>
-#include <rte_cycles.h>
-#include <rte_malloc.h>
-#include <cmdline_parse.h>
-
-#include "pipeline_common_be.h"
-#include "pipeline.h"
-#include "app.h"
-
-#ifndef MSG_TIMEOUT_DEFAULT
-#define MSG_TIMEOUT_DEFAULT                      1000
-#endif
-
-static inline struct app_pipeline_data *
-app_pipeline_data(struct app_params *app, uint32_t id)
-{
-	struct app_pipeline_params *params;
-
-	APP_PARAM_FIND_BY_ID(app->pipeline_params, "PIPELINE", id, params);
-	if (params == NULL)
-		return NULL;
-
-	return &app->pipeline_data[params - app->pipeline_params];
-}
-
-static inline void *
-app_pipeline_data_fe(struct app_params *app, uint32_t id, struct pipeline_type *ptype)
-{
-	struct app_pipeline_data *pipeline_data;
-
-	pipeline_data = app_pipeline_data(app, id);
-	if (pipeline_data == NULL)
-		return NULL;
-
-	if (strcmp(pipeline_data->ptype->name, ptype->name) != 0)
-		return NULL;
-
-	if (pipeline_data->enabled == 0)
-		return NULL;
-
-	return pipeline_data->fe;
-}
-
-static inline struct rte_ring *
-app_pipeline_msgq_in_get(struct app_params *app,
-	uint32_t pipeline_id)
-{
-	struct app_msgq_params *p;
-
-	APP_PARAM_FIND_BY_ID(app->msgq_params,
-		"MSGQ-REQ-PIPELINE",
-		pipeline_id,
-		p);
-	if (p == NULL)
-		return NULL;
-
-	return app->msgq[p - app->msgq_params];
-}
-
-static inline struct rte_ring *
-app_pipeline_msgq_out_get(struct app_params *app,
-	uint32_t pipeline_id)
-{
-	struct app_msgq_params *p;
-
-	APP_PARAM_FIND_BY_ID(app->msgq_params,
-		"MSGQ-RSP-PIPELINE",
-		pipeline_id,
-		p);
-	if (p == NULL)
-		return NULL;
-
-	return app->msgq[p - app->msgq_params];
-}
-
-static inline void *
-app_msg_alloc(__rte_unused struct app_params *app)
-{
-	return rte_malloc(NULL, 2048, RTE_CACHE_LINE_SIZE);
-}
-
-static inline void
-app_msg_free(__rte_unused struct app_params *app,
-	void *msg)
-{
-	rte_free(msg);
-}
-
-static inline void
-app_msg_send(struct app_params *app,
-	uint32_t pipeline_id,
-	void *msg)
-{
-	struct rte_ring *r = app_pipeline_msgq_in_get(app, pipeline_id);
-	int status;
-
-	do {
-		status = rte_ring_sp_enqueue(r, msg);
-	} while (status == -ENOBUFS);
-}
-
-static inline void *
-app_msg_recv(struct app_params *app,
-	uint32_t pipeline_id)
-{
-	struct rte_ring *r = app_pipeline_msgq_out_get(app, pipeline_id);
-	void *msg;
-	int status = rte_ring_sc_dequeue(r, &msg);
-
-	if (status != 0)
-		return NULL;
-
-	return msg;
-}
-
-static inline void *
-app_msg_send_recv(struct app_params *app,
-	uint32_t pipeline_id,
-	void *msg,
-	uint32_t timeout_ms)
-{
-	struct rte_ring *r_req = app_pipeline_msgq_in_get(app, pipeline_id);
-	struct rte_ring *r_rsp = app_pipeline_msgq_out_get(app, pipeline_id);
-	uint64_t hz = rte_get_tsc_hz();
-	void *msg_recv;
-	uint64_t deadline;
-	int status;
-
-	/* send */
-	do {
-		status = rte_ring_sp_enqueue(r_req, (void *) msg);
-	} while (status == -ENOBUFS);
-
-	/* recv */
-	deadline = (timeout_ms) ?
-		(rte_rdtsc() + ((hz * timeout_ms) / 1000)) :
-		UINT64_MAX;
-
-	do {
-		if (rte_rdtsc() > deadline)
-			return NULL;
-
-		status = rte_ring_sc_dequeue(r_rsp, &msg_recv);
-	} while (status != 0);
-
-	return msg_recv;
-}
-
-struct app_link_params *
-app_pipeline_track_pktq_out_to_link(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t pktq_out_id);
-
-int
-app_pipeline_track_default(struct pipeline_params *params,
-	uint32_t port_in,
-	uint32_t *port_out);
-
-int
-app_pipeline_ping(struct app_params *app,
-	uint32_t pipeline_id);
-
-int
-app_pipeline_stats_port_in(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t port_id,
-	struct rte_pipeline_port_in_stats *stats);
-
-int
-app_pipeline_stats_port_out(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t port_id,
-	struct rte_pipeline_port_out_stats *stats);
-
-int
-app_pipeline_stats_table(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t table_id,
-	struct rte_pipeline_table_stats *stats);
-
-int
-app_pipeline_port_in_enable(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t port_id);
-
-int
-app_pipeline_port_in_disable(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t port_id);
-
-int
-app_link_set_op(struct app_params *app,
-	uint32_t link_id,
-	uint32_t pipeline_id,
-	app_link_op op,
-	void *arg);
-
-int
-app_link_config(struct app_params *app,
-	uint32_t link_id,
-	uint32_t ip,
-	uint32_t depth);
-
-int
-app_link_up(struct app_params *app,
-	uint32_t link_id);
-
-int
-app_link_down(struct app_params *app,
-	uint32_t link_id);
-
-int
-app_pipeline_common_cmd_push(struct app_params *app);
-
-#define CMD_MSG_OUT_OF_MEMORY	"Not enough memory\n"
-#define CMD_MSG_NOT_ENOUGH_ARGS	"Not enough arguments for command \"%s\"\n"
-#define CMD_MSG_TOO_MANY_ARGS	"Too many arguments for command \"%s\"\n"
-#define CMD_MSG_MISMATCH_ARGS	"Incorrect set of arguments for command \"%s\"\n"
-#define CMD_MSG_INVALID_ARG	"Invalid value for argument \"%s\"\n"
-#define CMD_MSG_ARG_NOT_FOUND	"Syntax error: \"%s\" not found\n"
-#define CMD_MSG_FILE_ERR	"Error in file \"%s\" at line %u\n"
-#define CMD_MSG_FAIL		"Command \"%s\" failed\n"
-
-#endif
diff --git a/examples/ip_pipeline/pipeline/pipeline_firewall.c b/examples/ip_pipeline/pipeline/pipeline_firewall.c
deleted file mode 100644
index 0cae9d7..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_firewall.c
+++ /dev/null
@@ -1,1421 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-#include <errno.h>
-#include <stdio.h>
-#include <string.h>
-#include <stdlib.h>
-#include <unistd.h>
-#include <sys/queue.h>
-#include <netinet/in.h>
-
-#include <rte_common.h>
-#include <rte_hexdump.h>
-#include <rte_malloc.h>
-#include <cmdline_rdline.h>
-#include <cmdline_parse.h>
-#include <cmdline_parse_num.h>
-#include <cmdline_parse_string.h>
-
-#include "app.h"
-#include "pipeline_common_fe.h"
-#include "pipeline_firewall.h"
-#include "parser.h"
-
-struct app_pipeline_firewall_rule {
-	struct pipeline_firewall_key key;
-	int32_t priority;
-	uint32_t port_id;
-	void *entry_ptr;
-
-	TAILQ_ENTRY(app_pipeline_firewall_rule) node;
-};
-
-struct app_pipeline_firewall {
-	/* parameters */
-	uint32_t n_ports_in;
-	uint32_t n_ports_out;
-
-	/* rules */
-	TAILQ_HEAD(, app_pipeline_firewall_rule) rules;
-	uint32_t n_rules;
-	uint32_t default_rule_present;
-	uint32_t default_rule_port_id;
-	void *default_rule_entry_ptr;
-};
-
-static void
-print_firewall_ipv4_rule(struct app_pipeline_firewall_rule *rule)
-{
-	printf("Prio = %" PRId32 " (SA = %" PRIu32 ".%" PRIu32
-		".%" PRIu32 ".%" PRIu32 "/%" PRIu32 ", "
-		"DA = %" PRIu32 ".%" PRIu32
-		".%"PRIu32 ".%" PRIu32 "/%" PRIu32 ", "
-		"SP = %" PRIu32 "-%" PRIu32 ", "
-		"DP = %" PRIu32 "-%" PRIu32 ", "
-		"Proto = %" PRIu32 " / 0x%" PRIx32 ") => "
-		"Port = %" PRIu32 " (entry ptr = %p)\n",
-
-		rule->priority,
-
-		(rule->key.key.ipv4_5tuple.src_ip >> 24) & 0xFF,
-		(rule->key.key.ipv4_5tuple.src_ip >> 16) & 0xFF,
-		(rule->key.key.ipv4_5tuple.src_ip >> 8) & 0xFF,
-		rule->key.key.ipv4_5tuple.src_ip & 0xFF,
-		rule->key.key.ipv4_5tuple.src_ip_mask,
-
-		(rule->key.key.ipv4_5tuple.dst_ip >> 24) & 0xFF,
-		(rule->key.key.ipv4_5tuple.dst_ip >> 16) & 0xFF,
-		(rule->key.key.ipv4_5tuple.dst_ip >> 8) & 0xFF,
-		rule->key.key.ipv4_5tuple.dst_ip & 0xFF,
-		rule->key.key.ipv4_5tuple.dst_ip_mask,
-
-		rule->key.key.ipv4_5tuple.src_port_from,
-		rule->key.key.ipv4_5tuple.src_port_to,
-
-		rule->key.key.ipv4_5tuple.dst_port_from,
-		rule->key.key.ipv4_5tuple.dst_port_to,
-
-		rule->key.key.ipv4_5tuple.proto,
-		rule->key.key.ipv4_5tuple.proto_mask,
-
-		rule->port_id,
-		rule->entry_ptr);
-}
-
-static struct app_pipeline_firewall_rule *
-app_pipeline_firewall_rule_find(struct app_pipeline_firewall *p,
-	struct pipeline_firewall_key *key)
-{
-	struct app_pipeline_firewall_rule *r;
-
-	TAILQ_FOREACH(r, &p->rules, node)
-		if (memcmp(key,
-			&r->key,
-			sizeof(struct pipeline_firewall_key)) == 0)
-			return r;
-
-	return NULL;
-}
-
-static int
-app_pipeline_firewall_ls(
-	struct app_params *app,
-	uint32_t pipeline_id)
-{
-	struct app_pipeline_firewall *p;
-	struct app_pipeline_firewall_rule *rule;
-	uint32_t n_rules;
-	int priority;
-
-	/* Check input arguments */
-	if (app == NULL)
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id, &pipeline_firewall);
-	if (p == NULL)
-		return -1;
-
-	n_rules = p->n_rules;
-	for (priority = 0; n_rules; priority++)
-		TAILQ_FOREACH(rule, &p->rules, node)
-			if (rule->priority == priority) {
-				print_firewall_ipv4_rule(rule);
-				n_rules--;
-			}
-
-	if (p->default_rule_present)
-		printf("Default rule: port %" PRIu32 " (entry ptr = %p)\n",
-			p->default_rule_port_id,
-			p->default_rule_entry_ptr);
-	else
-		printf("Default rule: DROP\n");
-
-	printf("\n");
-
-	return 0;
-}
-
-static void*
-app_pipeline_firewall_init(struct pipeline_params *params,
-	__rte_unused void *arg)
-{
-	struct app_pipeline_firewall *p;
-	uint32_t size;
-
-	/* Check input arguments */
-	if ((params == NULL) ||
-		(params->n_ports_in == 0) ||
-		(params->n_ports_out == 0))
-		return NULL;
-
-	/* Memory allocation */
-	size = RTE_CACHE_LINE_ROUNDUP(sizeof(struct app_pipeline_firewall));
-	p = rte_zmalloc(NULL, size, RTE_CACHE_LINE_SIZE);
-	if (p == NULL)
-		return NULL;
-
-	/* Initialization */
-	p->n_ports_in = params->n_ports_in;
-	p->n_ports_out = params->n_ports_out;
-
-	TAILQ_INIT(&p->rules);
-	p->n_rules = 0;
-	p->default_rule_present = 0;
-	p->default_rule_port_id = 0;
-	p->default_rule_entry_ptr = NULL;
-
-	return (void *) p;
-}
-
-static int
-app_pipeline_firewall_free(void *pipeline)
-{
-	struct app_pipeline_firewall *p = pipeline;
-
-	/* Check input arguments */
-	if (p == NULL)
-		return -1;
-
-	/* Free resources */
-	while (!TAILQ_EMPTY(&p->rules)) {
-		struct app_pipeline_firewall_rule *rule;
-
-		rule = TAILQ_FIRST(&p->rules);
-		TAILQ_REMOVE(&p->rules, rule, node);
-		rte_free(rule);
-	}
-
-	rte_free(p);
-	return 0;
-}
-
-static int
-app_pipeline_firewall_key_check_and_normalize(struct pipeline_firewall_key *key)
-{
-	switch (key->type) {
-	case PIPELINE_FIREWALL_IPV4_5TUPLE:
-	{
-		uint32_t src_ip_depth = key->key.ipv4_5tuple.src_ip_mask;
-		uint32_t dst_ip_depth = key->key.ipv4_5tuple.dst_ip_mask;
-		uint16_t src_port_from = key->key.ipv4_5tuple.src_port_from;
-		uint16_t src_port_to = key->key.ipv4_5tuple.src_port_to;
-		uint16_t dst_port_from = key->key.ipv4_5tuple.dst_port_from;
-		uint16_t dst_port_to = key->key.ipv4_5tuple.dst_port_to;
-
-		uint32_t src_ip_netmask = 0;
-		uint32_t dst_ip_netmask = 0;
-
-		if ((src_ip_depth > 32) ||
-			(dst_ip_depth > 32) ||
-			(src_port_from > src_port_to) ||
-			(dst_port_from > dst_port_to))
-			return -1;
-
-		if (src_ip_depth)
-			src_ip_netmask = (~0U) << (32 - src_ip_depth);
-
-		if (dst_ip_depth)
-			dst_ip_netmask = ((~0U) << (32 - dst_ip_depth));
-
-		key->key.ipv4_5tuple.src_ip &= src_ip_netmask;
-		key->key.ipv4_5tuple.dst_ip &= dst_ip_netmask;
-
-		return 0;
-	}
-
-	default:
-		return -1;
-	}
-}
-
-int
-app_pipeline_firewall_load_file(char *filename,
-	struct pipeline_firewall_key *keys,
-	uint32_t *priorities,
-	uint32_t *port_ids,
-	uint32_t *n_keys,
-	uint32_t *line)
-{
-	FILE *f = NULL;
-	char file_buf[1024];
-	uint32_t i, l;
-
-	/* Check input arguments */
-	if ((filename == NULL) ||
-		(keys == NULL) ||
-		(priorities == NULL) ||
-		(port_ids == NULL) ||
-		(n_keys == NULL) ||
-		(*n_keys == 0) ||
-		(line == NULL)) {
-		if (line)
-			*line = 0;
-		return -1;
-		}
-
-	/* Open input file */
-	f = fopen(filename, "r");
-	if (f == NULL) {
-		*line = 0;
-		return -1;
-	}
-
-	/* Read file */
-	for (i = 0, l = 1; i < *n_keys; l++) {
-		char *tokens[32];
-		uint32_t n_tokens = RTE_DIM(tokens);
-
-		uint32_t priority = 0;
-		struct in_addr sipaddr;
-		uint32_t sipdepth = 0;
-		struct in_addr dipaddr;
-		uint32_t dipdepth = 0;
-		uint16_t sport0 = 0;
-		uint16_t sport1 = 0;
-		uint16_t dport0 = 0;
-		uint16_t dport1 = 0;
-		uint8_t proto = 0;
-		uint8_t protomask = 0;
-		uint32_t port_id = 0;
-
-		int status;
-
-		if (fgets(file_buf, sizeof(file_buf), f) == NULL)
-			break;
-
-		status = parse_tokenize_string(file_buf, tokens, &n_tokens);
-		if (status)
-			goto error1;
-
-		if ((n_tokens == 0) || (tokens[0][0] == '#'))
-			continue;
-
-		if ((n_tokens != 15) ||
-			strcmp(tokens[0], "priority") ||
-			parser_read_uint32(&priority, tokens[1]) ||
-			strcmp(tokens[2], "ipv4") ||
-			parse_ipv4_addr(tokens[3], &sipaddr) ||
-			parser_read_uint32(&sipdepth, tokens[4]) ||
-			parse_ipv4_addr(tokens[5], &dipaddr) ||
-			parser_read_uint32(&dipdepth, tokens[6]) ||
-			parser_read_uint16(&sport0, tokens[7]) ||
-			parser_read_uint16(&sport1, tokens[8]) ||
-			parser_read_uint16(&dport0, tokens[9]) ||
-			parser_read_uint16(&dport1, tokens[10]) ||
-			parser_read_uint8(&proto, tokens[11]) ||
-			parser_read_uint8_hex(&protomask, tokens[12]) ||
-			strcmp(tokens[13], "port") ||
-			parser_read_uint32(&port_id, tokens[14]))
-			goto error1;
-
-		keys[i].type = PIPELINE_FIREWALL_IPV4_5TUPLE;
-		keys[i].key.ipv4_5tuple.src_ip =
-			rte_be_to_cpu_32(sipaddr.s_addr);
-		keys[i].key.ipv4_5tuple.src_ip_mask = sipdepth;
-		keys[i].key.ipv4_5tuple.dst_ip =
-			rte_be_to_cpu_32(dipaddr.s_addr);
-		keys[i].key.ipv4_5tuple.dst_ip_mask = dipdepth;
-		keys[i].key.ipv4_5tuple.src_port_from = sport0;
-		keys[i].key.ipv4_5tuple.src_port_to = sport1;
-		keys[i].key.ipv4_5tuple.dst_port_from = dport0;
-		keys[i].key.ipv4_5tuple.dst_port_to = dport1;
-		keys[i].key.ipv4_5tuple.proto = proto;
-		keys[i].key.ipv4_5tuple.proto_mask = protomask;
-
-		port_ids[i] = port_id;
-		priorities[i] = priority;
-
-		if (app_pipeline_firewall_key_check_and_normalize(&keys[i]))
-			goto error1;
-
-		i++;
-	}
-
-	/* Close file */
-	*n_keys = i;
-	fclose(f);
-	return 0;
-
-error1:
-	*line = l;
-	fclose(f);
-	return -1;
-}
-
-int
-app_pipeline_firewall_add_rule(struct app_params *app,
-	uint32_t pipeline_id,
-	struct pipeline_firewall_key *key,
-	uint32_t priority,
-	uint32_t port_id)
-{
-	struct app_pipeline_firewall *p;
-	struct app_pipeline_firewall_rule *rule;
-	struct pipeline_firewall_add_msg_req *req;
-	struct pipeline_firewall_add_msg_rsp *rsp;
-	int new_rule;
-
-	/* Check input arguments */
-	if ((app == NULL) ||
-		(key == NULL) ||
-		(key->type != PIPELINE_FIREWALL_IPV4_5TUPLE))
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id, &pipeline_firewall);
-	if (p == NULL)
-		return -1;
-
-	if (port_id >= p->n_ports_out)
-		return -1;
-
-	if (app_pipeline_firewall_key_check_and_normalize(key) != 0)
-		return -1;
-
-	/* Find existing rule or allocate new rule */
-	rule = app_pipeline_firewall_rule_find(p, key);
-	new_rule = (rule == NULL);
-	if (rule == NULL) {
-		rule = rte_malloc(NULL, sizeof(*rule), RTE_CACHE_LINE_SIZE);
-
-		if (rule == NULL)
-			return -1;
-	}
-
-	/* Allocate and write request */
-	req = app_msg_alloc(app);
-	if (req == NULL) {
-		if (new_rule)
-			rte_free(rule);
-		return -1;
-	}
-
-	req->type = PIPELINE_MSG_REQ_CUSTOM;
-	req->subtype = PIPELINE_FIREWALL_MSG_REQ_ADD;
-	memcpy(&req->key, key, sizeof(*key));
-	req->priority = priority;
-	req->port_id = port_id;
-
-	/* Send request and wait for response */
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL) {
-		if (new_rule)
-			rte_free(rule);
-		return -1;
-	}
-
-	/* Read response and write rule */
-	if (rsp->status ||
-		(rsp->entry_ptr == NULL) ||
-		((new_rule == 0) && (rsp->key_found == 0)) ||
-		((new_rule == 1) && (rsp->key_found == 1))) {
-		app_msg_free(app, rsp);
-		if (new_rule)
-			rte_free(rule);
-		return -1;
-	}
-
-	memcpy(&rule->key, key, sizeof(*key));
-	rule->priority = priority;
-	rule->port_id = port_id;
-	rule->entry_ptr = rsp->entry_ptr;
-
-	/* Commit rule */
-	if (new_rule) {
-		TAILQ_INSERT_TAIL(&p->rules, rule, node);
-		p->n_rules++;
-	}
-
-	print_firewall_ipv4_rule(rule);
-
-	/* Free response */
-	app_msg_free(app, rsp);
-
-	return 0;
-}
-
-int
-app_pipeline_firewall_delete_rule(struct app_params *app,
-	uint32_t pipeline_id,
-	struct pipeline_firewall_key *key)
-{
-	struct app_pipeline_firewall *p;
-	struct app_pipeline_firewall_rule *rule;
-	struct pipeline_firewall_del_msg_req *req;
-	struct pipeline_firewall_del_msg_rsp *rsp;
-
-	/* Check input arguments */
-	if ((app == NULL) ||
-		(key == NULL) ||
-		(key->type != PIPELINE_FIREWALL_IPV4_5TUPLE))
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id, &pipeline_firewall);
-	if (p == NULL)
-		return -1;
-
-	if (app_pipeline_firewall_key_check_and_normalize(key) != 0)
-		return -1;
-
-	/* Find rule */
-	rule = app_pipeline_firewall_rule_find(p, key);
-	if (rule == NULL)
-		return 0;
-
-	/* Allocate and write request */
-	req = app_msg_alloc(app);
-	if (req == NULL)
-		return -1;
-
-	req->type = PIPELINE_MSG_REQ_CUSTOM;
-	req->subtype = PIPELINE_FIREWALL_MSG_REQ_DEL;
-	memcpy(&req->key, key, sizeof(*key));
-
-	/* Send request and wait for response */
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL)
-		return -1;
-
-	/* Read response */
-	if (rsp->status || !rsp->key_found) {
-		app_msg_free(app, rsp);
-		return -1;
-	}
-
-	/* Remove rule */
-	TAILQ_REMOVE(&p->rules, rule, node);
-	p->n_rules--;
-	rte_free(rule);
-
-	/* Free response */
-	app_msg_free(app, rsp);
-
-	return 0;
-}
-
-int
-app_pipeline_firewall_add_bulk(struct app_params *app,
-		uint32_t pipeline_id,
-		struct pipeline_firewall_key *keys,
-		uint32_t n_keys,
-		uint32_t *priorities,
-		uint32_t *port_ids)
-{
-	struct app_pipeline_firewall *p;
-	struct pipeline_firewall_add_bulk_msg_req *req;
-	struct pipeline_firewall_add_bulk_msg_rsp *rsp;
-
-	struct app_pipeline_firewall_rule **rules;
-	int *new_rules;
-
-	int *keys_found;
-	void **entries_ptr;
-
-	uint32_t i;
-	int status = 0;
-
-	/* Check input arguments */
-	if (app == NULL)
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id, &pipeline_firewall);
-	if (p == NULL)
-		return -1;
-
-	rules = rte_malloc(NULL,
-		n_keys * sizeof(struct app_pipeline_firewall_rule *),
-		RTE_CACHE_LINE_SIZE);
-	if (rules == NULL)
-		return -1;
-
-	new_rules = rte_malloc(NULL,
-		n_keys * sizeof(int),
-		RTE_CACHE_LINE_SIZE);
-	if (new_rules == NULL) {
-		rte_free(rules);
-		return -1;
-	}
-
-	/* check data integrity and add to rule list */
-	for (i = 0; i < n_keys; i++) {
-		if (port_ids[i]  >= p->n_ports_out) {
-			rte_free(rules);
-			rte_free(new_rules);
-			return -1;
-		}
-
-		if (app_pipeline_firewall_key_check_and_normalize(&keys[i]) != 0) {
-			rte_free(rules);
-			rte_free(new_rules);
-			return -1;
-		}
-
-		rules[i] = app_pipeline_firewall_rule_find(p, &keys[i]);
-		new_rules[i] = (rules[i] == NULL);
-		if (rules[i] == NULL) {
-			rules[i] = rte_malloc(NULL,
-				sizeof(*rules[i]),
-				RTE_CACHE_LINE_SIZE);
-
-			if (rules[i] == NULL) {
-				uint32_t j;
-
-				for (j = 0; j <= i; j++)
-					if (new_rules[j])
-						rte_free(rules[j]);
-
-				rte_free(rules);
-				rte_free(new_rules);
-				return -1;
-			}
-		}
-	}
-
-	keys_found = rte_malloc(NULL,
-		n_keys * sizeof(int),
-		RTE_CACHE_LINE_SIZE);
-	if (keys_found == NULL) {
-		uint32_t j;
-
-		for (j = 0; j < n_keys; j++)
-			if (new_rules[j])
-				rte_free(rules[j]);
-
-		rte_free(rules);
-		rte_free(new_rules);
-		return -1;
-	}
-
-	entries_ptr = rte_malloc(NULL,
-		n_keys * sizeof(struct rte_pipeline_table_entry *),
-		RTE_CACHE_LINE_SIZE);
-	if (entries_ptr == NULL) {
-		uint32_t j;
-
-		for (j = 0; j < n_keys; j++)
-			if (new_rules[j])
-				rte_free(rules[j]);
-
-		rte_free(rules);
-		rte_free(new_rules);
-		rte_free(keys_found);
-		return -1;
-	}
-	for (i = 0; i < n_keys; i++) {
-		entries_ptr[i] = rte_malloc(NULL,
-			sizeof(struct rte_pipeline_table_entry),
-			RTE_CACHE_LINE_SIZE);
-
-		if (entries_ptr[i] == NULL) {
-			uint32_t j;
-
-			for (j = 0; j < n_keys; j++)
-				if (new_rules[j])
-					rte_free(rules[j]);
-
-			for (j = 0; j <= i; j++)
-				rte_free(entries_ptr[j]);
-
-			rte_free(rules);
-			rte_free(new_rules);
-			rte_free(keys_found);
-			rte_free(entries_ptr);
-			return -1;
-		}
-	}
-
-	/* Allocate and write request */
-	req = app_msg_alloc(app);
-	if (req == NULL) {
-		uint32_t j;
-
-		for (j = 0; j < n_keys; j++)
-			if (new_rules[j])
-				rte_free(rules[j]);
-
-		for (j = 0; j < n_keys; j++)
-			rte_free(entries_ptr[j]);
-
-		rte_free(rules);
-		rte_free(new_rules);
-		rte_free(keys_found);
-		rte_free(entries_ptr);
-		return -1;
-	}
-
-	req->type = PIPELINE_MSG_REQ_CUSTOM;
-	req->subtype = PIPELINE_FIREWALL_MSG_REQ_ADD_BULK;
-
-	req->keys = keys;
-	req->n_keys = n_keys;
-	req->port_ids = port_ids;
-	req->priorities = priorities;
-	req->keys_found = keys_found;
-	req->entries_ptr = entries_ptr;
-
-	/* Send request and wait for response */
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL) {
-		uint32_t j;
-
-		for (j = 0; j < n_keys; j++)
-			if (new_rules[j])
-				rte_free(rules[j]);
-
-		for (j = 0; j < n_keys; j++)
-			rte_free(entries_ptr[j]);
-
-		rte_free(rules);
-		rte_free(new_rules);
-		rte_free(keys_found);
-		rte_free(entries_ptr);
-		return -1;
-	}
-
-	if (rsp->status) {
-		for (i = 0; i < n_keys; i++)
-			if (new_rules[i])
-				rte_free(rules[i]);
-
-		for (i = 0; i < n_keys; i++)
-			rte_free(entries_ptr[i]);
-
-		status = -1;
-		goto cleanup;
-	}
-
-	for (i = 0; i < n_keys; i++) {
-		if (entries_ptr[i] == NULL ||
-			((new_rules[i] == 0) && (keys_found[i] == 0)) ||
-			((new_rules[i] == 1) && (keys_found[i] == 1))) {
-			for (i = 0; i < n_keys; i++)
-				if (new_rules[i])
-					rte_free(rules[i]);
-
-			for (i = 0; i < n_keys; i++)
-				rte_free(entries_ptr[i]);
-
-			status = -1;
-			goto cleanup;
-		}
-	}
-
-	for (i = 0; i < n_keys; i++) {
-		memcpy(&rules[i]->key, &keys[i], sizeof(keys[i]));
-		rules[i]->priority = priorities[i];
-		rules[i]->port_id = port_ids[i];
-		rules[i]->entry_ptr = entries_ptr[i];
-
-		/* Commit rule */
-		if (new_rules[i]) {
-			TAILQ_INSERT_TAIL(&p->rules, rules[i], node);
-			p->n_rules++;
-		}
-
-		print_firewall_ipv4_rule(rules[i]);
-	}
-
-cleanup:
-	app_msg_free(app, rsp);
-	rte_free(rules);
-	rte_free(new_rules);
-	rte_free(keys_found);
-	rte_free(entries_ptr);
-
-	return status;
-}
-
-int
-app_pipeline_firewall_delete_bulk(struct app_params *app,
-	uint32_t pipeline_id,
-	struct pipeline_firewall_key *keys,
-	uint32_t n_keys)
-{
-	struct app_pipeline_firewall *p;
-	struct pipeline_firewall_del_bulk_msg_req *req;
-	struct pipeline_firewall_del_bulk_msg_rsp *rsp;
-
-	struct app_pipeline_firewall_rule **rules;
-	int *keys_found;
-
-	uint32_t i;
-	int status = 0;
-
-	/* Check input arguments */
-	if (app == NULL)
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id, &pipeline_firewall);
-	if (p == NULL)
-		return -1;
-
-	rules = rte_malloc(NULL,
-		n_keys * sizeof(struct app_pipeline_firewall_rule *),
-		RTE_CACHE_LINE_SIZE);
-	if (rules == NULL)
-		return -1;
-
-	for (i = 0; i < n_keys; i++) {
-		if (app_pipeline_firewall_key_check_and_normalize(&keys[i]) != 0) {
-			return -1;
-		}
-
-		rules[i] = app_pipeline_firewall_rule_find(p, &keys[i]);
-	}
-
-	keys_found = rte_malloc(NULL,
-		n_keys * sizeof(int),
-		RTE_CACHE_LINE_SIZE);
-	if (keys_found == NULL) {
-		rte_free(rules);
-		return -1;
-	}
-
-	/* Allocate and write request */
-	req = app_msg_alloc(app);
-	if (req == NULL) {
-		rte_free(rules);
-		rte_free(keys_found);
-		return -1;
-	}
-
-	req->type = PIPELINE_MSG_REQ_CUSTOM;
-	req->subtype = PIPELINE_FIREWALL_MSG_REQ_DEL_BULK;
-
-	req->keys = keys;
-	req->n_keys = n_keys;
-	req->keys_found = keys_found;
-
-	/* Send request and wait for response */
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL) {
-		rte_free(rules);
-		rte_free(keys_found);
-		return -1;
-	}
-
-	if (rsp->status) {
-		status = -1;
-		goto cleanup;
-	}
-
-	for (i = 0; i < n_keys; i++) {
-		if (keys_found[i] == 0) {
-			status = -1;
-			goto cleanup;
-		}
-	}
-
-	for (i = 0; i < n_keys; i++) {
-		TAILQ_REMOVE(&p->rules, rules[i], node);
-		p->n_rules--;
-		rte_free(rules[i]);
-	}
-
-cleanup:
-	app_msg_free(app, rsp);
-	rte_free(rules);
-	rte_free(keys_found);
-
-	return status;
-}
-
-int
-app_pipeline_firewall_add_default_rule(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t port_id)
-{
-	struct app_pipeline_firewall *p;
-	struct pipeline_firewall_add_default_msg_req *req;
-	struct pipeline_firewall_add_default_msg_rsp *rsp;
-
-	/* Check input arguments */
-	if (app == NULL)
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id, &pipeline_firewall);
-	if (p == NULL)
-		return -1;
-
-	if (port_id >= p->n_ports_out)
-		return -1;
-
-	/* Allocate and write request */
-	req = app_msg_alloc(app);
-	if (req == NULL)
-		return -1;
-
-	req->type = PIPELINE_MSG_REQ_CUSTOM;
-	req->subtype = PIPELINE_FIREWALL_MSG_REQ_ADD_DEFAULT;
-	req->port_id = port_id;
-
-	/* Send request and wait for response */
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL)
-		return -1;
-
-	/* Read response and write rule */
-	if (rsp->status || (rsp->entry_ptr == NULL)) {
-		app_msg_free(app, rsp);
-		return -1;
-	}
-
-	p->default_rule_port_id = port_id;
-	p->default_rule_entry_ptr = rsp->entry_ptr;
-
-	/* Commit rule */
-	p->default_rule_present = 1;
-
-	/* Free response */
-	app_msg_free(app, rsp);
-
-	return 0;
-}
-
-int
-app_pipeline_firewall_delete_default_rule(struct app_params *app,
-	uint32_t pipeline_id)
-{
-	struct app_pipeline_firewall *p;
-	struct pipeline_firewall_del_default_msg_req *req;
-	struct pipeline_firewall_del_default_msg_rsp *rsp;
-
-	/* Check input arguments */
-	if (app == NULL)
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id, &pipeline_firewall);
-	if (p == NULL)
-		return -1;
-
-	/* Allocate and write request */
-	req = app_msg_alloc(app);
-	if (req == NULL)
-		return -1;
-
-	req->type = PIPELINE_MSG_REQ_CUSTOM;
-	req->subtype = PIPELINE_FIREWALL_MSG_REQ_DEL_DEFAULT;
-
-	/* Send request and wait for response */
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL)
-		return -1;
-
-	/* Read response and write rule */
-	if (rsp->status) {
-		app_msg_free(app, rsp);
-		return -1;
-	}
-
-	/* Commit rule */
-	p->default_rule_present = 0;
-
-	/* Free response */
-	app_msg_free(app, rsp);
-
-	return 0;
-}
-
-/*
- * firewall
- *
- * firewall add:
- *    p <pipelineid> firewall add priority <priority>
- *       ipv4 <sipaddr> <sipdepth> <dipaddr> <dipdepth>
- *       <sport0> <sport1> <dport0> <dport1> <proto> <protomask>
- *       port <portid>
- *       Note: <protomask> is a hex value
- *
- *    p <pipelineid> firewall add bulk <file>
- *
- * firewall add default:
- *    p <pipelineid> firewall add default <port ID>
- *
- * firewall del:
- *    p <pipelineid> firewall del
- *       ipv4 <sipaddr> <sipdepth> <dipaddr> <dipdepth>
- *       <sport0> <sport1> <dport0> <dport1> <proto> <protomask>
- *
- *    p <pipelineid> firewall del bulk <file>
- *
- * firewall del default:
- *    p <pipelineid> firewall del default
- *
- * firewall ls:
- *    p <pipelineid> firewall ls
- */
-
-struct cmd_firewall_result {
-	cmdline_fixed_string_t p_string;
-	uint32_t pipeline_id;
-	cmdline_fixed_string_t firewall_string;
-	cmdline_multi_string_t multi_string;
-};
-
-static void cmd_firewall_parsed(void *parsed_result,
-	__attribute__((unused))  struct cmdline *cl,
-	void *data)
-{
-	struct cmd_firewall_result *params = parsed_result;
-	struct app_params *app = data;
-	int status;
-
-	char *tokens[17];
-	uint32_t n_tokens = RTE_DIM(tokens);
-
-	status = parse_tokenize_string(params->multi_string, tokens, &n_tokens);
-	if (status) {
-		printf(CMD_MSG_TOO_MANY_ARGS, "firewall");
-		return;
-	}
-
-	/* firewall add */
-	if ((n_tokens >= 2) &&
-		(strcmp(tokens[0], "add") == 0) &&
-		(strcmp(tokens[1], "priority") == 0)) {
-		struct pipeline_firewall_key key;
-		uint32_t priority;
-		struct in_addr sipaddr;
-		uint32_t sipdepth;
-		struct in_addr dipaddr;
-		uint32_t dipdepth;
-		uint16_t sport0;
-		uint16_t sport1;
-		uint16_t dport0;
-		uint16_t dport1;
-		uint8_t proto;
-		uint8_t protomask;
-		uint32_t port_id;
-
-		memset(&key, 0, sizeof(key));
-
-		if (n_tokens != 16) {
-			printf(CMD_MSG_MISMATCH_ARGS, "firewall add");
-			return;
-		}
-
-		if (parser_read_uint32(&priority, tokens[2])) {
-			printf(CMD_MSG_INVALID_ARG, "priority");
-			return;
-		}
-
-		if (strcmp(tokens[3], "ipv4")) {
-			printf(CMD_MSG_ARG_NOT_FOUND, "ipv4");
-			return;
-		}
-
-		if (parse_ipv4_addr(tokens[4], &sipaddr)) {
-			printf(CMD_MSG_INVALID_ARG, "sipaddr");
-			return;
-		}
-
-		if (parser_read_uint32(&sipdepth, tokens[5])) {
-			printf(CMD_MSG_INVALID_ARG, "sipdepth");
-			return;
-		}
-
-		if (parse_ipv4_addr(tokens[6], &dipaddr)) {
-			printf(CMD_MSG_INVALID_ARG, "dipaddr");
-			return;
-		}
-
-		if (parser_read_uint32(&dipdepth, tokens[7])) {
-			printf(CMD_MSG_INVALID_ARG, "dipdepth");
-			return;
-		}
-
-		if (parser_read_uint16(&sport0, tokens[8])) {
-			printf(CMD_MSG_INVALID_ARG, "sport0");
-			return;
-		}
-
-		if (parser_read_uint16(&sport1, tokens[9])) {
-			printf(CMD_MSG_INVALID_ARG, "sport1");
-			return;
-		}
-
-		if (parser_read_uint16(&dport0, tokens[10])) {
-			printf(CMD_MSG_INVALID_ARG, "dport0");
-			return;
-		}
-
-		if (parser_read_uint16(&dport1, tokens[11])) {
-			printf(CMD_MSG_INVALID_ARG, "dport1");
-			return;
-		}
-
-		if (parser_read_uint8(&proto, tokens[12])) {
-			printf(CMD_MSG_INVALID_ARG, "proto");
-			return;
-		}
-
-		if (parser_read_uint8_hex(&protomask, tokens[13])) {
-			printf(CMD_MSG_INVALID_ARG, "protomask");
-			return;
-		}
-
-		if (strcmp(tokens[14], "port")) {
-			printf(CMD_MSG_ARG_NOT_FOUND, "port");
-			return;
-		}
-
-		if (parser_read_uint32(&port_id, tokens[15])) {
-			printf(CMD_MSG_INVALID_ARG, "portid");
-			return;
-		}
-
-		key.type = PIPELINE_FIREWALL_IPV4_5TUPLE;
-		key.key.ipv4_5tuple.src_ip = rte_be_to_cpu_32(sipaddr.s_addr);
-		key.key.ipv4_5tuple.src_ip_mask = sipdepth;
-		key.key.ipv4_5tuple.dst_ip = rte_be_to_cpu_32(dipaddr.s_addr);
-		key.key.ipv4_5tuple.dst_ip_mask = dipdepth;
-		key.key.ipv4_5tuple.src_port_from = sport0;
-		key.key.ipv4_5tuple.src_port_to = sport1;
-		key.key.ipv4_5tuple.dst_port_from = dport0;
-		key.key.ipv4_5tuple.dst_port_to = dport1;
-		key.key.ipv4_5tuple.proto = proto;
-		key.key.ipv4_5tuple.proto_mask = protomask;
-
-		status = app_pipeline_firewall_add_rule(app,
-			params->pipeline_id,
-			&key,
-			priority,
-			port_id);
-		if (status)
-			printf(CMD_MSG_FAIL, "firewall add");
-
-		return;
-	} /* firewall add */
-
-	/* firewall add bulk */
-	if ((n_tokens >= 2) &&
-		(strcmp(tokens[0], "add") == 0) &&
-		(strcmp(tokens[1], "bulk") == 0)) {
-		struct pipeline_firewall_key *keys;
-		uint32_t *priorities, *port_ids, n_keys, line;
-		char *filename;
-
-		if (n_tokens != 3) {
-			printf(CMD_MSG_MISMATCH_ARGS, "firewall add bulk");
-			return;
-		}
-
-		filename = tokens[2];
-
-		n_keys = APP_PIPELINE_FIREWALL_MAX_RULES_IN_FILE;
-		keys = malloc(n_keys * sizeof(struct pipeline_firewall_key));
-		if (keys == NULL) {
-			printf(CMD_MSG_OUT_OF_MEMORY);
-			return;
-		}
-		memset(keys, 0, n_keys * sizeof(struct pipeline_firewall_key));
-
-		priorities = malloc(n_keys * sizeof(uint32_t));
-		if (priorities == NULL) {
-			printf(CMD_MSG_OUT_OF_MEMORY);
-			free(keys);
-			return;
-		}
-
-		port_ids = malloc(n_keys * sizeof(uint32_t));
-		if (port_ids == NULL) {
-			printf(CMD_MSG_OUT_OF_MEMORY);
-			free(priorities);
-			free(keys);
-			return;
-		}
-
-		status = app_pipeline_firewall_load_file(filename,
-			keys,
-			priorities,
-			port_ids,
-			&n_keys,
-			&line);
-		if (status != 0) {
-			printf(CMD_MSG_FILE_ERR, filename, line);
-			free(port_ids);
-			free(priorities);
-			free(keys);
-			return;
-		}
-
-		status = app_pipeline_firewall_add_bulk(app,
-			params->pipeline_id,
-			keys,
-			n_keys,
-			priorities,
-			port_ids);
-		if (status)
-			printf(CMD_MSG_FAIL, "firewall add bulk");
-
-		free(keys);
-		free(priorities);
-		free(port_ids);
-		return;
-	} /* firewall add bulk */
-
-	/* firewall add default */
-	if ((n_tokens >= 2) &&
-		(strcmp(tokens[0], "add") == 0) &&
-		(strcmp(tokens[1], "default") == 0)) {
-		uint32_t port_id;
-
-		if (n_tokens != 3) {
-			printf(CMD_MSG_MISMATCH_ARGS, "firewall add default");
-			return;
-		}
-
-		if (parser_read_uint32(&port_id, tokens[2])) {
-			printf(CMD_MSG_INVALID_ARG, "portid");
-			return;
-		}
-
-		status = app_pipeline_firewall_add_default_rule(app,
-			params->pipeline_id,
-			port_id);
-		if (status)
-			printf(CMD_MSG_FAIL, "firewall add default");
-
-		return;
-	} /* firewall add default */
-
-	/* firewall del */
-	if ((n_tokens >= 2) &&
-		(strcmp(tokens[0], "del") == 0) &&
-		(strcmp(tokens[1], "ipv4") == 0)) {
-		struct pipeline_firewall_key key;
-		struct in_addr sipaddr;
-		uint32_t sipdepth;
-		struct in_addr dipaddr;
-		uint32_t dipdepth;
-		uint16_t sport0;
-		uint16_t sport1;
-		uint16_t dport0;
-		uint16_t dport1;
-		uint8_t proto;
-		uint8_t protomask;
-
-		memset(&key, 0, sizeof(key));
-
-		if (n_tokens != 12) {
-			printf(CMD_MSG_MISMATCH_ARGS, "firewall del");
-			return;
-		}
-
-		if (parse_ipv4_addr(tokens[2], &sipaddr)) {
-			printf(CMD_MSG_INVALID_ARG, "sipaddr");
-			return;
-		}
-
-		if (parser_read_uint32(&sipdepth, tokens[3])) {
-			printf(CMD_MSG_INVALID_ARG, "sipdepth");
-			return;
-		}
-
-		if (parse_ipv4_addr(tokens[4], &dipaddr)) {
-			printf(CMD_MSG_INVALID_ARG, "dipaddr");
-			return;
-		}
-
-		if (parser_read_uint32(&dipdepth, tokens[5])) {
-			printf(CMD_MSG_INVALID_ARG, "dipdepth");
-			return;
-		}
-
-		if (parser_read_uint16(&sport0, tokens[6])) {
-			printf(CMD_MSG_INVALID_ARG, "sport0");
-			return;
-		}
-
-		if (parser_read_uint16(&sport1, tokens[7])) {
-			printf(CMD_MSG_INVALID_ARG, "sport1");
-			return;
-		}
-
-		if (parser_read_uint16(&dport0, tokens[8])) {
-			printf(CMD_MSG_INVALID_ARG, "dport0");
-			return;
-		}
-
-		if (parser_read_uint16(&dport1, tokens[9])) {
-			printf(CMD_MSG_INVALID_ARG, "dport1");
-			return;
-		}
-
-		if (parser_read_uint8(&proto, tokens[10])) {
-			printf(CMD_MSG_INVALID_ARG, "proto");
-			return;
-		}
-
-		if (parser_read_uint8_hex(&protomask, tokens[11])) {
-			printf(CMD_MSG_INVALID_ARG, "protomask");
-			return;
-		}
-
-		key.type = PIPELINE_FIREWALL_IPV4_5TUPLE;
-		key.key.ipv4_5tuple.src_ip = rte_be_to_cpu_32(sipaddr.s_addr);
-		key.key.ipv4_5tuple.src_ip_mask = sipdepth;
-		key.key.ipv4_5tuple.dst_ip = rte_be_to_cpu_32(dipaddr.s_addr);
-		key.key.ipv4_5tuple.dst_ip_mask = dipdepth;
-		key.key.ipv4_5tuple.src_port_from = sport0;
-		key.key.ipv4_5tuple.src_port_to = sport1;
-		key.key.ipv4_5tuple.dst_port_from = dport0;
-		key.key.ipv4_5tuple.dst_port_to = dport1;
-		key.key.ipv4_5tuple.proto = proto;
-		key.key.ipv4_5tuple.proto_mask = protomask;
-
-		status = app_pipeline_firewall_delete_rule(app,
-			params->pipeline_id,
-			&key);
-		if (status)
-			printf(CMD_MSG_FAIL, "firewall del");
-
-		return;
-	} /* firewall del */
-
-	/* firewall del bulk */
-	if ((n_tokens >= 2) &&
-		(strcmp(tokens[0], "del") == 0) &&
-		(strcmp(tokens[1], "bulk") == 0)) {
-		struct pipeline_firewall_key *keys;
-		uint32_t *priorities, *port_ids, n_keys, line;
-		char *filename;
-
-		if (n_tokens != 3) {
-			printf(CMD_MSG_MISMATCH_ARGS, "firewall del bulk");
-			return;
-		}
-
-		filename = tokens[2];
-
-		n_keys = APP_PIPELINE_FIREWALL_MAX_RULES_IN_FILE;
-		keys = malloc(n_keys * sizeof(struct pipeline_firewall_key));
-		if (keys == NULL) {
-			printf(CMD_MSG_OUT_OF_MEMORY);
-			return;
-		}
-		memset(keys, 0, n_keys * sizeof(struct pipeline_firewall_key));
-
-		priorities = malloc(n_keys * sizeof(uint32_t));
-		if (priorities == NULL) {
-			printf(CMD_MSG_OUT_OF_MEMORY);
-			free(keys);
-			return;
-		}
-
-		port_ids = malloc(n_keys * sizeof(uint32_t));
-		if (port_ids == NULL) {
-			printf(CMD_MSG_OUT_OF_MEMORY);
-			free(priorities);
-			free(keys);
-			return;
-		}
-
-		status = app_pipeline_firewall_load_file(filename,
-			keys,
-			priorities,
-			port_ids,
-			&n_keys,
-			&line);
-		if (status != 0) {
-			printf(CMD_MSG_FILE_ERR, filename, line);
-			free(port_ids);
-			free(priorities);
-			free(keys);
-			return;
-		}
-
-		status = app_pipeline_firewall_delete_bulk(app,
-			params->pipeline_id,
-			keys,
-			n_keys);
-		if (status)
-			printf(CMD_MSG_FAIL, "firewall del bulk");
-
-		free(port_ids);
-		free(priorities);
-		free(keys);
-		return;
-	} /* firewall del bulk */
-
-	/* firewall del default */
-	if ((n_tokens >= 2) &&
-		(strcmp(tokens[0], "del") == 0) &&
-		(strcmp(tokens[1], "default") == 0)) {
-		if (n_tokens != 2) {
-			printf(CMD_MSG_MISMATCH_ARGS, "firewall del default");
-			return;
-		}
-
-		status = app_pipeline_firewall_delete_default_rule(app,
-			params->pipeline_id);
-		if (status)
-			printf(CMD_MSG_FAIL, "firewall del default");
-
-		return;
-
-	} /* firewall del default */
-
-	/* firewall ls */
-	if ((n_tokens >= 1) && (strcmp(tokens[0], "ls") == 0)) {
-		if (n_tokens != 1) {
-			printf(CMD_MSG_MISMATCH_ARGS, "firewall ls");
-			return;
-		}
-
-		status = app_pipeline_firewall_ls(app, params->pipeline_id);
-		if (status)
-			printf(CMD_MSG_FAIL, "firewall ls");
-
-		return;
-	} /* firewall ls */
-
-	printf(CMD_MSG_MISMATCH_ARGS, "firewall");
-}
-
-static cmdline_parse_token_string_t cmd_firewall_p_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_firewall_result, p_string, "p");
-
-static cmdline_parse_token_num_t cmd_firewall_pipeline_id =
-	TOKEN_NUM_INITIALIZER(struct cmd_firewall_result, pipeline_id, UINT32);
-
-static cmdline_parse_token_string_t cmd_firewall_firewall_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_firewall_result, firewall_string,
-	"firewall");
-
-static cmdline_parse_token_string_t cmd_firewall_multi_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_firewall_result, multi_string,
-	TOKEN_STRING_MULTI);
-
-static cmdline_parse_inst_t cmd_firewall = {
-	.f = cmd_firewall_parsed,
-	.data = NULL,
-	.help_str =	"firewall add / add bulk / add default / del / del bulk"
-		" / del default / ls",
-	.tokens = {
-		(void *) &cmd_firewall_p_string,
-		(void *) &cmd_firewall_pipeline_id,
-		(void *) &cmd_firewall_firewall_string,
-		(void *) &cmd_firewall_multi_string,
-		NULL,
-	},
-};
-
-static cmdline_parse_ctx_t pipeline_cmds[] = {
-	(cmdline_parse_inst_t *) &cmd_firewall,
-	NULL,
-};
-
-static struct pipeline_fe_ops pipeline_firewall_fe_ops = {
-	.f_init = app_pipeline_firewall_init,
-	.f_post_init = NULL,
-	.f_free = app_pipeline_firewall_free,
-	.f_track = app_pipeline_track_default,
-	.cmds = pipeline_cmds,
-};
-
-struct pipeline_type pipeline_firewall = {
-	.name = "FIREWALL",
-	.be_ops = &pipeline_firewall_be_ops,
-	.fe_ops = &pipeline_firewall_fe_ops,
-};
diff --git a/examples/ip_pipeline/pipeline/pipeline_firewall.h b/examples/ip_pipeline/pipeline/pipeline_firewall.h
deleted file mode 100644
index 27304b0..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_firewall.h
+++ /dev/null
@@ -1,60 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#ifndef __INCLUDE_PIPELINE_FIREWALL_H__
-#define __INCLUDE_PIPELINE_FIREWALL_H__
-
-#include "pipeline.h"
-#include "pipeline_firewall_be.h"
-
-int
-app_pipeline_firewall_add_rule(struct app_params *app,
-	uint32_t pipeline_id,
-	struct pipeline_firewall_key *key,
-	uint32_t priority,
-	uint32_t port_id);
-
-int
-app_pipeline_firewall_delete_rule(struct app_params *app,
-	uint32_t pipeline_id,
-	struct pipeline_firewall_key *key);
-
-int
-app_pipeline_firewall_add_bulk(struct app_params *app,
-		uint32_t pipeline_id,
-		struct pipeline_firewall_key *keys,
-		uint32_t n_keys,
-		uint32_t *priorities,
-		uint32_t *port_ids);
-
-int
-app_pipeline_firewall_delete_bulk(struct app_params *app,
-	uint32_t pipeline_id,
-	struct pipeline_firewall_key *keys,
-	uint32_t n_keys);
-
-int
-app_pipeline_firewall_add_default_rule(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t port_id);
-
-int
-app_pipeline_firewall_delete_default_rule(struct app_params *app,
-	uint32_t pipeline_id);
-
-#ifndef APP_PIPELINE_FIREWALL_MAX_RULES_IN_FILE
-#define APP_PIPELINE_FIREWALL_MAX_RULES_IN_FILE		65536
-#endif
-
-int
-app_pipeline_firewall_load_file(char *filename,
-	struct pipeline_firewall_key *keys,
-	uint32_t *priorities,
-	uint32_t *port_ids,
-	uint32_t *n_keys,
-	uint32_t *line);
-
-extern struct pipeline_type pipeline_firewall;
-
-#endif
diff --git a/examples/ip_pipeline/pipeline/pipeline_firewall_be.c b/examples/ip_pipeline/pipeline/pipeline_firewall_be.c
deleted file mode 100644
index bd5e1b2..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_firewall_be.c
+++ /dev/null
@@ -1,856 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#include <string.h>
-
-#include <rte_common.h>
-#include <rte_malloc.h>
-#include <rte_ether.h>
-#include <rte_ip.h>
-#include <rte_tcp.h>
-#include <rte_byteorder.h>
-#include <rte_table_acl.h>
-
-#include "pipeline_firewall_be.h"
-#include "parser.h"
-
-struct pipeline_firewall {
-	struct pipeline p;
-	pipeline_msg_req_handler custom_handlers[PIPELINE_FIREWALL_MSG_REQS];
-
-	uint32_t n_rules;
-	uint32_t n_rule_fields;
-	struct rte_acl_field_def *field_format;
-	uint32_t field_format_size;
-} __rte_cache_aligned;
-
-static void *
-pipeline_firewall_msg_req_custom_handler(struct pipeline *p, void *msg);
-
-static pipeline_msg_req_handler handlers[] = {
-	[PIPELINE_MSG_REQ_PING] =
-		pipeline_msg_req_ping_handler,
-	[PIPELINE_MSG_REQ_STATS_PORT_IN] =
-		pipeline_msg_req_stats_port_in_handler,
-	[PIPELINE_MSG_REQ_STATS_PORT_OUT] =
-		pipeline_msg_req_stats_port_out_handler,
-	[PIPELINE_MSG_REQ_STATS_TABLE] =
-		pipeline_msg_req_stats_table_handler,
-	[PIPELINE_MSG_REQ_PORT_IN_ENABLE] =
-		pipeline_msg_req_port_in_enable_handler,
-	[PIPELINE_MSG_REQ_PORT_IN_DISABLE] =
-		pipeline_msg_req_port_in_disable_handler,
-	[PIPELINE_MSG_REQ_CUSTOM] =
-		pipeline_firewall_msg_req_custom_handler,
-};
-
-static void *
-pipeline_firewall_msg_req_add_handler(struct pipeline *p, void *msg);
-
-static void *
-pipeline_firewall_msg_req_del_handler(struct pipeline *p, void *msg);
-
-static void *
-pipeline_firewall_msg_req_add_bulk_handler(struct pipeline *p, void *msg);
-
-static void *
-pipeline_firewall_msg_req_del_bulk_handler(struct pipeline *p, void *msg);
-
-static void *
-pipeline_firewall_msg_req_add_default_handler(struct pipeline *p, void *msg);
-
-static void *
-pipeline_firewall_msg_req_del_default_handler(struct pipeline *p, void *msg);
-
-static pipeline_msg_req_handler custom_handlers[] = {
-	[PIPELINE_FIREWALL_MSG_REQ_ADD] =
-		pipeline_firewall_msg_req_add_handler,
-	[PIPELINE_FIREWALL_MSG_REQ_DEL] =
-		pipeline_firewall_msg_req_del_handler,
-	[PIPELINE_FIREWALL_MSG_REQ_ADD_BULK] =
-		pipeline_firewall_msg_req_add_bulk_handler,
-	[PIPELINE_FIREWALL_MSG_REQ_DEL_BULK] =
-		pipeline_firewall_msg_req_del_bulk_handler,
-	[PIPELINE_FIREWALL_MSG_REQ_ADD_DEFAULT] =
-		pipeline_firewall_msg_req_add_default_handler,
-	[PIPELINE_FIREWALL_MSG_REQ_DEL_DEFAULT] =
-		pipeline_firewall_msg_req_del_default_handler,
-};
-
-/*
- * Firewall table
- */
-struct firewall_table_entry {
-	struct rte_pipeline_table_entry head;
-};
-
-static struct rte_acl_field_def field_format_ipv4[] = {
-	/* Protocol */
-	[0] = {
-		.type = RTE_ACL_FIELD_TYPE_BITMASK,
-		.size = sizeof(uint8_t),
-		.field_index = 0,
-		.input_index = 0,
-		.offset = sizeof(struct ether_hdr) +
-			offsetof(struct ipv4_hdr, next_proto_id),
-	},
-
-	/* Source IP address (IPv4) */
-	[1] = {
-		.type = RTE_ACL_FIELD_TYPE_MASK,
-		.size = sizeof(uint32_t),
-		.field_index = 1,
-		.input_index = 1,
-		.offset = sizeof(struct ether_hdr) +
-			offsetof(struct ipv4_hdr, src_addr),
-	},
-
-	/* Destination IP address (IPv4) */
-	[2] = {
-		.type = RTE_ACL_FIELD_TYPE_MASK,
-		.size = sizeof(uint32_t),
-		.field_index = 2,
-		.input_index = 2,
-		.offset = sizeof(struct ether_hdr) +
-			offsetof(struct ipv4_hdr, dst_addr),
-	},
-
-	/* Source Port */
-	[3] = {
-		.type = RTE_ACL_FIELD_TYPE_RANGE,
-		.size = sizeof(uint16_t),
-		.field_index = 3,
-		.input_index = 3,
-		.offset = sizeof(struct ether_hdr) +
-			sizeof(struct ipv4_hdr) +
-			offsetof(struct tcp_hdr, src_port),
-	},
-
-	/* Destination Port */
-	[4] = {
-		.type = RTE_ACL_FIELD_TYPE_RANGE,
-		.size = sizeof(uint16_t),
-		.field_index = 4,
-		.input_index = 3,
-		.offset = sizeof(struct ether_hdr) +
-			sizeof(struct ipv4_hdr) +
-			offsetof(struct tcp_hdr, dst_port),
-	},
-};
-
-#define SIZEOF_VLAN_HDR                          4
-
-static struct rte_acl_field_def field_format_vlan_ipv4[] = {
-	/* Protocol */
-	[0] = {
-		.type = RTE_ACL_FIELD_TYPE_BITMASK,
-		.size = sizeof(uint8_t),
-		.field_index = 0,
-		.input_index = 0,
-		.offset = sizeof(struct ether_hdr) +
-			SIZEOF_VLAN_HDR +
-			offsetof(struct ipv4_hdr, next_proto_id),
-	},
-
-	/* Source IP address (IPv4) */
-	[1] = {
-		.type = RTE_ACL_FIELD_TYPE_MASK,
-		.size = sizeof(uint32_t),
-		.field_index = 1,
-		.input_index = 1,
-		.offset = sizeof(struct ether_hdr) +
-			SIZEOF_VLAN_HDR +
-			offsetof(struct ipv4_hdr, src_addr),
-	},
-
-	/* Destination IP address (IPv4) */
-	[2] = {
-		.type = RTE_ACL_FIELD_TYPE_MASK,
-		.size = sizeof(uint32_t),
-		.field_index = 2,
-		.input_index = 2,
-		.offset = sizeof(struct ether_hdr) +
-			SIZEOF_VLAN_HDR +
-			offsetof(struct ipv4_hdr, dst_addr),
-	},
-
-	/* Source Port */
-	[3] = {
-		.type = RTE_ACL_FIELD_TYPE_RANGE,
-		.size = sizeof(uint16_t),
-		.field_index = 3,
-		.input_index = 3,
-		.offset = sizeof(struct ether_hdr) +
-			SIZEOF_VLAN_HDR +
-			sizeof(struct ipv4_hdr) +
-			offsetof(struct tcp_hdr, src_port),
-	},
-
-	/* Destination Port */
-	[4] = {
-		.type = RTE_ACL_FIELD_TYPE_RANGE,
-		.size = sizeof(uint16_t),
-		.field_index = 4,
-		.input_index = 3,
-		.offset = sizeof(struct ether_hdr) +
-			SIZEOF_VLAN_HDR +
-			sizeof(struct ipv4_hdr) +
-			offsetof(struct tcp_hdr, dst_port),
-	},
-};
-
-#define SIZEOF_QINQ_HEADER                       8
-
-static struct rte_acl_field_def field_format_qinq_ipv4[] = {
-	/* Protocol */
-	[0] = {
-		.type = RTE_ACL_FIELD_TYPE_BITMASK,
-		.size = sizeof(uint8_t),
-		.field_index = 0,
-		.input_index = 0,
-		.offset = sizeof(struct ether_hdr) +
-			SIZEOF_QINQ_HEADER +
-			offsetof(struct ipv4_hdr, next_proto_id),
-	},
-
-	/* Source IP address (IPv4) */
-	[1] = {
-		.type = RTE_ACL_FIELD_TYPE_MASK,
-		.size = sizeof(uint32_t),
-		.field_index = 1,
-		.input_index = 1,
-		.offset = sizeof(struct ether_hdr) +
-			SIZEOF_QINQ_HEADER +
-			offsetof(struct ipv4_hdr, src_addr),
-	},
-
-	/* Destination IP address (IPv4) */
-	[2] = {
-		.type = RTE_ACL_FIELD_TYPE_MASK,
-		.size = sizeof(uint32_t),
-		.field_index = 2,
-		.input_index = 2,
-		.offset = sizeof(struct ether_hdr) +
-			SIZEOF_QINQ_HEADER +
-			offsetof(struct ipv4_hdr, dst_addr),
-	},
-
-	/* Source Port */
-	[3] = {
-		.type = RTE_ACL_FIELD_TYPE_RANGE,
-		.size = sizeof(uint16_t),
-		.field_index = 3,
-		.input_index = 3,
-		.offset = sizeof(struct ether_hdr) +
-			SIZEOF_QINQ_HEADER +
-			sizeof(struct ipv4_hdr) +
-			offsetof(struct tcp_hdr, src_port),
-	},
-
-	/* Destination Port */
-	[4] = {
-		.type = RTE_ACL_FIELD_TYPE_RANGE,
-		.size = sizeof(uint16_t),
-		.field_index = 4,
-		.input_index = 3,
-		.offset = sizeof(struct ether_hdr) +
-			SIZEOF_QINQ_HEADER +
-			sizeof(struct ipv4_hdr) +
-			offsetof(struct tcp_hdr, dst_port),
-	},
-};
-
-static int
-pipeline_firewall_parse_args(struct pipeline_firewall *p,
-	struct pipeline_params *params)
-{
-	uint32_t n_rules_present = 0;
-	uint32_t pkt_type_present = 0;
-	uint32_t i;
-
-	/* defaults */
-	p->n_rules = 4 * 1024;
-	p->n_rule_fields = RTE_DIM(field_format_ipv4);
-	p->field_format = field_format_ipv4;
-	p->field_format_size = sizeof(field_format_ipv4);
-
-	for (i = 0; i < params->n_args; i++) {
-		char *arg_name = params->args_name[i];
-		char *arg_value = params->args_value[i];
-
-		if (strcmp(arg_name, "n_rules") == 0) {
-			int status;
-
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				n_rules_present == 0, params->name,
-				arg_name);
-			n_rules_present = 1;
-
-			status = parser_read_uint32(&p->n_rules,
-				arg_value);
-			PIPELINE_PARSE_ERR_INV_VAL((status != -EINVAL),
-				params->name, arg_name, arg_value);
-			PIPELINE_PARSE_ERR_OUT_RNG((status != -ERANGE),
-				params->name, arg_name, arg_value);
-			continue;
-		}
-
-		if (strcmp(arg_name, "pkt_type") == 0) {
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				pkt_type_present == 0, params->name,
-				arg_name);
-			pkt_type_present = 1;
-
-			/* ipv4 */
-			if (strcmp(arg_value, "ipv4") == 0) {
-				p->n_rule_fields = RTE_DIM(field_format_ipv4);
-				p->field_format = field_format_ipv4;
-				p->field_format_size =
-					sizeof(field_format_ipv4);
-				continue;
-			}
-
-			/* vlan_ipv4 */
-			if (strcmp(arg_value, "vlan_ipv4") == 0) {
-				p->n_rule_fields =
-					RTE_DIM(field_format_vlan_ipv4);
-				p->field_format = field_format_vlan_ipv4;
-				p->field_format_size =
-					sizeof(field_format_vlan_ipv4);
-				continue;
-			}
-
-			/* qinq_ipv4 */
-			if (strcmp(arg_value, "qinq_ipv4") == 0) {
-				p->n_rule_fields =
-					RTE_DIM(field_format_qinq_ipv4);
-				p->field_format = field_format_qinq_ipv4;
-				p->field_format_size =
-					sizeof(field_format_qinq_ipv4);
-				continue;
-			}
-
-			/* other */
-			PIPELINE_PARSE_ERR_INV_VAL(0, params->name,
-				arg_name, arg_value);
-		}
-
-		/* other */
-		PIPELINE_PARSE_ERR_INV_ENT(0, params->name, arg_name);
-	}
-
-	return 0;
-}
-
-static void *
-pipeline_firewall_init(struct pipeline_params *params,
-	__rte_unused void *arg)
-{
-	struct pipeline *p;
-	struct pipeline_firewall *p_fw;
-	uint32_t size, i;
-
-	/* Check input arguments */
-	if ((params == NULL) ||
-		(params->n_ports_in == 0) ||
-		(params->n_ports_out == 0))
-		return NULL;
-
-	/* Memory allocation */
-	size = RTE_CACHE_LINE_ROUNDUP(sizeof(struct pipeline_firewall));
-	p = rte_zmalloc(NULL, size, RTE_CACHE_LINE_SIZE);
-	p_fw = (struct pipeline_firewall *) p;
-	if (p == NULL)
-		return NULL;
-
-	strcpy(p->name, params->name);
-	p->log_level = params->log_level;
-
-	PLOG(p, HIGH, "Firewall");
-
-	/* Parse arguments */
-	if (pipeline_firewall_parse_args(p_fw, params))
-		return NULL;
-
-	/* Pipeline */
-	{
-		struct rte_pipeline_params pipeline_params = {
-			.name = params->name,
-			.socket_id = params->socket_id,
-			.offset_port_id = 0,
-		};
-
-		p->p = rte_pipeline_create(&pipeline_params);
-		if (p->p == NULL) {
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Input ports */
-	p->n_ports_in = params->n_ports_in;
-	for (i = 0; i < p->n_ports_in; i++) {
-		struct rte_pipeline_port_in_params port_params = {
-			.ops = pipeline_port_in_params_get_ops(
-				&params->port_in[i]),
-			.arg_create = pipeline_port_in_params_convert(
-				&params->port_in[i]),
-			.f_action = NULL,
-			.arg_ah = NULL,
-			.burst_size = params->port_in[i].burst_size,
-		};
-
-		int status = rte_pipeline_port_in_create(p->p,
-			&port_params,
-			&p->port_in_id[i]);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Output ports */
-	p->n_ports_out = params->n_ports_out;
-	for (i = 0; i < p->n_ports_out; i++) {
-		struct rte_pipeline_port_out_params port_params = {
-			.ops = pipeline_port_out_params_get_ops(
-				&params->port_out[i]),
-			.arg_create = pipeline_port_out_params_convert(
-				&params->port_out[i]),
-			.f_action = NULL,
-			.arg_ah = NULL,
-		};
-
-		int status = rte_pipeline_port_out_create(p->p,
-			&port_params,
-			&p->port_out_id[i]);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Tables */
-	p->n_tables = 1;
-	{
-		struct rte_table_acl_params table_acl_params = {
-			.name = params->name,
-			.n_rules = p_fw->n_rules,
-			.n_rule_fields = p_fw->n_rule_fields,
-		};
-
-		struct rte_pipeline_table_params table_params = {
-				.ops = &rte_table_acl_ops,
-				.arg_create = &table_acl_params,
-				.f_action_hit = NULL,
-				.f_action_miss = NULL,
-				.arg_ah = NULL,
-				.action_data_size =
-					sizeof(struct firewall_table_entry) -
-					sizeof(struct rte_pipeline_table_entry),
-			};
-
-		int status;
-
-		memcpy(table_acl_params.field_format,
-			p_fw->field_format,
-			p_fw->field_format_size);
-
-		status = rte_pipeline_table_create(p->p,
-			&table_params,
-			&p->table_id[0]);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Connecting input ports to tables */
-	for (i = 0; i < p->n_ports_in; i++) {
-		int status = rte_pipeline_port_in_connect_to_table(p->p,
-			p->port_in_id[i],
-			p->table_id[0]);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Enable input ports */
-	for (i = 0; i < p->n_ports_in; i++) {
-		int status = rte_pipeline_port_in_enable(p->p,
-			p->port_in_id[i]);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Check pipeline consistency */
-	if (rte_pipeline_check(p->p) < 0) {
-		rte_pipeline_free(p->p);
-		rte_free(p);
-		return NULL;
-	}
-
-	/* Message queues */
-	p->n_msgq = params->n_msgq;
-	for (i = 0; i < p->n_msgq; i++)
-		p->msgq_in[i] = params->msgq_in[i];
-	for (i = 0; i < p->n_msgq; i++)
-		p->msgq_out[i] = params->msgq_out[i];
-
-	/* Message handlers */
-	memcpy(p->handlers, handlers, sizeof(p->handlers));
-	memcpy(p_fw->custom_handlers,
-		custom_handlers,
-		sizeof(p_fw->custom_handlers));
-
-	return p;
-}
-
-static int
-pipeline_firewall_free(void *pipeline)
-{
-	struct pipeline *p = (struct pipeline *) pipeline;
-
-	/* Check input arguments */
-	if (p == NULL)
-		return -1;
-
-	/* Free resources */
-	rte_pipeline_free(p->p);
-	rte_free(p);
-	return 0;
-}
-
-static int
-pipeline_firewall_timer(void *pipeline)
-{
-	struct pipeline *p = (struct pipeline *) pipeline;
-
-	pipeline_msg_req_handle(p);
-	rte_pipeline_flush(p->p);
-
-	return 0;
-}
-
-void *
-pipeline_firewall_msg_req_custom_handler(struct pipeline *p,
-	void *msg)
-{
-	struct pipeline_firewall *p_fw = (struct pipeline_firewall *) p;
-	struct pipeline_custom_msg_req *req = msg;
-	pipeline_msg_req_handler f_handle;
-
-	f_handle = (req->subtype < PIPELINE_FIREWALL_MSG_REQS) ?
-		p_fw->custom_handlers[req->subtype] :
-		pipeline_msg_req_invalid_handler;
-
-	if (f_handle == NULL)
-		f_handle = pipeline_msg_req_invalid_handler;
-
-	return f_handle(p, req);
-}
-
-void *
-pipeline_firewall_msg_req_add_handler(struct pipeline *p, void *msg)
-{
-	struct pipeline_firewall_add_msg_req *req = msg;
-	struct pipeline_firewall_add_msg_rsp *rsp = msg;
-
-	struct rte_table_acl_rule_add_params params;
-	struct firewall_table_entry entry = {
-		.head = {
-			.action = RTE_PIPELINE_ACTION_PORT,
-			{.port_id = p->port_out_id[req->port_id]},
-		},
-	};
-
-	memset(&params, 0, sizeof(params));
-
-	switch (req->key.type) {
-	case PIPELINE_FIREWALL_IPV4_5TUPLE:
-		params.priority = req->priority;
-		params.field_value[0].value.u8 =
-			req->key.key.ipv4_5tuple.proto;
-		params.field_value[0].mask_range.u8 =
-			req->key.key.ipv4_5tuple.proto_mask;
-		params.field_value[1].value.u32 =
-			req->key.key.ipv4_5tuple.src_ip;
-		params.field_value[1].mask_range.u32 =
-			req->key.key.ipv4_5tuple.src_ip_mask;
-		params.field_value[2].value.u32 =
-			req->key.key.ipv4_5tuple.dst_ip;
-		params.field_value[2].mask_range.u32 =
-			req->key.key.ipv4_5tuple.dst_ip_mask;
-		params.field_value[3].value.u16 =
-			req->key.key.ipv4_5tuple.src_port_from;
-		params.field_value[3].mask_range.u16 =
-			req->key.key.ipv4_5tuple.src_port_to;
-		params.field_value[4].value.u16 =
-			req->key.key.ipv4_5tuple.dst_port_from;
-		params.field_value[4].mask_range.u16 =
-			req->key.key.ipv4_5tuple.dst_port_to;
-		break;
-
-	default:
-		rsp->status = -1; /* Error */
-		return rsp;
-	}
-
-	rsp->status = rte_pipeline_table_entry_add(p->p,
-		p->table_id[0],
-		&params,
-		(struct rte_pipeline_table_entry *) &entry,
-		&rsp->key_found,
-		(struct rte_pipeline_table_entry **) &rsp->entry_ptr);
-
-	return rsp;
-}
-
-void *
-pipeline_firewall_msg_req_del_handler(struct pipeline *p, void *msg)
-{
-	struct pipeline_firewall_del_msg_req *req = msg;
-	struct pipeline_firewall_del_msg_rsp *rsp = msg;
-
-	struct rte_table_acl_rule_delete_params params;
-
-	memset(&params, 0, sizeof(params));
-
-	switch (req->key.type) {
-	case PIPELINE_FIREWALL_IPV4_5TUPLE:
-		params.field_value[0].value.u8 =
-			req->key.key.ipv4_5tuple.proto;
-		params.field_value[0].mask_range.u8 =
-			req->key.key.ipv4_5tuple.proto_mask;
-		params.field_value[1].value.u32 =
-			req->key.key.ipv4_5tuple.src_ip;
-		params.field_value[1].mask_range.u32 =
-			req->key.key.ipv4_5tuple.src_ip_mask;
-		params.field_value[2].value.u32 =
-			req->key.key.ipv4_5tuple.dst_ip;
-		params.field_value[2].mask_range.u32 =
-			req->key.key.ipv4_5tuple.dst_ip_mask;
-		params.field_value[3].value.u16 =
-			req->key.key.ipv4_5tuple.src_port_from;
-		params.field_value[3].mask_range.u16 =
-			req->key.key.ipv4_5tuple.src_port_to;
-		params.field_value[4].value.u16 =
-			req->key.key.ipv4_5tuple.dst_port_from;
-		params.field_value[4].mask_range.u16 =
-			req->key.key.ipv4_5tuple.dst_port_to;
-		break;
-
-	default:
-		rsp->status = -1; /* Error */
-		return rsp;
-	}
-
-	rsp->status = rte_pipeline_table_entry_delete(p->p,
-		p->table_id[0],
-		&params,
-		&rsp->key_found,
-		NULL);
-
-	return rsp;
-}
-
-static void *
-pipeline_firewall_msg_req_add_bulk_handler(struct pipeline *p, void *msg)
-{
-	struct pipeline_firewall_add_bulk_msg_req *req = msg;
-	struct pipeline_firewall_add_bulk_msg_rsp *rsp = msg;
-
-	struct rte_table_acl_rule_add_params *params[req->n_keys];
-	struct firewall_table_entry *entries[req->n_keys];
-
-	uint32_t i, n_keys;
-
-	n_keys = req->n_keys;
-
-	for (i = 0; i < n_keys; i++) {
-		entries[i] = rte_zmalloc(NULL,
-				sizeof(struct firewall_table_entry),
-				RTE_CACHE_LINE_SIZE);
-		if (entries[i] == NULL) {
-			rsp->status = -1;
-			return rsp;
-		}
-
-		params[i] = rte_zmalloc(NULL,
-				sizeof(struct rte_table_acl_rule_add_params),
-				RTE_CACHE_LINE_SIZE);
-		if (params[i] == NULL) {
-			rsp->status = -1;
-			return rsp;
-		}
-
-		entries[i]->head.action = RTE_PIPELINE_ACTION_PORT;
-		entries[i]->head.port_id = p->port_out_id[req->port_ids[i]];
-
-		switch (req->keys[i].type) {
-		case PIPELINE_FIREWALL_IPV4_5TUPLE:
-			params[i]->priority = req->priorities[i];
-			params[i]->field_value[0].value.u8 =
-				req->keys[i].key.ipv4_5tuple.proto;
-			params[i]->field_value[0].mask_range.u8 =
-				req->keys[i].key.ipv4_5tuple.proto_mask;
-			params[i]->field_value[1].value.u32 =
-				req->keys[i].key.ipv4_5tuple.src_ip;
-			params[i]->field_value[1].mask_range.u32 =
-				req->keys[i].key.ipv4_5tuple.src_ip_mask;
-			params[i]->field_value[2].value.u32 =
-				req->keys[i].key.ipv4_5tuple.dst_ip;
-			params[i]->field_value[2].mask_range.u32 =
-				req->keys[i].key.ipv4_5tuple.dst_ip_mask;
-			params[i]->field_value[3].value.u16 =
-				req->keys[i].key.ipv4_5tuple.src_port_from;
-			params[i]->field_value[3].mask_range.u16 =
-				req->keys[i].key.ipv4_5tuple.src_port_to;
-			params[i]->field_value[4].value.u16 =
-				req->keys[i].key.ipv4_5tuple.dst_port_from;
-			params[i]->field_value[4].mask_range.u16 =
-				req->keys[i].key.ipv4_5tuple.dst_port_to;
-			break;
-
-		default:
-			rsp->status = -1; /* Error */
-
-			for (i = 0; i < n_keys; i++) {
-				rte_free(entries[i]);
-				rte_free(params[i]);
-			}
-
-			return rsp;
-		}
-	}
-
-	rsp->status = rte_pipeline_table_entry_add_bulk(p->p, p->table_id[0],
-			(void *)params, (struct rte_pipeline_table_entry **)entries,
-			n_keys, req->keys_found,
-			(struct rte_pipeline_table_entry **)req->entries_ptr);
-
-	for (i = 0; i < n_keys; i++) {
-		rte_free(entries[i]);
-		rte_free(params[i]);
-	}
-
-	return rsp;
-}
-
-static void *
-pipeline_firewall_msg_req_del_bulk_handler(struct pipeline *p, void *msg)
-{
-	struct pipeline_firewall_del_bulk_msg_req *req = msg;
-	struct pipeline_firewall_del_bulk_msg_rsp *rsp = msg;
-
-	struct rte_table_acl_rule_delete_params *params[req->n_keys];
-
-	uint32_t i, n_keys;
-
-	n_keys = req->n_keys;
-
-	for (i = 0; i < n_keys; i++) {
-		params[i] = rte_zmalloc(NULL,
-				sizeof(struct rte_table_acl_rule_delete_params),
-				RTE_CACHE_LINE_SIZE);
-		if (params[i] == NULL) {
-			rsp->status = -1;
-			return rsp;
-		}
-
-		switch (req->keys[i].type) {
-		case PIPELINE_FIREWALL_IPV4_5TUPLE:
-			params[i]->field_value[0].value.u8 =
-				req->keys[i].key.ipv4_5tuple.proto;
-			params[i]->field_value[0].mask_range.u8 =
-				req->keys[i].key.ipv4_5tuple.proto_mask;
-			params[i]->field_value[1].value.u32 =
-				req->keys[i].key.ipv4_5tuple.src_ip;
-			params[i]->field_value[1].mask_range.u32 =
-				req->keys[i].key.ipv4_5tuple.src_ip_mask;
-			params[i]->field_value[2].value.u32 =
-				req->keys[i].key.ipv4_5tuple.dst_ip;
-			params[i]->field_value[2].mask_range.u32 =
-				req->keys[i].key.ipv4_5tuple.dst_ip_mask;
-			params[i]->field_value[3].value.u16 =
-				req->keys[i].key.ipv4_5tuple.src_port_from;
-			params[i]->field_value[3].mask_range.u16 =
-				req->keys[i].key.ipv4_5tuple.src_port_to;
-			params[i]->field_value[4].value.u16 =
-				req->keys[i].key.ipv4_5tuple.dst_port_from;
-			params[i]->field_value[4].mask_range.u16 =
-				req->keys[i].key.ipv4_5tuple.dst_port_to;
-			break;
-
-		default:
-			rsp->status = -1; /* Error */
-
-			for (i = 0; i < n_keys; i++)
-				rte_free(params[i]);
-
-			return rsp;
-		}
-	}
-
-	rsp->status = rte_pipeline_table_entry_delete_bulk(p->p, p->table_id[0],
-			(void **)&params, n_keys, req->keys_found, NULL);
-
-	for (i = 0; i < n_keys; i++)
-		rte_free(params[i]);
-
-	return rsp;
-}
-
-void *
-pipeline_firewall_msg_req_add_default_handler(struct pipeline *p, void *msg)
-{
-	struct pipeline_firewall_add_default_msg_req *req = msg;
-	struct pipeline_firewall_add_default_msg_rsp *rsp = msg;
-
-	struct firewall_table_entry default_entry = {
-		.head = {
-			.action = RTE_PIPELINE_ACTION_PORT,
-			{.port_id = p->port_out_id[req->port_id]},
-		},
-	};
-
-	rsp->status = rte_pipeline_table_default_entry_add(p->p,
-		p->table_id[0],
-		(struct rte_pipeline_table_entry *) &default_entry,
-		(struct rte_pipeline_table_entry **) &rsp->entry_ptr);
-
-	return rsp;
-}
-
-void *
-pipeline_firewall_msg_req_del_default_handler(struct pipeline *p, void *msg)
-{
-	struct pipeline_firewall_del_default_msg_rsp *rsp = msg;
-
-	rsp->status = rte_pipeline_table_default_entry_delete(p->p,
-		p->table_id[0],
-		NULL);
-
-	return rsp;
-}
-
-struct pipeline_be_ops pipeline_firewall_be_ops = {
-	.f_init = pipeline_firewall_init,
-	.f_free = pipeline_firewall_free,
-	.f_run = NULL,
-	.f_timer = pipeline_firewall_timer,
-};
diff --git a/examples/ip_pipeline/pipeline/pipeline_firewall_be.h b/examples/ip_pipeline/pipeline/pipeline_firewall_be.h
deleted file mode 100644
index 246f0a6..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_firewall_be.h
+++ /dev/null
@@ -1,147 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#ifndef __INCLUDE_PIPELINE_FIREWALL_BE_H__
-#define __INCLUDE_PIPELINE_FIREWALL_BE_H__
-
-#include "pipeline_common_be.h"
-
-enum pipeline_firewall_key_type {
-	PIPELINE_FIREWALL_IPV4_5TUPLE,
-};
-
-struct pipeline_firewall_key_ipv4_5tuple {
-	uint32_t src_ip;
-	uint32_t src_ip_mask;
-	uint32_t dst_ip;
-	uint32_t dst_ip_mask;
-	uint16_t src_port_from;
-	uint16_t src_port_to;
-	uint16_t dst_port_from;
-	uint16_t dst_port_to;
-	uint8_t proto;
-	uint8_t proto_mask;
-};
-
-struct pipeline_firewall_key {
-	enum pipeline_firewall_key_type type;
-	union {
-		struct pipeline_firewall_key_ipv4_5tuple ipv4_5tuple;
-	} key;
-};
-
-enum pipeline_firewall_msg_req_type {
-	PIPELINE_FIREWALL_MSG_REQ_ADD = 0,
-	PIPELINE_FIREWALL_MSG_REQ_DEL,
-	PIPELINE_FIREWALL_MSG_REQ_ADD_BULK,
-	PIPELINE_FIREWALL_MSG_REQ_DEL_BULK,
-	PIPELINE_FIREWALL_MSG_REQ_ADD_DEFAULT,
-	PIPELINE_FIREWALL_MSG_REQ_DEL_DEFAULT,
-	PIPELINE_FIREWALL_MSG_REQS
-};
-
-/*
- * MSG ADD
- */
-struct pipeline_firewall_add_msg_req {
-	enum pipeline_msg_req_type type;
-	enum pipeline_firewall_msg_req_type subtype;
-
-	/* key */
-	struct pipeline_firewall_key key;
-
-	/* data */
-	int32_t priority;
-	uint32_t port_id;
-};
-
-struct pipeline_firewall_add_msg_rsp {
-	int status;
-	int key_found;
-	void *entry_ptr;
-};
-
-/*
- * MSG DEL
- */
-struct pipeline_firewall_del_msg_req {
-	enum pipeline_msg_req_type type;
-	enum pipeline_firewall_msg_req_type subtype;
-
-	/* key */
-	struct pipeline_firewall_key key;
-};
-
-struct pipeline_firewall_del_msg_rsp {
-	int status;
-	int key_found;
-};
-
-/*
- * MSG ADD BULK
- */
-struct pipeline_firewall_add_bulk_msg_req {
-	enum pipeline_msg_req_type type;
-	enum pipeline_firewall_msg_req_type subtype;
-
-	struct pipeline_firewall_key *keys;
-	uint32_t n_keys;
-
-	uint32_t *priorities;
-	uint32_t *port_ids;
-	int *keys_found;
-	void **entries_ptr;
-};
-struct pipeline_firewall_add_bulk_msg_rsp {
-	int status;
-};
-
-/*
- * MSG DEL BULK
- */
-struct pipeline_firewall_del_bulk_msg_req {
-	enum pipeline_msg_req_type type;
-	enum pipeline_firewall_msg_req_type subtype;
-
-	/* key */
-	struct pipeline_firewall_key *keys;
-	uint32_t n_keys;
-	int *keys_found;
-};
-
-struct pipeline_firewall_del_bulk_msg_rsp {
-	int status;
-};
-
-/*
- * MSG ADD DEFAULT
- */
-struct pipeline_firewall_add_default_msg_req {
-	enum pipeline_msg_req_type type;
-	enum pipeline_firewall_msg_req_type subtype;
-
-	/* data */
-	uint32_t port_id;
-};
-
-struct pipeline_firewall_add_default_msg_rsp {
-	int status;
-	void *entry_ptr;
-};
-
-/*
- * MSG DEL DEFAULT
- */
-struct pipeline_firewall_del_default_msg_req {
-	enum pipeline_msg_req_type type;
-	enum pipeline_firewall_msg_req_type subtype;
-};
-
-struct pipeline_firewall_del_default_msg_rsp {
-	int status;
-};
-
-extern struct pipeline_be_ops pipeline_firewall_be_ops;
-
-#endif
diff --git a/examples/ip_pipeline/pipeline/pipeline_flow_actions.c b/examples/ip_pipeline/pipeline/pipeline_flow_actions.c
deleted file mode 100644
index 021aee1..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_flow_actions.c
+++ /dev/null
@@ -1,1286 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#include <stdio.h>
-#include <string.h>
-#include <sys/queue.h>
-#include <netinet/in.h>
-#include <unistd.h>
-
-#include <rte_common.h>
-#include <rte_hexdump.h>
-#include <rte_malloc.h>
-#include <cmdline_rdline.h>
-#include <cmdline_parse.h>
-#include <cmdline_parse_num.h>
-#include <cmdline_parse_string.h>
-
-#include "app.h"
-#include "pipeline_common_fe.h"
-#include "pipeline_flow_actions.h"
-#include "hash_func.h"
-#include "parser.h"
-
-/*
- * Flow actions pipeline
- */
-#ifndef N_FLOWS_BULK
-#define N_FLOWS_BULK					4096
-#endif
-
-struct app_pipeline_fa_flow {
-	struct pipeline_fa_flow_params params;
-	void *entry_ptr;
-};
-
-struct app_pipeline_fa_dscp {
-	uint32_t traffic_class;
-	enum rte_meter_color color;
-};
-
-struct app_pipeline_fa {
-	/* Parameters */
-	uint32_t n_ports_in;
-	uint32_t n_ports_out;
-	struct pipeline_fa_params params;
-
-	/* Flows */
-	struct app_pipeline_fa_dscp dscp[PIPELINE_FA_N_DSCP];
-	struct app_pipeline_fa_flow *flows;
-} __rte_cache_aligned;
-
-static void*
-app_pipeline_fa_init(struct pipeline_params *params,
-	__rte_unused void *arg)
-{
-	struct app_pipeline_fa *p;
-	uint32_t size, i;
-
-	/* Check input arguments */
-	if ((params == NULL) ||
-		(params->n_ports_in == 0) ||
-		(params->n_ports_out == 0))
-		return NULL;
-
-	/* Memory allocation */
-	size = RTE_CACHE_LINE_ROUNDUP(sizeof(struct app_pipeline_fa));
-	p = rte_zmalloc(NULL, size, RTE_CACHE_LINE_SIZE);
-	if (p == NULL)
-		return NULL;
-
-	/* Initialization */
-	p->n_ports_in = params->n_ports_in;
-	p->n_ports_out = params->n_ports_out;
-	if (pipeline_fa_parse_args(&p->params, params)) {
-		rte_free(p);
-		return NULL;
-	}
-
-	/* Memory allocation */
-	size = RTE_CACHE_LINE_ROUNDUP(
-		p->params.n_flows * sizeof(struct app_pipeline_fa_flow));
-	p->flows = rte_zmalloc(NULL, size, RTE_CACHE_LINE_SIZE);
-	if (p->flows == NULL) {
-		rte_free(p);
-		return NULL;
-	}
-
-	/* Initialization of flow table */
-	for (i = 0; i < p->params.n_flows; i++)
-		pipeline_fa_flow_params_set_default(&p->flows[i].params);
-
-	/* Initialization of DSCP table */
-	for (i = 0; i < RTE_DIM(p->dscp); i++) {
-		p->dscp[i].traffic_class = 0;
-		p->dscp[i].color = e_RTE_METER_GREEN;
-	}
-
-	return (void *) p;
-}
-
-static int
-app_pipeline_fa_free(void *pipeline)
-{
-	struct app_pipeline_fa *p = pipeline;
-
-	/* Check input arguments */
-	if (p == NULL)
-		return -1;
-
-	/* Free resources */
-	rte_free(p->flows);
-	rte_free(p);
-
-	return 0;
-}
-
-static int
-flow_params_check(struct app_pipeline_fa *p,
-	__rte_unused uint32_t meter_update_mask,
-	uint32_t policer_update_mask,
-	uint32_t port_update,
-	struct pipeline_fa_flow_params *params)
-{
-	uint32_t mask, i;
-
-	/* Meter */
-
-	/* Policer */
-	for (i = 0, mask = 1; i < PIPELINE_FA_N_TC_MAX; i++, mask <<= 1) {
-		struct pipeline_fa_policer_params *p = &params->p[i];
-		uint32_t j;
-
-		if ((mask & policer_update_mask) == 0)
-			continue;
-
-		for (j = 0; j < e_RTE_METER_COLORS; j++) {
-			struct pipeline_fa_policer_action *action =
-				&p->action[j];
-
-			if ((action->drop == 0) &&
-				(action->color >= e_RTE_METER_COLORS))
-				return -1;
-		}
-	}
-
-	/* Port */
-	if (port_update && (params->port_id >= p->n_ports_out))
-		return -1;
-
-	return 0;
-}
-
-int
-app_pipeline_fa_flow_config(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t flow_id,
-	uint32_t meter_update_mask,
-	uint32_t policer_update_mask,
-	uint32_t port_update,
-	struct pipeline_fa_flow_params *params)
-{
-	struct app_pipeline_fa *p;
-	struct app_pipeline_fa_flow *flow;
-
-	struct pipeline_fa_flow_config_msg_req *req;
-	struct pipeline_fa_flow_config_msg_rsp *rsp;
-
-	uint32_t i, mask;
-
-	/* Check input arguments */
-	if ((app == NULL) ||
-		((meter_update_mask == 0) &&
-		(policer_update_mask == 0) &&
-		(port_update == 0)) ||
-		(meter_update_mask >= (1 << PIPELINE_FA_N_TC_MAX)) ||
-		(policer_update_mask >= (1 << PIPELINE_FA_N_TC_MAX)) ||
-		(params == NULL))
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id,
-		&pipeline_flow_actions);
-	if (p == NULL)
-		return -1;
-
-	if (flow_params_check(p,
-		meter_update_mask,
-		policer_update_mask,
-		port_update,
-		params) != 0)
-		return -1;
-
-	flow_id %= p->params.n_flows;
-	flow = &p->flows[flow_id];
-
-	/* Allocate and write request */
-	req = app_msg_alloc(app);
-	if (req == NULL)
-		return -1;
-
-	req->type = PIPELINE_MSG_REQ_CUSTOM;
-	req->subtype = PIPELINE_FA_MSG_REQ_FLOW_CONFIG;
-	req->entry_ptr = flow->entry_ptr;
-	req->flow_id = flow_id;
-	req->meter_update_mask = meter_update_mask;
-	req->policer_update_mask = policer_update_mask;
-	req->port_update = port_update;
-	memcpy(&req->params, params, sizeof(*params));
-
-	/* Send request and wait for response */
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL)
-		return -1;
-
-	/* Read response */
-	if (rsp->status ||
-		(rsp->entry_ptr == NULL)) {
-		app_msg_free(app, rsp);
-		return -1;
-	}
-
-	/* Commit flow */
-	for (i = 0, mask = 1; i < PIPELINE_FA_N_TC_MAX; i++, mask <<= 1) {
-		if ((mask & meter_update_mask) == 0)
-			continue;
-
-		memcpy(&flow->params.m[i], &params->m[i], sizeof(params->m[i]));
-	}
-
-	for (i = 0, mask = 1; i < PIPELINE_FA_N_TC_MAX; i++, mask <<= 1) {
-		if ((mask & policer_update_mask) == 0)
-			continue;
-
-		memcpy(&flow->params.p[i], &params->p[i], sizeof(params->p[i]));
-	}
-
-	if (port_update)
-		flow->params.port_id = params->port_id;
-
-	flow->entry_ptr = rsp->entry_ptr;
-
-	/* Free response */
-	app_msg_free(app, rsp);
-
-	return 0;
-}
-
-int
-app_pipeline_fa_flow_config_bulk(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t *flow_id,
-	uint32_t n_flows,
-	uint32_t meter_update_mask,
-	uint32_t policer_update_mask,
-	uint32_t port_update,
-	struct pipeline_fa_flow_params *params)
-{
-	struct app_pipeline_fa *p;
-	struct pipeline_fa_flow_config_bulk_msg_req *req;
-	struct pipeline_fa_flow_config_bulk_msg_rsp *rsp;
-	void **req_entry_ptr;
-	uint32_t *req_flow_id;
-	uint32_t i;
-	int status;
-
-	/* Check input arguments */
-	if ((app == NULL) ||
-		(flow_id == NULL) ||
-		(n_flows == 0) ||
-		((meter_update_mask == 0) &&
-		(policer_update_mask == 0) &&
-		(port_update == 0)) ||
-		(meter_update_mask >= (1 << PIPELINE_FA_N_TC_MAX)) ||
-		(policer_update_mask >= (1 << PIPELINE_FA_N_TC_MAX)) ||
-		(params == NULL))
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id,
-		&pipeline_flow_actions);
-	if (p == NULL)
-		return -1;
-
-	for (i = 0; i < n_flows; i++) {
-		struct pipeline_fa_flow_params *flow_params = &params[i];
-
-		if (flow_params_check(p,
-			meter_update_mask,
-			policer_update_mask,
-			port_update,
-			flow_params) != 0)
-			return -1;
-	}
-
-	/* Allocate and write request */
-	req_entry_ptr = (void **) rte_malloc(NULL,
-		n_flows * sizeof(void *),
-		RTE_CACHE_LINE_SIZE);
-	if (req_entry_ptr == NULL)
-		return -1;
-
-	req_flow_id = (uint32_t *) rte_malloc(NULL,
-		n_flows * sizeof(uint32_t),
-		RTE_CACHE_LINE_SIZE);
-	if (req_flow_id == NULL) {
-		rte_free(req_entry_ptr);
-		return -1;
-	}
-
-	for (i = 0; i < n_flows; i++) {
-		uint32_t fid = flow_id[i] % p->params.n_flows;
-		struct app_pipeline_fa_flow *flow = &p->flows[fid];
-
-		req_flow_id[i] = fid;
-		req_entry_ptr[i] = flow->entry_ptr;
-	}
-
-	req = app_msg_alloc(app);
-	if (req == NULL) {
-		rte_free(req_flow_id);
-		rte_free(req_entry_ptr);
-		return -1;
-	}
-
-	req->type = PIPELINE_MSG_REQ_CUSTOM;
-	req->subtype = PIPELINE_FA_MSG_REQ_FLOW_CONFIG_BULK;
-	req->entry_ptr = req_entry_ptr;
-	req->flow_id = req_flow_id;
-	req->n_flows = n_flows;
-	req->meter_update_mask = meter_update_mask;
-	req->policer_update_mask = policer_update_mask;
-	req->port_update = port_update;
-	req->params = params;
-
-	/* Send request and wait for response */
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL) {
-		rte_free(req_flow_id);
-		rte_free(req_entry_ptr);
-		return -1;
-	}
-
-	/* Read response */
-	status = (rsp->n_flows == n_flows) ? 0 : -1;
-
-	/* Commit flows */
-	for (i = 0; i < rsp->n_flows; i++) {
-		uint32_t fid = flow_id[i] % p->params.n_flows;
-		struct app_pipeline_fa_flow *flow = &p->flows[fid];
-		struct pipeline_fa_flow_params *flow_params = &params[i];
-		void *entry_ptr = req_entry_ptr[i];
-		uint32_t j, mask;
-
-		for (j = 0, mask = 1; j < PIPELINE_FA_N_TC_MAX;
-			j++, mask <<= 1) {
-			if ((mask & meter_update_mask) == 0)
-				continue;
-
-			memcpy(&flow->params.m[j],
-				&flow_params->m[j],
-				sizeof(flow_params->m[j]));
-		}
-
-		for (j = 0, mask = 1; j < PIPELINE_FA_N_TC_MAX;
-			j++, mask <<= 1) {
-			if ((mask & policer_update_mask) == 0)
-				continue;
-
-			memcpy(&flow->params.p[j],
-				&flow_params->p[j],
-				sizeof(flow_params->p[j]));
-		}
-
-		if (port_update)
-			flow->params.port_id = flow_params->port_id;
-
-		flow->entry_ptr = entry_ptr;
-	}
-
-	/* Free response */
-	app_msg_free(app, rsp);
-	rte_free(req_flow_id);
-	rte_free(req_entry_ptr);
-
-	return status;
-}
-
-int
-app_pipeline_fa_dscp_config(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t dscp,
-	uint32_t traffic_class,
-	enum rte_meter_color color)
-{
-	struct app_pipeline_fa *p;
-
-	struct pipeline_fa_dscp_config_msg_req *req;
-	struct pipeline_fa_dscp_config_msg_rsp *rsp;
-
-	/* Check input arguments */
-	if ((app == NULL) ||
-		(dscp >= PIPELINE_FA_N_DSCP) ||
-		(traffic_class >= PIPELINE_FA_N_TC_MAX) ||
-		(color >= e_RTE_METER_COLORS))
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id,
-		&pipeline_flow_actions);
-	if (p == NULL)
-		return -1;
-
-	if (p->params.dscp_enabled == 0)
-		return -1;
-
-	/* Allocate and write request */
-	req = app_msg_alloc(app);
-	if (req == NULL)
-		return -1;
-
-	req->type = PIPELINE_MSG_REQ_CUSTOM;
-	req->subtype = PIPELINE_FA_MSG_REQ_DSCP_CONFIG;
-	req->dscp = dscp;
-	req->traffic_class = traffic_class;
-	req->color = color;
-
-	/* Send request and wait for response */
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL)
-		return -1;
-
-	/* Read response */
-	if (rsp->status) {
-		app_msg_free(app, rsp);
-		return -1;
-	}
-
-	/* Commit DSCP */
-	p->dscp[dscp].traffic_class = traffic_class;
-	p->dscp[dscp].color = color;
-
-	/* Free response */
-	app_msg_free(app, rsp);
-
-	return 0;
-}
-
-int
-app_pipeline_fa_flow_policer_stats_read(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t flow_id,
-	uint32_t policer_id,
-	int clear,
-	struct pipeline_fa_policer_stats *stats)
-{
-	struct app_pipeline_fa *p;
-	struct app_pipeline_fa_flow *flow;
-
-	struct pipeline_fa_policer_stats_msg_req *req;
-	struct pipeline_fa_policer_stats_msg_rsp *rsp;
-
-	/* Check input arguments */
-	if ((app == NULL) || (stats == NULL))
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id,
-		&pipeline_flow_actions);
-	if (p == NULL)
-		return -1;
-
-	flow_id %= p->params.n_flows;
-	flow = &p->flows[flow_id];
-
-	if ((policer_id >= p->params.n_meters_per_flow) ||
-		(flow->entry_ptr == NULL))
-		return -1;
-
-	/* Allocate and write request */
-	req = app_msg_alloc(app);
-	if (req == NULL)
-		return -1;
-
-	req->type = PIPELINE_MSG_REQ_CUSTOM;
-	req->subtype = PIPELINE_FA_MSG_REQ_POLICER_STATS_READ;
-	req->entry_ptr = flow->entry_ptr;
-	req->policer_id = policer_id;
-	req->clear = clear;
-
-	/* Send request and wait for response */
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL)
-		return -1;
-
-	/* Read response */
-	if (rsp->status) {
-		app_msg_free(app, rsp);
-		return -1;
-	}
-
-	memcpy(stats, &rsp->stats, sizeof(*stats));
-
-	/* Free response */
-	app_msg_free(app, rsp);
-
-	return 0;
-}
-
-static const char *
-color_to_string(enum rte_meter_color color)
-{
-	switch (color) {
-	case e_RTE_METER_GREEN: return "G";
-	case e_RTE_METER_YELLOW: return "Y";
-	case e_RTE_METER_RED: return "R";
-	default: return "?";
-	}
-}
-
-static int
-string_to_color(char *s, enum rte_meter_color *c)
-{
-	if (strcmp(s, "G") == 0) {
-		*c = e_RTE_METER_GREEN;
-		return 0;
-	}
-
-	if (strcmp(s, "Y") == 0) {
-		*c = e_RTE_METER_YELLOW;
-		return 0;
-	}
-
-	if (strcmp(s, "R") == 0) {
-		*c = e_RTE_METER_RED;
-		return 0;
-	}
-
-	return -1;
-}
-
-static const char *
-policer_action_to_string(struct pipeline_fa_policer_action *a)
-{
-	if (a->drop)
-		return "D";
-
-	return color_to_string(a->color);
-}
-
-static int
-string_to_policer_action(char *s, struct pipeline_fa_policer_action *a)
-{
-	if (strcmp(s, "G") == 0) {
-		a->drop = 0;
-		a->color = e_RTE_METER_GREEN;
-		return 0;
-	}
-
-	if (strcmp(s, "Y") == 0) {
-		a->drop = 0;
-		a->color = e_RTE_METER_YELLOW;
-		return 0;
-	}
-
-	if (strcmp(s, "R") == 0) {
-		a->drop = 0;
-		a->color = e_RTE_METER_RED;
-		return 0;
-	}
-
-	if (strcmp(s, "D") == 0) {
-		a->drop = 1;
-		a->color = e_RTE_METER_GREEN;
-		return 0;
-	}
-
-	return -1;
-}
-
-static void
-print_flow(struct app_pipeline_fa *p,
-	uint32_t flow_id,
-	struct app_pipeline_fa_flow *flow)
-{
-	uint32_t i;
-
-	printf("Flow ID = %" PRIu32 "\n", flow_id);
-
-	for (i = 0; i < p->params.n_meters_per_flow; i++) {
-		struct rte_meter_trtcm_params *meter = &flow->params.m[i];
-		struct pipeline_fa_policer_params *policer = &flow->params.p[i];
-
-	printf("\ttrTCM [CIR = %" PRIu64
-		", CBS = %" PRIu64 ", PIR = %" PRIu64
-		", PBS = %" PRIu64	"] Policer [G : %s, Y : %s, R : %s]\n",
-		meter->cir,
-		meter->cbs,
-		meter->pir,
-		meter->pbs,
-		policer_action_to_string(&policer->action[e_RTE_METER_GREEN]),
-		policer_action_to_string(&policer->action[e_RTE_METER_YELLOW]),
-		policer_action_to_string(&policer->action[e_RTE_METER_RED]));
-	}
-
-	printf("\tPort %u (entry_ptr = %p)\n",
-		flow->params.port_id,
-		flow->entry_ptr);
-}
-
-
-static int
-app_pipeline_fa_flow_ls(struct app_params *app,
-		uint32_t pipeline_id)
-{
-	struct app_pipeline_fa *p;
-	uint32_t i;
-
-	/* Check input arguments */
-	if (app == NULL)
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id,
-		&pipeline_flow_actions);
-	if (p == NULL)
-		return -1;
-
-	for (i = 0; i < p->params.n_flows; i++) {
-		struct app_pipeline_fa_flow *flow = &p->flows[i];
-
-		print_flow(p, i, flow);
-	}
-
-	return 0;
-}
-
-static int
-app_pipeline_fa_dscp_ls(struct app_params *app,
-		uint32_t pipeline_id)
-{
-	struct app_pipeline_fa *p;
-	uint32_t i;
-
-	/* Check input arguments */
-	if (app == NULL)
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id,
-		&pipeline_flow_actions);
-	if (p == NULL)
-		return -1;
-
-	if (p->params.dscp_enabled == 0)
-		return -1;
-
-	for (i = 0; i < RTE_DIM(p->dscp); i++) {
-		struct app_pipeline_fa_dscp *dscp =	&p->dscp[i];
-
-		printf("DSCP = %2" PRIu32 ": Traffic class = %" PRIu32
-			", Color = %s\n",
-			i,
-			dscp->traffic_class,
-			color_to_string(dscp->color));
-	}
-
-	return 0;
-}
-
-int
-app_pipeline_fa_load_file(char *filename,
-	uint32_t *flow_ids,
-	struct pipeline_fa_flow_params *p,
-	uint32_t *n_flows,
-	uint32_t *line)
-{
-	FILE *f = NULL;
-	char file_buf[1024];
-	uint32_t i, l;
-
-	/* Check input arguments */
-	if ((filename == NULL) ||
-		(flow_ids == NULL) ||
-		(p == NULL) ||
-		(n_flows == NULL) ||
-		(*n_flows == 0) ||
-		(line == NULL)) {
-		if (line)
-			*line = 0;
-		return -1;
-		}
-
-	/* Open input file */
-	f = fopen(filename, "r");
-	if (f == NULL) {
-		*line = 0;
-		return -1;
-	}
-
-	/* Read file */
-	for (i = 0, l = 1; i < *n_flows; l++) {
-		char *tokens[64];
-		uint32_t n_tokens = RTE_DIM(tokens);
-
-		int status;
-
-		if (fgets(file_buf, sizeof(file_buf), f) == NULL)
-			break;
-
-		status = parse_tokenize_string(file_buf, tokens, &n_tokens);
-		if (status)
-			goto error1;
-
-		if ((n_tokens == 0) || (tokens[0][0] == '#'))
-			continue;
-
-
-		if ((n_tokens != 64) ||
-			/* flow */
-			strcmp(tokens[0], "flow") ||
-			parser_read_uint32(&flow_ids[i], tokens[1]) ||
-
-			/* meter & policer 0 */
-			strcmp(tokens[2], "meter") ||
-			strcmp(tokens[3], "0") ||
-			strcmp(tokens[4], "trtcm") ||
-			parser_read_uint64(&p[i].m[0].cir, tokens[5]) ||
-			parser_read_uint64(&p[i].m[0].pir, tokens[6]) ||
-			parser_read_uint64(&p[i].m[0].cbs, tokens[7]) ||
-			parser_read_uint64(&p[i].m[0].pbs, tokens[8]) ||
-			strcmp(tokens[9], "policer") ||
-			strcmp(tokens[10], "0") ||
-			strcmp(tokens[11], "g") ||
-			string_to_policer_action(tokens[12],
-				&p[i].p[0].action[e_RTE_METER_GREEN]) ||
-			strcmp(tokens[13], "y") ||
-			string_to_policer_action(tokens[14],
-				&p[i].p[0].action[e_RTE_METER_YELLOW]) ||
-			strcmp(tokens[15], "r") ||
-			string_to_policer_action(tokens[16],
-				&p[i].p[0].action[e_RTE_METER_RED]) ||
-
-			/* meter & policer 1 */
-			strcmp(tokens[17], "meter") ||
-			strcmp(tokens[18], "1") ||
-			strcmp(tokens[19], "trtcm") ||
-			parser_read_uint64(&p[i].m[1].cir, tokens[20]) ||
-			parser_read_uint64(&p[i].m[1].pir, tokens[21]) ||
-			parser_read_uint64(&p[i].m[1].cbs, tokens[22]) ||
-			parser_read_uint64(&p[i].m[1].pbs, tokens[23]) ||
-			strcmp(tokens[24], "policer") ||
-			strcmp(tokens[25], "1") ||
-			strcmp(tokens[26], "g") ||
-			string_to_policer_action(tokens[27],
-				&p[i].p[1].action[e_RTE_METER_GREEN]) ||
-			strcmp(tokens[28], "y") ||
-			string_to_policer_action(tokens[29],
-				&p[i].p[1].action[e_RTE_METER_YELLOW]) ||
-			strcmp(tokens[30], "r") ||
-			string_to_policer_action(tokens[31],
-				&p[i].p[1].action[e_RTE_METER_RED]) ||
-
-			/* meter & policer 2 */
-			strcmp(tokens[32], "meter") ||
-			strcmp(tokens[33], "2") ||
-			strcmp(tokens[34], "trtcm") ||
-			parser_read_uint64(&p[i].m[2].cir, tokens[35]) ||
-			parser_read_uint64(&p[i].m[2].pir, tokens[36]) ||
-			parser_read_uint64(&p[i].m[2].cbs, tokens[37]) ||
-			parser_read_uint64(&p[i].m[2].pbs, tokens[38]) ||
-			strcmp(tokens[39], "policer") ||
-			strcmp(tokens[40], "2") ||
-			strcmp(tokens[41], "g") ||
-			string_to_policer_action(tokens[42],
-				&p[i].p[2].action[e_RTE_METER_GREEN]) ||
-			strcmp(tokens[43], "y") ||
-			string_to_policer_action(tokens[44],
-				&p[i].p[2].action[e_RTE_METER_YELLOW]) ||
-			strcmp(tokens[45], "r") ||
-			string_to_policer_action(tokens[46],
-				&p[i].p[2].action[e_RTE_METER_RED]) ||
-
-			/* meter & policer 3 */
-			strcmp(tokens[47], "meter") ||
-			strcmp(tokens[48], "3") ||
-			strcmp(tokens[49], "trtcm") ||
-			parser_read_uint64(&p[i].m[3].cir, tokens[50]) ||
-			parser_read_uint64(&p[i].m[3].pir, tokens[51]) ||
-			parser_read_uint64(&p[i].m[3].cbs, tokens[52]) ||
-			parser_read_uint64(&p[i].m[3].pbs, tokens[53]) ||
-			strcmp(tokens[54], "policer") ||
-			strcmp(tokens[55], "3") ||
-			strcmp(tokens[56], "g") ||
-			string_to_policer_action(tokens[57],
-				&p[i].p[3].action[e_RTE_METER_GREEN]) ||
-			strcmp(tokens[58], "y") ||
-			string_to_policer_action(tokens[59],
-				&p[i].p[3].action[e_RTE_METER_YELLOW]) ||
-			strcmp(tokens[60], "r") ||
-			string_to_policer_action(tokens[61],
-				&p[i].p[3].action[e_RTE_METER_RED]) ||
-
-			/* port */
-			strcmp(tokens[62], "port") ||
-			parser_read_uint32(&p[i].port_id, tokens[63]))
-			goto error1;
-
-		i++;
-	}
-
-	/* Close file */
-	*n_flows = i;
-	fclose(f);
-	return 0;
-
-error1:
-	*line = l;
-	fclose(f);
-	return -1;
-}
-
-/*
- * action
- *
- * flow meter, policer and output port configuration:
- *    p <pipelineid> action flow <flowid> meter <meterid> trtcm <cir> <pir> <cbs> <pbs>
- *
- *    p <pipelineid> action flow <flowid> policer <policerid> g <gaction> y <yaction> r <raction>
- *  <action> is one of the following:
- *      G = recolor to green
- *      Y = recolor as yellow
- *      R = recolor as red
- *      D = drop
- *
- *    p <pipelineid> action flow <flowid> port <port ID>
- *
- *    p <pipelineid> action flow bulk <file>
- *
- * flow policer stats read:
- *    p <pipelineid> action flow <flowid> stats
- *
- * flow ls:
- *    p <pipelineid> action flow ls
- *
- * dscp table configuration:
- *    p <pipelineid> action dscp <dscpid> class <class ID> color <color>
- *
- * dscp table ls:
- *    p <pipelineid> action dscp ls
-**/
-
-struct cmd_action_result {
-	cmdline_fixed_string_t p_string;
-	uint32_t pipeline_id;
-	cmdline_fixed_string_t action_string;
-	cmdline_multi_string_t multi_string;
-};
-
-static void
-cmd_action_parsed(
-	void *parsed_result,
-	__rte_unused struct cmdline *cl,
-	void *data)
-{
-	struct cmd_action_result *params = parsed_result;
-	struct app_params *app = data;
-
-	char *tokens[16];
-	uint32_t n_tokens = RTE_DIM(tokens);
-	int status;
-
-	status = parse_tokenize_string(params->multi_string, tokens, &n_tokens);
-	if (status != 0) {
-		printf(CMD_MSG_TOO_MANY_ARGS, "action");
-		return;
-	}
-
-	/* action flow meter */
-	if ((n_tokens >= 3) &&
-		(strcmp(tokens[0], "flow") == 0) &&
-		strcmp(tokens[1], "bulk") &&
-		strcmp(tokens[1], "ls") &&
-		(strcmp(tokens[2], "meter") == 0)) {
-		struct pipeline_fa_flow_params flow_params;
-		uint32_t flow_id, meter_id;
-
-		if (n_tokens != 9) {
-			printf(CMD_MSG_MISMATCH_ARGS, "action flow meter");
-			return;
-		}
-
-		memset(&flow_params, 0, sizeof(flow_params));
-
-		if (parser_read_uint32(&flow_id, tokens[1])) {
-			printf(CMD_MSG_INVALID_ARG, "flowid");
-			return;
-		}
-
-		if (parser_read_uint32(&meter_id, tokens[3]) ||
-			(meter_id >= PIPELINE_FA_N_TC_MAX)) {
-			printf(CMD_MSG_INVALID_ARG, "meterid");
-			return;
-		}
-
-		if (strcmp(tokens[4], "trtcm")) {
-			printf(CMD_MSG_ARG_NOT_FOUND, "trtcm");
-			return;
-		}
-
-		if (parser_read_uint64(&flow_params.m[meter_id].cir, tokens[5])) {
-			printf(CMD_MSG_INVALID_ARG, "cir");
-			return;
-		}
-
-		if (parser_read_uint64(&flow_params.m[meter_id].pir, tokens[6])) {
-			printf(CMD_MSG_INVALID_ARG, "pir");
-			return;
-		}
-
-		if (parser_read_uint64(&flow_params.m[meter_id].cbs, tokens[7])) {
-			printf(CMD_MSG_INVALID_ARG, "cbs");
-			return;
-		}
-
-		if (parser_read_uint64(&flow_params.m[meter_id].pbs, tokens[8])) {
-			printf(CMD_MSG_INVALID_ARG, "pbs");
-			return;
-		}
-
-		status = app_pipeline_fa_flow_config(app,
-			params->pipeline_id,
-			flow_id,
-			1 << meter_id,
-			0,
-			0,
-			&flow_params);
-		if (status)
-			printf(CMD_MSG_FAIL, "action flow meter");
-
-		return;
-	} /* action flow meter */
-
-	/* action flow policer */
-	if ((n_tokens >= 3) &&
-		(strcmp(tokens[0], "flow") == 0) &&
-		strcmp(tokens[1], "bulk") &&
-		strcmp(tokens[1], "ls") &&
-		(strcmp(tokens[2], "policer") == 0)) {
-		struct pipeline_fa_flow_params flow_params;
-		uint32_t flow_id, policer_id;
-
-		if (n_tokens != 10) {
-			printf(CMD_MSG_MISMATCH_ARGS, "action flow policer");
-			return;
-		}
-
-		memset(&flow_params, 0, sizeof(flow_params));
-
-		if (parser_read_uint32(&flow_id, tokens[1])) {
-			printf(CMD_MSG_INVALID_ARG, "flowid");
-			return;
-		}
-
-		if (parser_read_uint32(&policer_id, tokens[3]) ||
-			(policer_id >= PIPELINE_FA_N_TC_MAX)) {
-			printf(CMD_MSG_INVALID_ARG, "policerid");
-			return;
-		}
-
-		if (strcmp(tokens[4], "g")) {
-			printf(CMD_MSG_ARG_NOT_FOUND, "g");
-			return;
-		}
-
-		if (string_to_policer_action(tokens[5],
-			&flow_params.p[policer_id].action[e_RTE_METER_GREEN])) {
-			printf(CMD_MSG_INVALID_ARG, "gaction");
-			return;
-		}
-
-		if (strcmp(tokens[6], "y")) {
-			printf(CMD_MSG_ARG_NOT_FOUND, "y");
-			return;
-		}
-
-		if (string_to_policer_action(tokens[7],
-			&flow_params.p[policer_id].action[e_RTE_METER_YELLOW])) {
-			printf(CMD_MSG_INVALID_ARG, "yaction");
-			return;
-		}
-
-		if (strcmp(tokens[8], "r")) {
-			printf(CMD_MSG_ARG_NOT_FOUND, "r");
-			return;
-		}
-
-		if (string_to_policer_action(tokens[9],
-			&flow_params.p[policer_id].action[e_RTE_METER_RED])) {
-			printf(CMD_MSG_INVALID_ARG, "raction");
-			return;
-		}
-
-		status = app_pipeline_fa_flow_config(app,
-			params->pipeline_id,
-			flow_id,
-			0,
-			1 << policer_id,
-			0,
-			&flow_params);
-		if (status != 0)
-			printf(CMD_MSG_FAIL, "action flow policer");
-
-		return;
-	} /* action flow policer */
-
-	/* action flow port */
-	if ((n_tokens >= 3) &&
-		(strcmp(tokens[0], "flow") == 0) &&
-		strcmp(tokens[1], "bulk") &&
-		strcmp(tokens[1], "ls") &&
-		(strcmp(tokens[2], "port") == 0)) {
-		struct pipeline_fa_flow_params flow_params;
-		uint32_t flow_id, port_id;
-
-		if (n_tokens != 4) {
-			printf(CMD_MSG_MISMATCH_ARGS, "action flow port");
-			return;
-		}
-
-		memset(&flow_params, 0, sizeof(flow_params));
-
-		if (parser_read_uint32(&flow_id, tokens[1])) {
-			printf(CMD_MSG_INVALID_ARG, "flowid");
-			return;
-		}
-
-		if (parser_read_uint32(&port_id, tokens[3])) {
-			printf(CMD_MSG_INVALID_ARG, "portid");
-			return;
-		}
-
-		flow_params.port_id = port_id;
-
-		status = app_pipeline_fa_flow_config(app,
-			params->pipeline_id,
-			flow_id,
-			0,
-			0,
-			1,
-			&flow_params);
-		if (status)
-			printf(CMD_MSG_FAIL, "action flow port");
-
-		return;
-	} /* action flow port */
-
-	/* action flow stats */
-	if ((n_tokens >= 3) &&
-		(strcmp(tokens[0], "flow") == 0) &&
-		strcmp(tokens[1], "bulk") &&
-		strcmp(tokens[1], "ls") &&
-		(strcmp(tokens[2], "stats") == 0)) {
-		struct pipeline_fa_policer_stats stats;
-		uint32_t flow_id, policer_id;
-
-		if (n_tokens != 3) {
-			printf(CMD_MSG_MISMATCH_ARGS, "action flow stats");
-			return;
-		}
-
-		if (parser_read_uint32(&flow_id, tokens[1])) {
-			printf(CMD_MSG_INVALID_ARG, "flowid");
-			return;
-		}
-
-		for (policer_id = 0;
-			policer_id < PIPELINE_FA_N_TC_MAX;
-			policer_id++) {
-			status = app_pipeline_fa_flow_policer_stats_read(app,
-				params->pipeline_id,
-				flow_id,
-				policer_id,
-				1,
-				&stats);
-			if (status != 0) {
-				printf(CMD_MSG_FAIL, "action flow stats");
-				return;
-			}
-
-			/* Display stats */
-			printf("\tPolicer: %" PRIu32
-				"\tPkts G: %" PRIu64
-				"\tPkts Y: %" PRIu64
-				"\tPkts R: %" PRIu64
-				"\tPkts D: %" PRIu64 "\n",
-				policer_id,
-				stats.n_pkts[e_RTE_METER_GREEN],
-				stats.n_pkts[e_RTE_METER_YELLOW],
-				stats.n_pkts[e_RTE_METER_RED],
-				stats.n_pkts_drop);
-		}
-
-		return;
-	} /* action flow stats */
-
-	/* action flow bulk */
-	if ((n_tokens >= 2) &&
-		(strcmp(tokens[0], "flow") == 0) &&
-		(strcmp(tokens[1], "bulk") == 0)) {
-		struct pipeline_fa_flow_params *flow_params;
-		uint32_t *flow_ids, n_flows, line;
-		char *filename;
-
-		if (n_tokens != 3) {
-			printf(CMD_MSG_MISMATCH_ARGS, "action flow bulk");
-			return;
-		}
-
-		filename = tokens[2];
-
-		n_flows = APP_PIPELINE_FA_MAX_RECORDS_IN_FILE;
-		flow_ids = malloc(n_flows * sizeof(uint32_t));
-		if (flow_ids == NULL) {
-			printf(CMD_MSG_OUT_OF_MEMORY);
-			return;
-		}
-
-		flow_params = malloc(n_flows * sizeof(struct pipeline_fa_flow_params));
-		if (flow_params == NULL) {
-			printf(CMD_MSG_OUT_OF_MEMORY);
-			free(flow_ids);
-			return;
-		}
-
-		status = app_pipeline_fa_load_file(filename,
-			flow_ids,
-			flow_params,
-			&n_flows,
-			&line);
-		if (status) {
-			printf(CMD_MSG_FILE_ERR, filename, line);
-			free(flow_params);
-			free(flow_ids);
-			return;
-		}
-
-		status = app_pipeline_fa_flow_config_bulk(app,
-			params->pipeline_id,
-			flow_ids,
-			n_flows,
-			0xF,
-			0xF,
-			1,
-			flow_params);
-		if (status)
-			printf(CMD_MSG_FAIL, "action flow bulk");
-
-		free(flow_params);
-		free(flow_ids);
-		return;
-	} /* action flow bulk */
-
-	/* action flow ls */
-	if ((n_tokens >= 2) &&
-		(strcmp(tokens[0], "flow") == 0) &&
-		(strcmp(tokens[1], "ls") == 0)) {
-		if (n_tokens != 2) {
-			printf(CMD_MSG_MISMATCH_ARGS, "action flow ls");
-			return;
-		}
-
-		status = app_pipeline_fa_flow_ls(app,
-			params->pipeline_id);
-		if (status)
-			printf(CMD_MSG_FAIL, "action flow ls");
-
-		return;
-	} /* action flow ls */
-
-	/* action dscp */
-	if ((n_tokens >= 2) &&
-		(strcmp(tokens[0], "dscp") == 0) &&
-		strcmp(tokens[1], "ls")) {
-		uint32_t dscp_id, tc_id;
-		enum rte_meter_color color;
-
-		if (n_tokens != 6) {
-			printf(CMD_MSG_MISMATCH_ARGS, "action dscp");
-			return;
-		}
-
-		if (parser_read_uint32(&dscp_id, tokens[1])) {
-			printf(CMD_MSG_INVALID_ARG, "dscpid");
-			return;
-		}
-
-		if (strcmp(tokens[2], "class")) {
-			printf(CMD_MSG_ARG_NOT_FOUND, "class");
-			return;
-		}
-
-		if (parser_read_uint32(&tc_id, tokens[3])) {
-			printf(CMD_MSG_INVALID_ARG, "classid");
-			return;
-		}
-
-		if (strcmp(tokens[4], "color")) {
-			printf(CMD_MSG_ARG_NOT_FOUND, "color");
-			return;
-		}
-
-		if (string_to_color(tokens[5], &color)) {
-			printf(CMD_MSG_INVALID_ARG, "colorid");
-			return;
-		}
-
-		status = app_pipeline_fa_dscp_config(app,
-			params->pipeline_id,
-			dscp_id,
-			tc_id,
-			color);
-		if (status != 0)
-			printf(CMD_MSG_FAIL, "action dscp");
-
-		return;
-	} /* action dscp */
-
-	/* action dscp ls */
-	if ((n_tokens >= 2) &&
-		(strcmp(tokens[0], "dscp") == 0) &&
-		(strcmp(tokens[1], "ls") == 0)) {
-		if (n_tokens != 2) {
-			printf(CMD_MSG_MISMATCH_ARGS, "action dscp ls");
-			return;
-		}
-
-		status = app_pipeline_fa_dscp_ls(app,
-			params->pipeline_id);
-		if (status)
-			printf(CMD_MSG_FAIL, "action dscp ls");
-
-		return;
-	} /* action dscp ls */
-
-	printf(CMD_MSG_FAIL, "action");
-}
-
-static cmdline_parse_token_string_t cmd_action_p_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_action_result, p_string, "p");
-
-static cmdline_parse_token_num_t cmd_action_pipeline_id =
-	TOKEN_NUM_INITIALIZER(struct cmd_action_result, pipeline_id, UINT32);
-
-static cmdline_parse_token_string_t cmd_action_action_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_action_result, action_string, "action");
-
-static cmdline_parse_token_string_t cmd_action_multi_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_action_result, multi_string,
-	TOKEN_STRING_MULTI);
-
-cmdline_parse_inst_t cmd_action = {
-	.f = cmd_action_parsed,
-	.data = NULL,
-	.help_str = "flow actions (meter, policer, policer stats, dscp table)",
-	.tokens = {
-		(void *) &cmd_action_p_string,
-		(void *) &cmd_action_pipeline_id,
-		(void *) &cmd_action_action_string,
-		(void *) &cmd_action_multi_string,
-		NULL,
-	},
-};
-
-static cmdline_parse_ctx_t pipeline_cmds[] = {
-	(cmdline_parse_inst_t *) &cmd_action,
-	NULL,
-};
-
-static struct pipeline_fe_ops pipeline_flow_actions_fe_ops = {
-	.f_init = app_pipeline_fa_init,
-	.f_post_init = NULL,
-	.f_free = app_pipeline_fa_free,
-	.f_track = app_pipeline_track_default,
-	.cmds = pipeline_cmds,
-};
-
-struct pipeline_type pipeline_flow_actions = {
-	.name = "FLOW_ACTIONS",
-	.be_ops = &pipeline_flow_actions_be_ops,
-	.fe_ops = &pipeline_flow_actions_fe_ops,
-};
diff --git a/examples/ip_pipeline/pipeline/pipeline_flow_actions.h b/examples/ip_pipeline/pipeline/pipeline_flow_actions.h
deleted file mode 100644
index 885923e..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_flow_actions.h
+++ /dev/null
@@ -1,60 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#ifndef __INCLUDE_PIPELINE_FLOW_ACTIONS_H__
-#define __INCLUDE_PIPELINE_FLOW_ACTIONS_H__
-
-#include <rte_meter.h>
-
-#include "pipeline.h"
-#include "pipeline_flow_actions_be.h"
-
-int
-app_pipeline_fa_flow_config(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t flow_id,
-	uint32_t meter_update_mask,
-	uint32_t policer_update_mask,
-	uint32_t port_update,
-	struct pipeline_fa_flow_params *params);
-
-int
-app_pipeline_fa_flow_config_bulk(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t *flow_id,
-	uint32_t n_flows,
-	uint32_t meter_update_mask,
-	uint32_t policer_update_mask,
-	uint32_t port_update,
-	struct pipeline_fa_flow_params *params);
-
-int
-app_pipeline_fa_dscp_config(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t dscp,
-	uint32_t traffic_class,
-	enum rte_meter_color color);
-
-int
-app_pipeline_fa_flow_policer_stats_read(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t flow_id,
-	uint32_t policer_id,
-	int clear,
-	struct pipeline_fa_policer_stats *stats);
-
-#ifndef APP_PIPELINE_FA_MAX_RECORDS_IN_FILE
-#define APP_PIPELINE_FA_MAX_RECORDS_IN_FILE		65536
-#endif
-
-int
-app_pipeline_fa_load_file(char *filename,
-	uint32_t *flow_ids,
-	struct pipeline_fa_flow_params *p,
-	uint32_t *n_flows,
-	uint32_t *line);
-
-extern struct pipeline_type pipeline_flow_actions;
-
-#endif
diff --git a/examples/ip_pipeline/pipeline/pipeline_flow_actions_be.c b/examples/ip_pipeline/pipeline/pipeline_flow_actions_be.c
deleted file mode 100644
index 9599b7d..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_flow_actions_be.c
+++ /dev/null
@@ -1,960 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#include <string.h>
-
-#include <rte_common.h>
-#include <rte_malloc.h>
-#include <rte_cycles.h>
-#include <rte_table_array.h>
-#include <rte_byteorder.h>
-#include <rte_ip.h>
-
-#include "pipeline_actions_common.h"
-#include "pipeline_flow_actions_be.h"
-#include "parser.h"
-#include "hash_func.h"
-
-int
-pipeline_fa_flow_params_set_default(struct pipeline_fa_flow_params *params)
-{
-	uint32_t i;
-
-	if (params == NULL)
-		return -1;
-
-	for (i = 0; i < PIPELINE_FA_N_TC_MAX; i++) {
-		struct rte_meter_trtcm_params *m = &params->m[i];
-
-		m->cir = 1;
-		m->cbs = 1;
-		m->pir = 1;
-		m->pbs = 2;
-	}
-
-	for (i = 0; i < PIPELINE_FA_N_TC_MAX; i++) {
-		struct pipeline_fa_policer_params *p = &params->p[i];
-		uint32_t j;
-
-		for (j = 0; j < e_RTE_METER_COLORS; j++) {
-			struct pipeline_fa_policer_action *a = &p->action[j];
-
-			a->drop = 0;
-			a->color = (enum rte_meter_color) j;
-		}
-	}
-
-	params->port_id = 0;
-
-	return 0;
-}
-
-struct dscp_entry {
-	uint32_t traffic_class;
-	enum rte_meter_color color;
-};
-
-struct pipeline_flow_actions {
-	struct pipeline p;
-	struct pipeline_fa_params params;
-	pipeline_msg_req_handler custom_handlers[PIPELINE_FA_MSG_REQS];
-
-	struct dscp_entry dscp[PIPELINE_FA_N_DSCP];
-} __rte_cache_aligned;
-
-static void *
-pipeline_fa_msg_req_custom_handler(struct pipeline *p, void *msg);
-
-static pipeline_msg_req_handler handlers[] = {
-	[PIPELINE_MSG_REQ_PING] =
-		pipeline_msg_req_ping_handler,
-	[PIPELINE_MSG_REQ_STATS_PORT_IN] =
-		pipeline_msg_req_stats_port_in_handler,
-	[PIPELINE_MSG_REQ_STATS_PORT_OUT] =
-		pipeline_msg_req_stats_port_out_handler,
-	[PIPELINE_MSG_REQ_STATS_TABLE] =
-		pipeline_msg_req_stats_table_handler,
-	[PIPELINE_MSG_REQ_PORT_IN_ENABLE] =
-		pipeline_msg_req_port_in_enable_handler,
-	[PIPELINE_MSG_REQ_PORT_IN_DISABLE] =
-		pipeline_msg_req_port_in_disable_handler,
-	[PIPELINE_MSG_REQ_CUSTOM] =
-		pipeline_fa_msg_req_custom_handler,
-};
-
-static void *
-pipeline_fa_msg_req_flow_config_handler(struct pipeline *p, void *msg);
-
-static void *
-pipeline_fa_msg_req_flow_config_bulk_handler(struct pipeline *p, void *msg);
-
-static void *
-pipeline_fa_msg_req_dscp_config_handler(struct pipeline *p, void *msg);
-
-static void *
-pipeline_fa_msg_req_policer_stats_read_handler(struct pipeline *p, void *msg);
-
-static pipeline_msg_req_handler custom_handlers[] = {
-	[PIPELINE_FA_MSG_REQ_FLOW_CONFIG] =
-		pipeline_fa_msg_req_flow_config_handler,
-	[PIPELINE_FA_MSG_REQ_FLOW_CONFIG_BULK] =
-		pipeline_fa_msg_req_flow_config_bulk_handler,
-	[PIPELINE_FA_MSG_REQ_DSCP_CONFIG] =
-		pipeline_fa_msg_req_dscp_config_handler,
-	[PIPELINE_FA_MSG_REQ_POLICER_STATS_READ] =
-		pipeline_fa_msg_req_policer_stats_read_handler,
-};
-
-/*
- * Flow table
- */
-struct meter_policer {
-	struct rte_meter_trtcm meter;
-	struct pipeline_fa_policer_params policer;
-	struct pipeline_fa_policer_stats stats;
-};
-
-struct flow_table_entry {
-	struct rte_pipeline_table_entry head;
-	struct meter_policer mp[PIPELINE_FA_N_TC_MAX];
-};
-
-static int
-flow_table_entry_set_meter(struct flow_table_entry *entry,
-	uint32_t meter_id,
-	struct pipeline_fa_flow_params *params)
-{
-	struct rte_meter_trtcm *meter = &entry->mp[meter_id].meter;
-	struct rte_meter_trtcm_params *meter_params = &params->m[meter_id];
-
-	return rte_meter_trtcm_config(meter, meter_params);
-}
-
-static void
-flow_table_entry_set_policer(struct flow_table_entry *entry,
-	uint32_t policer_id,
-	struct pipeline_fa_flow_params *params)
-{
-	struct pipeline_fa_policer_params *p0 = &entry->mp[policer_id].policer;
-	struct pipeline_fa_policer_params *p1 = &params->p[policer_id];
-
-	memcpy(p0, p1, sizeof(*p0));
-}
-
-static void
-flow_table_entry_set_port_id(struct pipeline_flow_actions *p,
-	struct flow_table_entry *entry,
-	struct pipeline_fa_flow_params *params)
-{
-	entry->head.action = RTE_PIPELINE_ACTION_PORT;
-	entry->head.port_id = p->p.port_out_id[params->port_id];
-}
-
-static int
-flow_table_entry_set_default(struct pipeline_flow_actions *p,
-	struct flow_table_entry *entry)
-{
-	struct pipeline_fa_flow_params params;
-	uint32_t i;
-
-	pipeline_fa_flow_params_set_default(&params);
-
-	memset(entry, 0, sizeof(*entry));
-
-	flow_table_entry_set_port_id(p, entry, &params);
-
-	for (i = 0; i < PIPELINE_FA_N_TC_MAX; i++) {
-		int status;
-
-		status = flow_table_entry_set_meter(entry, i, &params);
-		if (status)
-			return status;
-	}
-
-	for (i = 0; i < PIPELINE_FA_N_TC_MAX; i++)
-		flow_table_entry_set_policer(entry, i, &params);
-
-	return 0;
-}
-
-static inline uint64_t
-pkt_work(
-	struct rte_mbuf *pkt,
-	struct rte_pipeline_table_entry *table_entry,
-	void *arg,
-	uint64_t time)
-{
-	struct pipeline_flow_actions *p = arg;
-	struct flow_table_entry *entry =
-		(struct flow_table_entry *) table_entry;
-
-	struct ipv4_hdr *pkt_ip = (struct ipv4_hdr *)
-		RTE_MBUF_METADATA_UINT32_PTR(pkt, p->params.ip_hdr_offset);
-	enum rte_meter_color *pkt_color = (enum rte_meter_color *)
-		RTE_MBUF_METADATA_UINT32_PTR(pkt, p->params.color_offset);
-
-	/* Read (IP header) */
-	uint32_t total_length = rte_bswap16(pkt_ip->total_length);
-	uint32_t dscp = pkt_ip->type_of_service >> 2;
-
-	uint32_t tc = p->dscp[dscp].traffic_class;
-	enum rte_meter_color color = p->dscp[dscp].color;
-
-	struct rte_meter_trtcm *meter = &entry->mp[tc].meter;
-	struct pipeline_fa_policer_params *policer = &entry->mp[tc].policer;
-	struct pipeline_fa_policer_stats *stats = &entry->mp[tc].stats;
-
-	/* Read (entry), compute */
-	enum rte_meter_color color2 = rte_meter_trtcm_color_aware_check(meter,
-		time,
-		total_length,
-		color);
-
-	enum rte_meter_color color3 = policer->action[color2].color;
-	uint64_t drop = policer->action[color2].drop;
-
-	/* Read (entry), write (entry, color) */
-	stats->n_pkts[color3] += drop ^ 1LLU;
-	stats->n_pkts_drop += drop;
-	*pkt_color = color3;
-
-	return drop;
-}
-
-static inline uint64_t
-pkt4_work(
-	struct rte_mbuf **pkts,
-	struct rte_pipeline_table_entry **table_entries,
-	void *arg,
-	uint64_t time)
-{
-	struct pipeline_flow_actions *p = arg;
-
-	struct flow_table_entry *entry0 =
-		(struct flow_table_entry *) table_entries[0];
-	struct flow_table_entry *entry1 =
-		(struct flow_table_entry *) table_entries[1];
-	struct flow_table_entry *entry2 =
-		(struct flow_table_entry *) table_entries[2];
-	struct flow_table_entry *entry3 =
-		(struct flow_table_entry *) table_entries[3];
-
-	struct ipv4_hdr *pkt0_ip = (struct ipv4_hdr *)
-		RTE_MBUF_METADATA_UINT32_PTR(pkts[0], p->params.ip_hdr_offset);
-	struct ipv4_hdr *pkt1_ip = (struct ipv4_hdr *)
-		RTE_MBUF_METADATA_UINT32_PTR(pkts[1], p->params.ip_hdr_offset);
-	struct ipv4_hdr *pkt2_ip = (struct ipv4_hdr *)
-		RTE_MBUF_METADATA_UINT32_PTR(pkts[2], p->params.ip_hdr_offset);
-	struct ipv4_hdr *pkt3_ip = (struct ipv4_hdr *)
-		RTE_MBUF_METADATA_UINT32_PTR(pkts[3], p->params.ip_hdr_offset);
-
-	enum rte_meter_color *pkt0_color = (enum rte_meter_color *)
-		RTE_MBUF_METADATA_UINT32_PTR(pkts[0], p->params.color_offset);
-	enum rte_meter_color *pkt1_color = (enum rte_meter_color *)
-		RTE_MBUF_METADATA_UINT32_PTR(pkts[1], p->params.color_offset);
-	enum rte_meter_color *pkt2_color = (enum rte_meter_color *)
-		RTE_MBUF_METADATA_UINT32_PTR(pkts[2], p->params.color_offset);
-	enum rte_meter_color *pkt3_color = (enum rte_meter_color *)
-		RTE_MBUF_METADATA_UINT32_PTR(pkts[3], p->params.color_offset);
-
-	/* Read (IP header) */
-	uint32_t total_length0 = rte_bswap16(pkt0_ip->total_length);
-	uint32_t dscp0 = pkt0_ip->type_of_service >> 2;
-
-	uint32_t total_length1 = rte_bswap16(pkt1_ip->total_length);
-	uint32_t dscp1 = pkt1_ip->type_of_service >> 2;
-
-	uint32_t total_length2 = rte_bswap16(pkt2_ip->total_length);
-	uint32_t dscp2 = pkt2_ip->type_of_service >> 2;
-
-	uint32_t total_length3 = rte_bswap16(pkt3_ip->total_length);
-	uint32_t dscp3 = pkt3_ip->type_of_service >> 2;
-
-	uint32_t tc0 = p->dscp[dscp0].traffic_class;
-	enum rte_meter_color color0 = p->dscp[dscp0].color;
-
-	uint32_t tc1 = p->dscp[dscp1].traffic_class;
-	enum rte_meter_color color1 = p->dscp[dscp1].color;
-
-	uint32_t tc2 = p->dscp[dscp2].traffic_class;
-	enum rte_meter_color color2 = p->dscp[dscp2].color;
-
-	uint32_t tc3 = p->dscp[dscp3].traffic_class;
-	enum rte_meter_color color3 = p->dscp[dscp3].color;
-
-	struct rte_meter_trtcm *meter0 = &entry0->mp[tc0].meter;
-	struct pipeline_fa_policer_params *policer0 = &entry0->mp[tc0].policer;
-	struct pipeline_fa_policer_stats *stats0 = &entry0->mp[tc0].stats;
-
-	struct rte_meter_trtcm *meter1 = &entry1->mp[tc1].meter;
-	struct pipeline_fa_policer_params *policer1 = &entry1->mp[tc1].policer;
-	struct pipeline_fa_policer_stats *stats1 = &entry1->mp[tc1].stats;
-
-	struct rte_meter_trtcm *meter2 = &entry2->mp[tc2].meter;
-	struct pipeline_fa_policer_params *policer2 = &entry2->mp[tc2].policer;
-	struct pipeline_fa_policer_stats *stats2 = &entry2->mp[tc2].stats;
-
-	struct rte_meter_trtcm *meter3 = &entry3->mp[tc3].meter;
-	struct pipeline_fa_policer_params *policer3 = &entry3->mp[tc3].policer;
-	struct pipeline_fa_policer_stats *stats3 = &entry3->mp[tc3].stats;
-
-	/* Read (entry), compute, write (entry) */
-	enum rte_meter_color color2_0 = rte_meter_trtcm_color_aware_check(
-		meter0,
-		time,
-		total_length0,
-		color0);
-
-	enum rte_meter_color color2_1 = rte_meter_trtcm_color_aware_check(
-		meter1,
-		time,
-		total_length1,
-		color1);
-
-	enum rte_meter_color color2_2 = rte_meter_trtcm_color_aware_check(
-		meter2,
-		time,
-		total_length2,
-		color2);
-
-	enum rte_meter_color color2_3 = rte_meter_trtcm_color_aware_check(
-		meter3,
-		time,
-		total_length3,
-		color3);
-
-	enum rte_meter_color color3_0 = policer0->action[color2_0].color;
-	enum rte_meter_color color3_1 = policer1->action[color2_1].color;
-	enum rte_meter_color color3_2 = policer2->action[color2_2].color;
-	enum rte_meter_color color3_3 = policer3->action[color2_3].color;
-
-	uint64_t drop0 = policer0->action[color2_0].drop;
-	uint64_t drop1 = policer1->action[color2_1].drop;
-	uint64_t drop2 = policer2->action[color2_2].drop;
-	uint64_t drop3 = policer3->action[color2_3].drop;
-
-	/* Read (entry), write (entry, color) */
-	stats0->n_pkts[color3_0] += drop0 ^ 1LLU;
-	stats0->n_pkts_drop += drop0;
-
-	stats1->n_pkts[color3_1] += drop1 ^ 1LLU;
-	stats1->n_pkts_drop += drop1;
-
-	stats2->n_pkts[color3_2] += drop2 ^ 1LLU;
-	stats2->n_pkts_drop += drop2;
-
-	stats3->n_pkts[color3_3] += drop3 ^ 1LLU;
-	stats3->n_pkts_drop += drop3;
-
-	*pkt0_color = color3_0;
-	*pkt1_color = color3_1;
-	*pkt2_color = color3_2;
-	*pkt3_color = color3_3;
-
-	return drop0 | (drop1 << 1) | (drop2 << 2) | (drop3 << 3);
-}
-
-PIPELINE_TABLE_AH_HIT_DROP_TIME(fa_table_ah_hit, pkt_work, pkt4_work);
-
-static rte_pipeline_table_action_handler_hit
-get_fa_table_ah_hit(__rte_unused struct pipeline_flow_actions *p)
-{
-	return fa_table_ah_hit;
-}
-
-/*
- * Argument parsing
- */
-int
-pipeline_fa_parse_args(struct pipeline_fa_params *p,
-	struct pipeline_params *params)
-{
-	uint32_t n_flows_present = 0;
-	uint32_t n_meters_per_flow_present = 0;
-	uint32_t flow_id_offset_present = 0;
-	uint32_t ip_hdr_offset_present = 0;
-	uint32_t color_offset_present = 0;
-	uint32_t i;
-
-	/* Default values */
-	p->n_meters_per_flow = 1;
-	p->dscp_enabled = 0;
-
-	for (i = 0; i < params->n_args; i++) {
-		char *arg_name = params->args_name[i];
-		char *arg_value = params->args_value[i];
-
-		/* n_flows */
-		if (strcmp(arg_name, "n_flows") == 0) {
-			int status;
-
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				n_flows_present == 0, params->name,
-				arg_name);
-			n_flows_present = 1;
-
-			status = parser_read_uint32(&p->n_flows,
-				arg_value);
-			PIPELINE_PARSE_ERR_INV_VAL(((status != -EINVAL) &&
-				(p->n_flows != 0)), params->name,
-				arg_name, arg_value);
-			PIPELINE_PARSE_ERR_OUT_RNG((status != -ERANGE),
-				params->name, arg_name, arg_value);
-
-			continue;
-		}
-
-		/* n_meters_per_flow */
-		if (strcmp(arg_name, "n_meters_per_flow") == 0) {
-			int status;
-
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				n_meters_per_flow_present == 0,
-				params->name, arg_name);
-			n_meters_per_flow_present = 1;
-
-			status = parser_read_uint32(&p->n_meters_per_flow,
-				arg_value);
-			PIPELINE_PARSE_ERR_INV_VAL(((status != -EINVAL) &&
-				(p->n_meters_per_flow != 0)),
-				params->name, arg_name, arg_value);
-			PIPELINE_PARSE_ERR_OUT_RNG(((status != -ERANGE) &&
-				(p->n_meters_per_flow <=
-				PIPELINE_FA_N_TC_MAX)), params->name,
-				arg_name, arg_value);
-
-			continue;
-		}
-
-		/* flow_id_offset */
-		if (strcmp(arg_name, "flow_id_offset") == 0) {
-			int status;
-
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				flow_id_offset_present == 0,
-				params->name, arg_name);
-			flow_id_offset_present = 1;
-
-			status = parser_read_uint32(&p->flow_id_offset,
-				arg_value);
-			PIPELINE_PARSE_ERR_INV_VAL((status != -EINVAL),
-				params->name, arg_name, arg_value);
-			PIPELINE_PARSE_ERR_OUT_RNG((status != -ERANGE),
-				params->name, arg_name, arg_value);
-
-			continue;
-		}
-
-		/* ip_hdr_offset */
-		if (strcmp(arg_name, "ip_hdr_offset") == 0) {
-			int status;
-
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				ip_hdr_offset_present == 0,
-				params->name, arg_name);
-			ip_hdr_offset_present = 1;
-
-			status = parser_read_uint32(&p->ip_hdr_offset,
-				arg_value);
-			PIPELINE_PARSE_ERR_INV_VAL((status != -EINVAL),
-				params->name, arg_name, arg_value);
-			PIPELINE_PARSE_ERR_OUT_RNG((status != -ERANGE),
-				params->name, arg_name, arg_value);
-
-			continue;
-		}
-
-		/* color_offset */
-		if (strcmp(arg_name, "color_offset") == 0) {
-			int status;
-
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				color_offset_present == 0, params->name,
-				arg_name);
-			color_offset_present = 1;
-
-			status = parser_read_uint32(&p->color_offset,
-				arg_value);
-			PIPELINE_PARSE_ERR_INV_VAL((status != -EINVAL),
-				params->name, arg_name, arg_value);
-			PIPELINE_PARSE_ERR_OUT_RNG((status != -ERANGE),
-				params->name, arg_name, arg_value);
-
-			p->dscp_enabled = 1;
-
-			continue;
-		}
-
-		/* Unknown argument */
-		PIPELINE_PARSE_ERR_INV_ENT(0, params->name, arg_name);
-	}
-
-	/* Check that mandatory arguments are present */
-	PIPELINE_PARSE_ERR_MANDATORY((n_flows_present), params->name,
-		"n_flows");
-	PIPELINE_PARSE_ERR_MANDATORY((flow_id_offset_present),
-		params->name, "flow_id_offset");
-	PIPELINE_PARSE_ERR_MANDATORY((ip_hdr_offset_present),
-		params->name, "ip_hdr_offset");
-	PIPELINE_PARSE_ERR_MANDATORY((color_offset_present), params->name,
-		"color_offset");
-
-	return 0;
-}
-
-static void
-dscp_init(struct pipeline_flow_actions *p)
-{
-	uint32_t i;
-
-	for (i = 0; i < PIPELINE_FA_N_DSCP; i++) {
-		p->dscp[i].traffic_class = 0;
-		p->dscp[i].color = e_RTE_METER_GREEN;
-	}
-}
-
-static void *pipeline_fa_init(struct pipeline_params *params,
-	__rte_unused void *arg)
-{
-	struct pipeline *p;
-	struct pipeline_flow_actions *p_fa;
-	uint32_t size, i;
-
-	/* Check input arguments */
-	if (params == NULL)
-		return NULL;
-
-	if (params->n_ports_in != params->n_ports_out)
-		return NULL;
-
-	/* Memory allocation */
-	size = RTE_CACHE_LINE_ROUNDUP(
-		sizeof(struct pipeline_flow_actions));
-	p = rte_zmalloc(NULL, size, RTE_CACHE_LINE_SIZE);
-	if (p == NULL)
-		return NULL;
-	p_fa = (struct pipeline_flow_actions *) p;
-
-	strcpy(p->name, params->name);
-	p->log_level = params->log_level;
-
-	PLOG(p, HIGH, "Flow actions");
-
-	/* Parse arguments */
-	if (pipeline_fa_parse_args(&p_fa->params, params))
-		return NULL;
-
-	dscp_init(p_fa);
-
-	/* Pipeline */
-	{
-		struct rte_pipeline_params pipeline_params = {
-			.name = params->name,
-			.socket_id = params->socket_id,
-			.offset_port_id = 0,
-		};
-
-		p->p = rte_pipeline_create(&pipeline_params);
-		if (p->p == NULL) {
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Input ports */
-	p->n_ports_in = params->n_ports_in;
-	for (i = 0; i < p->n_ports_in; i++) {
-		struct rte_pipeline_port_in_params port_params = {
-			.ops = pipeline_port_in_params_get_ops(
-				&params->port_in[i]),
-			.arg_create = pipeline_port_in_params_convert(
-				&params->port_in[i]),
-			.f_action = NULL,
-			.arg_ah = NULL,
-			.burst_size = params->port_in[i].burst_size,
-		};
-
-		int status = rte_pipeline_port_in_create(p->p,
-			&port_params,
-			&p->port_in_id[i]);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Output ports */
-	p->n_ports_out = params->n_ports_out;
-	for (i = 0; i < p->n_ports_out; i++) {
-		struct rte_pipeline_port_out_params port_params = {
-			.ops = pipeline_port_out_params_get_ops(
-				&params->port_out[i]),
-			.arg_create = pipeline_port_out_params_convert(
-				&params->port_out[i]),
-			.f_action = NULL,
-			.arg_ah = NULL,
-		};
-
-		int status = rte_pipeline_port_out_create(p->p,
-			&port_params,
-			&p->port_out_id[i]);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Tables */
-	p->n_tables = 1;
-	{
-		struct rte_table_array_params table_array_params = {
-			.n_entries = p_fa->params.n_flows,
-			.offset = p_fa->params.flow_id_offset,
-		};
-
-		struct rte_pipeline_table_params table_params = {
-			.ops = &rte_table_array_ops,
-			.arg_create = &table_array_params,
-			.f_action_hit = get_fa_table_ah_hit(p_fa),
-			.f_action_miss = NULL,
-			.arg_ah = p_fa,
-			.action_data_size =
-				sizeof(struct flow_table_entry) -
-				sizeof(struct rte_pipeline_table_entry),
-		};
-
-		int status;
-
-		status = rte_pipeline_table_create(p->p,
-			&table_params,
-			&p->table_id[0]);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Connecting input ports to tables */
-	for (i = 0; i < p->n_ports_in; i++) {
-		int status = rte_pipeline_port_in_connect_to_table(p->p,
-			p->port_in_id[i],
-			p->table_id[0]);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Enable input ports */
-	for (i = 0; i < p->n_ports_in; i++) {
-		int status = rte_pipeline_port_in_enable(p->p,
-			p->port_in_id[i]);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Initialize table entries */
-	for (i = 0; i < p_fa->params.n_flows; i++) {
-		struct rte_table_array_key key = {
-			.pos = i,
-		};
-
-		struct flow_table_entry entry;
-		struct rte_pipeline_table_entry *entry_ptr;
-		int key_found, status;
-
-		flow_table_entry_set_default(p_fa, &entry);
-
-		status = rte_pipeline_table_entry_add(p->p,
-			p->table_id[0],
-			&key,
-			(struct rte_pipeline_table_entry *) &entry,
-			&key_found,
-			&entry_ptr);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Check pipeline consistency */
-	if (rte_pipeline_check(p->p) < 0) {
-		rte_pipeline_free(p->p);
-		rte_free(p);
-		return NULL;
-	}
-
-	/* Message queues */
-	p->n_msgq = params->n_msgq;
-	for (i = 0; i < p->n_msgq; i++)
-		p->msgq_in[i] = params->msgq_in[i];
-	for (i = 0; i < p->n_msgq; i++)
-		p->msgq_out[i] = params->msgq_out[i];
-
-	/* Message handlers */
-	memcpy(p->handlers, handlers, sizeof(p->handlers));
-	memcpy(p_fa->custom_handlers,
-		custom_handlers,
-		sizeof(p_fa->custom_handlers));
-
-	return p;
-}
-
-static int
-pipeline_fa_free(void *pipeline)
-{
-	struct pipeline *p = (struct pipeline *) pipeline;
-
-	/* Check input arguments */
-	if (p == NULL)
-		return -1;
-
-	/* Free resources */
-	rte_pipeline_free(p->p);
-	rte_free(p);
-	return 0;
-}
-
-static int
-pipeline_fa_timer(void *pipeline)
-{
-	struct pipeline *p = (struct pipeline *) pipeline;
-
-	pipeline_msg_req_handle(p);
-	rte_pipeline_flush(p->p);
-
-	return 0;
-}
-
-void *
-pipeline_fa_msg_req_custom_handler(struct pipeline *p, void *msg)
-{
-	struct pipeline_flow_actions *p_fa =
-			(struct pipeline_flow_actions *) p;
-	struct pipeline_custom_msg_req *req = msg;
-	pipeline_msg_req_handler f_handle;
-
-	f_handle = (req->subtype < PIPELINE_FA_MSG_REQS) ?
-		p_fa->custom_handlers[req->subtype] :
-		pipeline_msg_req_invalid_handler;
-
-	if (f_handle == NULL)
-		f_handle = pipeline_msg_req_invalid_handler;
-
-	return f_handle(p, req);
-}
-
-void *
-pipeline_fa_msg_req_flow_config_handler(struct pipeline *p, void *msg)
-{
-	struct pipeline_flow_actions *p_fa = (struct pipeline_flow_actions *) p;
-	struct pipeline_fa_flow_config_msg_req *req = msg;
-	struct pipeline_fa_flow_config_msg_rsp *rsp = msg;
-	struct flow_table_entry *entry;
-	uint32_t mask, i;
-
-	/* Set flow table entry to default if not configured before */
-	if (req->entry_ptr == NULL) {
-		struct rte_table_array_key key = {
-			.pos = req->flow_id % p_fa->params.n_flows,
-		};
-
-		struct flow_table_entry default_entry;
-
-		int key_found, status;
-
-		flow_table_entry_set_default(p_fa, &default_entry);
-
-		status = rte_pipeline_table_entry_add(p->p,
-			p->table_id[0],
-			&key,
-			(struct rte_pipeline_table_entry *) &default_entry,
-			&key_found,
-			(struct rte_pipeline_table_entry **) &entry);
-		if (status) {
-			rsp->status = -1;
-			return rsp;
-		}
-	} else
-		entry = (struct flow_table_entry *) req->entry_ptr;
-
-	/* Meter */
-	for (i = 0, mask = 1; i < PIPELINE_FA_N_TC_MAX; i++, mask <<= 1) {
-		int status;
-
-		if ((mask & req->meter_update_mask) == 0)
-			continue;
-
-		status = flow_table_entry_set_meter(entry, i, &req->params);
-		if (status) {
-			rsp->status = -1;
-			return rsp;
-		}
-	}
-
-	/* Policer */
-	for (i = 0, mask = 1; i < PIPELINE_FA_N_TC_MAX; i++, mask <<= 1) {
-		if ((mask & req->policer_update_mask) == 0)
-			continue;
-
-		flow_table_entry_set_policer(entry, i, &req->params);
-	}
-
-	/* Port */
-	if (req->port_update)
-		flow_table_entry_set_port_id(p_fa, entry, &req->params);
-
-	/* Response */
-	rsp->status = 0;
-	rsp->entry_ptr = (void *) entry;
-	return rsp;
-}
-
-void *
-pipeline_fa_msg_req_flow_config_bulk_handler(struct pipeline *p, void *msg)
-{
-	struct pipeline_flow_actions *p_fa = (struct pipeline_flow_actions *) p;
-	struct pipeline_fa_flow_config_bulk_msg_req *req = msg;
-	struct pipeline_fa_flow_config_bulk_msg_rsp *rsp = msg;
-	uint32_t i;
-
-	for (i = 0; i < req->n_flows; i++) {
-		struct flow_table_entry *entry;
-		uint32_t j, mask;
-
-		/* Set flow table entry to default if not configured before */
-		if (req->entry_ptr[i] == NULL) {
-			struct rte_table_array_key key = {
-				.pos = req->flow_id[i] % p_fa->params.n_flows,
-			};
-
-			struct flow_table_entry entry_to_add;
-
-			int key_found, status;
-
-			flow_table_entry_set_default(p_fa, &entry_to_add);
-
-			status = rte_pipeline_table_entry_add(p->p,
-			 p->table_id[0],
-			 &key,
-			 (struct rte_pipeline_table_entry *) &entry_to_add,
-			 &key_found,
-			 (struct rte_pipeline_table_entry **) &entry);
-			if (status) {
-				rsp->n_flows = i;
-				return rsp;
-			}
-
-			req->entry_ptr[i] = (void *) entry;
-		} else
-			entry = (struct flow_table_entry *) req->entry_ptr[i];
-
-		/* Meter */
-		for (j = 0, mask = 1;
-			j < PIPELINE_FA_N_TC_MAX;
-			j++, mask <<= 1) {
-			int status;
-
-			if ((mask & req->meter_update_mask) == 0)
-				continue;
-
-			status = flow_table_entry_set_meter(entry,
-				j, &req->params[i]);
-			if (status) {
-				rsp->n_flows = i;
-				return rsp;
-			}
-		}
-
-		/* Policer */
-		for (j = 0, mask = 1;
-			j < PIPELINE_FA_N_TC_MAX;
-			j++, mask <<= 1) {
-			if ((mask & req->policer_update_mask) == 0)
-				continue;
-
-			flow_table_entry_set_policer(entry,
-			 j, &req->params[i]);
-		}
-
-		/* Port */
-		if (req->port_update)
-			flow_table_entry_set_port_id(p_fa,
-			 entry, &req->params[i]);
-	}
-
-	/* Response */
-	rsp->n_flows = i;
-	return rsp;
-}
-
-void *
-pipeline_fa_msg_req_dscp_config_handler(struct pipeline *p, void *msg)
-{
-	struct pipeline_flow_actions *p_fa = (struct pipeline_flow_actions *) p;
-	struct pipeline_fa_dscp_config_msg_req *req = msg;
-	struct pipeline_fa_dscp_config_msg_rsp *rsp = msg;
-
-	/* Check request */
-	if ((req->dscp >= PIPELINE_FA_N_DSCP) ||
-		(req->traffic_class >= PIPELINE_FA_N_TC_MAX) ||
-		(req->color >= e_RTE_METER_COLORS)) {
-		rsp->status = -1;
-		return rsp;
-	}
-
-	p_fa->dscp[req->dscp].traffic_class = req->traffic_class;
-	p_fa->dscp[req->dscp].color = req->color;
-	rsp->status = 0;
-	return rsp;
-}
-
-void *
-pipeline_fa_msg_req_policer_stats_read_handler(__rte_unused struct pipeline *p,
-	void *msg)
-{
-	struct pipeline_fa_policer_stats_msg_req *req = msg;
-	struct pipeline_fa_policer_stats_msg_rsp *rsp = msg;
-
-	struct flow_table_entry *entry = req->entry_ptr;
-	uint32_t policer_id = req->policer_id;
-	int clear = req->clear;
-
-	/* Check request */
-	if ((req->entry_ptr == NULL) ||
-		(req->policer_id >= PIPELINE_FA_N_TC_MAX)) {
-		rsp->status = -1;
-		return rsp;
-	}
-
-	memcpy(&rsp->stats,
-		&entry->mp[policer_id].stats,
-		sizeof(rsp->stats));
-	if (clear)
-		memset(&entry->mp[policer_id].stats,
-			0, sizeof(entry->mp[policer_id].stats));
-	rsp->status = 0;
-	return rsp;
-}
-
-struct pipeline_be_ops pipeline_flow_actions_be_ops = {
-	.f_init = pipeline_fa_init,
-	.f_free = pipeline_fa_free,
-	.f_run = NULL,
-	.f_timer = pipeline_fa_timer,
-};
diff --git a/examples/ip_pipeline/pipeline/pipeline_flow_actions_be.h b/examples/ip_pipeline/pipeline/pipeline_flow_actions_be.h
deleted file mode 100644
index ef6cb26..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_flow_actions_be.h
+++ /dev/null
@@ -1,139 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#ifndef __INCLUDE_PIPELINE_FLOW_ACTIONS_BE_H__
-#define __INCLUDE_PIPELINE_FLOW_ACTIONS_BE_H__
-
-#include <rte_meter.h>
-
-#include "pipeline_common_be.h"
-
-#ifndef PIPELINE_FA_N_TC_MAX
-#define PIPELINE_FA_N_TC_MAX                               4
-#endif
-
-#define PIPELINE_FA_N_DSCP                                 64
-
-struct pipeline_fa_params {
-	uint32_t n_flows;
-	uint32_t n_meters_per_flow;
-	uint32_t flow_id_offset;
-	uint32_t ip_hdr_offset;
-	uint32_t color_offset;
-	uint32_t dscp_enabled;
-};
-
-int
-pipeline_fa_parse_args(struct pipeline_fa_params *p,
-	struct pipeline_params *params);
-
-struct pipeline_fa_policer_action {
-	uint32_t drop;
-	enum rte_meter_color color;
-};
-
-struct pipeline_fa_policer_params {
-	struct pipeline_fa_policer_action action[e_RTE_METER_COLORS];
-};
-
-struct pipeline_fa_flow_params {
-	struct rte_meter_trtcm_params m[PIPELINE_FA_N_TC_MAX];
-	struct pipeline_fa_policer_params p[PIPELINE_FA_N_TC_MAX];
-	uint32_t port_id;
-};
-
-int
-pipeline_fa_flow_params_set_default(struct pipeline_fa_flow_params *params);
-
-struct pipeline_fa_policer_stats {
-	uint64_t n_pkts[e_RTE_METER_COLORS];
-	uint64_t n_pkts_drop;
-};
-
-enum pipeline_fa_msg_req_type {
-	PIPELINE_FA_MSG_REQ_FLOW_CONFIG = 0,
-	PIPELINE_FA_MSG_REQ_FLOW_CONFIG_BULK,
-	PIPELINE_FA_MSG_REQ_DSCP_CONFIG,
-	PIPELINE_FA_MSG_REQ_POLICER_STATS_READ,
-	PIPELINE_FA_MSG_REQS,
-};
-
-/*
- * MSG FLOW CONFIG
- */
-struct pipeline_fa_flow_config_msg_req {
-	enum pipeline_msg_req_type type;
-	enum pipeline_fa_msg_req_type subtype;
-
-	void *entry_ptr;
-	uint32_t flow_id;
-
-	uint32_t meter_update_mask;
-	uint32_t policer_update_mask;
-	uint32_t port_update;
-	struct pipeline_fa_flow_params params;
-};
-
-struct pipeline_fa_flow_config_msg_rsp {
-	int status;
-	void *entry_ptr;
-};
-
-/*
- * MSG FLOW CONFIG BULK
- */
-struct pipeline_fa_flow_config_bulk_msg_req {
-	enum pipeline_msg_req_type type;
-	enum pipeline_fa_msg_req_type subtype;
-
-	void **entry_ptr;
-	uint32_t *flow_id;
-	uint32_t n_flows;
-
-	uint32_t meter_update_mask;
-	uint32_t policer_update_mask;
-	uint32_t port_update;
-	struct pipeline_fa_flow_params *params;
-};
-
-struct pipeline_fa_flow_config_bulk_msg_rsp {
-	uint32_t n_flows;
-};
-
-/*
- * MSG DSCP CONFIG
- */
-struct pipeline_fa_dscp_config_msg_req {
-	enum pipeline_msg_req_type type;
-	enum pipeline_fa_msg_req_type subtype;
-
-	uint32_t dscp;
-	uint32_t traffic_class;
-	enum rte_meter_color color;
-};
-
-struct pipeline_fa_dscp_config_msg_rsp {
-	int status;
-};
-
-/*
- * MSG POLICER STATS READ
- */
-struct pipeline_fa_policer_stats_msg_req {
-	enum pipeline_msg_req_type type;
-	enum pipeline_fa_msg_req_type subtype;
-
-	void *entry_ptr;
-	uint32_t policer_id;
-	int clear;
-};
-
-struct pipeline_fa_policer_stats_msg_rsp {
-	int status;
-	struct pipeline_fa_policer_stats stats;
-};
-
-extern struct pipeline_be_ops pipeline_flow_actions_be_ops;
-
-#endif
diff --git a/examples/ip_pipeline/pipeline/pipeline_flow_classification.c b/examples/ip_pipeline/pipeline/pipeline_flow_classification.c
deleted file mode 100644
index d39e0fb..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_flow_classification.c
+++ /dev/null
@@ -1,1878 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#include <stdio.h>
-#include <string.h>
-#include <sys/queue.h>
-#include <netinet/in.h>
-#include <unistd.h>
-
-#include <rte_common.h>
-#include <rte_hexdump.h>
-#include <rte_malloc.h>
-#include <cmdline_rdline.h>
-#include <cmdline_parse.h>
-#include <cmdline_parse_num.h>
-#include <cmdline_parse_string.h>
-
-#include "app.h"
-#include "pipeline_common_fe.h"
-#include "pipeline_flow_classification.h"
-#include "hash_func.h"
-#include "parser.h"
-
-/*
- * Key conversion
- */
-
-struct pkt_key_qinq {
-	uint16_t ethertype_svlan;
-	uint16_t svlan;
-	uint16_t ethertype_cvlan;
-	uint16_t cvlan;
-} __attribute__((__packed__));
-
-struct pkt_key_ipv4_5tuple {
-	uint8_t ttl;
-	uint8_t proto;
-	uint16_t checksum;
-	uint32_t ip_src;
-	uint32_t ip_dst;
-	uint16_t port_src;
-	uint16_t port_dst;
-} __attribute__((__packed__));
-
-struct pkt_key_ipv6_5tuple {
-	uint16_t payload_length;
-	uint8_t proto;
-	uint8_t hop_limit;
-	uint8_t ip_src[16];
-	uint8_t ip_dst[16];
-	uint16_t port_src;
-	uint16_t port_dst;
-} __attribute__((__packed__));
-
-static int
-app_pipeline_fc_key_convert(struct pipeline_fc_key *key_in,
-	uint8_t *key_out,
-	uint32_t *signature)
-{
-	uint8_t buffer[PIPELINE_FC_FLOW_KEY_MAX_SIZE];
-	uint8_t m[PIPELINE_FC_FLOW_KEY_MAX_SIZE]; /* key mask */
-	void *key_buffer = (key_out) ? key_out : buffer;
-
-	memset(m, 0xFF, sizeof(m));
-	switch (key_in->type) {
-	case FLOW_KEY_QINQ:
-	{
-		struct pkt_key_qinq *qinq = key_buffer;
-
-		qinq->ethertype_svlan = 0;
-		qinq->svlan = rte_cpu_to_be_16(key_in->key.qinq.svlan);
-		qinq->ethertype_cvlan = 0;
-		qinq->cvlan = rte_cpu_to_be_16(key_in->key.qinq.cvlan);
-
-		if (signature)
-			*signature = (uint32_t) hash_default_key8(qinq, m, 8, 0);
-		return 0;
-	}
-
-	case FLOW_KEY_IPV4_5TUPLE:
-	{
-		struct pkt_key_ipv4_5tuple *ipv4 = key_buffer;
-
-		ipv4->ttl = 0;
-		ipv4->proto = key_in->key.ipv4_5tuple.proto;
-		ipv4->checksum = 0;
-		ipv4->ip_src = rte_cpu_to_be_32(key_in->key.ipv4_5tuple.ip_src);
-		ipv4->ip_dst = rte_cpu_to_be_32(key_in->key.ipv4_5tuple.ip_dst);
-		ipv4->port_src = rte_cpu_to_be_16(key_in->key.ipv4_5tuple.port_src);
-		ipv4->port_dst = rte_cpu_to_be_16(key_in->key.ipv4_5tuple.port_dst);
-
-		if (signature)
-			*signature = (uint32_t) hash_default_key16(ipv4, m, 16, 0);
-		return 0;
-	}
-
-	case FLOW_KEY_IPV6_5TUPLE:
-	{
-		struct pkt_key_ipv6_5tuple *ipv6 = key_buffer;
-
-		memset(ipv6, 0, 64);
-		ipv6->payload_length = 0;
-		ipv6->proto = key_in->key.ipv6_5tuple.proto;
-		ipv6->hop_limit = 0;
-		memcpy(&ipv6->ip_src, &key_in->key.ipv6_5tuple.ip_src, 16);
-		memcpy(&ipv6->ip_dst, &key_in->key.ipv6_5tuple.ip_dst, 16);
-		ipv6->port_src = rte_cpu_to_be_16(key_in->key.ipv6_5tuple.port_src);
-		ipv6->port_dst = rte_cpu_to_be_16(key_in->key.ipv6_5tuple.port_dst);
-
-		if (signature)
-			*signature = (uint32_t) hash_default_key64(ipv6, m, 64, 0);
-		return 0;
-	}
-
-	default:
-		return -1;
-	}
-}
-
-/*
- * Flow classification pipeline
- */
-
-struct app_pipeline_fc_flow {
-	struct pipeline_fc_key key;
-	uint32_t port_id;
-	uint32_t flow_id;
-	uint32_t signature;
-	void *entry_ptr;
-
-	TAILQ_ENTRY(app_pipeline_fc_flow) node;
-};
-
-#define N_BUCKETS                                65536
-
-struct app_pipeline_fc {
-	/* Parameters */
-	uint32_t n_ports_in;
-	uint32_t n_ports_out;
-
-	/* Flows */
-	TAILQ_HEAD(, app_pipeline_fc_flow) flows[N_BUCKETS];
-	uint32_t n_flows;
-
-	/* Default flow */
-	uint32_t default_flow_present;
-	uint32_t default_flow_port_id;
-	void *default_flow_entry_ptr;
-};
-
-static struct app_pipeline_fc_flow *
-app_pipeline_fc_flow_find(struct app_pipeline_fc *p,
-	struct pipeline_fc_key *key)
-{
-	struct app_pipeline_fc_flow *f;
-	uint32_t signature, bucket_id;
-
-	app_pipeline_fc_key_convert(key, NULL, &signature);
-	bucket_id = signature & (N_BUCKETS - 1);
-
-	TAILQ_FOREACH(f, &p->flows[bucket_id], node)
-		if ((signature == f->signature) &&
-			(memcmp(key,
-				&f->key,
-				sizeof(struct pipeline_fc_key)) == 0))
-			return f;
-
-	return NULL;
-}
-
-static void*
-app_pipeline_fc_init(struct pipeline_params *params,
-	__rte_unused void *arg)
-{
-	struct app_pipeline_fc *p;
-	uint32_t size, i;
-
-	/* Check input arguments */
-	if ((params == NULL) ||
-		(params->n_ports_in == 0) ||
-		(params->n_ports_out == 0))
-		return NULL;
-
-	/* Memory allocation */
-	size = RTE_CACHE_LINE_ROUNDUP(sizeof(struct app_pipeline_fc));
-	p = rte_zmalloc(NULL, size, RTE_CACHE_LINE_SIZE);
-	if (p == NULL)
-		return NULL;
-
-	/* Initialization */
-	p->n_ports_in = params->n_ports_in;
-	p->n_ports_out = params->n_ports_out;
-
-	for (i = 0; i < N_BUCKETS; i++)
-		TAILQ_INIT(&p->flows[i]);
-	p->n_flows = 0;
-
-	return (void *) p;
-}
-
-static int
-app_pipeline_fc_free(void *pipeline)
-{
-	struct app_pipeline_fc *p = pipeline;
-	uint32_t i;
-
-	/* Check input arguments */
-	if (p == NULL)
-		return -1;
-
-	/* Free resources */
-	for (i = 0; i < N_BUCKETS; i++)
-		while (!TAILQ_EMPTY(&p->flows[i])) {
-			struct app_pipeline_fc_flow *flow;
-
-			flow = TAILQ_FIRST(&p->flows[i]);
-			TAILQ_REMOVE(&p->flows[i], flow, node);
-			rte_free(flow);
-		}
-
-	rte_free(p);
-	return 0;
-}
-
-static int
-app_pipeline_fc_key_check(struct pipeline_fc_key *key)
-{
-	switch (key->type) {
-	case FLOW_KEY_QINQ:
-	{
-		uint16_t svlan = key->key.qinq.svlan;
-		uint16_t cvlan = key->key.qinq.cvlan;
-
-		if ((svlan & 0xF000) ||
-			(cvlan & 0xF000))
-			return -1;
-
-		return 0;
-	}
-
-	case FLOW_KEY_IPV4_5TUPLE:
-		return 0;
-
-	case FLOW_KEY_IPV6_5TUPLE:
-		return 0;
-
-	default:
-		return -1;
-	}
-}
-
-int
-app_pipeline_fc_load_file_qinq(char *filename,
-	struct pipeline_fc_key *keys,
-	uint32_t *port_ids,
-	uint32_t *flow_ids,
-	uint32_t *n_keys,
-	uint32_t *line)
-{
-	FILE *f = NULL;
-	char file_buf[1024];
-	uint32_t i, l;
-
-	/* Check input arguments */
-	if ((filename == NULL) ||
-		(keys == NULL) ||
-		(port_ids == NULL) ||
-		(flow_ids == NULL) ||
-		(n_keys == NULL) ||
-		(*n_keys == 0) ||
-		(line == NULL)) {
-		if (line)
-			*line = 0;
-		return -1;
-		}
-
-	/* Open input file */
-	f = fopen(filename, "r");
-	if (f == NULL) {
-		*line = 0;
-		return -1;
-	}
-
-	/* Read file */
-	for (i = 0, l = 1; i < *n_keys; l++) {
-		char *tokens[32];
-		uint32_t n_tokens = RTE_DIM(tokens);
-
-		uint16_t svlan, cvlan;
-		uint32_t portid, flowid;
-		int status;
-
-		if (fgets(file_buf, sizeof(file_buf), f) == NULL)
-			break;
-
-		status = parse_tokenize_string(file_buf, tokens, &n_tokens);
-		if (status)
-			goto error1;
-
-		if ((n_tokens == 0) || (tokens[0][0] == '#'))
-			continue;
-
-		if ((n_tokens != 7) ||
-			strcmp(tokens[0], "qinq") ||
-			parser_read_uint16(&svlan, tokens[1]) ||
-			parser_read_uint16(&cvlan, tokens[2]) ||
-			strcmp(tokens[3], "port") ||
-			parser_read_uint32(&portid, tokens[4]) ||
-			strcmp(tokens[5], "id") ||
-			parser_read_uint32(&flowid, tokens[6]))
-			goto error1;
-
-		keys[i].type = FLOW_KEY_QINQ;
-		keys[i].key.qinq.svlan = svlan;
-		keys[i].key.qinq.cvlan = cvlan;
-
-		port_ids[i] = portid;
-		flow_ids[i] = flowid;
-
-		if (app_pipeline_fc_key_check(&keys[i]))
-			goto error1;
-
-		i++;
-	}
-
-	/* Close file */
-	*n_keys = i;
-	fclose(f);
-	return 0;
-
-error1:
-	*line = l;
-	fclose(f);
-	return -1;
-}
-
-int
-app_pipeline_fc_load_file_ipv4(char *filename,
-	struct pipeline_fc_key *keys,
-	uint32_t *port_ids,
-	uint32_t *flow_ids,
-	uint32_t *n_keys,
-	uint32_t *line)
-{
-	FILE *f = NULL;
-	char file_buf[1024];
-	uint32_t i, l;
-
-	/* Check input arguments */
-	if ((filename == NULL) ||
-		(keys == NULL) ||
-		(port_ids == NULL) ||
-		(flow_ids == NULL) ||
-		(n_keys == NULL) ||
-		(*n_keys == 0) ||
-		(line == NULL)) {
-		if (line)
-			*line = 0;
-		return -1;
-		}
-
-	/* Open input file */
-	f = fopen(filename, "r");
-	if (f == NULL) {
-		*line = 0;
-		return -1;
-	}
-
-	/* Read file */
-	for (i = 0, l = 1; i < *n_keys; l++) {
-		char *tokens[32];
-		uint32_t n_tokens = RTE_DIM(tokens);
-
-		struct in_addr sipaddr, dipaddr;
-		uint16_t sport, dport;
-		uint8_t proto;
-		uint32_t portid, flowid;
-		int status;
-
-		if (fgets(file_buf, sizeof(file_buf), f) == NULL)
-			break;
-
-		status = parse_tokenize_string(file_buf, tokens, &n_tokens);
-		if (status)
-			goto error2;
-
-		if ((n_tokens == 0) || (tokens[0][0] == '#'))
-			continue;
-
-		if ((n_tokens != 10) ||
-			strcmp(tokens[0], "ipv4") ||
-			parse_ipv4_addr(tokens[1], &sipaddr) ||
-			parse_ipv4_addr(tokens[2], &dipaddr) ||
-			parser_read_uint16(&sport, tokens[3]) ||
-			parser_read_uint16(&dport, tokens[4]) ||
-			parser_read_uint8(&proto, tokens[5]) ||
-			strcmp(tokens[6], "port") ||
-			parser_read_uint32(&portid, tokens[7]) ||
-			strcmp(tokens[8], "id") ||
-			parser_read_uint32(&flowid, tokens[9]))
-			goto error2;
-
-		keys[i].type = FLOW_KEY_IPV4_5TUPLE;
-		keys[i].key.ipv4_5tuple.ip_src = rte_be_to_cpu_32(sipaddr.s_addr);
-		keys[i].key.ipv4_5tuple.ip_dst = rte_be_to_cpu_32(dipaddr.s_addr);
-		keys[i].key.ipv4_5tuple.port_src = sport;
-		keys[i].key.ipv4_5tuple.port_dst = dport;
-		keys[i].key.ipv4_5tuple.proto = proto;
-
-		port_ids[i] = portid;
-		flow_ids[i] = flowid;
-
-		if (app_pipeline_fc_key_check(&keys[i]))
-			goto error2;
-
-		i++;
-	}
-
-	/* Close file */
-	*n_keys = i;
-	fclose(f);
-	return 0;
-
-error2:
-	*line = l;
-	fclose(f);
-	return -1;
-}
-
-int
-app_pipeline_fc_load_file_ipv6(char *filename,
-	struct pipeline_fc_key *keys,
-	uint32_t *port_ids,
-	uint32_t *flow_ids,
-	uint32_t *n_keys,
-	uint32_t *line)
-{
-	FILE *f = NULL;
-	char file_buf[1024];
-	uint32_t i, l;
-
-	/* Check input arguments */
-	if ((filename == NULL) ||
-		(keys == NULL) ||
-		(port_ids == NULL) ||
-		(flow_ids == NULL) ||
-		(n_keys == NULL) ||
-		(*n_keys == 0) ||
-		(line == NULL)) {
-		if (line)
-			*line = 0;
-		return -1;
-		}
-
-	/* Open input file */
-	f = fopen(filename, "r");
-	if (f == NULL) {
-		*line = 0;
-		return -1;
-	}
-
-	/* Read file */
-	for (i = 0, l = 1; i < *n_keys; l++) {
-		char *tokens[32];
-		uint32_t n_tokens = RTE_DIM(tokens);
-
-		struct in6_addr sipaddr, dipaddr;
-		uint16_t sport, dport;
-		uint8_t proto;
-		uint32_t portid, flowid;
-		int status;
-
-		if (fgets(file_buf, sizeof(file_buf), f) == NULL)
-			break;
-
-		status = parse_tokenize_string(file_buf, tokens, &n_tokens);
-		if (status)
-			goto error3;
-
-		if ((n_tokens == 0) || (tokens[0][0] == '#'))
-			continue;
-
-		if ((n_tokens != 10) ||
-			strcmp(tokens[0], "ipv6") ||
-			parse_ipv6_addr(tokens[1], &sipaddr) ||
-			parse_ipv6_addr(tokens[2], &dipaddr) ||
-			parser_read_uint16(&sport, tokens[3]) ||
-			parser_read_uint16(&dport, tokens[4]) ||
-			parser_read_uint8(&proto, tokens[5]) ||
-			strcmp(tokens[6], "port") ||
-			parser_read_uint32(&portid, tokens[7]) ||
-			strcmp(tokens[8], "id") ||
-			parser_read_uint32(&flowid, tokens[9]))
-			goto error3;
-
-		keys[i].type = FLOW_KEY_IPV6_5TUPLE;
-		memcpy(keys[i].key.ipv6_5tuple.ip_src,
-			sipaddr.s6_addr,
-			sizeof(sipaddr.s6_addr));
-		memcpy(keys[i].key.ipv6_5tuple.ip_dst,
-			dipaddr.s6_addr,
-			sizeof(dipaddr.s6_addr));
-		keys[i].key.ipv6_5tuple.port_src = sport;
-		keys[i].key.ipv6_5tuple.port_dst = dport;
-		keys[i].key.ipv6_5tuple.proto = proto;
-
-		port_ids[i] = portid;
-		flow_ids[i] = flowid;
-
-		if (app_pipeline_fc_key_check(&keys[i]))
-			goto error3;
-
-		i++;
-	}
-
-	/* Close file */
-	*n_keys = i;
-	fclose(f);
-	return 0;
-
-error3:
-	*line = l;
-	fclose(f);
-	return -1;
-}
-
-
-
-int
-app_pipeline_fc_add(struct app_params *app,
-	uint32_t pipeline_id,
-	struct pipeline_fc_key *key,
-	uint32_t port_id,
-	uint32_t flow_id)
-{
-	struct app_pipeline_fc *p;
-	struct app_pipeline_fc_flow *flow;
-
-	struct pipeline_fc_add_msg_req *req;
-	struct pipeline_fc_add_msg_rsp *rsp;
-
-	uint32_t signature;
-	int new_flow;
-
-	/* Check input arguments */
-	if ((app == NULL) ||
-		(key == NULL))
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id, &pipeline_flow_classification);
-	if (p == NULL)
-		return -1;
-
-	if (port_id >= p->n_ports_out)
-		return -1;
-
-	if (app_pipeline_fc_key_check(key) != 0)
-		return -1;
-
-	/* Find existing flow or allocate new flow */
-	flow = app_pipeline_fc_flow_find(p, key);
-	new_flow = (flow == NULL);
-	if (flow == NULL) {
-		flow = rte_malloc(NULL, sizeof(*flow), RTE_CACHE_LINE_SIZE);
-
-		if (flow == NULL)
-			return -1;
-	}
-
-	/* Allocate and write request */
-	req = app_msg_alloc(app);
-	if (req == NULL)
-		return -1;
-
-	req->type = PIPELINE_MSG_REQ_CUSTOM;
-	req->subtype = PIPELINE_FC_MSG_REQ_FLOW_ADD;
-	app_pipeline_fc_key_convert(key, req->key, &signature);
-	req->port_id = port_id;
-	req->flow_id = flow_id;
-
-	/* Send request and wait for response */
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL) {
-		if (new_flow)
-			rte_free(flow);
-		return -1;
-	}
-
-	/* Read response and write flow */
-	if (rsp->status ||
-		(rsp->entry_ptr == NULL) ||
-		((new_flow == 0) && (rsp->key_found == 0)) ||
-		((new_flow == 1) && (rsp->key_found == 1))) {
-		app_msg_free(app, rsp);
-		if (new_flow)
-			rte_free(flow);
-		return -1;
-	}
-
-	memset(&flow->key, 0, sizeof(flow->key));
-	memcpy(&flow->key, key, sizeof(flow->key));
-	flow->port_id = port_id;
-	flow->flow_id = flow_id;
-	flow->signature = signature;
-	flow->entry_ptr = rsp->entry_ptr;
-
-	/* Commit rule */
-	if (new_flow) {
-		uint32_t bucket_id = signature & (N_BUCKETS - 1);
-
-		TAILQ_INSERT_TAIL(&p->flows[bucket_id], flow, node);
-		p->n_flows++;
-	}
-
-	/* Free response */
-	app_msg_free(app, rsp);
-
-	return 0;
-}
-
-int
-app_pipeline_fc_add_bulk(struct app_params *app,
-	uint32_t pipeline_id,
-	struct pipeline_fc_key *key,
-	uint32_t *port_id,
-	uint32_t *flow_id,
-	uint32_t n_keys)
-{
-	struct app_pipeline_fc *p;
-	struct pipeline_fc_add_bulk_msg_req *req;
-	struct pipeline_fc_add_bulk_msg_rsp *rsp;
-
-	struct app_pipeline_fc_flow **flow;
-	uint32_t *signature;
-	int *new_flow;
-	struct pipeline_fc_add_bulk_flow_req *flow_req;
-	struct pipeline_fc_add_bulk_flow_rsp *flow_rsp;
-
-	uint32_t i;
-	int status;
-
-	/* Check input arguments */
-	if ((app == NULL) ||
-		(key == NULL) ||
-		(port_id == NULL) ||
-		(flow_id == NULL) ||
-		(n_keys == 0))
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id, &pipeline_flow_classification);
-	if (p == NULL)
-		return -1;
-
-	for (i = 0; i < n_keys; i++)
-		if (port_id[i] >= p->n_ports_out)
-			return -1;
-
-	for (i = 0; i < n_keys; i++)
-		if (app_pipeline_fc_key_check(&key[i]) != 0)
-			return -1;
-
-	/* Memory allocation */
-	flow = rte_malloc(NULL,
-		n_keys * sizeof(struct app_pipeline_fc_flow *),
-		RTE_CACHE_LINE_SIZE);
-	if (flow == NULL)
-		return -1;
-
-	signature = rte_malloc(NULL,
-		n_keys * sizeof(uint32_t),
-		RTE_CACHE_LINE_SIZE);
-	if (signature == NULL) {
-		rte_free(flow);
-		return -1;
-	}
-
-	new_flow = rte_malloc(
-		NULL,
-		n_keys * sizeof(int),
-		RTE_CACHE_LINE_SIZE);
-	if (new_flow == NULL) {
-		rte_free(signature);
-		rte_free(flow);
-		return -1;
-	}
-
-	flow_req = rte_malloc(NULL,
-		n_keys * sizeof(struct pipeline_fc_add_bulk_flow_req),
-		RTE_CACHE_LINE_SIZE);
-	if (flow_req == NULL) {
-		rte_free(new_flow);
-		rte_free(signature);
-		rte_free(flow);
-		return -1;
-	}
-
-	flow_rsp = rte_malloc(NULL,
-		n_keys * sizeof(struct pipeline_fc_add_bulk_flow_rsp),
-		RTE_CACHE_LINE_SIZE);
-	if (flow_rsp == NULL) {
-		rte_free(flow_req);
-		rte_free(new_flow);
-		rte_free(signature);
-		rte_free(flow);
-		return -1;
-	}
-
-	/* Find existing flow or allocate new flow */
-	for (i = 0; i < n_keys; i++) {
-		flow[i] = app_pipeline_fc_flow_find(p, &key[i]);
-		new_flow[i] = (flow[i] == NULL);
-		if (flow[i] == NULL) {
-			flow[i] = rte_zmalloc(NULL,
-				sizeof(struct app_pipeline_fc_flow),
-				RTE_CACHE_LINE_SIZE);
-
-			if (flow[i] == NULL) {
-				uint32_t j;
-
-				for (j = 0; j < i; j++)
-					if (new_flow[j])
-						rte_free(flow[j]);
-
-				rte_free(flow_rsp);
-				rte_free(flow_req);
-				rte_free(new_flow);
-				rte_free(signature);
-				rte_free(flow);
-				return -1;
-			}
-		}
-	}
-
-	/* Allocate and write request */
-	req = app_msg_alloc(app);
-	if (req == NULL) {
-		for (i = 0; i < n_keys; i++)
-			if (new_flow[i])
-				rte_free(flow[i]);
-
-		rte_free(flow_rsp);
-		rte_free(flow_req);
-		rte_free(new_flow);
-		rte_free(signature);
-		rte_free(flow);
-		return -1;
-	}
-
-	for (i = 0; i < n_keys; i++) {
-		app_pipeline_fc_key_convert(&key[i],
-			flow_req[i].key,
-			&signature[i]);
-		flow_req[i].port_id = port_id[i];
-		flow_req[i].flow_id = flow_id[i];
-	}
-
-	req->type = PIPELINE_MSG_REQ_CUSTOM;
-	req->subtype = PIPELINE_FC_MSG_REQ_FLOW_ADD_BULK;
-	req->req = flow_req;
-	req->rsp = flow_rsp;
-	req->n_keys = n_keys;
-
-	/* Send request and wait for response */
-	rsp = app_msg_send_recv(app, pipeline_id, req, 10000);
-	if (rsp == NULL) {
-		for (i = 0; i < n_keys; i++)
-			if (new_flow[i])
-				rte_free(flow[i]);
-
-		rte_free(flow_rsp);
-		rte_free(flow_req);
-		rte_free(new_flow);
-		rte_free(signature);
-		rte_free(flow);
-		return -1;
-	}
-
-	/* Read response */
-	status = 0;
-
-	for (i = 0; i < rsp->n_keys; i++)
-		if ((flow_rsp[i].entry_ptr == NULL) ||
-			((new_flow[i] == 0) && (flow_rsp[i].key_found == 0)) ||
-			((new_flow[i] == 1) && (flow_rsp[i].key_found == 1)))
-			status = -1;
-
-	if (rsp->n_keys < n_keys)
-		status = -1;
-
-	/* Commit flows */
-	for (i = 0; i < rsp->n_keys; i++) {
-		memcpy(&flow[i]->key, &key[i], sizeof(flow[i]->key));
-		flow[i]->port_id = port_id[i];
-		flow[i]->flow_id = flow_id[i];
-		flow[i]->signature = signature[i];
-		flow[i]->entry_ptr = flow_rsp[i].entry_ptr;
-
-		if (new_flow[i]) {
-			uint32_t bucket_id = signature[i] & (N_BUCKETS - 1);
-
-			TAILQ_INSERT_TAIL(&p->flows[bucket_id], flow[i], node);
-			p->n_flows++;
-		}
-	}
-
-	/* Free resources */
-
-	for (i = rsp->n_keys; i < n_keys; i++)
-		if (new_flow[i])
-			rte_free(flow[i]);
-
-	app_msg_free(app, rsp);
-	rte_free(flow_rsp);
-	rte_free(flow_req);
-	rte_free(new_flow);
-	rte_free(signature);
-	rte_free(flow);
-
-	return status;
-}
-
-int
-app_pipeline_fc_del(struct app_params *app,
-	uint32_t pipeline_id,
-	struct pipeline_fc_key *key)
-{
-	struct app_pipeline_fc *p;
-	struct app_pipeline_fc_flow *flow;
-
-	struct pipeline_fc_del_msg_req *req;
-	struct pipeline_fc_del_msg_rsp *rsp;
-
-	uint32_t signature, bucket_id;
-
-	/* Check input arguments */
-	if ((app == NULL) ||
-		(key == NULL))
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id, &pipeline_flow_classification);
-	if (p == NULL)
-		return -1;
-
-	if (app_pipeline_fc_key_check(key) != 0)
-		return -1;
-
-	/* Find rule */
-	flow = app_pipeline_fc_flow_find(p, key);
-	if (flow == NULL)
-		return 0;
-
-	/* Allocate and write request */
-	req = app_msg_alloc(app);
-	if (req == NULL)
-		return -1;
-
-	req->type = PIPELINE_MSG_REQ_CUSTOM;
-	req->subtype = PIPELINE_FC_MSG_REQ_FLOW_DEL;
-	app_pipeline_fc_key_convert(key, req->key, &signature);
-
-	/* Send request and wait for response */
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL)
-		return -1;
-
-	/* Read response */
-	if (rsp->status || !rsp->key_found) {
-		app_msg_free(app, rsp);
-		return -1;
-	}
-
-	/* Remove rule */
-	bucket_id = signature & (N_BUCKETS - 1);
-	TAILQ_REMOVE(&p->flows[bucket_id], flow, node);
-	p->n_flows--;
-	rte_free(flow);
-
-	/* Free response */
-	app_msg_free(app, rsp);
-
-	return 0;
-}
-
-int
-app_pipeline_fc_add_default(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t port_id)
-{
-	struct app_pipeline_fc *p;
-
-	struct pipeline_fc_add_default_msg_req *req;
-	struct pipeline_fc_add_default_msg_rsp *rsp;
-
-	/* Check input arguments */
-	if (app == NULL)
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id, &pipeline_flow_classification);
-	if (p == NULL)
-		return -1;
-
-	if (port_id >= p->n_ports_out)
-		return -1;
-
-	/* Allocate and write request */
-	req = app_msg_alloc(app);
-	if (req == NULL)
-		return -1;
-
-	req->type = PIPELINE_MSG_REQ_CUSTOM;
-	req->subtype = PIPELINE_FC_MSG_REQ_FLOW_ADD_DEFAULT;
-	req->port_id = port_id;
-
-	/* Send request and wait for response */
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL)
-		return -1;
-
-	/* Read response and write flow */
-	if (rsp->status || (rsp->entry_ptr == NULL)) {
-		app_msg_free(app, rsp);
-		return -1;
-	}
-
-	p->default_flow_port_id = port_id;
-	p->default_flow_entry_ptr = rsp->entry_ptr;
-
-	/* Commit route */
-	p->default_flow_present = 1;
-
-	/* Free response */
-	app_msg_free(app, rsp);
-
-	return 0;
-}
-
-int
-app_pipeline_fc_del_default(struct app_params *app,
-	uint32_t pipeline_id)
-{
-	struct app_pipeline_fc *p;
-
-	struct pipeline_fc_del_default_msg_req *req;
-	struct pipeline_fc_del_default_msg_rsp *rsp;
-
-	/* Check input arguments */
-	if (app == NULL)
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id, &pipeline_flow_classification);
-	if (p == NULL)
-		return -EINVAL;
-
-	/* Allocate and write request */
-	req = app_msg_alloc(app);
-	if (req == NULL)
-		return -1;
-
-	req->type = PIPELINE_MSG_REQ_CUSTOM;
-	req->subtype = PIPELINE_FC_MSG_REQ_FLOW_DEL_DEFAULT;
-
-	/* Send request and wait for response */
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL)
-		return -1;
-
-	/* Read response */
-	if (rsp->status) {
-		app_msg_free(app, rsp);
-		return -1;
-	}
-
-	/* Commit route */
-	p->default_flow_present = 0;
-
-	/* Free response */
-	app_msg_free(app, rsp);
-
-	return 0;
-}
-
-/*
- * Flow ls
- */
-
-static void
-print_fc_qinq_flow(struct app_pipeline_fc_flow *flow)
-{
-	printf("(SVLAN = %" PRIu32 ", "
-		"CVLAN = %" PRIu32 ") => "
-		"Port = %" PRIu32 ", "
-		"Flow ID = %" PRIu32 ", "
-		"(signature = 0x%08" PRIx32 ", "
-		"entry_ptr = %p)\n",
-
-		flow->key.key.qinq.svlan,
-		flow->key.key.qinq.cvlan,
-		flow->port_id,
-		flow->flow_id,
-		flow->signature,
-		flow->entry_ptr);
-}
-
-static void
-print_fc_ipv4_5tuple_flow(struct app_pipeline_fc_flow *flow)
-{
-	printf("(SA = %" PRIu32 ".%" PRIu32 ".%" PRIu32 ".%" PRIu32 ", "
-		   "DA = %" PRIu32 ".%" PRIu32 ".%" PRIu32 ".%" PRIu32 ", "
-		   "SP = %" PRIu32 ", "
-		   "DP = %" PRIu32 ", "
-		   "Proto = %" PRIu32 ") => "
-		   "Port = %" PRIu32 ", "
-		   "Flow ID = %" PRIu32 " "
-		   "(signature = 0x%08" PRIx32 ", "
-		   "entry_ptr = %p)\n",
-
-		   (flow->key.key.ipv4_5tuple.ip_src >> 24) & 0xFF,
-		   (flow->key.key.ipv4_5tuple.ip_src >> 16) & 0xFF,
-		   (flow->key.key.ipv4_5tuple.ip_src >> 8) & 0xFF,
-		   flow->key.key.ipv4_5tuple.ip_src & 0xFF,
-
-		   (flow->key.key.ipv4_5tuple.ip_dst >> 24) & 0xFF,
-		   (flow->key.key.ipv4_5tuple.ip_dst >> 16) & 0xFF,
-		   (flow->key.key.ipv4_5tuple.ip_dst >> 8) & 0xFF,
-		   flow->key.key.ipv4_5tuple.ip_dst & 0xFF,
-
-		   flow->key.key.ipv4_5tuple.port_src,
-		   flow->key.key.ipv4_5tuple.port_dst,
-
-		   flow->key.key.ipv4_5tuple.proto,
-
-		   flow->port_id,
-		   flow->flow_id,
-		   flow->signature,
-		   flow->entry_ptr);
-}
-
-static void
-print_fc_ipv6_5tuple_flow(struct app_pipeline_fc_flow *flow) {
-	printf("(SA = %02" PRIx32 "%02" PRIx32 ":%02" PRIx32 "%02" PRIx32
-		":%02" PRIx32 "%02" PRIx32 ":%02" PRIx32 "%02" PRIx32
-		":%02" PRIx32 "%02" PRIx32 ":%02" PRIx32 "%02" PRIx32
-		":%02" PRIx32 "%02" PRIx32 ":%02" PRIx32 "%02" PRIx32 ", "
-		"DA = %02" PRIx32 "%02" PRIx32 ":%02" PRIx32 "%02" PRIx32
-		":%02" PRIx32 "%02" PRIx32 ":%02" PRIx32 "%02" PRIx32
-		":%02" PRIx32 "%02" PRIx32 ":%02" PRIx32 "%02" PRIx32
-		":%02" PRIx32 "%02" PRIx32 ":%02" PRIx32 "%02" PRIx32 ", "
-		"SP = %" PRIu32 ", "
-		"DP = %" PRIu32 " "
-		"Proto = %" PRIu32 " "
-		"=> Port = %" PRIu32 ", "
-		"Flow ID = %" PRIu32 " "
-		"(signature = 0x%08" PRIx32 ", "
-		"entry_ptr = %p)\n",
-
-		flow->key.key.ipv6_5tuple.ip_src[0],
-		flow->key.key.ipv6_5tuple.ip_src[1],
-		flow->key.key.ipv6_5tuple.ip_src[2],
-		flow->key.key.ipv6_5tuple.ip_src[3],
-		flow->key.key.ipv6_5tuple.ip_src[4],
-		flow->key.key.ipv6_5tuple.ip_src[5],
-		flow->key.key.ipv6_5tuple.ip_src[6],
-		flow->key.key.ipv6_5tuple.ip_src[7],
-		flow->key.key.ipv6_5tuple.ip_src[8],
-		flow->key.key.ipv6_5tuple.ip_src[9],
-		flow->key.key.ipv6_5tuple.ip_src[10],
-		flow->key.key.ipv6_5tuple.ip_src[11],
-		flow->key.key.ipv6_5tuple.ip_src[12],
-		flow->key.key.ipv6_5tuple.ip_src[13],
-		flow->key.key.ipv6_5tuple.ip_src[14],
-		flow->key.key.ipv6_5tuple.ip_src[15],
-
-		flow->key.key.ipv6_5tuple.ip_dst[0],
-		flow->key.key.ipv6_5tuple.ip_dst[1],
-		flow->key.key.ipv6_5tuple.ip_dst[2],
-		flow->key.key.ipv6_5tuple.ip_dst[3],
-		flow->key.key.ipv6_5tuple.ip_dst[4],
-		flow->key.key.ipv6_5tuple.ip_dst[5],
-		flow->key.key.ipv6_5tuple.ip_dst[6],
-		flow->key.key.ipv6_5tuple.ip_dst[7],
-		flow->key.key.ipv6_5tuple.ip_dst[8],
-		flow->key.key.ipv6_5tuple.ip_dst[9],
-		flow->key.key.ipv6_5tuple.ip_dst[10],
-		flow->key.key.ipv6_5tuple.ip_dst[11],
-		flow->key.key.ipv6_5tuple.ip_dst[12],
-		flow->key.key.ipv6_5tuple.ip_dst[13],
-		flow->key.key.ipv6_5tuple.ip_dst[14],
-		flow->key.key.ipv6_5tuple.ip_dst[15],
-
-		flow->key.key.ipv6_5tuple.port_src,
-		flow->key.key.ipv6_5tuple.port_dst,
-
-		flow->key.key.ipv6_5tuple.proto,
-
-		flow->port_id,
-		flow->flow_id,
-		flow->signature,
-		flow->entry_ptr);
-}
-
-static void
-print_fc_flow(struct app_pipeline_fc_flow *flow)
-{
-	switch (flow->key.type) {
-	case FLOW_KEY_QINQ:
-		print_fc_qinq_flow(flow);
-		break;
-
-	case FLOW_KEY_IPV4_5TUPLE:
-		print_fc_ipv4_5tuple_flow(flow);
-		break;
-
-	case FLOW_KEY_IPV6_5TUPLE:
-		print_fc_ipv6_5tuple_flow(flow);
-		break;
-	}
-}
-
-static int
-app_pipeline_fc_ls(struct app_params *app,
-		uint32_t pipeline_id)
-{
-	struct app_pipeline_fc *p;
-	struct app_pipeline_fc_flow *flow;
-	uint32_t i;
-
-	/* Check input arguments */
-	if (app == NULL)
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id, &pipeline_flow_classification);
-	if (p == NULL)
-		return -1;
-
-	for (i = 0; i < N_BUCKETS; i++)
-		TAILQ_FOREACH(flow, &p->flows[i], node)
-			print_fc_flow(flow);
-
-	if (p->default_flow_present)
-		printf("Default flow: port %" PRIu32 " (entry ptr = %p)\n",
-			p->default_flow_port_id,
-			p->default_flow_entry_ptr);
-	else
-		printf("Default: DROP\n");
-
-	return 0;
-}
-/*
- * flow
- *
- * flow add:
- *    p <pipelineid> flow add qinq <svlan> <cvlan> port <portid> id <flowid>
- *    p <pipelineid> flow add qinq bulk <file>
- *    p <pipelineid> flow add ipv4 <sipaddr> <dipaddr> <sport> <dport> <proto> port <port ID> id <flowid>
- *    p <pipelineid> flow add ipv4 bulk <file>
- *    p <pipelineid> flow add ipv6 <sipaddr> <dipaddr> <sport> <dport> <proto> port <port ID> id <flowid>
- *    p <pipelineid> flow add ipv6 bulk <file>
- *
- * flow add default:
- *    p <pipelineid> flow add default <portid>
- *
- * flow del:
- *    p <pipelineid> flow del qinq <svlan> <cvlan>
- *    p <pipelineid> flow del ipv4 <sipaddr> <dipaddr> <sport> <dport> <proto>
- *    p <pipelineid> flow del ipv6 <sipaddr> <dipaddr> <sport> <dport> <proto>
- *
- * flow del default:
- *    p <pipelineid> flow del default
- *
- * flow ls:
- *    p <pipelineid> flow ls
- */
-
-struct cmd_flow_result {
-	cmdline_fixed_string_t p_string;
-	uint32_t pipeline_id;
-	cmdline_fixed_string_t flow_string;
-	cmdline_multi_string_t multi_string;
-};
-
-static void
-cmd_flow_parsed(void *parsed_result,
-	__attribute__((unused)) struct cmdline *cl,
-	void *data)
-{
-	struct cmd_flow_result *results = parsed_result;
-	struct app_params *app = data;
-
-	char *tokens[16];
-	uint32_t n_tokens = RTE_DIM(tokens);
-	int status;
-
-	status = parse_tokenize_string(results->multi_string, tokens, &n_tokens);
-	if (status) {
-		printf(CMD_MSG_TOO_MANY_ARGS, "flow");
-		return;
-	}
-
-	/* flow add qinq */
-	if ((n_tokens >= 3) &&
-		(strcmp(tokens[0], "add") == 0) &&
-		(strcmp(tokens[1], "qinq") == 0) &&
-		strcmp(tokens[2], "bulk")) {
-		struct pipeline_fc_key key;
-		uint32_t svlan;
-		uint32_t cvlan;
-		uint32_t port_id;
-		uint32_t flow_id;
-
-		memset(&key, 0, sizeof(key));
-
-		if (n_tokens != 8) {
-			printf(CMD_MSG_MISMATCH_ARGS, "flow add qinq");
-			return;
-		}
-
-		if (parser_read_uint32(&svlan, tokens[2]) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "svlan");
-			return;
-		}
-
-		if (parser_read_uint32(&cvlan, tokens[3]) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "cvlan");
-			return;
-		}
-
-		if (strcmp(tokens[4], "port") != 0) {
-			printf(CMD_MSG_ARG_NOT_FOUND, "port");
-			return;
-		}
-
-		if (parser_read_uint32(&port_id, tokens[5]) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "portid");
-			return;
-		}
-
-		if (strcmp(tokens[6], "id") != 0) {
-			printf(CMD_MSG_ARG_NOT_FOUND, "id");
-			return;
-		}
-
-		if (parser_read_uint32(&flow_id, tokens[7]) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "flowid");
-			return;
-		}
-
-		key.type = FLOW_KEY_QINQ;
-		key.key.qinq.svlan = svlan;
-		key.key.qinq.cvlan = cvlan;
-
-		status = app_pipeline_fc_add(app,
-			results->pipeline_id,
-			&key,
-			port_id,
-			flow_id);
-		if (status)
-			printf(CMD_MSG_FAIL, "flow add qinq");
-
-		return;
-	} /* flow add qinq */
-
-	/* flow add ipv4 */
-	if ((n_tokens >= 3) &&
-		(strcmp(tokens[0], "add") == 0) &&
-		(strcmp(tokens[1], "ipv4") == 0) &&
-		strcmp(tokens[2], "bulk")) {
-		struct pipeline_fc_key key;
-		struct in_addr sipaddr;
-		struct in_addr dipaddr;
-		uint32_t sport;
-		uint32_t dport;
-		uint32_t proto;
-		uint32_t port_id;
-		uint32_t flow_id;
-
-		memset(&key, 0, sizeof(key));
-
-		if (n_tokens != 11) {
-			printf(CMD_MSG_MISMATCH_ARGS, "flow add ipv4");
-			return;
-		}
-
-		if (parse_ipv4_addr(tokens[2], &sipaddr) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "sipv4addr");
-			return;
-		}
-		if (parse_ipv4_addr(tokens[3], &dipaddr) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "dipv4addr");
-			return;
-		}
-
-		if (parser_read_uint32(&sport, tokens[4]) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "sport");
-			return;
-		}
-
-		if (parser_read_uint32(&dport, tokens[5]) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "dport");
-			return;
-		}
-
-		if (parser_read_uint32(&proto, tokens[6]) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "proto");
-			return;
-		}
-
-		if (strcmp(tokens[7], "port") != 0) {
-			printf(CMD_MSG_ARG_NOT_FOUND, "port");
-			return;
-		}
-
-		if (parser_read_uint32(&port_id, tokens[8]) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "portid");
-			return;
-		}
-
-		if (strcmp(tokens[9], "id") != 0) {
-			printf(CMD_MSG_ARG_NOT_FOUND, "id");
-			return;
-		}
-
-		if (parser_read_uint32(&flow_id, tokens[10]) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "flowid");
-			return;
-		}
-
-		key.type = FLOW_KEY_IPV4_5TUPLE;
-		key.key.ipv4_5tuple.ip_src = rte_be_to_cpu_32(sipaddr.s_addr);
-		key.key.ipv4_5tuple.ip_dst = rte_be_to_cpu_32(dipaddr.s_addr);
-		key.key.ipv4_5tuple.port_src = sport;
-		key.key.ipv4_5tuple.port_dst = dport;
-		key.key.ipv4_5tuple.proto = proto;
-
-		status = app_pipeline_fc_add(app,
-			results->pipeline_id,
-			&key,
-			port_id,
-			flow_id);
-		if (status)
-			printf(CMD_MSG_FAIL, "flow add ipv4");
-
-		return;
-	} /* flow add ipv4 */
-
-	/* flow add ipv6 */
-	if ((n_tokens >= 3) &&
-		(strcmp(tokens[0], "add") == 0) &&
-		(strcmp(tokens[1], "ipv6") == 0) &&
-		strcmp(tokens[2], "bulk")) {
-		struct pipeline_fc_key key;
-		struct in6_addr sipaddr;
-		struct in6_addr dipaddr;
-		uint32_t sport;
-		uint32_t dport;
-		uint32_t proto;
-		uint32_t port_id;
-		uint32_t flow_id;
-
-		memset(&key, 0, sizeof(key));
-
-		if (n_tokens != 11) {
-			printf(CMD_MSG_MISMATCH_ARGS, "flow add ipv6");
-			return;
-		}
-
-		if (parse_ipv6_addr(tokens[2], &sipaddr) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "sipv6addr");
-			return;
-		}
-		if (parse_ipv6_addr(tokens[3], &dipaddr) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "dipv6addr");
-			return;
-		}
-
-		if (parser_read_uint32(&sport, tokens[4]) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "sport");
-			return;
-		}
-
-		if (parser_read_uint32(&dport, tokens[5]) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "dport");
-			return;
-		}
-
-		if (parser_read_uint32(&proto, tokens[6]) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "proto");
-			return;
-		}
-
-		if (strcmp(tokens[7], "port") != 0) {
-			printf(CMD_MSG_ARG_NOT_FOUND, "port");
-			return;
-		}
-
-		if (parser_read_uint32(&port_id, tokens[8]) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "portid");
-			return;
-		}
-
-		if (strcmp(tokens[9], "id") != 0) {
-			printf(CMD_MSG_ARG_NOT_FOUND, "id");
-			return;
-		}
-
-		if (parser_read_uint32(&flow_id, tokens[10]) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "flowid");
-			return;
-		}
-
-		key.type = FLOW_KEY_IPV6_5TUPLE;
-		memcpy(key.key.ipv6_5tuple.ip_src, (void *)&sipaddr, 16);
-		memcpy(key.key.ipv6_5tuple.ip_dst, (void *)&dipaddr, 16);
-		key.key.ipv6_5tuple.port_src = sport;
-		key.key.ipv6_5tuple.port_dst = dport;
-		key.key.ipv6_5tuple.proto = proto;
-
-		status = app_pipeline_fc_add(app,
-			results->pipeline_id,
-			&key,
-			port_id,
-			flow_id);
-		if (status)
-			printf(CMD_MSG_FAIL, "flow add ipv6");
-
-		return;
-	} /* flow add ipv6 */
-
-	/* flow add qinq bulk */
-	if ((n_tokens >= 3) &&
-		(strcmp(tokens[0], "add") == 0) &&
-		(strcmp(tokens[1], "qinq") == 0) &&
-		(strcmp(tokens[2], "bulk") == 0)) {
-		struct pipeline_fc_key *keys;
-		uint32_t *port_ids, *flow_ids, n_keys, line;
-		char *filename;
-
-		if (n_tokens != 4) {
-			printf(CMD_MSG_MISMATCH_ARGS, "flow add qinq bulk");
-			return;
-		}
-
-		filename = tokens[3];
-
-		n_keys = APP_PIPELINE_FC_MAX_FLOWS_IN_FILE;
-		keys = malloc(n_keys * sizeof(struct pipeline_fc_key));
-		if (keys == NULL)
-			return;
-		memset(keys, 0, n_keys * sizeof(struct pipeline_fc_key));
-
-		port_ids = malloc(n_keys * sizeof(uint32_t));
-		if (port_ids == NULL) {
-			free(keys);
-			return;
-		}
-
-		flow_ids = malloc(n_keys * sizeof(uint32_t));
-		if (flow_ids == NULL) {
-			free(port_ids);
-			free(keys);
-			return;
-		}
-
-		status = app_pipeline_fc_load_file_qinq(filename,
-			keys,
-			port_ids,
-			flow_ids,
-			&n_keys,
-			&line);
-		if (status != 0) {
-			printf(CMD_MSG_FILE_ERR, filename, line);
-			free(flow_ids);
-			free(port_ids);
-			free(keys);
-			return;
-		}
-
-		status = app_pipeline_fc_add_bulk(app,
-			results->pipeline_id,
-			keys,
-			port_ids,
-			flow_ids,
-			n_keys);
-		if (status)
-			printf(CMD_MSG_FAIL, "flow add qinq bulk");
-
-		free(flow_ids);
-		free(port_ids);
-		free(keys);
-		return;
-	} /* flow add qinq bulk */
-
-	/* flow add ipv4 bulk */
-	if ((n_tokens >= 3) &&
-		(strcmp(tokens[0], "add") == 0) &&
-		(strcmp(tokens[1], "ipv4") == 0) &&
-		(strcmp(tokens[2], "bulk") == 0)) {
-		struct pipeline_fc_key *keys;
-		uint32_t *port_ids, *flow_ids, n_keys, line;
-		char *filename;
-
-		if (n_tokens != 4) {
-			printf(CMD_MSG_MISMATCH_ARGS, "flow add ipv4 bulk");
-			return;
-		}
-
-		filename = tokens[3];
-
-		n_keys = APP_PIPELINE_FC_MAX_FLOWS_IN_FILE;
-		keys = malloc(n_keys * sizeof(struct pipeline_fc_key));
-		if (keys == NULL)
-			return;
-		memset(keys, 0, n_keys * sizeof(struct pipeline_fc_key));
-
-		port_ids = malloc(n_keys * sizeof(uint32_t));
-		if (port_ids == NULL) {
-			free(keys);
-			return;
-		}
-
-		flow_ids = malloc(n_keys * sizeof(uint32_t));
-		if (flow_ids == NULL) {
-			free(port_ids);
-			free(keys);
-			return;
-		}
-
-		status = app_pipeline_fc_load_file_ipv4(filename,
-			keys,
-			port_ids,
-			flow_ids,
-			&n_keys,
-			&line);
-		if (status != 0) {
-			printf(CMD_MSG_FILE_ERR, filename, line);
-			free(flow_ids);
-			free(port_ids);
-			free(keys);
-			return;
-		}
-
-		status = app_pipeline_fc_add_bulk(app,
-			results->pipeline_id,
-			keys,
-			port_ids,
-			flow_ids,
-			n_keys);
-		if (status)
-			printf(CMD_MSG_FAIL, "flow add ipv4 bulk");
-
-		free(flow_ids);
-		free(port_ids);
-		free(keys);
-		return;
-	} /* flow add ipv4 bulk */
-
-	/* flow add ipv6 bulk */
-	if ((n_tokens >= 3) &&
-		(strcmp(tokens[0], "add") == 0) &&
-		(strcmp(tokens[1], "ipv6") == 0) &&
-		(strcmp(tokens[2], "bulk") == 0)) {
-		struct pipeline_fc_key *keys;
-		uint32_t *port_ids, *flow_ids, n_keys, line;
-		char *filename;
-
-		if (n_tokens != 4) {
-			printf(CMD_MSG_MISMATCH_ARGS, "flow add ipv6 bulk");
-			return;
-		}
-
-		filename = tokens[3];
-
-		n_keys = APP_PIPELINE_FC_MAX_FLOWS_IN_FILE;
-		keys = malloc(n_keys * sizeof(struct pipeline_fc_key));
-		if (keys == NULL)
-			return;
-		memset(keys, 0, n_keys * sizeof(struct pipeline_fc_key));
-
-		port_ids = malloc(n_keys * sizeof(uint32_t));
-		if (port_ids == NULL) {
-			free(keys);
-			return;
-		}
-
-		flow_ids = malloc(n_keys * sizeof(uint32_t));
-		if (flow_ids == NULL) {
-			free(port_ids);
-			free(keys);
-			return;
-		}
-
-		status = app_pipeline_fc_load_file_ipv6(filename,
-			keys,
-			port_ids,
-			flow_ids,
-			&n_keys,
-			&line);
-		if (status != 0) {
-			printf(CMD_MSG_FILE_ERR, filename, line);
-			free(flow_ids);
-			free(port_ids);
-			free(keys);
-			return;
-		}
-
-		status = app_pipeline_fc_add_bulk(app,
-			results->pipeline_id,
-			keys,
-			port_ids,
-			flow_ids,
-			n_keys);
-		if (status)
-			printf(CMD_MSG_FAIL, "flow add ipv6 bulk");
-
-		free(flow_ids);
-		free(port_ids);
-		free(keys);
-		return;
-	} /* flow add ipv6 bulk */
-
-	/* flow add default*/
-	if ((n_tokens >= 2) &&
-		(strcmp(tokens[0], "add") == 0) &&
-		(strcmp(tokens[1], "default") == 0)) {
-		uint32_t port_id;
-
-		if (n_tokens != 3) {
-			printf(CMD_MSG_MISMATCH_ARGS, "flow add default");
-			return;
-		}
-
-		if (parser_read_uint32(&port_id, tokens[2]) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "portid");
-			return;
-		}
-
-		status = app_pipeline_fc_add_default(app,
-			results->pipeline_id,
-			port_id);
-		if (status)
-			printf(CMD_MSG_FAIL, "flow add default");
-
-		return;
-	} /* flow add default */
-
-	/* flow del qinq */
-	if ((n_tokens >= 2) &&
-		(strcmp(tokens[0], "del") == 0) &&
-		(strcmp(tokens[1], "qinq") == 0)) {
-		struct pipeline_fc_key key;
-		uint32_t svlan;
-		uint32_t cvlan;
-
-		memset(&key, 0, sizeof(key));
-
-		if (n_tokens != 4) {
-			printf(CMD_MSG_MISMATCH_ARGS, "flow del qinq");
-			return;
-		}
-
-		if (parser_read_uint32(&svlan, tokens[2]) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "svlan");
-			return;
-		}
-
-		if (parser_read_uint32(&cvlan, tokens[3]) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "cvlan");
-			return;
-		}
-
-		key.type = FLOW_KEY_QINQ;
-		key.key.qinq.svlan = svlan;
-		key.key.qinq.cvlan = cvlan;
-
-		status = app_pipeline_fc_del(app,
-			results->pipeline_id,
-			&key);
-		if (status)
-			printf(CMD_MSG_FAIL, "flow del qinq");
-
-		return;
-	} /* flow del qinq */
-
-	/* flow del ipv4 */
-	if ((n_tokens >= 2) &&
-		(strcmp(tokens[0], "del") == 0) &&
-		(strcmp(tokens[1], "ipv4") == 0)) {
-		struct pipeline_fc_key key;
-		struct in_addr sipaddr;
-		struct in_addr dipaddr;
-		uint32_t sport;
-		uint32_t dport;
-		uint32_t proto;
-
-		memset(&key, 0, sizeof(key));
-
-		if (n_tokens != 7) {
-			printf(CMD_MSG_MISMATCH_ARGS, "flow del ipv4");
-			return;
-		}
-
-		if (parse_ipv4_addr(tokens[2], &sipaddr) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "sipv4addr");
-			return;
-		}
-		if (parse_ipv4_addr(tokens[3], &dipaddr) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "dipv4addr");
-			return;
-		}
-
-		if (parser_read_uint32(&sport, tokens[4]) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "sport");
-			return;
-		}
-
-		if (parser_read_uint32(&dport, tokens[5]) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "dport");
-			return;
-		}
-
-		if (parser_read_uint32(&proto, tokens[6]) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "proto");
-			return;
-		}
-
-		key.type = FLOW_KEY_IPV4_5TUPLE;
-		key.key.ipv4_5tuple.ip_src = rte_be_to_cpu_32(sipaddr.s_addr);
-		key.key.ipv4_5tuple.ip_dst = rte_be_to_cpu_32(dipaddr.s_addr);
-		key.key.ipv4_5tuple.port_src = sport;
-		key.key.ipv4_5tuple.port_dst = dport;
-		key.key.ipv4_5tuple.proto = proto;
-
-		status = app_pipeline_fc_del(app,
-			results->pipeline_id,
-			&key);
-		if (status)
-			printf(CMD_MSG_FAIL, "flow del ipv4");
-
-		return;
-	} /* flow del ipv4 */
-
-	/* flow del ipv6 */
-	if ((n_tokens >= 2) &&
-		(strcmp(tokens[0], "del") == 0) &&
-		(strcmp(tokens[1], "ipv6") == 0)) {
-		struct pipeline_fc_key key;
-		struct in6_addr sipaddr;
-		struct in6_addr dipaddr;
-		uint32_t sport;
-		uint32_t dport;
-		uint32_t proto;
-
-		memset(&key, 0, sizeof(key));
-
-		if (n_tokens != 7) {
-			printf(CMD_MSG_MISMATCH_ARGS, "flow del ipv6");
-			return;
-		}
-
-		if (parse_ipv6_addr(tokens[2], &sipaddr) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "sipv6addr");
-			return;
-		}
-
-		if (parse_ipv6_addr(tokens[3], &dipaddr) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "dipv6addr");
-			return;
-		}
-
-		if (parser_read_uint32(&sport, tokens[4]) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "sport");
-			return;
-		}
-
-		if (parser_read_uint32(&dport, tokens[5]) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "dport");
-			return;
-		}
-
-		if (parser_read_uint32(&proto, tokens[6]) != 0) {
-			printf(CMD_MSG_INVALID_ARG, "proto");
-			return;
-		}
-
-		key.type = FLOW_KEY_IPV6_5TUPLE;
-		memcpy(key.key.ipv6_5tuple.ip_src, &sipaddr, 16);
-		memcpy(key.key.ipv6_5tuple.ip_dst, &dipaddr, 16);
-		key.key.ipv6_5tuple.port_src = sport;
-		key.key.ipv6_5tuple.port_dst = dport;
-		key.key.ipv6_5tuple.proto = proto;
-
-		status = app_pipeline_fc_del(app,
-			results->pipeline_id,
-			&key);
-		if (status)
-			printf(CMD_MSG_FAIL, "flow del ipv6");
-
-		return;
-	} /* flow del ipv6 */
-
-	/* flow del default*/
-	if ((n_tokens >= 2) &&
-		(strcmp(tokens[0], "del") == 0) &&
-		(strcmp(tokens[1], "default") == 0)) {
-		if (n_tokens != 2) {
-			printf(CMD_MSG_MISMATCH_ARGS, "flow del default");
-			return;
-		}
-
-		status = app_pipeline_fc_del_default(app,
-			results->pipeline_id);
-		if (status)
-			printf(CMD_MSG_FAIL, "flow del default");
-
-		return;
-	} /* flow del default */
-
-	/* flow ls */
-	if ((n_tokens >= 1) && (strcmp(tokens[0], "ls") == 0)) {
-		if (n_tokens != 1) {
-			printf(CMD_MSG_MISMATCH_ARGS, "flow ls");
-			return;
-		}
-
-		status = app_pipeline_fc_ls(app, results->pipeline_id);
-		if (status)
-			printf(CMD_MSG_FAIL, "flow ls");
-
-		return;
-	} /* flow ls */
-
-	printf(CMD_MSG_MISMATCH_ARGS, "flow");
-}
-
-static cmdline_parse_token_string_t cmd_flow_p_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_flow_result, p_string, "p");
-
-static cmdline_parse_token_num_t cmd_flow_pipeline_id =
-	TOKEN_NUM_INITIALIZER(struct cmd_flow_result, pipeline_id, UINT32);
-
-static cmdline_parse_token_string_t cmd_flow_flow_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_flow_result, flow_string, "flow");
-
-static cmdline_parse_token_string_t cmd_flow_multi_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_flow_result, multi_string,
-		TOKEN_STRING_MULTI);
-
-static cmdline_parse_inst_t cmd_flow = {
-	.f = cmd_flow_parsed,
-	.data = NULL,
-	.help_str = "flow add / add bulk / add default / del / del default / ls",
-	.tokens = {
-		(void *) &cmd_flow_p_string,
-		(void *) &cmd_flow_pipeline_id,
-		(void *) &cmd_flow_flow_string,
-		(void *) &cmd_flow_multi_string,
-		NULL,
-	},
-};
-
-static cmdline_parse_ctx_t pipeline_cmds[] = {
-	(cmdline_parse_inst_t *) &cmd_flow,
-	NULL,
-};
-
-static struct pipeline_fe_ops pipeline_flow_classification_fe_ops = {
-	.f_init = app_pipeline_fc_init,
-	.f_post_init = NULL,
-	.f_free = app_pipeline_fc_free,
-	.f_track = app_pipeline_track_default,
-	.cmds = pipeline_cmds,
-};
-
-struct pipeline_type pipeline_flow_classification = {
-	.name = "FLOW_CLASSIFICATION",
-	.be_ops = &pipeline_flow_classification_be_ops,
-	.fe_ops = &pipeline_flow_classification_fe_ops,
-};
diff --git a/examples/ip_pipeline/pipeline/pipeline_flow_classification.h b/examples/ip_pipeline/pipeline/pipeline_flow_classification.h
deleted file mode 100644
index 8c35498..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_flow_classification.h
+++ /dev/null
@@ -1,106 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#ifndef __INCLUDE_PIPELINE_FLOW_CLASSIFICATION_H__
-#define __INCLUDE_PIPELINE_FLOW_CLASSIFICATION_H__
-
-#include "pipeline.h"
-#include "pipeline_flow_classification_be.h"
-
-enum flow_key_type {
-	FLOW_KEY_QINQ,
-	FLOW_KEY_IPV4_5TUPLE,
-	FLOW_KEY_IPV6_5TUPLE,
-};
-
-struct flow_key_qinq {
-	uint16_t svlan;
-	uint16_t cvlan;
-};
-
-struct flow_key_ipv4_5tuple {
-	uint32_t ip_src;
-	uint32_t ip_dst;
-	uint16_t port_src;
-	uint16_t port_dst;
-	uint32_t proto;
-};
-
-struct flow_key_ipv6_5tuple {
-	uint8_t ip_src[16];
-	uint8_t ip_dst[16];
-	uint16_t port_src;
-	uint16_t port_dst;
-	uint32_t proto;
-};
-
-struct pipeline_fc_key {
-	enum flow_key_type type;
-	union {
-		struct flow_key_qinq qinq;
-		struct flow_key_ipv4_5tuple ipv4_5tuple;
-		struct flow_key_ipv6_5tuple ipv6_5tuple;
-	} key;
-};
-
-int
-app_pipeline_fc_add(struct app_params *app,
-	uint32_t pipeline_id,
-	struct pipeline_fc_key *key,
-	uint32_t port_id,
-	uint32_t flow_id);
-
-int
-app_pipeline_fc_add_bulk(struct app_params *app,
-	uint32_t pipeline_id,
-	struct pipeline_fc_key *key,
-	uint32_t *port_id,
-	uint32_t *flow_id,
-	uint32_t n_keys);
-
-int
-app_pipeline_fc_del(struct app_params *app,
-	uint32_t pipeline_id,
-	struct pipeline_fc_key *key);
-
-int
-app_pipeline_fc_add_default(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t port_id);
-
-int
-app_pipeline_fc_del_default(struct app_params *app,
-	uint32_t pipeline_id);
-
-#ifndef APP_PIPELINE_FC_MAX_FLOWS_IN_FILE
-#define APP_PIPELINE_FC_MAX_FLOWS_IN_FILE	(16 * 1024 * 1024)
-#endif
-
-int
-app_pipeline_fc_load_file_qinq(char *filename,
-	struct pipeline_fc_key *keys,
-	uint32_t *port_ids,
-	uint32_t *flow_ids,
-	uint32_t *n_keys,
-	uint32_t *line);
-
-int
-app_pipeline_fc_load_file_ipv4(char *filename,
-	struct pipeline_fc_key *keys,
-	uint32_t *port_ids,
-	uint32_t *flow_ids,
-	uint32_t *n_keys,
-	uint32_t *line);
-
-int
-app_pipeline_fc_load_file_ipv6(char *filename,
-	struct pipeline_fc_key *keys,
-	uint32_t *port_ids,
-	uint32_t *flow_ids,
-	uint32_t *n_keys,
-	uint32_t *line);
-
-extern struct pipeline_type pipeline_flow_classification;
-
-#endif
diff --git a/examples/ip_pipeline/pipeline/pipeline_flow_classification_be.c b/examples/ip_pipeline/pipeline/pipeline_flow_classification_be.c
deleted file mode 100644
index 097ec34..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_flow_classification_be.c
+++ /dev/null
@@ -1,723 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#include <string.h>
-
-#include <rte_common.h>
-#include <rte_malloc.h>
-#include <rte_table_hash.h>
-#include <rte_byteorder.h>
-#include <pipeline.h>
-
-#include "pipeline_flow_classification_be.h"
-#include "pipeline_actions_common.h"
-#include "parser.h"
-#include "hash_func.h"
-
-struct pipeline_flow_classification {
-	struct pipeline p;
-	pipeline_msg_req_handler custom_handlers[PIPELINE_FC_MSG_REQS];
-
-	uint32_t n_flows;
-	uint32_t key_size;
-	uint32_t flow_id;
-
-	uint32_t key_offset;
-	uint32_t hash_offset;
-	uint8_t key_mask[PIPELINE_FC_FLOW_KEY_MAX_SIZE];
-	uint32_t key_mask_present;
-	uint32_t flow_id_offset;
-
-} __rte_cache_aligned;
-
-static void *
-pipeline_fc_msg_req_custom_handler(struct pipeline *p, void *msg);
-
-static pipeline_msg_req_handler handlers[] = {
-	[PIPELINE_MSG_REQ_PING] =
-		pipeline_msg_req_ping_handler,
-	[PIPELINE_MSG_REQ_STATS_PORT_IN] =
-		pipeline_msg_req_stats_port_in_handler,
-	[PIPELINE_MSG_REQ_STATS_PORT_OUT] =
-		pipeline_msg_req_stats_port_out_handler,
-	[PIPELINE_MSG_REQ_STATS_TABLE] =
-		pipeline_msg_req_stats_table_handler,
-	[PIPELINE_MSG_REQ_PORT_IN_ENABLE] =
-		pipeline_msg_req_port_in_enable_handler,
-	[PIPELINE_MSG_REQ_PORT_IN_DISABLE] =
-		pipeline_msg_req_port_in_disable_handler,
-	[PIPELINE_MSG_REQ_CUSTOM] =
-		pipeline_fc_msg_req_custom_handler,
-};
-
-static void *
-pipeline_fc_msg_req_add_handler(struct pipeline *p, void *msg);
-
-static void *
-pipeline_fc_msg_req_add_bulk_handler(struct pipeline *p, void *msg);
-
-static void *
-pipeline_fc_msg_req_del_handler(struct pipeline *p, void *msg);
-
-static void *
-pipeline_fc_msg_req_add_default_handler(struct pipeline *p, void *msg);
-
-static void *
-pipeline_fc_msg_req_del_default_handler(struct pipeline *p, void *msg);
-
-static pipeline_msg_req_handler custom_handlers[] = {
-	[PIPELINE_FC_MSG_REQ_FLOW_ADD] =
-		pipeline_fc_msg_req_add_handler,
-	[PIPELINE_FC_MSG_REQ_FLOW_ADD_BULK] =
-		pipeline_fc_msg_req_add_bulk_handler,
-	[PIPELINE_FC_MSG_REQ_FLOW_DEL] =
-		pipeline_fc_msg_req_del_handler,
-	[PIPELINE_FC_MSG_REQ_FLOW_ADD_DEFAULT] =
-		pipeline_fc_msg_req_add_default_handler,
-	[PIPELINE_FC_MSG_REQ_FLOW_DEL_DEFAULT] =
-		pipeline_fc_msg_req_del_default_handler,
-};
-
-/*
- * Flow table
- */
-struct flow_table_entry {
-	struct rte_pipeline_table_entry head;
-
-	uint32_t flow_id;
-	uint32_t pad;
-};
-
-rte_table_hash_op_hash hash_func[] = {
-	hash_default_key8,
-	hash_default_key16,
-	hash_default_key24,
-	hash_default_key32,
-	hash_default_key40,
-	hash_default_key48,
-	hash_default_key56,
-	hash_default_key64
-};
-
-/*
- * Flow table AH - Write flow_id to packet meta-data
- */
-static inline void
-pkt_work_flow_id(
-	struct rte_mbuf *pkt,
-	struct rte_pipeline_table_entry *table_entry,
-	void *arg)
-{
-	struct pipeline_flow_classification *p_fc = arg;
-	uint32_t *flow_id_ptr =
-		RTE_MBUF_METADATA_UINT32_PTR(pkt, p_fc->flow_id_offset);
-	struct flow_table_entry *entry =
-		(struct flow_table_entry *) table_entry;
-
-	/* Read */
-	uint32_t flow_id = entry->flow_id;
-
-	/* Compute */
-
-	/* Write */
-	*flow_id_ptr = flow_id;
-}
-
-static inline void
-pkt4_work_flow_id(
-	struct rte_mbuf **pkts,
-	struct rte_pipeline_table_entry **table_entries,
-	void *arg)
-{
-	struct pipeline_flow_classification *p_fc = arg;
-
-	uint32_t *flow_id_ptr0 =
-		RTE_MBUF_METADATA_UINT32_PTR(pkts[0], p_fc->flow_id_offset);
-	uint32_t *flow_id_ptr1 =
-		RTE_MBUF_METADATA_UINT32_PTR(pkts[1], p_fc->flow_id_offset);
-	uint32_t *flow_id_ptr2 =
-		RTE_MBUF_METADATA_UINT32_PTR(pkts[2], p_fc->flow_id_offset);
-	uint32_t *flow_id_ptr3 =
-		RTE_MBUF_METADATA_UINT32_PTR(pkts[3], p_fc->flow_id_offset);
-
-	struct flow_table_entry *entry0 =
-		(struct flow_table_entry *) table_entries[0];
-	struct flow_table_entry *entry1 =
-		(struct flow_table_entry *) table_entries[1];
-	struct flow_table_entry *entry2 =
-		(struct flow_table_entry *) table_entries[2];
-	struct flow_table_entry *entry3 =
-		(struct flow_table_entry *) table_entries[3];
-
-	/* Read */
-	uint32_t flow_id0 = entry0->flow_id;
-	uint32_t flow_id1 = entry1->flow_id;
-	uint32_t flow_id2 = entry2->flow_id;
-	uint32_t flow_id3 = entry3->flow_id;
-
-	/* Compute */
-
-	/* Write */
-	*flow_id_ptr0 = flow_id0;
-	*flow_id_ptr1 = flow_id1;
-	*flow_id_ptr2 = flow_id2;
-	*flow_id_ptr3 = flow_id3;
-}
-
-PIPELINE_TABLE_AH_HIT(fc_table_ah_hit,
-		pkt_work_flow_id, pkt4_work_flow_id);
-
-static rte_pipeline_table_action_handler_hit
-get_fc_table_ah_hit(struct pipeline_flow_classification *p)
-{
-	if (p->flow_id)
-		return fc_table_ah_hit;
-
-	return NULL;
-}
-
-/*
- * Argument parsing
- */
-static int
-pipeline_fc_parse_args(struct pipeline_flow_classification *p,
-	struct pipeline_params *params)
-{
-	uint32_t n_flows_present = 0;
-	uint32_t key_offset_present = 0;
-	uint32_t key_size_present = 0;
-	uint32_t hash_offset_present = 0;
-	uint32_t key_mask_present = 0;
-	uint32_t flow_id_offset_present = 0;
-
-	uint32_t i;
-	char key_mask_str[PIPELINE_FC_FLOW_KEY_MAX_SIZE * 2 + 1];
-
-	p->hash_offset = 0;
-
-	/* default values */
-	p->flow_id = 0;
-
-	for (i = 0; i < params->n_args; i++) {
-		char *arg_name = params->args_name[i];
-		char *arg_value = params->args_value[i];
-
-		/* n_flows */
-		if (strcmp(arg_name, "n_flows") == 0) {
-			int status;
-
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				n_flows_present == 0, params->name,
-				arg_name);
-			n_flows_present = 1;
-
-			status = parser_read_uint32(&p->n_flows,
-				arg_value);
-			PIPELINE_PARSE_ERR_INV_VAL(((status != -EINVAL) &&
-				(p->n_flows != 0)), params->name,
-				arg_name, arg_value);
-			PIPELINE_PARSE_ERR_OUT_RNG((status != -ERANGE),
-				params->name, arg_name, arg_value);
-
-			continue;
-		}
-
-		/* key_offset */
-		if (strcmp(arg_name, "key_offset") == 0) {
-			int status;
-
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				key_offset_present == 0, params->name,
-				arg_name);
-			key_offset_present = 1;
-
-			status = parser_read_uint32(&p->key_offset,
-				arg_value);
-			PIPELINE_PARSE_ERR_INV_VAL((status != -EINVAL),
-				params->name, arg_name, arg_value);
-			PIPELINE_PARSE_ERR_OUT_RNG((status != -ERANGE),
-				params->name, arg_name, arg_value);
-
-			continue;
-		}
-
-		/* key_size */
-		if (strcmp(arg_name, "key_size") == 0) {
-			int status;
-
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				key_size_present == 0, params->name,
-				arg_name);
-			key_size_present = 1;
-
-			status = parser_read_uint32(&p->key_size,
-				arg_value);
-			PIPELINE_PARSE_ERR_INV_VAL(((status != -EINVAL) &&
-				(p->key_size != 0) &&
-				(p->key_size % 8 == 0)),
-				params->name, arg_name, arg_value);
-			PIPELINE_PARSE_ERR_OUT_RNG(((status != -ERANGE) &&
-				(p->key_size <=
-				PIPELINE_FC_FLOW_KEY_MAX_SIZE)),
-				params->name, arg_name, arg_value);
-
-			continue;
-		}
-
-		/* key_mask */
-		if (strcmp(arg_name, "key_mask") == 0) {
-			int mask_str_len = strlen(arg_value);
-
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				key_mask_present == 0,
-				params->name, arg_name);
-			key_mask_present = 1;
-
-			PIPELINE_ARG_CHECK((mask_str_len <=
-				(PIPELINE_FC_FLOW_KEY_MAX_SIZE * 2)),
-				"Parse error in section \"%s\": entry "
-				"\"%s\" is too long", params->name,
-				arg_name);
-
-			snprintf(key_mask_str, mask_str_len + 1, "%s",
-				arg_value);
-
-			continue;
-		}
-
-		/* hash_offset */
-		if (strcmp(arg_name, "hash_offset") == 0) {
-			int status;
-
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				hash_offset_present == 0, params->name,
-				arg_name);
-			hash_offset_present = 1;
-
-			status = parser_read_uint32(&p->hash_offset,
-				arg_value);
-			PIPELINE_PARSE_ERR_INV_VAL((status != -EINVAL),
-				params->name, arg_name, arg_value);
-			PIPELINE_PARSE_ERR_OUT_RNG((status != -ERANGE),
-				params->name, arg_name, arg_value);
-
-			continue;
-		}
-
-		/* flow_id_offset */
-		if (strcmp(arg_name, "flowid_offset") == 0) {
-			int status;
-
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				flow_id_offset_present == 0, params->name,
-				arg_name);
-			flow_id_offset_present = 1;
-
-			status = parser_read_uint32(&p->flow_id_offset,
-				arg_value);
-			PIPELINE_PARSE_ERR_INV_VAL((status != -EINVAL),
-				params->name, arg_name, arg_value);
-			PIPELINE_PARSE_ERR_OUT_RNG((status != -ERANGE),
-				params->name, arg_name, arg_value);
-
-			p->flow_id = 1;
-
-			continue;
-		}
-
-		/* Unknown argument */
-		PIPELINE_PARSE_ERR_INV_ENT(0, params->name, arg_name);
-	}
-
-	/* Check that mandatory arguments are present */
-	PIPELINE_PARSE_ERR_MANDATORY((n_flows_present), params->name,
-		"n_flows");
-	PIPELINE_PARSE_ERR_MANDATORY((key_offset_present), params->name,
-		"key_offset");
-	PIPELINE_PARSE_ERR_MANDATORY((key_size_present), params->name,
-		"key_size");
-
-	if (key_mask_present) {
-		uint32_t key_size = p->key_size;
-		int status;
-
-		PIPELINE_ARG_CHECK(((key_size == 8) || (key_size == 16)),
-			"Parse error in section \"%s\": entry key_mask "
-			"only allowed for key_size of 8 or 16 bytes",
-			params->name);
-
-		PIPELINE_ARG_CHECK((strlen(key_mask_str) ==
-			(key_size * 2)), "Parse error in section "
-			"\"%s\": key_mask should have exactly %u hex "
-			"digits", params->name, (key_size * 2));
-
-		PIPELINE_ARG_CHECK((hash_offset_present == 0), "Parse "
-			"error in section \"%s\": entry hash_offset only "
-			"allowed when key_mask is not present",
-			params->name);
-
-		status = parse_hex_string(key_mask_str, p->key_mask,
-			&p->key_size);
-
-		PIPELINE_PARSE_ERR_INV_VAL(((status == 0) &&
-			(key_size == p->key_size)), params->name,
-			"key_mask", key_mask_str);
-	}
-
-	p->key_mask_present = key_mask_present;
-
-	return 0;
-}
-
-static void *pipeline_fc_init(struct pipeline_params *params,
-	__rte_unused void *arg)
-{
-	struct pipeline *p;
-	struct pipeline_flow_classification *p_fc;
-	uint32_t size, i;
-
-	/* Check input arguments */
-	if (params == NULL)
-		return NULL;
-
-	/* Memory allocation */
-	size = RTE_CACHE_LINE_ROUNDUP(
-		sizeof(struct pipeline_flow_classification));
-	p = rte_zmalloc(NULL, size, RTE_CACHE_LINE_SIZE);
-	if (p == NULL)
-		return NULL;
-	p_fc = (struct pipeline_flow_classification *) p;
-
-	strcpy(p->name, params->name);
-	p->log_level = params->log_level;
-
-	PLOG(p, HIGH, "Flow classification");
-
-	/* Parse arguments */
-	if (pipeline_fc_parse_args(p_fc, params))
-		return NULL;
-
-	/* Pipeline */
-	{
-		struct rte_pipeline_params pipeline_params = {
-			.name = params->name,
-			.socket_id = params->socket_id,
-			.offset_port_id = 0,
-		};
-
-		p->p = rte_pipeline_create(&pipeline_params);
-		if (p->p == NULL) {
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Input ports */
-	p->n_ports_in = params->n_ports_in;
-	for (i = 0; i < p->n_ports_in; i++) {
-		struct rte_pipeline_port_in_params port_params = {
-			.ops = pipeline_port_in_params_get_ops(
-				&params->port_in[i]),
-			.arg_create = pipeline_port_in_params_convert(
-				&params->port_in[i]),
-			.f_action = NULL,
-			.arg_ah = NULL,
-			.burst_size = params->port_in[i].burst_size,
-		};
-
-		int status = rte_pipeline_port_in_create(p->p,
-			&port_params,
-			&p->port_in_id[i]);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Output ports */
-	p->n_ports_out = params->n_ports_out;
-	for (i = 0; i < p->n_ports_out; i++) {
-		struct rte_pipeline_port_out_params port_params = {
-			.ops = pipeline_port_out_params_get_ops(
-				&params->port_out[i]),
-			.arg_create = pipeline_port_out_params_convert(
-				&params->port_out[i]),
-			.f_action = NULL,
-			.arg_ah = NULL,
-		};
-
-		int status = rte_pipeline_port_out_create(p->p,
-			&port_params,
-			&p->port_out_id[i]);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Tables */
-	p->n_tables = 1;
-	{
-		struct rte_table_hash_params table_hash_params = {
-			.name = p->name,
-			.key_size = p_fc->key_size,
-			.key_offset = p_fc->key_offset,
-			.key_mask = (p_fc->key_mask_present) ?
-				p_fc->key_mask : NULL,
-			.n_keys = p_fc->n_flows,
-			.n_buckets = rte_align32pow2(p_fc->n_flows / 4),
-			.f_hash = hash_func[(p_fc->key_size / 8) - 1],
-			.seed = 0,
-		};
-
-		struct rte_pipeline_table_params table_params = {
-			.ops = NULL, /* set below */
-			.arg_create = NULL, /* set below */
-			.f_action_hit = get_fc_table_ah_hit(p_fc),
-			.f_action_miss = NULL,
-			.arg_ah = p_fc,
-			.action_data_size = sizeof(struct flow_table_entry) -
-				sizeof(struct rte_pipeline_table_entry),
-		};
-
-		int status;
-
-		switch (p_fc->key_size) {
-		case 8:
-			table_params.ops = &rte_table_hash_key8_ext_ops;
-			break;
-
-		case 16:
-			table_params.ops = &rte_table_hash_key16_ext_ops;
-			break;
-
-		default:
-			table_params.ops = &rte_table_hash_ext_ops;
-		}
-
-		table_params.arg_create = &table_hash_params;
-
-		status = rte_pipeline_table_create(p->p,
-			&table_params,
-			&p->table_id[0]);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Connecting input ports to tables */
-	for (i = 0; i < p->n_ports_in; i++) {
-		int status = rte_pipeline_port_in_connect_to_table(p->p,
-			p->port_in_id[i],
-			p->table_id[0]);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Enable input ports */
-	for (i = 0; i < p->n_ports_in; i++) {
-		int status = rte_pipeline_port_in_enable(p->p,
-			p->port_in_id[i]);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Check pipeline consistency */
-	if (rte_pipeline_check(p->p) < 0) {
-		rte_pipeline_free(p->p);
-		rte_free(p);
-		return NULL;
-	}
-
-	/* Message queues */
-	p->n_msgq = params->n_msgq;
-	for (i = 0; i < p->n_msgq; i++)
-		p->msgq_in[i] = params->msgq_in[i];
-	for (i = 0; i < p->n_msgq; i++)
-		p->msgq_out[i] = params->msgq_out[i];
-
-	/* Message handlers */
-	memcpy(p->handlers, handlers, sizeof(p->handlers));
-	memcpy(p_fc->custom_handlers,
-		custom_handlers,
-		sizeof(p_fc->custom_handlers));
-
-	return p;
-}
-
-static int
-pipeline_fc_free(void *pipeline)
-{
-	struct pipeline *p = (struct pipeline *) pipeline;
-
-	/* Check input arguments */
-	if (p == NULL)
-		return -1;
-
-	/* Free resources */
-	rte_pipeline_free(p->p);
-	rte_free(p);
-	return 0;
-}
-
-static int
-pipeline_fc_timer(void *pipeline)
-{
-	struct pipeline *p = (struct pipeline *) pipeline;
-
-	pipeline_msg_req_handle(p);
-	rte_pipeline_flush(p->p);
-
-	return 0;
-}
-
-static void *
-pipeline_fc_msg_req_custom_handler(struct pipeline *p, void *msg)
-{
-	struct pipeline_flow_classification *p_fc =
-			(struct pipeline_flow_classification *) p;
-	struct pipeline_custom_msg_req *req = msg;
-	pipeline_msg_req_handler f_handle;
-
-	f_handle = (req->subtype < PIPELINE_FC_MSG_REQS) ?
-		p_fc->custom_handlers[req->subtype] :
-		pipeline_msg_req_invalid_handler;
-
-	if (f_handle == NULL)
-		f_handle = pipeline_msg_req_invalid_handler;
-
-	return f_handle(p, req);
-}
-
-static void *
-pipeline_fc_msg_req_add_handler(struct pipeline *p, void *msg)
-{
-	struct pipeline_fc_add_msg_req *req = msg;
-	struct pipeline_fc_add_msg_rsp *rsp = msg;
-
-	struct flow_table_entry entry = {
-		.head = {
-			.action = RTE_PIPELINE_ACTION_PORT,
-			{.port_id = p->port_out_id[req->port_id]},
-		},
-		.flow_id = req->flow_id,
-	};
-
-	rsp->status = rte_pipeline_table_entry_add(p->p,
-		p->table_id[0],
-		&req->key,
-		(struct rte_pipeline_table_entry *) &entry,
-		&rsp->key_found,
-		(struct rte_pipeline_table_entry **) &rsp->entry_ptr);
-
-	return rsp;
-}
-
-static void *
-pipeline_fc_msg_req_add_bulk_handler(struct pipeline *p, void *msg)
-{
-	struct pipeline_fc_add_bulk_msg_req *req = msg;
-	struct pipeline_fc_add_bulk_msg_rsp *rsp = msg;
-	uint32_t i;
-
-	for (i = 0; i < req->n_keys; i++) {
-		struct pipeline_fc_add_bulk_flow_req *flow_req = &req->req[i];
-		struct pipeline_fc_add_bulk_flow_rsp *flow_rsp = &req->rsp[i];
-
-		struct flow_table_entry entry = {
-			.head = {
-				.action = RTE_PIPELINE_ACTION_PORT,
-				{.port_id = p->port_out_id[flow_req->port_id]},
-			},
-			.flow_id = flow_req->flow_id,
-		};
-
-		int status = rte_pipeline_table_entry_add(p->p,
-			p->table_id[0],
-			&flow_req->key,
-			(struct rte_pipeline_table_entry *) &entry,
-			&flow_rsp->key_found,
-			(struct rte_pipeline_table_entry **)
-				&flow_rsp->entry_ptr);
-
-		if (status)
-			break;
-	}
-
-	rsp->n_keys = i;
-
-	return rsp;
-}
-
-static void *
-pipeline_fc_msg_req_del_handler(struct pipeline *p, void *msg)
-{
-	struct pipeline_fc_del_msg_req *req = msg;
-	struct pipeline_fc_del_msg_rsp *rsp = msg;
-
-	rsp->status = rte_pipeline_table_entry_delete(p->p,
-		p->table_id[0],
-		&req->key,
-		&rsp->key_found,
-		NULL);
-
-	return rsp;
-}
-
-static void *
-pipeline_fc_msg_req_add_default_handler(struct pipeline *p, void *msg)
-{
-	struct pipeline_fc_add_default_msg_req *req = msg;
-	struct pipeline_fc_add_default_msg_rsp *rsp = msg;
-
-	struct flow_table_entry default_entry = {
-		.head = {
-			.action = RTE_PIPELINE_ACTION_PORT,
-			{.port_id = p->port_out_id[req->port_id]},
-		},
-
-		.flow_id = 0,
-	};
-
-	rsp->status = rte_pipeline_table_default_entry_add(p->p,
-		p->table_id[0],
-		(struct rte_pipeline_table_entry *) &default_entry,
-		(struct rte_pipeline_table_entry **) &rsp->entry_ptr);
-
-	return rsp;
-}
-
-static void *
-pipeline_fc_msg_req_del_default_handler(struct pipeline *p, void *msg)
-{
-	struct pipeline_fc_del_default_msg_rsp *rsp = msg;
-
-	rsp->status = rte_pipeline_table_default_entry_delete(p->p,
-		p->table_id[0],
-		NULL);
-
-	return rsp;
-}
-
-struct pipeline_be_ops pipeline_flow_classification_be_ops = {
-	.f_init = pipeline_fc_init,
-	.f_free = pipeline_fc_free,
-	.f_run = NULL,
-	.f_timer = pipeline_fc_timer,
-};
diff --git a/examples/ip_pipeline/pipeline/pipeline_flow_classification_be.h b/examples/ip_pipeline/pipeline/pipeline_flow_classification_be.h
deleted file mode 100644
index 18f5bb4..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_flow_classification_be.h
+++ /dev/null
@@ -1,113 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#ifndef __INCLUDE_PIPELINE_FLOW_CLASSIFICATION_BE_H__
-#define __INCLUDE_PIPELINE_FLOW_CLASSIFICATION_BE_H__
-
-#include "pipeline_common_be.h"
-
-enum pipeline_fc_msg_req_type {
-	PIPELINE_FC_MSG_REQ_FLOW_ADD = 0,
-	PIPELINE_FC_MSG_REQ_FLOW_ADD_BULK,
-	PIPELINE_FC_MSG_REQ_FLOW_DEL,
-	PIPELINE_FC_MSG_REQ_FLOW_ADD_DEFAULT,
-	PIPELINE_FC_MSG_REQ_FLOW_DEL_DEFAULT,
-	PIPELINE_FC_MSG_REQS,
-};
-
-#ifndef PIPELINE_FC_FLOW_KEY_MAX_SIZE
-#define PIPELINE_FC_FLOW_KEY_MAX_SIZE            64
-#endif
-
-/*
- * MSG ADD
- */
-struct pipeline_fc_add_msg_req {
-	enum pipeline_msg_req_type type;
-	enum pipeline_fc_msg_req_type subtype;
-
-	uint8_t key[PIPELINE_FC_FLOW_KEY_MAX_SIZE];
-
-	uint32_t port_id;
-	uint32_t flow_id;
-};
-
-struct pipeline_fc_add_msg_rsp {
-	int status;
-	int key_found;
-	void *entry_ptr;
-};
-
-/*
- * MSG ADD BULK
- */
-struct pipeline_fc_add_bulk_flow_req {
-	uint8_t key[PIPELINE_FC_FLOW_KEY_MAX_SIZE];
-	uint32_t port_id;
-	uint32_t flow_id;
-};
-
-struct pipeline_fc_add_bulk_flow_rsp {
-	int key_found;
-	void *entry_ptr;
-};
-
-struct pipeline_fc_add_bulk_msg_req {
-	enum pipeline_msg_req_type type;
-	enum pipeline_fc_msg_req_type subtype;
-
-	struct pipeline_fc_add_bulk_flow_req *req;
-	struct pipeline_fc_add_bulk_flow_rsp *rsp;
-	uint32_t n_keys;
-};
-
-struct pipeline_fc_add_bulk_msg_rsp {
-	uint32_t n_keys;
-};
-
-/*
- * MSG DEL
- */
-struct pipeline_fc_del_msg_req {
-	enum pipeline_msg_req_type type;
-	enum pipeline_fc_msg_req_type subtype;
-
-	uint8_t key[PIPELINE_FC_FLOW_KEY_MAX_SIZE];
-};
-
-struct pipeline_fc_del_msg_rsp {
-	int status;
-	int key_found;
-};
-
-/*
- * MSG ADD DEFAULT
- */
-struct pipeline_fc_add_default_msg_req {
-	enum pipeline_msg_req_type type;
-	enum pipeline_fc_msg_req_type subtype;
-
-	uint32_t port_id;
-};
-
-struct pipeline_fc_add_default_msg_rsp {
-	int status;
-	void *entry_ptr;
-};
-
-/*
- * MSG DEL DEFAULT
- */
-struct pipeline_fc_del_default_msg_req {
-	enum pipeline_msg_req_type type;
-	enum pipeline_fc_msg_req_type subtype;
-};
-
-struct pipeline_fc_del_default_msg_rsp {
-	int status;
-};
-
-extern struct pipeline_be_ops pipeline_flow_classification_be_ops;
-
-#endif
diff --git a/examples/ip_pipeline/pipeline/pipeline_master.c b/examples/ip_pipeline/pipeline/pipeline_master.c
deleted file mode 100644
index b0d730a..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_master.c
+++ /dev/null
@@ -1,20 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#include "pipeline_master.h"
-#include "pipeline_master_be.h"
-
-static struct pipeline_fe_ops pipeline_master_fe_ops = {
-	.f_init = NULL,
-	.f_post_init = NULL,
-	.f_free = NULL,
-	.f_track = NULL,
-	.cmds = NULL,
-};
-
-struct pipeline_type pipeline_master = {
-	.name = "MASTER",
-	.be_ops = &pipeline_master_be_ops,
-	.fe_ops = &pipeline_master_fe_ops,
-};
diff --git a/examples/ip_pipeline/pipeline/pipeline_master.h b/examples/ip_pipeline/pipeline/pipeline_master.h
deleted file mode 100644
index a5183e3..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_master.h
+++ /dev/null
@@ -1,12 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#ifndef __INCLUDE_PIPELINE_MASTER_H__
-#define __INCLUDE_PIPELINE_MASTER_H__
-
-#include "pipeline.h"
-
-extern struct pipeline_type pipeline_master;
-
-#endif
diff --git a/examples/ip_pipeline/pipeline/pipeline_master_be.c b/examples/ip_pipeline/pipeline/pipeline_master_be.c
deleted file mode 100644
index c72038e..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_master_be.c
+++ /dev/null
@@ -1,141 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#include <fcntl.h>
-#include <unistd.h>
-
-#include <rte_common.h>
-#include <rte_malloc.h>
-
-#include <cmdline_parse.h>
-#include <cmdline_parse_string.h>
-#include <cmdline_socket.h>
-#include <cmdline.h>
-
-#include "app.h"
-#include "pipeline_master_be.h"
-
-struct pipeline_master {
-	struct app_params *app;
-	struct cmdline *cl;
-	int post_init_done;
-	int script_file_done;
-} __rte_cache_aligned;
-
-static void*
-pipeline_init(__rte_unused struct pipeline_params *params, void *arg)
-{
-	struct app_params *app = (struct app_params *) arg;
-	struct pipeline_master *p;
-	uint32_t size;
-
-	/* Check input arguments */
-	if (app == NULL)
-		return NULL;
-
-	/* Memory allocation */
-	size = RTE_CACHE_LINE_ROUNDUP(sizeof(struct pipeline_master));
-	p = rte_zmalloc(NULL, size, RTE_CACHE_LINE_SIZE);
-	if (p == NULL)
-		return NULL;
-
-	/* Initialization */
-	p->app = app;
-
-	p->cl = cmdline_stdin_new(app->cmds, "pipeline> ");
-	if (p->cl == NULL) {
-		rte_free(p);
-		return NULL;
-	}
-
-	p->post_init_done = 0;
-	p->script_file_done = 0;
-	if (app->script_file == NULL)
-		p->script_file_done = 1;
-
-	return (void *) p;
-}
-
-static int
-pipeline_free(void *pipeline)
-{
-	struct pipeline_master *p = (struct pipeline_master *) pipeline;
-
-	if (p == NULL)
-		return -EINVAL;
-
-	cmdline_stdin_exit(p->cl);
-	rte_free(p);
-
-	return 0;
-}
-
-static int
-pipeline_run(void *pipeline)
-{
-	struct pipeline_master *p = (struct pipeline_master *) pipeline;
-	struct app_params *app = p->app;
-	int status;
-#ifdef RTE_LIBRTE_KNI
-	uint32_t i;
-#endif /* RTE_LIBRTE_KNI */
-
-	/* Application post-init phase */
-	if (p->post_init_done == 0) {
-		app_post_init(app);
-
-		p->post_init_done = 1;
-	}
-
-	/* Run startup script file */
-	if (p->script_file_done == 0) {
-		struct app_params *app = p->app;
-		int fd = open(app->script_file, O_RDONLY);
-
-		if (fd < 0)
-			printf("Cannot open CLI script file \"%s\"\n",
-				app->script_file);
-		else {
-			struct cmdline *file_cl;
-
-			printf("Running CLI script file \"%s\" ...\n",
-				app->script_file);
-			file_cl = cmdline_new(p->cl->ctx, "", fd, 1);
-			cmdline_interact(file_cl);
-			close(fd);
-		}
-
-		p->script_file_done = 1;
-	}
-
-	/* Command Line Interface (CLI) */
-	status = cmdline_poll(p->cl);
-	if (status < 0)
-		rte_panic("CLI poll error (%" PRId32 ")\n", status);
-	else if (status == RDLINE_EXITED) {
-		cmdline_stdin_exit(p->cl);
-		rte_exit(0, "Bye!\n");
-	}
-
-#ifdef RTE_LIBRTE_KNI
-	/* Handle KNI requests from Linux kernel */
-	for (i = 0; i < app->n_pktq_kni; i++)
-		rte_kni_handle_request(app->kni[i]);
-#endif /* RTE_LIBRTE_KNI */
-
-	return 0;
-}
-
-static int
-pipeline_timer(__rte_unused void *pipeline)
-{
-	return 0;
-}
-
-struct pipeline_be_ops pipeline_master_be_ops = {
-		.f_init = pipeline_init,
-		.f_free = pipeline_free,
-		.f_run = pipeline_run,
-		.f_timer = pipeline_timer,
-};
diff --git a/examples/ip_pipeline/pipeline/pipeline_master_be.h b/examples/ip_pipeline/pipeline/pipeline_master_be.h
deleted file mode 100644
index 847c564..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_master_be.h
+++ /dev/null
@@ -1,12 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#ifndef __INCLUDE_PIPELINE_MASTER_BE_H__
-#define __INCLUDE_PIPELINE_MASTER_BE_H__
-
-#include "pipeline_common_be.h"
-
-extern struct pipeline_be_ops pipeline_master_be_ops;
-
-#endif
diff --git a/examples/ip_pipeline/pipeline/pipeline_passthrough.c b/examples/ip_pipeline/pipeline/pipeline_passthrough.c
deleted file mode 100644
index 031f5f0..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_passthrough.c
+++ /dev/null
@@ -1,45 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#include "pipeline_passthrough.h"
-#include "pipeline_passthrough_be.h"
-
-static int
-app_pipeline_passthrough_track(struct pipeline_params *p,
-	uint32_t port_in,
-	uint32_t *port_out)
-{
-	struct pipeline_passthrough_params pp;
-	int status;
-
-	/* Check input arguments */
-	if ((p == NULL) ||
-		(port_in >= p->n_ports_in) ||
-		(port_out == NULL))
-		return -1;
-
-	status = pipeline_passthrough_parse_args(&pp, p);
-	if (status)
-		return -1;
-
-	if (pp.dma_hash_lb_enabled)
-		return -1;
-
-	*port_out = port_in / (p->n_ports_in / p->n_ports_out);
-	return 0;
-}
-
-static struct pipeline_fe_ops pipeline_passthrough_fe_ops = {
-	.f_init = NULL,
-	.f_post_init = NULL,
-	.f_free = NULL,
-	.f_track = app_pipeline_passthrough_track,
-	.cmds = NULL,
-};
-
-struct pipeline_type pipeline_passthrough = {
-	.name = "PASS-THROUGH",
-	.be_ops = &pipeline_passthrough_be_ops,
-	.fe_ops = &pipeline_passthrough_fe_ops,
-};
diff --git a/examples/ip_pipeline/pipeline/pipeline_passthrough.h b/examples/ip_pipeline/pipeline/pipeline_passthrough.h
deleted file mode 100644
index 7a7a2fc..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_passthrough.h
+++ /dev/null
@@ -1,12 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#ifndef __INCLUDE_PIPELINE_PASSTHROUGH_H__
-#define __INCLUDE_PIPELINE_PASSTHROUGH_H__
-
-#include "pipeline.h"
-
-extern struct pipeline_type pipeline_passthrough;
-
-#endif
diff --git a/examples/ip_pipeline/pipeline/pipeline_passthrough_be.c b/examples/ip_pipeline/pipeline/pipeline_passthrough_be.c
deleted file mode 100644
index b2bbaed..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_passthrough_be.c
+++ /dev/null
@@ -1,929 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#include <stdio.h>
-#include <string.h>
-
-#include <rte_common.h>
-#include <rte_malloc.h>
-#include <rte_byteorder.h>
-#include <rte_table_stub.h>
-#include <rte_table_hash.h>
-#include <rte_pipeline.h>
-
-#include "pipeline_passthrough_be.h"
-#include "pipeline_actions_common.h"
-#include "parser.h"
-#include "hash_func.h"
-
-#define SWAP_DIM (PIPELINE_PASSTHROUGH_SWAP_N_FIELDS_MAX * \
-	(PIPELINE_PASSTHROUGH_SWAP_FIELD_SIZE_MAX / sizeof(uint64_t)))
-
-struct pipeline_passthrough {
-	struct pipeline p;
-	struct pipeline_passthrough_params params;
-	rte_table_hash_op_hash f_hash;
-	uint32_t swap_field0_offset[SWAP_DIM];
-	uint32_t swap_field1_offset[SWAP_DIM];
-	uint64_t swap_field_mask[SWAP_DIM];
-	uint32_t swap_n_fields;
-} __rte_cache_aligned;
-
-static pipeline_msg_req_handler handlers[] = {
-	[PIPELINE_MSG_REQ_PING] =
-		pipeline_msg_req_ping_handler,
-	[PIPELINE_MSG_REQ_STATS_PORT_IN] =
-		pipeline_msg_req_stats_port_in_handler,
-	[PIPELINE_MSG_REQ_STATS_PORT_OUT] =
-		pipeline_msg_req_stats_port_out_handler,
-	[PIPELINE_MSG_REQ_STATS_TABLE] =
-		pipeline_msg_req_stats_table_handler,
-	[PIPELINE_MSG_REQ_PORT_IN_ENABLE] =
-		pipeline_msg_req_port_in_enable_handler,
-	[PIPELINE_MSG_REQ_PORT_IN_DISABLE] =
-		pipeline_msg_req_port_in_disable_handler,
-	[PIPELINE_MSG_REQ_CUSTOM] =
-		pipeline_msg_req_invalid_handler,
-};
-
-static __rte_always_inline void
-pkt_work_dma(
-	struct rte_mbuf *pkt,
-	void *arg,
-	uint32_t dma_size,
-	uint32_t hash_enabled,
-	uint32_t lb_hash,
-	uint32_t port_out_pow2)
-{
-	struct pipeline_passthrough *p = arg;
-
-	uint64_t *dma_dst = RTE_MBUF_METADATA_UINT64_PTR(pkt,
-		p->params.dma_dst_offset);
-	uint64_t *dma_src = RTE_MBUF_METADATA_UINT64_PTR(pkt,
-		p->params.dma_src_offset);
-	uint64_t *dma_mask = (uint64_t *) p->params.dma_src_mask;
-	uint32_t *dma_hash = RTE_MBUF_METADATA_UINT32_PTR(pkt,
-		p->params.dma_hash_offset);
-	uint32_t i;
-
-	/* Read (dma_src), compute (dma_dst), write (dma_dst) */
-	for (i = 0; i < (dma_size / 8); i++)
-		dma_dst[i] = dma_src[i] & dma_mask[i];
-
-	/* Read (dma_dst), compute (hash), write (hash) */
-	if (hash_enabled) {
-		uint32_t hash = p->f_hash(dma_src, dma_mask, dma_size, 0);
-		*dma_hash = hash;
-
-		if (lb_hash) {
-			uint32_t port_out;
-
-			if (port_out_pow2)
-				port_out
-					= hash & (p->p.n_ports_out - 1);
-			else
-				port_out
-					= hash % p->p.n_ports_out;
-
-			rte_pipeline_port_out_packet_insert(p->p.p,
-				port_out, pkt);
-		}
-	}
-}
-
-static __rte_always_inline void
-pkt4_work_dma(
-	struct rte_mbuf **pkts,
-	void *arg,
-	uint32_t dma_size,
-	uint32_t hash_enabled,
-	uint32_t lb_hash,
-	uint32_t port_out_pow2)
-{
-	struct pipeline_passthrough *p = arg;
-
-	uint64_t *dma_dst0 = RTE_MBUF_METADATA_UINT64_PTR(pkts[0],
-		p->params.dma_dst_offset);
-	uint64_t *dma_dst1 = RTE_MBUF_METADATA_UINT64_PTR(pkts[1],
-		p->params.dma_dst_offset);
-	uint64_t *dma_dst2 = RTE_MBUF_METADATA_UINT64_PTR(pkts[2],
-		p->params.dma_dst_offset);
-	uint64_t *dma_dst3 = RTE_MBUF_METADATA_UINT64_PTR(pkts[3],
-		p->params.dma_dst_offset);
-
-	uint64_t *dma_src0 = RTE_MBUF_METADATA_UINT64_PTR(pkts[0],
-		p->params.dma_src_offset);
-	uint64_t *dma_src1 = RTE_MBUF_METADATA_UINT64_PTR(pkts[1],
-		p->params.dma_src_offset);
-	uint64_t *dma_src2 = RTE_MBUF_METADATA_UINT64_PTR(pkts[2],
-		p->params.dma_src_offset);
-	uint64_t *dma_src3 = RTE_MBUF_METADATA_UINT64_PTR(pkts[3],
-		p->params.dma_src_offset);
-
-	uint64_t *dma_mask = (uint64_t *) p->params.dma_src_mask;
-
-	uint32_t *dma_hash0 = RTE_MBUF_METADATA_UINT32_PTR(pkts[0],
-		p->params.dma_hash_offset);
-	uint32_t *dma_hash1 = RTE_MBUF_METADATA_UINT32_PTR(pkts[1],
-		p->params.dma_hash_offset);
-	uint32_t *dma_hash2 = RTE_MBUF_METADATA_UINT32_PTR(pkts[2],
-		p->params.dma_hash_offset);
-	uint32_t *dma_hash3 = RTE_MBUF_METADATA_UINT32_PTR(pkts[3],
-		p->params.dma_hash_offset);
-
-	uint32_t i;
-
-	/* Read (dma_src), compute (dma_dst), write (dma_dst) */
-	for (i = 0; i < (dma_size / 8); i++) {
-		dma_dst0[i] = dma_src0[i] & dma_mask[i];
-		dma_dst1[i] = dma_src1[i] & dma_mask[i];
-		dma_dst2[i] = dma_src2[i] & dma_mask[i];
-		dma_dst3[i] = dma_src3[i] & dma_mask[i];
-	}
-
-	/* Read (dma_dst), compute (hash), write (hash) */
-	if (hash_enabled) {
-		uint32_t hash0 = p->f_hash(dma_src0, dma_mask, dma_size, 0);
-		uint32_t hash1 = p->f_hash(dma_src1, dma_mask, dma_size, 0);
-		uint32_t hash2 = p->f_hash(dma_src2, dma_mask, dma_size, 0);
-		uint32_t hash3 = p->f_hash(dma_src3, dma_mask, dma_size, 0);
-
-		*dma_hash0 = hash0;
-		*dma_hash1 = hash1;
-		*dma_hash2 = hash2;
-		*dma_hash3 = hash3;
-
-		if (lb_hash) {
-			uint32_t port_out0, port_out1, port_out2, port_out3;
-
-			if (port_out_pow2) {
-				port_out0
-					= hash0 & (p->p.n_ports_out - 1);
-				port_out1
-					= hash1 & (p->p.n_ports_out - 1);
-				port_out2
-					= hash2 & (p->p.n_ports_out - 1);
-				port_out3
-					= hash3 & (p->p.n_ports_out - 1);
-			} else {
-				port_out0
-					= hash0 % p->p.n_ports_out;
-				port_out1
-					= hash1 % p->p.n_ports_out;
-				port_out2
-					= hash2 % p->p.n_ports_out;
-				port_out3
-					= hash3 % p->p.n_ports_out;
-			}
-			rte_pipeline_port_out_packet_insert(p->p.p,
-				port_out0, pkts[0]);
-			rte_pipeline_port_out_packet_insert(p->p.p,
-				port_out1, pkts[1]);
-			rte_pipeline_port_out_packet_insert(p->p.p,
-				port_out2, pkts[2]);
-			rte_pipeline_port_out_packet_insert(p->p.p,
-				port_out3, pkts[3]);
-		}
-	}
-}
-
-static __rte_always_inline void
-pkt_work_swap(
-	struct rte_mbuf *pkt,
-	void *arg)
-{
-	struct pipeline_passthrough *p = arg;
-	uint32_t i;
-
-	/* Read(field0, field1), compute(field0, field1), write(field0, field1) */
-	for (i = 0; i < p->swap_n_fields; i++) {
-		uint64_t *field0_ptr = RTE_MBUF_METADATA_UINT64_PTR(pkt,
-			p->swap_field0_offset[i]);
-		uint64_t *field1_ptr = RTE_MBUF_METADATA_UINT64_PTR(pkt,
-			p->swap_field1_offset[i]);
-		uint64_t mask = p->swap_field_mask[i];
-
-		uint64_t field0 = *field0_ptr;
-		uint64_t field1 = *field1_ptr;
-
-		*field0_ptr = (field0 & (~mask)) + (field1 & mask);
-		*field1_ptr = (field0 & mask) + (field1 & (~mask));
-	}
-}
-
-static __rte_always_inline void
-pkt4_work_swap(
-	struct rte_mbuf **pkts,
-	void *arg)
-{
-	struct pipeline_passthrough *p = arg;
-	uint32_t i;
-
-	/* Read(field0, field1), compute(field0, field1), write(field0, field1) */
-	for (i = 0; i < p->swap_n_fields; i++) {
-		uint64_t *pkt0_field0_ptr = RTE_MBUF_METADATA_UINT64_PTR(pkts[0],
-			p->swap_field0_offset[i]);
-		uint64_t *pkt1_field0_ptr = RTE_MBUF_METADATA_UINT64_PTR(pkts[1],
-			p->swap_field0_offset[i]);
-		uint64_t *pkt2_field0_ptr = RTE_MBUF_METADATA_UINT64_PTR(pkts[2],
-			p->swap_field0_offset[i]);
-		uint64_t *pkt3_field0_ptr = RTE_MBUF_METADATA_UINT64_PTR(pkts[3],
-			p->swap_field0_offset[i]);
-
-		uint64_t *pkt0_field1_ptr = RTE_MBUF_METADATA_UINT64_PTR(pkts[0],
-			p->swap_field1_offset[i]);
-		uint64_t *pkt1_field1_ptr = RTE_MBUF_METADATA_UINT64_PTR(pkts[1],
-			p->swap_field1_offset[i]);
-		uint64_t *pkt2_field1_ptr = RTE_MBUF_METADATA_UINT64_PTR(pkts[2],
-			p->swap_field1_offset[i]);
-		uint64_t *pkt3_field1_ptr = RTE_MBUF_METADATA_UINT64_PTR(pkts[3],
-			p->swap_field1_offset[i]);
-
-		uint64_t mask = p->swap_field_mask[i];
-
-		uint64_t pkt0_field0 = *pkt0_field0_ptr;
-		uint64_t pkt1_field0 = *pkt1_field0_ptr;
-		uint64_t pkt2_field0 = *pkt2_field0_ptr;
-		uint64_t pkt3_field0 = *pkt3_field0_ptr;
-
-		uint64_t pkt0_field1 = *pkt0_field1_ptr;
-		uint64_t pkt1_field1 = *pkt1_field1_ptr;
-		uint64_t pkt2_field1 = *pkt2_field1_ptr;
-		uint64_t pkt3_field1 = *pkt3_field1_ptr;
-
-		*pkt0_field0_ptr = (pkt0_field0 & (~mask)) + (pkt0_field1 & mask);
-		*pkt1_field0_ptr = (pkt1_field0 & (~mask)) + (pkt1_field1 & mask);
-		*pkt2_field0_ptr = (pkt2_field0 & (~mask)) + (pkt2_field1 & mask);
-		*pkt3_field0_ptr = (pkt3_field0 & (~mask)) + (pkt3_field1 & mask);
-
-		*pkt0_field1_ptr = (pkt0_field0 & mask) + (pkt0_field1 & (~mask));
-		*pkt1_field1_ptr = (pkt1_field0 & mask) + (pkt1_field1 & (~mask));
-		*pkt2_field1_ptr = (pkt2_field0 & mask) + (pkt2_field1 & (~mask));
-		*pkt3_field1_ptr = (pkt3_field0 & mask) + (pkt3_field1 & (~mask));
-	}
-}
-
-#define PKT_WORK_DMA(dma_size, hash_enabled, lb_hash, port_pow2)	\
-static inline void						\
-pkt_work_dma_size##dma_size##_hash##hash_enabled		\
-	##_lb##lb_hash##_pw##port_pow2(			\
-	struct rte_mbuf *pkt,					\
-	void *arg)						\
-{								\
-	pkt_work_dma(pkt, arg, dma_size, hash_enabled, lb_hash, port_pow2);	\
-}
-
-#define PKT4_WORK_DMA(dma_size, hash_enabled, lb_hash, port_pow2)	\
-static inline void						\
-pkt4_work_dma_size##dma_size##_hash##hash_enabled			\
-	##_lb##lb_hash##_pw##port_pow2(			\
-	struct rte_mbuf **pkts,					\
-	void *arg)						\
-{								\
-	pkt4_work_dma(pkts, arg, dma_size, hash_enabled, lb_hash, port_pow2); \
-}
-
-#define port_in_ah_dma(dma_size, hash_enabled, lb_hash, port_pow2)	\
-PKT_WORK_DMA(dma_size, hash_enabled, lb_hash, port_pow2)			\
-PKT4_WORK_DMA(dma_size, hash_enabled, lb_hash, port_pow2)			\
-PIPELINE_PORT_IN_AH(port_in_ah_dma_size##dma_size##_hash	\
-	##hash_enabled##_lb##lb_hash##_pw##port_pow2,		\
-	pkt_work_dma_size##dma_size##_hash##hash_enabled		\
-	##_lb##lb_hash##_pw##port_pow2,			\
-	pkt4_work_dma_size##dma_size##_hash##hash_enabled		\
-	##_lb##lb_hash##_pw##port_pow2)
-
-
-#define port_in_ah_lb(dma_size, hash_enabled, lb_hash, port_pow2) \
-PKT_WORK_DMA(dma_size, hash_enabled, lb_hash, port_pow2)		\
-PKT4_WORK_DMA(dma_size, hash_enabled, lb_hash, port_pow2)	\
-PIPELINE_PORT_IN_AH_HIJACK_ALL(						\
-	port_in_ah_lb_size##dma_size##_hash##hash_enabled		\
-	##_lb##lb_hash##_pw##port_pow2,			\
-	pkt_work_dma_size##dma_size##_hash##hash_enabled		\
-	##_lb##lb_hash##_pw##port_pow2,	\
-	pkt4_work_dma_size##dma_size##_hash##hash_enabled		\
-	##_lb##lb_hash##_pw##port_pow2)
-
-PIPELINE_PORT_IN_AH(port_in_ah_swap, pkt_work_swap,	pkt4_work_swap)
-
-
-/* Port in AH DMA(dma_size, hash_enabled, lb_hash, port_pow2) */
-
-port_in_ah_dma(8, 0, 0, 0)
-port_in_ah_dma(8, 1, 0, 0)
-port_in_ah_lb(8, 1, 1, 0)
-port_in_ah_lb(8, 1, 1, 1)
-
-port_in_ah_dma(16, 0, 0, 0)
-port_in_ah_dma(16, 1, 0, 0)
-port_in_ah_lb(16, 1, 1, 0)
-port_in_ah_lb(16, 1, 1, 1)
-
-port_in_ah_dma(24, 0, 0, 0)
-port_in_ah_dma(24, 1, 0, 0)
-port_in_ah_lb(24, 1, 1, 0)
-port_in_ah_lb(24, 1, 1, 1)
-
-port_in_ah_dma(32, 0, 0, 0)
-port_in_ah_dma(32, 1, 0, 0)
-port_in_ah_lb(32, 1, 1, 0)
-port_in_ah_lb(32, 1, 1, 1)
-
-port_in_ah_dma(40, 0, 0, 0)
-port_in_ah_dma(40, 1, 0, 0)
-port_in_ah_lb(40, 1, 1, 0)
-port_in_ah_lb(40, 1, 1, 1)
-
-port_in_ah_dma(48, 0, 0, 0)
-port_in_ah_dma(48, 1, 0, 0)
-port_in_ah_lb(48, 1, 1, 0)
-port_in_ah_lb(48, 1, 1, 1)
-
-port_in_ah_dma(56, 0, 0, 0)
-port_in_ah_dma(56, 1, 0, 0)
-port_in_ah_lb(56, 1, 1, 0)
-port_in_ah_lb(56, 1, 1, 1)
-
-port_in_ah_dma(64, 0, 0, 0)
-port_in_ah_dma(64, 1, 0, 0)
-port_in_ah_lb(64, 1, 1, 0)
-port_in_ah_lb(64, 1, 1, 1)
-
-static rte_pipeline_port_in_action_handler
-get_port_in_ah(struct pipeline_passthrough *p)
-{
-	if ((p->params.dma_enabled == 0) &&
-		(p->params.swap_enabled == 0))
-		return NULL;
-
-	if (p->params.swap_enabled)
-		return port_in_ah_swap;
-
-	if (p->params.dma_hash_enabled) {
-		if (p->params.dma_hash_lb_enabled) {
-			if (rte_is_power_of_2(p->p.n_ports_out))
-				switch (p->params.dma_size) {
-
-				case 8: return port_in_ah_lb_size8_hash1_lb1_pw1;
-				case 16: return port_in_ah_lb_size16_hash1_lb1_pw1;
-				case 24: return port_in_ah_lb_size24_hash1_lb1_pw1;
-				case 32: return port_in_ah_lb_size32_hash1_lb1_pw1;
-				case 40: return port_in_ah_lb_size40_hash1_lb1_pw1;
-				case 48: return port_in_ah_lb_size48_hash1_lb1_pw1;
-				case 56: return port_in_ah_lb_size56_hash1_lb1_pw1;
-				case 64: return port_in_ah_lb_size64_hash1_lb1_pw1;
-				default: return NULL;
-				}
-			else
-				switch (p->params.dma_size) {
-
-				case 8: return port_in_ah_lb_size8_hash1_lb1_pw0;
-				case 16: return port_in_ah_lb_size16_hash1_lb1_pw0;
-				case 24: return port_in_ah_lb_size24_hash1_lb1_pw0;
-				case 32: return port_in_ah_lb_size32_hash1_lb1_pw0;
-				case 40: return port_in_ah_lb_size40_hash1_lb1_pw0;
-				case 48: return port_in_ah_lb_size48_hash1_lb1_pw0;
-				case 56: return port_in_ah_lb_size56_hash1_lb1_pw0;
-				case 64: return port_in_ah_lb_size64_hash1_lb1_pw0;
-				default: return NULL;
-			}
-		} else
-			switch (p->params.dma_size) {
-
-			case 8: return port_in_ah_dma_size8_hash1_lb0_pw0;
-			case 16: return port_in_ah_dma_size16_hash1_lb0_pw0;
-			case 24: return port_in_ah_dma_size24_hash1_lb0_pw0;
-			case 32: return port_in_ah_dma_size32_hash1_lb0_pw0;
-			case 40: return port_in_ah_dma_size40_hash1_lb0_pw0;
-			case 48: return port_in_ah_dma_size48_hash1_lb0_pw0;
-			case 56: return port_in_ah_dma_size56_hash1_lb0_pw0;
-			case 64: return port_in_ah_dma_size64_hash1_lb0_pw0;
-			default: return NULL;
-		}
-	} else
-		switch (p->params.dma_size) {
-
-		case 8: return port_in_ah_dma_size8_hash0_lb0_pw0;
-		case 16: return port_in_ah_dma_size16_hash0_lb0_pw0;
-		case 24: return port_in_ah_dma_size24_hash0_lb0_pw0;
-		case 32: return port_in_ah_dma_size32_hash0_lb0_pw0;
-		case 40: return port_in_ah_dma_size40_hash0_lb0_pw0;
-		case 48: return port_in_ah_dma_size48_hash0_lb0_pw0;
-		case 56: return port_in_ah_dma_size56_hash0_lb0_pw0;
-		case 64: return port_in_ah_dma_size64_hash0_lb0_pw0;
-		default: return NULL;
-		}
-}
-
-int
-pipeline_passthrough_parse_args(struct pipeline_passthrough_params *p,
-	struct pipeline_params *params)
-{
-	uint32_t dma_dst_offset_present = 0;
-	uint32_t dma_src_offset_present = 0;
-	uint32_t dma_src_mask_present = 0;
-	char dma_mask_str[PIPELINE_PASSTHROUGH_DMA_SIZE_MAX * 2 + 1];
-	uint32_t dma_size_present = 0;
-	uint32_t dma_hash_offset_present = 0;
-	uint32_t dma_hash_lb_present = 0;
-	uint32_t i;
-
-	/* default values */
-	p->dma_enabled = 0;
-	p->dma_hash_enabled = 0;
-	p->dma_hash_lb_enabled = 0;
-	memset(p->dma_src_mask, 0xFF, sizeof(p->dma_src_mask));
-	p->swap_enabled = 0;
-	p->swap_n_fields = 0;
-
-	for (i = 0; i < params->n_args; i++) {
-		char *arg_name = params->args_name[i];
-		char *arg_value = params->args_value[i];
-
-		/* dma_dst_offset */
-		if (strcmp(arg_name, "dma_dst_offset") == 0) {
-			int status;
-
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				dma_dst_offset_present == 0, params->name,
-				arg_name);
-			dma_dst_offset_present = 1;
-
-			status = parser_read_uint32(&p->dma_dst_offset,
-				arg_value);
-			PIPELINE_PARSE_ERR_INV_VAL((status != -EINVAL),
-				params->name, arg_name, arg_value);
-			PIPELINE_PARSE_ERR_OUT_RNG((status != -ERANGE),
-				params->name, arg_name, arg_value);
-
-			p->dma_enabled = 1;
-
-			continue;
-		}
-
-		/* dma_src_offset */
-		if (strcmp(arg_name, "dma_src_offset") == 0) {
-			int status;
-
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				dma_src_offset_present == 0, params->name,
-				arg_name);
-			dma_src_offset_present = 1;
-
-			status = parser_read_uint32(&p->dma_src_offset,
-				arg_value);
-			PIPELINE_PARSE_ERR_INV_VAL((status != -EINVAL),
-				params->name, arg_name, arg_value);
-			PIPELINE_PARSE_ERR_OUT_RNG((status != -ERANGE),
-				params->name, arg_name, arg_value);
-
-			p->dma_enabled = 1;
-
-			continue;
-		}
-
-		/* dma_size */
-		if (strcmp(arg_name, "dma_size") == 0) {
-			int status;
-
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				dma_size_present == 0, params->name,
-				arg_name);
-			dma_size_present = 1;
-
-			status = parser_read_uint32(&p->dma_size,
-				arg_value);
-			PIPELINE_PARSE_ERR_INV_VAL(((status != -EINVAL) &&
-				(p->dma_size != 0) &&
-				((p->dma_size % 8) == 0)),
-				params->name, arg_name, arg_value);
-			PIPELINE_PARSE_ERR_OUT_RNG(((status != -ERANGE) &&
-				(p->dma_size <=
-				PIPELINE_PASSTHROUGH_DMA_SIZE_MAX)),
-				params->name, arg_name, arg_value);
-
-			p->dma_enabled = 1;
-
-			continue;
-		}
-
-		/* dma_src_mask */
-		if (strcmp(arg_name, "dma_src_mask") == 0) {
-			int mask_str_len = strlen(arg_value);
-
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				dma_src_mask_present == 0,
-				params->name, arg_name);
-			dma_src_mask_present = 1;
-
-			PIPELINE_ARG_CHECK((mask_str_len <=
-				(PIPELINE_PASSTHROUGH_DMA_SIZE_MAX * 2)),
-				"Parse error in section \"%s\": entry "
-				"\"%s\" too long", params->name,
-				arg_name);
-
-			snprintf(dma_mask_str, mask_str_len + 1,
-				"%s", arg_value);
-
-			p->dma_enabled = 1;
-
-			continue;
-		}
-
-		/* dma_hash_offset */
-		if (strcmp(arg_name, "dma_hash_offset") == 0) {
-			int status;
-
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				dma_hash_offset_present == 0,
-				params->name, arg_name);
-			dma_hash_offset_present = 1;
-
-			status = parser_read_uint32(&p->dma_hash_offset,
-				arg_value);
-			PIPELINE_PARSE_ERR_INV_VAL((status != -EINVAL),
-				params->name, arg_name, arg_value);
-			PIPELINE_PARSE_ERR_OUT_RNG((status != -ERANGE),
-				params->name, arg_name, arg_value);
-
-			p->dma_hash_enabled = 1;
-
-			continue;
-		}
-
-		/* load_balance mode */
-		if (strcmp(arg_name, "lb") == 0) {
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				dma_hash_lb_present == 0,
-				params->name, arg_name);
-			dma_hash_lb_present = 1;
-
-			if (strcmp(arg_value, "hash") &&
-				strcmp(arg_value, "HASH"))
-
-				PIPELINE_PARSE_ERR_INV_VAL(0,
-					params->name,
-					arg_name,
-					arg_value);
-
-			p->dma_hash_lb_enabled = 1;
-
-			continue;
-		}
-
-		/* swap */
-		if (strcmp(arg_name, "swap") == 0) {
-			uint32_t a, b, n_args;
-			int len;
-
-			n_args = sscanf(arg_value, "%" SCNu32 " %" SCNu32 "%n",
-				&a, &b, &len);
-			PIPELINE_PARSE_ERR_INV_VAL(((n_args == 2) &&
-				((size_t) len == strlen(arg_value))),
-				params->name, arg_name, arg_value);
-
-			p->swap_field0_offset[p->swap_n_fields] = a;
-			p->swap_field1_offset[p->swap_n_fields] = b;
-			p->swap_n_fields++;
-			p->swap_enabled = 1;
-
-			continue;
-		}
-
-		/* any other */
-		PIPELINE_PARSE_ERR_INV_ENT(0, params->name, arg_name);
-	}
-
-	/* Check correlations between arguments */
-	PIPELINE_ARG_CHECK((p->dma_enabled + p->swap_enabled < 2),
-		"Parse error in section \"%s\": DMA and SWAP actions are both enabled",
-		params->name);
-	PIPELINE_ARG_CHECK((dma_dst_offset_present == p->dma_enabled),
-		"Parse error in section \"%s\": missing entry "
-		"\"dma_dst_offset\"", params->name);
-	PIPELINE_ARG_CHECK((dma_src_offset_present == p->dma_enabled),
-		"Parse error in section \"%s\": missing entry "
-		"\"dma_src_offset\"", params->name);
-	PIPELINE_ARG_CHECK((dma_size_present == p->dma_enabled),
-		"Parse error in section \"%s\": missing entry "
-		"\"dma_size\"", params->name);
-	PIPELINE_ARG_CHECK((p->dma_hash_enabled <= p->dma_enabled),
-		"Parse error in section \"%s\": missing all DMA entries",
-		params->name);
-	PIPELINE_ARG_CHECK((p->dma_hash_lb_enabled <= p->dma_hash_enabled),
-		"Parse error in section \"%s\": missing all DMA hash entries ",
-		params->name);
-
-	if (dma_src_mask_present) {
-		uint32_t dma_size = p->dma_size;
-		int status;
-
-		PIPELINE_ARG_CHECK((strlen(dma_mask_str) ==
-			(dma_size * 2)), "Parse error in section "
-			"\"%s\": dma_src_mask should have exactly %u hex "
-			"digits", params->name, (dma_size * 2));
-
-		status = parse_hex_string(dma_mask_str, p->dma_src_mask,
-			&p->dma_size);
-
-		PIPELINE_PARSE_ERR_INV_VAL(((status == 0) &&
-			(dma_size == p->dma_size)), params->name,
-			"dma_src_mask", dma_mask_str);
-	}
-
-	if (p->dma_hash_lb_enabled)
-		PIPELINE_ARG_CHECK((params->n_ports_out > 1),
-			"Parse error in section \"%s\": entry \"lb\" not "
-			"allowed for single output port pipeline",
-			params->name);
-	else
-		PIPELINE_ARG_CHECK(((params->n_ports_in >= params->n_ports_out)
-			&& ((params->n_ports_in % params->n_ports_out) == 0)),
-			"Parse error in section \"%s\": n_ports_in needs to be "
-			"a multiple of n_ports_out (lb mode disabled)",
-			params->name);
-
-	return 0;
-}
-
-static rte_table_hash_op_hash
-get_hash_function(struct pipeline_passthrough *p)
-{
-	switch (p->params.dma_size) {
-
-	case 8: return hash_default_key8;
-	case 16: return hash_default_key16;
-	case 24: return hash_default_key24;
-	case 32: return hash_default_key32;
-	case 40: return hash_default_key40;
-	case 48: return hash_default_key48;
-	case 56: return hash_default_key56;
-	case 64: return hash_default_key64;
-	default: return NULL;
-	}
-}
-
-static int
-pipeline_passthrough_swap_convert(struct pipeline_passthrough *p)
-{
-	uint32_t i;
-
-	p->swap_n_fields = 0;
-
-	for (i = 0; i < p->params.swap_n_fields; i++) {
-		uint32_t offset0 = p->params.swap_field0_offset[i];
-		uint32_t offset1 = p->params.swap_field1_offset[i];
-		uint32_t size = offset1 - offset0;
-		uint32_t j;
-
-		/* Check */
-		if ((offset0 >= offset1) ||
-			(size > PIPELINE_PASSTHROUGH_SWAP_FIELD_SIZE_MAX) ||
-			(p->swap_n_fields >= SWAP_DIM))
-			return -1;
-
-		for (j = 0; j < (size / sizeof(uint64_t)); j++) {
-			p->swap_field0_offset[p->swap_n_fields] = offset0;
-			p->swap_field1_offset[p->swap_n_fields] = offset1;
-			p->swap_field_mask[p->swap_n_fields] = UINT64_MAX;
-			p->swap_n_fields++;
-			offset0 += sizeof(uint64_t);
-			offset1 += sizeof(uint64_t);
-		}
-		if (size % sizeof(uint64_t)) {
-			uint32_t n_bits = (size % sizeof(uint64_t)) * 8;
-
-			p->swap_field0_offset[p->swap_n_fields] = offset0;
-			p->swap_field1_offset[p->swap_n_fields] = offset1;
-			p->swap_field_mask[p->swap_n_fields] =
-				RTE_LEN2MASK(n_bits, uint64_t);
-			p->swap_n_fields++;
-		}
-	}
-
-	return 0;
-}
-
-static void*
-pipeline_passthrough_init(struct pipeline_params *params,
-	__rte_unused void *arg)
-{
-	struct pipeline *p;
-	struct pipeline_passthrough *p_pt;
-	uint32_t size, i;
-
-	/* Check input arguments */
-	if ((params == NULL) ||
-		(params->n_ports_in == 0) ||
-		(params->n_ports_out == 0))
-		return NULL;
-
-	/* Memory allocation */
-	size = RTE_CACHE_LINE_ROUNDUP(sizeof(struct pipeline_passthrough));
-	p = rte_zmalloc(NULL, size, RTE_CACHE_LINE_SIZE);
-	p_pt = (struct pipeline_passthrough *) p;
-	if (p == NULL)
-		return NULL;
-
-	strcpy(p->name, params->name);
-	p->log_level = params->log_level;
-
-	PLOG(p, HIGH, "Pass-through");
-
-	/* Parse arguments */
-	if (pipeline_passthrough_parse_args(&p_pt->params, params))
-		return NULL;
-	if (pipeline_passthrough_swap_convert(p_pt))
-		return NULL;
-	p_pt->f_hash = get_hash_function(p_pt);
-
-	/* Pipeline */
-	{
-		struct rte_pipeline_params pipeline_params = {
-			.name = "PASS-THROUGH",
-			.socket_id = params->socket_id,
-			.offset_port_id = 0,
-		};
-
-		p->p = rte_pipeline_create(&pipeline_params);
-		if (p->p == NULL) {
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	p->n_ports_in = params->n_ports_in;
-	p->n_ports_out = params->n_ports_out;
-	p->n_tables = p->n_ports_in;
-
-	/*Input ports*/
-	for (i = 0; i < p->n_ports_in; i++) {
-		struct rte_pipeline_port_in_params port_params = {
-			.ops = pipeline_port_in_params_get_ops(
-				&params->port_in[i]),
-			.arg_create = pipeline_port_in_params_convert(
-				&params->port_in[i]),
-			.f_action = get_port_in_ah(p_pt),
-			.arg_ah = p_pt,
-			.burst_size = params->port_in[i].burst_size,
-		};
-
-		int status = rte_pipeline_port_in_create(p->p,
-			&port_params,
-			&p->port_in_id[i]);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Output ports */
-	for (i = 0; i < p->n_ports_out; i++) {
-		struct rte_pipeline_port_out_params port_params = {
-			.ops = pipeline_port_out_params_get_ops(
-				&params->port_out[i]),
-			.arg_create = pipeline_port_out_params_convert(
-				&params->port_out[i]),
-			.f_action = NULL,
-			.arg_ah = NULL,
-		};
-
-		int status = rte_pipeline_port_out_create(p->p,
-			&port_params,
-			&p->port_out_id[i]);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Tables */
-	for (i = 0; i < p->n_ports_in; i++) {
-		struct rte_pipeline_table_params table_params = {
-			.ops = &rte_table_stub_ops,
-			.arg_create = NULL,
-			.f_action_hit = NULL,
-			.f_action_miss = NULL,
-			.arg_ah = NULL,
-			.action_data_size = 0,
-		};
-
-		int status = rte_pipeline_table_create(p->p,
-			&table_params,
-			&p->table_id[i]);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Connecting input ports to tables */
-	for (i = 0; i < p->n_ports_in; i++) {
-		int status = rte_pipeline_port_in_connect_to_table(p->p,
-			p->port_in_id[i],
-			p->table_id[i]);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Add entries to tables */
-	for (i = 0; i < p->n_ports_in; i++) {
-		uint32_t port_out_id = (p_pt->params.dma_hash_lb_enabled == 0) ?
-			(i / (p->n_ports_in / p->n_ports_out)) :
-			0;
-
-		struct rte_pipeline_table_entry default_entry = {
-			.action = RTE_PIPELINE_ACTION_PORT,
-			{.port_id = p->port_out_id[port_out_id]},
-		};
-
-		struct rte_pipeline_table_entry *default_entry_ptr;
-
-		int status = rte_pipeline_table_default_entry_add(p->p,
-			p->table_id[i],
-			&default_entry,
-			&default_entry_ptr);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Enable input ports */
-	for (i = 0; i < p->n_ports_in; i++) {
-		int status = rte_pipeline_port_in_enable(p->p,
-			p->port_in_id[i]);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Check pipeline consistency */
-	if (rte_pipeline_check(p->p) < 0) {
-		rte_pipeline_free(p->p);
-		rte_free(p);
-		return NULL;
-	}
-
-	/* Message queues */
-	p->n_msgq = params->n_msgq;
-	for (i = 0; i < p->n_msgq; i++)
-		p->msgq_in[i] = params->msgq_in[i];
-	for (i = 0; i < p->n_msgq; i++)
-		p->msgq_out[i] = params->msgq_out[i];
-
-	/* Message handlers */
-	memcpy(p->handlers, handlers, sizeof(p->handlers));
-
-	return p;
-}
-
-static int
-pipeline_passthrough_free(void *pipeline)
-{
-	struct pipeline *p = (struct pipeline *) pipeline;
-
-	/* Check input arguments */
-	if (p == NULL)
-		return -1;
-
-	/* Free resources */
-	rte_pipeline_free(p->p);
-	rte_free(p);
-	return 0;
-}
-
-static int
-pipeline_passthrough_timer(void *pipeline)
-{
-	struct pipeline *p = (struct pipeline *) pipeline;
-
-	pipeline_msg_req_handle(p);
-	rte_pipeline_flush(p->p);
-
-	return 0;
-}
-
-struct pipeline_be_ops pipeline_passthrough_be_ops = {
-	.f_init = pipeline_passthrough_init,
-	.f_free = pipeline_passthrough_free,
-	.f_run = NULL,
-	.f_timer = pipeline_passthrough_timer,
-};
diff --git a/examples/ip_pipeline/pipeline/pipeline_passthrough_be.h b/examples/ip_pipeline/pipeline/pipeline_passthrough_be.h
deleted file mode 100644
index 94d1d1c..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_passthrough_be.h
+++ /dev/null
@@ -1,44 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#ifndef __INCLUDE_PIPELINE_PASSTHROUGH_BE_H__
-#define __INCLUDE_PIPELINE_PASSTHROUGH_BE_H__
-
-#include "pipeline_common_be.h"
-
-#define PIPELINE_PASSTHROUGH_DMA_SIZE_MAX                             64
-
-#ifndef PIPELINE_PASSTHROUGH_SWAP_N_FIELDS_MAX
-#define PIPELINE_PASSTHROUGH_SWAP_N_FIELDS_MAX                        8
-#endif
-
-#ifndef PIPELINE_PASSTHROUGH_SWAP_FIELD_SIZE_MAX
-#define PIPELINE_PASSTHROUGH_SWAP_FIELD_SIZE_MAX                      16
-#endif
-
-struct pipeline_passthrough_params {
-	uint32_t dma_enabled;
-	uint32_t dma_dst_offset;
-	uint32_t dma_src_offset;
-	uint8_t dma_src_mask[PIPELINE_PASSTHROUGH_DMA_SIZE_MAX];
-	uint32_t dma_size;
-
-	uint32_t dma_hash_enabled;
-	uint32_t dma_hash_offset;
-
-	uint32_t dma_hash_lb_enabled;
-
-	uint32_t swap_enabled;
-	uint32_t swap_field0_offset[PIPELINE_PASSTHROUGH_SWAP_N_FIELDS_MAX];
-	uint32_t swap_field1_offset[PIPELINE_PASSTHROUGH_SWAP_N_FIELDS_MAX];
-	uint32_t swap_n_fields;
-};
-
-int
-pipeline_passthrough_parse_args(struct pipeline_passthrough_params *p,
-	struct pipeline_params *params);
-
-extern struct pipeline_be_ops pipeline_passthrough_be_ops;
-
-#endif
diff --git a/examples/ip_pipeline/pipeline/pipeline_routing.c b/examples/ip_pipeline/pipeline/pipeline_routing.c
deleted file mode 100644
index 0562c63..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_routing.c
+++ /dev/null
@@ -1,1613 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#include <cmdline_parse.h>
-#include <cmdline_parse_num.h>
-#include <cmdline_parse_string.h>
-
-#include "app.h"
-#include "pipeline_common_fe.h"
-#include "pipeline_routing.h"
-#include "parser.h"
-
-struct app_pipeline_routing_route {
-	struct pipeline_routing_route_key key;
-	struct pipeline_routing_route_data data;
-	void *entry_ptr;
-
-	TAILQ_ENTRY(app_pipeline_routing_route) node;
-};
-
-struct app_pipeline_routing_arp_entry {
-	struct pipeline_routing_arp_key key;
-	struct ether_addr macaddr;
-	void *entry_ptr;
-
-	TAILQ_ENTRY(app_pipeline_routing_arp_entry) node;
-};
-
-struct pipeline_routing {
-	/* Parameters */
-	struct app_params *app;
-	uint32_t pipeline_id;
-	uint32_t n_ports_in;
-	uint32_t n_ports_out;
-	struct pipeline_routing_params rp;
-
-	/* Links */
-	uint32_t link_id[PIPELINE_MAX_PORT_OUT];
-
-	/* Routes */
-	TAILQ_HEAD(, app_pipeline_routing_route) routes;
-	uint32_t n_routes;
-
-	uint32_t default_route_present;
-	uint32_t default_route_port_id;
-	void *default_route_entry_ptr;
-
-	/* ARP entries */
-	TAILQ_HEAD(, app_pipeline_routing_arp_entry) arp_entries;
-	uint32_t n_arp_entries;
-
-	uint32_t default_arp_entry_present;
-	uint32_t default_arp_entry_port_id;
-	void *default_arp_entry_ptr;
-};
-
-static int
-app_pipeline_routing_find_link(struct pipeline_routing *p,
-	uint32_t link_id,
-	uint32_t *port_id)
-{
-	uint32_t i;
-
-	for (i = 0; i < p->n_ports_out; i++)
-		if (p->link_id[i] == link_id) {
-			*port_id = i;
-			return 0;
-		}
-
-	return -1;
-}
-
-static void
-app_pipeline_routing_link_op(__rte_unused struct app_params *app,
-	uint32_t link_id,
-	uint32_t up,
-	void *arg)
-{
-	struct pipeline_routing_route_key key0, key1;
-	struct pipeline_routing *p = arg;
-	struct app_link_params *lp;
-	uint32_t port_id, netmask;
-	int status;
-
-	if (app == NULL)
-		return;
-
-	APP_PARAM_FIND_BY_ID(app->link_params, "LINK", link_id, lp);
-	if (lp == NULL)
-		return;
-
-	status = app_pipeline_routing_find_link(p,
-		link_id,
-		&port_id);
-	if (status)
-		return;
-
-	netmask = (~0U) << (32 - lp->depth);
-
-	/* Local network (directly attached network) */
-	key0.type = PIPELINE_ROUTING_ROUTE_IPV4;
-	key0.key.ipv4.ip = lp->ip & netmask;
-	key0.key.ipv4.depth = lp->depth;
-
-	/* Local termination */
-	key1.type = PIPELINE_ROUTING_ROUTE_IPV4;
-	key1.key.ipv4.ip = lp->ip;
-	key1.key.ipv4.depth = 32;
-
-	if (up) {
-		struct pipeline_routing_route_data data0, data1;
-
-		/* Local network (directly attached network) */
-		memset(&data0, 0, sizeof(data0));
-		data0.flags = PIPELINE_ROUTING_ROUTE_LOCAL |
-			PIPELINE_ROUTING_ROUTE_ARP;
-		if (p->rp.encap == PIPELINE_ROUTING_ENCAP_ETHERNET_QINQ)
-			data0.flags |= PIPELINE_ROUTING_ROUTE_QINQ;
-		if (p->rp.encap == PIPELINE_ROUTING_ENCAP_ETHERNET_MPLS) {
-			data0.flags |= PIPELINE_ROUTING_ROUTE_MPLS;
-			data0.l2.mpls.n_labels = 1;
-		}
-		data0.port_id = port_id;
-
-		if (p->rp.n_arp_entries)
-			app_pipeline_routing_add_route(app,
-				p->pipeline_id,
-				&key0,
-				&data0);
-
-		/* Local termination */
-		memset(&data1, 0, sizeof(data1));
-		data1.flags = PIPELINE_ROUTING_ROUTE_LOCAL |
-			PIPELINE_ROUTING_ROUTE_ARP;
-		if (p->rp.encap == PIPELINE_ROUTING_ENCAP_ETHERNET_QINQ)
-			data1.flags |= PIPELINE_ROUTING_ROUTE_QINQ;
-		if (p->rp.encap == PIPELINE_ROUTING_ENCAP_ETHERNET_MPLS) {
-			data1.flags |= PIPELINE_ROUTING_ROUTE_MPLS;
-			data1.l2.mpls.n_labels = 1;
-		}
-		data1.port_id = p->rp.port_local_dest;
-
-		app_pipeline_routing_add_route(app,
-			p->pipeline_id,
-			&key1,
-			&data1);
-	} else {
-		/* Local network (directly attached network) */
-		if (p->rp.n_arp_entries)
-			app_pipeline_routing_delete_route(app,
-				p->pipeline_id,
-				&key0);
-
-		/* Local termination */
-		app_pipeline_routing_delete_route(app,
-			p->pipeline_id,
-			&key1);
-	}
-}
-
-static int
-app_pipeline_routing_set_link_op(
-	struct app_params *app,
-	struct pipeline_routing *p)
-{
-	uint32_t port_id;
-
-	for (port_id = 0; port_id < p->n_ports_out; port_id++) {
-		struct app_link_params *link;
-		uint32_t link_id;
-		int status;
-
-		link = app_pipeline_track_pktq_out_to_link(app,
-			p->pipeline_id,
-			port_id);
-		if (link == NULL)
-			continue;
-
-		link_id = link - app->link_params;
-		p->link_id[port_id] = link_id;
-
-		status = app_link_set_op(app,
-			link_id,
-			p->pipeline_id,
-			app_pipeline_routing_link_op,
-			(void *) p);
-		if (status)
-			return status;
-	}
-
-	return 0;
-}
-
-static void *
-app_pipeline_routing_init(struct pipeline_params *params,
-	void *arg)
-{
-	struct app_params *app = (struct app_params *) arg;
-	struct pipeline_routing *p;
-	uint32_t pipeline_id, size;
-	int status;
-
-	/* Check input arguments */
-	if ((params == NULL) ||
-		(params->n_ports_in == 0) ||
-		(params->n_ports_out == 0))
-		return NULL;
-
-	APP_PARAM_GET_ID(params, "PIPELINE", pipeline_id);
-
-	/* Memory allocation */
-	size = RTE_CACHE_LINE_ROUNDUP(sizeof(struct pipeline_routing));
-	p = rte_zmalloc(NULL, size, RTE_CACHE_LINE_SIZE);
-	if (p == NULL)
-		return NULL;
-
-	/* Initialization */
-	p->app = app;
-	p->pipeline_id = pipeline_id;
-	p->n_ports_in = params->n_ports_in;
-	p->n_ports_out = params->n_ports_out;
-
-	status = pipeline_routing_parse_args(&p->rp, params);
-	if (status) {
-		rte_free(p);
-		return NULL;
-	}
-	TAILQ_INIT(&p->routes);
-	p->n_routes = 0;
-
-	TAILQ_INIT(&p->arp_entries);
-	p->n_arp_entries = 0;
-
-	app_pipeline_routing_set_link_op(app, p);
-
-	return p;
-}
-
-static int
-app_pipeline_routing_post_init(void *pipeline)
-{
-	struct pipeline_routing *p = pipeline;
-
-	/* Check input arguments */
-	if (p == NULL)
-		return -1;
-
-	return app_pipeline_routing_set_macaddr(p->app, p->pipeline_id);
-}
-
-static int
-app_pipeline_routing_free(void *pipeline)
-{
-	struct pipeline_routing *p = pipeline;
-
-	/* Check input arguments */
-	if (p == NULL)
-		return -1;
-
-	/* Free resources */
-	while (!TAILQ_EMPTY(&p->routes)) {
-		struct app_pipeline_routing_route *route;
-
-		route = TAILQ_FIRST(&p->routes);
-		TAILQ_REMOVE(&p->routes, route, node);
-		rte_free(route);
-	}
-
-	while (!TAILQ_EMPTY(&p->arp_entries)) {
-		struct app_pipeline_routing_arp_entry *arp_entry;
-
-		arp_entry = TAILQ_FIRST(&p->arp_entries);
-		TAILQ_REMOVE(&p->arp_entries, arp_entry, node);
-		rte_free(arp_entry);
-	}
-
-	rte_free(p);
-	return 0;
-}
-
-static struct app_pipeline_routing_route *
-app_pipeline_routing_find_route(struct pipeline_routing *p,
-		const struct pipeline_routing_route_key *key)
-{
-	struct app_pipeline_routing_route *it, *found;
-
-	found = NULL;
-	TAILQ_FOREACH(it, &p->routes, node) {
-		if ((key->type == it->key.type) &&
-			(key->key.ipv4.ip == it->key.key.ipv4.ip) &&
-			(key->key.ipv4.depth == it->key.key.ipv4.depth)) {
-			found = it;
-			break;
-		}
-	}
-
-	return found;
-}
-
-static struct app_pipeline_routing_arp_entry *
-app_pipeline_routing_find_arp_entry(struct pipeline_routing *p,
-		const struct pipeline_routing_arp_key *key)
-{
-	struct app_pipeline_routing_arp_entry *it, *found;
-
-	found = NULL;
-	TAILQ_FOREACH(it, &p->arp_entries, node) {
-		if ((key->type == it->key.type) &&
-			(key->key.ipv4.port_id == it->key.key.ipv4.port_id) &&
-			(key->key.ipv4.ip == it->key.key.ipv4.ip)) {
-			found = it;
-			break;
-		}
-	}
-
-	return found;
-}
-
-static void
-print_route(const struct app_pipeline_routing_route *route)
-{
-	if (route->key.type == PIPELINE_ROUTING_ROUTE_IPV4) {
-		const struct pipeline_routing_route_key_ipv4 *key =
-				&route->key.key.ipv4;
-
-		printf("IP Prefix = %" PRIu32 ".%" PRIu32
-			".%" PRIu32 ".%" PRIu32 "/%" PRIu32
-			" => (Port = %" PRIu32,
-
-			(key->ip >> 24) & 0xFF,
-			(key->ip >> 16) & 0xFF,
-			(key->ip >> 8) & 0xFF,
-			key->ip & 0xFF,
-
-			key->depth,
-			route->data.port_id);
-
-		if (route->data.flags & PIPELINE_ROUTING_ROUTE_LOCAL)
-			printf(", Local");
-		else if (route->data.flags & PIPELINE_ROUTING_ROUTE_ARP)
-			printf(
-				", Next Hop IP = %" PRIu32 ".%" PRIu32
-				".%" PRIu32 ".%" PRIu32,
-
-				(route->data.ethernet.ip >> 24) & 0xFF,
-				(route->data.ethernet.ip >> 16) & 0xFF,
-				(route->data.ethernet.ip >> 8) & 0xFF,
-				route->data.ethernet.ip & 0xFF);
-		else
-			printf(
-				", Next Hop HWaddress = %02" PRIx32
-				":%02" PRIx32 ":%02" PRIx32
-				":%02" PRIx32 ":%02" PRIx32
-				":%02" PRIx32,
-
-				route->data.ethernet.macaddr.addr_bytes[0],
-				route->data.ethernet.macaddr.addr_bytes[1],
-				route->data.ethernet.macaddr.addr_bytes[2],
-				route->data.ethernet.macaddr.addr_bytes[3],
-				route->data.ethernet.macaddr.addr_bytes[4],
-				route->data.ethernet.macaddr.addr_bytes[5]);
-
-		if (route->data.flags & PIPELINE_ROUTING_ROUTE_QINQ)
-			printf(", QinQ SVLAN = %" PRIu32 " CVLAN = %" PRIu32,
-				route->data.l2.qinq.svlan,
-				route->data.l2.qinq.cvlan);
-
-		if (route->data.flags & PIPELINE_ROUTING_ROUTE_MPLS) {
-			uint32_t i;
-
-			printf(", MPLS labels");
-			for (i = 0; i < route->data.l2.mpls.n_labels; i++)
-				printf(" %" PRIu32,
-					route->data.l2.mpls.labels[i]);
-		}
-
-		printf(")\n");
-	}
-}
-
-static void
-print_arp_entry(const struct app_pipeline_routing_arp_entry *entry)
-{
-	printf("(Port = %" PRIu32 ", IP = %" PRIu32 ".%" PRIu32
-		".%" PRIu32 ".%" PRIu32
-		") => HWaddress = %02" PRIx32 ":%02" PRIx32 ":%02" PRIx32
-		":%02" PRIx32 ":%02" PRIx32 ":%02" PRIx32 "\n",
-
-		entry->key.key.ipv4.port_id,
-		(entry->key.key.ipv4.ip >> 24) & 0xFF,
-		(entry->key.key.ipv4.ip >> 16) & 0xFF,
-		(entry->key.key.ipv4.ip >> 8) & 0xFF,
-		entry->key.key.ipv4.ip & 0xFF,
-
-		entry->macaddr.addr_bytes[0],
-		entry->macaddr.addr_bytes[1],
-		entry->macaddr.addr_bytes[2],
-		entry->macaddr.addr_bytes[3],
-		entry->macaddr.addr_bytes[4],
-		entry->macaddr.addr_bytes[5]);
-}
-
-static int
-app_pipeline_routing_route_ls(struct app_params *app, uint32_t pipeline_id)
-{
-	struct pipeline_routing *p;
-	struct app_pipeline_routing_route *it;
-
-	p = app_pipeline_data_fe(app, pipeline_id, &pipeline_routing);
-	if (p == NULL)
-		return -EINVAL;
-
-	TAILQ_FOREACH(it, &p->routes, node)
-		print_route(it);
-
-	if (p->default_route_present)
-		printf("Default route: port %" PRIu32 " (entry ptr = %p)\n",
-				p->default_route_port_id,
-				p->default_route_entry_ptr);
-	else
-		printf("Default: DROP\n");
-
-	return 0;
-}
-
-int
-app_pipeline_routing_add_route(struct app_params *app,
-	uint32_t pipeline_id,
-	struct pipeline_routing_route_key *key,
-	struct pipeline_routing_route_data *data)
-{
-	struct pipeline_routing *p;
-
-	struct pipeline_routing_route_add_msg_req *req;
-	struct pipeline_routing_route_add_msg_rsp *rsp;
-
-	struct app_pipeline_routing_route *entry;
-
-	int new_entry;
-
-	/* Check input arguments */
-	if ((app == NULL) ||
-		(key == NULL) ||
-		(data == NULL))
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id, &pipeline_routing);
-	if (p == NULL)
-		return -1;
-
-	switch (key->type) {
-	case PIPELINE_ROUTING_ROUTE_IPV4:
-	{
-		uint32_t depth = key->key.ipv4.depth;
-		uint32_t netmask;
-
-		/* key */
-		if ((depth == 0) || (depth > 32))
-			return -1;
-
-		netmask = (~0U) << (32 - depth);
-		key->key.ipv4.ip &= netmask;
-
-		/* data */
-		if (data->port_id >= p->n_ports_out)
-			return -1;
-
-		/* Valid range of VLAN tags 12 bits */
-		if (data->flags & PIPELINE_ROUTING_ROUTE_QINQ)
-			if ((data->l2.qinq.svlan & 0xF000) ||
-					(data->l2.qinq.cvlan & 0xF000))
-				return -1;
-
-		/* Max number of MPLS labels supported */
-		if (data->flags & PIPELINE_ROUTING_ROUTE_MPLS) {
-			uint32_t i;
-
-			if (data->l2.mpls.n_labels >
-					PIPELINE_ROUTING_MPLS_LABELS_MAX)
-				return -1;
-
-			/* Max MPLS label value 20 bits */
-			for (i = 0; i < data->l2.mpls.n_labels; i++)
-				if (data->l2.mpls.labels[i] & 0xFFF00000)
-					return -1;
-		}
-	}
-	break;
-
-	default:
-		return -1;
-	}
-
-	/* Find existing rule or allocate new rule */
-	entry = app_pipeline_routing_find_route(p, key);
-	new_entry = (entry == NULL);
-	if (entry == NULL) {
-		entry = rte_malloc(NULL, sizeof(*entry), RTE_CACHE_LINE_SIZE);
-
-		if (entry == NULL)
-			return -1;
-	}
-
-	/* Allocate and write request */
-	req = app_msg_alloc(app);
-	if (req == NULL) {
-		if (new_entry)
-			rte_free(entry);
-		return -1;
-	}
-
-	req->type = PIPELINE_MSG_REQ_CUSTOM;
-	req->subtype = PIPELINE_ROUTING_MSG_REQ_ROUTE_ADD;
-	memcpy(&req->key, key, sizeof(*key));
-	memcpy(&req->data, data, sizeof(*data));
-
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL) {
-		if (new_entry)
-			rte_free(entry);
-		return -1;
-	}
-
-	/* Read response and write entry */
-	if (rsp->status ||
-		(rsp->entry_ptr == NULL) ||
-		((new_entry == 0) && (rsp->key_found == 0)) ||
-		((new_entry == 1) && (rsp->key_found == 1))) {
-		app_msg_free(app, rsp);
-		if (new_entry)
-			rte_free(entry);
-		return -1;
-	}
-
-	memcpy(&entry->key, key, sizeof(*key));
-	memcpy(&entry->data, data, sizeof(*data));
-	entry->entry_ptr = rsp->entry_ptr;
-
-	/* Commit entry */
-	if (new_entry) {
-		TAILQ_INSERT_TAIL(&p->routes, entry, node);
-		p->n_routes++;
-	}
-
-	/* Message buffer free */
-	app_msg_free(app, rsp);
-	return 0;
-}
-
-int
-app_pipeline_routing_delete_route(struct app_params *app,
-	uint32_t pipeline_id,
-	struct pipeline_routing_route_key *key)
-{
-	struct pipeline_routing *p;
-
-	struct pipeline_routing_route_delete_msg_req *req;
-	struct pipeline_routing_route_delete_msg_rsp *rsp;
-
-	struct app_pipeline_routing_route *entry;
-
-	/* Check input arguments */
-	if ((app == NULL) ||
-		(key == NULL))
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id, &pipeline_routing);
-	if (p == NULL)
-		return -1;
-
-	switch (key->type) {
-	case PIPELINE_ROUTING_ROUTE_IPV4:
-	{
-		uint32_t depth = key->key.ipv4.depth;
-		uint32_t netmask;
-
-		/* key */
-		if ((depth == 0) || (depth > 32))
-			return -1;
-
-		netmask = (~0U) << (32 - depth);
-		key->key.ipv4.ip &= netmask;
-	}
-	break;
-
-	default:
-		return -1;
-	}
-
-	/* Find rule */
-	entry = app_pipeline_routing_find_route(p, key);
-	if (entry == NULL)
-		return 0;
-
-	/* Allocate and write request */
-	req = app_msg_alloc(app);
-	if (req == NULL)
-		return -1;
-
-	req->type = PIPELINE_MSG_REQ_CUSTOM;
-	req->subtype = PIPELINE_ROUTING_MSG_REQ_ROUTE_DEL;
-	memcpy(&req->key, key, sizeof(*key));
-
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL)
-		return -1;
-
-	/* Read response */
-	if (rsp->status || !rsp->key_found) {
-		app_msg_free(app, rsp);
-		return -1;
-	}
-
-	/* Remove route */
-	TAILQ_REMOVE(&p->routes, entry, node);
-	p->n_routes--;
-	rte_free(entry);
-
-	/* Free response */
-	app_msg_free(app, rsp);
-
-	return 0;
-}
-
-int
-app_pipeline_routing_add_default_route(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t port_id)
-{
-	struct pipeline_routing *p;
-
-	struct pipeline_routing_route_add_default_msg_req *req;
-	struct pipeline_routing_route_add_default_msg_rsp *rsp;
-
-	/* Check input arguments */
-	if (app == NULL)
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id, &pipeline_routing);
-	if (p == NULL)
-		return -1;
-
-	if (port_id >= p->n_ports_out)
-		return -1;
-
-	/* Allocate and write request */
-	req = app_msg_alloc(app);
-	if (req == NULL)
-		return -1;
-
-	req->type = PIPELINE_MSG_REQ_CUSTOM;
-	req->subtype = PIPELINE_ROUTING_MSG_REQ_ROUTE_ADD_DEFAULT;
-	req->port_id = port_id;
-
-	/* Send request and wait for response */
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL)
-		return -1;
-
-	/* Read response and write route */
-	if (rsp->status || (rsp->entry_ptr == NULL)) {
-		app_msg_free(app, rsp);
-		return -1;
-	}
-
-	p->default_route_port_id = port_id;
-	p->default_route_entry_ptr = rsp->entry_ptr;
-
-	/* Commit route */
-	p->default_route_present = 1;
-
-	/* Free response */
-	app_msg_free(app, rsp);
-
-	return 0;
-}
-
-int
-app_pipeline_routing_delete_default_route(struct app_params *app,
-	uint32_t pipeline_id)
-{
-	struct pipeline_routing *p;
-
-	struct pipeline_routing_arp_delete_default_msg_req *req;
-	struct pipeline_routing_arp_delete_default_msg_rsp *rsp;
-
-	/* Check input arguments */
-	if (app == NULL)
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id, &pipeline_routing);
-	if (p == NULL)
-		return -1;
-
-	/* Allocate and write request */
-	req = app_msg_alloc(app);
-	if (req == NULL)
-		return -1;
-
-	req->type = PIPELINE_MSG_REQ_CUSTOM;
-	req->subtype = PIPELINE_ROUTING_MSG_REQ_ROUTE_DEL_DEFAULT;
-
-	/* Send request and wait for response */
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL)
-		return -1;
-
-	/* Read response and write route */
-	if (rsp->status) {
-		app_msg_free(app, rsp);
-		return -1;
-	}
-
-	/* Commit route */
-	p->default_route_present = 0;
-
-	/* Free response */
-	app_msg_free(app, rsp);
-
-	return 0;
-}
-
-static int
-app_pipeline_routing_arp_ls(struct app_params *app, uint32_t pipeline_id)
-{
-	struct pipeline_routing *p;
-	struct app_pipeline_routing_arp_entry *it;
-
-	p = app_pipeline_data_fe(app, pipeline_id, &pipeline_routing);
-	if (p == NULL)
-		return -EINVAL;
-
-	TAILQ_FOREACH(it, &p->arp_entries, node)
-		print_arp_entry(it);
-
-	if (p->default_arp_entry_present)
-		printf("Default entry: port %" PRIu32 " (entry ptr = %p)\n",
-				p->default_arp_entry_port_id,
-				p->default_arp_entry_ptr);
-	else
-		printf("Default: DROP\n");
-
-	return 0;
-}
-
-int
-app_pipeline_routing_add_arp_entry(struct app_params *app, uint32_t pipeline_id,
-		struct pipeline_routing_arp_key *key,
-		struct ether_addr *macaddr)
-{
-	struct pipeline_routing *p;
-
-	struct pipeline_routing_arp_add_msg_req *req;
-	struct pipeline_routing_arp_add_msg_rsp *rsp;
-
-	struct app_pipeline_routing_arp_entry *entry;
-
-	int new_entry;
-
-	/* Check input arguments */
-	if ((app == NULL) ||
-		(key == NULL) ||
-		(macaddr == NULL))
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id, &pipeline_routing);
-	if (p == NULL)
-		return -1;
-
-	switch (key->type) {
-	case PIPELINE_ROUTING_ARP_IPV4:
-	{
-		uint32_t port_id = key->key.ipv4.port_id;
-
-		/* key */
-		if (port_id >= p->n_ports_out)
-			return -1;
-	}
-	break;
-
-	default:
-		return -1;
-	}
-
-	/* Find existing entry or allocate new */
-	entry = app_pipeline_routing_find_arp_entry(p, key);
-	new_entry = (entry == NULL);
-	if (entry == NULL) {
-		entry = rte_malloc(NULL, sizeof(*entry), RTE_CACHE_LINE_SIZE);
-
-		if (entry == NULL)
-			return -1;
-	}
-
-	/* Message buffer allocation */
-	req = app_msg_alloc(app);
-	if (req == NULL) {
-		if (new_entry)
-			rte_free(entry);
-		return -1;
-	}
-
-	req->type = PIPELINE_MSG_REQ_CUSTOM;
-	req->subtype = PIPELINE_ROUTING_MSG_REQ_ARP_ADD;
-	memcpy(&req->key, key, sizeof(*key));
-	ether_addr_copy(macaddr, &req->macaddr);
-
-	/* Send request and wait for response */
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL) {
-		if (new_entry)
-			rte_free(entry);
-		return -1;
-	}
-
-	/* Read response and write entry */
-	if (rsp->status ||
-		(rsp->entry_ptr == NULL) ||
-		((new_entry == 0) && (rsp->key_found == 0)) ||
-		((new_entry == 1) && (rsp->key_found == 1))) {
-		app_msg_free(app, rsp);
-		if (new_entry)
-			rte_free(entry);
-		return -1;
-	}
-
-	memcpy(&entry->key, key, sizeof(*key));
-	ether_addr_copy(macaddr, &entry->macaddr);
-	entry->entry_ptr = rsp->entry_ptr;
-
-	/* Commit entry */
-	if (new_entry) {
-		TAILQ_INSERT_TAIL(&p->arp_entries, entry, node);
-		p->n_arp_entries++;
-	}
-
-	/* Message buffer free */
-	app_msg_free(app, rsp);
-	return 0;
-}
-
-int
-app_pipeline_routing_delete_arp_entry(struct app_params *app,
-	uint32_t pipeline_id,
-	struct pipeline_routing_arp_key *key)
-{
-	struct pipeline_routing *p;
-
-	struct pipeline_routing_arp_delete_msg_req *req;
-	struct pipeline_routing_arp_delete_msg_rsp *rsp;
-
-	struct app_pipeline_routing_arp_entry *entry;
-
-	/* Check input arguments */
-	if ((app == NULL) ||
-		(key == NULL))
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id, &pipeline_routing);
-	if (p == NULL)
-		return -EINVAL;
-
-	switch (key->type) {
-	case PIPELINE_ROUTING_ARP_IPV4:
-	{
-		uint32_t port_id = key->key.ipv4.port_id;
-
-		/* key */
-		if (port_id >= p->n_ports_out)
-			return -1;
-	}
-	break;
-
-	default:
-		return -1;
-	}
-
-	/* Find rule */
-	entry = app_pipeline_routing_find_arp_entry(p, key);
-	if (entry == NULL)
-		return 0;
-
-	/* Allocate and write request */
-	req = app_msg_alloc(app);
-	if (req == NULL)
-		return -1;
-
-	req->type = PIPELINE_MSG_REQ_CUSTOM;
-	req->subtype = PIPELINE_ROUTING_MSG_REQ_ARP_DEL;
-	memcpy(&req->key, key, sizeof(*key));
-
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL)
-		return -1;
-
-	/* Read response */
-	if (rsp->status || !rsp->key_found) {
-		app_msg_free(app, rsp);
-		return -1;
-	}
-
-	/* Remove entry */
-	TAILQ_REMOVE(&p->arp_entries, entry, node);
-	p->n_arp_entries--;
-	rte_free(entry);
-
-	/* Free response */
-	app_msg_free(app, rsp);
-
-	return 0;
-}
-
-int
-app_pipeline_routing_add_default_arp_entry(struct app_params *app,
-		uint32_t pipeline_id,
-		uint32_t port_id)
-{
-	struct pipeline_routing *p;
-
-	struct pipeline_routing_arp_add_default_msg_req *req;
-	struct pipeline_routing_arp_add_default_msg_rsp *rsp;
-
-	/* Check input arguments */
-	if (app == NULL)
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id, &pipeline_routing);
-	if (p == NULL)
-		return -1;
-
-	if (port_id >= p->n_ports_out)
-		return -1;
-
-	/* Allocate and write request */
-	req = app_msg_alloc(app);
-	if (req == NULL)
-		return -1;
-
-	req->type = PIPELINE_MSG_REQ_CUSTOM;
-	req->subtype = PIPELINE_ROUTING_MSG_REQ_ARP_ADD_DEFAULT;
-	req->port_id = port_id;
-
-	/* Send request and wait for response */
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL)
-		return -1;
-
-	/* Read response and write entry */
-	if (rsp->status || rsp->entry_ptr == NULL) {
-		app_msg_free(app, rsp);
-		return -1;
-	}
-
-	p->default_arp_entry_port_id = port_id;
-	p->default_arp_entry_ptr = rsp->entry_ptr;
-
-	/* Commit entry */
-	p->default_arp_entry_present = 1;
-
-	/* Free response */
-	app_msg_free(app, rsp);
-
-	return 0;
-}
-
-int
-app_pipeline_routing_delete_default_arp_entry(struct app_params *app,
-	uint32_t pipeline_id)
-{
-	struct pipeline_routing *p;
-
-	struct pipeline_routing_arp_delete_default_msg_req *req;
-	struct pipeline_routing_arp_delete_default_msg_rsp *rsp;
-
-	/* Check input arguments */
-	if (app == NULL)
-		return -1;
-
-	p = app_pipeline_data_fe(app, pipeline_id, &pipeline_routing);
-	if (p == NULL)
-		return -EINVAL;
-
-	/* Allocate and write request */
-	req = app_msg_alloc(app);
-	if (req == NULL)
-		return -ENOMEM;
-
-	req->type = PIPELINE_MSG_REQ_CUSTOM;
-	req->subtype = PIPELINE_ROUTING_MSG_REQ_ARP_DEL_DEFAULT;
-
-	/* Send request and wait for response */
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL)
-		return -ETIMEDOUT;
-
-	/* Read response and write entry */
-	if (rsp->status) {
-		app_msg_free(app, rsp);
-		return rsp->status;
-	}
-
-	/* Commit entry */
-	p->default_arp_entry_present = 0;
-
-	/* Free response */
-	app_msg_free(app, rsp);
-
-	return 0;
-}
-
-int
-app_pipeline_routing_set_macaddr(struct app_params *app,
-	uint32_t pipeline_id)
-{
-	struct app_pipeline_params *p;
-	struct pipeline_routing_set_macaddr_msg_req *req;
-	struct pipeline_routing_set_macaddr_msg_rsp *rsp;
-	uint32_t port_id;
-
-	/* Check input arguments */
-	if (app == NULL)
-		return -EINVAL;
-
-	APP_PARAM_FIND_BY_ID(app->pipeline_params, "PIPELINE", pipeline_id, p);
-	if (p == NULL)
-		return -EINVAL;
-
-	/* Allocate and write request */
-	req = app_msg_alloc(app);
-	if (req == NULL)
-		return -ENOMEM;
-
-	req->type = PIPELINE_MSG_REQ_CUSTOM;
-	req->subtype = PIPELINE_ROUTING_MSG_REQ_SET_MACADDR;
-
-	memset(req->macaddr, 0, sizeof(req->macaddr));
-	for (port_id = 0; port_id < p->n_pktq_out; port_id++) {
-		struct app_link_params *link;
-
-		link = app_pipeline_track_pktq_out_to_link(app,
-			pipeline_id,
-			port_id);
-		if (link)
-			req->macaddr[port_id] = link->mac_addr;
-	}
-
-	/* Send request and wait for response */
-	rsp = app_msg_send_recv(app, pipeline_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL)
-		return -ETIMEDOUT;
-
-	/* Read response and write entry */
-	if (rsp->status) {
-		app_msg_free(app, rsp);
-		return rsp->status;
-	}
-
-	/* Free response */
-	app_msg_free(app, rsp);
-
-	return 0;
-}
-
-/*
- * route
- *
- * route add (ARP = ON/OFF, MPLS = ON/OFF, QINQ = ON/OFF):
- *    p <pipelineid> route add <ipaddr> <depth> port <portid> ether <nhmacaddr>
- *    p <pipelineid> route add <ipaddr> <depth> port <portid> ether <nhipaddr>
- *    p <pipelineid> route add <ipaddr> <depth> port <portid> ether <nhmacaddr> qinq <svlan> <cvlan>
- *    p <pipelineid> route add <ipaddr> <depth> port <portid> ether <nhipaddr> qinq <svlan> <cvlan>
- *    p <pipelineid> route add <ipaddr> <depth> port <portid> ether <nhmacaddr> mpls <mpls labels>
- *    p <pipelineid> route add <ipaddr> <depth> port <portid> ether <nhipaddr> mpls <mpls labels>
- *
- * route add default:
- *    p <pipelineid> route add default <portid>
- *
- * route del:
- *    p <pipelineid> route del <ipaddr> <depth>
- *
- * route del default:
- *    p <pipelineid> route del default
- *
- * route ls:
- *    p <pipelineid> route ls
- */
-
-struct cmd_route_result {
-	cmdline_fixed_string_t p_string;
-	uint32_t p;
-	cmdline_fixed_string_t route_string;
-	cmdline_multi_string_t multi_string;
-};
-
-static void
-cmd_route_parsed(
-	void *parsed_result,
-	__rte_unused struct cmdline *cl,
-	void *data)
-{
-	struct cmd_route_result *params = parsed_result;
-	struct app_params *app = data;
-
-	char *tokens[16];
-	uint32_t n_tokens = RTE_DIM(tokens);
-	int status;
-
-	status = parse_tokenize_string(params->multi_string, tokens, &n_tokens);
-	if (status != 0) {
-		printf(CMD_MSG_TOO_MANY_ARGS, "route");
-		return;
-	}
-
-	/* route add */
-	if ((n_tokens >= 2) &&
-		(strcmp(tokens[0], "add") == 0) &&
-		strcmp(tokens[1], "default")) {
-		struct pipeline_routing_route_key key;
-		struct pipeline_routing_route_data route_data;
-		struct in_addr ipv4, nh_ipv4;
-		struct ether_addr mac_addr;
-		uint32_t depth, port_id, svlan, cvlan, i;
-		uint32_t mpls_labels[PIPELINE_ROUTING_MPLS_LABELS_MAX];
-		uint32_t n_labels = RTE_DIM(mpls_labels);
-
-		memset(&key, 0, sizeof(key));
-		memset(&route_data, 0, sizeof(route_data));
-
-		if (n_tokens < 7) {
-			printf(CMD_MSG_NOT_ENOUGH_ARGS, "route add");
-			return;
-		}
-
-		if (parse_ipv4_addr(tokens[1], &ipv4)) {
-			printf(CMD_MSG_INVALID_ARG, "ipaddr");
-			return;
-		}
-
-		if (parser_read_uint32(&depth, tokens[2])) {
-			printf(CMD_MSG_INVALID_ARG, "depth");
-			return;
-		}
-
-		if (strcmp(tokens[3], "port")) {
-			printf(CMD_MSG_ARG_NOT_FOUND, "port");
-			return;
-		}
-
-		if (parser_read_uint32(&port_id, tokens[4])) {
-			printf(CMD_MSG_INVALID_ARG, "portid");
-			return;
-		}
-
-		if (strcmp(tokens[5], "ether")) {
-			printf(CMD_MSG_ARG_NOT_FOUND, "ether");
-			return;
-		}
-
-		if (parse_mac_addr(tokens[6], &mac_addr)) {
-			if (parse_ipv4_addr(tokens[6], &nh_ipv4)) {
-				printf(CMD_MSG_INVALID_ARG, "nhmacaddr or nhipaddr");
-				return;
-			}
-
-			route_data.flags |= PIPELINE_ROUTING_ROUTE_ARP;
-		}
-
-		if (n_tokens > 7) {
-			if (strcmp(tokens[7], "mpls") == 0) {
-				if (n_tokens != 9) {
-					printf(CMD_MSG_MISMATCH_ARGS, "route add mpls");
-					return;
-				}
-
-				if (parse_mpls_labels(tokens[8], mpls_labels, &n_labels)) {
-					printf(CMD_MSG_INVALID_ARG, "mpls labels");
-					return;
-				}
-
-				route_data.flags |= PIPELINE_ROUTING_ROUTE_MPLS;
-			} else if (strcmp(tokens[7], "qinq") == 0) {
-				if (n_tokens != 10) {
-					printf(CMD_MSG_MISMATCH_ARGS, "route add qinq");
-					return;
-				}
-
-				if (parser_read_uint32(&svlan, tokens[8])) {
-					printf(CMD_MSG_INVALID_ARG, "svlan");
-					return;
-				}
-				if (parser_read_uint32(&cvlan, tokens[9])) {
-					printf(CMD_MSG_INVALID_ARG, "cvlan");
-					return;
-				}
-
-				route_data.flags |= PIPELINE_ROUTING_ROUTE_QINQ;
-			} else {
-				printf(CMD_MSG_ARG_NOT_FOUND, "mpls or qinq");
-				return;
-			}
-		}
-
-		switch (route_data.flags) {
-		case 0:
-			route_data.port_id = port_id;
-			route_data.ethernet.macaddr = mac_addr;
-			break;
-
-		case PIPELINE_ROUTING_ROUTE_ARP:
-			route_data.port_id = port_id;
-			route_data.ethernet.ip = rte_be_to_cpu_32(nh_ipv4.s_addr);
-			break;
-
-		case PIPELINE_ROUTING_ROUTE_MPLS:
-			route_data.port_id = port_id;
-			route_data.ethernet.macaddr = mac_addr;
-			for (i = 0; i < n_labels; i++)
-				route_data.l2.mpls.labels[i] = mpls_labels[i];
-			route_data.l2.mpls.n_labels = n_labels;
-			break;
-
-		case PIPELINE_ROUTING_ROUTE_MPLS | PIPELINE_ROUTING_ROUTE_ARP:
-			route_data.port_id = port_id;
-			route_data.ethernet.ip = rte_be_to_cpu_32(nh_ipv4.s_addr);
-			for (i = 0; i < n_labels; i++)
-				route_data.l2.mpls.labels[i] = mpls_labels[i];
-			route_data.l2.mpls.n_labels = n_labels;
-			break;
-
-		case PIPELINE_ROUTING_ROUTE_QINQ:
-			route_data.port_id = port_id;
-			route_data.ethernet.macaddr = mac_addr;
-			route_data.l2.qinq.svlan = svlan;
-			route_data.l2.qinq.cvlan = cvlan;
-			break;
-
-		case PIPELINE_ROUTING_ROUTE_QINQ | PIPELINE_ROUTING_ROUTE_ARP:
-		default:
-			route_data.port_id = port_id;
-			route_data.ethernet.ip = rte_be_to_cpu_32(nh_ipv4.s_addr);
-			route_data.l2.qinq.svlan = svlan;
-			route_data.l2.qinq.cvlan = cvlan;
-			break;
-		}
-
-		key.type = PIPELINE_ROUTING_ROUTE_IPV4;
-		key.key.ipv4.ip = rte_be_to_cpu_32(ipv4.s_addr);
-		key.key.ipv4.depth = depth;
-
-		status = app_pipeline_routing_add_route(app,
-			params->p,
-			&key,
-			&route_data);
-		if (status != 0)
-			printf(CMD_MSG_FAIL, "route add");
-
-		return;
-	} /* route add */
-
-	/* route add default */
-	if ((n_tokens >= 2) &&
-		(strcmp(tokens[0], "add") == 0) &&
-		(strcmp(tokens[1], "default") == 0)) {
-		uint32_t port_id;
-
-		if (n_tokens != 3) {
-			printf(CMD_MSG_MISMATCH_ARGS, "route add default");
-			return;
-		}
-
-		if (parser_read_uint32(&port_id, tokens[2])) {
-			printf(CMD_MSG_INVALID_ARG, "portid");
-			return;
-		}
-
-		status = app_pipeline_routing_add_default_route(app,
-			params->p,
-			port_id);
-		if (status != 0)
-			printf(CMD_MSG_FAIL, "route add default");
-
-		return;
-	} /* route add default */
-
-	/* route del*/
-	if ((n_tokens >= 2) &&
-		(strcmp(tokens[0], "del") == 0) &&
-		strcmp(tokens[1], "default")) {
-		struct pipeline_routing_route_key key;
-		struct in_addr ipv4;
-		uint32_t depth;
-
-		memset(&key, 0, sizeof(key));
-
-		if (n_tokens != 3) {
-			printf(CMD_MSG_MISMATCH_ARGS, "route del");
-			return;
-		}
-
-		if (parse_ipv4_addr(tokens[1], &ipv4)) {
-			printf(CMD_MSG_INVALID_ARG, "ipaddr");
-			return;
-		}
-
-		if (parser_read_uint32(&depth, tokens[2])) {
-			printf(CMD_MSG_INVALID_ARG, "depth");
-			return;
-		}
-
-		key.type = PIPELINE_ROUTING_ROUTE_IPV4;
-		key.key.ipv4.ip = rte_be_to_cpu_32(ipv4.s_addr);
-		key.key.ipv4.depth = depth;
-
-		status = app_pipeline_routing_delete_route(app, params->p, &key);
-		if (status != 0)
-			printf(CMD_MSG_FAIL, "route del");
-
-		return;
-	} /* route del */
-
-	/* route del default */
-	if ((n_tokens >= 2) &&
-		(strcmp(tokens[0], "del") == 0) &&
-		(strcmp(tokens[1], "default") == 0)) {
-		if (n_tokens != 2) {
-			printf(CMD_MSG_MISMATCH_ARGS, "route del default");
-			return;
-		}
-
-		status = app_pipeline_routing_delete_default_route(app,
-			params->p);
-		if (status != 0)
-			printf(CMD_MSG_FAIL, "route del default");
-
-		return;
-	} /* route del default */
-
-	/* route ls */
-	if ((n_tokens >= 1) && (strcmp(tokens[0], "ls") == 0)) {
-		if (n_tokens != 1) {
-			printf(CMD_MSG_MISMATCH_ARGS, "route ls");
-			return;
-		}
-
-		status = app_pipeline_routing_route_ls(app, params->p);
-		if (status != 0)
-			printf(CMD_MSG_FAIL, "route ls");
-
-		return;
-	} /* route ls */
-
-	printf(CMD_MSG_MISMATCH_ARGS, "route");
-}
-
-static cmdline_parse_token_string_t cmd_route_p_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_route_result, p_string, "p");
-
-static cmdline_parse_token_num_t cmd_route_p =
-	TOKEN_NUM_INITIALIZER(struct cmd_route_result, p, UINT32);
-
-static cmdline_parse_token_string_t cmd_route_route_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_route_result, route_string, "route");
-
-static cmdline_parse_token_string_t cmd_route_multi_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_route_result, multi_string,
-	TOKEN_STRING_MULTI);
-
-static cmdline_parse_inst_t cmd_route = {
-	.f = cmd_route_parsed,
-	.data = NULL,
-	.help_str = "route add / add default / del / del default / ls",
-	.tokens = {
-		(void *)&cmd_route_p_string,
-		(void *)&cmd_route_p,
-		(void *)&cmd_route_route_string,
-		(void *)&cmd_route_multi_string,
-		NULL,
-	},
-};
-
-/*
- * arp
- *
- * arp add:
- *    p <pipelineid> arp add <portid> <ipaddr> <macaddr>
- *
- * arp add default:
- *    p <pipelineid> arp add default <portid>
- *
- * arp del:
- *    p <pipelineid> arp del <portid> <ipaddr>
- *
- * arp del default:
- *    p <pipelineid> arp del default
- *
- * arp ls:
- *    p <pipelineid> arp ls
- */
-
-struct cmd_arp_result {
-	cmdline_fixed_string_t p_string;
-	uint32_t p;
-	cmdline_fixed_string_t arp_string;
-	cmdline_multi_string_t multi_string;
-};
-
-static void
-cmd_arp_parsed(
-	void *parsed_result,
-	__rte_unused struct cmdline *cl,
-	void *data)
-{
-	struct cmd_arp_result *params = parsed_result;
-	struct app_params *app = data;
-
-	char *tokens[16];
-	uint32_t n_tokens = RTE_DIM(tokens);
-	int status;
-
-	status = parse_tokenize_string(params->multi_string, tokens, &n_tokens);
-	if (status != 0) {
-		printf(CMD_MSG_TOO_MANY_ARGS, "arp");
-		return;
-	}
-
-	/* arp add */
-	if ((n_tokens >= 2) &&
-		(strcmp(tokens[0], "add") == 0) &&
-		strcmp(tokens[1], "default")) {
-		struct pipeline_routing_arp_key key;
-		struct in_addr ipv4;
-		struct ether_addr mac_addr;
-		uint32_t port_id;
-
-		memset(&key, 0, sizeof(key));
-
-		if (n_tokens != 4) {
-			printf(CMD_MSG_MISMATCH_ARGS, "arp add");
-			return;
-		}
-
-		if (parser_read_uint32(&port_id, tokens[1])) {
-			printf(CMD_MSG_INVALID_ARG, "portid");
-			return;
-		}
-
-		if (parse_ipv4_addr(tokens[2], &ipv4)) {
-			printf(CMD_MSG_INVALID_ARG, "ipaddr");
-			return;
-		}
-
-		if (parse_mac_addr(tokens[3], &mac_addr)) {
-			printf(CMD_MSG_INVALID_ARG, "macaddr");
-			return;
-		}
-
-		key.type = PIPELINE_ROUTING_ARP_IPV4;
-		key.key.ipv4.port_id = port_id;
-		key.key.ipv4.ip = rte_be_to_cpu_32(ipv4.s_addr);
-
-		status = app_pipeline_routing_add_arp_entry(app,
-			params->p,
-			&key,
-			&mac_addr);
-		if (status != 0)
-			printf(CMD_MSG_FAIL, "arp add");
-
-		return;
-	} /* arp add */
-
-	/* arp add default */
-	if ((n_tokens >= 2) &&
-		(strcmp(tokens[0], "add") == 0) &&
-		(strcmp(tokens[1], "default") == 0)) {
-		uint32_t port_id;
-
-		if (n_tokens != 3) {
-			printf(CMD_MSG_MISMATCH_ARGS, "arp add default");
-			return;
-		}
-
-		if (parser_read_uint32(&port_id, tokens[2])) {
-			printf(CMD_MSG_INVALID_ARG, "portid");
-			return;
-		}
-
-		status = app_pipeline_routing_add_default_arp_entry(app,
-			params->p,
-			port_id);
-		if (status != 0)
-			printf(CMD_MSG_FAIL, "arp add default");
-
-		return;
-	} /* arp add default */
-
-	/* arp del*/
-	if ((n_tokens >= 2) &&
-		(strcmp(tokens[0], "del") == 0) &&
-		strcmp(tokens[1], "default")) {
-		struct pipeline_routing_arp_key key;
-		struct in_addr ipv4;
-		uint32_t port_id;
-
-		memset(&key, 0, sizeof(key));
-
-		if (n_tokens != 3) {
-			printf(CMD_MSG_MISMATCH_ARGS, "arp del");
-			return;
-		}
-
-		if (parser_read_uint32(&port_id, tokens[1])) {
-			printf(CMD_MSG_INVALID_ARG, "portid");
-			return;
-		}
-
-		if (parse_ipv4_addr(tokens[2], &ipv4)) {
-			printf(CMD_MSG_INVALID_ARG, "ipaddr");
-			return;
-		}
-
-		key.type = PIPELINE_ROUTING_ARP_IPV4;
-		key.key.ipv4.ip = rte_be_to_cpu_32(ipv4.s_addr);
-		key.key.ipv4.port_id = port_id;
-
-		status = app_pipeline_routing_delete_arp_entry(app,
-			params->p,
-			&key);
-		if (status != 0)
-			printf(CMD_MSG_FAIL, "arp del");
-
-		return;
-	} /* arp del */
-
-	/* arp del default */
-	if ((n_tokens >= 2) &&
-		(strcmp(tokens[0], "del") == 0) &&
-		(strcmp(tokens[1], "default") == 0)) {
-			if (n_tokens != 2) {
-				printf(CMD_MSG_MISMATCH_ARGS, "arp del default");
-				return;
-			}
-
-			status = app_pipeline_routing_delete_default_arp_entry(app,
-				params->p);
-			if (status != 0)
-				printf(CMD_MSG_FAIL, "arp del default");
-
-			return;
-	} /* arp del default */
-
-	/* arp ls */
-	if ((n_tokens >= 1) && (strcmp(tokens[0], "ls") == 0)) {
-		if (n_tokens != 1) {
-			printf(CMD_MSG_MISMATCH_ARGS, "arp ls");
-			return;
-		}
-
-		status = app_pipeline_routing_arp_ls(app, params->p);
-		if (status != 0)
-			printf(CMD_MSG_FAIL, "arp ls");
-
-		return;
-	} /* arp ls */
-
-	printf(CMD_MSG_FAIL, "arp");
-}
-
-static cmdline_parse_token_string_t cmd_arp_p_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_arp_result, p_string, "p");
-
-static cmdline_parse_token_num_t cmd_arp_p =
-	TOKEN_NUM_INITIALIZER(struct cmd_arp_result, p, UINT32);
-
-static cmdline_parse_token_string_t cmd_arp_arp_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_arp_result, arp_string, "arp");
-
-static cmdline_parse_token_string_t cmd_arp_multi_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_arp_result, multi_string,
-	TOKEN_STRING_MULTI);
-
-static cmdline_parse_inst_t cmd_arp = {
-	.f = cmd_arp_parsed,
-	.data = NULL,
-	.help_str = "arp add / add default / del / del default / ls",
-	.tokens = {
-		(void *)&cmd_arp_p_string,
-		(void *)&cmd_arp_p,
-		(void *)&cmd_arp_arp_string,
-		(void *)&cmd_arp_multi_string,
-		NULL,
-	},
-};
-
-static cmdline_parse_ctx_t pipeline_cmds[] = {
-	(cmdline_parse_inst_t *)&cmd_route,
-	(cmdline_parse_inst_t *)&cmd_arp,
-	NULL,
-};
-
-static struct pipeline_fe_ops pipeline_routing_fe_ops = {
-	.f_init = app_pipeline_routing_init,
-	.f_post_init = app_pipeline_routing_post_init,
-	.f_free = app_pipeline_routing_free,
-	.f_track = app_pipeline_track_default,
-	.cmds = pipeline_cmds,
-};
-
-struct pipeline_type pipeline_routing = {
-	.name = "ROUTING",
-	.be_ops = &pipeline_routing_be_ops,
-	.fe_ops = &pipeline_routing_fe_ops,
-};
diff --git a/examples/ip_pipeline/pipeline/pipeline_routing.h b/examples/ip_pipeline/pipeline/pipeline_routing.h
deleted file mode 100644
index f249295..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_routing.h
+++ /dev/null
@@ -1,71 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#ifndef __INCLUDE_PIPELINE_ROUTING_H__
-#define __INCLUDE_PIPELINE_ROUTING_H__
-
-#include "pipeline.h"
-#include "pipeline_routing_be.h"
-
-/*
- * Route
- */
-
-int
-app_pipeline_routing_add_route(struct app_params *app,
-	uint32_t pipeline_id,
-	struct pipeline_routing_route_key *key,
-	struct pipeline_routing_route_data *data);
-
-int
-app_pipeline_routing_delete_route(struct app_params *app,
-	uint32_t pipeline_id,
-	struct pipeline_routing_route_key *key);
-
-int
-app_pipeline_routing_add_default_route(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t port_id);
-
-int
-app_pipeline_routing_delete_default_route(struct app_params *app,
-	uint32_t pipeline_id);
-
-/*
- * ARP
- */
-
-int
-app_pipeline_routing_add_arp_entry(struct app_params *app,
-	uint32_t pipeline_id,
-	struct pipeline_routing_arp_key *key,
-	struct ether_addr *macaddr);
-
-int
-app_pipeline_routing_delete_arp_entry(struct app_params *app,
-	uint32_t pipeline_id,
-	struct pipeline_routing_arp_key *key);
-
-int
-app_pipeline_routing_add_default_arp_entry(struct app_params *app,
-	uint32_t pipeline_id,
-	uint32_t port_id);
-
-int
-app_pipeline_routing_delete_default_arp_entry(struct app_params *app,
-	uint32_t pipeline_id);
-
-/*
- * SETTINGS
- */
-int
-app_pipeline_routing_set_macaddr(struct app_params *app,
-	uint32_t pipeline_id);
-
-/*
- * Pipeline type
- */
-extern struct pipeline_type pipeline_routing;
-
-#endif
diff --git a/examples/ip_pipeline/pipeline/pipeline_routing_be.c b/examples/ip_pipeline/pipeline/pipeline_routing_be.c
deleted file mode 100644
index 6258a1a..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_routing_be.c
+++ /dev/null
@@ -1,1966 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <stdint.h>
-#include <string.h>
-#include <unistd.h>
-
-#include <rte_common.h>
-#include <rte_malloc.h>
-#include <rte_ip.h>
-#include <rte_byteorder.h>
-#include <rte_table_lpm.h>
-#include <rte_table_hash.h>
-#include <rte_pipeline.h>
-
-#include "pipeline_routing_be.h"
-#include "pipeline_actions_common.h"
-#include "parser.h"
-#include "hash_func.h"
-
-#define MPLS_LABEL(label, exp, s, ttl)					\
-	(((((uint64_t) (label)) & 0xFFFFFLLU) << 12) |		\
-	((((uint64_t) (exp)) & 0x7LLU) << 9) |				\
-	((((uint64_t) (s)) & 0x1LLU) << 8) |				\
-	(((uint64_t) (ttl)) & 0xFFLU))
-
-#define RTE_SCHED_PORT_HIERARCHY(subport, pipe,		\
-	traffic_class, queue, color)				\
-	((((uint64_t) (queue)) & 0x3) |                \
-	((((uint64_t) (traffic_class)) & 0x3) << 2) |  \
-	((((uint64_t) (color)) & 0x3) << 4) |          \
-	((((uint64_t) (subport)) & 0xFFFF) << 16) |    \
-	((((uint64_t) (pipe)) & 0xFFFFFFFF) << 32))
-
-
-/* Network Byte Order (NBO) */
-#define SLAB_NBO_MACADDRSRC_ETHERTYPE(macaddr, ethertype)	\
-	(((uint64_t) macaddr) | (((uint64_t) rte_cpu_to_be_16(ethertype)) << 48))
-
-#ifndef PIPELINE_ROUTING_LPM_TABLE_NUMBER_TABLE8s
-#define PIPELINE_ROUTING_LPM_TABLE_NUMBER_TABLE8s 256
-#endif
-
-struct pipeline_routing {
-	struct pipeline p;
-	struct pipeline_routing_params params;
-	pipeline_msg_req_handler custom_handlers[PIPELINE_ROUTING_MSG_REQS];
-	uint64_t macaddr[PIPELINE_MAX_PORT_OUT];
-} __rte_cache_aligned;
-
-/*
- * Message handlers
- */
-static void *
-pipeline_routing_msg_req_custom_handler(struct pipeline *p, void *msg);
-
-static pipeline_msg_req_handler handlers[] = {
-	[PIPELINE_MSG_REQ_PING] =
-		pipeline_msg_req_ping_handler,
-	[PIPELINE_MSG_REQ_STATS_PORT_IN] =
-		pipeline_msg_req_stats_port_in_handler,
-	[PIPELINE_MSG_REQ_STATS_PORT_OUT] =
-		pipeline_msg_req_stats_port_out_handler,
-	[PIPELINE_MSG_REQ_STATS_TABLE] =
-		pipeline_msg_req_stats_table_handler,
-	[PIPELINE_MSG_REQ_PORT_IN_ENABLE] =
-		pipeline_msg_req_port_in_enable_handler,
-	[PIPELINE_MSG_REQ_PORT_IN_DISABLE] =
-		pipeline_msg_req_port_in_disable_handler,
-	[PIPELINE_MSG_REQ_CUSTOM] =
-		pipeline_routing_msg_req_custom_handler,
-};
-
-static void *
-pipeline_routing_msg_req_route_add_handler(struct pipeline *p,
-	void *msg);
-
-static void *
-pipeline_routing_msg_req_route_del_handler(struct pipeline *p,
-	void *msg);
-
-static void *
-pipeline_routing_msg_req_route_add_default_handler(struct pipeline *p,
-	void *msg);
-
-static void *
-pipeline_routing_msg_req_route_del_default_handler(struct pipeline *p,
-	void *msg);
-
-static void *
-pipeline_routing_msg_req_arp_add_handler(struct pipeline *p,
-	void *msg);
-
-static void *
-pipeline_routing_msg_req_arp_del_handler(struct pipeline *p,
-	void *msg);
-
-static void *
-pipeline_routing_msg_req_arp_add_default_handler(struct pipeline *p,
-	void *msg);
-
-static void *
-pipeline_routing_msg_req_arp_del_default_handler(struct pipeline *p,
-	void *msg);
-
-static void *
-pipeline_routing_msg_req_set_macaddr_handler(struct pipeline *p,
-	void *msg);
-
-static pipeline_msg_req_handler custom_handlers[] = {
-	[PIPELINE_ROUTING_MSG_REQ_ROUTE_ADD] =
-		pipeline_routing_msg_req_route_add_handler,
-	[PIPELINE_ROUTING_MSG_REQ_ROUTE_DEL] =
-		pipeline_routing_msg_req_route_del_handler,
-	[PIPELINE_ROUTING_MSG_REQ_ROUTE_ADD_DEFAULT] =
-		pipeline_routing_msg_req_route_add_default_handler,
-	[PIPELINE_ROUTING_MSG_REQ_ROUTE_DEL_DEFAULT] =
-		pipeline_routing_msg_req_route_del_default_handler,
-	[PIPELINE_ROUTING_MSG_REQ_ARP_ADD] =
-		pipeline_routing_msg_req_arp_add_handler,
-	[PIPELINE_ROUTING_MSG_REQ_ARP_DEL] =
-		pipeline_routing_msg_req_arp_del_handler,
-	[PIPELINE_ROUTING_MSG_REQ_ARP_ADD_DEFAULT] =
-		pipeline_routing_msg_req_arp_add_default_handler,
-	[PIPELINE_ROUTING_MSG_REQ_ARP_DEL_DEFAULT] =
-		pipeline_routing_msg_req_arp_del_default_handler,
-	[PIPELINE_ROUTING_MSG_REQ_SET_MACADDR] =
-		pipeline_routing_msg_req_set_macaddr_handler,
-};
-
-/*
- * Routing table
- */
-struct routing_table_entry {
-	struct rte_pipeline_table_entry head;
-	uint32_t flags;
-	uint32_t port_id; /* Output port ID */
-	uint32_t ip; /* Next hop IP address (only valid for remote routes) */
-
-	/* ether_l2 */
-	uint16_t data_offset;
-	uint16_t ether_l2_length;
-	uint64_t slab[4];
-	uint16_t slab_offset[4];
-};
-
-struct layout {
-	uint16_t a;
-	uint32_t b;
-	uint16_t c;
-} __attribute__((__packed__));
-
-#define MACADDR_DST_WRITE(slab_ptr, slab)			\
-{								\
-	struct layout *dst = (struct layout *) (slab_ptr);	\
-	struct layout *src = (struct layout *) &(slab);		\
-								\
-	dst->b = src->b;					\
-	dst->c = src->c;					\
-}
-
-static __rte_always_inline void
-pkt_work_routing(
-	struct rte_mbuf *pkt,
-	struct rte_pipeline_table_entry *table_entry,
-	void *arg,
-	int arp,
-	int qinq,
-	int qinq_sched,
-	int mpls,
-	int mpls_color_mark)
-{
-	struct pipeline_routing *p_rt = arg;
-
-	struct routing_table_entry *entry =
-		(struct routing_table_entry *) table_entry;
-
-	struct ipv4_hdr *ip = (struct ipv4_hdr *)
-		RTE_MBUF_METADATA_UINT8_PTR(pkt, p_rt->params.ip_hdr_offset);
-
-	enum rte_meter_color pkt_color = (enum rte_meter_color)
-		RTE_MBUF_METADATA_UINT32(pkt, p_rt->params.color_offset);
-
-	struct pipeline_routing_arp_key_ipv4 *arp_key =
-		(struct pipeline_routing_arp_key_ipv4 *)
-		RTE_MBUF_METADATA_UINT8_PTR(pkt, p_rt->params.arp_key_offset);
-
-	uint64_t *slab0_ptr, *slab1_ptr, *slab2_ptr, *slab3_ptr, sched;
-	uint32_t ip_da, nh_ip, port_id;
-	uint16_t total_length, data_offset, ether_l2_length;
-
-	/* Read */
-	total_length = rte_bswap16(ip->total_length);
-	ip_da = ip->dst_addr;
-	data_offset = entry->data_offset;
-	ether_l2_length = entry->ether_l2_length;
-	slab0_ptr = RTE_MBUF_METADATA_UINT64_PTR(pkt, entry->slab_offset[0]);
-	slab1_ptr = RTE_MBUF_METADATA_UINT64_PTR(pkt, entry->slab_offset[1]);
-	slab2_ptr = RTE_MBUF_METADATA_UINT64_PTR(pkt, entry->slab_offset[2]);
-	slab3_ptr = RTE_MBUF_METADATA_UINT64_PTR(pkt, entry->slab_offset[3]);
-
-	if (arp) {
-		port_id = entry->port_id;
-		nh_ip = entry->ip;
-		if (entry->flags & PIPELINE_ROUTING_ROUTE_LOCAL)
-			nh_ip = ip_da;
-	}
-
-	/* Compute */
-	total_length += ether_l2_length;
-
-	if (qinq && qinq_sched) {
-		uint32_t dscp = ip->type_of_service >> 2;
-		uint32_t svlan, cvlan, tc, tc_q;
-
-		if (qinq_sched == 1) {
-			uint64_t slab_qinq = rte_bswap64(entry->slab[0]);
-
-			svlan = (slab_qinq >> 48) & 0xFFF;
-			cvlan = (slab_qinq >> 16) & 0xFFF;
-			tc = (dscp >> 2) & 0x3;
-			tc_q = dscp & 0x3;
-		} else {
-			uint32_t ip_src = rte_bswap32(ip->src_addr);
-
-			svlan = 0;
-			cvlan = (ip_src >> 16) & 0xFFF;
-			tc = (ip_src >> 2) & 0x3;
-			tc_q = ip_src & 0x3;
-		}
-		sched = RTE_SCHED_PORT_HIERARCHY(svlan,
-			cvlan,
-			tc,
-			tc_q,
-			e_RTE_METER_GREEN);
-	}
-
-	/* Write */
-	pkt->data_off = data_offset;
-	pkt->data_len = total_length;
-	pkt->pkt_len = total_length;
-
-	if ((qinq == 0) && (mpls == 0)) {
-		*slab0_ptr = entry->slab[0];
-
-		if (arp == 0)
-			MACADDR_DST_WRITE(slab1_ptr, entry->slab[1]);
-	}
-
-	if (qinq) {
-		*slab0_ptr = entry->slab[0];
-		*slab1_ptr = entry->slab[1];
-
-		if (arp == 0)
-			MACADDR_DST_WRITE(slab2_ptr, entry->slab[2]);
-
-		if (qinq_sched) {
-			pkt->hash.sched.lo = sched & 0xFFFFFFFF;
-			pkt->hash.sched.hi = sched >> 32;
-		}
-	}
-
-	if (mpls) {
-		if (mpls_color_mark) {
-			uint64_t mpls_exp = rte_bswap64(
-				(MPLS_LABEL(0, pkt_color, 0, 0) << 32) |
-				MPLS_LABEL(0, pkt_color, 0, 0));
-
-			*slab0_ptr = entry->slab[0] | mpls_exp;
-			*slab1_ptr = entry->slab[1] | mpls_exp;
-			*slab2_ptr = entry->slab[2];
-		} else {
-			*slab0_ptr = entry->slab[0];
-			*slab1_ptr = entry->slab[1];
-			*slab2_ptr = entry->slab[2];
-		}
-
-		if (arp == 0)
-			MACADDR_DST_WRITE(slab3_ptr, entry->slab[3]);
-	}
-
-	if (arp) {
-		arp_key->port_id = port_id;
-		arp_key->ip = nh_ip;
-	}
-}
-
-static __rte_always_inline void
-pkt4_work_routing(
-	struct rte_mbuf **pkts,
-	struct rte_pipeline_table_entry **table_entries,
-	void *arg,
-	int arp,
-	int qinq,
-	int qinq_sched,
-	int mpls,
-	int mpls_color_mark)
-{
-	struct pipeline_routing *p_rt = arg;
-
-	struct routing_table_entry *entry0 =
-		(struct routing_table_entry *) table_entries[0];
-	struct routing_table_entry *entry1 =
-		(struct routing_table_entry *) table_entries[1];
-	struct routing_table_entry *entry2 =
-		(struct routing_table_entry *) table_entries[2];
-	struct routing_table_entry *entry3 =
-		(struct routing_table_entry *) table_entries[3];
-
-	struct ipv4_hdr *ip0 = (struct ipv4_hdr *)
-		RTE_MBUF_METADATA_UINT8_PTR(pkts[0],
-			p_rt->params.ip_hdr_offset);
-	struct ipv4_hdr *ip1 = (struct ipv4_hdr *)
-		RTE_MBUF_METADATA_UINT8_PTR(pkts[1],
-			p_rt->params.ip_hdr_offset);
-	struct ipv4_hdr *ip2 = (struct ipv4_hdr *)
-		RTE_MBUF_METADATA_UINT8_PTR(pkts[2],
-			p_rt->params.ip_hdr_offset);
-	struct ipv4_hdr *ip3 = (struct ipv4_hdr *)
-		RTE_MBUF_METADATA_UINT8_PTR(pkts[3],
-			p_rt->params.ip_hdr_offset);
-
-	enum rte_meter_color pkt0_color = (enum rte_meter_color)
-		RTE_MBUF_METADATA_UINT32(pkts[0], p_rt->params.color_offset);
-	enum rte_meter_color pkt1_color = (enum rte_meter_color)
-		RTE_MBUF_METADATA_UINT32(pkts[1], p_rt->params.color_offset);
-	enum rte_meter_color pkt2_color = (enum rte_meter_color)
-		RTE_MBUF_METADATA_UINT32(pkts[2], p_rt->params.color_offset);
-	enum rte_meter_color pkt3_color = (enum rte_meter_color)
-		RTE_MBUF_METADATA_UINT32(pkts[3], p_rt->params.color_offset);
-
-	struct pipeline_routing_arp_key_ipv4 *arp_key0 =
-		(struct pipeline_routing_arp_key_ipv4 *)
-		RTE_MBUF_METADATA_UINT8_PTR(pkts[0],
-			p_rt->params.arp_key_offset);
-	struct pipeline_routing_arp_key_ipv4 *arp_key1 =
-		(struct pipeline_routing_arp_key_ipv4 *)
-		RTE_MBUF_METADATA_UINT8_PTR(pkts[1],
-			p_rt->params.arp_key_offset);
-	struct pipeline_routing_arp_key_ipv4 *arp_key2 =
-		(struct pipeline_routing_arp_key_ipv4 *)
-		RTE_MBUF_METADATA_UINT8_PTR(pkts[2],
-			p_rt->params.arp_key_offset);
-	struct pipeline_routing_arp_key_ipv4 *arp_key3 =
-		(struct pipeline_routing_arp_key_ipv4 *)
-		RTE_MBUF_METADATA_UINT8_PTR(pkts[3],
-			p_rt->params.arp_key_offset);
-
-	uint64_t *slab0_ptr0, *slab1_ptr0, *slab2_ptr0, *slab3_ptr0;
-	uint64_t *slab0_ptr1, *slab1_ptr1, *slab2_ptr1, *slab3_ptr1;
-	uint64_t *slab0_ptr2, *slab1_ptr2, *slab2_ptr2, *slab3_ptr2;
-	uint64_t *slab0_ptr3, *slab1_ptr3, *slab2_ptr3, *slab3_ptr3;
-	uint64_t sched0, sched1, sched2, sched3;
-
-	uint32_t ip_da0, nh_ip0, port_id0;
-	uint32_t ip_da1, nh_ip1, port_id1;
-	uint32_t ip_da2, nh_ip2, port_id2;
-	uint32_t ip_da3, nh_ip3, port_id3;
-
-	uint16_t total_length0, data_offset0, ether_l2_length0;
-	uint16_t total_length1, data_offset1, ether_l2_length1;
-	uint16_t total_length2, data_offset2, ether_l2_length2;
-	uint16_t total_length3, data_offset3, ether_l2_length3;
-
-	/* Read */
-	total_length0 = rte_bswap16(ip0->total_length);
-	total_length1 = rte_bswap16(ip1->total_length);
-	total_length2 = rte_bswap16(ip2->total_length);
-	total_length3 = rte_bswap16(ip3->total_length);
-
-	ip_da0 = ip0->dst_addr;
-	ip_da1 = ip1->dst_addr;
-	ip_da2 = ip2->dst_addr;
-	ip_da3 = ip3->dst_addr;
-
-	data_offset0 = entry0->data_offset;
-	data_offset1 = entry1->data_offset;
-	data_offset2 = entry2->data_offset;
-	data_offset3 = entry3->data_offset;
-
-	ether_l2_length0 = entry0->ether_l2_length;
-	ether_l2_length1 = entry1->ether_l2_length;
-	ether_l2_length2 = entry2->ether_l2_length;
-	ether_l2_length3 = entry3->ether_l2_length;
-
-	slab0_ptr0 = RTE_MBUF_METADATA_UINT64_PTR(pkts[0],
-		entry0->slab_offset[0]);
-	slab1_ptr0 = RTE_MBUF_METADATA_UINT64_PTR(pkts[0],
-		entry0->slab_offset[1]);
-	slab2_ptr0 = RTE_MBUF_METADATA_UINT64_PTR(pkts[0],
-		entry0->slab_offset[2]);
-	slab3_ptr0 = RTE_MBUF_METADATA_UINT64_PTR(pkts[0],
-		entry0->slab_offset[3]);
-
-	slab0_ptr1 = RTE_MBUF_METADATA_UINT64_PTR(pkts[1],
-		entry1->slab_offset[0]);
-	slab1_ptr1 = RTE_MBUF_METADATA_UINT64_PTR(pkts[1],
-		entry1->slab_offset[1]);
-	slab2_ptr1 = RTE_MBUF_METADATA_UINT64_PTR(pkts[1],
-		entry1->slab_offset[2]);
-	slab3_ptr1 = RTE_MBUF_METADATA_UINT64_PTR(pkts[1],
-		entry1->slab_offset[3]);
-
-	slab0_ptr2 = RTE_MBUF_METADATA_UINT64_PTR(pkts[2],
-		entry2->slab_offset[0]);
-	slab1_ptr2 = RTE_MBUF_METADATA_UINT64_PTR(pkts[2],
-		entry2->slab_offset[1]);
-	slab2_ptr2 = RTE_MBUF_METADATA_UINT64_PTR(pkts[2],
-		entry2->slab_offset[2]);
-	slab3_ptr2 = RTE_MBUF_METADATA_UINT64_PTR(pkts[2],
-		entry2->slab_offset[3]);
-
-	slab0_ptr3 = RTE_MBUF_METADATA_UINT64_PTR(pkts[3],
-		entry3->slab_offset[0]);
-	slab1_ptr3 = RTE_MBUF_METADATA_UINT64_PTR(pkts[3],
-		entry3->slab_offset[1]);
-	slab2_ptr3 = RTE_MBUF_METADATA_UINT64_PTR(pkts[3],
-		entry3->slab_offset[2]);
-	slab3_ptr3 = RTE_MBUF_METADATA_UINT64_PTR(pkts[3],
-		entry3->slab_offset[3]);
-
-	if (arp) {
-		port_id0 = entry0->port_id;
-		nh_ip0 = entry0->ip;
-		if (entry0->flags & PIPELINE_ROUTING_ROUTE_LOCAL)
-			nh_ip0 = ip_da0;
-
-		port_id1 = entry1->port_id;
-		nh_ip1 = entry1->ip;
-		if (entry1->flags & PIPELINE_ROUTING_ROUTE_LOCAL)
-			nh_ip1 = ip_da1;
-
-		port_id2 = entry2->port_id;
-		nh_ip2 = entry2->ip;
-		if (entry2->flags & PIPELINE_ROUTING_ROUTE_LOCAL)
-			nh_ip2 = ip_da2;
-
-		port_id3 = entry3->port_id;
-		nh_ip3 = entry3->ip;
-		if (entry3->flags & PIPELINE_ROUTING_ROUTE_LOCAL)
-			nh_ip3 = ip_da3;
-	}
-
-	/* Compute */
-	total_length0 += ether_l2_length0;
-	total_length1 += ether_l2_length1;
-	total_length2 += ether_l2_length2;
-	total_length3 += ether_l2_length3;
-
-	if (qinq && qinq_sched) {
-		uint32_t dscp0 = ip0->type_of_service >> 2;
-		uint32_t dscp1 = ip1->type_of_service >> 2;
-		uint32_t dscp2 = ip2->type_of_service >> 2;
-		uint32_t dscp3 = ip3->type_of_service >> 2;
-		uint32_t svlan0, cvlan0, tc0, tc_q0;
-		uint32_t svlan1, cvlan1, tc1, tc_q1;
-		uint32_t svlan2, cvlan2, tc2, tc_q2;
-		uint32_t svlan3, cvlan3, tc3, tc_q3;
-
-		if (qinq_sched == 1) {
-			uint64_t slab_qinq0 = rte_bswap64(entry0->slab[0]);
-			uint64_t slab_qinq1 = rte_bswap64(entry1->slab[0]);
-			uint64_t slab_qinq2 = rte_bswap64(entry2->slab[0]);
-			uint64_t slab_qinq3 = rte_bswap64(entry3->slab[0]);
-
-			svlan0 = (slab_qinq0 >> 48) & 0xFFF;
-			svlan1 = (slab_qinq1 >> 48) & 0xFFF;
-			svlan2 = (slab_qinq2 >> 48) & 0xFFF;
-			svlan3 = (slab_qinq3 >> 48) & 0xFFF;
-
-			cvlan0 = (slab_qinq0 >> 16) & 0xFFF;
-			cvlan1 = (slab_qinq1 >> 16) & 0xFFF;
-			cvlan2 = (slab_qinq2 >> 16) & 0xFFF;
-			cvlan3 = (slab_qinq3 >> 16) & 0xFFF;
-
-			tc0 = (dscp0 >> 2) & 0x3;
-			tc1 = (dscp1 >> 2) & 0x3;
-			tc2 = (dscp2 >> 2) & 0x3;
-			tc3 = (dscp3 >> 2) & 0x3;
-
-			tc_q0 = dscp0 & 0x3;
-			tc_q1 = dscp1 & 0x3;
-			tc_q2 = dscp2 & 0x3;
-			tc_q3 = dscp3 & 0x3;
-		} else {
-			uint32_t ip_src0 = rte_bswap32(ip0->src_addr);
-			uint32_t ip_src1 = rte_bswap32(ip1->src_addr);
-			uint32_t ip_src2 = rte_bswap32(ip2->src_addr);
-			uint32_t ip_src3 = rte_bswap32(ip3->src_addr);
-
-			svlan0 = 0;
-			svlan1 = 0;
-			svlan2 = 0;
-			svlan3 = 0;
-
-			cvlan0 = (ip_src0 >> 16) & 0xFFF;
-			cvlan1 = (ip_src1 >> 16) & 0xFFF;
-			cvlan2 = (ip_src2 >> 16) & 0xFFF;
-			cvlan3 = (ip_src3 >> 16) & 0xFFF;
-
-			tc0 = (ip_src0 >> 2) & 0x3;
-			tc1 = (ip_src1 >> 2) & 0x3;
-			tc2 = (ip_src2 >> 2) & 0x3;
-			tc3 = (ip_src3 >> 2) & 0x3;
-
-			tc_q0 = ip_src0 & 0x3;
-			tc_q1 = ip_src1 & 0x3;
-			tc_q2 = ip_src2 & 0x3;
-			tc_q3 = ip_src3 & 0x3;
-		}
-
-		sched0 = RTE_SCHED_PORT_HIERARCHY(svlan0,
-			cvlan0,
-			tc0,
-			tc_q0,
-			e_RTE_METER_GREEN);
-		sched1 = RTE_SCHED_PORT_HIERARCHY(svlan1,
-			cvlan1,
-			tc1,
-			tc_q1,
-			e_RTE_METER_GREEN);
-		sched2 = RTE_SCHED_PORT_HIERARCHY(svlan2,
-			cvlan2,
-			tc2,
-			tc_q2,
-			e_RTE_METER_GREEN);
-		sched3 = RTE_SCHED_PORT_HIERARCHY(svlan3,
-			cvlan3,
-			tc3,
-			tc_q3,
-			e_RTE_METER_GREEN);
-
-	}
-
-	/* Write */
-	pkts[0]->data_off = data_offset0;
-	pkts[1]->data_off = data_offset1;
-	pkts[2]->data_off = data_offset2;
-	pkts[3]->data_off = data_offset3;
-
-	pkts[0]->data_len = total_length0;
-	pkts[1]->data_len = total_length1;
-	pkts[2]->data_len = total_length2;
-	pkts[3]->data_len = total_length3;
-
-	pkts[0]->pkt_len = total_length0;
-	pkts[1]->pkt_len = total_length1;
-	pkts[2]->pkt_len = total_length2;
-	pkts[3]->pkt_len = total_length3;
-
-	if ((qinq == 0) && (mpls == 0)) {
-		*slab0_ptr0 = entry0->slab[0];
-		*slab0_ptr1 = entry1->slab[0];
-		*slab0_ptr2 = entry2->slab[0];
-		*slab0_ptr3 = entry3->slab[0];
-
-		if (arp == 0) {
-			MACADDR_DST_WRITE(slab1_ptr0, entry0->slab[1]);
-			MACADDR_DST_WRITE(slab1_ptr1, entry1->slab[1]);
-			MACADDR_DST_WRITE(slab1_ptr2, entry2->slab[1]);
-			MACADDR_DST_WRITE(slab1_ptr3, entry3->slab[1]);
-		}
-	}
-
-	if (qinq) {
-		*slab0_ptr0 = entry0->slab[0];
-		*slab0_ptr1 = entry1->slab[0];
-		*slab0_ptr2 = entry2->slab[0];
-		*slab0_ptr3 = entry3->slab[0];
-
-		*slab1_ptr0 = entry0->slab[1];
-		*slab1_ptr1 = entry1->slab[1];
-		*slab1_ptr2 = entry2->slab[1];
-		*slab1_ptr3 = entry3->slab[1];
-
-		if (arp == 0) {
-			MACADDR_DST_WRITE(slab2_ptr0, entry0->slab[2]);
-			MACADDR_DST_WRITE(slab2_ptr1, entry1->slab[2]);
-			MACADDR_DST_WRITE(slab2_ptr2, entry2->slab[2]);
-			MACADDR_DST_WRITE(slab2_ptr3, entry3->slab[2]);
-		}
-
-		if (qinq_sched) {
-			pkts[0]->hash.sched.lo = sched0 & 0xFFFFFFFF;
-			pkts[0]->hash.sched.hi = sched0 >> 32;
-			pkts[1]->hash.sched.lo = sched1 & 0xFFFFFFFF;
-			pkts[1]->hash.sched.hi = sched1 >> 32;
-			pkts[2]->hash.sched.lo = sched2 & 0xFFFFFFFF;
-			pkts[2]->hash.sched.hi = sched2 >> 32;
-			pkts[3]->hash.sched.lo = sched3 & 0xFFFFFFFF;
-			pkts[3]->hash.sched.hi = sched3 >> 32;
-		}
-	}
-
-	if (mpls) {
-		if (mpls_color_mark) {
-			uint64_t mpls_exp0 = rte_bswap64(
-				(MPLS_LABEL(0, pkt0_color, 0, 0) << 32) |
-				MPLS_LABEL(0, pkt0_color, 0, 0));
-			uint64_t mpls_exp1 = rte_bswap64(
-				(MPLS_LABEL(0, pkt1_color, 0, 0) << 32) |
-				MPLS_LABEL(0, pkt1_color, 0, 0));
-			uint64_t mpls_exp2 = rte_bswap64(
-				(MPLS_LABEL(0, pkt2_color, 0, 0) << 32) |
-				MPLS_LABEL(0, pkt2_color, 0, 0));
-			uint64_t mpls_exp3 = rte_bswap64(
-				(MPLS_LABEL(0, pkt3_color, 0, 0) << 32) |
-				MPLS_LABEL(0, pkt3_color, 0, 0));
-
-			*slab0_ptr0 = entry0->slab[0] | mpls_exp0;
-			*slab0_ptr1 = entry1->slab[0] | mpls_exp1;
-			*slab0_ptr2 = entry2->slab[0] | mpls_exp2;
-			*slab0_ptr3 = entry3->slab[0] | mpls_exp3;
-
-			*slab1_ptr0 = entry0->slab[1] | mpls_exp0;
-			*slab1_ptr1 = entry1->slab[1] | mpls_exp1;
-			*slab1_ptr2 = entry2->slab[1] | mpls_exp2;
-			*slab1_ptr3 = entry3->slab[1] | mpls_exp3;
-
-			*slab2_ptr0 = entry0->slab[2];
-			*slab2_ptr1 = entry1->slab[2];
-			*slab2_ptr2 = entry2->slab[2];
-			*slab2_ptr3 = entry3->slab[2];
-		} else {
-			*slab0_ptr0 = entry0->slab[0];
-			*slab0_ptr1 = entry1->slab[0];
-			*slab0_ptr2 = entry2->slab[0];
-			*slab0_ptr3 = entry3->slab[0];
-
-			*slab1_ptr0 = entry0->slab[1];
-			*slab1_ptr1 = entry1->slab[1];
-			*slab1_ptr2 = entry2->slab[1];
-			*slab1_ptr3 = entry3->slab[1];
-
-			*slab2_ptr0 = entry0->slab[2];
-			*slab2_ptr1 = entry1->slab[2];
-			*slab2_ptr2 = entry2->slab[2];
-			*slab2_ptr3 = entry3->slab[2];
-		}
-
-		if (arp == 0) {
-			MACADDR_DST_WRITE(slab3_ptr0, entry0->slab[3]);
-			MACADDR_DST_WRITE(slab3_ptr1, entry1->slab[3]);
-			MACADDR_DST_WRITE(slab3_ptr2, entry2->slab[3]);
-			MACADDR_DST_WRITE(slab3_ptr3, entry3->slab[3]);
-		}
-	}
-
-	if (arp) {
-		arp_key0->port_id = port_id0;
-		arp_key1->port_id = port_id1;
-		arp_key2->port_id = port_id2;
-		arp_key3->port_id = port_id3;
-
-		arp_key0->ip = nh_ip0;
-		arp_key1->ip = nh_ip1;
-		arp_key2->ip = nh_ip2;
-		arp_key3->ip = nh_ip3;
-	}
-}
-
-#define PKT_WORK_ROUTING_ETHERNET(arp)				\
-static inline void						\
-pkt_work_routing_ether_arp##arp(				\
-	struct rte_mbuf *pkt,					\
-	struct rte_pipeline_table_entry *table_entry,		\
-	void *arg)						\
-{								\
-	pkt_work_routing(pkt, table_entry, arg, arp, 0, 0, 0, 0);\
-}
-
-#define PKT4_WORK_ROUTING_ETHERNET(arp)				\
-static inline void						\
-pkt4_work_routing_ether_arp##arp(				\
-	struct rte_mbuf **pkts,					\
-	struct rte_pipeline_table_entry **table_entries,	\
-	void *arg)						\
-{								\
-	pkt4_work_routing(pkts, table_entries, arg, arp, 0, 0, 0, 0);\
-}
-
-#define routing_table_ah_hit_ether(arp)				\
-PKT_WORK_ROUTING_ETHERNET(arp)					\
-PKT4_WORK_ROUTING_ETHERNET(arp)					\
-PIPELINE_TABLE_AH_HIT(routing_table_ah_hit_ether_arp##arp,	\
-	pkt_work_routing_ether_arp##arp,			\
-	pkt4_work_routing_ether_arp##arp)
-
-routing_table_ah_hit_ether(0)
-routing_table_ah_hit_ether(1)
-
-#define PKT_WORK_ROUTING_ETHERNET_QINQ(sched, arp)		\
-static inline void						\
-pkt_work_routing_ether_qinq_sched##sched##_arp##arp(		\
-	struct rte_mbuf *pkt,					\
-	struct rte_pipeline_table_entry *table_entry,		\
-	void *arg)						\
-{								\
-	pkt_work_routing(pkt, table_entry, arg, arp, 1, sched, 0, 0);\
-}
-
-#define PKT4_WORK_ROUTING_ETHERNET_QINQ(sched, arp)		\
-static inline void						\
-pkt4_work_routing_ether_qinq_sched##sched##_arp##arp(		\
-	struct rte_mbuf **pkts,					\
-	struct rte_pipeline_table_entry **table_entries,	\
-	void *arg)						\
-{								\
-	pkt4_work_routing(pkts, table_entries, arg, arp, 1, sched, 0, 0);\
-}
-
-#define routing_table_ah_hit_ether_qinq(sched, arp)		\
-PKT_WORK_ROUTING_ETHERNET_QINQ(sched, arp)			\
-PKT4_WORK_ROUTING_ETHERNET_QINQ(sched, arp)			\
-PIPELINE_TABLE_AH_HIT(routing_table_ah_hit_ether_qinq_sched##sched##_arp##arp,\
-	pkt_work_routing_ether_qinq_sched##sched##_arp##arp,	\
-	pkt4_work_routing_ether_qinq_sched##sched##_arp##arp)
-
-routing_table_ah_hit_ether_qinq(0, 0)
-routing_table_ah_hit_ether_qinq(1, 0)
-routing_table_ah_hit_ether_qinq(2, 0)
-routing_table_ah_hit_ether_qinq(0, 1)
-routing_table_ah_hit_ether_qinq(1, 1)
-routing_table_ah_hit_ether_qinq(2, 1)
-
-#define PKT_WORK_ROUTING_ETHERNET_MPLS(color, arp)		\
-static inline void						\
-pkt_work_routing_ether_mpls_color##color##_arp##arp(		\
-	struct rte_mbuf *pkt,					\
-	struct rte_pipeline_table_entry *table_entry,		\
-	void *arg)						\
-{								\
-	pkt_work_routing(pkt, table_entry, arg, arp, 0, 0, 1, color);\
-}
-
-#define PKT4_WORK_ROUTING_ETHERNET_MPLS(color, arp)		\
-static inline void						\
-pkt4_work_routing_ether_mpls_color##color##_arp##arp(		\
-	struct rte_mbuf **pkts,					\
-	struct rte_pipeline_table_entry **table_entries,	\
-	void *arg)						\
-{								\
-	pkt4_work_routing(pkts, table_entries, arg, arp, 0, 0, 1, color);\
-}
-
-#define routing_table_ah_hit_ether_mpls(color, arp)		\
-PKT_WORK_ROUTING_ETHERNET_MPLS(color, arp)			\
-PKT4_WORK_ROUTING_ETHERNET_MPLS(color, arp)			\
-PIPELINE_TABLE_AH_HIT(routing_table_ah_hit_ether_mpls_color##color##_arp##arp,\
-	pkt_work_routing_ether_mpls_color##color##_arp##arp,	\
-	pkt4_work_routing_ether_mpls_color##color##_arp##arp)
-
-routing_table_ah_hit_ether_mpls(0, 0)
-routing_table_ah_hit_ether_mpls(1, 0)
-routing_table_ah_hit_ether_mpls(0, 1)
-routing_table_ah_hit_ether_mpls(1, 1)
-
-static rte_pipeline_table_action_handler_hit
-get_routing_table_ah_hit(struct pipeline_routing *p)
-{
-	if (p->params.dbg_ah_disable)
-		return NULL;
-
-	switch (p->params.encap) {
-	case PIPELINE_ROUTING_ENCAP_ETHERNET:
-		return (p->params.n_arp_entries) ?
-			routing_table_ah_hit_ether_arp1 :
-			routing_table_ah_hit_ether_arp0;
-
-	case PIPELINE_ROUTING_ENCAP_ETHERNET_QINQ:
-		if (p->params.n_arp_entries)
-			switch (p->params.qinq_sched) {
-			case 0:
-				return routing_table_ah_hit_ether_qinq_sched0_arp1;
-			case 1:
-				return routing_table_ah_hit_ether_qinq_sched1_arp1;
-			case 2:
-				return routing_table_ah_hit_ether_qinq_sched2_arp1;
-			default:
-				return NULL;
-			}
-		 else
-			switch (p->params.qinq_sched) {
-			case 0:
-				return routing_table_ah_hit_ether_qinq_sched0_arp0;
-			case 1:
-				return routing_table_ah_hit_ether_qinq_sched1_arp0;
-			case 2:
-				return routing_table_ah_hit_ether_qinq_sched2_arp0;
-			default:
-				return NULL;
-			}
-
-	case PIPELINE_ROUTING_ENCAP_ETHERNET_MPLS:
-		if (p->params.n_arp_entries)
-			if (p->params.mpls_color_mark)
-				return routing_table_ah_hit_ether_mpls_color1_arp1;
-			else
-				return routing_table_ah_hit_ether_mpls_color0_arp1;
-		else
-			if (p->params.mpls_color_mark)
-				return routing_table_ah_hit_ether_mpls_color1_arp0;
-			else
-				return routing_table_ah_hit_ether_mpls_color0_arp0;
-
-	default:
-		return NULL;
-	}
-}
-
-/*
- * ARP table
- */
-struct arp_table_entry {
-	struct rte_pipeline_table_entry head;
-	uint64_t macaddr;
-};
-
-/**
- * ARP table AH
- */
-static inline void
-pkt_work_arp(
-	struct rte_mbuf *pkt,
-	struct rte_pipeline_table_entry *table_entry,
-	__rte_unused void *arg)
-{
-	struct arp_table_entry *entry = (struct arp_table_entry *) table_entry;
-
-	/* Read */
-	uint64_t macaddr_dst = entry->macaddr;
-	uint64_t *slab_ptr = (uint64_t *) ((char *) pkt->buf_addr +
-		(pkt->data_off - 2));
-
-	/* Compute */
-
-	/* Write */
-	MACADDR_DST_WRITE(slab_ptr, macaddr_dst);
-}
-
-static inline void
-pkt4_work_arp(
-	struct rte_mbuf **pkts,
-	struct rte_pipeline_table_entry **table_entries,
-	__rte_unused void *arg)
-{
-	struct arp_table_entry *entry0 =
-		(struct arp_table_entry *) table_entries[0];
-	struct arp_table_entry *entry1 =
-		(struct arp_table_entry *) table_entries[1];
-	struct arp_table_entry *entry2 =
-		(struct arp_table_entry *) table_entries[2];
-	struct arp_table_entry *entry3 =
-		(struct arp_table_entry *) table_entries[3];
-
-	/* Read */
-	uint64_t macaddr_dst0 = entry0->macaddr;
-	uint64_t macaddr_dst1 = entry1->macaddr;
-	uint64_t macaddr_dst2 = entry2->macaddr;
-	uint64_t macaddr_dst3 = entry3->macaddr;
-
-	uint64_t *slab_ptr0 = (uint64_t *) ((char *) pkts[0]->buf_addr +
-		(pkts[0]->data_off - 2));
-	uint64_t *slab_ptr1 = (uint64_t *) ((char *) pkts[1]->buf_addr +
-		(pkts[1]->data_off - 2));
-	uint64_t *slab_ptr2 = (uint64_t *) ((char *) pkts[2]->buf_addr +
-		(pkts[2]->data_off - 2));
-	uint64_t *slab_ptr3 = (uint64_t *) ((char *) pkts[3]->buf_addr +
-		(pkts[3]->data_off - 2));
-
-	/* Compute */
-
-	/* Write */
-	MACADDR_DST_WRITE(slab_ptr0, macaddr_dst0);
-	MACADDR_DST_WRITE(slab_ptr1, macaddr_dst1);
-	MACADDR_DST_WRITE(slab_ptr2, macaddr_dst2);
-	MACADDR_DST_WRITE(slab_ptr3, macaddr_dst3);
-}
-
-PIPELINE_TABLE_AH_HIT(arp_table_ah_hit,
-	pkt_work_arp,
-	pkt4_work_arp);
-
-static rte_pipeline_table_action_handler_hit
-get_arp_table_ah_hit(struct pipeline_routing *p)
-{
-	if (p->params.dbg_ah_disable)
-		return NULL;
-
-	return arp_table_ah_hit;
-}
-
-/*
- * Argument parsing
- */
-int
-pipeline_routing_parse_args(struct pipeline_routing_params *p,
-	struct pipeline_params *params)
-{
-	uint32_t n_routes_present = 0;
-	uint32_t port_local_dest_present = 0;
-	uint32_t encap_present = 0;
-	uint32_t qinq_sched_present = 0;
-	uint32_t mpls_color_mark_present = 0;
-	uint32_t n_arp_entries_present = 0;
-	uint32_t ip_hdr_offset_present = 0;
-	uint32_t arp_key_offset_present = 0;
-	uint32_t color_offset_present = 0;
-	uint32_t dbg_ah_disable_present = 0;
-	uint32_t i;
-
-	/* default values */
-	p->n_routes = PIPELINE_ROUTING_N_ROUTES_DEFAULT;
-	p->port_local_dest = params->n_ports_out - 1;
-	p->encap = PIPELINE_ROUTING_ENCAP_ETHERNET;
-	p->qinq_sched = 0;
-	p->mpls_color_mark = 0;
-	p->n_arp_entries = 0;
-	p->dbg_ah_disable = 0;
-
-	for (i = 0; i < params->n_args; i++) {
-		char *arg_name = params->args_name[i];
-		char *arg_value = params->args_value[i];
-
-		/* n_routes */
-		if (strcmp(arg_name, "n_routes") == 0) {
-			int status;
-
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				n_routes_present == 0, params->name,
-				arg_name);
-			n_routes_present = 1;
-
-			status = parser_read_uint32(&p->n_routes,
-				arg_value);
-			PIPELINE_PARSE_ERR_INV_VAL(((status != -EINVAL) &&
-				(p->n_routes != 0)), params->name,
-				arg_name, arg_value);
-			PIPELINE_PARSE_ERR_OUT_RNG((status != -ERANGE),
-				params->name, arg_name, arg_value);
-
-			continue;
-		}
-		/* port_local_dest */
-		if (strcmp(arg_name, "port_local_dest") == 0) {
-			int status;
-
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				port_local_dest_present == 0, params->name,
-				arg_name);
-			port_local_dest_present = 1;
-
-			status = parser_read_uint32(&p->port_local_dest,
-				arg_value);
-			PIPELINE_PARSE_ERR_INV_VAL(((status == 0) &&
-				(p->port_local_dest < params->n_ports_out)),
-				params->name, arg_name, arg_value);
-
-			continue;
-		}
-
-		/* encap */
-		if (strcmp(arg_name, "encap") == 0) {
-			PIPELINE_PARSE_ERR_DUPLICATE(encap_present == 0,
-				params->name, arg_name);
-			encap_present = 1;
-
-			/* ethernet */
-			if (strcmp(arg_value, "ethernet") == 0) {
-				p->encap = PIPELINE_ROUTING_ENCAP_ETHERNET;
-				continue;
-			}
-
-			/* ethernet_qinq */
-			if (strcmp(arg_value, "ethernet_qinq") == 0) {
-				p->encap = PIPELINE_ROUTING_ENCAP_ETHERNET_QINQ;
-				continue;
-			}
-
-			/* ethernet_mpls */
-			if (strcmp(arg_value, "ethernet_mpls") == 0) {
-				p->encap = PIPELINE_ROUTING_ENCAP_ETHERNET_MPLS;
-				continue;
-			}
-
-			/* any other */
-			PIPELINE_PARSE_ERR_INV_VAL(0, params->name,
-				arg_name, arg_value);
-		}
-
-		/* qinq_sched */
-		if (strcmp(arg_name, "qinq_sched") == 0) {
-			int status;
-
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				qinq_sched_present == 0, params->name,
-				arg_name);
-			qinq_sched_present = 1;
-
-			status = parser_read_arg_bool(arg_value);
-			if (status == -EINVAL) {
-				if (strcmp(arg_value, "test") == 0) {
-					p->qinq_sched = 2;
-					continue;
-				}
-			} else {
-				p->qinq_sched = status;
-				continue;
-			}
-
-			PIPELINE_PARSE_ERR_INV_VAL(0, params->name,
-				arg_name, arg_value);
-		}
-
-		/* mpls_color_mark */
-		if (strcmp(arg_name, "mpls_color_mark") == 0) {
-			int status;
-
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				mpls_color_mark_present == 0,
-				params->name, arg_name);
-			mpls_color_mark_present = 1;
-
-
-			status = parser_read_arg_bool(arg_value);
-			if (status >= 0) {
-				p->mpls_color_mark = status;
-				continue;
-			}
-
-			PIPELINE_PARSE_ERR_INV_VAL(0, params->name,
-				arg_name, arg_value);
-		}
-
-		/* n_arp_entries */
-		if (strcmp(arg_name, "n_arp_entries") == 0) {
-			int status;
-
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				n_arp_entries_present == 0, params->name,
-				arg_name);
-			n_arp_entries_present = 1;
-
-			status = parser_read_uint32(&p->n_arp_entries,
-				arg_value);
-			PIPELINE_PARSE_ERR_INV_VAL((status != -EINVAL),
-				params->name, arg_name, arg_value);
-			PIPELINE_PARSE_ERR_OUT_RNG((status != -ERANGE),
-				params->name, arg_name, arg_value);
-
-			continue;
-		}
-
-		/* ip_hdr_offset */
-		if (strcmp(arg_name, "ip_hdr_offset") == 0) {
-			int status;
-
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				ip_hdr_offset_present == 0, params->name,
-				arg_name);
-			ip_hdr_offset_present = 1;
-
-			status = parser_read_uint32(&p->ip_hdr_offset,
-				arg_value);
-			PIPELINE_PARSE_ERR_INV_VAL((status != -EINVAL),
-				params->name, arg_name, arg_value);
-			PIPELINE_PARSE_ERR_OUT_RNG((status != -ERANGE),
-				params->name, arg_name, arg_value);
-
-			continue;
-		}
-
-		/* arp_key_offset */
-		if (strcmp(arg_name, "arp_key_offset") == 0) {
-			int status;
-
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				arp_key_offset_present == 0, params->name,
-				arg_name);
-			arp_key_offset_present = 1;
-
-			status = parser_read_uint32(&p->arp_key_offset,
-				arg_value);
-			PIPELINE_PARSE_ERR_INV_VAL((status != -EINVAL),
-				params->name, arg_name, arg_value);
-			PIPELINE_PARSE_ERR_OUT_RNG((status != -ERANGE),
-				params->name, arg_name, arg_value);
-
-			continue;
-		}
-
-		/* color_offset */
-		if (strcmp(arg_name, "color_offset") == 0) {
-			int status;
-
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				color_offset_present == 0, params->name,
-				arg_name);
-			color_offset_present = 1;
-
-			status = parser_read_uint32(&p->color_offset,
-				arg_value);
-			PIPELINE_PARSE_ERR_INV_VAL((status != -EINVAL),
-				params->name, arg_name, arg_value);
-			PIPELINE_PARSE_ERR_OUT_RNG((status != -ERANGE),
-				params->name, arg_name, arg_value);
-
-			continue;
-		}
-
-		/* debug */
-		if (strcmp(arg_name, "dbg_ah_disable") == 0) {
-			int status;
-
-			PIPELINE_PARSE_ERR_DUPLICATE(
-				dbg_ah_disable_present == 0, params->name,
-				arg_name);
-			dbg_ah_disable_present = 1;
-
-			status = parser_read_arg_bool(arg_value);
-			if (status >= 0) {
-				p->dbg_ah_disable = status;
-				continue;
-			}
-
-			PIPELINE_PARSE_ERR_INV_VAL(0, params->name,
-				arg_name, arg_value);
-
-			continue;
-		}
-
-		/* any other */
-		PIPELINE_PARSE_ERR_INV_ENT(0, params->name, arg_name);
-	}
-
-	/* Check that mandatory arguments are present */
-	PIPELINE_PARSE_ERR_MANDATORY(ip_hdr_offset_present, params->name,
-		"ip_hdr_offset");
-
-	/* Check relations between arguments */
-	switch (p->encap) {
-	case PIPELINE_ROUTING_ENCAP_ETHERNET:
-		PIPELINE_ARG_CHECK((!p->qinq_sched), "Parse error in "
-			"section \"%s\": encap = ethernet, therefore "
-			"qinq_sched = yes/test is not allowed",
-			params->name);
-		PIPELINE_ARG_CHECK((!p->mpls_color_mark), "Parse error "
-			"in section \"%s\": encap = ethernet, therefore "
-			"mpls_color_mark = yes is not allowed",
-			params->name);
-		PIPELINE_ARG_CHECK((!color_offset_present), "Parse error "
-			"in section \"%s\": encap = ethernet, therefore "
-			"color_offset is not allowed",
-			params->name);
-		break;
-
-	case PIPELINE_ROUTING_ENCAP_ETHERNET_QINQ:
-		PIPELINE_ARG_CHECK((!p->mpls_color_mark), "Parse error "
-			"in section \"%s\": encap = ethernet_qinq, "
-			"therefore mpls_color_mark = yes is not allowed",
-			params->name);
-		PIPELINE_ARG_CHECK((!color_offset_present), "Parse error "
-			"in section \"%s\": encap = ethernet_qinq, "
-			"therefore color_offset is not allowed",
-			params->name);
-		break;
-
-	case PIPELINE_ROUTING_ENCAP_ETHERNET_MPLS:
-		PIPELINE_ARG_CHECK((!p->qinq_sched), "Parse error in "
-			"section \"%s\": encap = ethernet_mpls, therefore "
-			"qinq_sched  = yes/test is not allowed",
-			params->name);
-		break;
-	}
-
-	PIPELINE_ARG_CHECK((!(p->n_arp_entries &&
-		(!arp_key_offset_present))), "Parse error in section "
-			"\"%s\": n_arp_entries is set while "
-			"arp_key_offset is not set", params->name);
-
-	PIPELINE_ARG_CHECK((!((p->n_arp_entries == 0) &&
-		arp_key_offset_present)), "Parse error in section "
-			"\"%s\": arp_key_offset present while "
-			"n_arp_entries is not set", params->name);
-
-	return 0;
-}
-
-static void *
-pipeline_routing_init(struct pipeline_params *params,
-	__rte_unused void *arg)
-{
-	struct pipeline *p;
-	struct pipeline_routing *p_rt;
-	uint32_t size, i;
-
-	/* Check input arguments */
-	if ((params == NULL) ||
-		(params->n_ports_in == 0) ||
-		(params->n_ports_out == 0))
-		return NULL;
-
-	/* Memory allocation */
-	size = RTE_CACHE_LINE_ROUNDUP(sizeof(struct pipeline_routing));
-	p = rte_zmalloc(NULL, size, RTE_CACHE_LINE_SIZE);
-	p_rt = (struct pipeline_routing *) p;
-	if (p == NULL)
-		return NULL;
-
-	strcpy(p->name, params->name);
-	p->log_level = params->log_level;
-
-	PLOG(p, HIGH, "Routing");
-
-	/* Parse arguments */
-	if (pipeline_routing_parse_args(&p_rt->params, params))
-		return NULL;
-
-	/* Pipeline */
-	{
-		struct rte_pipeline_params pipeline_params = {
-			.name = params->name,
-			.socket_id = params->socket_id,
-			.offset_port_id = 0,
-		};
-
-		p->p = rte_pipeline_create(&pipeline_params);
-		if (p->p == NULL) {
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Input ports */
-	p->n_ports_in = params->n_ports_in;
-	for (i = 0; i < p->n_ports_in; i++) {
-		struct rte_pipeline_port_in_params port_params = {
-			.ops = pipeline_port_in_params_get_ops(
-				&params->port_in[i]),
-			.arg_create = pipeline_port_in_params_convert(
-				&params->port_in[i]),
-			.f_action = NULL,
-			.arg_ah = NULL,
-			.burst_size = params->port_in[i].burst_size,
-		};
-
-		int status = rte_pipeline_port_in_create(p->p,
-			&port_params,
-			&p->port_in_id[i]);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Output ports */
-	p->n_ports_out = params->n_ports_out;
-	for (i = 0; i < p->n_ports_out; i++) {
-		struct rte_pipeline_port_out_params port_params = {
-			.ops = pipeline_port_out_params_get_ops(
-				&params->port_out[i]),
-			.arg_create = pipeline_port_out_params_convert(
-				&params->port_out[i]),
-			.f_action = NULL,
-			.arg_ah = NULL,
-		};
-
-		int status = rte_pipeline_port_out_create(p->p,
-			&port_params,
-			&p->port_out_id[i]);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Routing table */
-	p->n_tables = 1;
-	{
-		struct rte_table_lpm_params table_lpm_params = {
-			.name = p->name,
-			.n_rules = p_rt->params.n_routes,
-			.number_tbl8s = PIPELINE_ROUTING_LPM_TABLE_NUMBER_TABLE8s,
-			.flags = 0,
-			.entry_unique_size = sizeof(struct routing_table_entry),
-			.offset = p_rt->params.ip_hdr_offset +
-				__builtin_offsetof(struct ipv4_hdr, dst_addr),
-		};
-
-		struct rte_pipeline_table_params table_params = {
-				.ops = &rte_table_lpm_ops,
-				.arg_create = &table_lpm_params,
-				.f_action_hit = get_routing_table_ah_hit(p_rt),
-				.f_action_miss = NULL,
-				.arg_ah = p_rt,
-				.action_data_size =
-					sizeof(struct routing_table_entry) -
-					sizeof(struct rte_pipeline_table_entry),
-			};
-
-		int status;
-
-		status = rte_pipeline_table_create(p->p,
-			&table_params,
-			&p->table_id[0]);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* ARP table configuration */
-	if (p_rt->params.n_arp_entries) {
-		struct rte_table_hash_params table_arp_params = {
-			.name = p->name,
-			.key_size = 8,
-			.key_offset = p_rt->params.arp_key_offset,
-			.key_mask = NULL,
-			.n_keys = p_rt->params.n_arp_entries,
-			.n_buckets =
-				rte_align32pow2(p_rt->params.n_arp_entries / 4),
-			.f_hash = hash_default_key8,
-			.seed = 0,
-		};
-
-		struct rte_pipeline_table_params table_params = {
-			.ops = &rte_table_hash_key8_ext_ops,
-			.arg_create = &table_arp_params,
-			.f_action_hit = get_arp_table_ah_hit(p_rt),
-			.f_action_miss = NULL,
-			.arg_ah = p_rt,
-			.action_data_size = sizeof(struct arp_table_entry) -
-				sizeof(struct rte_pipeline_table_entry),
-		};
-
-		int status;
-
-		status = rte_pipeline_table_create(p->p,
-			&table_params,
-			&p->table_id[1]);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-
-		p->n_tables++;
-	}
-
-	/* Connecting input ports to tables */
-	for (i = 0; i < p->n_ports_in; i++) {
-		int status = rte_pipeline_port_in_connect_to_table(p->p,
-			p->port_in_id[i],
-			p->table_id[0]);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Enable input ports */
-	for (i = 0; i < p->n_ports_in; i++) {
-		int status = rte_pipeline_port_in_enable(p->p,
-			p->port_in_id[i]);
-
-		if (status) {
-			rte_pipeline_free(p->p);
-			rte_free(p);
-			return NULL;
-		}
-	}
-
-	/* Check pipeline consistency */
-	if (rte_pipeline_check(p->p) < 0) {
-		rte_pipeline_free(p->p);
-		rte_free(p);
-		return NULL;
-	}
-
-	/* Message queues */
-	p->n_msgq = params->n_msgq;
-	for (i = 0; i < p->n_msgq; i++)
-		p->msgq_in[i] = params->msgq_in[i];
-	for (i = 0; i < p->n_msgq; i++)
-		p->msgq_out[i] = params->msgq_out[i];
-
-	/* Message handlers */
-	memcpy(p->handlers, handlers, sizeof(p->handlers));
-	memcpy(p_rt->custom_handlers,
-		custom_handlers,
-		sizeof(p_rt->custom_handlers));
-
-	return p;
-}
-
-static int
-pipeline_routing_free(void *pipeline)
-{
-	struct pipeline *p = (struct pipeline *) pipeline;
-
-	/* Check input arguments */
-	if (p == NULL)
-		return -1;
-
-	/* Free resources */
-	rte_pipeline_free(p->p);
-	rte_free(p);
-	return 0;
-}
-
-static int
-pipeline_routing_timer(void *pipeline)
-{
-	struct pipeline *p = (struct pipeline *) pipeline;
-
-	pipeline_msg_req_handle(p);
-	rte_pipeline_flush(p->p);
-
-	return 0;
-}
-
-void *
-pipeline_routing_msg_req_custom_handler(struct pipeline *p,
-	void *msg)
-{
-	struct pipeline_routing *p_rt = (struct pipeline_routing *) p;
-	struct pipeline_custom_msg_req *req = msg;
-	pipeline_msg_req_handler f_handle;
-
-	f_handle = (req->subtype < PIPELINE_ROUTING_MSG_REQS) ?
-		p_rt->custom_handlers[req->subtype] :
-		pipeline_msg_req_invalid_handler;
-
-	if (f_handle == NULL)
-		f_handle = pipeline_msg_req_invalid_handler;
-
-	return f_handle(p, req);
-}
-
-void *
-pipeline_routing_msg_req_route_add_handler(struct pipeline *p, void *msg)
-{
-	struct pipeline_routing *p_rt = (struct pipeline_routing *) p;
-	struct pipeline_routing_route_add_msg_req *req = msg;
-	struct pipeline_routing_route_add_msg_rsp *rsp = msg;
-
-	struct rte_table_lpm_key key = {
-		.ip = req->key.key.ipv4.ip,
-		.depth = req->key.key.ipv4.depth,
-	};
-
-	struct routing_table_entry entry_arp0 = {
-		.head = {
-			.action = RTE_PIPELINE_ACTION_PORT,
-			{.port_id = p->port_out_id[req->data.port_id]},
-		},
-
-		.flags = req->data.flags,
-		.port_id = req->data.port_id,
-		.ip = 0,
-		.data_offset = 0,
-		.ether_l2_length = 0,
-		.slab = {0},
-		.slab_offset = {0},
-	};
-
-	struct routing_table_entry entry_arp1 = {
-		.head = {
-			.action = RTE_PIPELINE_ACTION_TABLE,
-			{.table_id = p->table_id[1]},
-		},
-
-		.flags = req->data.flags,
-		.port_id = req->data.port_id,
-		.ip = rte_bswap32(req->data.ethernet.ip),
-		.data_offset = 0,
-		.ether_l2_length = 0,
-		.slab = {0},
-		.slab_offset = {0},
-	};
-
-	struct rte_pipeline_table_entry *entry = (p_rt->params.n_arp_entries) ?
-		(struct rte_pipeline_table_entry *) &entry_arp1 :
-		(struct rte_pipeline_table_entry *) &entry_arp0;
-
-	if ((req->key.type != PIPELINE_ROUTING_ROUTE_IPV4) ||
-		((p_rt->params.n_arp_entries == 0) &&
-			(req->data.flags & PIPELINE_ROUTING_ROUTE_ARP)) ||
-		(p_rt->params.n_arp_entries &&
-			((req->data.flags & PIPELINE_ROUTING_ROUTE_ARP) == 0)) ||
-		((p_rt->params.encap != PIPELINE_ROUTING_ENCAP_ETHERNET_QINQ) &&
-			(req->data.flags & PIPELINE_ROUTING_ROUTE_QINQ)) ||
-		((p_rt->params.encap == PIPELINE_ROUTING_ENCAP_ETHERNET_QINQ) &&
-			((req->data.flags & PIPELINE_ROUTING_ROUTE_QINQ) == 0)) ||
-		((p_rt->params.encap != PIPELINE_ROUTING_ENCAP_ETHERNET_MPLS) &&
-			(req->data.flags & PIPELINE_ROUTING_ROUTE_MPLS)) ||
-		((p_rt->params.encap == PIPELINE_ROUTING_ENCAP_ETHERNET_MPLS) &&
-			((req->data.flags & PIPELINE_ROUTING_ROUTE_MPLS) == 0))) {
-		rsp->status = -1;
-		return rsp;
-	}
-
-	/* Ether - ARP off */
-	if ((p_rt->params.encap == PIPELINE_ROUTING_ENCAP_ETHERNET) &&
-		(p_rt->params.n_arp_entries == 0)) {
-		uint64_t macaddr_src = p_rt->macaddr[req->data.port_id];
-		uint64_t macaddr_dst;
-		uint64_t ethertype = ETHER_TYPE_IPv4;
-
-		macaddr_dst = *((uint64_t *)&(req->data.ethernet.macaddr));
-		macaddr_dst = rte_bswap64(macaddr_dst << 16);
-
-		entry_arp0.slab[0] =
-			SLAB_NBO_MACADDRSRC_ETHERTYPE(macaddr_src, ethertype);
-		entry_arp0.slab_offset[0] = p_rt->params.ip_hdr_offset - 8;
-
-		entry_arp0.slab[1] = rte_bswap64(macaddr_dst);
-		entry_arp0.slab_offset[1] = p_rt->params.ip_hdr_offset - 2 * 8;
-
-		entry_arp0.data_offset = entry_arp0.slab_offset[1] + 2
-			- sizeof(struct rte_mbuf);
-		entry_arp0.ether_l2_length = 14;
-	}
-
-	/* Ether - ARP on */
-	if ((p_rt->params.encap == PIPELINE_ROUTING_ENCAP_ETHERNET) &&
-		p_rt->params.n_arp_entries) {
-		uint64_t macaddr_src = p_rt->macaddr[req->data.port_id];
-		uint64_t ethertype = ETHER_TYPE_IPv4;
-
-		entry_arp1.slab[0] =
-			SLAB_NBO_MACADDRSRC_ETHERTYPE(macaddr_src, ethertype);
-		entry_arp1.slab_offset[0] = p_rt->params.ip_hdr_offset - 8;
-
-		entry_arp1.data_offset = entry_arp1.slab_offset[0] - 6
-			- sizeof(struct rte_mbuf);
-		entry_arp1.ether_l2_length = 14;
-	}
-
-	/* Ether QinQ - ARP off */
-	if ((p_rt->params.encap == PIPELINE_ROUTING_ENCAP_ETHERNET_QINQ) &&
-		(p_rt->params.n_arp_entries == 0)) {
-		uint64_t macaddr_src = p_rt->macaddr[req->data.port_id];
-		uint64_t macaddr_dst;
-		uint64_t ethertype_ipv4 = ETHER_TYPE_IPv4;
-		uint64_t ethertype_vlan = 0x8100;
-		uint64_t ethertype_qinq = 0x9100;
-		uint64_t svlan = req->data.l2.qinq.svlan;
-		uint64_t cvlan = req->data.l2.qinq.cvlan;
-
-		macaddr_dst = *((uint64_t *)&(req->data.ethernet.macaddr));
-		macaddr_dst = rte_bswap64(macaddr_dst << 16);
-
-		entry_arp0.slab[0] = rte_bswap64((svlan << 48) |
-			(ethertype_vlan << 32) |
-			(cvlan << 16) |
-			ethertype_ipv4);
-		entry_arp0.slab_offset[0] = p_rt->params.ip_hdr_offset - 8;
-
-		entry_arp0.slab[1] =
-			SLAB_NBO_MACADDRSRC_ETHERTYPE(macaddr_src, ethertype_qinq);
-		entry_arp0.slab_offset[1] = p_rt->params.ip_hdr_offset - 2 * 8;
-
-		entry_arp0.slab[2] = rte_bswap64(macaddr_dst);
-		entry_arp0.slab_offset[2] = p_rt->params.ip_hdr_offset - 3 * 8;
-
-		entry_arp0.data_offset = entry_arp0.slab_offset[2] + 2
-			- sizeof(struct rte_mbuf);
-		entry_arp0.ether_l2_length = 22;
-	}
-
-	/* Ether QinQ - ARP on */
-	if ((p_rt->params.encap == PIPELINE_ROUTING_ENCAP_ETHERNET_QINQ) &&
-		p_rt->params.n_arp_entries) {
-		uint64_t macaddr_src = p_rt->macaddr[req->data.port_id];
-		uint64_t ethertype_ipv4 = ETHER_TYPE_IPv4;
-		uint64_t ethertype_vlan = 0x8100;
-		uint64_t ethertype_qinq = 0x9100;
-		uint64_t svlan = req->data.l2.qinq.svlan;
-		uint64_t cvlan = req->data.l2.qinq.cvlan;
-
-		entry_arp1.slab[0] = rte_bswap64((svlan << 48) |
-			(ethertype_vlan << 32) |
-			(cvlan << 16) |
-			ethertype_ipv4);
-		entry_arp1.slab_offset[0] = p_rt->params.ip_hdr_offset - 8;
-
-		entry_arp1.slab[1] =
-			SLAB_NBO_MACADDRSRC_ETHERTYPE(macaddr_src, ethertype_qinq);
-		entry_arp1.slab_offset[1] = p_rt->params.ip_hdr_offset - 2 * 8;
-
-		entry_arp1.data_offset = entry_arp1.slab_offset[1] - 6
-			- sizeof(struct rte_mbuf);
-		entry_arp1.ether_l2_length = 22;
-	}
-
-	/* Ether MPLS - ARP off */
-	if ((p_rt->params.encap == PIPELINE_ROUTING_ENCAP_ETHERNET_MPLS) &&
-		(p_rt->params.n_arp_entries == 0)) {
-		uint64_t macaddr_src = p_rt->macaddr[req->data.port_id];
-		uint64_t macaddr_dst;
-		uint64_t ethertype_mpls = 0x8847;
-
-		uint64_t label0 = req->data.l2.mpls.labels[0];
-		uint64_t label1 = req->data.l2.mpls.labels[1];
-		uint64_t label2 = req->data.l2.mpls.labels[2];
-		uint64_t label3 = req->data.l2.mpls.labels[3];
-		uint32_t n_labels = req->data.l2.mpls.n_labels;
-
-		macaddr_dst = *((uint64_t *)&(req->data.ethernet.macaddr));
-		macaddr_dst = rte_bswap64(macaddr_dst << 16);
-
-		switch (n_labels) {
-		case 1:
-			entry_arp0.slab[0] = 0;
-			entry_arp0.slab_offset[0] =
-				p_rt->params.ip_hdr_offset - 8;
-
-			entry_arp0.slab[1] = rte_bswap64(
-				MPLS_LABEL(label0, 0, 1, 0));
-			entry_arp0.slab_offset[1] =
-				p_rt->params.ip_hdr_offset - 8;
-			break;
-
-		case 2:
-			entry_arp0.slab[0] = 0;
-			entry_arp0.slab_offset[0] =
-				p_rt->params.ip_hdr_offset - 8;
-
-			entry_arp0.slab[1] = rte_bswap64(
-				(MPLS_LABEL(label0, 0, 0, 0) << 32) |
-				MPLS_LABEL(label1, 0, 1, 0));
-			entry_arp0.slab_offset[1] =
-				p_rt->params.ip_hdr_offset - 8;
-			break;
-
-		case 3:
-			entry_arp0.slab[0] = rte_bswap64(
-				(MPLS_LABEL(label1, 0, 0, 0) << 32) |
-				MPLS_LABEL(label2, 0, 1, 0));
-			entry_arp0.slab_offset[0] =
-				p_rt->params.ip_hdr_offset - 8;
-
-			entry_arp0.slab[1] = rte_bswap64(
-				MPLS_LABEL(label0, 0, 0, 0));
-			entry_arp0.slab_offset[1] =
-				p_rt->params.ip_hdr_offset - 2 * 8;
-			break;
-
-		case 4:
-			entry_arp0.slab[0] = rte_bswap64(
-				(MPLS_LABEL(label2, 0, 0, 0) << 32) |
-				MPLS_LABEL(label3, 0, 1, 0));
-			entry_arp0.slab_offset[0] =
-				p_rt->params.ip_hdr_offset - 8;
-
-			entry_arp0.slab[1] = rte_bswap64(
-				(MPLS_LABEL(label0, 0, 0, 0) << 32) |
-				MPLS_LABEL(label1, 0, 0, 0));
-			entry_arp0.slab_offset[1] =
-				p_rt->params.ip_hdr_offset - 2 * 8;
-			break;
-
-		default:
-			rsp->status = -1;
-			return rsp;
-		}
-
-		entry_arp0.slab[2] =
-			SLAB_NBO_MACADDRSRC_ETHERTYPE(macaddr_src, ethertype_mpls);
-		entry_arp0.slab_offset[2] = p_rt->params.ip_hdr_offset -
-			(n_labels * 4 + 8);
-
-		entry_arp0.slab[3] = rte_bswap64(macaddr_dst);
-		entry_arp0.slab_offset[3] = p_rt->params.ip_hdr_offset -
-			(n_labels * 4 + 2 * 8);
-
-		entry_arp0.data_offset = entry_arp0.slab_offset[3] + 2
-			- sizeof(struct rte_mbuf);
-		entry_arp0.ether_l2_length = n_labels * 4 + 14;
-	}
-
-	/* Ether MPLS - ARP on */
-	if ((p_rt->params.encap == PIPELINE_ROUTING_ENCAP_ETHERNET_MPLS) &&
-		p_rt->params.n_arp_entries) {
-		uint64_t macaddr_src = p_rt->macaddr[req->data.port_id];
-		uint64_t ethertype_mpls = 0x8847;
-
-		uint64_t label0 = req->data.l2.mpls.labels[0];
-		uint64_t label1 = req->data.l2.mpls.labels[1];
-		uint64_t label2 = req->data.l2.mpls.labels[2];
-		uint64_t label3 = req->data.l2.mpls.labels[3];
-		uint32_t n_labels = req->data.l2.mpls.n_labels;
-
-		switch (n_labels) {
-		case 1:
-			entry_arp1.slab[0] = 0;
-			entry_arp1.slab_offset[0] =
-				p_rt->params.ip_hdr_offset - 8;
-
-			entry_arp1.slab[1] = rte_bswap64(
-				MPLS_LABEL(label0, 0, 1, 0));
-			entry_arp1.slab_offset[1] =
-				p_rt->params.ip_hdr_offset - 8;
-			break;
-
-		case 2:
-			entry_arp1.slab[0] = 0;
-			entry_arp1.slab_offset[0] =
-				p_rt->params.ip_hdr_offset - 8;
-
-			entry_arp1.slab[1] = rte_bswap64(
-				(MPLS_LABEL(label0, 0, 0, 0) << 32) |
-				MPLS_LABEL(label1, 0, 1, 0));
-			entry_arp1.slab_offset[1] =
-				p_rt->params.ip_hdr_offset - 8;
-			break;
-
-		case 3:
-			entry_arp1.slab[0] = rte_bswap64(
-				(MPLS_LABEL(label1, 0, 0, 0) << 32) |
-				MPLS_LABEL(label2, 0, 1, 0));
-			entry_arp1.slab_offset[0] =
-				p_rt->params.ip_hdr_offset - 8;
-
-			entry_arp1.slab[1] = rte_bswap64(
-				MPLS_LABEL(label0, 0, 0, 0));
-			entry_arp1.slab_offset[1] =
-				p_rt->params.ip_hdr_offset - 2 * 8;
-			break;
-
-		case 4:
-			entry_arp1.slab[0] = rte_bswap64(
-				(MPLS_LABEL(label2, 0, 0, 0) << 32) |
-				MPLS_LABEL(label3, 0, 1, 0));
-			entry_arp1.slab_offset[0] =
-				p_rt->params.ip_hdr_offset - 8;
-
-			entry_arp1.slab[1] = rte_bswap64(
-				(MPLS_LABEL(label0, 0, 0, 0) << 32) |
-				MPLS_LABEL(label1, 0, 0, 0));
-			entry_arp1.slab_offset[1] =
-				p_rt->params.ip_hdr_offset - 2 * 8;
-			break;
-
-		default:
-			rsp->status = -1;
-			return rsp;
-		}
-
-		entry_arp1.slab[2] =
-			SLAB_NBO_MACADDRSRC_ETHERTYPE(macaddr_src, ethertype_mpls);
-		entry_arp1.slab_offset[2] = p_rt->params.ip_hdr_offset -
-			(n_labels * 4 + 8);
-
-		entry_arp1.data_offset = entry_arp1.slab_offset[2] - 6
-			- sizeof(struct rte_mbuf);
-		entry_arp1.ether_l2_length = n_labels * 4 + 14;
-	}
-
-	rsp->status = rte_pipeline_table_entry_add(p->p,
-		p->table_id[0],
-		&key,
-		entry,
-		&rsp->key_found,
-		(struct rte_pipeline_table_entry **) &rsp->entry_ptr);
-
-	return rsp;
-}
-
-void *
-pipeline_routing_msg_req_route_del_handler(struct pipeline *p, void *msg)
-{
-	struct pipeline_routing_route_delete_msg_req *req = msg;
-	struct pipeline_routing_route_delete_msg_rsp *rsp = msg;
-
-	struct rte_table_lpm_key key = {
-		.ip = req->key.key.ipv4.ip,
-		.depth = req->key.key.ipv4.depth,
-	};
-
-	if (req->key.type != PIPELINE_ROUTING_ROUTE_IPV4) {
-		rsp->status = -1;
-		return rsp;
-	}
-
-	rsp->status = rte_pipeline_table_entry_delete(p->p,
-		p->table_id[0],
-		&key,
-		&rsp->key_found,
-		NULL);
-
-	return rsp;
-}
-
-void *
-pipeline_routing_msg_req_route_add_default_handler(struct pipeline *p,
-	void *msg)
-{
-	struct pipeline_routing_route_add_default_msg_req *req = msg;
-	struct pipeline_routing_route_add_default_msg_rsp *rsp = msg;
-
-	struct routing_table_entry default_entry = {
-		.head = {
-			.action = RTE_PIPELINE_ACTION_PORT,
-			{.port_id = p->port_out_id[req->port_id]},
-		},
-
-		.flags = 0,
-		.port_id = 0,
-		.ip = 0,
-	};
-
-	rsp->status = rte_pipeline_table_default_entry_add(p->p,
-		p->table_id[0],
-		(struct rte_pipeline_table_entry *) &default_entry,
-		(struct rte_pipeline_table_entry **) &rsp->entry_ptr);
-
-	return rsp;
-}
-
-void *
-pipeline_routing_msg_req_route_del_default_handler(struct pipeline *p,
-	void *msg)
-{
-	struct pipeline_routing_route_delete_default_msg_rsp *rsp = msg;
-
-	rsp->status = rte_pipeline_table_default_entry_delete(p->p,
-		p->table_id[0],
-		NULL);
-
-	return rsp;
-}
-
-void *
-pipeline_routing_msg_req_arp_add_handler(struct pipeline *p, void *msg)
-{
-	struct pipeline_routing_arp_add_msg_req *req = msg;
-	struct pipeline_routing_arp_add_msg_rsp *rsp = msg;
-
-	struct pipeline_routing_arp_key_ipv4 key = {
-		.port_id = req->key.key.ipv4.port_id,
-		.ip = rte_bswap32(req->key.key.ipv4.ip),
-	};
-
-	struct arp_table_entry entry = {
-		.head = {
-			.action = RTE_PIPELINE_ACTION_PORT,
-			{.port_id = p->port_out_id[req->key.key.ipv4.port_id]},
-		},
-
-		.macaddr = 0, /* set below */
-	};
-
-	if (req->key.type != PIPELINE_ROUTING_ARP_IPV4) {
-		rsp->status = -1;
-		return rsp;
-	}
-
-	entry.macaddr = *((uint64_t *)&(req->macaddr));
-	entry.macaddr = entry.macaddr << 16;
-
-	rsp->status = rte_pipeline_table_entry_add(p->p,
-		p->table_id[1],
-		&key,
-		(struct rte_pipeline_table_entry *) &entry,
-		&rsp->key_found,
-		(struct rte_pipeline_table_entry **) &rsp->entry_ptr);
-
-	return rsp;
-}
-
-void *
-pipeline_routing_msg_req_arp_del_handler(struct pipeline *p, void *msg)
-{
-	struct pipeline_routing_arp_delete_msg_req *req = msg;
-	struct pipeline_routing_arp_delete_msg_rsp *rsp = msg;
-
-	struct pipeline_routing_arp_key_ipv4 key = {
-		.port_id = req->key.key.ipv4.port_id,
-		.ip = rte_bswap32(req->key.key.ipv4.ip),
-	};
-
-	if (req->key.type != PIPELINE_ROUTING_ARP_IPV4) {
-		rsp->status = -1;
-		return rsp;
-	}
-
-	rsp->status = rte_pipeline_table_entry_delete(p->p,
-		p->table_id[1],
-		&key,
-		&rsp->key_found,
-		NULL);
-
-	return rsp;
-}
-
-void *
-pipeline_routing_msg_req_arp_add_default_handler(struct pipeline *p, void *msg)
-{
-	struct pipeline_routing_arp_add_default_msg_req *req = msg;
-	struct pipeline_routing_arp_add_default_msg_rsp *rsp = msg;
-
-	struct arp_table_entry default_entry = {
-		.head = {
-			.action = RTE_PIPELINE_ACTION_PORT,
-			{.port_id = p->port_out_id[req->port_id]},
-		},
-
-		.macaddr = 0,
-	};
-
-	rsp->status = rte_pipeline_table_default_entry_add(p->p,
-		p->table_id[1],
-		(struct rte_pipeline_table_entry *) &default_entry,
-		(struct rte_pipeline_table_entry **) &rsp->entry_ptr);
-
-	return rsp;
-}
-
-void *
-pipeline_routing_msg_req_arp_del_default_handler(struct pipeline *p, void *msg)
-{
-	struct pipeline_routing_arp_delete_default_msg_rsp *rsp = msg;
-
-	rsp->status = rte_pipeline_table_default_entry_delete(p->p,
-		p->table_id[1],
-		NULL);
-
-	return rsp;
-}
-
-void *
-pipeline_routing_msg_req_set_macaddr_handler(struct pipeline *p, void *msg)
-{
-	struct pipeline_routing *p_rt = (struct pipeline_routing *) p;
-	struct pipeline_routing_set_macaddr_msg_req *req = msg;
-	struct pipeline_routing_set_macaddr_msg_rsp *rsp = msg;
-	uint32_t port_id;
-
-	for (port_id = 0; port_id < p->n_ports_out; port_id++)
-		p_rt->macaddr[port_id] = req->macaddr[port_id];
-
-	rsp->status = 0;
-
-	return rsp;
-}
-
-struct pipeline_be_ops pipeline_routing_be_ops = {
-	.f_init = pipeline_routing_init,
-	.f_free = pipeline_routing_free,
-	.f_run = NULL,
-	.f_timer = pipeline_routing_timer,
-};
diff --git a/examples/ip_pipeline/pipeline/pipeline_routing_be.h b/examples/ip_pipeline/pipeline/pipeline_routing_be.h
deleted file mode 100644
index 7140ee4..0000000
--- a/examples/ip_pipeline/pipeline/pipeline_routing_be.h
+++ /dev/null
@@ -1,283 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#ifndef __INCLUDE_PIPELINE_ROUTING_BE_H__
-#define __INCLUDE_PIPELINE_ROUTING_BE_H__
-
-#include <rte_ether.h>
-
-#include "pipeline_common_be.h"
-
-/*
- * Pipeline argument parsing
- */
-#ifndef PIPELINE_ROUTING_N_ROUTES_DEFAULT
-#define PIPELINE_ROUTING_N_ROUTES_DEFAULT                  4096
-#endif
-
-enum pipeline_routing_encap {
-	PIPELINE_ROUTING_ENCAP_ETHERNET = 0,
-	PIPELINE_ROUTING_ENCAP_ETHERNET_QINQ,
-	PIPELINE_ROUTING_ENCAP_ETHERNET_MPLS,
-};
-
-struct pipeline_routing_params {
-	/* routing */
-	uint32_t n_routes;
-	uint32_t port_local_dest;
-
-	/* routing packet encapsulation */
-	enum pipeline_routing_encap encap;
-	uint32_t qinq_sched;
-	uint32_t mpls_color_mark;
-
-	/* arp */
-	uint32_t n_arp_entries;
-
-	/* packet buffer offsets */
-	uint32_t ip_hdr_offset;
-	uint32_t arp_key_offset;
-	uint32_t color_offset;
-
-	/* debug */
-	uint32_t dbg_ah_disable;
-};
-
-int
-pipeline_routing_parse_args(struct pipeline_routing_params *p,
-	struct pipeline_params *params);
-
-/*
- * Route
- */
-enum pipeline_routing_route_key_type {
-	PIPELINE_ROUTING_ROUTE_IPV4,
-};
-
-struct pipeline_routing_route_key_ipv4 {
-	uint32_t ip;
-	uint32_t depth;
-};
-
-struct pipeline_routing_route_key {
-	enum pipeline_routing_route_key_type type;
-	union {
-		struct pipeline_routing_route_key_ipv4 ipv4;
-	} key;
-};
-
-enum pipeline_routing_route_flags {
-	PIPELINE_ROUTING_ROUTE_LOCAL = 1 << 0, /* 0 = remote; 1 = local */
-	PIPELINE_ROUTING_ROUTE_ARP = 1 << 1, /* 0 = ARP OFF; 1 = ARP ON */
-	PIPELINE_ROUTING_ROUTE_QINQ = 1 << 2, /* 0 = QINQ OFF; 1 = QINQ ON */
-	PIPELINE_ROUTING_ROUTE_MPLS = 1 << 3, /* 0 = MPLS OFF; 1 = MPLS ON */
-};
-
-#define PIPELINE_ROUTING_MPLS_LABELS_MAX         4
-
-struct pipeline_routing_route_data {
-	uint32_t flags;
-	uint32_t port_id; /* Output port ID */
-
-	union {
-		/* Next hop IP (valid only when ARP is enabled) */
-		uint32_t ip;
-
-		/* Next hop MAC address (valid only when ARP disabled */
-		struct ether_addr macaddr;
-	} ethernet;
-
-	union {
-		struct {
-			uint16_t svlan;
-			uint16_t cvlan;
-		} qinq;
-
-		struct {
-			uint32_t labels[PIPELINE_ROUTING_MPLS_LABELS_MAX];
-			uint32_t n_labels;
-		} mpls;
-	} l2;
-};
-
-/*
- * ARP
- */
-enum pipeline_routing_arp_key_type {
-	PIPELINE_ROUTING_ARP_IPV4,
-};
-
-struct pipeline_routing_arp_key_ipv4 {
-	uint32_t port_id;
-	uint32_t ip;
-};
-
-struct pipeline_routing_arp_key {
-	enum pipeline_routing_arp_key_type type;
-	union {
-		struct pipeline_routing_arp_key_ipv4 ipv4;
-	} key;
-};
-
-/*
- * Messages
- */
-enum pipeline_routing_msg_req_type {
-	PIPELINE_ROUTING_MSG_REQ_ROUTE_ADD,
-	PIPELINE_ROUTING_MSG_REQ_ROUTE_DEL,
-	PIPELINE_ROUTING_MSG_REQ_ROUTE_ADD_DEFAULT,
-	PIPELINE_ROUTING_MSG_REQ_ROUTE_DEL_DEFAULT,
-	PIPELINE_ROUTING_MSG_REQ_ARP_ADD,
-	PIPELINE_ROUTING_MSG_REQ_ARP_DEL,
-	PIPELINE_ROUTING_MSG_REQ_ARP_ADD_DEFAULT,
-	PIPELINE_ROUTING_MSG_REQ_ARP_DEL_DEFAULT,
-	PIPELINE_ROUTING_MSG_REQ_SET_MACADDR,
-	PIPELINE_ROUTING_MSG_REQS
-};
-
-/*
- * MSG ROUTE ADD
- */
-struct pipeline_routing_route_add_msg_req {
-	enum pipeline_msg_req_type type;
-	enum pipeline_routing_msg_req_type subtype;
-
-	/* key */
-	struct pipeline_routing_route_key key;
-
-	/* data */
-	struct pipeline_routing_route_data data;
-};
-
-struct pipeline_routing_route_add_msg_rsp {
-	int status;
-	int key_found;
-	void *entry_ptr;
-};
-
-/*
- * MSG ROUTE DELETE
- */
-struct pipeline_routing_route_delete_msg_req {
-	enum pipeline_msg_req_type type;
-	enum pipeline_routing_msg_req_type subtype;
-
-	/* key */
-	struct pipeline_routing_route_key key;
-};
-
-struct pipeline_routing_route_delete_msg_rsp {
-	int status;
-	int key_found;
-};
-
-/*
- * MSG ROUTE ADD DEFAULT
- */
-struct pipeline_routing_route_add_default_msg_req {
-	enum pipeline_msg_req_type type;
-	enum pipeline_routing_msg_req_type subtype;
-
-	/* data */
-	uint32_t port_id;
-};
-
-struct pipeline_routing_route_add_default_msg_rsp {
-	int status;
-	void *entry_ptr;
-};
-
-/*
- * MSG ROUTE DELETE DEFAULT
- */
-struct pipeline_routing_route_delete_default_msg_req {
-	enum pipeline_msg_req_type type;
-	enum pipeline_routing_msg_req_type subtype;
-};
-
-struct pipeline_routing_route_delete_default_msg_rsp {
-	int status;
-};
-
-/*
- * MSG ARP ADD
- */
-struct pipeline_routing_arp_add_msg_req {
-	enum pipeline_msg_req_type type;
-	enum pipeline_routing_msg_req_type subtype;
-
-	/* key */
-	struct pipeline_routing_arp_key key;
-
-	/* data */
-	struct ether_addr macaddr;
-};
-
-struct pipeline_routing_arp_add_msg_rsp {
-	int status;
-	int key_found;
-	void *entry_ptr;
-};
-
-/*
- * MSG ARP DELETE
- */
-struct pipeline_routing_arp_delete_msg_req {
-	enum pipeline_msg_req_type type;
-	enum pipeline_routing_msg_req_type subtype;
-
-	/* key */
-	struct pipeline_routing_arp_key key;
-};
-
-struct pipeline_routing_arp_delete_msg_rsp {
-	int status;
-	int key_found;
-};
-
-/*
- * MSG ARP ADD DEFAULT
- */
-struct pipeline_routing_arp_add_default_msg_req {
-	enum pipeline_msg_req_type type;
-	enum pipeline_routing_msg_req_type subtype;
-
-	/* data */
-	uint32_t port_id;
-};
-
-struct pipeline_routing_arp_add_default_msg_rsp {
-	int status;
-	void *entry_ptr;
-};
-
-/*
- * MSG ARP DELETE DEFAULT
- */
-struct pipeline_routing_arp_delete_default_msg_req {
-	enum pipeline_msg_req_type type;
-	enum pipeline_routing_msg_req_type subtype;
-};
-
-struct pipeline_routing_arp_delete_default_msg_rsp {
-	int status;
-};
-
-/*
- * MSG SET MACADDR
- */
-struct pipeline_routing_set_macaddr_msg_req {
-	enum pipeline_msg_req_type type;
-	enum pipeline_routing_msg_req_type subtype;
-
-	uint64_t macaddr[PIPELINE_MAX_PORT_OUT];
-};
-
-struct pipeline_routing_set_macaddr_msg_rsp {
-	int status;
-};
-
-extern struct pipeline_be_ops pipeline_routing_be_ops;
-
-#endif
diff --git a/examples/ip_pipeline/pipeline_be.h b/examples/ip_pipeline/pipeline_be.h
deleted file mode 100644
index 6c0c97a..0000000
--- a/examples/ip_pipeline/pipeline_be.h
+++ /dev/null
@@ -1,322 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#ifndef __INCLUDE_PIPELINE_BE_H__
-#define __INCLUDE_PIPELINE_BE_H__
-
-#include <rte_port_ethdev.h>
-#include <rte_port_ring.h>
-#include <rte_port_frag.h>
-#include <rte_port_ras.h>
-#include <rte_port_sched.h>
-#include <rte_port_fd.h>
-#include <rte_port_source_sink.h>
-#ifdef RTE_LIBRTE_KNI
-#include <rte_port_kni.h>
-#endif
-#include <rte_pipeline.h>
-
-enum pipeline_port_in_type {
-	PIPELINE_PORT_IN_ETHDEV_READER,
-	PIPELINE_PORT_IN_RING_READER,
-	PIPELINE_PORT_IN_RING_MULTI_READER,
-	PIPELINE_PORT_IN_RING_READER_IPV4_FRAG,
-	PIPELINE_PORT_IN_RING_READER_IPV6_FRAG,
-	PIPELINE_PORT_IN_SCHED_READER,
-	PIPELINE_PORT_IN_FD_READER,
-	PIPELINE_PORT_IN_KNI_READER,
-	PIPELINE_PORT_IN_SOURCE,
-};
-
-struct pipeline_port_in_params {
-	enum pipeline_port_in_type type;
-	union {
-		struct rte_port_ethdev_reader_params ethdev;
-		struct rte_port_ring_reader_params ring;
-		struct rte_port_ring_multi_reader_params ring_multi;
-		struct rte_port_ring_reader_ipv4_frag_params ring_ipv4_frag;
-		struct rte_port_ring_reader_ipv6_frag_params ring_ipv6_frag;
-		struct rte_port_sched_reader_params sched;
-		struct rte_port_fd_reader_params fd;
-#ifdef RTE_LIBRTE_KNI
-		struct rte_port_kni_reader_params kni;
-#endif
-		struct rte_port_source_params source;
-	} params;
-	uint32_t burst_size;
-};
-
-static inline void *
-pipeline_port_in_params_convert(struct pipeline_port_in_params  *p)
-{
-	switch (p->type) {
-	case PIPELINE_PORT_IN_ETHDEV_READER:
-		return (void *) &p->params.ethdev;
-	case PIPELINE_PORT_IN_RING_READER:
-		return (void *) &p->params.ring;
-	case PIPELINE_PORT_IN_RING_MULTI_READER:
-		return (void *) &p->params.ring_multi;
-	case PIPELINE_PORT_IN_RING_READER_IPV4_FRAG:
-		return (void *) &p->params.ring_ipv4_frag;
-	case PIPELINE_PORT_IN_RING_READER_IPV6_FRAG:
-		return (void *) &p->params.ring_ipv6_frag;
-	case PIPELINE_PORT_IN_SCHED_READER:
-		return (void *) &p->params.sched;
-	case PIPELINE_PORT_IN_FD_READER:
-		return (void *) &p->params.fd;
-#ifdef RTE_LIBRTE_KNI
-	case PIPELINE_PORT_IN_KNI_READER:
-		return (void *) &p->params.kni;
-#endif
-	case PIPELINE_PORT_IN_SOURCE:
-		return (void *) &p->params.source;
-	default:
-		return NULL;
-	}
-}
-
-static inline struct rte_port_in_ops *
-pipeline_port_in_params_get_ops(struct pipeline_port_in_params  *p)
-{
-	switch (p->type) {
-	case PIPELINE_PORT_IN_ETHDEV_READER:
-		return &rte_port_ethdev_reader_ops;
-	case PIPELINE_PORT_IN_RING_READER:
-		return &rte_port_ring_reader_ops;
-	case PIPELINE_PORT_IN_RING_MULTI_READER:
-		return &rte_port_ring_multi_reader_ops;
-	case PIPELINE_PORT_IN_RING_READER_IPV4_FRAG:
-		return &rte_port_ring_reader_ipv4_frag_ops;
-	case PIPELINE_PORT_IN_RING_READER_IPV6_FRAG:
-		return &rte_port_ring_reader_ipv6_frag_ops;
-	case PIPELINE_PORT_IN_SCHED_READER:
-		return &rte_port_sched_reader_ops;
-	case PIPELINE_PORT_IN_FD_READER:
-		return &rte_port_fd_reader_ops;
-#ifdef RTE_LIBRTE_KNI
-	case PIPELINE_PORT_IN_KNI_READER:
-		return &rte_port_kni_reader_ops;
-#endif
-	case PIPELINE_PORT_IN_SOURCE:
-		return &rte_port_source_ops;
-	default:
-		return NULL;
-	}
-}
-
-enum pipeline_port_out_type {
-	PIPELINE_PORT_OUT_ETHDEV_WRITER,
-	PIPELINE_PORT_OUT_ETHDEV_WRITER_NODROP,
-	PIPELINE_PORT_OUT_RING_WRITER,
-	PIPELINE_PORT_OUT_RING_MULTI_WRITER,
-	PIPELINE_PORT_OUT_RING_WRITER_NODROP,
-	PIPELINE_PORT_OUT_RING_MULTI_WRITER_NODROP,
-	PIPELINE_PORT_OUT_RING_WRITER_IPV4_RAS,
-	PIPELINE_PORT_OUT_RING_WRITER_IPV6_RAS,
-	PIPELINE_PORT_OUT_SCHED_WRITER,
-	PIPELINE_PORT_OUT_FD_WRITER,
-	PIPELINE_PORT_OUT_KNI_WRITER,
-	PIPELINE_PORT_OUT_KNI_WRITER_NODROP,
-	PIPELINE_PORT_OUT_SINK,
-};
-
-struct pipeline_port_out_params {
-	enum pipeline_port_out_type type;
-	union {
-		struct rte_port_ethdev_writer_params ethdev;
-		struct rte_port_ethdev_writer_nodrop_params ethdev_nodrop;
-		struct rte_port_ring_writer_params ring;
-		struct rte_port_ring_multi_writer_params ring_multi;
-		struct rte_port_ring_writer_nodrop_params ring_nodrop;
-		struct rte_port_ring_multi_writer_nodrop_params ring_multi_nodrop;
-		struct rte_port_ring_writer_ipv4_ras_params ring_ipv4_ras;
-		struct rte_port_ring_writer_ipv6_ras_params ring_ipv6_ras;
-		struct rte_port_sched_writer_params sched;
-		struct rte_port_fd_writer_params fd;
-#ifdef RTE_LIBRTE_KNI
-		struct rte_port_kni_writer_params kni;
-		struct rte_port_kni_writer_nodrop_params kni_nodrop;
-#endif
-		struct rte_port_sink_params sink;
-	} params;
-};
-
-static inline void *
-pipeline_port_out_params_convert(struct pipeline_port_out_params  *p)
-{
-	switch (p->type) {
-	case PIPELINE_PORT_OUT_ETHDEV_WRITER:
-		return (void *) &p->params.ethdev;
-	case PIPELINE_PORT_OUT_ETHDEV_WRITER_NODROP:
-		return (void *) &p->params.ethdev_nodrop;
-	case PIPELINE_PORT_OUT_RING_WRITER:
-		return (void *) &p->params.ring;
-	case PIPELINE_PORT_OUT_RING_MULTI_WRITER:
-		return (void *) &p->params.ring_multi;
-	case PIPELINE_PORT_OUT_RING_WRITER_NODROP:
-		return (void *) &p->params.ring_nodrop;
-	case PIPELINE_PORT_OUT_RING_MULTI_WRITER_NODROP:
-		return (void *) &p->params.ring_multi_nodrop;
-	case PIPELINE_PORT_OUT_RING_WRITER_IPV4_RAS:
-		return (void *) &p->params.ring_ipv4_ras;
-	case PIPELINE_PORT_OUT_RING_WRITER_IPV6_RAS:
-		return (void *) &p->params.ring_ipv6_ras;
-	case PIPELINE_PORT_OUT_SCHED_WRITER:
-		return (void *) &p->params.sched;
-	case PIPELINE_PORT_OUT_FD_WRITER:
-		return (void *) &p->params.fd;
-#ifdef RTE_LIBRTE_KNI
-	case PIPELINE_PORT_OUT_KNI_WRITER:
-		return (void *) &p->params.kni;
-	case PIPELINE_PORT_OUT_KNI_WRITER_NODROP:
-		return (void *) &p->params.kni_nodrop;
-#endif
-	case PIPELINE_PORT_OUT_SINK:
-		return (void *) &p->params.sink;
-	default:
-		return NULL;
-	}
-}
-
-static inline void *
-pipeline_port_out_params_get_ops(struct pipeline_port_out_params  *p)
-{
-	switch (p->type) {
-	case PIPELINE_PORT_OUT_ETHDEV_WRITER:
-		return &rte_port_ethdev_writer_ops;
-	case PIPELINE_PORT_OUT_ETHDEV_WRITER_NODROP:
-		return &rte_port_ethdev_writer_nodrop_ops;
-	case PIPELINE_PORT_OUT_RING_WRITER:
-		return &rte_port_ring_writer_ops;
-	case PIPELINE_PORT_OUT_RING_MULTI_WRITER:
-		return &rte_port_ring_multi_writer_ops;
-	case PIPELINE_PORT_OUT_RING_WRITER_NODROP:
-		return &rte_port_ring_writer_nodrop_ops;
-	case PIPELINE_PORT_OUT_RING_MULTI_WRITER_NODROP:
-		return &rte_port_ring_multi_writer_nodrop_ops;
-	case PIPELINE_PORT_OUT_RING_WRITER_IPV4_RAS:
-		return &rte_port_ring_writer_ipv4_ras_ops;
-	case PIPELINE_PORT_OUT_RING_WRITER_IPV6_RAS:
-		return &rte_port_ring_writer_ipv6_ras_ops;
-	case PIPELINE_PORT_OUT_SCHED_WRITER:
-		return &rte_port_sched_writer_ops;
-	case PIPELINE_PORT_OUT_FD_WRITER:
-		return &rte_port_fd_writer_ops;
-#ifdef RTE_LIBRTE_KNI
-	case PIPELINE_PORT_OUT_KNI_WRITER:
-		return &rte_port_kni_writer_ops;
-	case PIPELINE_PORT_OUT_KNI_WRITER_NODROP:
-		return &rte_port_kni_writer_nodrop_ops;
-#endif
-	case PIPELINE_PORT_OUT_SINK:
-		return &rte_port_sink_ops;
-	default:
-		return NULL;
-	}
-}
-
-#ifndef PIPELINE_NAME_SIZE
-#define PIPELINE_NAME_SIZE                       64
-#endif
-
-#ifndef PIPELINE_TYPE_SIZE
-#define PIPELINE_TYPE_SIZE                       64
-#endif
-
-#ifndef PIPELINE_MAX_PORT_IN
-#define PIPELINE_MAX_PORT_IN                     64
-#endif
-
-#ifndef PIPELINE_MAX_PORT_OUT
-#define PIPELINE_MAX_PORT_OUT                    64
-#endif
-
-#ifndef PIPELINE_MAX_TABLES
-#define PIPELINE_MAX_TABLES                      16
-#endif
-
-#ifndef PIPELINE_MAX_MSGQ_IN
-#define PIPELINE_MAX_MSGQ_IN                     16
-#endif
-
-#ifndef PIPELINE_MAX_MSGQ_OUT
-#define PIPELINE_MAX_MSGQ_OUT                    16
-#endif
-
-#ifndef PIPELINE_MAX_ARGS
-#define PIPELINE_MAX_ARGS                        64
-#endif
-
-struct pipeline_params {
-	char name[PIPELINE_NAME_SIZE];
-	char type[PIPELINE_TYPE_SIZE];
-
-	struct pipeline_port_in_params port_in[PIPELINE_MAX_PORT_IN];
-	struct pipeline_port_out_params port_out[PIPELINE_MAX_PORT_OUT];
-	struct rte_ring *msgq_in[PIPELINE_MAX_MSGQ_IN];
-	struct rte_ring *msgq_out[PIPELINE_MAX_MSGQ_OUT];
-
-	uint32_t n_ports_in;
-	uint32_t n_ports_out;
-	uint32_t n_msgq;
-
-	int socket_id;
-
-	char *args_name[PIPELINE_MAX_ARGS];
-	char *args_value[PIPELINE_MAX_ARGS];
-	uint32_t n_args;
-
-	uint32_t log_level;
-};
-
-/*
- * Pipeline type back-end operations
- */
-
-typedef void* (*pipeline_be_op_init)(struct pipeline_params *params,
-	void *arg);
-
-typedef int (*pipeline_be_op_free)(void *pipeline);
-
-typedef int (*pipeline_be_op_run)(void *pipeline);
-
-typedef int (*pipeline_be_op_timer)(void *pipeline);
-
-struct pipeline_be_ops {
-	pipeline_be_op_init f_init;
-	pipeline_be_op_free f_free;
-	pipeline_be_op_run f_run;
-	pipeline_be_op_timer f_timer;
-};
-
-/* Pipeline specific config parse error messages */
-#define PIPELINE_ARG_CHECK(exp, fmt, ...)				\
-do {									\
-	if (!(exp)) {							\
-		fprintf(stderr, fmt "\n", ## __VA_ARGS__);		\
-		return -1;						\
-	}								\
-} while (0)
-
-#define PIPELINE_PARSE_ERR_INV_VAL(exp, section, entry, val)		\
-PIPELINE_ARG_CHECK(exp, "Parse error in section \"%s\": entry \"%s\" "	\
-	"has invalid value (\"%s\")", section, entry, val)
-
-#define PIPELINE_PARSE_ERR_OUT_RNG(exp, section, entry, val)		\
-PIPELINE_ARG_CHECK(exp, "Parse error in section \"%s\": entry \"%s\" "	\
-	"value is out of range (\"%s\")", section, entry, val)
-
-#define PIPELINE_PARSE_ERR_DUPLICATE(exp, section, entry)		\
-PIPELINE_ARG_CHECK(exp, "Parse error in section \"%s\": duplicated "	\
-	"entry \"%s\"", section, entry)
-
-#define PIPELINE_PARSE_ERR_INV_ENT(exp, section, entry)			\
-PIPELINE_ARG_CHECK(exp, "Parse error in section \"%s\": invalid entry "	\
-	"\"%s\"", section, entry)
-
-#define PIPELINE_PARSE_ERR_MANDATORY(exp, section, entry)		\
-PIPELINE_ARG_CHECK(exp, "Parse error in section \"%s\": mandatory "	\
-	"entry \"%s\" is missing", section, entry)
-
-#endif
diff --git a/examples/ip_pipeline/thread.c b/examples/ip_pipeline/thread.c
deleted file mode 100644
index 9013afd..0000000
--- a/examples/ip_pipeline/thread.c
+++ /dev/null
@@ -1,293 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#include <rte_common.h>
-#include <rte_cycles.h>
-#include <rte_pipeline.h>
-
-#include "pipeline_common_be.h"
-#include "app.h"
-#include "thread.h"
-
-#if APP_THREAD_HEADROOM_STATS_COLLECT
-
-#define PIPELINE_RUN_REGULAR(thread, pipeline)		\
-do {							\
-	uint64_t t0 = rte_rdtsc_precise();		\
-	int n_pkts = rte_pipeline_run(pipeline->p);	\
-							\
-	if (n_pkts == 0) {				\
-		uint64_t t1 = rte_rdtsc_precise();	\
-							\
-		thread->headroom_cycles += t1 - t0;	\
-	}						\
-} while (0)
-
-
-#define PIPELINE_RUN_CUSTOM(thread, data)		\
-do {							\
-	uint64_t t0 = rte_rdtsc_precise();		\
-	int n_pkts = data->f_run(data->be);		\
-							\
-	if (n_pkts == 0) {				\
-		uint64_t t1 = rte_rdtsc_precise();	\
-							\
-		thread->headroom_cycles += t1 - t0;	\
-	}						\
-} while (0)
-
-#else
-
-#define PIPELINE_RUN_REGULAR(thread, pipeline)		\
-	rte_pipeline_run(pipeline->p)
-
-#define PIPELINE_RUN_CUSTOM(thread, data)		\
-	data->f_run(data->be)
-
-#endif
-
-static inline void *
-thread_msg_recv(struct rte_ring *r)
-{
-	void *msg;
-	int status = rte_ring_sc_dequeue(r, &msg);
-
-	if (status != 0)
-		return NULL;
-
-	return msg;
-}
-
-static inline void
-thread_msg_send(struct rte_ring *r,
-	void *msg)
-{
-	int status;
-
-	do {
-		status = rte_ring_sp_enqueue(r, msg);
-	} while (status == -ENOBUFS);
-}
-
-static int
-thread_pipeline_enable(struct app_thread_data *t,
-		struct thread_pipeline_enable_msg_req *req)
-{
-	struct app_thread_pipeline_data *p;
-
-	if (req->f_run == NULL) {
-		if (t->n_regular >= APP_MAX_THREAD_PIPELINES)
-			return -1;
-	} else {
-		if (t->n_custom >= APP_MAX_THREAD_PIPELINES)
-			return -1;
-	}
-
-	p = (req->f_run == NULL) ?
-		&t->regular[t->n_regular] :
-		&t->custom[t->n_custom];
-
-	p->pipeline_id = req->pipeline_id;
-	p->be = req->be;
-	p->f_run = req->f_run;
-	p->f_timer = req->f_timer;
-	p->timer_period = req->timer_period;
-	p->deadline = 0;
-
-	if (req->f_run == NULL)
-		t->n_regular++;
-	else
-		t->n_custom++;
-
-	return 0;
-}
-
-static int
-thread_pipeline_disable(struct app_thread_data *t,
-		struct thread_pipeline_disable_msg_req *req)
-{
-	uint32_t n_regular = RTE_MIN(t->n_regular, RTE_DIM(t->regular));
-	uint32_t n_custom = RTE_MIN(t->n_custom, RTE_DIM(t->custom));
-	uint32_t i;
-
-	/* search regular pipelines of current thread */
-	for (i = 0; i < n_regular; i++) {
-		if (t->regular[i].pipeline_id != req->pipeline_id)
-			continue;
-
-		if (i < n_regular - 1)
-			memcpy(&t->regular[i],
-			  &t->regular[i+1],
-			  (n_regular - 1 - i) * sizeof(struct app_thread_pipeline_data));
-
-		n_regular--;
-		t->n_regular = n_regular;
-
-		return 0;
-	}
-
-	/* search custom pipelines of current thread */
-	for (i = 0; i < n_custom; i++) {
-		if (t->custom[i].pipeline_id != req->pipeline_id)
-			continue;
-
-		if (i < n_custom - 1)
-			memcpy(&t->custom[i],
-			  &t->custom[i+1],
-			  (n_custom - 1 - i) * sizeof(struct app_thread_pipeline_data));
-
-		n_custom--;
-		t->n_custom = n_custom;
-
-		return 0;
-	}
-
-	/* return if pipeline not found */
-	return -1;
-}
-
-static int
-thread_msg_req_handle(struct app_thread_data *t)
-{
-	void *msg_ptr;
-	struct thread_msg_req *req;
-	struct thread_msg_rsp *rsp;
-
-	msg_ptr = thread_msg_recv(t->msgq_in);
-	req = msg_ptr;
-	rsp = msg_ptr;
-
-	if (req != NULL)
-		switch (req->type) {
-		case THREAD_MSG_REQ_PIPELINE_ENABLE: {
-			rsp->status = thread_pipeline_enable(t,
-					(struct thread_pipeline_enable_msg_req *) req);
-			thread_msg_send(t->msgq_out, rsp);
-			break;
-		}
-
-		case THREAD_MSG_REQ_PIPELINE_DISABLE: {
-			rsp->status = thread_pipeline_disable(t,
-					(struct thread_pipeline_disable_msg_req *) req);
-			thread_msg_send(t->msgq_out, rsp);
-			break;
-		}
-
-		case THREAD_MSG_REQ_HEADROOM_READ: {
-			struct thread_headroom_read_msg_rsp *rsp =
-				(struct thread_headroom_read_msg_rsp *)
-				req;
-
-			rsp->headroom_ratio = t->headroom_ratio;
-			rsp->status = 0;
-			thread_msg_send(t->msgq_out, rsp);
-			break;
-		}
-		default:
-			break;
-		}
-
-	return 0;
-}
-
-static void
-thread_headroom_update(struct app_thread_data *t, uint64_t time)
-{
-	uint64_t time_diff = time - t->headroom_time;
-
-	t->headroom_ratio =
-		((double) t->headroom_cycles) / ((double) time_diff);
-
-	t->headroom_cycles = 0;
-	t->headroom_time = rte_rdtsc_precise();
-}
-
-int
-app_thread(void *arg)
-{
-	struct app_params *app = (struct app_params *) arg;
-	uint32_t core_id = rte_lcore_id(), i, j;
-	struct app_thread_data *t = &app->thread_data[core_id];
-
-	for (i = 0; ; i++) {
-		uint32_t n_regular = RTE_MIN(t->n_regular, RTE_DIM(t->regular));
-		uint32_t n_custom = RTE_MIN(t->n_custom, RTE_DIM(t->custom));
-
-		/* Run regular pipelines */
-		for (j = 0; j < n_regular; j++) {
-			struct app_thread_pipeline_data *data = &t->regular[j];
-			struct pipeline *p = data->be;
-
-			PIPELINE_RUN_REGULAR(t, p);
-		}
-
-		/* Run custom pipelines */
-		for (j = 0; j < n_custom; j++) {
-			struct app_thread_pipeline_data *data = &t->custom[j];
-
-			PIPELINE_RUN_CUSTOM(t, data);
-		}
-
-		/* Timer */
-		if ((i & 0xF) == 0) {
-			uint64_t time = rte_get_tsc_cycles();
-			uint64_t t_deadline = UINT64_MAX;
-
-			if (time < t->deadline)
-				continue;
-
-			/* Timer for regular pipelines */
-			for (j = 0; j < n_regular; j++) {
-				struct app_thread_pipeline_data *data =
-					&t->regular[j];
-				uint64_t p_deadline = data->deadline;
-
-				if (p_deadline <= time) {
-					data->f_timer(data->be);
-					p_deadline = time + data->timer_period;
-					data->deadline = p_deadline;
-				}
-
-				if (p_deadline < t_deadline)
-					t_deadline = p_deadline;
-			}
-
-			/* Timer for custom pipelines */
-			for (j = 0; j < n_custom; j++) {
-				struct app_thread_pipeline_data *data =
-					&t->custom[j];
-				uint64_t p_deadline = data->deadline;
-
-				if (p_deadline <= time) {
-					data->f_timer(data->be);
-					p_deadline = time + data->timer_period;
-					data->deadline = p_deadline;
-				}
-
-				if (p_deadline < t_deadline)
-					t_deadline = p_deadline;
-			}
-
-			/* Timer for thread message request */
-			{
-				uint64_t deadline = t->thread_req_deadline;
-
-				if (deadline <= time) {
-					thread_msg_req_handle(t);
-					thread_headroom_update(t, time);
-					deadline = time + t->timer_period;
-					t->thread_req_deadline = deadline;
-				}
-
-				if (deadline < t_deadline)
-					t_deadline = deadline;
-			}
-
-
-			t->deadline = t_deadline;
-		}
-	}
-
-	return 0;
-}
diff --git a/examples/ip_pipeline/thread.h b/examples/ip_pipeline/thread.h
deleted file mode 100644
index 2c4fb6a..0000000
--- a/examples/ip_pipeline/thread.h
+++ /dev/null
@@ -1,69 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#ifndef THREAD_H_
-#define THREAD_H_
-
-#include "app.h"
-#include "pipeline_be.h"
-
-enum thread_msg_req_type {
-	THREAD_MSG_REQ_PIPELINE_ENABLE = 0,
-	THREAD_MSG_REQ_PIPELINE_DISABLE,
-	THREAD_MSG_REQ_HEADROOM_READ,
-	THREAD_MSG_REQS
-};
-
-struct thread_msg_req {
-	enum thread_msg_req_type type;
-};
-
-struct thread_msg_rsp {
-	int status;
-};
-
-/*
- * PIPELINE ENABLE
- */
-struct thread_pipeline_enable_msg_req {
-	enum thread_msg_req_type type;
-
-	uint32_t pipeline_id;
-	void *be;
-	pipeline_be_op_run f_run;
-	pipeline_be_op_timer f_timer;
-	uint64_t timer_period;
-};
-
-struct thread_pipeline_enable_msg_rsp {
-	int status;
-};
-
-/*
- * PIPELINE DISABLE
- */
-struct thread_pipeline_disable_msg_req {
-	enum thread_msg_req_type type;
-
-	uint32_t pipeline_id;
-};
-
-struct thread_pipeline_disable_msg_rsp {
-	int status;
-};
-
-/*
- * THREAD HEADROOM
- */
-struct thread_headroom_read_msg_req {
-	enum thread_msg_req_type type;
-};
-
-struct thread_headroom_read_msg_rsp {
-	int status;
-
-	double headroom_ratio;
-};
-
-#endif /* THREAD_H_ */
diff --git a/examples/ip_pipeline/thread_fe.c b/examples/ip_pipeline/thread_fe.c
deleted file mode 100644
index 4590c2b..0000000
--- a/examples/ip_pipeline/thread_fe.c
+++ /dev/null
@@ -1,457 +0,0 @@
-#include <rte_common.h>
-#include <rte_ring.h>
-#include <rte_malloc.h>
-#include <cmdline_rdline.h>
-#include <cmdline_parse.h>
-#include <cmdline_parse_num.h>
-#include <cmdline_parse_string.h>
-
-#include "thread.h"
-#include "thread_fe.h"
-#include "pipeline.h"
-#include "pipeline_common_fe.h"
-#include "app.h"
-
-static inline void *
-thread_msg_send_recv(struct app_params *app,
-	uint32_t socket_id, uint32_t core_id, uint32_t ht_id,
-	void *msg,
-	uint32_t timeout_ms)
-{
-	struct rte_ring *r_req = app_thread_msgq_in_get(app,
-		socket_id, core_id, ht_id);
-	struct rte_ring *r_rsp = app_thread_msgq_out_get(app,
-		socket_id, core_id, ht_id);
-	uint64_t hz = rte_get_tsc_hz();
-	void *msg_recv;
-	uint64_t deadline;
-	int status;
-
-	/* send */
-	do {
-		status = rte_ring_sp_enqueue(r_req, (void *) msg);
-	} while (status == -ENOBUFS);
-
-	/* recv */
-	deadline = (timeout_ms) ?
-		(rte_rdtsc() + ((hz * timeout_ms) / 1000)) :
-		UINT64_MAX;
-
-	do {
-		if (rte_rdtsc() > deadline)
-			return NULL;
-
-		status = rte_ring_sc_dequeue(r_rsp, &msg_recv);
-	} while (status != 0);
-
-	return msg_recv;
-}
-
-int
-app_pipeline_enable(struct app_params *app,
-		uint32_t socket_id,
-		uint32_t core_id,
-		uint32_t hyper_th_id,
-		uint32_t pipeline_id)
-{
-	struct thread_pipeline_enable_msg_req *req;
-	struct thread_pipeline_enable_msg_rsp *rsp;
-	int thread_id;
-	struct app_pipeline_data *p;
-	struct app_pipeline_params *p_params;
-	struct pipeline_type *p_type;
-	int status;
-
-	if (app == NULL)
-		return -1;
-
-	thread_id = cpu_core_map_get_lcore_id(app->core_map,
-			socket_id,
-			core_id,
-			hyper_th_id);
-
-	if ((thread_id < 0) || !app_core_is_enabled(app, thread_id))
-		return -1;
-
-	if (app_pipeline_data(app, pipeline_id) == NULL)
-		return -1;
-
-	p = &app->pipeline_data[pipeline_id];
-	p_params = &app->pipeline_params[pipeline_id];
-	p_type = app_pipeline_type_find(app, p_params->type);
-
-	if (p_type == NULL)
-		return -1;
-
-	if (p->enabled == 1)
-		return -1;
-
-	req = app_msg_alloc(app);
-	if (req == NULL)
-		return -1;
-
-	req->type = THREAD_MSG_REQ_PIPELINE_ENABLE;
-	req->pipeline_id = pipeline_id;
-	req->be = p->be;
-	req->f_run = p_type->be_ops->f_run;
-	req->f_timer = p_type->be_ops->f_timer;
-	req->timer_period = p->timer_period;
-
-	rsp = thread_msg_send_recv(app,
-		socket_id, core_id, hyper_th_id, req, MSG_TIMEOUT_DEFAULT);
-	if (rsp == NULL)
-		return -1;
-
-	status = rsp->status;
-	app_msg_free(app, rsp);
-
-	if (status != 0)
-		return -1;
-
-	p->enabled = 1;
-	return 0;
-}
-
-int
-app_pipeline_disable(struct app_params *app,
-		uint32_t socket_id,
-		uint32_t core_id,
-		uint32_t hyper_th_id,
-		uint32_t pipeline_id)
-{
-	struct thread_pipeline_disable_msg_req *req;
-	struct thread_pipeline_disable_msg_rsp *rsp;
-	int thread_id;
-	struct app_pipeline_data *p;
-	int status;
-
-	if (app == NULL)
-		return -1;
-
-	thread_id = cpu_core_map_get_lcore_id(app->core_map,
-			socket_id,
-			core_id,
-			hyper_th_id);
-
-	if ((thread_id < 0) || !app_core_is_enabled(app, thread_id))
-		return -1;
-
-	if (app_pipeline_data(app, pipeline_id) == NULL)
-		return -1;
-
-	p = &app->pipeline_data[pipeline_id];
-
-	if (p->enabled == 0)
-		return -1;
-
-	req = app_msg_alloc(app);
-	if (req == NULL)
-		return -1;
-
-	req->type = THREAD_MSG_REQ_PIPELINE_DISABLE;
-	req->pipeline_id = pipeline_id;
-
-	rsp = thread_msg_send_recv(app,
-		socket_id, core_id, hyper_th_id, req, MSG_TIMEOUT_DEFAULT);
-
-	if (rsp == NULL)
-		return -1;
-
-	status = rsp->status;
-	app_msg_free(app, rsp);
-
-	if (status != 0)
-		return -1;
-
-	p->enabled = 0;
-	return 0;
-}
-
-int
-app_thread_headroom(struct app_params *app,
-		uint32_t socket_id,
-		uint32_t core_id,
-		uint32_t hyper_th_id)
-{
-	struct thread_headroom_read_msg_req *req;
-	struct thread_headroom_read_msg_rsp *rsp;
-	int thread_id;
-	int status;
-
-	if (app == NULL)
-		return -1;
-
-	thread_id = cpu_core_map_get_lcore_id(app->core_map,
-			socket_id,
-			core_id,
-			hyper_th_id);
-
-	if ((thread_id < 0) || !app_core_is_enabled(app, thread_id))
-		return -1;
-
-	req = app_msg_alloc(app);
-	if (req == NULL)
-		return -1;
-
-	req->type = THREAD_MSG_REQ_HEADROOM_READ;
-
-	rsp = thread_msg_send_recv(app,
-		socket_id, core_id, hyper_th_id, req, MSG_TIMEOUT_DEFAULT);
-
-	if (rsp == NULL)
-		return -1;
-
-	status = rsp->status;
-
-	if (status != 0)
-		return -1;
-
-	printf("%.3f%%\n", rsp->headroom_ratio * 100);
-
-
-	app_msg_free(app, rsp);
-
-	return 0;
-}
-
-/*
- * pipeline enable
- */
-
-struct cmd_pipeline_enable_result {
-	cmdline_fixed_string_t t_string;
-	cmdline_fixed_string_t t_id_string;
-	cmdline_fixed_string_t pipeline_string;
-	uint32_t pipeline_id;
-	cmdline_fixed_string_t enable_string;
-};
-
-static void
-cmd_pipeline_enable_parsed(
-	void *parsed_result,
-	__rte_unused struct cmdline *cl,
-	 void *data)
-{
-	struct cmd_pipeline_enable_result *params = parsed_result;
-	struct app_params *app = data;
-	int status;
-	uint32_t core_id, socket_id, hyper_th_id;
-
-	if (parse_pipeline_core(&socket_id,
-			&core_id,
-			&hyper_th_id,
-			params->t_id_string) != 0) {
-		printf("Command failed\n");
-		return;
-	}
-
-	status = app_pipeline_enable(app,
-			socket_id,
-			core_id,
-			hyper_th_id,
-			params->pipeline_id);
-
-	if (status != 0)
-		printf("Command failed\n");
-}
-
-static cmdline_parse_token_string_t cmd_pipeline_enable_t_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_pipeline_enable_result, t_string, "t");
-
-static cmdline_parse_token_string_t cmd_pipeline_enable_t_id_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_pipeline_enable_result, t_id_string,
-		NULL);
-
-static cmdline_parse_token_string_t cmd_pipeline_enable_pipeline_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_pipeline_enable_result, pipeline_string,
-		"pipeline");
-
-static cmdline_parse_token_num_t cmd_pipeline_enable_pipeline_id =
-	TOKEN_NUM_INITIALIZER(struct cmd_pipeline_enable_result, pipeline_id,
-		UINT32);
-
-static cmdline_parse_token_string_t cmd_pipeline_enable_enable_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_pipeline_enable_result, enable_string,
-		"enable");
-
-static cmdline_parse_inst_t cmd_pipeline_enable = {
-	.f = cmd_pipeline_enable_parsed,
-	.data = NULL,
-	.help_str = "Enable pipeline on specified core",
-	.tokens = {
-		(void *)&cmd_pipeline_enable_t_string,
-		(void *)&cmd_pipeline_enable_t_id_string,
-		(void *)&cmd_pipeline_enable_pipeline_string,
-		(void *)&cmd_pipeline_enable_pipeline_id,
-		(void *)&cmd_pipeline_enable_enable_string,
-		NULL,
-	},
-};
-
-/*
- * pipeline disable
- */
-
-struct cmd_pipeline_disable_result {
-	cmdline_fixed_string_t t_string;
-	cmdline_fixed_string_t t_id_string;
-	cmdline_fixed_string_t pipeline_string;
-	uint32_t pipeline_id;
-	cmdline_fixed_string_t disable_string;
-};
-
-static void
-cmd_pipeline_disable_parsed(
-	void *parsed_result,
-	__rte_unused struct cmdline *cl,
-	 void *data)
-{
-	struct cmd_pipeline_disable_result *params = parsed_result;
-	struct app_params *app = data;
-	int status;
-	uint32_t core_id, socket_id, hyper_th_id;
-
-	if (parse_pipeline_core(&socket_id,
-			&core_id,
-			&hyper_th_id,
-			params->t_id_string) != 0) {
-		printf("Command failed\n");
-		return;
-	}
-
-	status = app_pipeline_disable(app,
-			socket_id,
-			core_id,
-			hyper_th_id,
-			params->pipeline_id);
-
-	if (status != 0)
-		printf("Command failed\n");
-}
-
-static cmdline_parse_token_string_t cmd_pipeline_disable_t_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_pipeline_disable_result, t_string, "t");
-
-static cmdline_parse_token_string_t cmd_pipeline_disable_t_id_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_pipeline_disable_result, t_id_string,
-		NULL);
-
-static cmdline_parse_token_string_t cmd_pipeline_disable_pipeline_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_pipeline_disable_result,
-		pipeline_string, "pipeline");
-
-static cmdline_parse_token_num_t cmd_pipeline_disable_pipeline_id =
-	TOKEN_NUM_INITIALIZER(struct cmd_pipeline_disable_result, pipeline_id,
-		UINT32);
-
-static cmdline_parse_token_string_t cmd_pipeline_disable_disable_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_pipeline_disable_result, disable_string,
-		"disable");
-
-static cmdline_parse_inst_t cmd_pipeline_disable = {
-	.f = cmd_pipeline_disable_parsed,
-	.data = NULL,
-	.help_str = "Disable pipeline on specified core",
-	.tokens = {
-		(void *)&cmd_pipeline_disable_t_string,
-		(void *)&cmd_pipeline_disable_t_id_string,
-		(void *)&cmd_pipeline_disable_pipeline_string,
-		(void *)&cmd_pipeline_disable_pipeline_id,
-		(void *)&cmd_pipeline_disable_disable_string,
-		NULL,
-	},
-};
-
-
-/*
- * thread headroom
- */
-
-struct cmd_thread_headroom_result {
-	cmdline_fixed_string_t t_string;
-	cmdline_fixed_string_t t_id_string;
-	cmdline_fixed_string_t headroom_string;
-};
-
-static void
-cmd_thread_headroom_parsed(
-	void *parsed_result,
-	__rte_unused struct cmdline *cl,
-	 void *data)
-{
-	struct cmd_thread_headroom_result *params = parsed_result;
-	struct app_params *app = data;
-	int status;
-	uint32_t core_id, socket_id, hyper_th_id;
-
-	if (parse_pipeline_core(&socket_id,
-			&core_id,
-			&hyper_th_id,
-			params->t_id_string) != 0) {
-		printf("Command failed\n");
-		return;
-	}
-
-	status = app_thread_headroom(app,
-			socket_id,
-			core_id,
-			hyper_th_id);
-
-	if (status != 0)
-		printf("Command failed\n");
-}
-
-static cmdline_parse_token_string_t cmd_thread_headroom_t_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_thread_headroom_result,
-	t_string, "t");
-
-static cmdline_parse_token_string_t cmd_thread_headroom_t_id_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_thread_headroom_result,
-	t_id_string, NULL);
-
-static cmdline_parse_token_string_t cmd_thread_headroom_headroom_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_thread_headroom_result,
-		headroom_string, "headroom");
-
-static cmdline_parse_inst_t cmd_thread_headroom = {
-	.f = cmd_thread_headroom_parsed,
-	.data = NULL,
-	.help_str = "Display thread headroom",
-	.tokens = {
-		(void *)&cmd_thread_headroom_t_string,
-		(void *)&cmd_thread_headroom_t_id_string,
-		(void *)&cmd_thread_headroom_headroom_string,
-		NULL,
-	},
-};
-
-
-static cmdline_parse_ctx_t thread_cmds[] = {
-	(cmdline_parse_inst_t *) &cmd_pipeline_enable,
-	(cmdline_parse_inst_t *) &cmd_pipeline_disable,
-	(cmdline_parse_inst_t *) &cmd_thread_headroom,
-	NULL,
-};
-
-int
-app_pipeline_thread_cmd_push(struct app_params *app)
-{
-	uint32_t n_cmds, i;
-
-	/* Check for available slots in the application commands array */
-	n_cmds = RTE_DIM(thread_cmds) - 1;
-	if (n_cmds > APP_MAX_CMDS - app->n_cmds)
-		return -ENOMEM;
-
-	/* Push thread commands into the application */
-	memcpy(&app->cmds[app->n_cmds], thread_cmds,
-		n_cmds * sizeof(cmdline_parse_ctx_t));
-
-	for (i = 0; i < n_cmds; i++)
-		app->cmds[app->n_cmds + i]->data = app;
-
-	app->n_cmds += n_cmds;
-	app->cmds[app->n_cmds] = NULL;
-
-	return 0;
-}
diff --git a/examples/ip_pipeline/thread_fe.h b/examples/ip_pipeline/thread_fe.h
deleted file mode 100644
index 056a5e8..0000000
--- a/examples/ip_pipeline/thread_fe.h
+++ /dev/null
@@ -1,72 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#ifndef THREAD_FE_H_
-#define THREAD_FE_H_
-
-static inline struct rte_ring *
-app_thread_msgq_in_get(struct app_params *app,
-		uint32_t socket_id, uint32_t core_id, uint32_t ht_id)
-{
-	char msgq_name[32];
-	ssize_t param_idx;
-
-	snprintf(msgq_name, sizeof(msgq_name),
-		"MSGQ-REQ-CORE-s%" PRIu32 "c%" PRIu32 "%s",
-		socket_id,
-		core_id,
-		(ht_id) ? "h" : "");
-	param_idx = APP_PARAM_FIND(app->msgq_params, msgq_name);
-
-	if (param_idx < 0)
-		return NULL;
-
-	return app->msgq[param_idx];
-}
-
-static inline struct rte_ring *
-app_thread_msgq_out_get(struct app_params *app,
-		uint32_t socket_id, uint32_t core_id, uint32_t ht_id)
-{
-	char msgq_name[32];
-	ssize_t param_idx;
-
-	snprintf(msgq_name, sizeof(msgq_name),
-		"MSGQ-RSP-CORE-s%" PRIu32 "c%" PRIu32 "%s",
-		socket_id,
-		core_id,
-		(ht_id) ? "h" : "");
-	param_idx = APP_PARAM_FIND(app->msgq_params, msgq_name);
-
-	if (param_idx < 0)
-		return NULL;
-
-	return app->msgq[param_idx];
-
-}
-
-int
-app_pipeline_thread_cmd_push(struct app_params *app);
-
-int
-app_pipeline_enable(struct app_params *app,
-		uint32_t core_id,
-		uint32_t socket_id,
-		uint32_t hyper_th_id,
-		uint32_t pipeline_id);
-
-int
-app_pipeline_disable(struct app_params *app,
-		uint32_t core_id,
-		uint32_t socket_id,
-		uint32_t hyper_th_id,
-		uint32_t pipeline_id);
-
-int
-app_thread_headroom(struct app_params *app,
-		uint32_t core_id,
-		uint32_t socket_id,
-		uint32_t hyper_th_id);
-
-#endif /* THREAD_FE_H_ */
diff --git a/examples/ip_reassembly/Makefile b/examples/ip_reassembly/Makefile
deleted file mode 100644
index 6438d97..0000000
--- a/examples/ip_reassembly/Makefile
+++ /dev/null
@@ -1,66 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-#
-
-# binary name
-APP = ip_reassembly
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-
-# workaround for a gcc bug with noreturn attribute
-# http://gcc.gnu.org/bugzilla/show_bug.cgi?id=12603
-ifeq ($(CONFIG_RTE_TOOLCHAIN_GCC),y)
-CFLAGS_main.o += -Wno-return-type
-endif
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-
-endif
diff --git a/examples/ip_reassembly/main.c b/examples/ip_reassembly/main.c
deleted file mode 100644
index ddff358..0000000
--- a/examples/ip_reassembly/main.c
+++ /dev/null
@@ -1,1174 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <sys/types.h>
-#include <string.h>
-#include <sys/queue.h>
-#include <stdarg.h>
-#include <errno.h>
-#include <getopt.h>
-#include <signal.h>
-#include <sys/param.h>
-
-#include <rte_common.h>
-#include <rte_byteorder.h>
-#include <rte_log.h>
-#include <rte_memory.h>
-#include <rte_memcpy.h>
-#include <rte_eal.h>
-#include <rte_launch.h>
-#include <rte_atomic.h>
-#include <rte_cycles.h>
-#include <rte_prefetch.h>
-#include <rte_lcore.h>
-#include <rte_per_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_interrupts.h>
-#include <rte_random.h>
-#include <rte_debug.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-#include <rte_malloc.h>
-#include <rte_ip.h>
-#include <rte_tcp.h>
-#include <rte_udp.h>
-#include <rte_string_fns.h>
-#include <rte_lpm.h>
-#include <rte_lpm6.h>
-
-#include <rte_ip_frag.h>
-
-#define MAX_PKT_BURST 32
-
-
-#define RTE_LOGTYPE_IP_RSMBL RTE_LOGTYPE_USER1
-
-#define MAX_JUMBO_PKT_LEN  9600
-
-#define	BUF_SIZE	RTE_MBUF_DEFAULT_DATAROOM
-#define	MBUF_DATA_SIZE	RTE_MBUF_DEFAULT_BUF_SIZE
-
-#define NB_MBUF 8192
-#define MEMPOOL_CACHE_SIZE 256
-
-/* allow max jumbo frame 9.5 KB */
-#define JUMBO_FRAME_MAX_SIZE	0x2600
-
-#define	MAX_FLOW_NUM	UINT16_MAX
-#define	MIN_FLOW_NUM	1
-#define	DEF_FLOW_NUM	0x1000
-
-/* TTL numbers are in ms. */
-#define	MAX_FLOW_TTL	(3600 * MS_PER_S)
-#define	MIN_FLOW_TTL	1
-#define	DEF_FLOW_TTL	MS_PER_S
-
-#define MAX_FRAG_NUM RTE_LIBRTE_IP_FRAG_MAX_FRAG
-
-/* Should be power of two. */
-#define	IP_FRAG_TBL_BUCKET_ENTRIES	16
-
-static uint32_t max_flow_num = DEF_FLOW_NUM;
-static uint32_t max_flow_ttl = DEF_FLOW_TTL;
-
-#define BURST_TX_DRAIN_US 100 /* TX drain every ~100us */
-
-#define NB_SOCKETS 8
-
-/* Configure how many packets ahead to prefetch, when reading packets */
-#define PREFETCH_OFFSET	3
-
-/*
- * Configurable number of RX/TX ring descriptors
- */
-#define RTE_TEST_RX_DESC_DEFAULT 1024
-#define RTE_TEST_TX_DESC_DEFAULT 1024
-
-static uint16_t nb_rxd = RTE_TEST_RX_DESC_DEFAULT;
-static uint16_t nb_txd = RTE_TEST_TX_DESC_DEFAULT;
-
-/* ethernet addresses of ports */
-static struct ether_addr ports_eth_addr[RTE_MAX_ETHPORTS];
-
-#ifndef IPv4_BYTES
-#define IPv4_BYTES_FMT "%" PRIu8 ".%" PRIu8 ".%" PRIu8 ".%" PRIu8
-#define IPv4_BYTES(addr) \
-		(uint8_t) (((addr) >> 24) & 0xFF),\
-		(uint8_t) (((addr) >> 16) & 0xFF),\
-		(uint8_t) (((addr) >> 8) & 0xFF),\
-		(uint8_t) ((addr) & 0xFF)
-#endif
-
-#ifndef IPv6_BYTES
-#define IPv6_BYTES_FMT "%02x%02x:%02x%02x:%02x%02x:%02x%02x:"\
-                       "%02x%02x:%02x%02x:%02x%02x:%02x%02x"
-#define IPv6_BYTES(addr) \
-	addr[0],  addr[1], addr[2],  addr[3], \
-	addr[4],  addr[5], addr[6],  addr[7], \
-	addr[8],  addr[9], addr[10], addr[11],\
-	addr[12], addr[13],addr[14], addr[15]
-#endif
-
-#define IPV6_ADDR_LEN 16
-
-/* mask of enabled ports */
-static uint32_t enabled_port_mask = 0;
-
-static int rx_queue_per_lcore = 1;
-
-struct mbuf_table {
-	uint32_t len;
-	uint32_t head;
-	uint32_t tail;
-	struct rte_mbuf *m_table[0];
-};
-
-struct rx_queue {
-	struct rte_ip_frag_tbl *frag_tbl;
-	struct rte_mempool *pool;
-	struct rte_lpm *lpm;
-	struct rte_lpm6 *lpm6;
-	uint16_t portid;
-};
-
-struct tx_lcore_stat {
-	uint64_t call;
-	uint64_t drop;
-	uint64_t queue;
-	uint64_t send;
-};
-
-#define MAX_RX_QUEUE_PER_LCORE 16
-#define MAX_TX_QUEUE_PER_PORT 16
-#define MAX_RX_QUEUE_PER_PORT 128
-
-struct lcore_queue_conf {
-	uint16_t n_rx_queue;
-	struct rx_queue rx_queue_list[MAX_RX_QUEUE_PER_LCORE];
-	uint16_t tx_queue_id[RTE_MAX_ETHPORTS];
-	struct rte_ip_frag_death_row death_row;
-	struct mbuf_table *tx_mbufs[RTE_MAX_ETHPORTS];
-	struct tx_lcore_stat tx_stat;
-} __rte_cache_aligned;
-static struct lcore_queue_conf lcore_queue_conf[RTE_MAX_LCORE];
-
-static struct rte_eth_conf port_conf = {
-	.rxmode = {
-		.mq_mode        = ETH_MQ_RX_RSS,
-		.max_rx_pkt_len = JUMBO_FRAME_MAX_SIZE,
-		.split_hdr_size = 0,
-		.ignore_offload_bitfield = 1,
-		.offloads = (DEV_RX_OFFLOAD_CHECKSUM |
-			     DEV_RX_OFFLOAD_JUMBO_FRAME |
-			     DEV_RX_OFFLOAD_CRC_STRIP),
-	},
-	.rx_adv_conf = {
-			.rss_conf = {
-				.rss_key = NULL,
-				.rss_hf = ETH_RSS_IP,
-		},
-	},
-	.txmode = {
-		.mq_mode = ETH_MQ_TX_NONE,
-		.offloads = (DEV_TX_OFFLOAD_IPV4_CKSUM |
-			     DEV_TX_OFFLOAD_MULTI_SEGS),
-	},
-};
-
-/*
- * IPv4 forwarding table
- */
-struct l3fwd_ipv4_route {
-	uint32_t ip;
-	uint8_t  depth;
-	uint8_t  if_out;
-};
-
-struct l3fwd_ipv4_route l3fwd_ipv4_route_array[] = {
-		{IPv4(100,10,0,0), 16, 0},
-		{IPv4(100,20,0,0), 16, 1},
-		{IPv4(100,30,0,0), 16, 2},
-		{IPv4(100,40,0,0), 16, 3},
-		{IPv4(100,50,0,0), 16, 4},
-		{IPv4(100,60,0,0), 16, 5},
-		{IPv4(100,70,0,0), 16, 6},
-		{IPv4(100,80,0,0), 16, 7},
-};
-
-/*
- * IPv6 forwarding table
- */
-
-struct l3fwd_ipv6_route {
-	uint8_t ip[IPV6_ADDR_LEN];
-	uint8_t depth;
-	uint8_t if_out;
-};
-
-static struct l3fwd_ipv6_route l3fwd_ipv6_route_array[] = {
-	{{1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1}, 48, 0},
-	{{2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1}, 48, 1},
-	{{3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1}, 48, 2},
-	{{4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1}, 48, 3},
-	{{5,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1}, 48, 4},
-	{{6,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1}, 48, 5},
-	{{7,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1}, 48, 6},
-	{{8,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1}, 48, 7},
-};
-
-#define LPM_MAX_RULES         1024
-#define LPM6_MAX_RULES         1024
-#define LPM6_NUMBER_TBL8S (1 << 16)
-
-struct rte_lpm6_config lpm6_config = {
-		.max_rules = LPM6_MAX_RULES,
-		.number_tbl8s = LPM6_NUMBER_TBL8S,
-		.flags = 0
-};
-
-static struct rte_lpm *socket_lpm[RTE_MAX_NUMA_NODES];
-static struct rte_lpm6 *socket_lpm6[RTE_MAX_NUMA_NODES];
-
-#ifdef RTE_LIBRTE_IP_FRAG_TBL_STAT
-#define TX_LCORE_STAT_UPDATE(s, f, v)   ((s)->f += (v))
-#else
-#define TX_LCORE_STAT_UPDATE(s, f, v)   do {} while (0)
-#endif /* RTE_LIBRTE_IP_FRAG_TBL_STAT */
-
-/*
- * If number of queued packets reached given threahold, then
- * send burst of packets on an output interface.
- */
-static inline uint32_t
-send_burst(struct lcore_queue_conf *qconf, uint32_t thresh, uint16_t port)
-{
-	uint32_t fill, len, k, n;
-	struct mbuf_table *txmb;
-
-	txmb = qconf->tx_mbufs[port];
-	len = txmb->len;
-
-	if ((int32_t)(fill = txmb->head - txmb->tail) < 0)
-		fill += len;
-
-	if (fill >= thresh) {
-		n = RTE_MIN(len - txmb->tail, fill);
-
-		k = rte_eth_tx_burst(port, qconf->tx_queue_id[port],
-			txmb->m_table + txmb->tail, (uint16_t)n);
-
-		TX_LCORE_STAT_UPDATE(&qconf->tx_stat, call, 1);
-		TX_LCORE_STAT_UPDATE(&qconf->tx_stat, send, k);
-
-		fill -= k;
-		if ((txmb->tail += k) == len)
-			txmb->tail = 0;
-	}
-
-	return fill;
-}
-
-/* Enqueue a single packet, and send burst if queue is filled */
-static inline int
-send_single_packet(struct rte_mbuf *m, uint16_t port)
-{
-	uint32_t fill, lcore_id, len;
-	struct lcore_queue_conf *qconf;
-	struct mbuf_table *txmb;
-
-	lcore_id = rte_lcore_id();
-	qconf = &lcore_queue_conf[lcore_id];
-
-	txmb = qconf->tx_mbufs[port];
-	len = txmb->len;
-
-	fill = send_burst(qconf, MAX_PKT_BURST, port);
-
-	if (fill == len - 1) {
-		TX_LCORE_STAT_UPDATE(&qconf->tx_stat, drop, 1);
-		rte_pktmbuf_free(txmb->m_table[txmb->tail]);
-		if (++txmb->tail == len)
-			txmb->tail = 0;
-	}
-
-	TX_LCORE_STAT_UPDATE(&qconf->tx_stat, queue, 1);
-	txmb->m_table[txmb->head] = m;
-	if(++txmb->head == len)
-		txmb->head = 0;
-
-	return 0;
-}
-
-static inline void
-reassemble(struct rte_mbuf *m, uint16_t portid, uint32_t queue,
-	struct lcore_queue_conf *qconf, uint64_t tms)
-{
-	struct ether_hdr *eth_hdr;
-	struct rte_ip_frag_tbl *tbl;
-	struct rte_ip_frag_death_row *dr;
-	struct rx_queue *rxq;
-	void *d_addr_bytes;
-	uint32_t next_hop;
-	uint16_t dst_port;
-
-	rxq = &qconf->rx_queue_list[queue];
-
-	eth_hdr = rte_pktmbuf_mtod(m, struct ether_hdr *);
-
-	dst_port = portid;
-
-	/* if packet is IPv4 */
-	if (RTE_ETH_IS_IPV4_HDR(m->packet_type)) {
-		struct ipv4_hdr *ip_hdr;
-		uint32_t ip_dst;
-
-		ip_hdr = (struct ipv4_hdr *)(eth_hdr + 1);
-
-		 /* if it is a fragmented packet, then try to reassemble. */
-		if (rte_ipv4_frag_pkt_is_fragmented(ip_hdr)) {
-			struct rte_mbuf *mo;
-
-			tbl = rxq->frag_tbl;
-			dr = &qconf->death_row;
-
-			/* prepare mbuf: setup l2_len/l3_len. */
-			m->l2_len = sizeof(*eth_hdr);
-			m->l3_len = sizeof(*ip_hdr);
-
-			/* process this fragment. */
-			mo = rte_ipv4_frag_reassemble_packet(tbl, dr, m, tms, ip_hdr);
-			if (mo == NULL)
-				/* no packet to send out. */
-				return;
-
-			/* we have our packet reassembled. */
-			if (mo != m) {
-				m = mo;
-				eth_hdr = rte_pktmbuf_mtod(m,
-					struct ether_hdr *);
-				ip_hdr = (struct ipv4_hdr *)(eth_hdr + 1);
-			}
-		}
-		ip_dst = rte_be_to_cpu_32(ip_hdr->dst_addr);
-
-		/* Find destination port */
-		if (rte_lpm_lookup(rxq->lpm, ip_dst, &next_hop) == 0 &&
-				(enabled_port_mask & 1 << next_hop) != 0) {
-			dst_port = next_hop;
-		}
-
-		eth_hdr->ether_type = rte_be_to_cpu_16(ETHER_TYPE_IPv4);
-	} else if (RTE_ETH_IS_IPV6_HDR(m->packet_type)) {
-		/* if packet is IPv6 */
-		struct ipv6_extension_fragment *frag_hdr;
-		struct ipv6_hdr *ip_hdr;
-
-		ip_hdr = (struct ipv6_hdr *)(eth_hdr + 1);
-
-		frag_hdr = rte_ipv6_frag_get_ipv6_fragment_header(ip_hdr);
-
-		if (frag_hdr != NULL) {
-			struct rte_mbuf *mo;
-
-			tbl = rxq->frag_tbl;
-			dr  = &qconf->death_row;
-
-			/* prepare mbuf: setup l2_len/l3_len. */
-			m->l2_len = sizeof(*eth_hdr);
-			m->l3_len = sizeof(*ip_hdr) + sizeof(*frag_hdr);
-
-			mo = rte_ipv6_frag_reassemble_packet(tbl, dr, m, tms, ip_hdr, frag_hdr);
-			if (mo == NULL)
-				return;
-
-			if (mo != m) {
-				m = mo;
-				eth_hdr = rte_pktmbuf_mtod(m, struct ether_hdr *);
-				ip_hdr = (struct ipv6_hdr *)(eth_hdr + 1);
-			}
-		}
-
-		/* Find destination port */
-		if (rte_lpm6_lookup(rxq->lpm6, ip_hdr->dst_addr,
-						&next_hop) == 0 &&
-				(enabled_port_mask & 1 << next_hop) != 0) {
-			dst_port = next_hop;
-		}
-
-		eth_hdr->ether_type = rte_be_to_cpu_16(ETHER_TYPE_IPv6);
-	}
-	/* if packet wasn't IPv4 or IPv6, it's forwarded to the port it came from */
-
-	/* 02:00:00:00:00:xx */
-	d_addr_bytes = &eth_hdr->d_addr.addr_bytes[0];
-	*((uint64_t *)d_addr_bytes) = 0x000000000002 + ((uint64_t)dst_port << 40);
-
-	/* src addr */
-	ether_addr_copy(&ports_eth_addr[dst_port], &eth_hdr->s_addr);
-
-	send_single_packet(m, dst_port);
-}
-
-/* main processing loop */
-static int
-main_loop(__attribute__((unused)) void *dummy)
-{
-	struct rte_mbuf *pkts_burst[MAX_PKT_BURST];
-	unsigned lcore_id;
-	uint64_t diff_tsc, cur_tsc, prev_tsc;
-	int i, j, nb_rx;
-	uint16_t portid;
-	struct lcore_queue_conf *qconf;
-	const uint64_t drain_tsc = (rte_get_tsc_hz() + US_PER_S - 1) / US_PER_S * BURST_TX_DRAIN_US;
-
-	prev_tsc = 0;
-
-	lcore_id = rte_lcore_id();
-	qconf = &lcore_queue_conf[lcore_id];
-
-	if (qconf->n_rx_queue == 0) {
-		RTE_LOG(INFO, IP_RSMBL, "lcore %u has nothing to do\n", lcore_id);
-		return 0;
-	}
-
-	RTE_LOG(INFO, IP_RSMBL, "entering main loop on lcore %u\n", lcore_id);
-
-	for (i = 0; i < qconf->n_rx_queue; i++) {
-
-		portid = qconf->rx_queue_list[i].portid;
-		RTE_LOG(INFO, IP_RSMBL, " -- lcoreid=%u portid=%u\n", lcore_id,
-			portid);
-	}
-
-	while (1) {
-
-		cur_tsc = rte_rdtsc();
-
-		/*
-		 * TX burst queue drain
-		 */
-		diff_tsc = cur_tsc - prev_tsc;
-		if (unlikely(diff_tsc > drain_tsc)) {
-
-			/*
-			 * This could be optimized (use queueid instead of
-			 * portid), but it is not called so often
-			 */
-			for (portid = 0; portid < RTE_MAX_ETHPORTS; portid++) {
-				if ((enabled_port_mask & (1 << portid)) != 0)
-					send_burst(qconf, 1, portid);
-			}
-
-			prev_tsc = cur_tsc;
-		}
-
-		/*
-		 * Read packet from RX queues
-		 */
-		for (i = 0; i < qconf->n_rx_queue; ++i) {
-
-			portid = qconf->rx_queue_list[i].portid;
-
-			nb_rx = rte_eth_rx_burst(portid, 0, pkts_burst,
-				MAX_PKT_BURST);
-
-			/* Prefetch first packets */
-			for (j = 0; j < PREFETCH_OFFSET && j < nb_rx; j++) {
-				rte_prefetch0(rte_pktmbuf_mtod(
-						pkts_burst[j], void *));
-			}
-
-			/* Prefetch and forward already prefetched packets */
-			for (j = 0; j < (nb_rx - PREFETCH_OFFSET); j++) {
-				rte_prefetch0(rte_pktmbuf_mtod(pkts_burst[
-					j + PREFETCH_OFFSET], void *));
-				reassemble(pkts_burst[j], portid,
-					i, qconf, cur_tsc);
-			}
-
-			/* Forward remaining prefetched packets */
-			for (; j < nb_rx; j++) {
-				reassemble(pkts_burst[j], portid,
-					i, qconf, cur_tsc);
-			}
-
-			rte_ip_frag_free_death_row(&qconf->death_row,
-				PREFETCH_OFFSET);
-		}
-	}
-}
-
-/* display usage */
-static void
-print_usage(const char *prgname)
-{
-	printf("%s [EAL options] -- -p PORTMASK [-q NQ]"
-		"  [--max-pkt-len PKTLEN]"
-		"  [--maxflows=<flows>]  [--flowttl=<ttl>[(s|ms)]]\n"
-		"  -p PORTMASK: hexadecimal bitmask of ports to configure\n"
-		"  -q NQ: number of RX queues per lcore\n"
-		"  --maxflows=<flows>: optional, maximum number of flows "
-		"supported\n"
-		"  --flowttl=<ttl>[(s|ms)]: optional, maximum TTL for each "
-		"flow\n",
-		prgname);
-}
-
-static uint32_t
-parse_flow_num(const char *str, uint32_t min, uint32_t max, uint32_t *val)
-{
-	char *end;
-	uint64_t v;
-
-	/* parse decimal string */
-	errno = 0;
-	v = strtoul(str, &end, 10);
-	if (errno != 0 || *end != '\0')
-		return -EINVAL;
-
-	if (v < min || v > max)
-		return -EINVAL;
-
-	*val = (uint32_t)v;
-	return 0;
-}
-
-static int
-parse_flow_ttl(const char *str, uint32_t min, uint32_t max, uint32_t *val)
-{
-	char *end;
-	uint64_t v;
-
-	static const char frmt_sec[] = "s";
-	static const char frmt_msec[] = "ms";
-
-	/* parse decimal string */
-	errno = 0;
-	v = strtoul(str, &end, 10);
-	if (errno != 0)
-		return -EINVAL;
-
-	if (*end != '\0') {
-		if (strncmp(frmt_sec, end, sizeof(frmt_sec)) == 0)
-			v *= MS_PER_S;
-		else if (strncmp(frmt_msec, end, sizeof (frmt_msec)) != 0)
-			return -EINVAL;
-	}
-
-	if (v < min || v > max)
-		return -EINVAL;
-
-	*val = (uint32_t)v;
-	return 0;
-}
-
-static int
-parse_portmask(const char *portmask)
-{
-	char *end = NULL;
-	unsigned long pm;
-
-	/* parse hexadecimal string */
-	pm = strtoul(portmask, &end, 16);
-	if ((portmask[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (pm == 0)
-		return -1;
-
-	return pm;
-}
-
-static int
-parse_nqueue(const char *q_arg)
-{
-	char *end = NULL;
-	unsigned long n;
-
-	printf("%p\n", q_arg);
-
-	/* parse hexadecimal string */
-	n = strtoul(q_arg, &end, 10);
-	if ((q_arg[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-	if (n == 0)
-		return -1;
-	if (n >= MAX_RX_QUEUE_PER_LCORE)
-		return -1;
-
-	return n;
-}
-
-/* Parse the argument given in the command line of the application */
-static int
-parse_args(int argc, char **argv)
-{
-	int opt, ret;
-	char **argvopt;
-	int option_index;
-	char *prgname = argv[0];
-	static struct option lgopts[] = {
-		{"max-pkt-len", 1, 0, 0},
-		{"maxflows", 1, 0, 0},
-		{"flowttl", 1, 0, 0},
-		{NULL, 0, 0, 0}
-	};
-
-	argvopt = argv;
-
-	while ((opt = getopt_long(argc, argvopt, "p:q:",
-				lgopts, &option_index)) != EOF) {
-
-		switch (opt) {
-		/* portmask */
-		case 'p':
-			enabled_port_mask = parse_portmask(optarg);
-			if (enabled_port_mask == 0) {
-				printf("invalid portmask\n");
-				print_usage(prgname);
-				return -1;
-			}
-			break;
-
-		/* nqueue */
-		case 'q':
-			rx_queue_per_lcore = parse_nqueue(optarg);
-			if (rx_queue_per_lcore < 0) {
-				printf("invalid queue number\n");
-				print_usage(prgname);
-				return -1;
-			}
-			break;
-
-		/* long options */
-		case 0:
-			if (!strncmp(lgopts[option_index].name,
-					"maxflows", 8)) {
-				if ((ret = parse_flow_num(optarg, MIN_FLOW_NUM,
-						MAX_FLOW_NUM,
-						&max_flow_num)) != 0) {
-					printf("invalid value: \"%s\" for "
-						"parameter %s\n",
-						optarg,
-						lgopts[option_index].name);
-					print_usage(prgname);
-					return ret;
-				}
-			}
-
-			if (!strncmp(lgopts[option_index].name, "flowttl", 7)) {
-				if ((ret = parse_flow_ttl(optarg, MIN_FLOW_TTL,
-						MAX_FLOW_TTL,
-						&max_flow_ttl)) != 0) {
-					printf("invalid value: \"%s\" for "
-						"parameter %s\n",
-						optarg,
-						lgopts[option_index].name);
-					print_usage(prgname);
-					return ret;
-				}
-			}
-
-			break;
-
-		default:
-			print_usage(prgname);
-			return -1;
-		}
-	}
-
-	if (optind >= 0)
-		argv[optind-1] = prgname;
-
-	ret = optind-1;
-	optind = 1; /* reset getopt lib */
-	return ret;
-}
-
-static void
-print_ethaddr(const char *name, const struct ether_addr *eth_addr)
-{
-	char buf[ETHER_ADDR_FMT_SIZE];
-	ether_format_addr(buf, ETHER_ADDR_FMT_SIZE, eth_addr);
-	printf("%s%s", name, buf);
-}
-
-/* Check the link status of all ports in up to 9s, and print them finally */
-static void
-check_all_ports_link_status(uint32_t port_mask)
-{
-#define CHECK_INTERVAL 100 /* 100ms */
-#define MAX_CHECK_TIME 90 /* 9s (90 * 100ms) in total */
-	uint16_t portid;
-	uint8_t count, all_ports_up, print_flag = 0;
-	struct rte_eth_link link;
-
-	printf("\nChecking link status");
-	fflush(stdout);
-	for (count = 0; count <= MAX_CHECK_TIME; count++) {
-		all_ports_up = 1;
-		RTE_ETH_FOREACH_DEV(portid) {
-			if ((port_mask & (1 << portid)) == 0)
-				continue;
-			memset(&link, 0, sizeof(link));
-			rte_eth_link_get_nowait(portid, &link);
-			/* print link status if flag set */
-			if (print_flag == 1) {
-				if (link.link_status)
-					printf(
-					"Port%d Link Up. Speed %u Mbps - %s\n",
-						portid, link.link_speed,
-				(link.link_duplex == ETH_LINK_FULL_DUPLEX) ?
-					("full-duplex") : ("half-duplex\n"));
-				else
-					printf("Port %d Link Down\n", portid);
-				continue;
-			}
-			/* clear all_ports_up flag if any link down */
-			if (link.link_status == ETH_LINK_DOWN) {
-				all_ports_up = 0;
-				break;
-			}
-		}
-		/* after finally printing all link status, get out */
-		if (print_flag == 1)
-			break;
-
-		if (all_ports_up == 0) {
-			printf(".");
-			fflush(stdout);
-			rte_delay_ms(CHECK_INTERVAL);
-		}
-
-		/* set the print_flag if all ports up or timeout */
-		if (all_ports_up == 1 || count == (MAX_CHECK_TIME - 1)) {
-			print_flag = 1;
-			printf("\ndone\n");
-		}
-	}
-}
-
-static int
-init_routing_table(void)
-{
-	struct rte_lpm *lpm;
-	struct rte_lpm6 *lpm6;
-	int socket, ret;
-	unsigned i;
-
-	for (socket = 0; socket < RTE_MAX_NUMA_NODES; socket++) {
-		if (socket_lpm[socket]) {
-			lpm = socket_lpm[socket];
-			/* populate the LPM table */
-			for (i = 0; i < RTE_DIM(l3fwd_ipv4_route_array); i++) {
-				ret = rte_lpm_add(lpm,
-					l3fwd_ipv4_route_array[i].ip,
-					l3fwd_ipv4_route_array[i].depth,
-					l3fwd_ipv4_route_array[i].if_out);
-
-				if (ret < 0) {
-					RTE_LOG(ERR, IP_RSMBL, "Unable to add entry %i to the l3fwd "
-						"LPM table\n", i);
-					return -1;
-				}
-
-				RTE_LOG(INFO, IP_RSMBL, "Socket %i: adding route " IPv4_BYTES_FMT
-						"/%d (port %d)\n",
-					socket,
-					IPv4_BYTES(l3fwd_ipv4_route_array[i].ip),
-					l3fwd_ipv4_route_array[i].depth,
-					l3fwd_ipv4_route_array[i].if_out);
-			}
-		}
-
-		if (socket_lpm6[socket]) {
-			lpm6 = socket_lpm6[socket];
-			/* populate the LPM6 table */
-			for (i = 0; i < RTE_DIM(l3fwd_ipv6_route_array); i++) {
-				ret = rte_lpm6_add(lpm6,
-					l3fwd_ipv6_route_array[i].ip,
-					l3fwd_ipv6_route_array[i].depth,
-					l3fwd_ipv6_route_array[i].if_out);
-
-				if (ret < 0) {
-					RTE_LOG(ERR, IP_RSMBL, "Unable to add entry %i to the l3fwd "
-						"LPM6 table\n", i);
-					return -1;
-				}
-
-				RTE_LOG(INFO, IP_RSMBL, "Socket %i: adding route " IPv6_BYTES_FMT
-						"/%d (port %d)\n",
-					socket,
-					IPv6_BYTES(l3fwd_ipv6_route_array[i].ip),
-					l3fwd_ipv6_route_array[i].depth,
-					l3fwd_ipv6_route_array[i].if_out);
-			}
-		}
-	}
-	return 0;
-}
-
-static int
-setup_port_tbl(struct lcore_queue_conf *qconf, uint32_t lcore, int socket,
-	uint32_t port)
-{
-	struct mbuf_table *mtb;
-	uint32_t n;
-	size_t sz;
-
-	n = RTE_MAX(max_flow_num, 2UL * MAX_PKT_BURST);
-	sz = sizeof (*mtb) + sizeof (mtb->m_table[0]) *  n;
-
-	if ((mtb = rte_zmalloc_socket(__func__, sz, RTE_CACHE_LINE_SIZE,
-			socket)) == NULL) {
-		RTE_LOG(ERR, IP_RSMBL, "%s() for lcore: %u, port: %u "
-			"failed to allocate %zu bytes\n",
-			__func__, lcore, port, sz);
-		return -1;
-	}
-
-	mtb->len = n;
-	qconf->tx_mbufs[port] = mtb;
-
-	return 0;
-}
-
-static int
-setup_queue_tbl(struct rx_queue *rxq, uint32_t lcore, uint32_t queue)
-{
-	int socket;
-	uint32_t nb_mbuf;
-	uint64_t frag_cycles;
-	char buf[RTE_MEMPOOL_NAMESIZE];
-
-	socket = rte_lcore_to_socket_id(lcore);
-	if (socket == SOCKET_ID_ANY)
-		socket = 0;
-
-	frag_cycles = (rte_get_tsc_hz() + MS_PER_S - 1) / MS_PER_S *
-		max_flow_ttl;
-
-	if ((rxq->frag_tbl = rte_ip_frag_table_create(max_flow_num,
-			IP_FRAG_TBL_BUCKET_ENTRIES, max_flow_num, frag_cycles,
-			socket)) == NULL) {
-		RTE_LOG(ERR, IP_RSMBL, "ip_frag_tbl_create(%u) on "
-			"lcore: %u for queue: %u failed\n",
-			max_flow_num, lcore, queue);
-		return -1;
-	}
-
-	/*
-	 * At any given moment up to <max_flow_num * (MAX_FRAG_NUM)>
-	 * mbufs could be stored int the fragment table.
-	 * Plus, each TX queue can hold up to <max_flow_num> packets.
-	 */
-
-	nb_mbuf = RTE_MAX(max_flow_num, 2UL * MAX_PKT_BURST) * MAX_FRAG_NUM;
-	nb_mbuf *= (port_conf.rxmode.max_rx_pkt_len + BUF_SIZE - 1) / BUF_SIZE;
-	nb_mbuf *= 2; /* ipv4 and ipv6 */
-	nb_mbuf += nb_rxd + nb_txd;
-
-	nb_mbuf = RTE_MAX(nb_mbuf, (uint32_t)NB_MBUF);
-
-	snprintf(buf, sizeof(buf), "mbuf_pool_%u_%u", lcore, queue);
-
-	rxq->pool = rte_pktmbuf_pool_create(buf, nb_mbuf, MEMPOOL_CACHE_SIZE, 0,
-					    MBUF_DATA_SIZE, socket);
-	if (rxq->pool == NULL) {
-		RTE_LOG(ERR, IP_RSMBL,
-			"rte_pktmbuf_pool_create(%s) failed", buf);
-		return -1;
-	}
-
-	return 0;
-}
-
-static int
-init_mem(void)
-{
-	char buf[PATH_MAX];
-	struct rte_lpm *lpm;
-	struct rte_lpm6 *lpm6;
-	struct rte_lpm_config lpm_config;
-	int socket;
-	unsigned lcore_id;
-
-	/* traverse through lcores and initialize structures on each socket */
-
-	for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-
-		if (rte_lcore_is_enabled(lcore_id) == 0)
-			continue;
-
-		socket = rte_lcore_to_socket_id(lcore_id);
-
-		if (socket == SOCKET_ID_ANY)
-			socket = 0;
-
-		if (socket_lpm[socket] == NULL) {
-			RTE_LOG(INFO, IP_RSMBL, "Creating LPM table on socket %i\n", socket);
-			snprintf(buf, sizeof(buf), "IP_RSMBL_LPM_%i", socket);
-
-			lpm_config.max_rules = LPM_MAX_RULES;
-			lpm_config.number_tbl8s = 256;
-			lpm_config.flags = 0;
-
-			lpm = rte_lpm_create(buf, socket, &lpm_config);
-			if (lpm == NULL) {
-				RTE_LOG(ERR, IP_RSMBL, "Cannot create LPM table\n");
-				return -1;
-			}
-			socket_lpm[socket] = lpm;
-		}
-
-		if (socket_lpm6[socket] == NULL) {
-			RTE_LOG(INFO, IP_RSMBL, "Creating LPM6 table on socket %i\n", socket);
-			snprintf(buf, sizeof(buf), "IP_RSMBL_LPM_%i", socket);
-
-			lpm6 = rte_lpm6_create(buf, socket, &lpm6_config);
-			if (lpm6 == NULL) {
-				RTE_LOG(ERR, IP_RSMBL, "Cannot create LPM table\n");
-				return -1;
-			}
-			socket_lpm6[socket] = lpm6;
-		}
-	}
-
-	return 0;
-}
-
-static void
-queue_dump_stat(void)
-{
-	uint32_t i, lcore;
-	const struct lcore_queue_conf *qconf;
-
-	for (lcore = 0; lcore < RTE_MAX_LCORE; lcore++) {
-		if (rte_lcore_is_enabled(lcore) == 0)
-			continue;
-
-		qconf = &lcore_queue_conf[lcore];
-		for (i = 0; i < qconf->n_rx_queue; i++) {
-
-			fprintf(stdout, " -- lcoreid=%u portid=%u "
-				"frag tbl stat:\n",
-				lcore,  qconf->rx_queue_list[i].portid);
-			rte_ip_frag_table_statistics_dump(stdout,
-					qconf->rx_queue_list[i].frag_tbl);
-			fprintf(stdout, "TX bursts:\t%" PRIu64 "\n"
-				"TX packets _queued:\t%" PRIu64 "\n"
-				"TX packets dropped:\t%" PRIu64 "\n"
-				"TX packets send:\t%" PRIu64 "\n",
-				qconf->tx_stat.call,
-				qconf->tx_stat.queue,
-				qconf->tx_stat.drop,
-				qconf->tx_stat.send);
-		}
-	}
-}
-
-static void
-signal_handler(int signum)
-{
-	queue_dump_stat();
-	if (signum != SIGUSR1)
-		rte_exit(0, "received signal: %d, exiting\n", signum);
-}
-
-int
-main(int argc, char **argv)
-{
-	struct lcore_queue_conf *qconf;
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_txconf *txconf;
-	struct rx_queue *rxq;
-	int ret, socket;
-	unsigned nb_ports;
-	uint16_t queueid;
-	unsigned lcore_id = 0, rx_lcore_id = 0;
-	uint32_t n_tx_queue, nb_lcores;
-	uint16_t portid;
-
-	/* init EAL */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid EAL parameters\n");
-	argc -= ret;
-	argv += ret;
-
-	/* parse application arguments (after the EAL ones) */
-	ret = parse_args(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid IP reassembly parameters\n");
-
-	nb_ports = rte_eth_dev_count();
-	if (nb_ports == 0)
-		rte_exit(EXIT_FAILURE, "No ports found!\n");
-
-	nb_lcores = rte_lcore_count();
-
-	/* initialize structures (mempools, lpm etc.) */
-	if (init_mem() < 0)
-		rte_panic("Cannot initialize memory structures!\n");
-
-	/* check if portmask has non-existent ports */
-	if (enabled_port_mask & ~(RTE_LEN2MASK(nb_ports, unsigned)))
-		rte_exit(EXIT_FAILURE, "Non-existent ports in portmask!\n");
-
-	/* initialize all ports */
-	RTE_ETH_FOREACH_DEV(portid) {
-		struct rte_eth_rxconf rxq_conf;
-		struct rte_eth_conf local_port_conf = port_conf;
-
-		/* skip ports that are not enabled */
-		if ((enabled_port_mask & (1 << portid)) == 0) {
-			printf("\nSkipping disabled port %d\n", portid);
-			continue;
-		}
-
-		qconf = &lcore_queue_conf[rx_lcore_id];
-
-		/* limit the frame size to the maximum supported by NIC */
-		rte_eth_dev_info_get(portid, &dev_info);
-		local_port_conf.rxmode.max_rx_pkt_len = RTE_MIN(
-		    dev_info.max_rx_pktlen,
-		    local_port_conf.rxmode.max_rx_pkt_len);
-
-		/* get the lcore_id for this port */
-		while (rte_lcore_is_enabled(rx_lcore_id) == 0 ||
-			   qconf->n_rx_queue == (unsigned)rx_queue_per_lcore) {
-
-			rx_lcore_id++;
-			if (rx_lcore_id >= RTE_MAX_LCORE)
-				rte_exit(EXIT_FAILURE, "Not enough cores\n");
-
-			qconf = &lcore_queue_conf[rx_lcore_id];
-		}
-
-		socket = rte_lcore_to_socket_id(portid);
-		if (socket == SOCKET_ID_ANY)
-			socket = 0;
-
-		queueid = qconf->n_rx_queue;
-		rxq = &qconf->rx_queue_list[queueid];
-		rxq->portid = portid;
-		rxq->lpm = socket_lpm[socket];
-		rxq->lpm6 = socket_lpm6[socket];
-
-		ret = rte_eth_dev_adjust_nb_rx_tx_desc(portid, &nb_rxd,
-						       &nb_txd);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-				 "Cannot adjust number of descriptors: err=%d, port=%d\n",
-				 ret, portid);
-
-		if (setup_queue_tbl(rxq, rx_lcore_id, queueid) < 0)
-			rte_exit(EXIT_FAILURE, "Failed to set up queue table\n");
-		qconf->n_rx_queue++;
-
-		/* init port */
-		printf("Initializing port %d ... ", portid );
-		fflush(stdout);
-
-		n_tx_queue = nb_lcores;
-		if (n_tx_queue > MAX_TX_QUEUE_PER_PORT)
-			n_tx_queue = MAX_TX_QUEUE_PER_PORT;
-		if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-			local_port_conf.txmode.offloads |=
-				DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-		ret = rte_eth_dev_configure(portid, 1, (uint16_t)n_tx_queue,
-					    &local_port_conf);
-		if (ret < 0) {
-			printf("\n");
-			rte_exit(EXIT_FAILURE, "Cannot configure device: "
-				"err=%d, port=%d\n",
-				ret, portid);
-		}
-
-		/* init one RX queue */
-		rxq_conf = dev_info.default_rxconf;
-		rxq_conf.offloads = local_port_conf.rxmode.offloads;
-		ret = rte_eth_rx_queue_setup(portid, 0, nb_rxd,
-					     socket, &rxq_conf,
-					     rxq->pool);
-		if (ret < 0) {
-			printf("\n");
-			rte_exit(EXIT_FAILURE, "rte_eth_rx_queue_setup: "
-				"err=%d, port=%d\n",
-				ret, portid);
-		}
-
-		rte_eth_macaddr_get(portid, &ports_eth_addr[portid]);
-		print_ethaddr(" Address:", &ports_eth_addr[portid]);
-		printf("\n");
-
-		/* init one TX queue per couple (lcore,port) */
-		queueid = 0;
-		for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-			if (rte_lcore_is_enabled(lcore_id) == 0)
-				continue;
-
-			socket = (int) rte_lcore_to_socket_id(lcore_id);
-
-			printf("txq=%u,%d,%d ", lcore_id, queueid, socket);
-			fflush(stdout);
-
-			txconf = &dev_info.default_txconf;
-			txconf->txq_flags = ETH_TXQ_FLAGS_IGNORE;
-			txconf->offloads = local_port_conf.txmode.offloads;
-
-			ret = rte_eth_tx_queue_setup(portid, queueid, nb_txd,
-					socket, txconf);
-			if (ret < 0)
-				rte_exit(EXIT_FAILURE, "rte_eth_tx_queue_setup: err=%d, "
-					"port=%d\n", ret, portid);
-
-			qconf = &lcore_queue_conf[lcore_id];
-			qconf->tx_queue_id[portid] = queueid;
-			setup_port_tbl(qconf, lcore_id, socket, portid);
-			queueid++;
-		}
-		printf("\n");
-	}
-
-	printf("\n");
-
-	/* start ports */
-	RTE_ETH_FOREACH_DEV(portid) {
-		if ((enabled_port_mask & (1 << portid)) == 0) {
-			continue;
-		}
-		/* Start device */
-		ret = rte_eth_dev_start(portid);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "rte_eth_dev_start: err=%d, port=%d\n",
-				ret, portid);
-
-		rte_eth_promiscuous_enable(portid);
-	}
-
-	if (init_routing_table() < 0)
-		rte_exit(EXIT_FAILURE, "Cannot init routing table\n");
-
-	check_all_ports_link_status(enabled_port_mask);
-
-	signal(SIGUSR1, signal_handler);
-	signal(SIGTERM, signal_handler);
-	signal(SIGINT, signal_handler);
-
-	/* launch per-lcore init on every lcore */
-	rte_eal_mp_remote_launch(main_loop, NULL, CALL_MASTER);
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		if (rte_eal_wait_lcore(lcore_id) < 0)
-			return -1;
-	}
-
-	return 0;
-}
diff --git a/examples/ip_reassembly/meson.build b/examples/ip_reassembly/meson.build
deleted file mode 100644
index 8a667c2..0000000
--- a/examples/ip_reassembly/meson.build
+++ /dev/null
@@ -1,13 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-deps += ['lpm', 'ip_frag']
-allow_experimental_apis = true
-sources = files(
-	'main.c'
-)
diff --git a/examples/ipsec-secgw/Makefile b/examples/ipsec-secgw/Makefile
deleted file mode 100644
index 02d41e3..0000000
--- a/examples/ipsec-secgw/Makefile
+++ /dev/null
@@ -1,82 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2016 Intel Corporation
-
-APP = ipsec-secgw
-
-#
-# all source are stored in SRCS-y
-#
-SRCS-y += parser.c
-SRCS-y += ipsec.c
-SRCS-y += esp.c
-SRCS-y += sp4.c
-SRCS-y += sp6.c
-SRCS-y += sa.c
-SRCS-y += rt.c
-SRCS-y += ipsec-secgw.c
-
-CFLAGS += -gdwarf-2
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else
-
-ifeq ($(RTE_SDK),)
-	$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-ifneq ($(MAKECMDGOALS),clean)
-ifneq ($(CONFIG_RTE_LIBRTE_SECURITY),y)
-$(error "RTE_LIBRTE_SECURITY is required to build ipsec-secgw")
-endif
-endif
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -O3 -gdwarf-2
-CFLAGS += $(WERROR_FLAGS)
-ifeq ($(CONFIG_RTE_TOOLCHAIN_ICC),y)
-CFLAGS_sa.o += -diag-disable=vec
-endif
-
-ifeq ($(DEBUG),1)
-CFLAGS += -DIPSEC_DEBUG -fstack-protector-all -O0
-endif
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-
-endif
diff --git a/examples/ipsec-secgw/ep0.cfg b/examples/ipsec-secgw/ep0.cfg
deleted file mode 100644
index 299aa9e..0000000
--- a/examples/ipsec-secgw/ep0.cfg
+++ /dev/null
@@ -1,160 +0,0 @@
-###########################################################################
-#   IPSEC-SECGW Endpoint sample configuration
-#
-#   The main purpose of this file is to show how to configure two systems
-#   back-to-back that would forward traffic through an IPsec tunnel. This
-#   file is the Endpoint 0 configuration. To use this configuration file,
-#   add the following command-line option:
-#
-#       -f ./ep0.cfg
-#
-###########################################################################
-
-#SP IPv4 rules
-sp ipv4 out esp protect 5 pri 1 dst 192.168.105.0/24 sport 0:65535 dport 0:65535
-sp ipv4 out esp protect 6 pri 1 dst 192.168.106.0/24 sport 0:65535 dport 0:65535
-sp ipv4 out esp protect 10 pri 1 dst 192.168.175.0/24 sport 0:65535 dport 0:65535
-sp ipv4 out esp protect 11 pri 1 dst 192.168.176.0/24 sport 0:65535 dport 0:65535
-sp ipv4 out esp protect 15 pri 1 dst 192.168.200.0/24 sport 0:65535 dport 0:65535
-sp ipv4 out esp protect 16 pri 1 dst 192.168.201.0/24 sport 0:65535 dport 0:65535
-sp ipv4 out esp protect 25 pri 1 dst 192.168.55.0/24 sport 0:65535 dport 0:65535
-sp ipv4 out esp protect 26 pri 1 dst 192.168.56.0/24 sport 0:65535 dport 0:65535
-sp ipv4 out esp bypass pri 1 dst 192.168.240.0/24 sport 0:65535 dport 0:65535
-sp ipv4 out esp bypass pri 1 dst 192.168.241.0/24 sport 0:65535 dport 0:65535
-
-sp ipv4 in esp protect 105 pri 1 dst 192.168.115.0/24 sport 0:65535 dport 0:65535
-sp ipv4 in esp protect 106 pri 1 dst 192.168.116.0/24 sport 0:65535 dport 0:65535
-sp ipv4 in esp protect 110 pri 1 dst 192.168.185.0/24 sport 0:65535 dport 0:65535
-sp ipv4 in esp protect 111 pri 1 dst 192.168.186.0/24 sport 0:65535 dport 0:65535
-sp ipv4 in esp protect 115 pri 1 dst 192.168.210.0/24 sport 0:65535 dport 0:65535
-sp ipv4 in esp protect 116 pri 1 dst 192.168.211.0/24 sport 0:65535 dport 0:65535
-sp ipv4 in esp protect 115 pri 1 dst 192.168.210.0/24 sport 0:65535 dport 0:65535
-sp ipv4 in esp protect 125 pri 1 dst 192.168.65.0/24 sport 0:65535 dport 0:65535
-sp ipv4 in esp protect 125 pri 1 dst 192.168.65.0/24 sport 0:65535 dport 0:65535
-sp ipv4 in esp protect 126 pri 1 dst 192.168.66.0/24 sport 0:65535 dport 0:65535
-sp ipv4 in esp bypass pri 1 dst 192.168.245.0/24 sport 0:65535 dport 0:65535
-sp ipv4 in esp bypass pri 1 dst 192.168.246.0/24 sport 0:65535 dport 0:65535
-
-#SP IPv6 rules
-sp ipv6 out esp protect 5 pri 1 dst 0000:0000:0000:0000:5555:5555:0000:0000/96 \
-sport 0:65535 dport 0:65535
-sp ipv6 out esp protect 6 pri 1 dst 0000:0000:0000:0000:6666:6666:0000:0000/96 \
-sport 0:65535 dport 0:65535
-sp ipv6 out esp protect 10 pri 1 dst 0000:0000:1111:1111:0000:0000:0000:0000/96 \
-sport 0:65535 dport 0:65535
-sp ipv6 out esp protect 11 pri 1 dst 0000:0000:1111:1111:1111:1111:0000:0000/96 \
-sport 0:65535 dport 0:65535
-sp ipv6 out esp protect 25 pri 1 dst 0000:0000:0000:0000:aaaa:aaaa:0000:0000/96 \
-sport 0:65535 dport 0:65535
-sp ipv6 out esp protect 26 pri 1 dst 0000:0000:0000:0000:bbbb:bbbb:0000:0000/96 \
-sport 0:65535 dport 0:65535
-
-sp ipv6 in esp protect 15 pri 1 dst ffff:0000:0000:0000:5555:5555:0000:0000/96 \
-sport 0:65535 dport 0:65535
-sp ipv6 in esp protect 16 pri 1 dst ffff:0000:0000:0000:6666:6666:0000:0000/96 \
-sport 0:65535 dport 0:65535
-sp ipv6 in esp protect 110 pri 1 dst ffff:0000:1111:1111:0000:0000:0000:0000/96 \
-sport 0:65535 dport 0:65535
-sp ipv6 in esp protect 111 pri 1 dst ffff:0000:1111:1111:1111:1111:0000:0000/96 \
-sport 0:65535 dport 0:65535
-sp ipv6 in esp protect 125 pri 1 dst ffff:0000:0000:0000:aaaa:aaaa:0000:0000/96 \
-sport 0:65535 dport 0:65535
-sp ipv6 in esp protect 126 pri 1 dst ffff:0000:0000:0000:bbbb:bbbb:0000:0000/96 \
-sport 0:65535 dport 0:65535
-
-#SA rules
-sa out 5 cipher_algo aes-128-cbc cipher_key 0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0 \
-auth_algo sha1-hmac auth_key 0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0 \
-mode ipv4-tunnel src 172.16.1.5 dst 172.16.2.5
-
-sa out 6 cipher_algo aes-128-cbc cipher_key a0:a0:a0:a0:a0:a0:a0:a0:a0:a0:a0:\
-a0:a0:a0:a0:a0 auth_algo sha1-hmac auth_key a0:a0:a0:a0:a0:a0:a0:a0:a0:a0:a0:\
-a0:a0:a0:a0:a0:a0:a0:a0:a0 mode ipv4-tunnel src 172.16.1.6 dst 172.16.2.6
-
-sa out 10 cipher_algo aes-128-cbc cipher_key a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:\
-a1:a1:a1:a1:a1 auth_algo sha1-hmac auth_key a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:\
-a1:a1:a1:a1:a1:a1:a1:a1:a1 mode transport
-
-sa out 11 cipher_algo aes-128-cbc cipher_key b2:b2:b2:b2:b2:b2:b2:b2:b2:b2:b2:\
-b2:b2:b2:b2:b2 auth_algo sha1-hmac auth_key b2:b2:b2:b2:b2:b2:b2:b2:b2:b2:b2:\
-b2:b2:b2:b2:b2:b2:b2:b2:b2 mode transport
-
-sa out 15 cipher_algo null auth_algo null mode ipv4-tunnel src 172.16.1.5 \
-dst 172.16.2.5
-
-sa out 16 cipher_algo null auth_algo null mode ipv4-tunnel src 172.16.1.6 \
-dst 172.16.2.6
-
-sa out 25 cipher_algo aes-128-cbc cipher_key c3:c3:c3:c3:c3:c3:c3:c3:c3:c3:c3:\
-c3:c3:c3:c3:c3 auth_algo sha1-hmac auth_key c3:c3:c3:c3:c3:c3:c3:c3:c3:c3:c3:\
-c3:c3:c3:c3:c3:c3:c3:c3:c3 mode ipv6-tunnel \
-src 1111:1111:1111:1111:1111:1111:1111:5555 \
-dst 2222:2222:2222:2222:2222:2222:2222:5555
-
-sa out 26 cipher_algo aes-128-cbc cipher_key 4d:4d:4d:4d:4d:4d:4d:4d:4d:4d:4d:\
-4d:4d:4d:4d:4d auth_algo sha1-hmac auth_key 4d:4d:4d:4d:4d:4d:4d:4d:4d:4d:4d:\
-4d:4d:4d:4d:4d:4d:4d:4d:4d mode ipv6-tunnel \
-src 1111:1111:1111:1111:1111:1111:1111:6666 \
-dst 2222:2222:2222:2222:2222:2222:2222:6666
-
-sa in 105 cipher_algo aes-128-cbc cipher_key 0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0 \
-auth_algo sha1-hmac auth_key 0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0 \
-mode ipv4-tunnel src 172.16.2.5 dst 172.16.1.5
-
-sa in 106 cipher_algo aes-128-cbc cipher_key a0:a0:a0:a0:a0:a0:a0:a0:a0:a0:a0:\
-a0:a0:a0:a0:a0 auth_algo sha1-hmac auth_key a0:a0:a0:a0:a0:a0:a0:a0:a0:a0:a0:\
-a0:a0:a0:a0:a0:a0:a0:a0:a0 mode ipv4-tunnel src 172.16.2.6 dst 172.16.1.6
-
-sa in 110 cipher_algo aes-128-cbc cipher_key a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:\
-a1:a1:a1:a1:a1 auth_algo sha1-hmac auth_key a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:\
-a1:a1:a1:a1:a1:a1:a1:a1:a1 mode transport
-
-sa in 111 cipher_algo aes-128-cbc cipher_key b2:b2:b2:b2:b2:b2:b2:b2:b2:b2:b2:\
-b2:b2:b2:b2:b2 auth_algo sha1-hmac auth_key b2:b2:b2:b2:b2:b2:b2:b2:b2:b2:b2:\
-b2:b2:b2:b2:b2:b2:b2:b2:b2 mode transport
-
-sa in 115 cipher_algo null auth_algo null mode ipv4-tunnel src 172.16.2.5 \
-dst 172.16.1.5
-
-sa in 116 cipher_algo null auth_algo null mode ipv4-tunnel src 172.16.2.6 dst 172.16.1.6
-
-sa in 125 cipher_algo aes-128-cbc cipher_key c3:c3:c3:c3:c3:c3:c3:c3:c3:c3:c3:\
-c3:c3:c3:c3:c3 auth_algo sha1-hmac auth_key c3:c3:c3:c3:c3:c3:c3:c3:c3:c3:c3:\
-c3:c3:c3:c3:c3:c3:c3:c3:c3 mode ipv6-tunnel \
-src 2222:2222:2222:2222:2222:2222:2222:5555 \
-dst 1111:1111:1111:1111:1111:1111:1111:5555
-
-sa in 126 cipher_algo aes-128-cbc cipher_key 4d:4d:4d:4d:4d:4d:4d:4d:4d:4d:4d:\
-4d:4d:4d:4d:4d auth_algo sha1-hmac auth_key 4d:4d:4d:4d:4d:4d:4d:4d:4d:4d:4d:\
-4d:4d:4d:4d:4d:4d:4d:4d:4d mode ipv6-tunnel \
-src 2222:2222:2222:2222:2222:2222:2222:6666 \
-dst 1111:1111:1111:1111:1111:1111:1111:6666
-
-#Routing rules
-rt ipv4 dst 172.16.2.5/32 port 0
-rt ipv4 dst 172.16.2.6/32 port 1
-rt ipv4 dst 192.168.175.0/24 port 0
-rt ipv4 dst 192.168.176.0/24 port 1
-rt ipv4 dst 192.168.240.0/24 port 0
-rt ipv4 dst 192.168.241.0/24 port 1
-rt ipv4 dst 192.168.115.0/24 port 2
-rt ipv4 dst 192.168.116.0/24 port 3
-rt ipv4 dst 192.168.65.0/24 port 2
-rt ipv4 dst 192.168.66.0/24 port 3
-rt ipv4 dst 192.168.185.0/24 port 2
-rt ipv4 dst 192.168.186.0/24 port 3
-rt ipv4 dst 192.168.210.0/24 port 2
-rt ipv4 dst 192.168.211.0/24 port 3
-rt ipv4 dst 192.168.245.0/24 port 2
-rt ipv4 dst 192.168.246.0/24 port 3
-
-rt ipv6 dst 2222:2222:2222:2222:2222:2222:2222:5555/116 port 0
-rt ipv6 dst 2222:2222:2222:2222:2222:2222:2222:6666/116 port 1
-rt ipv6 dst 0000:0000:1111:1111:0000:0000:0000:0000/116 port 0
-rt ipv6 dst 0000:0000:1111:1111:1111:1111:0000:0000/116 port 1
-rt ipv6 dst ffff:0000:0000:0000:aaaa:aaaa:0000:0000/116 port 2
-rt ipv6 dst ffff:0000:0000:0000:bbbb:bbbb:0000:0000/116 port 3
-rt ipv6 dst ffff:0000:0000:0000:5555:5555:0000:0000/116 port 2
-rt ipv6 dst ffff:0000:0000:0000:6666:6666:0000:0000/116 port 3
-rt ipv6 dst ffff:0000:1111:1111:0000:0000:0000:0000/116 port 2
-rt ipv6 dst ffff:0000:1111:1111:1111:1111:0000:0000/116 port 3
diff --git a/examples/ipsec-secgw/ep1.cfg b/examples/ipsec-secgw/ep1.cfg
deleted file mode 100644
index 3f6ff81..0000000
--- a/examples/ipsec-secgw/ep1.cfg
+++ /dev/null
@@ -1,160 +0,0 @@
-###########################################################################
-#   IPSEC-SECGW Endpoint1 sample configuration
-#
-#   The main purpose of this file is to show how to configure two systems
-#   back-to-back that would forward traffic through an IPsec tunnel. This
-#   file is the Endpoint1 configuration. To use this configuration file,
-#   add the following command-line option:
-#
-#       -f ./ep1.cfg
-#
-###########################################################################
-
-#SP IPv4 rules
-sp ipv4 in esp protect 5 pri 1 dst 192.168.105.0/24 sport 0:65535 dport 0:65535
-sp ipv4 in esp protect 6 pri 1 dst 192.168.106.0/24 sport 0:65535 dport 0:65535
-sp ipv4 in esp protect 10 pri 1 dst 192.168.175.0/24 sport 0:65535 dport 0:65535
-sp ipv4 in esp protect 11 pri 1 dst 192.168.176.0/24 sport 0:65535 dport 0:65535
-sp ipv4 in esp protect 15 pri 1 dst 192.168.200.0/24 sport 0:65535 dport 0:65535
-sp ipv4 in esp protect 16 pri 1 dst 192.168.201.0/24 sport 0:65535 dport 0:65535
-sp ipv4 in esp protect 25 pri 1 dst 192.168.55.0/24 sport 0:65535 dport 0:65535
-sp ipv4 in esp protect 26 pri 1 dst 192.168.56.0/24 sport 0:65535 dport 0:65535
-sp ipv4 in esp bypass dst 192.168.240.0/24 sport 0:65535 dport 0:65535
-sp ipv4 in esp bypass dst 192.168.241.0/24 sport 0:65535 dport 0:65535
-
-sp ipv4 out esp protect 105 pri 1 dst 192.168.115.0/24 sport 0:65535 dport 0:65535
-sp ipv4 out esp protect 106 pri 1 dst 192.168.116.0/24 sport 0:65535 dport 0:65535
-sp ipv4 out esp protect 110 pri 1 dst 192.168.185.0/24 sport 0:65535 dport 0:65535
-sp ipv4 out esp protect 111 pri 1 dst 192.168.186.0/24 sport 0:65535 dport 0:65535
-sp ipv4 out esp protect 115 pri 1 dst 192.168.210.0/24 sport 0:65535 dport 0:65535
-sp ipv4 out esp protect 116 pri 1 dst 192.168.211.0/24 sport 0:65535 dport 0:65535
-sp ipv4 out esp protect 115 pri 1 dst 192.168.210.0/24 sport 0:65535 dport 0:65535
-sp ipv4 out esp protect 125 pri 1 dst 192.168.65.0/24 sport 0:65535 dport 0:65535
-sp ipv4 out esp protect 125 pri 1 dst 192.168.65.0/24 sport 0:65535 dport 0:65535
-sp ipv4 out esp protect 126 pri 1 dst 192.168.66.0/24 sport 0:65535 dport 0:65535
-sp ipv4 out esp bypass pri 1 dst 192.168.245.0/24 sport 0:65535 dport 0:65535
-sp ipv4 out esp bypass pri 1 dst 192.168.246.0/24 sport 0:65535 dport 0:65535
-
-#SP IPv6 rules
-sp ipv6 in esp protect 5 pri 1 dst 0000:0000:0000:0000:5555:5555:0000:0000/96 \
-sport 0:65535 dport 0:65535
-sp ipv6 in esp protect 6 pri 1 dst 0000:0000:0000:0000:6666:6666:0000:0000/96 \
-sport 0:65535 dport 0:65535
-sp ipv6 in esp protect 10 pri 1 dst 0000:0000:1111:1111:0000:0000:0000:0000/96 \
-sport 0:65535 dport 0:65535
-sp ipv6 in esp protect 11 pri 1 dst 0000:0000:1111:1111:1111:1111:0000:0000/96 \
-sport 0:65535 dport 0:65535
-sp ipv6 in esp protect 25 pri 1 dst 0000:0000:0000:0000:aaaa:aaaa:0000:0000/96 \
-sport 0:65535 dport 0:65535
-sp ipv6 in esp protect 26 pri 1 dst 0000:0000:0000:0000:bbbb:bbbb:0000:0000/96 \
-sport 0:65535 dport 0:65535
-
-sp ipv6 out esp protect 15 pri 1 dst ffff:0000:0000:0000:5555:5555:0000:0000/96 \
-sport 0:65535 dport 0:65535
-sp ipv6 out esp protect 16 pri 1 dst ffff:0000:0000:0000:6666:6666:0000:0000/96 \
-sport 0:65535 dport 0:65535
-sp ipv6 out esp protect 110 pri 1 dst ffff:0000:1111:1111:0000:0000:0000:0000/96 \
-sport 0:65535 dport 0:65535
-sp ipv6 out esp protect 111 pri 1 dst ffff:0000:1111:1111:1111:1111:0000:0000/96 \
-sport 0:65535 dport 0:65535
-sp ipv6 out esp protect 125 pri 1 dst ffff:0000:0000:0000:aaaa:aaaa:0000:0000/96 \
-sport 0:65535 dport 0:65535
-sp ipv6 out esp protect 126 pri 1 dst ffff:0000:0000:0000:bbbb:bbbb:0000:0000/96 \
-sport 0:65535 dport 0:65535
-
-#SA rules
-sa in 5 cipher_algo aes-128-cbc cipher_key 0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0 \
-auth_algo sha1-hmac auth_key 0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0 \
-mode ipv4-tunnel src 172.16.1.5 dst 172.16.2.5
-
-sa in 6 cipher_algo aes-128-cbc cipher_key a0:a0:a0:a0:a0:a0:a0:a0:a0:a0:a0:\
-a0:a0:a0:a0:a0 auth_algo sha1-hmac auth_key a0:a0:a0:a0:a0:a0:a0:a0:a0:a0:a0:\
-a0:a0:a0:a0:a0:a0:a0:a0:a0 mode ipv4-tunnel src 172.16.1.6 dst 172.16.2.6
-
-sa in 10 cipher_algo aes-128-cbc cipher_key a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:\
-a1:a1:a1:a1:a1 auth_algo sha1-hmac auth_key a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:\
-a1:a1:a1:a1:a1:a1:a1:a1:a1 mode transport
-
-sa in 11 cipher_algo aes-128-cbc cipher_key b2:b2:b2:b2:b2:b2:b2:b2:b2:b2:b2:\
-b2:b2:b2:b2:b2 auth_algo sha1-hmac auth_key b2:b2:b2:b2:b2:b2:b2:b2:b2:b2:b2:\
-b2:b2:b2:b2:b2:b2:b2:b2:b2 mode transport
-
-sa in 15 cipher_algo null auth_algo null mode ipv4-tunnel src 172.16.1.5 \
-dst 172.16.2.5
-
-sa in 16 cipher_algo null auth_algo null mode ipv4-tunnel src 172.16.1.6 \
-dst 172.16.2.6
-
-sa in 25 cipher_algo aes-128-cbc cipher_key c3:c3:c3:c3:c3:c3:c3:c3:c3:c3:c3:\
-c3:c3:c3:c3:c3 auth_algo sha1-hmac auth_key c3:c3:c3:c3:c3:c3:c3:c3:c3:c3:c3:\
-c3:c3:c3:c3:c3:c3:c3:c3:c3 mode ipv6-tunnel \
-src 1111:1111:1111:1111:1111:1111:1111:5555 \
-dst 2222:2222:2222:2222:2222:2222:2222:5555
-
-sa in 26 cipher_algo aes-128-cbc cipher_key 4d:4d:4d:4d:4d:4d:4d:4d:4d:4d:4d:\
-4d:4d:4d:4d:4d auth_algo sha1-hmac auth_key 4d:4d:4d:4d:4d:4d:4d:4d:4d:4d:4d:\
-4d:4d:4d:4d:4d:4d:4d:4d:4d mode ipv6-tunnel \
-src 1111:1111:1111:1111:1111:1111:1111:6666 \
-dst 2222:2222:2222:2222:2222:2222:2222:6666
-
-sa out 105 cipher_algo aes-128-cbc cipher_key 0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0 \
-auth_algo sha1-hmac auth_key 0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0 \
-mode ipv4-tunnel src 172.16.2.5 dst 172.16.1.5
-
-sa out 106 cipher_algo aes-128-cbc cipher_key a0:a0:a0:a0:a0:a0:a0:a0:a0:a0:a0:\
-a0:a0:a0:a0:a0 auth_algo sha1-hmac auth_key a0:a0:a0:a0:a0:a0:a0:a0:a0:a0:a0:\
-a0:a0:a0:a0:a0:a0:a0:a0:a0 mode ipv4-tunnel src 172.16.2.6 dst 172.16.1.6
-
-sa out 110 cipher_algo aes-128-cbc cipher_key a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:\
-a1:a1:a1:a1:a1 auth_algo sha1-hmac auth_key a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:\
-a1:a1:a1:a1:a1:a1:a1:a1:a1 mode transport
-
-sa out 111 cipher_algo aes-128-cbc cipher_key b2:b2:b2:b2:b2:b2:b2:b2:b2:b2:b2:\
-b2:b2:b2:b2:b2 auth_algo sha1-hmac auth_key b2:b2:b2:b2:b2:b2:b2:b2:b2:b2:b2:\
-b2:b2:b2:b2:b2:b2:b2:b2:b2 mode transport
-
-sa out 115 cipher_algo null auth_algo null mode ipv4-tunnel src 172.16.2.5 \
-dst 172.16.1.5
-
-sa out 116 cipher_algo null auth_algo null mode ipv4-tunnel src 172.16.2.6 dst 172.16.1.6
-
-sa out 125 cipher_algo aes-128-cbc cipher_key c3:c3:c3:c3:c3:c3:c3:c3:c3:c3:c3:\
-c3:c3:c3:c3:c3 auth_algo sha1-hmac auth_key c3:c3:c3:c3:c3:c3:c3:c3:c3:c3:c3:\
-c3:c3:c3:c3:c3:c3:c3:c3:c3 mode ipv6-tunnel \
-src 2222:2222:2222:2222:2222:2222:2222:5555 \
-dst 1111:1111:1111:1111:1111:1111:1111:5555
-
-sa out 126 cipher_algo aes-128-cbc cipher_key 4d:4d:4d:4d:4d:4d:4d:4d:4d:4d:4d:\
-4d:4d:4d:4d:4d auth_algo sha1-hmac auth_key 4d:4d:4d:4d:4d:4d:4d:4d:4d:4d:4d:\
-4d:4d:4d:4d:4d:4d:4d:4d:4d mode ipv6-tunnel \
-src 2222:2222:2222:2222:2222:2222:2222:6666 \
-dst 1111:1111:1111:1111:1111:1111:1111:6666
-
-#Routing rules
-rt ipv4 dst 172.16.1.5/32 port 0
-rt ipv4 dst 172.16.1.6/32 port 1
-rt ipv4 dst 192.168.185.0/24 port 0
-rt ipv4 dst 192.168.186.0/24 port 1
-rt ipv4 dst 192.168.245.0/24 port 0
-rt ipv4 dst 192.168.246.0/24 port 1
-rt ipv4 dst 192.168.105.0/24 port 2
-rt ipv4 dst 192.168.106.0/24 port 3
-rt ipv4 dst 192.168.55.0/24 port 2
-rt ipv4 dst 192.168.56.0/24 port 3
-rt ipv4 dst 192.168.175.0/24 port 2
-rt ipv4 dst 192.168.176.0/24 port 3
-rt ipv4 dst 192.168.200.0/24 port 2
-rt ipv4 dst 192.168.201.0/24 port 3
-rt ipv4 dst 192.168.240.0/24 port 2
-rt ipv4 dst 192.168.241.0/24 port 3
-
-rt ipv6 dst 1111:1111:1111:1111:1111:1111:1111:5555/116 port 0
-rt ipv6 dst 1111:1111:1111:1111:1111:1111:1111:6666/116 port 1
-rt ipv6 dst ffff:0000:1111:1111:0000:0000:0000:0000/116 port 0
-rt ipv6 dst ffff:0000:1111:1111:1111:1111:0000:0000/116 port 1
-rt ipv6 dst 0000:0000:0000:0000:aaaa:aaaa:0000:0000/116 port 2
-rt ipv6 dst 0000:0000:0000:0000:bbbb:bbbb:0000:0000/116 port 3
-rt ipv6 dst 0000:0000:0000:0000:5555:5555:0000:0000/116 port 2
-rt ipv6 dst 0000:0000:0000:0000:6666:6666:0000:0000/116 port 3
-rt ipv6 dst 0000:0000:1111:1111:0000:0000:0000:0000/116 port 2
-rt ipv6 dst 0000:0000:1111:1111:1111:1111:0000:0000/116 port 3
diff --git a/examples/ipsec-secgw/esp.c b/examples/ipsec-secgw/esp.c
deleted file mode 100644
index ee9e590..0000000
--- a/examples/ipsec-secgw/esp.c
+++ /dev/null
@@ -1,461 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016-2017 Intel Corporation
- */
-
-#include <stdint.h>
-#include <stdlib.h>
-#include <sys/types.h>
-#include <sys/stat.h>
-#include <netinet/in.h>
-#include <netinet/ip.h>
-#include <netinet/ip6.h>
-#include <fcntl.h>
-#include <unistd.h>
-
-#include <rte_common.h>
-#include <rte_crypto.h>
-#include <rte_cryptodev.h>
-#include <rte_random.h>
-
-#include "ipsec.h"
-#include "esp.h"
-#include "ipip.h"
-
-int
-esp_inbound(struct rte_mbuf *m, struct ipsec_sa *sa,
-		struct rte_crypto_op *cop)
-{
-	struct ip *ip4;
-	struct rte_crypto_sym_op *sym_cop;
-	int32_t payload_len, ip_hdr_len;
-
-	RTE_ASSERT(sa != NULL);
-	if (sa->type == RTE_SECURITY_ACTION_TYPE_INLINE_CRYPTO)
-		return 0;
-
-	RTE_ASSERT(m != NULL);
-	RTE_ASSERT(cop != NULL);
-
-	ip4 = rte_pktmbuf_mtod(m, struct ip *);
-	if (likely(ip4->ip_v == IPVERSION))
-		ip_hdr_len = ip4->ip_hl * 4;
-	else if (ip4->ip_v == IP6_VERSION)
-		/* XXX No option headers supported */
-		ip_hdr_len = sizeof(struct ip6_hdr);
-	else {
-		RTE_LOG(ERR, IPSEC_ESP, "invalid IP packet type %d\n",
-				ip4->ip_v);
-		return -EINVAL;
-	}
-
-	payload_len = rte_pktmbuf_pkt_len(m) - ip_hdr_len -
-		sizeof(struct esp_hdr) - sa->iv_len - sa->digest_len;
-
-	if ((payload_len & (sa->block_size - 1)) || (payload_len <= 0)) {
-		RTE_LOG_DP(DEBUG, IPSEC_ESP, "payload %d not multiple of %u\n",
-				payload_len, sa->block_size);
-		return -EINVAL;
-	}
-
-	sym_cop = get_sym_cop(cop);
-	sym_cop->m_src = m;
-
-	if (sa->aead_algo == RTE_CRYPTO_AEAD_AES_GCM) {
-		sym_cop->aead.data.offset =  ip_hdr_len + sizeof(struct esp_hdr) +
-			sa->iv_len;
-		sym_cop->aead.data.length = payload_len;
-
-		struct cnt_blk *icb;
-		uint8_t *aad;
-		uint8_t *iv = RTE_PTR_ADD(ip4, ip_hdr_len + sizeof(struct esp_hdr));
-
-		icb = get_cnt_blk(m);
-		icb->salt = sa->salt;
-		memcpy(&icb->iv, iv, 8);
-		icb->cnt = rte_cpu_to_be_32(1);
-
-		aad = get_aad(m);
-		memcpy(aad, iv - sizeof(struct esp_hdr), 8);
-		sym_cop->aead.aad.data = aad;
-		sym_cop->aead.aad.phys_addr = rte_pktmbuf_iova_offset(m,
-				aad - rte_pktmbuf_mtod(m, uint8_t *));
-
-		sym_cop->aead.digest.data = rte_pktmbuf_mtod_offset(m, void*,
-				rte_pktmbuf_pkt_len(m) - sa->digest_len);
-		sym_cop->aead.digest.phys_addr = rte_pktmbuf_iova_offset(m,
-				rte_pktmbuf_pkt_len(m) - sa->digest_len);
-	} else {
-		sym_cop->cipher.data.offset =  ip_hdr_len + sizeof(struct esp_hdr) +
-			sa->iv_len;
-		sym_cop->cipher.data.length = payload_len;
-
-		struct cnt_blk *icb;
-		uint8_t *iv = RTE_PTR_ADD(ip4, ip_hdr_len + sizeof(struct esp_hdr));
-		uint8_t *iv_ptr = rte_crypto_op_ctod_offset(cop,
-					uint8_t *, IV_OFFSET);
-
-		switch (sa->cipher_algo) {
-		case RTE_CRYPTO_CIPHER_NULL:
-		case RTE_CRYPTO_CIPHER_AES_CBC:
-			/* Copy IV at the end of crypto operation */
-			rte_memcpy(iv_ptr, iv, sa->iv_len);
-			break;
-		case RTE_CRYPTO_CIPHER_AES_CTR:
-			icb = get_cnt_blk(m);
-			icb->salt = sa->salt;
-			memcpy(&icb->iv, iv, 8);
-			icb->cnt = rte_cpu_to_be_32(1);
-			break;
-		default:
-			RTE_LOG(ERR, IPSEC_ESP, "unsupported cipher algorithm %u\n",
-					sa->cipher_algo);
-			return -EINVAL;
-		}
-
-		switch (sa->auth_algo) {
-		case RTE_CRYPTO_AUTH_NULL:
-		case RTE_CRYPTO_AUTH_SHA1_HMAC:
-		case RTE_CRYPTO_AUTH_SHA256_HMAC:
-			sym_cop->auth.data.offset = ip_hdr_len;
-			sym_cop->auth.data.length = sizeof(struct esp_hdr) +
-				sa->iv_len + payload_len;
-			break;
-		default:
-			RTE_LOG(ERR, IPSEC_ESP, "unsupported auth algorithm %u\n",
-					sa->auth_algo);
-			return -EINVAL;
-		}
-
-		sym_cop->auth.digest.data = rte_pktmbuf_mtod_offset(m, void*,
-				rte_pktmbuf_pkt_len(m) - sa->digest_len);
-		sym_cop->auth.digest.phys_addr = rte_pktmbuf_iova_offset(m,
-				rte_pktmbuf_pkt_len(m) - sa->digest_len);
-	}
-
-	return 0;
-}
-
-int
-esp_inbound_post(struct rte_mbuf *m, struct ipsec_sa *sa,
-		struct rte_crypto_op *cop)
-{
-	struct ip *ip4, *ip;
-	struct ip6_hdr *ip6;
-	uint8_t *nexthdr, *pad_len;
-	uint8_t *padding;
-	uint16_t i;
-
-	RTE_ASSERT(m != NULL);
-	RTE_ASSERT(sa != NULL);
-	RTE_ASSERT(cop != NULL);
-
-	if ((sa->type == RTE_SECURITY_ACTION_TYPE_INLINE_PROTOCOL) ||
-			(sa->type == RTE_SECURITY_ACTION_TYPE_INLINE_CRYPTO)) {
-		if (m->ol_flags & PKT_RX_SEC_OFFLOAD) {
-			if (m->ol_flags & PKT_RX_SEC_OFFLOAD_FAILED)
-				cop->status = RTE_CRYPTO_OP_STATUS_ERROR;
-			else
-				cop->status = RTE_CRYPTO_OP_STATUS_SUCCESS;
-		} else
-			cop->status = RTE_CRYPTO_OP_STATUS_NOT_PROCESSED;
-	}
-
-	if (cop->status != RTE_CRYPTO_OP_STATUS_SUCCESS) {
-		RTE_LOG(ERR, IPSEC_ESP, "failed crypto op\n");
-		return -1;
-	}
-
-	if (sa->type == RTE_SECURITY_ACTION_TYPE_INLINE_CRYPTO &&
-	    sa->ol_flags & RTE_SECURITY_RX_HW_TRAILER_OFFLOAD) {
-		nexthdr = &m->inner_esp_next_proto;
-	} else {
-		nexthdr = rte_pktmbuf_mtod_offset(m, uint8_t*,
-				rte_pktmbuf_pkt_len(m) - sa->digest_len - 1);
-		pad_len = nexthdr - 1;
-
-		padding = pad_len - *pad_len;
-		for (i = 0; i < *pad_len; i++) {
-			if (padding[i] != i + 1) {
-				RTE_LOG(ERR, IPSEC_ESP, "invalid padding\n");
-				return -EINVAL;
-			}
-		}
-
-		if (rte_pktmbuf_trim(m, *pad_len + 2 + sa->digest_len)) {
-			RTE_LOG(ERR, IPSEC_ESP,
-					"failed to remove pad_len + digest\n");
-			return -EINVAL;
-		}
-	}
-
-	if (unlikely(sa->flags == TRANSPORT)) {
-		ip = rte_pktmbuf_mtod(m, struct ip *);
-		ip4 = (struct ip *)rte_pktmbuf_adj(m,
-				sizeof(struct esp_hdr) + sa->iv_len);
-		if (likely(ip->ip_v == IPVERSION)) {
-			memmove(ip4, ip, ip->ip_hl * 4);
-			ip4->ip_p = *nexthdr;
-			ip4->ip_len = htons(rte_pktmbuf_data_len(m));
-		} else {
-			ip6 = (struct ip6_hdr *)ip4;
-			/* XXX No option headers supported */
-			memmove(ip6, ip, sizeof(struct ip6_hdr));
-			ip6->ip6_nxt = *nexthdr;
-			ip6->ip6_plen = htons(rte_pktmbuf_data_len(m) -
-					      sizeof(struct ip6_hdr));
-		}
-	} else
-		ipip_inbound(m, sizeof(struct esp_hdr) + sa->iv_len);
-
-	return 0;
-}
-
-int
-esp_outbound(struct rte_mbuf *m, struct ipsec_sa *sa,
-		struct rte_crypto_op *cop)
-{
-	struct ip *ip4;
-	struct ip6_hdr *ip6;
-	struct esp_hdr *esp = NULL;
-	uint8_t *padding = NULL, *new_ip, nlp;
-	struct rte_crypto_sym_op *sym_cop;
-	int32_t i;
-	uint16_t pad_payload_len, pad_len, ip_hdr_len;
-
-	RTE_ASSERT(m != NULL);
-	RTE_ASSERT(sa != NULL);
-
-	ip_hdr_len = 0;
-
-	ip4 = rte_pktmbuf_mtod(m, struct ip *);
-	if (likely(ip4->ip_v == IPVERSION)) {
-		if (unlikely(sa->flags == TRANSPORT)) {
-			ip_hdr_len = ip4->ip_hl * 4;
-			nlp = ip4->ip_p;
-		} else
-			nlp = IPPROTO_IPIP;
-	} else if (ip4->ip_v == IP6_VERSION) {
-		if (unlikely(sa->flags == TRANSPORT)) {
-			/* XXX No option headers supported */
-			ip_hdr_len = sizeof(struct ip6_hdr);
-			ip6 = (struct ip6_hdr *)ip4;
-			nlp = ip6->ip6_nxt;
-		} else
-			nlp = IPPROTO_IPV6;
-	} else {
-		RTE_LOG(ERR, IPSEC_ESP, "invalid IP packet type %d\n",
-				ip4->ip_v);
-		return -EINVAL;
-	}
-
-	/* Padded payload length */
-	pad_payload_len = RTE_ALIGN_CEIL(rte_pktmbuf_pkt_len(m) -
-			ip_hdr_len + 2, sa->block_size);
-	pad_len = pad_payload_len + ip_hdr_len - rte_pktmbuf_pkt_len(m);
-
-	RTE_ASSERT(sa->flags == IP4_TUNNEL || sa->flags == IP6_TUNNEL ||
-			sa->flags == TRANSPORT);
-
-	if (likely(sa->flags == IP4_TUNNEL))
-		ip_hdr_len = sizeof(struct ip);
-	else if (sa->flags == IP6_TUNNEL)
-		ip_hdr_len = sizeof(struct ip6_hdr);
-	else if (sa->flags != TRANSPORT) {
-		RTE_LOG(ERR, IPSEC_ESP, "Unsupported SA flags: 0x%x\n",
-				sa->flags);
-		return -EINVAL;
-	}
-
-	/* Check maximum packet size */
-	if (unlikely(ip_hdr_len + sizeof(struct esp_hdr) + sa->iv_len +
-			pad_payload_len + sa->digest_len > IP_MAXPACKET)) {
-		RTE_LOG(ERR, IPSEC_ESP, "ipsec packet is too big\n");
-		return -EINVAL;
-	}
-
-	/* Add trailer padding if it is not constructed by HW */
-	if (sa->type != RTE_SECURITY_ACTION_TYPE_INLINE_CRYPTO ||
-	    (sa->type == RTE_SECURITY_ACTION_TYPE_INLINE_CRYPTO &&
-	     !(sa->ol_flags & RTE_SECURITY_TX_HW_TRAILER_OFFLOAD))) {
-		padding = (uint8_t *)rte_pktmbuf_append(m, pad_len +
-							sa->digest_len);
-		if (unlikely(padding == NULL)) {
-			RTE_LOG(ERR, IPSEC_ESP,
-					"not enough mbuf trailing space\n");
-			return -ENOSPC;
-		}
-		rte_prefetch0(padding);
-	}
-
-	switch (sa->flags) {
-	case IP4_TUNNEL:
-		ip4 = ip4ip_outbound(m, sizeof(struct esp_hdr) + sa->iv_len,
-				&sa->src, &sa->dst);
-		esp = (struct esp_hdr *)(ip4 + 1);
-		break;
-	case IP6_TUNNEL:
-		ip6 = ip6ip_outbound(m, sizeof(struct esp_hdr) + sa->iv_len,
-				&sa->src, &sa->dst);
-		esp = (struct esp_hdr *)(ip6 + 1);
-		break;
-	case TRANSPORT:
-		new_ip = (uint8_t *)rte_pktmbuf_prepend(m,
-				sizeof(struct esp_hdr) + sa->iv_len);
-		memmove(new_ip, ip4, ip_hdr_len);
-		esp = (struct esp_hdr *)(new_ip + ip_hdr_len);
-		ip4 = (struct ip *)new_ip;
-		if (likely(ip4->ip_v == IPVERSION)) {
-			ip4->ip_p = IPPROTO_ESP;
-			ip4->ip_len = htons(rte_pktmbuf_data_len(m));
-		} else {
-			ip6 = (struct ip6_hdr *)new_ip;
-			ip6->ip6_nxt = IPPROTO_ESP;
-			ip6->ip6_plen = htons(rte_pktmbuf_data_len(m) -
-					      sizeof(struct ip6_hdr));
-		}
-	}
-
-	sa->seq++;
-	esp->spi = rte_cpu_to_be_32(sa->spi);
-	esp->seq = rte_cpu_to_be_32((uint32_t)sa->seq);
-
-	/* set iv */
-	uint64_t *iv = (uint64_t *)(esp + 1);
-	if (sa->aead_algo == RTE_CRYPTO_AEAD_AES_GCM) {
-		*iv = rte_cpu_to_be_64(sa->seq);
-	} else {
-		switch (sa->cipher_algo) {
-		case RTE_CRYPTO_CIPHER_NULL:
-		case RTE_CRYPTO_CIPHER_AES_CBC:
-			memset(iv, 0, sa->iv_len);
-			break;
-		case RTE_CRYPTO_CIPHER_AES_CTR:
-			*iv = rte_cpu_to_be_64(sa->seq);
-			break;
-		default:
-			RTE_LOG(ERR, IPSEC_ESP,
-				"unsupported cipher algorithm %u\n",
-				sa->cipher_algo);
-			return -EINVAL;
-		}
-	}
-
-	if (sa->type == RTE_SECURITY_ACTION_TYPE_INLINE_CRYPTO) {
-		if (sa->ol_flags & RTE_SECURITY_TX_HW_TRAILER_OFFLOAD) {
-			/* Set the inner esp next protocol for HW trailer */
-			m->inner_esp_next_proto = nlp;
-			m->packet_type |= RTE_PTYPE_TUNNEL_ESP;
-		} else {
-			padding[pad_len - 2] = pad_len - 2;
-			padding[pad_len - 1] = nlp;
-		}
-		goto done;
-	}
-
-	RTE_ASSERT(cop != NULL);
-	sym_cop = get_sym_cop(cop);
-	sym_cop->m_src = m;
-
-	if (sa->aead_algo == RTE_CRYPTO_AEAD_AES_GCM) {
-		uint8_t *aad;
-
-		sym_cop->aead.data.offset = ip_hdr_len +
-			sizeof(struct esp_hdr) + sa->iv_len;
-		sym_cop->aead.data.length = pad_payload_len;
-
-		/* Fill pad_len using default sequential scheme */
-		for (i = 0; i < pad_len - 2; i++)
-			padding[i] = i + 1;
-		padding[pad_len - 2] = pad_len - 2;
-		padding[pad_len - 1] = nlp;
-
-		struct cnt_blk *icb = get_cnt_blk(m);
-		icb->salt = sa->salt;
-		icb->iv = rte_cpu_to_be_64(sa->seq);
-		icb->cnt = rte_cpu_to_be_32(1);
-
-		aad = get_aad(m);
-		memcpy(aad, esp, 8);
-		sym_cop->aead.aad.data = aad;
-		sym_cop->aead.aad.phys_addr = rte_pktmbuf_iova_offset(m,
-				aad - rte_pktmbuf_mtod(m, uint8_t *));
-
-		sym_cop->aead.digest.data = rte_pktmbuf_mtod_offset(m, uint8_t *,
-			rte_pktmbuf_pkt_len(m) - sa->digest_len);
-		sym_cop->aead.digest.phys_addr = rte_pktmbuf_iova_offset(m,
-			rte_pktmbuf_pkt_len(m) - sa->digest_len);
-	} else {
-		switch (sa->cipher_algo) {
-		case RTE_CRYPTO_CIPHER_NULL:
-		case RTE_CRYPTO_CIPHER_AES_CBC:
-			sym_cop->cipher.data.offset = ip_hdr_len +
-				sizeof(struct esp_hdr);
-			sym_cop->cipher.data.length = pad_payload_len + sa->iv_len;
-			break;
-		case RTE_CRYPTO_CIPHER_AES_CTR:
-			sym_cop->cipher.data.offset = ip_hdr_len +
-				sizeof(struct esp_hdr) + sa->iv_len;
-			sym_cop->cipher.data.length = pad_payload_len;
-			break;
-		default:
-			RTE_LOG(ERR, IPSEC_ESP, "unsupported cipher algorithm %u\n",
-					sa->cipher_algo);
-			return -EINVAL;
-		}
-
-		/* Fill pad_len using default sequential scheme */
-		for (i = 0; i < pad_len - 2; i++)
-			padding[i] = i + 1;
-		padding[pad_len - 2] = pad_len - 2;
-		padding[pad_len - 1] = nlp;
-
-		struct cnt_blk *icb = get_cnt_blk(m);
-		icb->salt = sa->salt;
-		icb->iv = rte_cpu_to_be_64(sa->seq);
-		icb->cnt = rte_cpu_to_be_32(1);
-
-		switch (sa->auth_algo) {
-		case RTE_CRYPTO_AUTH_NULL:
-		case RTE_CRYPTO_AUTH_SHA1_HMAC:
-		case RTE_CRYPTO_AUTH_SHA256_HMAC:
-			sym_cop->auth.data.offset = ip_hdr_len;
-			sym_cop->auth.data.length = sizeof(struct esp_hdr) +
-				sa->iv_len + pad_payload_len;
-			break;
-		default:
-			RTE_LOG(ERR, IPSEC_ESP, "unsupported auth algorithm %u\n",
-					sa->auth_algo);
-			return -EINVAL;
-		}
-
-		sym_cop->auth.digest.data = rte_pktmbuf_mtod_offset(m, uint8_t *,
-				rte_pktmbuf_pkt_len(m) - sa->digest_len);
-		sym_cop->auth.digest.phys_addr = rte_pktmbuf_iova_offset(m,
-				rte_pktmbuf_pkt_len(m) - sa->digest_len);
-	}
-
-done:
-	return 0;
-}
-
-int
-esp_outbound_post(struct rte_mbuf *m,
-		  struct ipsec_sa *sa,
-		  struct rte_crypto_op *cop)
-{
-	RTE_ASSERT(m != NULL);
-	RTE_ASSERT(sa != NULL);
-
-	if ((sa->type == RTE_SECURITY_ACTION_TYPE_INLINE_PROTOCOL) ||
-			(sa->type == RTE_SECURITY_ACTION_TYPE_INLINE_CRYPTO)) {
-		m->ol_flags |= PKT_TX_SEC_OFFLOAD;
-	} else {
-		RTE_ASSERT(cop != NULL);
-		if (cop->status != RTE_CRYPTO_OP_STATUS_SUCCESS) {
-			RTE_LOG(ERR, IPSEC_ESP, "Failed crypto op\n");
-			return -1;
-		}
-	}
-
-	return 0;
-}
diff --git a/examples/ipsec-secgw/esp.h b/examples/ipsec-secgw/esp.h
deleted file mode 100644
index 792312c..0000000
--- a/examples/ipsec-secgw/esp.h
+++ /dev/null
@@ -1,26 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016 Intel Corporation
- */
-#ifndef __RTE_IPSEC_XFORM_ESP_H__
-#define __RTE_IPSEC_XFORM_ESP_H__
-
-struct mbuf;
-
-
-int
-esp_inbound(struct rte_mbuf *m, struct ipsec_sa *sa,
-		struct rte_crypto_op *cop);
-
-int
-esp_inbound_post(struct rte_mbuf *m, struct ipsec_sa *sa,
-		struct rte_crypto_op *cop);
-
-int
-esp_outbound(struct rte_mbuf *m, struct ipsec_sa *sa,
-		struct rte_crypto_op *cop);
-
-int
-esp_outbound_post(struct rte_mbuf *m, struct ipsec_sa *sa,
-		struct rte_crypto_op *cop);
-
-#endif /* __RTE_IPSEC_XFORM_ESP_H__ */
diff --git a/examples/ipsec-secgw/ipip.h b/examples/ipsec-secgw/ipip.h
deleted file mode 100644
index 13b8455..0000000
--- a/examples/ipsec-secgw/ipip.h
+++ /dev/null
@@ -1,174 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016 Intel Corporation
- */
-
-#ifndef __IPIP_H__
-#define __IPIP_H__
-
-#include <stdint.h>
-#include <netinet/in.h>
-#include <netinet/ip.h>
-#include <netinet/ip6.h>
-
-#include <rte_mbuf.h>
-
-static inline void *
-ipip_outbound(struct rte_mbuf *m, uint32_t offset, uint32_t is_ipv6,
-		struct ip_addr *src,  struct ip_addr *dst)
-{
-	struct ip *inip4, *outip4;
-	struct ip6_hdr *inip6, *outip6;
-	uint8_t ds_ecn;
-
-	inip4 = rte_pktmbuf_mtod(m, struct ip *);
-
-	RTE_ASSERT(inip4->ip_v == IPVERSION || inip4->ip_v == IP6_VERSION);
-
-	if (inip4->ip_v == IPVERSION) {
-		/* XXX This should be done by the forwarding engine instead */
-		inip4->ip_ttl -= 1;
-		if (inip4->ip_sum >= rte_cpu_to_be_16(0xffff - 0x100))
-			inip4->ip_sum += rte_cpu_to_be_16(0x100) + 1;
-		else
-			inip4->ip_sum += rte_cpu_to_be_16(0x100);
-		ds_ecn = inip4->ip_tos;
-	} else {
-		inip6 = (struct ip6_hdr *)inip4;
-		/* XXX This should be done by the forwarding engine instead */
-		inip6->ip6_hops -= 1;
-		ds_ecn = ntohl(inip6->ip6_flow) >> 20;
-	}
-
-	if (is_ipv6) {
-		offset += sizeof(struct ip6_hdr);
-		outip6 = (struct ip6_hdr *)rte_pktmbuf_prepend(m, offset);
-
-		RTE_ASSERT(outip6 != NULL);
-
-		/* Per RFC4301 5.1.2.1 */
-		outip6->ip6_flow = htonl(IP6_VERSION << 28 | ds_ecn << 20);
-		outip6->ip6_plen = htons(rte_pktmbuf_data_len(m) -
-					 sizeof(struct ip6_hdr));
-
-		outip6->ip6_nxt = IPPROTO_ESP;
-		outip6->ip6_hops = IPDEFTTL;
-
-		memcpy(&outip6->ip6_src.s6_addr, src, 16);
-		memcpy(&outip6->ip6_dst.s6_addr, dst, 16);
-
-		return outip6;
-	}
-
-	offset += sizeof(struct ip);
-	outip4 = (struct ip *)rte_pktmbuf_prepend(m, offset);
-
-	RTE_ASSERT(outip4 != NULL);
-
-	/* Per RFC4301 5.1.2.1 */
-	outip4->ip_v = IPVERSION;
-	outip4->ip_hl = 5;
-	outip4->ip_tos = ds_ecn;
-	outip4->ip_len = htons(rte_pktmbuf_data_len(m));
-
-	outip4->ip_id = 0;
-	outip4->ip_off = 0;
-
-	outip4->ip_ttl = IPDEFTTL;
-	outip4->ip_p = IPPROTO_ESP;
-
-	outip4->ip_src.s_addr = src->ip.ip4;
-	outip4->ip_dst.s_addr = dst->ip.ip4;
-	m->packet_type &= ~RTE_PTYPE_L4_MASK;
-	return outip4;
-}
-
-static inline struct ip *
-ip4ip_outbound(struct rte_mbuf *m, uint32_t offset,
-		struct ip_addr *src,  struct ip_addr *dst)
-{
-	return ipip_outbound(m, offset, 0, src, dst);
-}
-
-static inline struct ip6_hdr *
-ip6ip_outbound(struct rte_mbuf *m, uint32_t offset,
-		struct ip_addr *src,  struct ip_addr *dst)
-{
-	return ipip_outbound(m, offset, 1, src, dst);
-}
-
-static inline void
-ip4_ecn_setup(struct ip *ip4)
-{
-	if (ip4->ip_tos & IPTOS_ECN_MASK) {
-		unsigned long sum;
-		uint8_t old;
-
-		old = ip4->ip_tos;
-		ip4->ip_tos |= IPTOS_ECN_CE;
-		sum = old + (~(*(uint8_t *)&ip4->ip_tos) & 0xff);
-		sum += rte_be_to_cpu_16(ip4->ip_sum);
-		sum = (sum & 0xffff) + (sum >> 16);
-		ip4->ip_sum = rte_cpu_to_be_16(sum + (sum >> 16));
-	}
-}
-
-static inline void
-ip6_ecn_setup(struct ip6_hdr *ip6)
-{
-	if ((ntohl(ip6->ip6_flow) >> 20) & IPTOS_ECN_MASK)
-		ip6->ip6_flow = htonl(ntohl(ip6->ip6_flow) |
-					(IPTOS_ECN_CE << 20));
-}
-
-static inline void
-ipip_inbound(struct rte_mbuf *m, uint32_t offset)
-{
-	struct ip *inip4, *outip4;
-	struct ip6_hdr *inip6, *outip6;
-	uint32_t ip_len, set_ecn;
-
-	outip4 = rte_pktmbuf_mtod(m, struct ip*);
-
-	RTE_ASSERT(outip4->ip_v == IPVERSION || outip4->ip_v == IP6_VERSION);
-
-	if (outip4->ip_v == IPVERSION) {
-		ip_len = sizeof(struct ip);
-		set_ecn = ((outip4->ip_tos & IPTOS_ECN_CE) == IPTOS_ECN_CE);
-	} else {
-		outip6 = (struct ip6_hdr *)outip4;
-		ip_len = sizeof(struct ip6_hdr);
-		set_ecn = ntohl(outip6->ip6_flow) >> 20;
-		set_ecn = ((set_ecn & IPTOS_ECN_CE) == IPTOS_ECN_CE);
-	}
-
-	inip4 = (struct ip *)rte_pktmbuf_adj(m, offset + ip_len);
-	RTE_ASSERT(inip4->ip_v == IPVERSION || inip4->ip_v == IP6_VERSION);
-
-	/* Check packet is still bigger than IP header (inner) */
-	RTE_ASSERT(rte_pktmbuf_pkt_len(m) > ip_len);
-
-	/* RFC4301 5.1.2.1 Note 6 */
-	if (inip4->ip_v == IPVERSION) {
-		if (set_ecn)
-			ip4_ecn_setup(inip4);
-		/* XXX This should be done by the forwarding engine instead */
-		inip4->ip_ttl -= 1;
-		if (inip4->ip_sum >= rte_cpu_to_be_16(0xffff - 0x100))
-			inip4->ip_sum += rte_cpu_to_be_16(0x100) + 1;
-		else
-			inip4->ip_sum += rte_cpu_to_be_16(0x100);
-		m->packet_type &= ~RTE_PTYPE_L4_MASK;
-		if (inip4->ip_p == IPPROTO_UDP)
-			m->packet_type |= RTE_PTYPE_L4_UDP;
-		else if (inip4->ip_p == IPPROTO_TCP)
-			m->packet_type |= RTE_PTYPE_L4_TCP;
-	} else {
-		inip6 = (struct ip6_hdr *)inip4;
-		if (set_ecn)
-			ip6_ecn_setup(inip6);
-		/* XXX This should be done by the forwarding engine instead */
-		inip6->ip6_hops -= 1;
-	}
-}
-
-#endif /* __IPIP_H__ */
diff --git a/examples/ipsec-secgw/ipsec-secgw.c b/examples/ipsec-secgw/ipsec-secgw.c
deleted file mode 100644
index c9d3f24..0000000
--- a/examples/ipsec-secgw/ipsec-secgw.c
+++ /dev/null
@@ -1,1746 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <sys/types.h>
-#include <netinet/in.h>
-#include <netinet/ip.h>
-#include <netinet/ip6.h>
-#include <string.h>
-#include <sys/queue.h>
-#include <stdarg.h>
-#include <errno.h>
-#include <getopt.h>
-
-#include <rte_common.h>
-#include <rte_byteorder.h>
-#include <rte_log.h>
-#include <rte_eal.h>
-#include <rte_launch.h>
-#include <rte_atomic.h>
-#include <rte_cycles.h>
-#include <rte_prefetch.h>
-#include <rte_lcore.h>
-#include <rte_per_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_interrupts.h>
-#include <rte_random.h>
-#include <rte_debug.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-#include <rte_acl.h>
-#include <rte_lpm.h>
-#include <rte_lpm6.h>
-#include <rte_hash.h>
-#include <rte_jhash.h>
-#include <rte_cryptodev.h>
-
-#include "ipsec.h"
-#include "parser.h"
-
-#define RTE_LOGTYPE_IPSEC RTE_LOGTYPE_USER1
-
-#define MAX_JUMBO_PKT_LEN  9600
-
-#define MEMPOOL_CACHE_SIZE 256
-
-#define NB_MBUF	(32000)
-
-#define CDEV_QUEUE_DESC 2048
-#define CDEV_MAP_ENTRIES 1024
-#define CDEV_MP_NB_OBJS 2048
-#define CDEV_MP_CACHE_SZ 64
-#define MAX_QUEUE_PAIRS 1
-
-#define OPTION_CONFIG		"config"
-#define OPTION_SINGLE_SA	"single-sa"
-#define OPTION_CRYPTODEV_MASK	"cryptodev_mask"
-
-#define BURST_TX_DRAIN_US 100 /* TX drain every ~100us */
-
-#define NB_SOCKETS 4
-
-/* Configure how many packets ahead to prefetch, when reading packets */
-#define PREFETCH_OFFSET	3
-
-#define MAX_RX_QUEUE_PER_LCORE 16
-
-#define MAX_LCORE_PARAMS 1024
-
-#define UNPROTECTED_PORT(port) (unprotected_port_mask & (1 << portid))
-
-/*
- * Configurable number of RX/TX ring descriptors
- */
-#define IPSEC_SECGW_RX_DESC_DEFAULT 1024
-#define IPSEC_SECGW_TX_DESC_DEFAULT 1024
-static uint16_t nb_rxd = IPSEC_SECGW_RX_DESC_DEFAULT;
-static uint16_t nb_txd = IPSEC_SECGW_TX_DESC_DEFAULT;
-
-#if RTE_BYTE_ORDER != RTE_LITTLE_ENDIAN
-#define __BYTES_TO_UINT64(a, b, c, d, e, f, g, h) \
-	(((uint64_t)((a) & 0xff) << 56) | \
-	((uint64_t)((b) & 0xff) << 48) | \
-	((uint64_t)((c) & 0xff) << 40) | \
-	((uint64_t)((d) & 0xff) << 32) | \
-	((uint64_t)((e) & 0xff) << 24) | \
-	((uint64_t)((f) & 0xff) << 16) | \
-	((uint64_t)((g) & 0xff) << 8)  | \
-	((uint64_t)(h) & 0xff))
-#else
-#define __BYTES_TO_UINT64(a, b, c, d, e, f, g, h) \
-	(((uint64_t)((h) & 0xff) << 56) | \
-	((uint64_t)((g) & 0xff) << 48) | \
-	((uint64_t)((f) & 0xff) << 40) | \
-	((uint64_t)((e) & 0xff) << 32) | \
-	((uint64_t)((d) & 0xff) << 24) | \
-	((uint64_t)((c) & 0xff) << 16) | \
-	((uint64_t)((b) & 0xff) << 8) | \
-	((uint64_t)(a) & 0xff))
-#endif
-#define ETHADDR(a, b, c, d, e, f) (__BYTES_TO_UINT64(a, b, c, d, e, f, 0, 0))
-
-#define ETHADDR_TO_UINT64(addr) __BYTES_TO_UINT64( \
-		addr.addr_bytes[0], addr.addr_bytes[1], \
-		addr.addr_bytes[2], addr.addr_bytes[3], \
-		addr.addr_bytes[4], addr.addr_bytes[5], \
-		0, 0)
-
-/* port/source ethernet addr and destination ethernet addr */
-struct ethaddr_info {
-	uint64_t src, dst;
-};
-
-struct ethaddr_info ethaddr_tbl[RTE_MAX_ETHPORTS] = {
-	{ 0, ETHADDR(0x00, 0x16, 0x3e, 0x7e, 0x94, 0x9a) },
-	{ 0, ETHADDR(0x00, 0x16, 0x3e, 0x22, 0xa1, 0xd9) },
-	{ 0, ETHADDR(0x00, 0x16, 0x3e, 0x08, 0x69, 0x26) },
-	{ 0, ETHADDR(0x00, 0x16, 0x3e, 0x49, 0x9e, 0xdd) }
-};
-
-/* mask of enabled ports */
-static uint32_t enabled_port_mask;
-static uint64_t enabled_cryptodev_mask = UINT64_MAX;
-static uint32_t unprotected_port_mask;
-static int32_t promiscuous_on = 1;
-static int32_t numa_on = 1; /**< NUMA is enabled by default. */
-static uint32_t nb_lcores;
-static uint32_t single_sa;
-static uint32_t single_sa_idx;
-static uint32_t frame_size;
-
-struct lcore_rx_queue {
-	uint16_t port_id;
-	uint8_t queue_id;
-} __rte_cache_aligned;
-
-struct lcore_params {
-	uint16_t port_id;
-	uint8_t queue_id;
-	uint8_t lcore_id;
-} __rte_cache_aligned;
-
-static struct lcore_params lcore_params_array[MAX_LCORE_PARAMS];
-
-static struct lcore_params *lcore_params;
-static uint16_t nb_lcore_params;
-
-static struct rte_hash *cdev_map_in;
-static struct rte_hash *cdev_map_out;
-
-struct buffer {
-	uint16_t len;
-	struct rte_mbuf *m_table[MAX_PKT_BURST] __rte_aligned(sizeof(void *));
-};
-
-struct lcore_conf {
-	uint16_t nb_rx_queue;
-	struct lcore_rx_queue rx_queue_list[MAX_RX_QUEUE_PER_LCORE];
-	uint16_t tx_queue_id[RTE_MAX_ETHPORTS];
-	struct buffer tx_mbufs[RTE_MAX_ETHPORTS];
-	struct ipsec_ctx inbound;
-	struct ipsec_ctx outbound;
-	struct rt_ctx *rt4_ctx;
-	struct rt_ctx *rt6_ctx;
-} __rte_cache_aligned;
-
-static struct lcore_conf lcore_conf[RTE_MAX_LCORE];
-
-static struct rte_eth_conf port_conf = {
-	.rxmode = {
-		.mq_mode	= ETH_MQ_RX_RSS,
-		.max_rx_pkt_len = ETHER_MAX_LEN,
-		.split_hdr_size = 0,
-		.offloads = DEV_RX_OFFLOAD_CHECKSUM |
-			    DEV_RX_OFFLOAD_CRC_STRIP,
-		.ignore_offload_bitfield = 1,
-	},
-	.rx_adv_conf = {
-		.rss_conf = {
-			.rss_key = NULL,
-			.rss_hf = ETH_RSS_IP | ETH_RSS_UDP |
-				ETH_RSS_TCP | ETH_RSS_SCTP,
-		},
-	},
-	.txmode = {
-		.mq_mode = ETH_MQ_TX_NONE,
-		.offloads = (DEV_TX_OFFLOAD_IPV4_CKSUM |
-			     DEV_TX_OFFLOAD_MULTI_SEGS),
-	},
-};
-
-static struct socket_ctx socket_ctx[NB_SOCKETS];
-
-struct traffic_type {
-	const uint8_t *data[MAX_PKT_BURST * 2];
-	struct rte_mbuf *pkts[MAX_PKT_BURST * 2];
-	uint32_t res[MAX_PKT_BURST * 2];
-	uint32_t num;
-};
-
-struct ipsec_traffic {
-	struct traffic_type ipsec;
-	struct traffic_type ip4;
-	struct traffic_type ip6;
-};
-
-static inline void
-prepare_one_packet(struct rte_mbuf *pkt, struct ipsec_traffic *t)
-{
-	uint8_t *nlp;
-	struct ether_hdr *eth;
-
-	eth = rte_pktmbuf_mtod(pkt, struct ether_hdr *);
-	if (eth->ether_type == rte_cpu_to_be_16(ETHER_TYPE_IPv4)) {
-		nlp = (uint8_t *)rte_pktmbuf_adj(pkt, ETHER_HDR_LEN);
-		nlp = RTE_PTR_ADD(nlp, offsetof(struct ip, ip_p));
-		if (*nlp == IPPROTO_ESP)
-			t->ipsec.pkts[(t->ipsec.num)++] = pkt;
-		else {
-			t->ip4.data[t->ip4.num] = nlp;
-			t->ip4.pkts[(t->ip4.num)++] = pkt;
-		}
-	} else if (eth->ether_type == rte_cpu_to_be_16(ETHER_TYPE_IPv6)) {
-		nlp = (uint8_t *)rte_pktmbuf_adj(pkt, ETHER_HDR_LEN);
-		nlp = RTE_PTR_ADD(nlp, offsetof(struct ip6_hdr, ip6_nxt));
-		if (*nlp == IPPROTO_ESP)
-			t->ipsec.pkts[(t->ipsec.num)++] = pkt;
-		else {
-			t->ip6.data[t->ip6.num] = nlp;
-			t->ip6.pkts[(t->ip6.num)++] = pkt;
-		}
-	} else {
-		/* Unknown/Unsupported type, drop the packet */
-		RTE_LOG(ERR, IPSEC, "Unsupported packet type\n");
-		rte_pktmbuf_free(pkt);
-	}
-
-	/* Check if the packet has been processed inline. For inline protocol
-	 * processed packets, the metadata in the mbuf can be used to identify
-	 * the security processing done on the packet. The metadata will be
-	 * used to retrieve the application registered userdata associated
-	 * with the security session.
-	 */
-
-	if (pkt->ol_flags & PKT_RX_SEC_OFFLOAD) {
-		struct ipsec_sa *sa;
-		struct ipsec_mbuf_metadata *priv;
-		struct rte_security_ctx *ctx = (struct rte_security_ctx *)
-						rte_eth_dev_get_sec_ctx(
-						pkt->port);
-
-		/* Retrieve the userdata registered. Here, the userdata
-		 * registered is the SA pointer.
-		 */
-
-		sa = (struct ipsec_sa *)
-				rte_security_get_userdata(ctx, pkt->udata64);
-
-		if (sa == NULL) {
-			/* userdata could not be retrieved */
-			return;
-		}
-
-		/* Save SA as priv member in mbuf. This will be used in the
-		 * IPsec selector(SP-SA) check.
-		 */
-
-		priv = get_priv(pkt);
-		priv->sa = sa;
-	}
-}
-
-static inline void
-prepare_traffic(struct rte_mbuf **pkts, struct ipsec_traffic *t,
-		uint16_t nb_pkts)
-{
-	int32_t i;
-
-	t->ipsec.num = 0;
-	t->ip4.num = 0;
-	t->ip6.num = 0;
-
-	for (i = 0; i < (nb_pkts - PREFETCH_OFFSET); i++) {
-		rte_prefetch0(rte_pktmbuf_mtod(pkts[i + PREFETCH_OFFSET],
-					void *));
-		prepare_one_packet(pkts[i], t);
-	}
-	/* Process left packets */
-	for (; i < nb_pkts; i++)
-		prepare_one_packet(pkts[i], t);
-}
-
-static inline void
-prepare_tx_pkt(struct rte_mbuf *pkt, uint16_t port)
-{
-	struct ip *ip;
-	struct ether_hdr *ethhdr;
-
-	ip = rte_pktmbuf_mtod(pkt, struct ip *);
-
-	ethhdr = (struct ether_hdr *)rte_pktmbuf_prepend(pkt, ETHER_HDR_LEN);
-
-	if (ip->ip_v == IPVERSION) {
-		pkt->ol_flags |= PKT_TX_IP_CKSUM | PKT_TX_IPV4;
-		pkt->l3_len = sizeof(struct ip);
-		pkt->l2_len = ETHER_HDR_LEN;
-
-		ethhdr->ether_type = rte_cpu_to_be_16(ETHER_TYPE_IPv4);
-	} else {
-		pkt->ol_flags |= PKT_TX_IPV6;
-		pkt->l3_len = sizeof(struct ip6_hdr);
-		pkt->l2_len = ETHER_HDR_LEN;
-
-		ethhdr->ether_type = rte_cpu_to_be_16(ETHER_TYPE_IPv6);
-	}
-
-	memcpy(&ethhdr->s_addr, &ethaddr_tbl[port].src,
-			sizeof(struct ether_addr));
-	memcpy(&ethhdr->d_addr, &ethaddr_tbl[port].dst,
-			sizeof(struct ether_addr));
-}
-
-static inline void
-prepare_tx_burst(struct rte_mbuf *pkts[], uint16_t nb_pkts, uint16_t port)
-{
-	int32_t i;
-	const int32_t prefetch_offset = 2;
-
-	for (i = 0; i < (nb_pkts - prefetch_offset); i++) {
-		rte_mbuf_prefetch_part2(pkts[i + prefetch_offset]);
-		prepare_tx_pkt(pkts[i], port);
-	}
-	/* Process left packets */
-	for (; i < nb_pkts; i++)
-		prepare_tx_pkt(pkts[i], port);
-}
-
-/* Send burst of packets on an output interface */
-static inline int32_t
-send_burst(struct lcore_conf *qconf, uint16_t n, uint16_t port)
-{
-	struct rte_mbuf **m_table;
-	int32_t ret;
-	uint16_t queueid;
-
-	queueid = qconf->tx_queue_id[port];
-	m_table = (struct rte_mbuf **)qconf->tx_mbufs[port].m_table;
-
-	prepare_tx_burst(m_table, n, port);
-
-	ret = rte_eth_tx_burst(port, queueid, m_table, n);
-	if (unlikely(ret < n)) {
-		do {
-			rte_pktmbuf_free(m_table[ret]);
-		} while (++ret < n);
-	}
-
-	return 0;
-}
-
-/* Enqueue a single packet, and send burst if queue is filled */
-static inline int32_t
-send_single_packet(struct rte_mbuf *m, uint16_t port)
-{
-	uint32_t lcore_id;
-	uint16_t len;
-	struct lcore_conf *qconf;
-
-	lcore_id = rte_lcore_id();
-
-	qconf = &lcore_conf[lcore_id];
-	len = qconf->tx_mbufs[port].len;
-	qconf->tx_mbufs[port].m_table[len] = m;
-	len++;
-
-	/* enough pkts to be sent */
-	if (unlikely(len == MAX_PKT_BURST)) {
-		send_burst(qconf, MAX_PKT_BURST, port);
-		len = 0;
-	}
-
-	qconf->tx_mbufs[port].len = len;
-	return 0;
-}
-
-static inline void
-inbound_sp_sa(struct sp_ctx *sp, struct sa_ctx *sa, struct traffic_type *ip,
-		uint16_t lim)
-{
-	struct rte_mbuf *m;
-	uint32_t i, j, res, sa_idx;
-
-	if (ip->num == 0 || sp == NULL)
-		return;
-
-	rte_acl_classify((struct rte_acl_ctx *)sp, ip->data, ip->res,
-			ip->num, DEFAULT_MAX_CATEGORIES);
-
-	j = 0;
-	for (i = 0; i < ip->num; i++) {
-		m = ip->pkts[i];
-		res = ip->res[i];
-		if (res & BYPASS) {
-			ip->pkts[j++] = m;
-			continue;
-		}
-		if (res & DISCARD) {
-			rte_pktmbuf_free(m);
-			continue;
-		}
-
-		/* Only check SPI match for processed IPSec packets */
-		if (i < lim && ((m->ol_flags & PKT_RX_SEC_OFFLOAD) == 0)) {
-			rte_pktmbuf_free(m);
-			continue;
-		}
-
-		sa_idx = ip->res[i] & PROTECT_MASK;
-		if (sa_idx >= IPSEC_SA_MAX_ENTRIES ||
-				!inbound_sa_check(sa, m, sa_idx)) {
-			rte_pktmbuf_free(m);
-			continue;
-		}
-		ip->pkts[j++] = m;
-	}
-	ip->num = j;
-}
-
-static inline void
-process_pkts_inbound(struct ipsec_ctx *ipsec_ctx,
-		struct ipsec_traffic *traffic)
-{
-	struct rte_mbuf *m;
-	uint16_t idx, nb_pkts_in, i, n_ip4, n_ip6;
-
-	nb_pkts_in = ipsec_inbound(ipsec_ctx, traffic->ipsec.pkts,
-			traffic->ipsec.num, MAX_PKT_BURST);
-
-	n_ip4 = traffic->ip4.num;
-	n_ip6 = traffic->ip6.num;
-
-	/* SP/ACL Inbound check ipsec and ip4 */
-	for (i = 0; i < nb_pkts_in; i++) {
-		m = traffic->ipsec.pkts[i];
-		struct ip *ip = rte_pktmbuf_mtod(m, struct ip *);
-		if (ip->ip_v == IPVERSION) {
-			idx = traffic->ip4.num++;
-			traffic->ip4.pkts[idx] = m;
-			traffic->ip4.data[idx] = rte_pktmbuf_mtod_offset(m,
-					uint8_t *, offsetof(struct ip, ip_p));
-		} else if (ip->ip_v == IP6_VERSION) {
-			idx = traffic->ip6.num++;
-			traffic->ip6.pkts[idx] = m;
-			traffic->ip6.data[idx] = rte_pktmbuf_mtod_offset(m,
-					uint8_t *,
-					offsetof(struct ip6_hdr, ip6_nxt));
-		} else
-			rte_pktmbuf_free(m);
-	}
-
-	inbound_sp_sa(ipsec_ctx->sp4_ctx, ipsec_ctx->sa_ctx, &traffic->ip4,
-			n_ip4);
-
-	inbound_sp_sa(ipsec_ctx->sp6_ctx, ipsec_ctx->sa_ctx, &traffic->ip6,
-			n_ip6);
-}
-
-static inline void
-outbound_sp(struct sp_ctx *sp, struct traffic_type *ip,
-		struct traffic_type *ipsec)
-{
-	struct rte_mbuf *m;
-	uint32_t i, j, sa_idx;
-
-	if (ip->num == 0 || sp == NULL)
-		return;
-
-	rte_acl_classify((struct rte_acl_ctx *)sp, ip->data, ip->res,
-			ip->num, DEFAULT_MAX_CATEGORIES);
-
-	j = 0;
-	for (i = 0; i < ip->num; i++) {
-		m = ip->pkts[i];
-		sa_idx = ip->res[i] & PROTECT_MASK;
-		if (ip->res[i] & DISCARD)
-			rte_pktmbuf_free(m);
-		else if (sa_idx < IPSEC_SA_MAX_ENTRIES) {
-			ipsec->res[ipsec->num] = sa_idx;
-			ipsec->pkts[ipsec->num++] = m;
-		} else /* BYPASS */
-			ip->pkts[j++] = m;
-	}
-	ip->num = j;
-}
-
-static inline void
-process_pkts_outbound(struct ipsec_ctx *ipsec_ctx,
-		struct ipsec_traffic *traffic)
-{
-	struct rte_mbuf *m;
-	uint16_t idx, nb_pkts_out, i;
-
-	/* Drop any IPsec traffic from protected ports */
-	for (i = 0; i < traffic->ipsec.num; i++)
-		rte_pktmbuf_free(traffic->ipsec.pkts[i]);
-
-	traffic->ipsec.num = 0;
-
-	outbound_sp(ipsec_ctx->sp4_ctx, &traffic->ip4, &traffic->ipsec);
-
-	outbound_sp(ipsec_ctx->sp6_ctx, &traffic->ip6, &traffic->ipsec);
-
-	nb_pkts_out = ipsec_outbound(ipsec_ctx, traffic->ipsec.pkts,
-			traffic->ipsec.res, traffic->ipsec.num,
-			MAX_PKT_BURST);
-
-	for (i = 0; i < nb_pkts_out; i++) {
-		m = traffic->ipsec.pkts[i];
-		struct ip *ip = rte_pktmbuf_mtod(m, struct ip *);
-		if (ip->ip_v == IPVERSION) {
-			idx = traffic->ip4.num++;
-			traffic->ip4.pkts[idx] = m;
-		} else {
-			idx = traffic->ip6.num++;
-			traffic->ip6.pkts[idx] = m;
-		}
-	}
-}
-
-static inline void
-process_pkts_inbound_nosp(struct ipsec_ctx *ipsec_ctx,
-		struct ipsec_traffic *traffic)
-{
-	struct rte_mbuf *m;
-	uint32_t nb_pkts_in, i, idx;
-
-	/* Drop any IPv4 traffic from unprotected ports */
-	for (i = 0; i < traffic->ip4.num; i++)
-		rte_pktmbuf_free(traffic->ip4.pkts[i]);
-
-	traffic->ip4.num = 0;
-
-	/* Drop any IPv6 traffic from unprotected ports */
-	for (i = 0; i < traffic->ip6.num; i++)
-		rte_pktmbuf_free(traffic->ip6.pkts[i]);
-
-	traffic->ip6.num = 0;
-
-	nb_pkts_in = ipsec_inbound(ipsec_ctx, traffic->ipsec.pkts,
-			traffic->ipsec.num, MAX_PKT_BURST);
-
-	for (i = 0; i < nb_pkts_in; i++) {
-		m = traffic->ipsec.pkts[i];
-		struct ip *ip = rte_pktmbuf_mtod(m, struct ip *);
-		if (ip->ip_v == IPVERSION) {
-			idx = traffic->ip4.num++;
-			traffic->ip4.pkts[idx] = m;
-		} else {
-			idx = traffic->ip6.num++;
-			traffic->ip6.pkts[idx] = m;
-		}
-	}
-}
-
-static inline void
-process_pkts_outbound_nosp(struct ipsec_ctx *ipsec_ctx,
-		struct ipsec_traffic *traffic)
-{
-	struct rte_mbuf *m;
-	uint32_t nb_pkts_out, i;
-	struct ip *ip;
-
-	/* Drop any IPsec traffic from protected ports */
-	for (i = 0; i < traffic->ipsec.num; i++)
-		rte_pktmbuf_free(traffic->ipsec.pkts[i]);
-
-	traffic->ipsec.num = 0;
-
-	for (i = 0; i < traffic->ip4.num; i++)
-		traffic->ip4.res[i] = single_sa_idx;
-
-	for (i = 0; i < traffic->ip6.num; i++)
-		traffic->ip6.res[i] = single_sa_idx;
-
-	nb_pkts_out = ipsec_outbound(ipsec_ctx, traffic->ip4.pkts,
-			traffic->ip4.res, traffic->ip4.num,
-			MAX_PKT_BURST);
-
-	/* They all sue the same SA (ip4 or ip6 tunnel) */
-	m = traffic->ipsec.pkts[i];
-	ip = rte_pktmbuf_mtod(m, struct ip *);
-	if (ip->ip_v == IPVERSION)
-		traffic->ip4.num = nb_pkts_out;
-	else
-		traffic->ip6.num = nb_pkts_out;
-}
-
-static inline int32_t
-get_hop_for_offload_pkt(struct rte_mbuf *pkt, int is_ipv6)
-{
-	struct ipsec_mbuf_metadata *priv;
-	struct ipsec_sa *sa;
-
-	priv = get_priv(pkt);
-
-	sa = priv->sa;
-	if (unlikely(sa == NULL)) {
-		RTE_LOG(ERR, IPSEC, "SA not saved in private data\n");
-		goto fail;
-	}
-
-	if (is_ipv6)
-		return sa->portid;
-
-	/* else */
-	return (sa->portid | RTE_LPM_LOOKUP_SUCCESS);
-
-fail:
-	if (is_ipv6)
-		return -1;
-
-	/* else */
-	return 0;
-}
-
-static inline void
-route4_pkts(struct rt_ctx *rt_ctx, struct rte_mbuf *pkts[], uint8_t nb_pkts)
-{
-	uint32_t hop[MAX_PKT_BURST * 2];
-	uint32_t dst_ip[MAX_PKT_BURST * 2];
-	int32_t pkt_hop = 0;
-	uint16_t i, offset;
-	uint16_t lpm_pkts = 0;
-
-	if (nb_pkts == 0)
-		return;
-
-	/* Need to do an LPM lookup for non-inline packets. Inline packets will
-	 * have port ID in the SA
-	 */
-
-	for (i = 0; i < nb_pkts; i++) {
-		if (!(pkts[i]->ol_flags & PKT_TX_SEC_OFFLOAD)) {
-			/* Security offload not enabled. So an LPM lookup is
-			 * required to get the hop
-			 */
-			offset = offsetof(struct ip, ip_dst);
-			dst_ip[lpm_pkts] = *rte_pktmbuf_mtod_offset(pkts[i],
-					uint32_t *, offset);
-			dst_ip[lpm_pkts] = rte_be_to_cpu_32(dst_ip[lpm_pkts]);
-			lpm_pkts++;
-		}
-	}
-
-	rte_lpm_lookup_bulk((struct rte_lpm *)rt_ctx, dst_ip, hop, lpm_pkts);
-
-	lpm_pkts = 0;
-
-	for (i = 0; i < nb_pkts; i++) {
-		if (pkts[i]->ol_flags & PKT_TX_SEC_OFFLOAD) {
-			/* Read hop from the SA */
-			pkt_hop = get_hop_for_offload_pkt(pkts[i], 0);
-		} else {
-			/* Need to use hop returned by lookup */
-			pkt_hop = hop[lpm_pkts++];
-		}
-
-		if ((pkt_hop & RTE_LPM_LOOKUP_SUCCESS) == 0) {
-			rte_pktmbuf_free(pkts[i]);
-			continue;
-		}
-		send_single_packet(pkts[i], pkt_hop & 0xff);
-	}
-}
-
-static inline void
-route6_pkts(struct rt_ctx *rt_ctx, struct rte_mbuf *pkts[], uint8_t nb_pkts)
-{
-	int32_t hop[MAX_PKT_BURST * 2];
-	uint8_t dst_ip[MAX_PKT_BURST * 2][16];
-	uint8_t *ip6_dst;
-	int32_t pkt_hop = 0;
-	uint16_t i, offset;
-	uint16_t lpm_pkts = 0;
-
-	if (nb_pkts == 0)
-		return;
-
-	/* Need to do an LPM lookup for non-inline packets. Inline packets will
-	 * have port ID in the SA
-	 */
-
-	for (i = 0; i < nb_pkts; i++) {
-		if (!(pkts[i]->ol_flags & PKT_TX_SEC_OFFLOAD)) {
-			/* Security offload not enabled. So an LPM lookup is
-			 * required to get the hop
-			 */
-			offset = offsetof(struct ip6_hdr, ip6_dst);
-			ip6_dst = rte_pktmbuf_mtod_offset(pkts[i], uint8_t *,
-					offset);
-			memcpy(&dst_ip[lpm_pkts][0], ip6_dst, 16);
-			lpm_pkts++;
-		}
-	}
-
-	rte_lpm6_lookup_bulk_func((struct rte_lpm6 *)rt_ctx, dst_ip, hop,
-			lpm_pkts);
-
-	lpm_pkts = 0;
-
-	for (i = 0; i < nb_pkts; i++) {
-		if (pkts[i]->ol_flags & PKT_TX_SEC_OFFLOAD) {
-			/* Read hop from the SA */
-			pkt_hop = get_hop_for_offload_pkt(pkts[i], 1);
-		} else {
-			/* Need to use hop returned by lookup */
-			pkt_hop = hop[lpm_pkts++];
-		}
-
-		if (pkt_hop == -1) {
-			rte_pktmbuf_free(pkts[i]);
-			continue;
-		}
-		send_single_packet(pkts[i], pkt_hop & 0xff);
-	}
-}
-
-static inline void
-process_pkts(struct lcore_conf *qconf, struct rte_mbuf **pkts,
-		uint8_t nb_pkts, uint16_t portid)
-{
-	struct ipsec_traffic traffic;
-
-	prepare_traffic(pkts, &traffic, nb_pkts);
-
-	if (unlikely(single_sa)) {
-		if (UNPROTECTED_PORT(portid))
-			process_pkts_inbound_nosp(&qconf->inbound, &traffic);
-		else
-			process_pkts_outbound_nosp(&qconf->outbound, &traffic);
-	} else {
-		if (UNPROTECTED_PORT(portid))
-			process_pkts_inbound(&qconf->inbound, &traffic);
-		else
-			process_pkts_outbound(&qconf->outbound, &traffic);
-	}
-
-	route4_pkts(qconf->rt4_ctx, traffic.ip4.pkts, traffic.ip4.num);
-	route6_pkts(qconf->rt6_ctx, traffic.ip6.pkts, traffic.ip6.num);
-}
-
-static inline void
-drain_buffers(struct lcore_conf *qconf)
-{
-	struct buffer *buf;
-	uint32_t portid;
-
-	for (portid = 0; portid < RTE_MAX_ETHPORTS; portid++) {
-		buf = &qconf->tx_mbufs[portid];
-		if (buf->len == 0)
-			continue;
-		send_burst(qconf, buf->len, portid);
-		buf->len = 0;
-	}
-}
-
-/* main processing loop */
-static int32_t
-main_loop(__attribute__((unused)) void *dummy)
-{
-	struct rte_mbuf *pkts[MAX_PKT_BURST];
-	uint32_t lcore_id;
-	uint64_t prev_tsc, diff_tsc, cur_tsc;
-	int32_t i, nb_rx;
-	uint16_t portid;
-	uint8_t queueid;
-	struct lcore_conf *qconf;
-	int32_t socket_id;
-	const uint64_t drain_tsc = (rte_get_tsc_hz() + US_PER_S - 1)
-			/ US_PER_S * BURST_TX_DRAIN_US;
-	struct lcore_rx_queue *rxql;
-
-	prev_tsc = 0;
-	lcore_id = rte_lcore_id();
-	qconf = &lcore_conf[lcore_id];
-	rxql = qconf->rx_queue_list;
-	socket_id = rte_lcore_to_socket_id(lcore_id);
-
-	qconf->rt4_ctx = socket_ctx[socket_id].rt_ip4;
-	qconf->rt6_ctx = socket_ctx[socket_id].rt_ip6;
-	qconf->inbound.sp4_ctx = socket_ctx[socket_id].sp_ip4_in;
-	qconf->inbound.sp6_ctx = socket_ctx[socket_id].sp_ip6_in;
-	qconf->inbound.sa_ctx = socket_ctx[socket_id].sa_in;
-	qconf->inbound.cdev_map = cdev_map_in;
-	qconf->inbound.session_pool = socket_ctx[socket_id].session_pool;
-	qconf->outbound.sp4_ctx = socket_ctx[socket_id].sp_ip4_out;
-	qconf->outbound.sp6_ctx = socket_ctx[socket_id].sp_ip6_out;
-	qconf->outbound.sa_ctx = socket_ctx[socket_id].sa_out;
-	qconf->outbound.cdev_map = cdev_map_out;
-	qconf->outbound.session_pool = socket_ctx[socket_id].session_pool;
-
-	if (qconf->nb_rx_queue == 0) {
-		RTE_LOG(INFO, IPSEC, "lcore %u has nothing to do\n", lcore_id);
-		return 0;
-	}
-
-	RTE_LOG(INFO, IPSEC, "entering main loop on lcore %u\n", lcore_id);
-
-	for (i = 0; i < qconf->nb_rx_queue; i++) {
-		portid = rxql[i].port_id;
-		queueid = rxql[i].queue_id;
-		RTE_LOG(INFO, IPSEC,
-			" -- lcoreid=%u portid=%u rxqueueid=%hhu\n",
-			lcore_id, portid, queueid);
-	}
-
-	while (1) {
-		cur_tsc = rte_rdtsc();
-
-		/* TX queue buffer drain */
-		diff_tsc = cur_tsc - prev_tsc;
-
-		if (unlikely(diff_tsc > drain_tsc)) {
-			drain_buffers(qconf);
-			prev_tsc = cur_tsc;
-		}
-
-		/* Read packet from RX queues */
-		for (i = 0; i < qconf->nb_rx_queue; ++i) {
-			portid = rxql[i].port_id;
-			queueid = rxql[i].queue_id;
-			nb_rx = rte_eth_rx_burst(portid, queueid,
-					pkts, MAX_PKT_BURST);
-
-			if (nb_rx > 0)
-				process_pkts(qconf, pkts, nb_rx, portid);
-		}
-	}
-}
-
-static int32_t
-check_params(void)
-{
-	uint8_t lcore;
-	uint16_t portid;
-	uint16_t i;
-	int32_t socket_id;
-
-	if (lcore_params == NULL) {
-		printf("Error: No port/queue/core mappings\n");
-		return -1;
-	}
-
-	for (i = 0; i < nb_lcore_params; ++i) {
-		lcore = lcore_params[i].lcore_id;
-		if (!rte_lcore_is_enabled(lcore)) {
-			printf("error: lcore %hhu is not enabled in "
-				"lcore mask\n", lcore);
-			return -1;
-		}
-		socket_id = rte_lcore_to_socket_id(lcore);
-		if (socket_id != 0 && numa_on == 0) {
-			printf("warning: lcore %hhu is on socket %d "
-				"with numa off\n",
-				lcore, socket_id);
-		}
-		portid = lcore_params[i].port_id;
-		if ((enabled_port_mask & (1 << portid)) == 0) {
-			printf("port %u is not enabled in port mask\n", portid);
-			return -1;
-		}
-		if (!rte_eth_dev_is_valid_port(portid)) {
-			printf("port %u is not present on the board\n", portid);
-			return -1;
-		}
-	}
-	return 0;
-}
-
-static uint8_t
-get_port_nb_rx_queues(const uint16_t port)
-{
-	int32_t queue = -1;
-	uint16_t i;
-
-	for (i = 0; i < nb_lcore_params; ++i) {
-		if (lcore_params[i].port_id == port &&
-				lcore_params[i].queue_id > queue)
-			queue = lcore_params[i].queue_id;
-	}
-	return (uint8_t)(++queue);
-}
-
-static int32_t
-init_lcore_rx_queues(void)
-{
-	uint16_t i, nb_rx_queue;
-	uint8_t lcore;
-
-	for (i = 0; i < nb_lcore_params; ++i) {
-		lcore = lcore_params[i].lcore_id;
-		nb_rx_queue = lcore_conf[lcore].nb_rx_queue;
-		if (nb_rx_queue >= MAX_RX_QUEUE_PER_LCORE) {
-			printf("error: too many queues (%u) for lcore: %u\n",
-					nb_rx_queue + 1, lcore);
-			return -1;
-		}
-		lcore_conf[lcore].rx_queue_list[nb_rx_queue].port_id =
-			lcore_params[i].port_id;
-		lcore_conf[lcore].rx_queue_list[nb_rx_queue].queue_id =
-			lcore_params[i].queue_id;
-		lcore_conf[lcore].nb_rx_queue++;
-	}
-	return 0;
-}
-
-/* display usage */
-static void
-print_usage(const char *prgname)
-{
-	fprintf(stderr, "%s [EAL options] --"
-		" -p PORTMASK"
-		" [-P]"
-		" [-u PORTMASK]"
-		" [-j FRAMESIZE]"
-		" -f CONFIG_FILE"
-		" --config (port,queue,lcore)[,(port,queue,lcore)]"
-		" [--single-sa SAIDX]"
-		" [--cryptodev_mask MASK]"
-		"\n\n"
-		"  -p PORTMASK: Hexadecimal bitmask of ports to configure\n"
-		"  -P : Enable promiscuous mode\n"
-		"  -u PORTMASK: Hexadecimal bitmask of unprotected ports\n"
-		"  -j FRAMESIZE: Enable jumbo frame with 'FRAMESIZE' as maximum\n"
-		"                packet size\n"
-		"  -f CONFIG_FILE: Configuration file\n"
-		"  --config (port,queue,lcore): Rx queue configuration\n"
-		"  --single-sa SAIDX: Use single SA index for outbound traffic,\n"
-		"                     bypassing the SP\n"
-		"  --cryptodev_mask MASK: Hexadecimal bitmask of the crypto\n"
-		"                         devices to configure\n"
-		"\n",
-		prgname);
-}
-
-static int32_t
-parse_portmask(const char *portmask)
-{
-	char *end = NULL;
-	unsigned long pm;
-
-	/* parse hexadecimal string */
-	pm = strtoul(portmask, &end, 16);
-	if ((portmask[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if ((pm == 0) && errno)
-		return -1;
-
-	return pm;
-}
-
-static int32_t
-parse_decimal(const char *str)
-{
-	char *end = NULL;
-	unsigned long num;
-
-	num = strtoul(str, &end, 10);
-	if ((str[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	return num;
-}
-
-static int32_t
-parse_config(const char *q_arg)
-{
-	char s[256];
-	const char *p, *p0 = q_arg;
-	char *end;
-	enum fieldnames {
-		FLD_PORT = 0,
-		FLD_QUEUE,
-		FLD_LCORE,
-		_NUM_FLD
-	};
-	unsigned long int_fld[_NUM_FLD];
-	char *str_fld[_NUM_FLD];
-	int32_t i;
-	uint32_t size;
-
-	nb_lcore_params = 0;
-
-	while ((p = strchr(p0, '(')) != NULL) {
-		++p;
-		p0 = strchr(p, ')');
-		if (p0 == NULL)
-			return -1;
-
-		size = p0 - p;
-		if (size >= sizeof(s))
-			return -1;
-
-		snprintf(s, sizeof(s), "%.*s", size, p);
-		if (rte_strsplit(s, sizeof(s), str_fld, _NUM_FLD, ',') !=
-				_NUM_FLD)
-			return -1;
-		for (i = 0; i < _NUM_FLD; i++) {
-			errno = 0;
-			int_fld[i] = strtoul(str_fld[i], &end, 0);
-			if (errno != 0 || end == str_fld[i] || int_fld[i] > 255)
-				return -1;
-		}
-		if (nb_lcore_params >= MAX_LCORE_PARAMS) {
-			printf("exceeded max number of lcore params: %hu\n",
-				nb_lcore_params);
-			return -1;
-		}
-		lcore_params_array[nb_lcore_params].port_id =
-			(uint8_t)int_fld[FLD_PORT];
-		lcore_params_array[nb_lcore_params].queue_id =
-			(uint8_t)int_fld[FLD_QUEUE];
-		lcore_params_array[nb_lcore_params].lcore_id =
-			(uint8_t)int_fld[FLD_LCORE];
-		++nb_lcore_params;
-	}
-	lcore_params = lcore_params_array;
-	return 0;
-}
-
-#define __STRNCMP(name, opt) (!strncmp(name, opt, sizeof(opt)))
-static int32_t
-parse_args_long_options(struct option *lgopts, int32_t option_index)
-{
-	int32_t ret = -1;
-	const char *optname = lgopts[option_index].name;
-
-	if (__STRNCMP(optname, OPTION_CONFIG)) {
-		ret = parse_config(optarg);
-		if (ret)
-			printf("invalid config\n");
-	}
-
-	if (__STRNCMP(optname, OPTION_SINGLE_SA)) {
-		ret = parse_decimal(optarg);
-		if (ret != -1) {
-			single_sa = 1;
-			single_sa_idx = ret;
-			printf("Configured with single SA index %u\n",
-					single_sa_idx);
-			ret = 0;
-		}
-	}
-
-	if (__STRNCMP(optname, OPTION_CRYPTODEV_MASK)) {
-		ret = parse_portmask(optarg);
-		if (ret != -1) {
-			enabled_cryptodev_mask = ret;
-			ret = 0;
-		}
-	}
-
-	return ret;
-}
-#undef __STRNCMP
-
-static int32_t
-parse_args(int32_t argc, char **argv)
-{
-	int32_t opt, ret;
-	char **argvopt;
-	int32_t option_index;
-	char *prgname = argv[0];
-	static struct option lgopts[] = {
-		{OPTION_CONFIG, 1, 0, 0},
-		{OPTION_SINGLE_SA, 1, 0, 0},
-		{OPTION_CRYPTODEV_MASK, 1, 0, 0},
-		{NULL, 0, 0, 0}
-	};
-	int32_t f_present = 0;
-
-	argvopt = argv;
-
-	while ((opt = getopt_long(argc, argvopt, "p:Pu:f:j:",
-				lgopts, &option_index)) != EOF) {
-
-		switch (opt) {
-		case 'p':
-			enabled_port_mask = parse_portmask(optarg);
-			if (enabled_port_mask == 0) {
-				printf("invalid portmask\n");
-				print_usage(prgname);
-				return -1;
-			}
-			break;
-		case 'P':
-			printf("Promiscuous mode selected\n");
-			promiscuous_on = 1;
-			break;
-		case 'u':
-			unprotected_port_mask = parse_portmask(optarg);
-			if (unprotected_port_mask == 0) {
-				printf("invalid unprotected portmask\n");
-				print_usage(prgname);
-				return -1;
-			}
-			break;
-		case 'f':
-			if (f_present == 1) {
-				printf("\"-f\" option present more than "
-					"once!\n");
-				print_usage(prgname);
-				return -1;
-			}
-			if (parse_cfg_file(optarg) < 0) {
-				printf("parsing file \"%s\" failed\n",
-					optarg);
-				print_usage(prgname);
-				return -1;
-			}
-			f_present = 1;
-			break;
-		case 'j':
-			{
-				int32_t size = parse_decimal(optarg);
-				if (size <= 1518) {
-					printf("Invalid jumbo frame size\n");
-					if (size < 0) {
-						print_usage(prgname);
-						return -1;
-					}
-					printf("Using default value 9000\n");
-					frame_size = 9000;
-				} else {
-					frame_size = size;
-				}
-			}
-			printf("Enabled jumbo frames size %u\n", frame_size);
-			break;
-		case 0:
-			if (parse_args_long_options(lgopts, option_index)) {
-				print_usage(prgname);
-				return -1;
-			}
-			break;
-		default:
-			print_usage(prgname);
-			return -1;
-		}
-	}
-
-	if (f_present == 0) {
-		printf("Mandatory option \"-f\" not present\n");
-		return -1;
-	}
-
-	if (optind >= 0)
-		argv[optind-1] = prgname;
-
-	ret = optind-1;
-	optind = 1; /* reset getopt lib */
-	return ret;
-}
-
-static void
-print_ethaddr(const char *name, const struct ether_addr *eth_addr)
-{
-	char buf[ETHER_ADDR_FMT_SIZE];
-	ether_format_addr(buf, ETHER_ADDR_FMT_SIZE, eth_addr);
-	printf("%s%s", name, buf);
-}
-
-/* Check the link status of all ports in up to 9s, and print them finally */
-static void
-check_all_ports_link_status(uint32_t port_mask)
-{
-#define CHECK_INTERVAL 100 /* 100ms */
-#define MAX_CHECK_TIME 90 /* 9s (90 * 100ms) in total */
-	uint16_t portid;
-	uint8_t count, all_ports_up, print_flag = 0;
-	struct rte_eth_link link;
-
-	printf("\nChecking link status");
-	fflush(stdout);
-	for (count = 0; count <= MAX_CHECK_TIME; count++) {
-		all_ports_up = 1;
-		RTE_ETH_FOREACH_DEV(portid) {
-			if ((port_mask & (1 << portid)) == 0)
-				continue;
-			memset(&link, 0, sizeof(link));
-			rte_eth_link_get_nowait(portid, &link);
-			/* print link status if flag set */
-			if (print_flag == 1) {
-				if (link.link_status)
-					printf(
-					"Port%d Link Up - speed %u Mbps -%s\n",
-						portid, link.link_speed,
-				(link.link_duplex == ETH_LINK_FULL_DUPLEX) ?
-					("full-duplex") : ("half-duplex\n"));
-				else
-					printf("Port %d Link Down\n", portid);
-				continue;
-			}
-			/* clear all_ports_up flag if any link down */
-			if (link.link_status == ETH_LINK_DOWN) {
-				all_ports_up = 0;
-				break;
-			}
-		}
-		/* after finally printing all link status, get out */
-		if (print_flag == 1)
-			break;
-
-		if (all_ports_up == 0) {
-			printf(".");
-			fflush(stdout);
-			rte_delay_ms(CHECK_INTERVAL);
-		}
-
-		/* set the print_flag if all ports up or timeout */
-		if (all_ports_up == 1 || count == (MAX_CHECK_TIME - 1)) {
-			print_flag = 1;
-			printf("done\n");
-		}
-	}
-}
-
-static int32_t
-add_mapping(struct rte_hash *map, const char *str, uint16_t cdev_id,
-		uint16_t qp, struct lcore_params *params,
-		struct ipsec_ctx *ipsec_ctx,
-		const struct rte_cryptodev_capabilities *cipher,
-		const struct rte_cryptodev_capabilities *auth,
-		const struct rte_cryptodev_capabilities *aead)
-{
-	int32_t ret = 0;
-	unsigned long i;
-	struct cdev_key key = { 0 };
-
-	key.lcore_id = params->lcore_id;
-	if (cipher)
-		key.cipher_algo = cipher->sym.cipher.algo;
-	if (auth)
-		key.auth_algo = auth->sym.auth.algo;
-	if (aead)
-		key.aead_algo = aead->sym.aead.algo;
-
-	ret = rte_hash_lookup(map, &key);
-	if (ret != -ENOENT)
-		return 0;
-
-	for (i = 0; i < ipsec_ctx->nb_qps; i++)
-		if (ipsec_ctx->tbl[i].id == cdev_id)
-			break;
-
-	if (i == ipsec_ctx->nb_qps) {
-		if (ipsec_ctx->nb_qps == MAX_QP_PER_LCORE) {
-			printf("Maximum number of crypto devices assigned to "
-				"a core, increase MAX_QP_PER_LCORE value\n");
-			return 0;
-		}
-		ipsec_ctx->tbl[i].id = cdev_id;
-		ipsec_ctx->tbl[i].qp = qp;
-		ipsec_ctx->nb_qps++;
-		printf("%s cdev mapping: lcore %u using cdev %u qp %u "
-				"(cdev_id_qp %lu)\n", str, key.lcore_id,
-				cdev_id, qp, i);
-	}
-
-	ret = rte_hash_add_key_data(map, &key, (void *)i);
-	if (ret < 0) {
-		printf("Faled to insert cdev mapping for (lcore %u, "
-				"cdev %u, qp %u), errno %d\n",
-				key.lcore_id, ipsec_ctx->tbl[i].id,
-				ipsec_ctx->tbl[i].qp, ret);
-		return 0;
-	}
-
-	return 1;
-}
-
-static int32_t
-add_cdev_mapping(struct rte_cryptodev_info *dev_info, uint16_t cdev_id,
-		uint16_t qp, struct lcore_params *params)
-{
-	int32_t ret = 0;
-	const struct rte_cryptodev_capabilities *i, *j;
-	struct rte_hash *map;
-	struct lcore_conf *qconf;
-	struct ipsec_ctx *ipsec_ctx;
-	const char *str;
-
-	qconf = &lcore_conf[params->lcore_id];
-
-	if ((unprotected_port_mask & (1 << params->port_id)) == 0) {
-		map = cdev_map_out;
-		ipsec_ctx = &qconf->outbound;
-		str = "Outbound";
-	} else {
-		map = cdev_map_in;
-		ipsec_ctx = &qconf->inbound;
-		str = "Inbound";
-	}
-
-	/* Required cryptodevs with operation chainning */
-	if (!(dev_info->feature_flags &
-				RTE_CRYPTODEV_FF_SYM_OPERATION_CHAINING))
-		return ret;
-
-	for (i = dev_info->capabilities;
-			i->op != RTE_CRYPTO_OP_TYPE_UNDEFINED; i++) {
-		if (i->op != RTE_CRYPTO_OP_TYPE_SYMMETRIC)
-			continue;
-
-		if (i->sym.xform_type == RTE_CRYPTO_SYM_XFORM_AEAD) {
-			ret |= add_mapping(map, str, cdev_id, qp, params,
-					ipsec_ctx, NULL, NULL, i);
-			continue;
-		}
-
-		if (i->sym.xform_type != RTE_CRYPTO_SYM_XFORM_CIPHER)
-			continue;
-
-		for (j = dev_info->capabilities;
-				j->op != RTE_CRYPTO_OP_TYPE_UNDEFINED; j++) {
-			if (j->op != RTE_CRYPTO_OP_TYPE_SYMMETRIC)
-				continue;
-
-			if (j->sym.xform_type != RTE_CRYPTO_SYM_XFORM_AUTH)
-				continue;
-
-			ret |= add_mapping(map, str, cdev_id, qp, params,
-						ipsec_ctx, i, j, NULL);
-		}
-	}
-
-	return ret;
-}
-
-/* Check if the device is enabled by cryptodev_mask */
-static int
-check_cryptodev_mask(uint8_t cdev_id)
-{
-	if (enabled_cryptodev_mask & (1 << cdev_id))
-		return 0;
-
-	return -1;
-}
-
-static int32_t
-cryptodevs_init(void)
-{
-	struct rte_cryptodev_config dev_conf;
-	struct rte_cryptodev_qp_conf qp_conf;
-	uint16_t idx, max_nb_qps, qp, i;
-	int16_t cdev_id, port_id;
-	struct rte_hash_parameters params = { 0 };
-
-	params.entries = CDEV_MAP_ENTRIES;
-	params.key_len = sizeof(struct cdev_key);
-	params.hash_func = rte_jhash;
-	params.hash_func_init_val = 0;
-	params.socket_id = rte_socket_id();
-
-	params.name = "cdev_map_in";
-	cdev_map_in = rte_hash_create(&params);
-	if (cdev_map_in == NULL)
-		rte_panic("Failed to create cdev_map hash table, errno = %d\n",
-				rte_errno);
-
-	params.name = "cdev_map_out";
-	cdev_map_out = rte_hash_create(&params);
-	if (cdev_map_out == NULL)
-		rte_panic("Failed to create cdev_map hash table, errno = %d\n",
-				rte_errno);
-
-	printf("lcore/cryptodev/qp mappings:\n");
-
-	uint32_t max_sess_sz = 0, sess_sz;
-	for (cdev_id = 0; cdev_id < rte_cryptodev_count(); cdev_id++) {
-		sess_sz = rte_cryptodev_get_private_session_size(cdev_id);
-		if (sess_sz > max_sess_sz)
-			max_sess_sz = sess_sz;
-	}
-	RTE_ETH_FOREACH_DEV(port_id) {
-		void *sec_ctx;
-
-		if ((enabled_port_mask & (1 << port_id)) == 0)
-			continue;
-
-		sec_ctx = rte_eth_dev_get_sec_ctx(port_id);
-		if (sec_ctx == NULL)
-			continue;
-
-		sess_sz = rte_security_session_get_size(sec_ctx);
-		if (sess_sz > max_sess_sz)
-			max_sess_sz = sess_sz;
-	}
-
-	idx = 0;
-	for (cdev_id = 0; cdev_id < rte_cryptodev_count(); cdev_id++) {
-		struct rte_cryptodev_info cdev_info;
-
-		if (check_cryptodev_mask((uint8_t)cdev_id))
-			continue;
-
-		rte_cryptodev_info_get(cdev_id, &cdev_info);
-
-		if (nb_lcore_params > cdev_info.max_nb_queue_pairs)
-			max_nb_qps = cdev_info.max_nb_queue_pairs;
-		else
-			max_nb_qps = nb_lcore_params;
-
-		qp = 0;
-		i = 0;
-		while (qp < max_nb_qps && i < nb_lcore_params) {
-			if (add_cdev_mapping(&cdev_info, cdev_id, qp,
-						&lcore_params[idx]))
-				qp++;
-			idx++;
-			idx = idx % nb_lcore_params;
-			i++;
-		}
-
-		if (qp == 0)
-			continue;
-
-		dev_conf.socket_id = rte_cryptodev_socket_id(cdev_id);
-		dev_conf.nb_queue_pairs = qp;
-
-		if (!socket_ctx[dev_conf.socket_id].session_pool) {
-			char mp_name[RTE_MEMPOOL_NAMESIZE];
-			struct rte_mempool *sess_mp;
-
-			snprintf(mp_name, RTE_MEMPOOL_NAMESIZE,
-					"sess_mp_%u", dev_conf.socket_id);
-			sess_mp = rte_mempool_create(mp_name,
-					CDEV_MP_NB_OBJS,
-					max_sess_sz,
-					CDEV_MP_CACHE_SZ,
-					0, NULL, NULL, NULL,
-					NULL, dev_conf.socket_id,
-					0);
-			if (sess_mp == NULL)
-				rte_exit(EXIT_FAILURE,
-					"Cannot create session pool on socket %d\n",
-					dev_conf.socket_id);
-			else
-				printf("Allocated session pool on socket %d\n",
-					dev_conf.socket_id);
-			socket_ctx[dev_conf.socket_id].session_pool = sess_mp;
-		}
-
-		if (rte_cryptodev_configure(cdev_id, &dev_conf))
-			rte_panic("Failed to initialize cryptodev %u\n",
-					cdev_id);
-
-		qp_conf.nb_descriptors = CDEV_QUEUE_DESC;
-		for (qp = 0; qp < dev_conf.nb_queue_pairs; qp++)
-			if (rte_cryptodev_queue_pair_setup(cdev_id, qp,
-					&qp_conf, dev_conf.socket_id,
-					socket_ctx[dev_conf.socket_id].session_pool))
-				rte_panic("Failed to setup queue %u for "
-						"cdev_id %u\n",	0, cdev_id);
-
-		if (rte_cryptodev_start(cdev_id))
-			rte_panic("Failed to start cryptodev %u\n",
-					cdev_id);
-	}
-
-	/* create session pools for eth devices that implement security */
-	RTE_ETH_FOREACH_DEV(port_id) {
-		if ((enabled_port_mask & (1 << port_id)) &&
-				rte_eth_dev_get_sec_ctx(port_id)) {
-			int socket_id = rte_eth_dev_socket_id(port_id);
-
-			if (!socket_ctx[socket_id].session_pool) {
-				char mp_name[RTE_MEMPOOL_NAMESIZE];
-				struct rte_mempool *sess_mp;
-
-				snprintf(mp_name, RTE_MEMPOOL_NAMESIZE,
-						"sess_mp_%u", socket_id);
-				sess_mp = rte_mempool_create(mp_name,
-						CDEV_MP_NB_OBJS,
-						max_sess_sz,
-						CDEV_MP_CACHE_SZ,
-						0, NULL, NULL, NULL,
-						NULL, socket_id,
-						0);
-				if (sess_mp == NULL)
-					rte_exit(EXIT_FAILURE,
-						"Cannot create session pool "
-						"on socket %d\n", socket_id);
-				else
-					printf("Allocated session pool "
-						"on socket %d\n", socket_id);
-				socket_ctx[socket_id].session_pool = sess_mp;
-			}
-		}
-	}
-
-
-	printf("\n");
-
-	return 0;
-}
-
-static void
-port_init(uint16_t portid)
-{
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_txconf *txconf;
-	uint16_t nb_tx_queue, nb_rx_queue;
-	uint16_t tx_queueid, rx_queueid, queue, lcore_id;
-	int32_t ret, socket_id;
-	struct lcore_conf *qconf;
-	struct ether_addr ethaddr;
-	struct rte_eth_conf local_port_conf = port_conf;
-
-	rte_eth_dev_info_get(portid, &dev_info);
-
-	printf("Configuring device port %u:\n", portid);
-
-	rte_eth_macaddr_get(portid, &ethaddr);
-	ethaddr_tbl[portid].src = ETHADDR_TO_UINT64(ethaddr);
-	print_ethaddr("Address: ", &ethaddr);
-	printf("\n");
-
-	nb_rx_queue = get_port_nb_rx_queues(portid);
-	nb_tx_queue = nb_lcores;
-
-	if (nb_rx_queue > dev_info.max_rx_queues)
-		rte_exit(EXIT_FAILURE, "Error: queue %u not available "
-				"(max rx queue is %u)\n",
-				nb_rx_queue, dev_info.max_rx_queues);
-
-	if (nb_tx_queue > dev_info.max_tx_queues)
-		rte_exit(EXIT_FAILURE, "Error: queue %u not available "
-				"(max tx queue is %u)\n",
-				nb_tx_queue, dev_info.max_tx_queues);
-
-	printf("Creating queues: nb_rx_queue=%d nb_tx_queue=%u...\n",
-			nb_rx_queue, nb_tx_queue);
-
-	if (frame_size) {
-		local_port_conf.rxmode.max_rx_pkt_len = frame_size;
-		local_port_conf.rxmode.offloads |= DEV_RX_OFFLOAD_JUMBO_FRAME;
-	}
-
-	if (dev_info.rx_offload_capa & DEV_RX_OFFLOAD_SECURITY)
-		local_port_conf.rxmode.offloads |= DEV_RX_OFFLOAD_SECURITY;
-	if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_SECURITY)
-		local_port_conf.txmode.offloads |= DEV_TX_OFFLOAD_SECURITY;
-	if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-		local_port_conf.txmode.offloads |=
-			DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-	ret = rte_eth_dev_configure(portid, nb_rx_queue, nb_tx_queue,
-			&local_port_conf);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Cannot configure device: "
-				"err=%d, port=%d\n", ret, portid);
-
-	ret = rte_eth_dev_adjust_nb_rx_tx_desc(portid, &nb_rxd, &nb_txd);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Cannot adjust number of descriptors: "
-				"err=%d, port=%d\n", ret, portid);
-
-	/* init one TX queue per lcore */
-	tx_queueid = 0;
-	for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-		if (rte_lcore_is_enabled(lcore_id) == 0)
-			continue;
-
-		if (numa_on)
-			socket_id = (uint8_t)rte_lcore_to_socket_id(lcore_id);
-		else
-			socket_id = 0;
-
-		/* init TX queue */
-		printf("Setup txq=%u,%d,%d\n", lcore_id, tx_queueid, socket_id);
-
-		txconf = &dev_info.default_txconf;
-		txconf->txq_flags = ETH_TXQ_FLAGS_IGNORE;
-		txconf->offloads = local_port_conf.txmode.offloads;
-
-		ret = rte_eth_tx_queue_setup(portid, tx_queueid, nb_txd,
-				socket_id, txconf);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "rte_eth_tx_queue_setup: "
-					"err=%d, port=%d\n", ret, portid);
-
-		qconf = &lcore_conf[lcore_id];
-		qconf->tx_queue_id[portid] = tx_queueid;
-		tx_queueid++;
-
-		/* init RX queues */
-		for (queue = 0; queue < qconf->nb_rx_queue; ++queue) {
-			struct rte_eth_rxconf rxq_conf;
-
-			if (portid != qconf->rx_queue_list[queue].port_id)
-				continue;
-
-			rx_queueid = qconf->rx_queue_list[queue].queue_id;
-
-			printf("Setup rxq=%d,%d,%d\n", portid, rx_queueid,
-					socket_id);
-
-			rxq_conf = dev_info.default_rxconf;
-			rxq_conf.offloads = local_port_conf.rxmode.offloads;
-			ret = rte_eth_rx_queue_setup(portid, rx_queueid,
-					nb_rxd,	socket_id, &rxq_conf,
-					socket_ctx[socket_id].mbuf_pool);
-			if (ret < 0)
-				rte_exit(EXIT_FAILURE,
-					"rte_eth_rx_queue_setup: err=%d, "
-					"port=%d\n", ret, portid);
-		}
-	}
-	printf("\n");
-}
-
-static void
-pool_init(struct socket_ctx *ctx, int32_t socket_id, uint32_t nb_mbuf)
-{
-	char s[64];
-	uint32_t buff_size = frame_size ? (frame_size + RTE_PKTMBUF_HEADROOM) :
-			RTE_MBUF_DEFAULT_BUF_SIZE;
-
-
-	snprintf(s, sizeof(s), "mbuf_pool_%d", socket_id);
-	ctx->mbuf_pool = rte_pktmbuf_pool_create(s, nb_mbuf,
-			MEMPOOL_CACHE_SIZE, ipsec_metadata_size(),
-			buff_size,
-			socket_id);
-	if (ctx->mbuf_pool == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot init mbuf pool on socket %d\n",
-				socket_id);
-	else
-		printf("Allocated mbuf pool on socket %d\n", socket_id);
-}
-
-int32_t
-main(int32_t argc, char **argv)
-{
-	int32_t ret;
-	uint32_t lcore_id;
-	uint8_t socket_id;
-	uint16_t portid;
-
-	/* init EAL */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid EAL parameters\n");
-	argc -= ret;
-	argv += ret;
-
-	/* parse application arguments (after the EAL ones) */
-	ret = parse_args(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid parameters\n");
-
-	if ((unprotected_port_mask & enabled_port_mask) !=
-			unprotected_port_mask)
-		rte_exit(EXIT_FAILURE, "Invalid unprotected portmask 0x%x\n",
-				unprotected_port_mask);
-
-	if (check_params() < 0)
-		rte_exit(EXIT_FAILURE, "check_params failed\n");
-
-	ret = init_lcore_rx_queues();
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "init_lcore_rx_queues failed\n");
-
-	nb_lcores = rte_lcore_count();
-
-	/* Replicate each context per socket */
-	for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-		if (rte_lcore_is_enabled(lcore_id) == 0)
-			continue;
-
-		if (numa_on)
-			socket_id = (uint8_t)rte_lcore_to_socket_id(lcore_id);
-		else
-			socket_id = 0;
-
-		if (socket_ctx[socket_id].mbuf_pool)
-			continue;
-
-		sa_init(&socket_ctx[socket_id], socket_id);
-
-		sp4_init(&socket_ctx[socket_id], socket_id);
-
-		sp6_init(&socket_ctx[socket_id], socket_id);
-
-		rt_init(&socket_ctx[socket_id], socket_id);
-
-		pool_init(&socket_ctx[socket_id], socket_id, NB_MBUF);
-	}
-
-	RTE_ETH_FOREACH_DEV(portid) {
-		if ((enabled_port_mask & (1 << portid)) == 0)
-			continue;
-
-		port_init(portid);
-	}
-
-	cryptodevs_init();
-
-	/* start ports */
-	RTE_ETH_FOREACH_DEV(portid) {
-		if ((enabled_port_mask & (1 << portid)) == 0)
-			continue;
-
-		/* Start device */
-		ret = rte_eth_dev_start(portid);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "rte_eth_dev_start: "
-					"err=%d, port=%d\n", ret, portid);
-		/*
-		 * If enabled, put device in promiscuous mode.
-		 * This allows IO forwarding mode to forward packets
-		 * to itself through 2 cross-connected  ports of the
-		 * target machine.
-		 */
-		if (promiscuous_on)
-			rte_eth_promiscuous_enable(portid);
-	}
-
-	check_all_ports_link_status(enabled_port_mask);
-
-	/* launch per-lcore init on every lcore */
-	rte_eal_mp_remote_launch(main_loop, NULL, CALL_MASTER);
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		if (rte_eal_wait_lcore(lcore_id) < 0)
-			return -1;
-	}
-
-	return 0;
-}
diff --git a/examples/ipsec-secgw/ipsec.c b/examples/ipsec-secgw/ipsec.c
deleted file mode 100644
index 5fb5bc1..0000000
--- a/examples/ipsec-secgw/ipsec.c
+++ /dev/null
@@ -1,573 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016-2017 Intel Corporation
- */
-#include <sys/types.h>
-#include <netinet/in.h>
-#include <netinet/ip.h>
-
-#include <rte_branch_prediction.h>
-#include <rte_log.h>
-#include <rte_crypto.h>
-#include <rte_security.h>
-#include <rte_cryptodev.h>
-#include <rte_ethdev.h>
-#include <rte_mbuf.h>
-#include <rte_hash.h>
-
-#include "ipsec.h"
-#include "esp.h"
-
-static inline void
-set_ipsec_conf(struct ipsec_sa *sa, struct rte_security_ipsec_xform *ipsec)
-{
-	if (ipsec->mode == RTE_SECURITY_IPSEC_SA_MODE_TUNNEL) {
-		struct rte_security_ipsec_tunnel_param *tunnel =
-				&ipsec->tunnel;
-		if (sa->flags == IP4_TUNNEL) {
-			tunnel->type =
-				RTE_SECURITY_IPSEC_TUNNEL_IPV4;
-			tunnel->ipv4.ttl = IPDEFTTL;
-
-			memcpy((uint8_t *)&tunnel->ipv4.src_ip,
-				(uint8_t *)&sa->src.ip.ip4, 4);
-
-			memcpy((uint8_t *)&tunnel->ipv4.dst_ip,
-				(uint8_t *)&sa->dst.ip.ip4, 4);
-		}
-		/* TODO support for Transport and IPV6 tunnel */
-	}
-}
-
-static inline int
-create_session(struct ipsec_ctx *ipsec_ctx, struct ipsec_sa *sa)
-{
-	struct rte_cryptodev_info cdev_info;
-	unsigned long cdev_id_qp = 0;
-	int32_t ret = 0;
-	struct cdev_key key = { 0 };
-
-	key.lcore_id = (uint8_t)rte_lcore_id();
-
-	key.cipher_algo = (uint8_t)sa->cipher_algo;
-	key.auth_algo = (uint8_t)sa->auth_algo;
-	key.aead_algo = (uint8_t)sa->aead_algo;
-
-	if (sa->type == RTE_SECURITY_ACTION_TYPE_NONE) {
-		ret = rte_hash_lookup_data(ipsec_ctx->cdev_map, &key,
-				(void **)&cdev_id_qp);
-		if (ret < 0) {
-			RTE_LOG(ERR, IPSEC,
-				"No cryptodev: core %u, cipher_algo %u, "
-				"auth_algo %u, aead_algo %u\n",
-				key.lcore_id,
-				key.cipher_algo,
-				key.auth_algo,
-				key.aead_algo);
-			return -1;
-		}
-	}
-
-	RTE_LOG_DP(DEBUG, IPSEC, "Create session for SA spi %u on cryptodev "
-			"%u qp %u\n", sa->spi,
-			ipsec_ctx->tbl[cdev_id_qp].id,
-			ipsec_ctx->tbl[cdev_id_qp].qp);
-
-	if (sa->type != RTE_SECURITY_ACTION_TYPE_NONE) {
-		struct rte_security_session_conf sess_conf = {
-			.action_type = sa->type,
-			.protocol = RTE_SECURITY_PROTOCOL_IPSEC,
-			{.ipsec = {
-				.spi = sa->spi,
-				.salt = sa->salt,
-				.options = { 0 },
-				.direction = sa->direction,
-				.proto = RTE_SECURITY_IPSEC_SA_PROTO_ESP,
-				.mode = (sa->flags == IP4_TUNNEL ||
-						sa->flags == IP6_TUNNEL) ?
-					RTE_SECURITY_IPSEC_SA_MODE_TUNNEL :
-					RTE_SECURITY_IPSEC_SA_MODE_TRANSPORT,
-			} },
-			.crypto_xform = sa->xforms,
-			.userdata = NULL,
-
-		};
-
-		if (sa->type == RTE_SECURITY_ACTION_TYPE_LOOKASIDE_PROTOCOL) {
-			struct rte_security_ctx *ctx = (struct rte_security_ctx *)
-							rte_cryptodev_get_sec_ctx(
-							ipsec_ctx->tbl[cdev_id_qp].id);
-
-			/* Set IPsec parameters in conf */
-			set_ipsec_conf(sa, &(sess_conf.ipsec));
-
-			sa->sec_session = rte_security_session_create(ctx,
-					&sess_conf, ipsec_ctx->session_pool);
-			if (sa->sec_session == NULL) {
-				RTE_LOG(ERR, IPSEC,
-				"SEC Session init failed: err: %d\n", ret);
-				return -1;
-			}
-		} else if (sa->type == RTE_SECURITY_ACTION_TYPE_INLINE_CRYPTO) {
-			struct rte_flow_error err;
-			struct rte_security_ctx *ctx = (struct rte_security_ctx *)
-							rte_eth_dev_get_sec_ctx(
-							sa->portid);
-			const struct rte_security_capability *sec_cap;
-			int ret = 0;
-
-			sa->sec_session = rte_security_session_create(ctx,
-					&sess_conf, ipsec_ctx->session_pool);
-			if (sa->sec_session == NULL) {
-				RTE_LOG(ERR, IPSEC,
-				"SEC Session init failed: err: %d\n", ret);
-				return -1;
-			}
-
-			sec_cap = rte_security_capabilities_get(ctx);
-
-			/* iterate until ESP tunnel*/
-			while (sec_cap->action !=
-					RTE_SECURITY_ACTION_TYPE_NONE) {
-
-				if (sec_cap->action == sa->type &&
-				    sec_cap->protocol ==
-					RTE_SECURITY_PROTOCOL_IPSEC &&
-				    sec_cap->ipsec.mode ==
-					RTE_SECURITY_IPSEC_SA_MODE_TUNNEL &&
-				    sec_cap->ipsec.direction == sa->direction)
-					break;
-				sec_cap++;
-			}
-
-			if (sec_cap->action == RTE_SECURITY_ACTION_TYPE_NONE) {
-				RTE_LOG(ERR, IPSEC,
-				"No suitable security capability found\n");
-				return -1;
-			}
-
-			sa->ol_flags = sec_cap->ol_flags;
-			sa->security_ctx = ctx;
-			sa->pattern[0].type = RTE_FLOW_ITEM_TYPE_ETH;
-
-			sa->pattern[1].type = RTE_FLOW_ITEM_TYPE_IPV4;
-			sa->pattern[1].mask = &rte_flow_item_ipv4_mask;
-			if (sa->flags & IP6_TUNNEL) {
-				sa->pattern[1].spec = &sa->ipv6_spec;
-				memcpy(sa->ipv6_spec.hdr.dst_addr,
-					sa->dst.ip.ip6.ip6_b, 16);
-				memcpy(sa->ipv6_spec.hdr.src_addr,
-				       sa->src.ip.ip6.ip6_b, 16);
-			} else {
-				sa->pattern[1].spec = &sa->ipv4_spec;
-				sa->ipv4_spec.hdr.dst_addr = sa->dst.ip.ip4;
-				sa->ipv4_spec.hdr.src_addr = sa->src.ip.ip4;
-			}
-
-			sa->pattern[2].type = RTE_FLOW_ITEM_TYPE_ESP;
-			sa->pattern[2].spec = &sa->esp_spec;
-			sa->pattern[2].mask = &rte_flow_item_esp_mask;
-			sa->esp_spec.hdr.spi = rte_cpu_to_be_32(sa->spi);
-
-			sa->pattern[3].type = RTE_FLOW_ITEM_TYPE_END;
-
-			sa->action[0].type = RTE_FLOW_ACTION_TYPE_SECURITY;
-			sa->action[0].conf = sa->sec_session;
-
-			sa->action[1].type = RTE_FLOW_ACTION_TYPE_END;
-
-			sa->attr.egress = (sa->direction ==
-					RTE_SECURITY_IPSEC_SA_DIR_EGRESS);
-			sa->attr.ingress = (sa->direction ==
-					RTE_SECURITY_IPSEC_SA_DIR_INGRESS);
-			if (sa->attr.ingress) {
-				uint8_t rss_key[40];
-				struct rte_eth_rss_conf rss_conf = {
-					.rss_key = rss_key,
-					.rss_key_len = 40,
-				};
-				struct rte_eth_dev *eth_dev;
-				union {
-					struct rte_flow_action_rss rss;
-					struct {
-					const struct rte_eth_rss_conf *rss_conf;
-					uint16_t num;
-					uint16_t queue[RTE_MAX_QUEUES_PER_PORT];
-					} local;
-				} action_rss;
-				unsigned int i;
-				unsigned int j;
-
-				sa->action[2].type = RTE_FLOW_ACTION_TYPE_END;
-				/* Try RSS. */
-				sa->action[1].type = RTE_FLOW_ACTION_TYPE_RSS;
-				sa->action[1].conf = &action_rss;
-				eth_dev = ctx->device;
-				rte_eth_dev_rss_hash_conf_get(sa->portid,
-							      &rss_conf);
-				for (i = 0, j = 0;
-				     i < eth_dev->data->nb_rx_queues; ++i)
-					if (eth_dev->data->rx_queues[i])
-						action_rss.local.queue[j++] = i;
-				action_rss.local.num = j;
-				action_rss.local.rss_conf = &rss_conf;
-				ret = rte_flow_validate(sa->portid, &sa->attr,
-							sa->pattern, sa->action,
-							&err);
-				if (!ret)
-					goto flow_create;
-				/* Try Queue. */
-				sa->action[1].type = RTE_FLOW_ACTION_TYPE_QUEUE;
-				sa->action[1].conf =
-					&(struct rte_flow_action_queue){
-					.index = 0,
-				};
-				ret = rte_flow_validate(sa->portid, &sa->attr,
-							sa->pattern, sa->action,
-							&err);
-				/* Try End. */
-				sa->action[1].type = RTE_FLOW_ACTION_TYPE_END;
-				sa->action[1].conf = NULL;
-				ret = rte_flow_validate(sa->portid, &sa->attr,
-							sa->pattern, sa->action,
-							&err);
-				if (ret)
-					goto flow_create_failure;
-			} else if (sa->attr.egress &&
-				   (sa->ol_flags &
-				    RTE_SECURITY_TX_HW_TRAILER_OFFLOAD)) {
-				sa->action[1].type =
-					RTE_FLOW_ACTION_TYPE_PASSTHRU;
-				sa->action[2].type =
-					RTE_FLOW_ACTION_TYPE_END;
-			}
-flow_create:
-			sa->flow = rte_flow_create(sa->portid,
-				&sa->attr, sa->pattern, sa->action, &err);
-			if (sa->flow == NULL) {
-flow_create_failure:
-				RTE_LOG(ERR, IPSEC,
-					"Failed to create ipsec flow msg: %s\n",
-					err.message);
-				return -1;
-			}
-		} else if (sa->type ==
-				RTE_SECURITY_ACTION_TYPE_INLINE_PROTOCOL) {
-			struct rte_security_ctx *ctx =
-					(struct rte_security_ctx *)
-					rte_eth_dev_get_sec_ctx(sa->portid);
-			const struct rte_security_capability *sec_cap;
-
-			if (ctx == NULL) {
-				RTE_LOG(ERR, IPSEC,
-				"Ethernet device doesn't have security features registered\n");
-				return -1;
-			}
-
-			/* Set IPsec parameters in conf */
-			set_ipsec_conf(sa, &(sess_conf.ipsec));
-
-			/* Save SA as userdata for the security session. When
-			 * the packet is received, this userdata will be
-			 * retrieved using the metadata from the packet.
-			 *
-			 * This is required only for inbound SAs.
-			 */
-
-			if (sa->direction == RTE_SECURITY_IPSEC_SA_DIR_INGRESS)
-				sess_conf.userdata = (void *) sa;
-
-			sa->sec_session = rte_security_session_create(ctx,
-					&sess_conf, ipsec_ctx->session_pool);
-			if (sa->sec_session == NULL) {
-				RTE_LOG(ERR, IPSEC,
-				"SEC Session init failed: err: %d\n", ret);
-				return -1;
-			}
-
-			sec_cap = rte_security_capabilities_get(ctx);
-
-			if (sec_cap == NULL) {
-				RTE_LOG(ERR, IPSEC,
-				"No capabilities registered\n");
-				return -1;
-			}
-
-			/* iterate until ESP tunnel*/
-			while (sec_cap->action !=
-					RTE_SECURITY_ACTION_TYPE_NONE) {
-
-				if (sec_cap->action == sa->type &&
-				    sec_cap->protocol ==
-					RTE_SECURITY_PROTOCOL_IPSEC &&
-				    sec_cap->ipsec.mode ==
-					RTE_SECURITY_IPSEC_SA_MODE_TUNNEL &&
-				    sec_cap->ipsec.direction == sa->direction)
-					break;
-				sec_cap++;
-			}
-
-			if (sec_cap->action == RTE_SECURITY_ACTION_TYPE_NONE) {
-				RTE_LOG(ERR, IPSEC,
-				"No suitable security capability found\n");
-				return -1;
-			}
-
-			sa->ol_flags = sec_cap->ol_flags;
-			sa->security_ctx = ctx;
-		}
-	} else {
-		sa->crypto_session = rte_cryptodev_sym_session_create(
-				ipsec_ctx->session_pool);
-		rte_cryptodev_sym_session_init(ipsec_ctx->tbl[cdev_id_qp].id,
-				sa->crypto_session, sa->xforms,
-				ipsec_ctx->session_pool);
-
-		rte_cryptodev_info_get(ipsec_ctx->tbl[cdev_id_qp].id,
-				&cdev_info);
-		if (cdev_info.sym.max_nb_sessions_per_qp > 0) {
-			ret = rte_cryptodev_queue_pair_attach_sym_session(
-					ipsec_ctx->tbl[cdev_id_qp].id,
-					ipsec_ctx->tbl[cdev_id_qp].qp,
-					sa->crypto_session);
-			if (ret < 0) {
-				RTE_LOG(ERR, IPSEC,
-					"Session cannot be attached to qp %u\n",
-					ipsec_ctx->tbl[cdev_id_qp].qp);
-				return -1;
-			}
-		}
-	}
-	sa->cdev_id_qp = cdev_id_qp;
-
-	return 0;
-}
-
-static inline void
-enqueue_cop(struct cdev_qp *cqp, struct rte_crypto_op *cop)
-{
-	int32_t ret, i;
-
-	cqp->buf[cqp->len++] = cop;
-
-	if (cqp->len == MAX_PKT_BURST) {
-		ret = rte_cryptodev_enqueue_burst(cqp->id, cqp->qp,
-				cqp->buf, cqp->len);
-		if (ret < cqp->len) {
-			RTE_LOG_DP(DEBUG, IPSEC, "Cryptodev %u queue %u:"
-					" enqueued %u crypto ops out of %u\n",
-					 cqp->id, cqp->qp,
-					 ret, cqp->len);
-			for (i = ret; i < cqp->len; i++)
-				rte_pktmbuf_free(cqp->buf[i]->sym->m_src);
-		}
-		cqp->in_flight += ret;
-		cqp->len = 0;
-	}
-}
-
-static inline void
-ipsec_enqueue(ipsec_xform_fn xform_func, struct ipsec_ctx *ipsec_ctx,
-		struct rte_mbuf *pkts[], struct ipsec_sa *sas[],
-		uint16_t nb_pkts)
-{
-	int32_t ret = 0, i;
-	struct ipsec_mbuf_metadata *priv;
-	struct rte_crypto_sym_op *sym_cop;
-	struct ipsec_sa *sa;
-
-	for (i = 0; i < nb_pkts; i++) {
-		if (unlikely(sas[i] == NULL)) {
-			rte_pktmbuf_free(pkts[i]);
-			continue;
-		}
-
-		rte_prefetch0(sas[i]);
-		rte_prefetch0(pkts[i]);
-
-		priv = get_priv(pkts[i]);
-		sa = sas[i];
-		priv->sa = sa;
-
-		switch (sa->type) {
-		case RTE_SECURITY_ACTION_TYPE_LOOKASIDE_PROTOCOL:
-			priv->cop.type = RTE_CRYPTO_OP_TYPE_SYMMETRIC;
-			priv->cop.status = RTE_CRYPTO_OP_STATUS_NOT_PROCESSED;
-
-			rte_prefetch0(&priv->sym_cop);
-
-			if ((unlikely(sa->sec_session == NULL)) &&
-					create_session(ipsec_ctx, sa)) {
-				rte_pktmbuf_free(pkts[i]);
-				continue;
-			}
-
-			sym_cop = get_sym_cop(&priv->cop);
-			sym_cop->m_src = pkts[i];
-
-			rte_security_attach_session(&priv->cop,
-					sa->sec_session);
-			break;
-		case RTE_SECURITY_ACTION_TYPE_NONE:
-
-			priv->cop.type = RTE_CRYPTO_OP_TYPE_SYMMETRIC;
-			priv->cop.status = RTE_CRYPTO_OP_STATUS_NOT_PROCESSED;
-
-			rte_prefetch0(&priv->sym_cop);
-
-			if ((unlikely(sa->crypto_session == NULL)) &&
-					create_session(ipsec_ctx, sa)) {
-				rte_pktmbuf_free(pkts[i]);
-				continue;
-			}
-
-			rte_crypto_op_attach_sym_session(&priv->cop,
-					sa->crypto_session);
-
-			ret = xform_func(pkts[i], sa, &priv->cop);
-			if (unlikely(ret)) {
-				rte_pktmbuf_free(pkts[i]);
-				continue;
-			}
-			break;
-		case RTE_SECURITY_ACTION_TYPE_INLINE_PROTOCOL:
-			if ((unlikely(sa->sec_session == NULL)) &&
-					create_session(ipsec_ctx, sa)) {
-				rte_pktmbuf_free(pkts[i]);
-				continue;
-			}
-
-			ipsec_ctx->ol_pkts[ipsec_ctx->ol_pkts_cnt++] = pkts[i];
-			if (sa->ol_flags & RTE_SECURITY_TX_OLOAD_NEED_MDATA)
-				rte_security_set_pkt_metadata(
-						sa->security_ctx,
-						sa->sec_session, pkts[i], NULL);
-			continue;
-		case RTE_SECURITY_ACTION_TYPE_INLINE_CRYPTO:
-			priv->cop.type = RTE_CRYPTO_OP_TYPE_SYMMETRIC;
-			priv->cop.status = RTE_CRYPTO_OP_STATUS_NOT_PROCESSED;
-
-			rte_prefetch0(&priv->sym_cop);
-
-			if ((unlikely(sa->sec_session == NULL)) &&
-					create_session(ipsec_ctx, sa)) {
-				rte_pktmbuf_free(pkts[i]);
-				continue;
-			}
-
-			rte_security_attach_session(&priv->cop,
-					sa->sec_session);
-
-			ret = xform_func(pkts[i], sa, &priv->cop);
-			if (unlikely(ret)) {
-				rte_pktmbuf_free(pkts[i]);
-				continue;
-			}
-
-			ipsec_ctx->ol_pkts[ipsec_ctx->ol_pkts_cnt++] = pkts[i];
-			if (sa->ol_flags & RTE_SECURITY_TX_OLOAD_NEED_MDATA)
-				rte_security_set_pkt_metadata(
-						sa->security_ctx,
-						sa->sec_session, pkts[i], NULL);
-			continue;
-		}
-
-		RTE_ASSERT(sa->cdev_id_qp < ipsec_ctx->nb_qps);
-		enqueue_cop(&ipsec_ctx->tbl[sa->cdev_id_qp], &priv->cop);
-	}
-}
-
-static inline int
-ipsec_dequeue(ipsec_xform_fn xform_func, struct ipsec_ctx *ipsec_ctx,
-	      struct rte_mbuf *pkts[], uint16_t max_pkts)
-{
-	int32_t nb_pkts = 0, ret = 0, i, j, nb_cops;
-	struct ipsec_mbuf_metadata *priv;
-	struct rte_crypto_op *cops[max_pkts];
-	struct ipsec_sa *sa;
-	struct rte_mbuf *pkt;
-
-	for (i = 0; i < ipsec_ctx->nb_qps && nb_pkts < max_pkts;) {
-		struct cdev_qp *cqp;
-		cqp = &ipsec_ctx->tbl[ipsec_ctx->last_qp];
-
-		while (ipsec_ctx->ol_pkts_cnt > 0 && nb_pkts < max_pkts) {
-			pkt = ipsec_ctx->ol_pkts[--ipsec_ctx->ol_pkts_cnt];
-			rte_prefetch0(pkt);
-			priv = get_priv(pkt);
-			sa = priv->sa;
-			ret = xform_func(pkt, sa, &priv->cop);
-			if (unlikely(ret)) {
-				rte_pktmbuf_free(pkt);
-				continue;
-			}
-			pkts[nb_pkts++] = pkt;
-		}
-
-		if (cqp->in_flight == 0) {
-			ipsec_ctx->last_qp++;
-			if (ipsec_ctx->last_qp == ipsec_ctx->nb_qps)
-				ipsec_ctx->last_qp %= ipsec_ctx->nb_qps;
-			i++;
-			continue;
-		}
-
-		nb_cops = rte_cryptodev_dequeue_burst(cqp->id, cqp->qp,
-				cops, max_pkts - nb_pkts);
-
-		cqp->in_flight -= nb_cops;
-
-		for (j = 0; j < nb_cops; j++) {
-			pkt = cops[j]->sym->m_src;
-			rte_prefetch0(pkt);
-
-			priv = get_priv(pkt);
-			sa = priv->sa;
-
-			RTE_ASSERT(sa != NULL);
-
-			if (sa->type == RTE_SECURITY_ACTION_TYPE_NONE) {
-				ret = xform_func(pkt, sa, cops[j]);
-				if (unlikely(ret)) {
-					rte_pktmbuf_free(pkt);
-					continue;
-				}
-			}
-			pkts[nb_pkts++] = pkt;
-			if (cqp->in_flight < max_pkts) {
-				ipsec_ctx->last_qp++;
-				if (ipsec_ctx->last_qp == ipsec_ctx->nb_qps)
-					ipsec_ctx->last_qp %= ipsec_ctx->nb_qps;
-				i++;
-			}
-		}
-	}
-
-	/* return packets */
-	return nb_pkts;
-}
-
-uint16_t
-ipsec_inbound(struct ipsec_ctx *ctx, struct rte_mbuf *pkts[],
-		uint16_t nb_pkts, uint16_t len)
-{
-	struct ipsec_sa *sas[nb_pkts];
-
-	inbound_sa_lookup(ctx->sa_ctx, pkts, sas, nb_pkts);
-
-	ipsec_enqueue(esp_inbound, ctx, pkts, sas, nb_pkts);
-
-	return ipsec_dequeue(esp_inbound_post, ctx, pkts, len);
-}
-
-uint16_t
-ipsec_outbound(struct ipsec_ctx *ctx, struct rte_mbuf *pkts[],
-		uint32_t sa_idx[], uint16_t nb_pkts, uint16_t len)
-{
-	struct ipsec_sa *sas[nb_pkts];
-
-	outbound_sa_lookup(ctx->sa_ctx, sa_idx, sas, nb_pkts);
-
-	ipsec_enqueue(esp_outbound, ctx, pkts, sas, nb_pkts);
-
-	return ipsec_dequeue(esp_outbound_post, ctx, pkts, len);
-}
diff --git a/examples/ipsec-secgw/ipsec.h b/examples/ipsec-secgw/ipsec.h
deleted file mode 100644
index 6059f6c..0000000
--- a/examples/ipsec-secgw/ipsec.h
+++ /dev/null
@@ -1,239 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016-2017 Intel Corporation
- */
-
-#ifndef __IPSEC_H__
-#define __IPSEC_H__
-
-#include <stdint.h>
-
-#include <rte_byteorder.h>
-#include <rte_crypto.h>
-#include <rte_security.h>
-#include <rte_flow.h>
-
-#define RTE_LOGTYPE_IPSEC       RTE_LOGTYPE_USER1
-#define RTE_LOGTYPE_IPSEC_ESP   RTE_LOGTYPE_USER2
-#define RTE_LOGTYPE_IPSEC_IPIP  RTE_LOGTYPE_USER3
-
-#define MAX_PKT_BURST 32
-#define MAX_QP_PER_LCORE 256
-
-#define MAX_DIGEST_SIZE 32 /* Bytes -- 256 bits */
-
-#define IV_OFFSET		(sizeof(struct rte_crypto_op) + \
-				sizeof(struct rte_crypto_sym_op))
-
-#define uint32_t_to_char(ip, a, b, c, d) do {\
-		*a = (uint8_t)(ip >> 24 & 0xff);\
-		*b = (uint8_t)(ip >> 16 & 0xff);\
-		*c = (uint8_t)(ip >> 8 & 0xff);\
-		*d = (uint8_t)(ip & 0xff);\
-	} while (0)
-
-#define DEFAULT_MAX_CATEGORIES	1
-
-#define IPSEC_SA_MAX_ENTRIES (128) /* must be power of 2, max 2 power 30 */
-#define SPI2IDX(spi) (spi & (IPSEC_SA_MAX_ENTRIES - 1))
-#define INVALID_SPI (0)
-
-#define DISCARD (0x80000000)
-#define BYPASS (0x40000000)
-#define PROTECT_MASK (0x3fffffff)
-#define PROTECT(sa_idx) (SPI2IDX(sa_idx) & PROTECT_MASK) /* SA idx 30 bits */
-
-#define IPSEC_XFORM_MAX 2
-
-#define IP6_VERSION (6)
-
-struct rte_crypto_xform;
-struct ipsec_xform;
-struct rte_mbuf;
-
-struct ipsec_sa;
-
-typedef int32_t (*ipsec_xform_fn)(struct rte_mbuf *m, struct ipsec_sa *sa,
-		struct rte_crypto_op *cop);
-
-struct ip_addr {
-	union {
-		uint32_t ip4;
-		union {
-			uint64_t ip6[2];
-			uint8_t ip6_b[16];
-		} ip6;
-	} ip;
-};
-
-#define MAX_KEY_SIZE		32
-
-struct ipsec_sa {
-	uint32_t spi;
-	uint32_t cdev_id_qp;
-	uint64_t seq;
-	uint32_t salt;
-	union {
-		struct rte_cryptodev_sym_session *crypto_session;
-		struct rte_security_session *sec_session;
-	};
-	enum rte_crypto_cipher_algorithm cipher_algo;
-	enum rte_crypto_auth_algorithm auth_algo;
-	enum rte_crypto_aead_algorithm aead_algo;
-	uint16_t digest_len;
-	uint16_t iv_len;
-	uint16_t block_size;
-	uint16_t flags;
-#define IP4_TUNNEL (1 << 0)
-#define IP6_TUNNEL (1 << 1)
-#define TRANSPORT  (1 << 2)
-	struct ip_addr src;
-	struct ip_addr dst;
-	uint8_t cipher_key[MAX_KEY_SIZE];
-	uint16_t cipher_key_len;
-	uint8_t auth_key[MAX_KEY_SIZE];
-	uint16_t auth_key_len;
-	uint16_t aad_len;
-	union {
-		struct rte_crypto_sym_xform *xforms;
-		struct rte_security_ipsec_xform *sec_xform;
-	};
-	enum rte_security_session_action_type type;
-	enum rte_security_ipsec_sa_direction direction;
-	uint16_t portid;
-	struct rte_security_ctx *security_ctx;
-	uint32_t ol_flags;
-
-#define MAX_RTE_FLOW_PATTERN (4)
-#define MAX_RTE_FLOW_ACTIONS (3)
-	struct rte_flow_item pattern[MAX_RTE_FLOW_PATTERN];
-	struct rte_flow_action action[MAX_RTE_FLOW_ACTIONS];
-	struct rte_flow_attr attr;
-	union {
-		struct rte_flow_item_ipv4 ipv4_spec;
-		struct rte_flow_item_ipv6 ipv6_spec;
-	};
-	struct rte_flow_item_esp esp_spec;
-	struct rte_flow *flow;
-	struct rte_security_session_conf sess_conf;
-} __rte_cache_aligned;
-
-struct ipsec_mbuf_metadata {
-	struct ipsec_sa *sa;
-	struct rte_crypto_op cop;
-	struct rte_crypto_sym_op sym_cop;
-	uint8_t buf[32];
-} __rte_cache_aligned;
-
-struct cdev_qp {
-	uint16_t id;
-	uint16_t qp;
-	uint16_t in_flight;
-	uint16_t len;
-	struct rte_crypto_op *buf[MAX_PKT_BURST] __rte_aligned(sizeof(void *));
-};
-
-struct ipsec_ctx {
-	struct rte_hash *cdev_map;
-	struct sp_ctx *sp4_ctx;
-	struct sp_ctx *sp6_ctx;
-	struct sa_ctx *sa_ctx;
-	uint16_t nb_qps;
-	uint16_t last_qp;
-	struct cdev_qp tbl[MAX_QP_PER_LCORE];
-	struct rte_mempool *session_pool;
-	struct rte_mbuf *ol_pkts[MAX_PKT_BURST] __rte_aligned(sizeof(void *));
-	uint16_t ol_pkts_cnt;
-};
-
-struct cdev_key {
-	uint16_t lcore_id;
-	uint8_t cipher_algo;
-	uint8_t auth_algo;
-	uint8_t aead_algo;
-};
-
-struct socket_ctx {
-	struct sa_ctx *sa_in;
-	struct sa_ctx *sa_out;
-	struct sp_ctx *sp_ip4_in;
-	struct sp_ctx *sp_ip4_out;
-	struct sp_ctx *sp_ip6_in;
-	struct sp_ctx *sp_ip6_out;
-	struct rt_ctx *rt_ip4;
-	struct rt_ctx *rt_ip6;
-	struct rte_mempool *mbuf_pool;
-	struct rte_mempool *session_pool;
-};
-
-struct cnt_blk {
-	uint32_t salt;
-	uint64_t iv;
-	uint32_t cnt;
-} __attribute__((packed));
-
-uint16_t
-ipsec_inbound(struct ipsec_ctx *ctx, struct rte_mbuf *pkts[],
-		uint16_t nb_pkts, uint16_t len);
-
-uint16_t
-ipsec_outbound(struct ipsec_ctx *ctx, struct rte_mbuf *pkts[],
-		uint32_t sa_idx[], uint16_t nb_pkts, uint16_t len);
-
-static inline uint16_t
-ipsec_metadata_size(void)
-{
-	return sizeof(struct ipsec_mbuf_metadata);
-}
-
-static inline struct ipsec_mbuf_metadata *
-get_priv(struct rte_mbuf *m)
-{
-	return RTE_PTR_ADD(m, sizeof(struct rte_mbuf));
-}
-
-static inline void *
-get_cnt_blk(struct rte_mbuf *m)
-{
-	struct ipsec_mbuf_metadata *priv = get_priv(m);
-
-	return &priv->buf[0];
-}
-
-static inline void *
-get_aad(struct rte_mbuf *m)
-{
-	struct ipsec_mbuf_metadata *priv = get_priv(m);
-
-	return &priv->buf[16];
-}
-
-static inline void *
-get_sym_cop(struct rte_crypto_op *cop)
-{
-	return (cop + 1);
-}
-
-int
-inbound_sa_check(struct sa_ctx *sa_ctx, struct rte_mbuf *m, uint32_t sa_idx);
-
-void
-inbound_sa_lookup(struct sa_ctx *sa_ctx, struct rte_mbuf *pkts[],
-		struct ipsec_sa *sa[], uint16_t nb_pkts);
-
-void
-outbound_sa_lookup(struct sa_ctx *sa_ctx, uint32_t sa_idx[],
-		struct ipsec_sa *sa[], uint16_t nb_pkts);
-
-void
-sp4_init(struct socket_ctx *ctx, int32_t socket_id);
-
-void
-sp6_init(struct socket_ctx *ctx, int32_t socket_id);
-
-void
-sa_init(struct socket_ctx *ctx, int32_t socket_id);
-
-void
-rt_init(struct socket_ctx *ctx, int32_t socket_id);
-
-#endif /* __IPSEC_H__ */
diff --git a/examples/ipsec-secgw/meson.build b/examples/ipsec-secgw/meson.build
deleted file mode 100644
index 77d8b29..0000000
--- a/examples/ipsec-secgw/meson.build
+++ /dev/null
@@ -1,14 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-deps += ['security', 'lpm', 'acl', 'hash']
-allow_experimental_apis = true
-sources = files(
-	'esp.c', 'ipsec.c', 'ipsec-secgw.c', 'parser.c',
-	'rt.c', 'sa.c', 'sp4.c', 'sp6.c'
-)
diff --git a/examples/ipsec-secgw/parser.c b/examples/ipsec-secgw/parser.c
deleted file mode 100644
index 2403b56..0000000
--- a/examples/ipsec-secgw/parser.c
+++ /dev/null
@@ -1,562 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016 Intel Corporation
- */
-#include <rte_common.h>
-#include <rte_crypto.h>
-
-#include <cmdline_parse_string.h>
-#include <cmdline_parse_num.h>
-#include <cmdline_parse_ipaddr.h>
-#include <cmdline_socket.h>
-#include <cmdline.h>
-
-#include "ipsec.h"
-#include "parser.h"
-
-#define PARSE_DELIMITER		" \f\n\r\t\v"
-static int
-parse_tokenize_string(char *string, char *tokens[], uint32_t *n_tokens)
-{
-	uint32_t i;
-
-	if ((string == NULL) ||
-		(tokens == NULL) ||
-		(*n_tokens < 1))
-		return -EINVAL;
-
-	for (i = 0; i < *n_tokens; i++) {
-		tokens[i] = strtok_r(string, PARSE_DELIMITER, &string);
-		if (tokens[i] == NULL)
-			break;
-	}
-
-	if ((i == *n_tokens) &&
-		(NULL != strtok_r(string, PARSE_DELIMITER, &string)))
-		return -E2BIG;
-
-	*n_tokens = i;
-	return 0;
-}
-
-#define INADDRSZ 4
-#define IN6ADDRSZ 16
-
-/* int
- * inet_pton4(src, dst)
- *      like inet_aton() but without all the hexadecimal and shorthand.
- * return:
- *      1 if `src' is a valid dotted quad, else 0.
- * notice:
- *      does not touch `dst' unless it's returning 1.
- * author:
- *      Paul Vixie, 1996.
- */
-static int
-inet_pton4(const char *src, unsigned char *dst)
-{
-	static const char digits[] = "0123456789";
-	int saw_digit, octets, ch;
-	unsigned char tmp[INADDRSZ], *tp;
-
-	saw_digit = 0;
-	octets = 0;
-	*(tp = tmp) = 0;
-	while ((ch = *src++) != '\0') {
-		const char *pch;
-
-		pch = strchr(digits, ch);
-		if (pch != NULL) {
-			unsigned int new = *tp * 10 + (pch - digits);
-
-			if (new > 255)
-				return 0;
-			if (!saw_digit) {
-				if (++octets > 4)
-					return 0;
-				saw_digit = 1;
-			}
-			*tp = (unsigned char)new;
-		} else if (ch == '.' && saw_digit) {
-			if (octets == 4)
-				return 0;
-			*++tp = 0;
-			saw_digit = 0;
-		} else
-			return 0;
-	}
-	if (octets < 4)
-		return 0;
-
-	memcpy(dst, tmp, INADDRSZ);
-	return 1;
-}
-
-/* int
- * inet_pton6(src, dst)
- *      convert presentation level address to network order binary form.
- * return:
- *      1 if `src' is a valid [RFC1884 2.2] address, else 0.
- * notice:
- *      (1) does not touch `dst' unless it's returning 1.
- *      (2) :: in a full address is silently ignored.
- * credit:
- *      inspired by Mark Andrews.
- * author:
- *      Paul Vixie, 1996.
- */
-static int
-inet_pton6(const char *src, unsigned char *dst)
-{
-	static const char xdigits_l[] = "0123456789abcdef",
-		xdigits_u[] = "0123456789ABCDEF";
-	unsigned char tmp[IN6ADDRSZ], *tp = 0, *endp = 0, *colonp = 0;
-	const char *xdigits = 0, *curtok = 0;
-	int ch = 0, saw_xdigit = 0, count_xdigit = 0;
-	unsigned int val = 0;
-	unsigned dbloct_count = 0;
-
-	memset((tp = tmp), '\0', IN6ADDRSZ);
-	endp = tp + IN6ADDRSZ;
-	colonp = NULL;
-	/* Leading :: requires some special handling. */
-	if (*src == ':')
-		if (*++src != ':')
-			return 0;
-	curtok = src;
-	saw_xdigit = count_xdigit = 0;
-	val = 0;
-
-	while ((ch = *src++) != '\0') {
-		const char *pch;
-
-		pch = strchr((xdigits = xdigits_l), ch);
-		if (pch == NULL)
-			pch = strchr((xdigits = xdigits_u), ch);
-		if (pch != NULL) {
-			if (count_xdigit >= 4)
-				return 0;
-			val <<= 4;
-			val |= (pch - xdigits);
-			if (val > 0xffff)
-				return 0;
-			saw_xdigit = 1;
-			count_xdigit++;
-			continue;
-		}
-		if (ch == ':') {
-			curtok = src;
-			if (!saw_xdigit) {
-				if (colonp)
-					return 0;
-				colonp = tp;
-				continue;
-			} else if (*src == '\0') {
-				return 0;
-			}
-			if (tp + sizeof(int16_t) > endp)
-				return 0;
-			*tp++ = (unsigned char) ((val >> 8) & 0xff);
-			*tp++ = (unsigned char) (val & 0xff);
-			saw_xdigit = 0;
-			count_xdigit = 0;
-			val = 0;
-			dbloct_count++;
-			continue;
-		}
-		if (ch == '.' && ((tp + INADDRSZ) <= endp) &&
-		    inet_pton4(curtok, tp) > 0) {
-			tp += INADDRSZ;
-			saw_xdigit = 0;
-			dbloct_count += 2;
-			break;  /* '\0' was seen by inet_pton4(). */
-		}
-		return 0;
-	}
-	if (saw_xdigit) {
-		if (tp + sizeof(int16_t) > endp)
-			return 0;
-		*tp++ = (unsigned char) ((val >> 8) & 0xff);
-		*tp++ = (unsigned char) (val & 0xff);
-		dbloct_count++;
-	}
-	if (colonp != NULL) {
-		/* if we already have 8 double octets, having a colon
-		 * means error */
-		if (dbloct_count == 8)
-			return 0;
-
-		/*
-		 * Since some memmove()'s erroneously fail to handle
-		 * overlapping regions, we'll do the shift by hand.
-		 */
-		const int n = tp - colonp;
-		int i;
-
-		for (i = 1; i <= n; i++) {
-			endp[-i] = colonp[n - i];
-			colonp[n - i] = 0;
-		}
-		tp = endp;
-	}
-	if (tp != endp)
-		return 0;
-	memcpy(dst, tmp, IN6ADDRSZ);
-	return 1;
-}
-
-int
-parse_ipv4_addr(const char *token, struct in_addr *ipv4, uint32_t *mask)
-{
-	char ip_str[256] = {0};
-	char *pch;
-
-	pch = strchr(token, '/');
-	if (pch != NULL) {
-		strncpy(ip_str, token, pch - token);
-		pch += 1;
-		if (is_str_num(pch) != 0)
-			return -EINVAL;
-		if (mask)
-			*mask = atoi(pch);
-	} else {
-		strncpy(ip_str, token, sizeof(ip_str) - 1);
-		if (mask)
-			*mask = 0;
-	}
-
-	if (strlen(ip_str) >= INET_ADDRSTRLEN)
-		return -EINVAL;
-
-	if (inet_pton4(ip_str, (unsigned char *)ipv4) != 1)
-		return -EINVAL;
-
-	return 0;
-}
-
-int
-parse_ipv6_addr(const char *token, struct in6_addr *ipv6, uint32_t *mask)
-{
-	char ip_str[256] = {0};
-	char *pch;
-
-	pch = strchr(token, '/');
-	if (pch != NULL) {
-		strncpy(ip_str, token, pch - token);
-		pch += 1;
-		if (is_str_num(pch) != 0)
-			return -EINVAL;
-		if (mask)
-			*mask = atoi(pch);
-	} else {
-		strncpy(ip_str, token, sizeof(ip_str) - 1);
-		if (mask)
-			*mask = 0;
-	}
-
-	if (strlen(ip_str) >= INET6_ADDRSTRLEN)
-		return -EINVAL;
-
-	if (inet_pton6(ip_str, (unsigned char *)ipv6) != 1)
-		return -EINVAL;
-
-	return 0;
-}
-
-int
-parse_range(const char *token, uint16_t *low, uint16_t *high)
-{
-	char ch;
-	char num_str[20];
-	uint32_t pos;
-	int range_low = -1;
-	int range_high = -1;
-
-	if (!low || !high)
-		return -1;
-
-	memset(num_str, 0, 20);
-	pos = 0;
-
-	while ((ch = *token++) != '\0') {
-		if (isdigit(ch)) {
-			if (pos >= 19)
-				return -1;
-			num_str[pos++] = ch;
-		} else if (ch == ':') {
-			if (range_low != -1)
-				return -1;
-			range_low = atoi(num_str);
-			memset(num_str, 0, 20);
-			pos = 0;
-		}
-	}
-
-	if (strlen(num_str) == 0)
-		return -1;
-
-	range_high = atoi(num_str);
-
-	*low = (uint16_t)range_low;
-	*high = (uint16_t)range_high;
-
-	return 0;
-}
-
-/** sp add parse */
-struct cfg_sp_add_cfg_item {
-	cmdline_fixed_string_t sp_keyword;
-	cmdline_multi_string_t multi_string;
-};
-
-static void
-cfg_sp_add_cfg_item_parsed(void *parsed_result,
-	__rte_unused struct cmdline *cl, void *data)
-{
-	struct cfg_sp_add_cfg_item *params = parsed_result;
-	char *tokens[32];
-	uint32_t n_tokens = RTE_DIM(tokens);
-	struct parse_status *status = (struct parse_status *)data;
-
-	APP_CHECK((parse_tokenize_string(params->multi_string, tokens,
-		&n_tokens) == 0), status, "too many arguments");
-
-	if (status->status < 0)
-		return;
-
-	if (strcmp(tokens[0], "ipv4") == 0) {
-		parse_sp4_tokens(tokens, n_tokens, status);
-		if (status->status < 0)
-			return;
-	} else if (strcmp(tokens[0], "ipv6") == 0) {
-		parse_sp6_tokens(tokens, n_tokens, status);
-		if (status->status < 0)
-			return;
-	} else {
-		APP_CHECK(0, status, "unrecognizable input %s\n",
-			tokens[0]);
-		return;
-	}
-}
-
-static cmdline_parse_token_string_t cfg_sp_add_sp_str =
-	TOKEN_STRING_INITIALIZER(struct cfg_sp_add_cfg_item,
-		sp_keyword, "sp");
-
-static cmdline_parse_token_string_t cfg_sp_add_multi_str =
-	TOKEN_STRING_INITIALIZER(struct cfg_sp_add_cfg_item, multi_string,
-		TOKEN_STRING_MULTI);
-
-cmdline_parse_inst_t cfg_sp_add_rule = {
-	.f = cfg_sp_add_cfg_item_parsed,
-	.data = NULL,
-	.help_str = "",
-	.tokens = {
-		(void *) &cfg_sp_add_sp_str,
-		(void *) &cfg_sp_add_multi_str,
-		NULL,
-	},
-};
-
-/* sa add parse */
-struct cfg_sa_add_cfg_item {
-	cmdline_fixed_string_t sa_keyword;
-	cmdline_multi_string_t multi_string;
-};
-
-static void
-cfg_sa_add_cfg_item_parsed(void *parsed_result,
-	__rte_unused struct cmdline *cl, void *data)
-{
-	struct cfg_sa_add_cfg_item *params = parsed_result;
-	char *tokens[32];
-	uint32_t n_tokens = RTE_DIM(tokens);
-	struct parse_status *status = (struct parse_status *)data;
-
-	APP_CHECK(parse_tokenize_string(params->multi_string, tokens,
-		&n_tokens) == 0, status, "too many arguments\n");
-
-	parse_sa_tokens(tokens, n_tokens, status);
-}
-
-static cmdline_parse_token_string_t cfg_sa_add_sa_str =
-	TOKEN_STRING_INITIALIZER(struct cfg_sa_add_cfg_item,
-		sa_keyword, "sa");
-
-static cmdline_parse_token_string_t cfg_sa_add_multi_str =
-	TOKEN_STRING_INITIALIZER(struct cfg_sa_add_cfg_item, multi_string,
-		TOKEN_STRING_MULTI);
-
-cmdline_parse_inst_t cfg_sa_add_rule = {
-	.f = cfg_sa_add_cfg_item_parsed,
-	.data = NULL,
-	.help_str = "",
-	.tokens = {
-		(void *) &cfg_sa_add_sa_str,
-		(void *) &cfg_sa_add_multi_str,
-		NULL,
-	},
-};
-
-/* rt add parse */
-struct cfg_rt_add_cfg_item {
-	cmdline_fixed_string_t rt_keyword;
-	cmdline_multi_string_t multi_string;
-};
-
-static void
-cfg_rt_add_cfg_item_parsed(void *parsed_result,
-	__rte_unused struct cmdline *cl, void *data)
-{
-	struct cfg_rt_add_cfg_item *params = parsed_result;
-	char *tokens[32];
-	uint32_t n_tokens = RTE_DIM(tokens);
-	struct parse_status *status = (struct parse_status *)data;
-
-	APP_CHECK(parse_tokenize_string(
-		params->multi_string, tokens, &n_tokens) == 0,
-		status, "too many arguments\n");
-	if (status->status < 0)
-		return;
-
-	parse_rt_tokens(tokens, n_tokens, status);
-}
-
-static cmdline_parse_token_string_t cfg_rt_add_rt_str =
-	TOKEN_STRING_INITIALIZER(struct cfg_rt_add_cfg_item,
-		rt_keyword, "rt");
-
-static cmdline_parse_token_string_t cfg_rt_add_multi_str =
-	TOKEN_STRING_INITIALIZER(struct cfg_rt_add_cfg_item, multi_string,
-		TOKEN_STRING_MULTI);
-
-cmdline_parse_inst_t cfg_rt_add_rule = {
-	.f = cfg_rt_add_cfg_item_parsed,
-	.data = NULL,
-	.help_str = "",
-	.tokens = {
-		(void *) &cfg_rt_add_rt_str,
-		(void *) &cfg_rt_add_multi_str,
-		NULL,
-	},
-};
-
-/** set of cfg items */
-cmdline_parse_ctx_t ipsec_ctx[] = {
-	(cmdline_parse_inst_t *)&cfg_sp_add_rule,
-	(cmdline_parse_inst_t *)&cfg_sa_add_rule,
-	(cmdline_parse_inst_t *)&cfg_rt_add_rule,
-	NULL,
-};
-
-int
-parse_cfg_file(const char *cfg_filename)
-{
-	struct cmdline *cl = cmdline_stdin_new(ipsec_ctx, "");
-	FILE *f = fopen(cfg_filename, "r");
-	char str[1024] = {0}, *get_s = NULL;
-	uint32_t line_num = 0;
-	struct parse_status status = {0};
-
-	if (f == NULL) {
-		rte_panic("Error: invalid file descriptor %s\n", cfg_filename);
-		goto error_exit;
-	}
-
-	if (cl == NULL) {
-		rte_panic("Error: cannot create cmdline instance\n");
-		goto error_exit;
-	}
-
-	cfg_sp_add_rule.data = &status;
-	cfg_sa_add_rule.data = &status;
-	cfg_rt_add_rule.data = &status;
-
-	do {
-		char oneline[1024];
-		char *pos;
-		get_s = fgets(oneline, 1024, f);
-
-		if (!get_s)
-			break;
-
-		line_num++;
-
-		if (strlen(oneline) > 1022) {
-			rte_panic("%s:%u: error: "
-				"the line contains more characters the parser can handle\n",
-				cfg_filename, line_num);
-			goto error_exit;
-		}
-
-		/* process comment char '#' */
-		if (oneline[0] == '#')
-			continue;
-
-		pos = strchr(oneline, '#');
-		if (pos != NULL)
-			*pos = '\0';
-
-		/* process line concatenator '\' */
-		pos = strchr(oneline, 92);
-		if (pos != NULL) {
-			if (pos != oneline+strlen(oneline) - 2) {
-				rte_panic("%s:%u: error: "
-					"no character should exist after '\\'\n",
-					cfg_filename, line_num);
-				goto error_exit;
-			}
-
-			*pos = '\0';
-
-			if (strlen(oneline) + strlen(str) > 1022) {
-				rte_panic("%s:%u: error: "
-					"the concatenated line contains more characters the parser can handle\n",
-					cfg_filename, line_num);
-				goto error_exit;
-			}
-
-			strncpy(str + strlen(str), oneline,
-				strlen(oneline));
-
-			continue;
-		}
-
-		/* copy the line to str and process */
-		if (strlen(oneline) + strlen(str) > 1022) {
-			rte_panic("%s:%u: error: "
-				"the line contains more characters the parser can handle\n",
-				cfg_filename, line_num);
-			goto error_exit;
-		}
-		strncpy(str + strlen(str), oneline,
-			strlen(oneline));
-
-		str[strlen(str)] = '\n';
-		if (cmdline_parse(cl, str) < 0) {
-			rte_panic("%s:%u: error: parsing \"%s\" failed\n",
-				cfg_filename, line_num, str);
-			goto error_exit;
-		}
-
-		if (status.status < 0) {
-			rte_panic("%s:%u: error: %s", cfg_filename,
-				line_num, status.parse_msg);
-			goto error_exit;
-		}
-
-		memset(str, 0, 1024);
-	} while (1);
-
-	cmdline_stdin_exit(cl);
-	fclose(f);
-
-	return 0;
-
-error_exit:
-	if (cl)
-		cmdline_stdin_exit(cl);
-	if (f)
-		fclose(f);
-
-	return -1;
-}
diff --git a/examples/ipsec-secgw/parser.h b/examples/ipsec-secgw/parser.h
deleted file mode 100644
index be02537..0000000
--- a/examples/ipsec-secgw/parser.h
+++ /dev/null
@@ -1,88 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016 Intel Corporation
- */
-
-#include <sys/types.h>
-#include <netinet/in.h>
-#include <netinet/ip.h>
-
-#ifndef __PARSER_H
-#define __PARSER_H
-
-struct parse_status {
-	int status;
-	char parse_msg[256];
-};
-
-#define	APP_CHECK(exp, status, fmt, ...)				\
-do {									\
-	if (!(exp)) {							\
-		sprintf(status->parse_msg, fmt "\n",			\
-			## __VA_ARGS__);				\
-		status->status = -1;					\
-	} else								\
-		status->status = 0;					\
-} while (0)
-
-#define APP_CHECK_PRESENCE(val, str, status)				\
-	APP_CHECK(val == 0, status,					\
-		"item \"%s\" already present", str)
-
-#define APP_CHECK_TOKEN_EQUAL(tokens, index, ref, status)		\
-	APP_CHECK(strcmp(tokens[index], ref) == 0, status,		\
-		"unrecognized input \"%s\": expect \"%s\"\n",		\
-		tokens[index], ref)
-
-static inline int
-is_str_num(const char *str)
-{
-	uint32_t i;
-
-	for (i = 0; i < strlen(str); i++)
-		if (!isdigit(str[i]))
-			return -1;
-
-	return 0;
-}
-
-#define APP_CHECK_TOKEN_IS_NUM(tokens, index, status)			\
-	APP_CHECK(is_str_num(tokens[index]) == 0, status,		\
-	"input \"%s\" is not valid number string", tokens[index])
-
-
-#define INCREMENT_TOKEN_INDEX(index, max_num, status)			\
-do {									\
-	APP_CHECK(index + 1 < max_num, status, "reaching the end of "	\
-		"the token array");					\
-	index++;							\
-} while (0)
-
-int
-parse_ipv4_addr(const char *token, struct in_addr *ipv4, uint32_t *mask);
-
-int
-parse_ipv6_addr(const char *token, struct in6_addr *ipv6, uint32_t *mask);
-
-int
-parse_range(const char *token, uint16_t *low, uint16_t *high);
-
-void
-parse_sp4_tokens(char **tokens, uint32_t n_tokens,
-	struct parse_status *status);
-
-void
-parse_sp6_tokens(char **tokens, uint32_t n_tokens,
-	struct parse_status *status);
-
-void
-parse_sa_tokens(char **tokens, uint32_t n_tokens,
-	struct parse_status *status);
-
-void
-parse_rt_tokens(char **tokens, uint32_t n_tokens,
-	struct parse_status *status);
-
-int
-parse_cfg_file(const char *cfg_filename);
-
-#endif
diff --git a/examples/ipsec-secgw/rt.c b/examples/ipsec-secgw/rt.c
deleted file mode 100644
index ec3a375..0000000
--- a/examples/ipsec-secgw/rt.c
+++ /dev/null
@@ -1,206 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016 Intel Corporation
- */
-
-/*
- * Routing Table (RT)
- */
-#include <sys/types.h>
-#include <rte_lpm.h>
-#include <rte_lpm6.h>
-#include <rte_errno.h>
-#include <rte_ip.h>
-
-#include "ipsec.h"
-#include "parser.h"
-
-#define RT_IPV4_MAX_RULES	1024
-#define RT_IPV6_MAX_RULES	1024
-
-struct ip4_route {
-	uint32_t ip;
-	uint8_t depth;
-	uint8_t if_out;
-};
-
-struct ip6_route {
-	uint8_t ip[16];
-	uint8_t depth;
-	uint8_t if_out;
-};
-
-struct ip4_route rt_ip4[RT_IPV4_MAX_RULES];
-uint32_t nb_rt_ip4;
-
-struct ip6_route rt_ip6[RT_IPV4_MAX_RULES];
-uint32_t nb_rt_ip6;
-
-void
-parse_rt_tokens(char **tokens, uint32_t n_tokens,
-	struct parse_status *status)
-{
-	uint32_t ti;
-	uint32_t *n_rts = NULL;
-	struct ip4_route *route_ipv4 = NULL;
-	struct ip6_route *route_ipv6 = NULL;
-
-	if (strcmp(tokens[0], "ipv4") == 0) {
-		n_rts = &nb_rt_ip4;
-		route_ipv4 = &rt_ip4[*n_rts];
-
-		APP_CHECK(*n_rts <= RT_IPV4_MAX_RULES - 1, status,
-			"too many rt rules, abort insertion\n");
-		if (status->status < 0)
-			return;
-
-	} else if (strcmp(tokens[0], "ipv6") == 0) {
-		n_rts = &nb_rt_ip6;
-		route_ipv6 = &rt_ip6[*n_rts];
-
-		APP_CHECK(*n_rts <= RT_IPV6_MAX_RULES - 1, status,
-			"too many rt rules, abort insertion\n");
-		if (status->status < 0)
-			return;
-	} else {
-		APP_CHECK(0, status, "unrecognized input \"%s\"",
-			tokens[0]);
-		return;
-	}
-
-	for (ti = 1; ti < n_tokens; ti++) {
-		if (strcmp(tokens[ti], "dst") == 0) {
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-
-			if (route_ipv4 != NULL) {
-				struct in_addr ip;
-				uint32_t depth = 0;
-
-				APP_CHECK(parse_ipv4_addr(tokens[ti],
-					&ip, &depth) == 0, status,
-					"unrecognized input \"%s\", "
-					"expect valid ipv4 addr",
-					tokens[ti]);
-				if (status->status < 0)
-					return;
-				route_ipv4->ip = rte_bswap32(
-					(uint32_t)ip.s_addr);
-				route_ipv4->depth = (uint8_t)depth;
-			} else {
-				struct in6_addr ip;
-				uint32_t depth;
-
-				APP_CHECK(parse_ipv6_addr(tokens[ti],
-					&ip, &depth) == 0, status,
-					"unrecognized input \"%s\", "
-					"expect valid ipv6 address",
-					tokens[ti]);
-				if (status->status < 0)
-					return;
-				memcpy(route_ipv6->ip, ip.s6_addr, 16);
-				route_ipv6->depth = (uint8_t)depth;
-			}
-		}
-
-		if (strcmp(tokens[ti], "port") == 0) {
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-			APP_CHECK_TOKEN_IS_NUM(tokens, ti, status);
-			if (status->status < 0)
-				return;
-			if (route_ipv4 != NULL)
-				route_ipv4->if_out = atoi(tokens[ti]);
-			else
-				route_ipv6->if_out = atoi(tokens[ti]);
-		}
-	}
-
-	*n_rts = *n_rts + 1;
-}
-
-void
-rt_init(struct socket_ctx *ctx, int32_t socket_id)
-{
-	char name[PATH_MAX];
-	uint32_t i;
-	int32_t ret;
-	struct rte_lpm *lpm;
-	struct rte_lpm6 *lpm6;
-	char a, b, c, d;
-	struct rte_lpm_config conf = { 0 };
-	struct rte_lpm6_config conf6 = { 0 };
-
-	if (ctx == NULL)
-		rte_exit(EXIT_FAILURE, "NULL context.\n");
-
-	if (ctx->rt_ip4 != NULL)
-		rte_exit(EXIT_FAILURE, "IPv4 Routing Table for socket %u "
-			"already initialized\n", socket_id);
-
-	if (ctx->rt_ip6 != NULL)
-		rte_exit(EXIT_FAILURE, "IPv6 Routing Table for socket %u "
-			"already initialized\n", socket_id);
-
-	if (nb_rt_ip4 == 0 && nb_rt_ip6 == 0)
-		RTE_LOG(WARNING, IPSEC, "No Routing rule specified\n");
-
-	printf("Creating IPv4 Routing Table (RT) context with %u max routes\n",
-			RT_IPV4_MAX_RULES);
-
-	/* create the LPM table */
-	snprintf(name, sizeof(name), "%s_%u", "rt_ip4", socket_id);
-	conf.max_rules = RT_IPV4_MAX_RULES;
-	conf.number_tbl8s = RTE_LPM_TBL8_NUM_ENTRIES;
-	lpm = rte_lpm_create(name, socket_id, &conf);
-	if (lpm == NULL)
-		rte_exit(EXIT_FAILURE, "Unable to create %s LPM table "
-			"on socket %d\n", name, socket_id);
-
-	/* populate the LPM table */
-	for (i = 0; i < nb_rt_ip4; i++) {
-		ret = rte_lpm_add(lpm, rt_ip4[i].ip, rt_ip4[i].depth,
-			rt_ip4[i].if_out);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "Fail to add entry num %u to %s "
-				"LPM table on socket %d\n", i, name, socket_id);
-
-		uint32_t_to_char(rt_ip4[i].ip, &a, &b, &c, &d);
-		printf("LPM: Adding route %hhu.%hhu.%hhu.%hhu/%hhu (%hhu)\n",
-				a, b, c, d, rt_ip4[i].depth,
-				rt_ip4[i].if_out);
-	}
-
-	snprintf(name, sizeof(name), "%s_%u", "rt_ip6", socket_id);
-	conf6.max_rules = RT_IPV6_MAX_RULES;
-	conf6.number_tbl8s = RTE_LPM_TBL8_NUM_ENTRIES;
-	lpm6 = rte_lpm6_create(name, socket_id, &conf6);
-	if (lpm6 == NULL)
-		rte_exit(EXIT_FAILURE, "Unable to create %s LPM table "
-			"on socket %d\n", name, socket_id);
-
-	/* populate the LPM table */
-	for (i = 0; i < nb_rt_ip6; i++) {
-		ret = rte_lpm6_add(lpm6, rt_ip6[i].ip, rt_ip6[i].depth,
-				rt_ip6[i].if_out);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "Fail to add entry num %u to %s "
-				"LPM table on socket %d\n", i, name, socket_id);
-
-		printf("LPM6: Adding route "
-			" %hx:%hx:%hx:%hx:%hx:%hx:%hx:%hx/%hhx (%hhx)\n",
-			(uint16_t)((rt_ip6[i].ip[0] << 8) | rt_ip6[i].ip[1]),
-			(uint16_t)((rt_ip6[i].ip[2] << 8) | rt_ip6[i].ip[3]),
-			(uint16_t)((rt_ip6[i].ip[4] << 8) | rt_ip6[i].ip[5]),
-			(uint16_t)((rt_ip6[i].ip[6] << 8) | rt_ip6[i].ip[7]),
-			(uint16_t)((rt_ip6[i].ip[8] << 8) | rt_ip6[i].ip[9]),
-			(uint16_t)((rt_ip6[i].ip[10] << 8) | rt_ip6[i].ip[11]),
-			(uint16_t)((rt_ip6[i].ip[12] << 8) | rt_ip6[i].ip[13]),
-			(uint16_t)((rt_ip6[i].ip[14] << 8) | rt_ip6[i].ip[15]),
-			rt_ip6[i].depth, rt_ip6[i].if_out);
-	}
-
-	ctx->rt_ip4 = (struct rt_ctx *)lpm;
-	ctx->rt_ip6 = (struct rt_ctx *)lpm6;
-}
diff --git a/examples/ipsec-secgw/sa.c b/examples/ipsec-secgw/sa.c
deleted file mode 100644
index d9dcc0e..0000000
--- a/examples/ipsec-secgw/sa.c
+++ /dev/null
@@ -1,1010 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016-2017 Intel Corporation
- */
-
-/*
- * Security Associations
- */
-#include <sys/types.h>
-#include <netinet/in.h>
-#include <netinet/ip.h>
-#include <netinet/ip6.h>
-
-#include <rte_memzone.h>
-#include <rte_crypto.h>
-#include <rte_security.h>
-#include <rte_cryptodev.h>
-#include <rte_byteorder.h>
-#include <rte_errno.h>
-#include <rte_ip.h>
-#include <rte_random.h>
-#include <rte_ethdev.h>
-
-#include "ipsec.h"
-#include "esp.h"
-#include "parser.h"
-
-#define IPDEFTTL 64
-
-struct supported_cipher_algo {
-	const char *keyword;
-	enum rte_crypto_cipher_algorithm algo;
-	uint16_t iv_len;
-	uint16_t block_size;
-	uint16_t key_len;
-};
-
-struct supported_auth_algo {
-	const char *keyword;
-	enum rte_crypto_auth_algorithm algo;
-	uint16_t digest_len;
-	uint16_t key_len;
-	uint8_t key_not_req;
-};
-
-struct supported_aead_algo {
-	const char *keyword;
-	enum rte_crypto_aead_algorithm algo;
-	uint16_t iv_len;
-	uint16_t block_size;
-	uint16_t digest_len;
-	uint16_t key_len;
-	uint8_t aad_len;
-};
-
-
-const struct supported_cipher_algo cipher_algos[] = {
-	{
-		.keyword = "null",
-		.algo = RTE_CRYPTO_CIPHER_NULL,
-		.iv_len = 0,
-		.block_size = 4,
-		.key_len = 0
-	},
-	{
-		.keyword = "aes-128-cbc",
-		.algo = RTE_CRYPTO_CIPHER_AES_CBC,
-		.iv_len = 16,
-		.block_size = 16,
-		.key_len = 16
-	},
-	{
-		.keyword = "aes-256-cbc",
-		.algo = RTE_CRYPTO_CIPHER_AES_CBC,
-		.iv_len = 16,
-		.block_size = 16,
-		.key_len = 32
-	},
-	{
-		.keyword = "aes-128-ctr",
-		.algo = RTE_CRYPTO_CIPHER_AES_CTR,
-		.iv_len = 8,
-		.block_size = 16, /* XXX AESNI MB limition, should be 4 */
-		.key_len = 20
-	}
-};
-
-const struct supported_auth_algo auth_algos[] = {
-	{
-		.keyword = "null",
-		.algo = RTE_CRYPTO_AUTH_NULL,
-		.digest_len = 0,
-		.key_len = 0,
-		.key_not_req = 1
-	},
-	{
-		.keyword = "sha1-hmac",
-		.algo = RTE_CRYPTO_AUTH_SHA1_HMAC,
-		.digest_len = 12,
-		.key_len = 20
-	},
-	{
-		.keyword = "sha256-hmac",
-		.algo = RTE_CRYPTO_AUTH_SHA256_HMAC,
-		.digest_len = 12,
-		.key_len = 32
-	}
-};
-
-const struct supported_aead_algo aead_algos[] = {
-	{
-		.keyword = "aes-128-gcm",
-		.algo = RTE_CRYPTO_AEAD_AES_GCM,
-		.iv_len = 8,
-		.block_size = 4,
-		.key_len = 20,
-		.digest_len = 16,
-		.aad_len = 8,
-	}
-};
-
-struct ipsec_sa sa_out[IPSEC_SA_MAX_ENTRIES];
-uint32_t nb_sa_out;
-
-struct ipsec_sa sa_in[IPSEC_SA_MAX_ENTRIES];
-uint32_t nb_sa_in;
-
-static const struct supported_cipher_algo *
-find_match_cipher_algo(const char *cipher_keyword)
-{
-	size_t i;
-
-	for (i = 0; i < RTE_DIM(cipher_algos); i++) {
-		const struct supported_cipher_algo *algo =
-			&cipher_algos[i];
-
-		if (strcmp(cipher_keyword, algo->keyword) == 0)
-			return algo;
-	}
-
-	return NULL;
-}
-
-static const struct supported_auth_algo *
-find_match_auth_algo(const char *auth_keyword)
-{
-	size_t i;
-
-	for (i = 0; i < RTE_DIM(auth_algos); i++) {
-		const struct supported_auth_algo *algo =
-			&auth_algos[i];
-
-		if (strcmp(auth_keyword, algo->keyword) == 0)
-			return algo;
-	}
-
-	return NULL;
-}
-
-static const struct supported_aead_algo *
-find_match_aead_algo(const char *aead_keyword)
-{
-	size_t i;
-
-	for (i = 0; i < RTE_DIM(aead_algos); i++) {
-		const struct supported_aead_algo *algo =
-			&aead_algos[i];
-
-		if (strcmp(aead_keyword, algo->keyword) == 0)
-			return algo;
-	}
-
-	return NULL;
-}
-
-/** parse_key_string
- *  parse x:x:x:x.... hex number key string into uint8_t *key
- *  return:
- *  > 0: number of bytes parsed
- *  0:   failed
- */
-static uint32_t
-parse_key_string(const char *key_str, uint8_t *key)
-{
-	const char *pt_start = key_str, *pt_end = key_str;
-	uint32_t nb_bytes = 0;
-
-	while (pt_end != NULL) {
-		char sub_str[3] = {0};
-
-		pt_end = strchr(pt_start, ':');
-
-		if (pt_end == NULL) {
-			if (strlen(pt_start) > 2)
-				return 0;
-			strncpy(sub_str, pt_start, 2);
-		} else {
-			if (pt_end - pt_start > 2)
-				return 0;
-
-			strncpy(sub_str, pt_start, pt_end - pt_start);
-			pt_start = pt_end + 1;
-		}
-
-		key[nb_bytes++] = strtol(sub_str, NULL, 16);
-	}
-
-	return nb_bytes;
-}
-
-void
-parse_sa_tokens(char **tokens, uint32_t n_tokens,
-	struct parse_status *status)
-{
-	struct ipsec_sa *rule = NULL;
-	uint32_t ti; /*token index*/
-	uint32_t *ri /*rule index*/;
-	uint32_t cipher_algo_p = 0;
-	uint32_t auth_algo_p = 0;
-	uint32_t aead_algo_p = 0;
-	uint32_t src_p = 0;
-	uint32_t dst_p = 0;
-	uint32_t mode_p = 0;
-	uint32_t type_p = 0;
-	uint32_t portid_p = 0;
-
-	if (strcmp(tokens[0], "in") == 0) {
-		ri = &nb_sa_in;
-
-		APP_CHECK(*ri <= IPSEC_SA_MAX_ENTRIES - 1, status,
-			"too many sa rules, abort insertion\n");
-		if (status->status < 0)
-			return;
-
-		rule = &sa_in[*ri];
-	} else {
-		ri = &nb_sa_out;
-
-		APP_CHECK(*ri <= IPSEC_SA_MAX_ENTRIES - 1, status,
-			"too many sa rules, abort insertion\n");
-		if (status->status < 0)
-			return;
-
-		rule = &sa_out[*ri];
-	}
-
-	/* spi number */
-	APP_CHECK_TOKEN_IS_NUM(tokens, 1, status);
-	if (status->status < 0)
-		return;
-	if (atoi(tokens[1]) == INVALID_SPI)
-		return;
-	rule->spi = atoi(tokens[1]);
-
-	for (ti = 2; ti < n_tokens; ti++) {
-		if (strcmp(tokens[ti], "mode") == 0) {
-			APP_CHECK_PRESENCE(mode_p, tokens[ti], status);
-			if (status->status < 0)
-				return;
-
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-
-			if (strcmp(tokens[ti], "ipv4-tunnel") == 0)
-				rule->flags = IP4_TUNNEL;
-			else if (strcmp(tokens[ti], "ipv6-tunnel") == 0)
-				rule->flags = IP6_TUNNEL;
-			else if (strcmp(tokens[ti], "transport") == 0)
-				rule->flags = TRANSPORT;
-			else {
-				APP_CHECK(0, status, "unrecognized "
-					"input \"%s\"", tokens[ti]);
-				return;
-			}
-
-			mode_p = 1;
-			continue;
-		}
-
-		if (strcmp(tokens[ti], "cipher_algo") == 0) {
-			const struct supported_cipher_algo *algo;
-			uint32_t key_len;
-
-			APP_CHECK_PRESENCE(cipher_algo_p, tokens[ti],
-				status);
-			if (status->status < 0)
-				return;
-
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-
-			algo = find_match_cipher_algo(tokens[ti]);
-
-			APP_CHECK(algo != NULL, status, "unrecognized "
-				"input \"%s\"", tokens[ti]);
-
-			rule->cipher_algo = algo->algo;
-			rule->block_size = algo->block_size;
-			rule->iv_len = algo->iv_len;
-			rule->cipher_key_len = algo->key_len;
-
-			/* for NULL algorithm, no cipher key required */
-			if (rule->cipher_algo == RTE_CRYPTO_CIPHER_NULL) {
-				cipher_algo_p = 1;
-				continue;
-			}
-
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-
-			APP_CHECK(strcmp(tokens[ti], "cipher_key") == 0,
-				status, "unrecognized input \"%s\", "
-				"expect \"cipher_key\"", tokens[ti]);
-			if (status->status < 0)
-				return;
-
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-
-			key_len = parse_key_string(tokens[ti],
-				rule->cipher_key);
-			APP_CHECK(key_len == rule->cipher_key_len, status,
-				"unrecognized input \"%s\"", tokens[ti]);
-			if (status->status < 0)
-				return;
-
-			if (algo->algo == RTE_CRYPTO_CIPHER_AES_CBC)
-				rule->salt = (uint32_t)rte_rand();
-
-			if (algo->algo == RTE_CRYPTO_CIPHER_AES_CTR) {
-				key_len -= 4;
-				rule->cipher_key_len = key_len;
-				memcpy(&rule->salt,
-					&rule->cipher_key[key_len], 4);
-			}
-
-			cipher_algo_p = 1;
-			continue;
-		}
-
-		if (strcmp(tokens[ti], "auth_algo") == 0) {
-			const struct supported_auth_algo *algo;
-			uint32_t key_len;
-
-			APP_CHECK_PRESENCE(auth_algo_p, tokens[ti],
-				status);
-			if (status->status < 0)
-				return;
-
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-
-			algo = find_match_auth_algo(tokens[ti]);
-			APP_CHECK(algo != NULL, status, "unrecognized "
-				"input \"%s\"", tokens[ti]);
-
-			rule->auth_algo = algo->algo;
-			rule->auth_key_len = algo->key_len;
-			rule->digest_len = algo->digest_len;
-
-			/* NULL algorithm and combined algos do not
-			 * require auth key
-			 */
-			if (algo->key_not_req) {
-				auth_algo_p = 1;
-				continue;
-			}
-
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-
-			APP_CHECK(strcmp(tokens[ti], "auth_key") == 0,
-				status, "unrecognized input \"%s\", "
-				"expect \"auth_key\"", tokens[ti]);
-			if (status->status < 0)
-				return;
-
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-
-			key_len = parse_key_string(tokens[ti],
-				rule->auth_key);
-			APP_CHECK(key_len == rule->auth_key_len, status,
-				"unrecognized input \"%s\"", tokens[ti]);
-			if (status->status < 0)
-				return;
-
-			auth_algo_p = 1;
-			continue;
-		}
-
-		if (strcmp(tokens[ti], "aead_algo") == 0) {
-			const struct supported_aead_algo *algo;
-			uint32_t key_len;
-
-			APP_CHECK_PRESENCE(aead_algo_p, tokens[ti],
-				status);
-			if (status->status < 0)
-				return;
-
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-
-			algo = find_match_aead_algo(tokens[ti]);
-
-			APP_CHECK(algo != NULL, status, "unrecognized "
-				"input \"%s\"", tokens[ti]);
-
-			rule->aead_algo = algo->algo;
-			rule->cipher_key_len = algo->key_len;
-			rule->digest_len = algo->digest_len;
-			rule->aad_len = algo->aad_len;
-			rule->block_size = algo->block_size;
-			rule->iv_len = algo->iv_len;
-
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-
-			APP_CHECK(strcmp(tokens[ti], "aead_key") == 0,
-				status, "unrecognized input \"%s\", "
-				"expect \"aead_key\"", tokens[ti]);
-			if (status->status < 0)
-				return;
-
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-
-			key_len = parse_key_string(tokens[ti],
-				rule->cipher_key);
-			APP_CHECK(key_len == rule->cipher_key_len, status,
-				"unrecognized input \"%s\"", tokens[ti]);
-			if (status->status < 0)
-				return;
-
-			key_len -= 4;
-			rule->cipher_key_len = key_len;
-			memcpy(&rule->salt,
-				&rule->cipher_key[key_len], 4);
-
-			aead_algo_p = 1;
-			continue;
-		}
-
-		if (strcmp(tokens[ti], "src") == 0) {
-			APP_CHECK_PRESENCE(src_p, tokens[ti], status);
-			if (status->status < 0)
-				return;
-
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-
-			if (rule->flags == IP4_TUNNEL) {
-				struct in_addr ip;
-
-				APP_CHECK(parse_ipv4_addr(tokens[ti],
-					&ip, NULL) == 0, status,
-					"unrecognized input \"%s\", "
-					"expect valid ipv4 addr",
-					tokens[ti]);
-				if (status->status < 0)
-					return;
-				rule->src.ip.ip4 = rte_bswap32(
-					(uint32_t)ip.s_addr);
-			} else if (rule->flags == IP6_TUNNEL) {
-				struct in6_addr ip;
-
-				APP_CHECK(parse_ipv6_addr(tokens[ti], &ip,
-					NULL) == 0, status,
-					"unrecognized input \"%s\", "
-					"expect valid ipv6 addr",
-					tokens[ti]);
-				if (status->status < 0)
-					return;
-				memcpy(rule->src.ip.ip6.ip6_b,
-					ip.s6_addr, 16);
-			} else if (rule->flags == TRANSPORT) {
-				APP_CHECK(0, status, "unrecognized input "
-					"\"%s\"", tokens[ti]);
-				return;
-			}
-
-			src_p = 1;
-			continue;
-		}
-
-		if (strcmp(tokens[ti], "dst") == 0) {
-			APP_CHECK_PRESENCE(dst_p, tokens[ti], status);
-			if (status->status < 0)
-				return;
-
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-
-			if (rule->flags == IP4_TUNNEL) {
-				struct in_addr ip;
-
-				APP_CHECK(parse_ipv4_addr(tokens[ti],
-					&ip, NULL) == 0, status,
-					"unrecognized input \"%s\", "
-					"expect valid ipv4 addr",
-					tokens[ti]);
-				if (status->status < 0)
-					return;
-				rule->dst.ip.ip4 = rte_bswap32(
-					(uint32_t)ip.s_addr);
-			} else if (rule->flags == IP6_TUNNEL) {
-				struct in6_addr ip;
-
-				APP_CHECK(parse_ipv6_addr(tokens[ti], &ip,
-					NULL) == 0, status,
-					"unrecognized input \"%s\", "
-					"expect valid ipv6 addr",
-					tokens[ti]);
-				if (status->status < 0)
-					return;
-				memcpy(rule->dst.ip.ip6.ip6_b, ip.s6_addr, 16);
-			} else if (rule->flags == TRANSPORT) {
-				APP_CHECK(0, status, "unrecognized "
-					"input \"%s\"",	tokens[ti]);
-				return;
-			}
-
-			dst_p = 1;
-			continue;
-		}
-
-		if (strcmp(tokens[ti], "type") == 0) {
-			APP_CHECK_PRESENCE(type_p, tokens[ti], status);
-			if (status->status < 0)
-				return;
-
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-
-			if (strcmp(tokens[ti], "inline-crypto-offload") == 0)
-				rule->type =
-					RTE_SECURITY_ACTION_TYPE_INLINE_CRYPTO;
-			else if (strcmp(tokens[ti],
-					"inline-protocol-offload") == 0)
-				rule->type =
-				RTE_SECURITY_ACTION_TYPE_INLINE_PROTOCOL;
-			else if (strcmp(tokens[ti],
-					"lookaside-protocol-offload") == 0)
-				rule->type =
-				RTE_SECURITY_ACTION_TYPE_LOOKASIDE_PROTOCOL;
-			else if (strcmp(tokens[ti], "no-offload") == 0)
-				rule->type = RTE_SECURITY_ACTION_TYPE_NONE;
-			else {
-				APP_CHECK(0, status, "Invalid input \"%s\"",
-						tokens[ti]);
-				return;
-			}
-
-			type_p = 1;
-			continue;
-		}
-
-		if (strcmp(tokens[ti], "port_id") == 0) {
-			APP_CHECK_PRESENCE(portid_p, tokens[ti], status);
-			if (status->status < 0)
-				return;
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-			rule->portid = atoi(tokens[ti]);
-			if (status->status < 0)
-				return;
-			portid_p = 1;
-			continue;
-		}
-
-		/* unrecognizeable input */
-		APP_CHECK(0, status, "unrecognized input \"%s\"",
-			tokens[ti]);
-		return;
-	}
-
-	if (aead_algo_p) {
-		APP_CHECK(cipher_algo_p == 0, status,
-				"AEAD used, no need for cipher options");
-		if (status->status < 0)
-			return;
-
-		APP_CHECK(auth_algo_p == 0, status,
-				"AEAD used, no need for auth options");
-		if (status->status < 0)
-			return;
-	} else {
-		APP_CHECK(cipher_algo_p == 1, status, "missing cipher or AEAD options");
-		if (status->status < 0)
-			return;
-
-		APP_CHECK(auth_algo_p == 1, status, "missing auth or AEAD options");
-		if (status->status < 0)
-			return;
-	}
-
-	APP_CHECK(mode_p == 1, status, "missing mode option");
-	if (status->status < 0)
-		return;
-
-	if ((rule->type != RTE_SECURITY_ACTION_TYPE_NONE) && (portid_p == 0))
-		printf("Missing portid option, falling back to non-offload\n");
-
-	if (!type_p || !portid_p) {
-		rule->type = RTE_SECURITY_ACTION_TYPE_NONE;
-		rule->portid = -1;
-	}
-
-	*ri = *ri + 1;
-}
-
-static inline void
-print_one_sa_rule(const struct ipsec_sa *sa, int inbound)
-{
-	uint32_t i;
-	uint8_t a, b, c, d;
-
-	printf("\tspi_%s(%3u):", inbound?"in":"out", sa->spi);
-
-	for (i = 0; i < RTE_DIM(cipher_algos); i++) {
-		if (cipher_algos[i].algo == sa->cipher_algo &&
-				cipher_algos[i].key_len == sa->cipher_key_len) {
-			printf("%s ", cipher_algos[i].keyword);
-			break;
-		}
-	}
-
-	for (i = 0; i < RTE_DIM(auth_algos); i++) {
-		if (auth_algos[i].algo == sa->auth_algo) {
-			printf("%s ", auth_algos[i].keyword);
-			break;
-		}
-	}
-
-	for (i = 0; i < RTE_DIM(aead_algos); i++) {
-		if (aead_algos[i].algo == sa->aead_algo) {
-			printf("%s ", aead_algos[i].keyword);
-			break;
-		}
-	}
-
-	printf("mode:");
-
-	switch (sa->flags) {
-	case IP4_TUNNEL:
-		printf("IP4Tunnel ");
-		uint32_t_to_char(sa->src.ip.ip4, &a, &b, &c, &d);
-		printf("%hhu.%hhu.%hhu.%hhu ", d, c, b, a);
-		uint32_t_to_char(sa->dst.ip.ip4, &a, &b, &c, &d);
-		printf("%hhu.%hhu.%hhu.%hhu", d, c, b, a);
-		break;
-	case IP6_TUNNEL:
-		printf("IP6Tunnel ");
-		for (i = 0; i < 16; i++) {
-			if (i % 2 && i != 15)
-				printf("%.2x:", sa->src.ip.ip6.ip6_b[i]);
-			else
-				printf("%.2x", sa->src.ip.ip6.ip6_b[i]);
-		}
-		printf(" ");
-		for (i = 0; i < 16; i++) {
-			if (i % 2 && i != 15)
-				printf("%.2x:", sa->dst.ip.ip6.ip6_b[i]);
-			else
-				printf("%.2x", sa->dst.ip.ip6.ip6_b[i]);
-		}
-		break;
-	case TRANSPORT:
-		printf("Transport");
-		break;
-	}
-	printf("\n");
-}
-
-struct sa_ctx {
-	struct ipsec_sa sa[IPSEC_SA_MAX_ENTRIES];
-	union {
-		struct {
-			struct rte_crypto_sym_xform a;
-			struct rte_crypto_sym_xform b;
-		};
-	} xf[IPSEC_SA_MAX_ENTRIES];
-};
-
-static struct sa_ctx *
-sa_create(const char *name, int32_t socket_id)
-{
-	char s[PATH_MAX];
-	struct sa_ctx *sa_ctx;
-	uint32_t mz_size;
-	const struct rte_memzone *mz;
-
-	snprintf(s, sizeof(s), "%s_%u", name, socket_id);
-
-	/* Create SA array table */
-	printf("Creating SA context with %u maximum entries\n",
-			IPSEC_SA_MAX_ENTRIES);
-
-	mz_size = sizeof(struct sa_ctx);
-	mz = rte_memzone_reserve(s, mz_size, socket_id,
-			RTE_MEMZONE_1GB | RTE_MEMZONE_SIZE_HINT_ONLY);
-	if (mz == NULL) {
-		printf("Failed to allocate SA DB memory\n");
-		rte_errno = -ENOMEM;
-		return NULL;
-	}
-
-	sa_ctx = (struct sa_ctx *)mz->addr;
-
-	return sa_ctx;
-}
-
-static int
-check_eth_dev_caps(uint16_t portid, uint32_t inbound)
-{
-	struct rte_eth_dev_info dev_info;
-
-	rte_eth_dev_info_get(portid, &dev_info);
-
-	if (inbound) {
-		if ((dev_info.rx_offload_capa &
-				DEV_RX_OFFLOAD_SECURITY) == 0) {
-			RTE_LOG(WARNING, PORT,
-				"hardware RX IPSec offload is not supported\n");
-			return -EINVAL;
-		}
-
-	} else { /* outbound */
-		if ((dev_info.tx_offload_capa &
-				DEV_TX_OFFLOAD_SECURITY) == 0) {
-			RTE_LOG(WARNING, PORT,
-				"hardware TX IPSec offload is not supported\n");
-			return -EINVAL;
-		}
-	}
-	return 0;
-}
-
-
-static int
-sa_add_rules(struct sa_ctx *sa_ctx, const struct ipsec_sa entries[],
-		uint32_t nb_entries, uint32_t inbound)
-{
-	struct ipsec_sa *sa;
-	uint32_t i, idx;
-	uint16_t iv_length;
-
-	for (i = 0; i < nb_entries; i++) {
-		idx = SPI2IDX(entries[i].spi);
-		sa = &sa_ctx->sa[idx];
-		if (sa->spi != 0) {
-			printf("Index %u already in use by SPI %u\n",
-					idx, sa->spi);
-			return -EINVAL;
-		}
-		*sa = entries[i];
-		sa->seq = 0;
-
-		if (sa->type == RTE_SECURITY_ACTION_TYPE_INLINE_PROTOCOL ||
-			sa->type == RTE_SECURITY_ACTION_TYPE_INLINE_CRYPTO) {
-			if (check_eth_dev_caps(sa->portid, inbound))
-				return -EINVAL;
-		}
-
-		sa->direction = (inbound == 1) ?
-				RTE_SECURITY_IPSEC_SA_DIR_INGRESS :
-				RTE_SECURITY_IPSEC_SA_DIR_EGRESS;
-
-		switch (sa->flags) {
-		case IP4_TUNNEL:
-			sa->src.ip.ip4 = rte_cpu_to_be_32(sa->src.ip.ip4);
-			sa->dst.ip.ip4 = rte_cpu_to_be_32(sa->dst.ip.ip4);
-		}
-
-		if (sa->aead_algo == RTE_CRYPTO_AEAD_AES_GCM) {
-			iv_length = 16;
-
-			sa_ctx->xf[idx].a.type = RTE_CRYPTO_SYM_XFORM_AEAD;
-			sa_ctx->xf[idx].a.aead.algo = sa->aead_algo;
-			sa_ctx->xf[idx].a.aead.key.data = sa->cipher_key;
-			sa_ctx->xf[idx].a.aead.key.length =
-				sa->cipher_key_len;
-			sa_ctx->xf[idx].a.aead.op = (inbound == 1) ?
-				RTE_CRYPTO_AEAD_OP_DECRYPT :
-				RTE_CRYPTO_AEAD_OP_ENCRYPT;
-			sa_ctx->xf[idx].a.next = NULL;
-			sa_ctx->xf[idx].a.aead.iv.offset = IV_OFFSET;
-			sa_ctx->xf[idx].a.aead.iv.length = iv_length;
-			sa_ctx->xf[idx].a.aead.aad_length =
-				sa->aad_len;
-			sa_ctx->xf[idx].a.aead.digest_length =
-				sa->digest_len;
-
-			sa->xforms = &sa_ctx->xf[idx].a;
-
-			print_one_sa_rule(sa, inbound);
-		} else {
-			switch (sa->cipher_algo) {
-			case RTE_CRYPTO_CIPHER_NULL:
-			case RTE_CRYPTO_CIPHER_AES_CBC:
-				iv_length = sa->iv_len;
-				break;
-			case RTE_CRYPTO_CIPHER_AES_CTR:
-				iv_length = 16;
-				break;
-			default:
-				RTE_LOG(ERR, IPSEC_ESP,
-						"unsupported cipher algorithm %u\n",
-						sa->cipher_algo);
-				return -EINVAL;
-			}
-
-			if (inbound) {
-				sa_ctx->xf[idx].b.type = RTE_CRYPTO_SYM_XFORM_CIPHER;
-				sa_ctx->xf[idx].b.cipher.algo = sa->cipher_algo;
-				sa_ctx->xf[idx].b.cipher.key.data = sa->cipher_key;
-				sa_ctx->xf[idx].b.cipher.key.length =
-					sa->cipher_key_len;
-				sa_ctx->xf[idx].b.cipher.op =
-					RTE_CRYPTO_CIPHER_OP_DECRYPT;
-				sa_ctx->xf[idx].b.next = NULL;
-				sa_ctx->xf[idx].b.cipher.iv.offset = IV_OFFSET;
-				sa_ctx->xf[idx].b.cipher.iv.length = iv_length;
-
-				sa_ctx->xf[idx].a.type = RTE_CRYPTO_SYM_XFORM_AUTH;
-				sa_ctx->xf[idx].a.auth.algo = sa->auth_algo;
-				sa_ctx->xf[idx].a.auth.key.data = sa->auth_key;
-				sa_ctx->xf[idx].a.auth.key.length =
-					sa->auth_key_len;
-				sa_ctx->xf[idx].a.auth.digest_length =
-					sa->digest_len;
-				sa_ctx->xf[idx].a.auth.op =
-					RTE_CRYPTO_AUTH_OP_VERIFY;
-			} else { /* outbound */
-				sa_ctx->xf[idx].a.type = RTE_CRYPTO_SYM_XFORM_CIPHER;
-				sa_ctx->xf[idx].a.cipher.algo = sa->cipher_algo;
-				sa_ctx->xf[idx].a.cipher.key.data = sa->cipher_key;
-				sa_ctx->xf[idx].a.cipher.key.length =
-					sa->cipher_key_len;
-				sa_ctx->xf[idx].a.cipher.op =
-					RTE_CRYPTO_CIPHER_OP_ENCRYPT;
-				sa_ctx->xf[idx].a.next = NULL;
-				sa_ctx->xf[idx].a.cipher.iv.offset = IV_OFFSET;
-				sa_ctx->xf[idx].a.cipher.iv.length = iv_length;
-
-				sa_ctx->xf[idx].b.type = RTE_CRYPTO_SYM_XFORM_AUTH;
-				sa_ctx->xf[idx].b.auth.algo = sa->auth_algo;
-				sa_ctx->xf[idx].b.auth.key.data = sa->auth_key;
-				sa_ctx->xf[idx].b.auth.key.length =
-					sa->auth_key_len;
-				sa_ctx->xf[idx].b.auth.digest_length =
-					sa->digest_len;
-				sa_ctx->xf[idx].b.auth.op =
-					RTE_CRYPTO_AUTH_OP_GENERATE;
-			}
-
-			sa_ctx->xf[idx].a.next = &sa_ctx->xf[idx].b;
-			sa_ctx->xf[idx].b.next = NULL;
-			sa->xforms = &sa_ctx->xf[idx].a;
-
-			print_one_sa_rule(sa, inbound);
-		}
-	}
-
-	return 0;
-}
-
-static inline int
-sa_out_add_rules(struct sa_ctx *sa_ctx, const struct ipsec_sa entries[],
-		uint32_t nb_entries)
-{
-	return sa_add_rules(sa_ctx, entries, nb_entries, 0);
-}
-
-static inline int
-sa_in_add_rules(struct sa_ctx *sa_ctx, const struct ipsec_sa entries[],
-		uint32_t nb_entries)
-{
-	return sa_add_rules(sa_ctx, entries, nb_entries, 1);
-}
-
-void
-sa_init(struct socket_ctx *ctx, int32_t socket_id)
-{
-	const char *name;
-
-	if (ctx == NULL)
-		rte_exit(EXIT_FAILURE, "NULL context.\n");
-
-	if (ctx->sa_in != NULL)
-		rte_exit(EXIT_FAILURE, "Inbound SA DB for socket %u already "
-				"initialized\n", socket_id);
-
-	if (ctx->sa_out != NULL)
-		rte_exit(EXIT_FAILURE, "Outbound SA DB for socket %u already "
-				"initialized\n", socket_id);
-
-	if (nb_sa_in > 0) {
-		name = "sa_in";
-		ctx->sa_in = sa_create(name, socket_id);
-		if (ctx->sa_in == NULL)
-			rte_exit(EXIT_FAILURE, "Error [%d] creating SA "
-				"context %s in socket %d\n", rte_errno,
-				name, socket_id);
-
-		sa_in_add_rules(ctx->sa_in, sa_in, nb_sa_in);
-	} else
-		RTE_LOG(WARNING, IPSEC, "No SA Inbound rule specified\n");
-
-	if (nb_sa_out > 0) {
-		name = "sa_out";
-		ctx->sa_out = sa_create(name, socket_id);
-		if (ctx->sa_out == NULL)
-			rte_exit(EXIT_FAILURE, "Error [%d] creating SA "
-				"context %s in socket %d\n", rte_errno,
-				name, socket_id);
-
-		sa_out_add_rules(ctx->sa_out, sa_out, nb_sa_out);
-	} else
-		RTE_LOG(WARNING, IPSEC, "No SA Outbound rule "
-			"specified\n");
-}
-
-int
-inbound_sa_check(struct sa_ctx *sa_ctx, struct rte_mbuf *m, uint32_t sa_idx)
-{
-	struct ipsec_mbuf_metadata *priv;
-
-	priv = RTE_PTR_ADD(m, sizeof(struct rte_mbuf));
-
-	return (sa_ctx->sa[sa_idx].spi == priv->sa->spi);
-}
-
-static inline void
-single_inbound_lookup(struct ipsec_sa *sadb, struct rte_mbuf *pkt,
-		struct ipsec_sa **sa_ret)
-{
-	struct esp_hdr *esp;
-	struct ip *ip;
-	uint32_t *src4_addr;
-	uint8_t *src6_addr;
-	struct ipsec_sa *sa;
-
-	*sa_ret = NULL;
-
-	ip = rte_pktmbuf_mtod(pkt, struct ip *);
-	if (ip->ip_v == IPVERSION)
-		esp = (struct esp_hdr *)(ip + 1);
-	else
-		esp = (struct esp_hdr *)(((struct ip6_hdr *)ip) + 1);
-
-	if (esp->spi == INVALID_SPI)
-		return;
-
-	sa = &sadb[SPI2IDX(rte_be_to_cpu_32(esp->spi))];
-	if (rte_be_to_cpu_32(esp->spi) != sa->spi)
-		return;
-
-	switch (sa->flags) {
-	case IP4_TUNNEL:
-		src4_addr = RTE_PTR_ADD(ip, offsetof(struct ip, ip_src));
-		if ((ip->ip_v == IPVERSION) &&
-				(sa->src.ip.ip4 == *src4_addr) &&
-				(sa->dst.ip.ip4 == *(src4_addr + 1)))
-			*sa_ret = sa;
-		break;
-	case IP6_TUNNEL:
-		src6_addr = RTE_PTR_ADD(ip, offsetof(struct ip6_hdr, ip6_src));
-		if ((ip->ip_v == IP6_VERSION) &&
-				!memcmp(&sa->src.ip.ip6.ip6, src6_addr, 16) &&
-				!memcmp(&sa->dst.ip.ip6.ip6, src6_addr + 16, 16))
-			*sa_ret = sa;
-		break;
-	case TRANSPORT:
-		*sa_ret = sa;
-	}
-}
-
-void
-inbound_sa_lookup(struct sa_ctx *sa_ctx, struct rte_mbuf *pkts[],
-		struct ipsec_sa *sa[], uint16_t nb_pkts)
-{
-	uint32_t i;
-
-	for (i = 0; i < nb_pkts; i++)
-		single_inbound_lookup(sa_ctx->sa, pkts[i], &sa[i]);
-}
-
-void
-outbound_sa_lookup(struct sa_ctx *sa_ctx, uint32_t sa_idx[],
-		struct ipsec_sa *sa[], uint16_t nb_pkts)
-{
-	uint32_t i;
-
-	for (i = 0; i < nb_pkts; i++)
-		sa[i] = &sa_ctx->sa[sa_idx[i]];
-}
diff --git a/examples/ipsec-secgw/sp4.c b/examples/ipsec-secgw/sp4.c
deleted file mode 100644
index 8d3d3d8..0000000
--- a/examples/ipsec-secgw/sp4.c
+++ /dev/null
@@ -1,506 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016 Intel Corporation
- */
-
-/*
- * Security Policies
- */
-#include <sys/types.h>
-#include <netinet/in.h>
-#include <netinet/ip.h>
-
-#include <rte_acl.h>
-#include <rte_ip.h>
-
-#include "ipsec.h"
-#include "parser.h"
-
-#define MAX_ACL_RULE_NUM	1024
-
-/*
- * Rule and trace formats definitions.
- */
-enum {
-	PROTO_FIELD_IPV4,
-	SRC_FIELD_IPV4,
-	DST_FIELD_IPV4,
-	SRCP_FIELD_IPV4,
-	DSTP_FIELD_IPV4,
-	NUM_FIELDS_IPV4
-};
-
-/*
- * That effectively defines order of IPV4 classifications:
- *  - PROTO
- *  - SRC IP ADDRESS
- *  - DST IP ADDRESS
- *  - PORTS (SRC and DST)
- */
-enum {
-	RTE_ACL_IPV4_PROTO,
-	RTE_ACL_IPV4_SRC,
-	RTE_ACL_IPV4_DST,
-	RTE_ACL_IPV4_PORTS,
-	RTE_ACL_IPV4_NUM
-};
-
-struct rte_acl_field_def ip4_defs[NUM_FIELDS_IPV4] = {
-	{
-	.type = RTE_ACL_FIELD_TYPE_BITMASK,
-	.size = sizeof(uint8_t),
-	.field_index = PROTO_FIELD_IPV4,
-	.input_index = RTE_ACL_IPV4_PROTO,
-	.offset = 0,
-	},
-	{
-	.type = RTE_ACL_FIELD_TYPE_MASK,
-	.size = sizeof(uint32_t),
-	.field_index = SRC_FIELD_IPV4,
-	.input_index = RTE_ACL_IPV4_SRC,
-	.offset = offsetof(struct ip, ip_src) -	offsetof(struct ip, ip_p)
-	},
-	{
-	.type = RTE_ACL_FIELD_TYPE_MASK,
-	.size = sizeof(uint32_t),
-	.field_index = DST_FIELD_IPV4,
-	.input_index = RTE_ACL_IPV4_DST,
-	.offset = offsetof(struct ip, ip_dst) - offsetof(struct ip, ip_p)
-	},
-	{
-	.type = RTE_ACL_FIELD_TYPE_RANGE,
-	.size = sizeof(uint16_t),
-	.field_index = SRCP_FIELD_IPV4,
-	.input_index = RTE_ACL_IPV4_PORTS,
-	.offset = sizeof(struct ip) - offsetof(struct ip, ip_p)
-	},
-	{
-	.type = RTE_ACL_FIELD_TYPE_RANGE,
-	.size = sizeof(uint16_t),
-	.field_index = DSTP_FIELD_IPV4,
-	.input_index = RTE_ACL_IPV4_PORTS,
-	.offset = sizeof(struct ip) - offsetof(struct ip, ip_p) +
-		sizeof(uint16_t)
-	},
-};
-
-RTE_ACL_RULE_DEF(acl4_rules, RTE_DIM(ip4_defs));
-
-struct acl4_rules acl4_rules_out[MAX_ACL_RULE_NUM];
-uint32_t nb_acl4_rules_out;
-
-struct acl4_rules acl4_rules_in[MAX_ACL_RULE_NUM];
-uint32_t nb_acl4_rules_in;
-
-void
-parse_sp4_tokens(char **tokens, uint32_t n_tokens,
-	struct parse_status *status)
-{
-	struct acl4_rules *rule_ipv4 = NULL;
-
-	uint32_t *ri = NULL; /* rule index */
-	uint32_t ti = 0; /* token index */
-
-	uint32_t esp_p = 0;
-	uint32_t protect_p = 0;
-	uint32_t bypass_p = 0;
-	uint32_t discard_p = 0;
-	uint32_t pri_p = 0;
-	uint32_t src_p = 0;
-	uint32_t dst_p = 0;
-	uint32_t proto_p = 0;
-	uint32_t sport_p = 0;
-	uint32_t dport_p = 0;
-
-	if (strcmp(tokens[1], "in") == 0) {
-		ri = &nb_acl4_rules_in;
-
-		APP_CHECK(*ri <= MAX_ACL_RULE_NUM - 1, status,
-			"too many sp rules, abort insertion\n");
-		if (status->status < 0)
-			return;
-
-		rule_ipv4 = &acl4_rules_in[*ri];
-
-	} else if (strcmp(tokens[1], "out") == 0) {
-		ri = &nb_acl4_rules_out;
-
-		APP_CHECK(*ri <= MAX_ACL_RULE_NUM - 1, status,
-			"too many sp rules, abort insertion\n");
-		if (status->status < 0)
-			return;
-
-		rule_ipv4 = &acl4_rules_out[*ri];
-	} else {
-		APP_CHECK(0, status, "unrecognized input \"%s\", expect"
-			" \"in\" or \"out\"\n", tokens[ti]);
-		return;
-	}
-
-	rule_ipv4->data.category_mask = 1;
-
-	for (ti = 2; ti < n_tokens; ti++) {
-		if (strcmp(tokens[ti], "esp") == 0) {
-			/* currently do nothing */
-			APP_CHECK_PRESENCE(esp_p, tokens[ti], status);
-			if (status->status < 0)
-				return;
-			esp_p = 1;
-			continue;
-		}
-
-		if (strcmp(tokens[ti], "protect") == 0) {
-			APP_CHECK_PRESENCE(protect_p, tokens[ti], status);
-			if (status->status < 0)
-				return;
-			APP_CHECK(bypass_p == 0, status, "conflict item "
-				"between \"%s\" and \"%s\"", tokens[ti],
-				"bypass");
-			if (status->status < 0)
-				return;
-			APP_CHECK(discard_p == 0, status, "conflict item "
-				"between \"%s\" and \"%s\"", tokens[ti],
-				"discard");
-			if (status->status < 0)
-				return;
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-			APP_CHECK_TOKEN_IS_NUM(tokens, ti, status);
-			if (status->status < 0)
-				return;
-
-			rule_ipv4->data.userdata =
-				PROTECT(atoi(tokens[ti]));
-
-			protect_p = 1;
-			continue;
-		}
-
-		if (strcmp(tokens[ti], "bypass") == 0) {
-			APP_CHECK_PRESENCE(bypass_p, tokens[ti], status);
-			if (status->status < 0)
-				return;
-			APP_CHECK(protect_p == 0, status, "conflict item "
-				"between \"%s\" and \"%s\"", tokens[ti],
-				"protect");
-			if (status->status < 0)
-				return;
-			APP_CHECK(discard_p == 0, status, "conflict item "
-				"between \"%s\" and \"%s\"", tokens[ti],
-				"discard");
-			if (status->status < 0)
-				return;
-
-			rule_ipv4->data.userdata = BYPASS;
-
-			bypass_p = 1;
-			continue;
-		}
-
-		if (strcmp(tokens[ti], "discard") == 0) {
-			APP_CHECK_PRESENCE(discard_p, tokens[ti], status);
-			if (status->status < 0)
-				return;
-			APP_CHECK(protect_p == 0, status, "conflict item "
-				"between \"%s\" and \"%s\"", tokens[ti],
-				"protect");
-			if (status->status < 0)
-				return;
-			APP_CHECK(bypass_p == 0, status, "conflict item "
-				"between \"%s\" and \"%s\"", tokens[ti],
-				"discard");
-			if (status->status < 0)
-				return;
-
-			rule_ipv4->data.userdata = DISCARD;
-
-			discard_p = 1;
-			continue;
-		}
-
-		if (strcmp(tokens[ti], "pri") == 0) {
-			APP_CHECK_PRESENCE(pri_p, tokens[ti], status);
-			if (status->status < 0)
-				return;
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-			APP_CHECK_TOKEN_IS_NUM(tokens, ti, status);
-			if (status->status < 0)
-				return;
-
-			rule_ipv4->data.priority = atoi(tokens[ti]);
-
-			pri_p = 1;
-			continue;
-		}
-
-		if (strcmp(tokens[ti], "src") == 0) {
-			struct in_addr ip;
-			uint32_t depth;
-
-			APP_CHECK_PRESENCE(src_p, tokens[ti], status);
-			if (status->status < 0)
-				return;
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-
-			APP_CHECK(parse_ipv4_addr(tokens[ti], &ip,
-				&depth) == 0, status, "unrecognized "
-				"input \"%s\", expect valid ipv4 addr",
-				tokens[ti]);
-			if (status->status < 0)
-				return;
-
-			rule_ipv4->field[1].value.u32 =
-				rte_bswap32(ip.s_addr);
-			rule_ipv4->field[1].mask_range.u32 =
-				depth;
-
-			src_p = 1;
-			continue;
-		}
-
-		if (strcmp(tokens[ti], "dst") == 0) {
-			struct in_addr ip;
-			uint32_t depth;
-
-			APP_CHECK_PRESENCE(dst_p, tokens[ti], status);
-			if (status->status < 0)
-				return;
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-			APP_CHECK(parse_ipv4_addr(tokens[ti], &ip,
-				&depth) == 0, status, "unrecognized "
-				"input \"%s\", expect valid ipv4 addr",
-				tokens[ti]);
-			if (status->status < 0)
-				return;
-
-			rule_ipv4->field[2].value.u32 =
-				rte_bswap32(ip.s_addr);
-			rule_ipv4->field[2].mask_range.u32 =
-				depth;
-
-			dst_p = 1;
-			continue;
-		}
-
-		if (strcmp(tokens[ti], "proto") == 0) {
-			uint16_t low, high;
-
-			APP_CHECK_PRESENCE(proto_p, tokens[ti], status);
-			if (status->status < 0)
-				return;
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-
-			APP_CHECK(parse_range(tokens[ti], &low, &high)
-				== 0, status, "unrecognized input \"%s\""
-				", expect \"from:to\"", tokens[ti]);
-			if (status->status < 0)
-				return;
-			APP_CHECK(low <= 0xff, status, "proto low "
-				"over-limit");
-			if (status->status < 0)
-				return;
-			APP_CHECK(high <= 0xff, status, "proto high "
-				"over-limit");
-			if (status->status < 0)
-				return;
-
-			rule_ipv4->field[0].value.u8 = (uint8_t)low;
-			rule_ipv4->field[0].mask_range.u8 = (uint8_t)high;
-
-			proto_p = 1;
-			continue;
-		}
-
-		if (strcmp(tokens[ti], "sport") == 0) {
-			uint16_t port_low, port_high;
-
-			APP_CHECK_PRESENCE(sport_p, tokens[ti], status);
-			if (status->status < 0)
-				return;
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-
-			APP_CHECK(parse_range(tokens[ti], &port_low,
-				&port_high) == 0, status, "unrecognized "
-				"input \"%s\", expect \"port_from:"
-				"port_to\"", tokens[ti]);
-			if (status->status < 0)
-				return;
-
-			rule_ipv4->field[3].value.u16 = port_low;
-			rule_ipv4->field[3].mask_range.u16 = port_high;
-
-			sport_p = 1;
-			continue;
-		}
-
-		if (strcmp(tokens[ti], "dport") == 0) {
-			uint16_t port_low, port_high;
-
-			APP_CHECK_PRESENCE(dport_p, tokens[ti], status);
-			if (status->status < 0)
-				return;
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-
-			APP_CHECK(parse_range(tokens[ti], &port_low,
-				&port_high) == 0, status, "unrecognized "
-				"input \"%s\", expect \"port_from:"
-				"port_to\"", tokens[ti]);
-			if (status->status < 0)
-				return;
-
-			rule_ipv4->field[4].value.u16 = port_low;
-			rule_ipv4->field[4].mask_range.u16 = port_high;
-
-			dport_p = 1;
-			continue;
-		}
-
-		/* unrecognizeable input */
-		APP_CHECK(0, status, "unrecognized input \"%s\"",
-			tokens[ti]);
-		return;
-	}
-
-	/* check if argument(s) are missing */
-	APP_CHECK(esp_p == 1, status, "missing argument \"esp\"");
-	if (status->status < 0)
-		return;
-
-	APP_CHECK(protect_p | bypass_p | discard_p, status, "missing "
-		"argument \"protect\", \"bypass\", or \"discard\"");
-	if (status->status < 0)
-		return;
-
-	*ri = *ri + 1;
-}
-
-static void
-print_one_ip4_rule(const struct acl4_rules *rule, int32_t extra)
-{
-	uint8_t a, b, c, d;
-
-	uint32_t_to_char(rule->field[SRC_FIELD_IPV4].value.u32,
-			&a, &b, &c, &d);
-	printf("%hhu.%hhu.%hhu.%hhu/%u ", a, b, c, d,
-			rule->field[SRC_FIELD_IPV4].mask_range.u32);
-	uint32_t_to_char(rule->field[DST_FIELD_IPV4].value.u32,
-			&a, &b, &c, &d);
-	printf("%hhu.%hhu.%hhu.%hhu/%u ", a, b, c, d,
-			rule->field[DST_FIELD_IPV4].mask_range.u32);
-	printf("%hu : %hu %hu : %hu 0x%hhx/0x%hhx ",
-		rule->field[SRCP_FIELD_IPV4].value.u16,
-		rule->field[SRCP_FIELD_IPV4].mask_range.u16,
-		rule->field[DSTP_FIELD_IPV4].value.u16,
-		rule->field[DSTP_FIELD_IPV4].mask_range.u16,
-		rule->field[PROTO_FIELD_IPV4].value.u8,
-		rule->field[PROTO_FIELD_IPV4].mask_range.u8);
-	if (extra)
-		printf("0x%x-0x%x-0x%x ",
-			rule->data.category_mask,
-			rule->data.priority,
-			rule->data.userdata);
-}
-
-static inline void
-dump_ip4_rules(const struct acl4_rules *rule, int32_t num, int32_t extra)
-{
-	int32_t i;
-
-	for (i = 0; i < num; i++, rule++) {
-		printf("\t%d:", i + 1);
-		print_one_ip4_rule(rule, extra);
-		printf("\n");
-	}
-}
-
-static struct rte_acl_ctx *
-acl4_init(const char *name, int32_t socketid, const struct acl4_rules *rules,
-		uint32_t rules_nb)
-{
-	char s[PATH_MAX];
-	struct rte_acl_param acl_param;
-	struct rte_acl_config acl_build_param;
-	struct rte_acl_ctx *ctx;
-
-	printf("Creating SP context with %u max rules\n", MAX_ACL_RULE_NUM);
-
-	memset(&acl_param, 0, sizeof(acl_param));
-
-	/* Create ACL contexts */
-	snprintf(s, sizeof(s), "%s_%d", name, socketid);
-
-	printf("IPv4 %s entries [%u]:\n", s, rules_nb);
-	dump_ip4_rules(rules, rules_nb, 1);
-
-	acl_param.name = s;
-	acl_param.socket_id = socketid;
-	acl_param.rule_size = RTE_ACL_RULE_SZ(RTE_DIM(ip4_defs));
-	acl_param.max_rule_num = MAX_ACL_RULE_NUM;
-
-	ctx = rte_acl_create(&acl_param);
-	if (ctx == NULL)
-		rte_exit(EXIT_FAILURE, "Failed to create ACL context\n");
-
-	if (rte_acl_add_rules(ctx, (const struct rte_acl_rule *)rules,
-				rules_nb) < 0)
-		rte_exit(EXIT_FAILURE, "add rules failed\n");
-
-	/* Perform builds */
-	memset(&acl_build_param, 0, sizeof(acl_build_param));
-
-	acl_build_param.num_categories = DEFAULT_MAX_CATEGORIES;
-	acl_build_param.num_fields = RTE_DIM(ip4_defs);
-	memcpy(&acl_build_param.defs, ip4_defs, sizeof(ip4_defs));
-
-	if (rte_acl_build(ctx, &acl_build_param) != 0)
-		rte_exit(EXIT_FAILURE, "Failed to build ACL trie\n");
-
-	rte_acl_dump(ctx);
-
-	return ctx;
-}
-
-void
-sp4_init(struct socket_ctx *ctx, int32_t socket_id)
-{
-	const char *name;
-
-	if (ctx == NULL)
-		rte_exit(EXIT_FAILURE, "NULL context.\n");
-
-	if (ctx->sp_ip4_in != NULL)
-		rte_exit(EXIT_FAILURE, "Inbound SP DB for socket %u already "
-				"initialized\n", socket_id);
-
-	if (ctx->sp_ip4_out != NULL)
-		rte_exit(EXIT_FAILURE, "Outbound SP DB for socket %u already "
-				"initialized\n", socket_id);
-
-	if (nb_acl4_rules_in > 0) {
-		name = "sp_ip4_in";
-		ctx->sp_ip4_in = (struct sp_ctx *)acl4_init(name,
-			socket_id, acl4_rules_in, nb_acl4_rules_in);
-	} else
-		RTE_LOG(WARNING, IPSEC, "No IPv4 SP Inbound rule "
-			"specified\n");
-
-	if (nb_acl4_rules_out > 0) {
-		name = "sp_ip4_out";
-		ctx->sp_ip4_out = (struct sp_ctx *)acl4_init(name,
-			socket_id, acl4_rules_out, nb_acl4_rules_out);
-	} else
-		RTE_LOG(WARNING, IPSEC, "No IPv4 SP Outbound rule "
-			"specified\n");
-}
diff --git a/examples/ipsec-secgw/sp6.c b/examples/ipsec-secgw/sp6.c
deleted file mode 100644
index 6002afe..0000000
--- a/examples/ipsec-secgw/sp6.c
+++ /dev/null
@@ -1,620 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016 Intel Corporation
- */
-
-/*
- * Security Policies
- */
-#include <sys/types.h>
-#include <netinet/in.h>
-#include <netinet/ip6.h>
-
-#include <rte_acl.h>
-#include <rte_ip.h>
-
-#include "ipsec.h"
-#include "parser.h"
-
-#define MAX_ACL_RULE_NUM	1024
-
-enum {
-	IP6_PROTO,
-	IP6_SRC0,
-	IP6_SRC1,
-	IP6_SRC2,
-	IP6_SRC3,
-	IP6_DST0,
-	IP6_DST1,
-	IP6_DST2,
-	IP6_DST3,
-	IP6_SRCP,
-	IP6_DSTP,
-	IP6_NUM
-};
-
-#define IP6_ADDR_SIZE 16
-
-struct rte_acl_field_def ip6_defs[IP6_NUM] = {
-	{
-	.type = RTE_ACL_FIELD_TYPE_BITMASK,
-	.size = sizeof(uint8_t),
-	.field_index = IP6_PROTO,
-	.input_index = IP6_PROTO,
-	.offset = 0,
-	},
-	{
-	.type = RTE_ACL_FIELD_TYPE_MASK,
-	.size = 4,
-	.field_index = IP6_SRC0,
-	.input_index = IP6_SRC0,
-	.offset = 2
-	},
-	{
-	.type = RTE_ACL_FIELD_TYPE_MASK,
-	.size = 4,
-	.field_index = IP6_SRC1,
-	.input_index = IP6_SRC1,
-	.offset = 6
-	},
-	{
-	.type = RTE_ACL_FIELD_TYPE_MASK,
-	.size = 4,
-	.field_index = IP6_SRC2,
-	.input_index = IP6_SRC2,
-	.offset = 10
-	},
-	{
-	.type = RTE_ACL_FIELD_TYPE_MASK,
-	.size = 4,
-	.field_index = IP6_SRC3,
-	.input_index = IP6_SRC3,
-	.offset = 14
-	},
-	{
-	.type = RTE_ACL_FIELD_TYPE_MASK,
-	.size = 4,
-	.field_index = IP6_DST0,
-	.input_index = IP6_DST0,
-	.offset = 18
-	},
-	{
-	.type = RTE_ACL_FIELD_TYPE_MASK,
-	.size = 4,
-	.field_index = IP6_DST1,
-	.input_index = IP6_DST1,
-	.offset = 22
-	},
-	{
-	.type = RTE_ACL_FIELD_TYPE_MASK,
-	.size = 4,
-	.field_index = IP6_DST2,
-	.input_index = IP6_DST2,
-	.offset = 26
-	},
-	{
-	.type = RTE_ACL_FIELD_TYPE_MASK,
-	.size = 4,
-	.field_index = IP6_DST3,
-	.input_index = IP6_DST3,
-	.offset = 30
-	},
-	{
-	.type = RTE_ACL_FIELD_TYPE_RANGE,
-	.size = sizeof(uint16_t),
-	.field_index = IP6_SRCP,
-	.input_index = IP6_SRCP,
-	.offset = 34
-	},
-	{
-	.type = RTE_ACL_FIELD_TYPE_RANGE,
-	.size = sizeof(uint16_t),
-	.field_index = IP6_DSTP,
-	.input_index = IP6_SRCP,
-	.offset = 36
-	}
-};
-
-RTE_ACL_RULE_DEF(acl6_rules, RTE_DIM(ip6_defs));
-
-struct acl6_rules acl6_rules_out[MAX_ACL_RULE_NUM];
-uint32_t nb_acl6_rules_out;
-
-struct acl6_rules acl6_rules_in[MAX_ACL_RULE_NUM];
-uint32_t nb_acl6_rules_in;
-
-void
-parse_sp6_tokens(char **tokens, uint32_t n_tokens,
-	struct parse_status *status)
-{
-	struct acl6_rules *rule_ipv6 = NULL;
-
-	uint32_t *ri = NULL; /* rule index */
-	uint32_t ti = 0; /* token index */
-
-	uint32_t esp_p = 0;
-	uint32_t protect_p = 0;
-	uint32_t bypass_p = 0;
-	uint32_t discard_p = 0;
-	uint32_t pri_p = 0;
-	uint32_t src_p = 0;
-	uint32_t dst_p = 0;
-	uint32_t proto_p = 0;
-	uint32_t sport_p = 0;
-	uint32_t dport_p = 0;
-
-	if (strcmp(tokens[1], "in") == 0) {
-		ri = &nb_acl6_rules_in;
-
-		APP_CHECK(*ri <= MAX_ACL_RULE_NUM - 1, status, "too "
-			"many sp rules, abort insertion\n");
-		if (status->status < 0)
-			return;
-
-		rule_ipv6 = &acl6_rules_in[*ri];
-
-	} else if (strcmp(tokens[1], "out") == 0) {
-		ri = &nb_acl6_rules_out;
-
-		APP_CHECK(*ri <= MAX_ACL_RULE_NUM - 1, status, "too "
-			"many sp rules, abort insertion\n");
-		if (status->status < 0)
-			return;
-
-		rule_ipv6 = &acl6_rules_out[*ri];
-
-	} else {
-		APP_CHECK(0, status, "unrecognized input \"%s\", expect"
-			" \"in\" or \"out\"\n", tokens[ti]);
-		return;
-	}
-
-	rule_ipv6->data.category_mask = 1;
-
-
-	for (ti = 2; ti < n_tokens; ti++) {
-		if (strcmp(tokens[ti], "esp") == 0) {
-			/* currently do nothing */
-			APP_CHECK_PRESENCE(esp_p, tokens[ti], status);
-			if (status->status < 0)
-				return;
-			esp_p = 1;
-			continue;
-		}
-
-		if (strcmp(tokens[ti], "protect") == 0) {
-			APP_CHECK_PRESENCE(protect_p, tokens[ti], status);
-			if (status->status < 0)
-				return;
-			APP_CHECK(bypass_p == 0, status, "conflict item "
-				"between \"%s\" and \"%s\"", tokens[ti],
-				"bypass");
-			if (status->status < 0)
-				return;
-			APP_CHECK(discard_p == 0, status, "conflict item "
-				"between \"%s\" and \"%s\"", tokens[ti],
-				"discard");
-			if (status->status < 0)
-				return;
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-			APP_CHECK_TOKEN_IS_NUM(tokens, ti, status);
-			if (status->status < 0)
-				return;
-
-			rule_ipv6->data.userdata =
-				PROTECT(atoi(tokens[ti]));
-
-			protect_p = 1;
-			continue;
-		}
-
-		if (strcmp(tokens[ti], "bypass") == 0) {
-			APP_CHECK_PRESENCE(bypass_p, tokens[ti], status);
-			if (status->status < 0)
-				return;
-			APP_CHECK(protect_p == 0, status, "conflict item "
-				"between \"%s\" and \"%s\"", tokens[ti],
-				"protect");
-			if (status->status < 0)
-				return;
-			APP_CHECK(discard_p == 0, status, "conflict item "
-				"between \"%s\" and \"%s\"", tokens[ti],
-				"discard");
-			if (status->status < 0)
-				return;
-
-			rule_ipv6->data.userdata = BYPASS;
-
-			bypass_p = 1;
-			continue;
-		}
-
-		if (strcmp(tokens[ti], "discard") == 0) {
-			APP_CHECK_PRESENCE(discard_p, tokens[ti], status);
-			if (status->status < 0)
-				return;
-			APP_CHECK(protect_p == 0, status, "conflict item "
-				"between \"%s\" and \"%s\"", tokens[ti],
-				"protect");
-			if (status->status < 0)
-				return;
-			APP_CHECK(bypass_p == 0, status, "conflict item "
-				"between \"%s\" and \"%s\"", tokens[ti],
-				"discard");
-			if (status->status < 0)
-				return;
-
-			rule_ipv6->data.userdata = DISCARD;
-
-			discard_p = 1;
-			continue;
-		}
-
-		if (strcmp(tokens[ti], "pri") == 0) {
-			APP_CHECK_PRESENCE(pri_p, tokens[ti], status);
-			if (status->status < 0)
-				return;
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-			APP_CHECK_TOKEN_IS_NUM(tokens, ti, status);
-			if (status->status < 0)
-				return;
-
-			rule_ipv6->data.priority = atoi(tokens[ti]);
-
-			pri_p = 1;
-			continue;
-		}
-
-		if (strcmp(tokens[ti], "src") == 0) {
-			struct in6_addr ip;
-			uint32_t depth;
-
-			APP_CHECK_PRESENCE(src_p, tokens[ti], status);
-			if (status->status < 0)
-				return;
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-
-			APP_CHECK(parse_ipv6_addr(tokens[ti], &ip,
-				&depth) == 0, status, "unrecognized "
-				"input \"%s\", expect valid ipv6 "
-				"addr", tokens[ti]);
-			if (status->status < 0)
-				return;
-
-			rule_ipv6->field[1].value.u32 =
-				(uint32_t)ip.s6_addr[0] << 24 |
-				(uint32_t)ip.s6_addr[1] << 16 |
-				(uint32_t)ip.s6_addr[2] << 8 |
-				(uint32_t)ip.s6_addr[3];
-			rule_ipv6->field[1].mask_range.u32 =
-				(depth > 32) ? 32 : depth;
-			depth = (depth > 32) ? (depth - 32) : 0;
-			rule_ipv6->field[2].value.u32 =
-				(uint32_t)ip.s6_addr[4] << 24 |
-				(uint32_t)ip.s6_addr[5] << 16 |
-				(uint32_t)ip.s6_addr[6] << 8 |
-				(uint32_t)ip.s6_addr[7];
-			rule_ipv6->field[2].mask_range.u32 =
-				(depth > 32) ? 32 : depth;
-			depth = (depth > 32) ? (depth - 32) : 0;
-			rule_ipv6->field[3].value.u32 =
-				(uint32_t)ip.s6_addr[8] << 24 |
-				(uint32_t)ip.s6_addr[9] << 16 |
-				(uint32_t)ip.s6_addr[10] << 8 |
-				(uint32_t)ip.s6_addr[11];
-			rule_ipv6->field[3].mask_range.u32 =
-				(depth > 32) ? 32 : depth;
-			depth = (depth > 32) ? (depth - 32) : 0;
-			rule_ipv6->field[4].value.u32 =
-				(uint32_t)ip.s6_addr[12] << 24 |
-				(uint32_t)ip.s6_addr[13] << 16 |
-				(uint32_t)ip.s6_addr[14] << 8 |
-				(uint32_t)ip.s6_addr[15];
-			rule_ipv6->field[4].mask_range.u32 =
-				(depth > 32) ? 32 : depth;
-
-			src_p = 1;
-			continue;
-		}
-
-		if (strcmp(tokens[ti], "dst") == 0) {
-			struct in6_addr ip;
-			uint32_t depth;
-
-			APP_CHECK_PRESENCE(dst_p, tokens[ti], status);
-			if (status->status < 0)
-				return;
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-
-			APP_CHECK(parse_ipv6_addr(tokens[ti], &ip,
-				&depth) == 0, status, "unrecognized "
-				"input \"%s\", expect valid ipv6 "
-				"addr", tokens[ti]);
-			if (status->status < 0)
-				return;
-
-			rule_ipv6->field[5].value.u32 =
-				(uint32_t)ip.s6_addr[0] << 24 |
-				(uint32_t)ip.s6_addr[1] << 16 |
-				(uint32_t)ip.s6_addr[2] << 8 |
-				(uint32_t)ip.s6_addr[3];
-			rule_ipv6->field[5].mask_range.u32 =
-				(depth > 32) ? 32 : depth;
-			depth = (depth > 32) ? (depth - 32) : 0;
-			rule_ipv6->field[6].value.u32 =
-				(uint32_t)ip.s6_addr[4] << 24 |
-				(uint32_t)ip.s6_addr[5] << 16 |
-				(uint32_t)ip.s6_addr[6] << 8 |
-				(uint32_t)ip.s6_addr[7];
-			rule_ipv6->field[6].mask_range.u32 =
-				(depth > 32) ? 32 : depth;
-			depth = (depth > 32) ? (depth - 32) : 0;
-			rule_ipv6->field[7].value.u32 =
-				(uint32_t)ip.s6_addr[8] << 24 |
-				(uint32_t)ip.s6_addr[9] << 16 |
-				(uint32_t)ip.s6_addr[10] << 8 |
-				(uint32_t)ip.s6_addr[11];
-			rule_ipv6->field[7].mask_range.u32 =
-				(depth > 32) ? 32 : depth;
-			depth = (depth > 32) ? (depth - 32) : 0;
-			rule_ipv6->field[8].value.u32 =
-				(uint32_t)ip.s6_addr[12] << 24 |
-				(uint32_t)ip.s6_addr[13] << 16 |
-				(uint32_t)ip.s6_addr[14] << 8 |
-				(uint32_t)ip.s6_addr[15];
-			rule_ipv6->field[8].mask_range.u32 =
-				(depth > 32) ? 32 : depth;
-
-			dst_p = 1;
-			continue;
-		}
-
-		if (strcmp(tokens[ti], "proto") == 0) {
-			uint16_t low, high;
-
-			APP_CHECK_PRESENCE(proto_p, tokens[ti], status);
-			if (status->status < 0)
-				return;
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-
-			APP_CHECK(parse_range(tokens[ti], &low, &high)
-				== 0, status, "unrecognized input \"%s\""
-				", expect \"from:to\"", tokens[ti]);
-			if (status->status < 0)
-				return;
-			APP_CHECK(low <= 0xff, status, "proto low "
-				"over-limit");
-			if (status->status < 0)
-				return;
-			APP_CHECK(high <= 0xff, status, "proto high "
-				"over-limit");
-			if (status->status < 0)
-				return;
-
-			rule_ipv6->field[0].value.u8 = (uint8_t)low;
-			rule_ipv6->field[0].mask_range.u8 = (uint8_t)high;
-
-			proto_p = 1;
-			continue;
-		}
-
-		if (strcmp(tokens[ti], "sport") == 0) {
-			uint16_t port_low, port_high;
-
-			APP_CHECK_PRESENCE(sport_p, tokens[ti], status);
-			if (status->status < 0)
-				return;
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-
-			APP_CHECK(parse_range(tokens[ti], &port_low,
-				&port_high) == 0, status, "unrecognized "
-				"input \"%s\", expect \"port_from:"
-				"port_to\"", tokens[ti]);
-			if (status->status < 0)
-				return;
-
-			rule_ipv6->field[9].value.u16 = port_low;
-			rule_ipv6->field[9].mask_range.u16 = port_high;
-
-			sport_p = 1;
-			continue;
-		}
-
-		if (strcmp(tokens[ti], "dport") == 0) {
-			uint16_t port_low, port_high;
-
-			APP_CHECK_PRESENCE(dport_p, tokens[ti], status);
-			if (status->status < 0)
-				return;
-			INCREMENT_TOKEN_INDEX(ti, n_tokens, status);
-			if (status->status < 0)
-				return;
-
-			APP_CHECK(parse_range(tokens[ti], &port_low,
-				&port_high) == 0, status, "unrecognized "
-				"input \"%s\", expect \"port_from:"
-				"port_to\"", tokens[ti]);
-			if (status->status < 0)
-				return;
-
-			rule_ipv6->field[10].value.u16 = port_low;
-			rule_ipv6->field[10].mask_range.u16 = port_high;
-
-			dport_p = 1;
-			continue;
-		}
-
-		/* unrecognizeable input */
-		APP_CHECK(0, status, "unrecognized input \"%s\"",
-			tokens[ti]);
-		return;
-	}
-
-	/* check if argument(s) are missing */
-	APP_CHECK(esp_p == 1, status, "missing argument \"esp\"");
-	if (status->status < 0)
-		return;
-
-	APP_CHECK(protect_p | bypass_p | discard_p, status, "missing "
-		"argument \"protect\", \"bypass\", or \"discard\"");
-	if (status->status < 0)
-		return;
-
-	*ri = *ri + 1;
-}
-
-static inline void
-print_one_ip6_rule(const struct acl6_rules *rule, int32_t extra)
-{
-	uint8_t a, b, c, d;
-
-	uint32_t_to_char(rule->field[IP6_SRC0].value.u32,
-		&a, &b, &c, &d);
-	printf("%.2x%.2x:%.2x%.2x", a, b, c, d);
-	uint32_t_to_char(rule->field[IP6_SRC1].value.u32,
-		&a, &b, &c, &d);
-	printf(":%.2x%.2x:%.2x%.2x", a, b, c, d);
-	uint32_t_to_char(rule->field[IP6_SRC2].value.u32,
-		&a, &b, &c, &d);
-	printf(":%.2x%.2x:%.2x%.2x", a, b, c, d);
-	uint32_t_to_char(rule->field[IP6_SRC3].value.u32,
-		&a, &b, &c, &d);
-	printf(":%.2x%.2x:%.2x%.2x/%u ", a, b, c, d,
-			rule->field[IP6_SRC0].mask_range.u32
-			+ rule->field[IP6_SRC1].mask_range.u32
-			+ rule->field[IP6_SRC2].mask_range.u32
-			+ rule->field[IP6_SRC3].mask_range.u32);
-
-	uint32_t_to_char(rule->field[IP6_DST0].value.u32,
-		&a, &b, &c, &d);
-	printf("%.2x%.2x:%.2x%.2x", a, b, c, d);
-	uint32_t_to_char(rule->field[IP6_DST1].value.u32,
-		&a, &b, &c, &d);
-	printf(":%.2x%.2x:%.2x%.2x", a, b, c, d);
-	uint32_t_to_char(rule->field[IP6_DST2].value.u32,
-		&a, &b, &c, &d);
-	printf(":%.2x%.2x:%.2x%.2x", a, b, c, d);
-	uint32_t_to_char(rule->field[IP6_DST3].value.u32,
-		&a, &b, &c, &d);
-	printf(":%.2x%.2x:%.2x%.2x/%u ", a, b, c, d,
-			rule->field[IP6_DST0].mask_range.u32
-			+ rule->field[IP6_DST1].mask_range.u32
-			+ rule->field[IP6_DST2].mask_range.u32
-			+ rule->field[IP6_DST3].mask_range.u32);
-
-	printf("%hu : %hu %hu : %hu 0x%hhx/0x%hhx ",
-		rule->field[IP6_SRCP].value.u16,
-		rule->field[IP6_SRCP].mask_range.u16,
-		rule->field[IP6_DSTP].value.u16,
-		rule->field[IP6_DSTP].mask_range.u16,
-		rule->field[IP6_PROTO].value.u8,
-		rule->field[IP6_PROTO].mask_range.u8);
-	if (extra)
-		printf("0x%x-0x%x-0x%x ",
-			rule->data.category_mask,
-			rule->data.priority,
-			rule->data.userdata);
-}
-
-static inline void
-dump_ip6_rules(const struct acl6_rules *rule, int32_t num, int32_t extra)
-{
-	int32_t i;
-
-	for (i = 0; i < num; i++, rule++) {
-		printf("\t%d:", i + 1);
-		print_one_ip6_rule(rule, extra);
-		printf("\n");
-	}
-}
-
-static struct rte_acl_ctx *
-acl6_init(const char *name, int32_t socketid, const struct acl6_rules *rules,
-		uint32_t rules_nb)
-{
-	char s[PATH_MAX];
-	struct rte_acl_param acl_param;
-	struct rte_acl_config acl_build_param;
-	struct rte_acl_ctx *ctx;
-
-	printf("Creating SP context with %u max rules\n", MAX_ACL_RULE_NUM);
-
-	memset(&acl_param, 0, sizeof(acl_param));
-
-	/* Create ACL contexts */
-	snprintf(s, sizeof(s), "%s_%d", name, socketid);
-
-	printf("IPv4 %s entries [%u]:\n", s, rules_nb);
-	dump_ip6_rules(rules, rules_nb, 1);
-
-	acl_param.name = s;
-	acl_param.socket_id = socketid;
-	acl_param.rule_size = RTE_ACL_RULE_SZ(RTE_DIM(ip6_defs));
-	acl_param.max_rule_num = MAX_ACL_RULE_NUM;
-
-	ctx = rte_acl_create(&acl_param);
-	if (ctx == NULL)
-		rte_exit(EXIT_FAILURE, "Failed to create ACL context\n");
-
-	if (rte_acl_add_rules(ctx, (const struct rte_acl_rule *)rules,
-				rules_nb) < 0)
-		rte_exit(EXIT_FAILURE, "add rules failed\n");
-
-	/* Perform builds */
-	memset(&acl_build_param, 0, sizeof(acl_build_param));
-
-	acl_build_param.num_categories = DEFAULT_MAX_CATEGORIES;
-	acl_build_param.num_fields = RTE_DIM(ip6_defs);
-	memcpy(&acl_build_param.defs, ip6_defs, sizeof(ip6_defs));
-
-	if (rte_acl_build(ctx, &acl_build_param) != 0)
-		rte_exit(EXIT_FAILURE, "Failed to build ACL trie\n");
-
-	rte_acl_dump(ctx);
-
-	return ctx;
-}
-
-void
-sp6_init(struct socket_ctx *ctx, int32_t socket_id)
-{
-	const char *name;
-
-	if (ctx == NULL)
-		rte_exit(EXIT_FAILURE, "NULL context.\n");
-
-	if (ctx->sp_ip6_in != NULL)
-		rte_exit(EXIT_FAILURE, "Inbound IPv6 SP DB for socket %u "
-				"already initialized\n", socket_id);
-
-	if (ctx->sp_ip6_out != NULL)
-		rte_exit(EXIT_FAILURE, "Outbound IPv6 SP DB for socket %u "
-				"already initialized\n", socket_id);
-
-	if (nb_acl6_rules_in > 0) {
-		name = "sp_ip6_in";
-		ctx->sp_ip6_in = (struct sp_ctx *)acl6_init(name,
-			socket_id, acl6_rules_in, nb_acl6_rules_in);
-	} else
-		RTE_LOG(WARNING, IPSEC, "No IPv6 SP Inbound rule "
-			"specified\n");
-
-	if (nb_acl6_rules_out > 0) {
-		name = "sp_ip6_out";
-		ctx->sp_ip6_out = (struct sp_ctx *)acl6_init(name,
-			socket_id, acl6_rules_out, nb_acl6_rules_out);
-	} else
-		RTE_LOG(WARNING, IPSEC, "No IPv6 SP Outbound rule "
-			"specified\n");
-}
diff --git a/examples/ipv4_multicast/Makefile b/examples/ipv4_multicast/Makefile
deleted file mode 100644
index 236e706..0000000
--- a/examples/ipv4_multicast/Makefile
+++ /dev/null
@@ -1,66 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-#
-
-# binary name
-APP = ipv4_multicast
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else # Build using legacy build system
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-
-# workaround for a gcc bug with noreturn attribute
-# http://gcc.gnu.org/bugzilla/show_bug.cgi?id=12603
-ifeq ($(CONFIG_RTE_TOOLCHAIN_GCC),y)
-CFLAGS_main.o += -Wno-return-type
-endif
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-
-endif
diff --git a/examples/ipv4_multicast/main.c b/examples/ipv4_multicast/main.c
deleted file mode 100644
index 23b266b..0000000
--- a/examples/ipv4_multicast/main.c
+++ /dev/null
@@ -1,804 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <sys/types.h>
-#include <string.h>
-#include <sys/queue.h>
-#include <stdarg.h>
-#include <errno.h>
-#include <getopt.h>
-
-#include <rte_common.h>
-#include <rte_byteorder.h>
-#include <rte_log.h>
-#include <rte_memory.h>
-#include <rte_memcpy.h>
-#include <rte_eal.h>
-#include <rte_launch.h>
-#include <rte_atomic.h>
-#include <rte_cycles.h>
-#include <rte_prefetch.h>
-#include <rte_lcore.h>
-#include <rte_per_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_interrupts.h>
-#include <rte_random.h>
-#include <rte_debug.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-#include <rte_malloc.h>
-#include <rte_fbk_hash.h>
-#include <rte_ip.h>
-
-#define RTE_LOGTYPE_IPv4_MULTICAST RTE_LOGTYPE_USER1
-
-#define MAX_PORTS 16
-
-#define	MCAST_CLONE_PORTS	2
-#define	MCAST_CLONE_SEGS	2
-
-#define	PKT_MBUF_DATA_SIZE	RTE_MBUF_DEFAULT_BUF_SIZE
-#define	NB_PKT_MBUF	8192
-
-#define	HDR_MBUF_DATA_SIZE	(2 * RTE_PKTMBUF_HEADROOM)
-#define	NB_HDR_MBUF	(NB_PKT_MBUF * MAX_PORTS)
-
-#define	NB_CLONE_MBUF	(NB_PKT_MBUF * MCAST_CLONE_PORTS * MCAST_CLONE_SEGS * 2)
-
-/* allow max jumbo frame 9.5 KB */
-#define	JUMBO_FRAME_MAX_SIZE	0x2600
-
-#define MAX_PKT_BURST 32
-#define BURST_TX_DRAIN_US 100 /* TX drain every ~100us */
-
-/* Configure how many packets ahead to prefetch, when reading packets */
-#define PREFETCH_OFFSET	3
-
-/*
- * Construct Ethernet multicast address from IPv4 multicast address.
- * Citing RFC 1112, section 6.4:
- * "An IP host group address is mapped to an Ethernet multicast address
- * by placing the low-order 23-bits of the IP address into the low-order
- * 23 bits of the Ethernet multicast address 01-00-5E-00-00-00 (hex)."
- */
-#define	ETHER_ADDR_FOR_IPV4_MCAST(x)	\
-	(rte_cpu_to_be_64(0x01005e000000ULL | ((x) & 0x7fffff)) >> 16)
-
-/*
- * Configurable number of RX/TX ring descriptors
- */
-#define RTE_TEST_RX_DESC_DEFAULT 1024
-#define RTE_TEST_TX_DESC_DEFAULT 1024
-static uint16_t nb_rxd = RTE_TEST_RX_DESC_DEFAULT;
-static uint16_t nb_txd = RTE_TEST_TX_DESC_DEFAULT;
-
-/* ethernet addresses of ports */
-static struct ether_addr ports_eth_addr[MAX_PORTS];
-
-/* mask of enabled ports */
-static uint32_t enabled_port_mask = 0;
-
-static uint16_t nb_ports;
-
-static int rx_queue_per_lcore = 1;
-
-struct mbuf_table {
-	uint16_t len;
-	struct rte_mbuf *m_table[MAX_PKT_BURST];
-};
-
-#define MAX_RX_QUEUE_PER_LCORE 16
-#define MAX_TX_QUEUE_PER_PORT 16
-struct lcore_queue_conf {
-	uint64_t tx_tsc;
-	uint16_t n_rx_queue;
-	uint8_t rx_queue_list[MAX_RX_QUEUE_PER_LCORE];
-	uint16_t tx_queue_id[MAX_PORTS];
-	struct mbuf_table tx_mbufs[MAX_PORTS];
-} __rte_cache_aligned;
-static struct lcore_queue_conf lcore_queue_conf[RTE_MAX_LCORE];
-
-static struct rte_eth_conf port_conf = {
-	.rxmode = {
-		.max_rx_pkt_len = JUMBO_FRAME_MAX_SIZE,
-		.split_hdr_size = 0,
-		.ignore_offload_bitfield = 1,
-		.offloads = (DEV_RX_OFFLOAD_JUMBO_FRAME |
-			     DEV_RX_OFFLOAD_CRC_STRIP),
-	},
-	.txmode = {
-		.mq_mode = ETH_MQ_TX_NONE,
-		.offloads = DEV_TX_OFFLOAD_MULTI_SEGS,
-	},
-};
-
-static struct rte_mempool *packet_pool, *header_pool, *clone_pool;
-
-
-/* Multicast */
-static struct rte_fbk_hash_params mcast_hash_params = {
-	.name = "MCAST_HASH",
-	.entries = 1024,
-	.entries_per_bucket = 4,
-	.socket_id = 0,
-	.hash_func = NULL,
-	.init_val = 0,
-};
-
-struct rte_fbk_hash_table *mcast_hash = NULL;
-
-struct mcast_group_params {
-	uint32_t ip;
-	uint16_t port_mask;
-};
-
-static struct mcast_group_params mcast_group_table[] = {
-		{IPv4(224,0,0,101), 0x1},
-		{IPv4(224,0,0,102), 0x2},
-		{IPv4(224,0,0,103), 0x3},
-		{IPv4(224,0,0,104), 0x4},
-		{IPv4(224,0,0,105), 0x5},
-		{IPv4(224,0,0,106), 0x6},
-		{IPv4(224,0,0,107), 0x7},
-		{IPv4(224,0,0,108), 0x8},
-		{IPv4(224,0,0,109), 0x9},
-		{IPv4(224,0,0,110), 0xA},
-		{IPv4(224,0,0,111), 0xB},
-		{IPv4(224,0,0,112), 0xC},
-		{IPv4(224,0,0,113), 0xD},
-		{IPv4(224,0,0,114), 0xE},
-		{IPv4(224,0,0,115), 0xF},
-};
-
-#define N_MCAST_GROUPS \
-	(sizeof (mcast_group_table) / sizeof (mcast_group_table[0]))
-
-
-/* Send burst of packets on an output interface */
-static void
-send_burst(struct lcore_queue_conf *qconf, uint16_t port)
-{
-	struct rte_mbuf **m_table;
-	uint16_t n, queueid;
-	int ret;
-
-	queueid = qconf->tx_queue_id[port];
-	m_table = (struct rte_mbuf **)qconf->tx_mbufs[port].m_table;
-	n = qconf->tx_mbufs[port].len;
-
-	ret = rte_eth_tx_burst(port, queueid, m_table, n);
-	while (unlikely (ret < n)) {
-		rte_pktmbuf_free(m_table[ret]);
-		ret++;
-	}
-
-	qconf->tx_mbufs[port].len = 0;
-}
-
-/* Get number of bits set. */
-static inline uint32_t
-bitcnt(uint32_t v)
-{
-	uint32_t n;
-
-	for (n = 0; v != 0; v &= v - 1, n++)
-		;
-
-	return n;
-}
-
-/**
- * Create the output multicast packet based on the given input packet.
- * There are two approaches for creating outgoing packet, though both
- * are based on data zero-copy idea, they differ in few details:
- * First one creates a clone of the input packet, e.g - walk though all
- * segments of the input packet, and for each of them create a new packet
- * mbuf and attach that new mbuf to the segment (refer to rte_pktmbuf_clone()
- * for more details). Then new mbuf is allocated for the packet header
- * and is prepended to the 'clone' mbuf.
- * Second approach doesn't make a clone, it just increment refcnt for all
- * input packet segments. Then it allocates new mbuf for the packet header
- * and prepends it to the input packet.
- * Basically first approach reuses only input packet's data, but creates
- * it's own copy of packet's metadata. Second approach reuses both input's
- * packet data and metadata.
- * The advantage of first approach - is that each outgoing packet has it's
- * own copy of metadata, so we can safely modify data pointer of the
- * input packet. That allows us to skip creation if the output packet for
- * the last destination port, but instead modify input packet's header inplace,
- * e.g: for N destination ports we need to invoke mcast_out_pkt (N-1) times.
- * The advantage of second approach - less work for each outgoing packet,
- * e.g: we skip "clone" operation completely. Though it comes with a price -
- * input packet's metadata has to be intact. So for N destination ports we
- * need to invoke mcast_out_pkt N times.
- * So for small number of outgoing ports (and segments in the input packet)
- * first approach will be faster.
- * As number of outgoing ports (and/or input segments) will grow,
- * second way will become more preferable.
- *
- *  @param pkt
- *  Input packet mbuf.
- *  @param use_clone
- *  Control which of the two approaches described above should be used:
- *  - 0 - use second approach:
- *    Don't "clone" input packet.
- *    Prepend new header directly to the input packet
- *  - 1 - use first approach:
- *    Make a "clone" of input packet first.
- *    Prepend new header to the clone of the input packet
- *  @return
- *  - The pointer to the new outgoing packet.
- *  - NULL if operation failed.
- */
-static inline struct rte_mbuf *
-mcast_out_pkt(struct rte_mbuf *pkt, int use_clone)
-{
-	struct rte_mbuf *hdr;
-
-	/* Create new mbuf for the header. */
-	if (unlikely ((hdr = rte_pktmbuf_alloc(header_pool)) == NULL))
-		return NULL;
-
-	/* If requested, then make a new clone packet. */
-	if (use_clone != 0 &&
-	    unlikely ((pkt = rte_pktmbuf_clone(pkt, clone_pool)) == NULL)) {
-		rte_pktmbuf_free(hdr);
-		return NULL;
-	}
-
-	/* prepend new header */
-	hdr->next = pkt;
-
-
-	/* update header's fields */
-	hdr->pkt_len = (uint16_t)(hdr->data_len + pkt->pkt_len);
-	hdr->nb_segs = pkt->nb_segs + 1;
-
-	/* copy metadata from source packet*/
-	hdr->port = pkt->port;
-	hdr->vlan_tci = pkt->vlan_tci;
-	hdr->vlan_tci_outer = pkt->vlan_tci_outer;
-	hdr->tx_offload = pkt->tx_offload;
-	hdr->hash = pkt->hash;
-
-	hdr->ol_flags = pkt->ol_flags;
-
-	__rte_mbuf_sanity_check(hdr, 1);
-	return hdr;
-}
-
-/*
- * Write new Ethernet header to the outgoing packet,
- * and put it into the outgoing queue for the given port.
- */
-static inline void
-mcast_send_pkt(struct rte_mbuf *pkt, struct ether_addr *dest_addr,
-		struct lcore_queue_conf *qconf, uint16_t port)
-{
-	struct ether_hdr *ethdr;
-	uint16_t len;
-
-	/* Construct Ethernet header. */
-	ethdr = (struct ether_hdr *)rte_pktmbuf_prepend(pkt, (uint16_t)sizeof(*ethdr));
-	RTE_ASSERT(ethdr != NULL);
-
-	ether_addr_copy(dest_addr, &ethdr->d_addr);
-	ether_addr_copy(&ports_eth_addr[port], &ethdr->s_addr);
-	ethdr->ether_type = rte_be_to_cpu_16(ETHER_TYPE_IPv4);
-
-	/* Put new packet into the output queue */
-	len = qconf->tx_mbufs[port].len;
-	qconf->tx_mbufs[port].m_table[len] = pkt;
-	qconf->tx_mbufs[port].len = ++len;
-
-	/* Transmit packets */
-	if (unlikely(MAX_PKT_BURST == len))
-		send_burst(qconf, port);
-}
-
-/* Multicast forward of the input packet */
-static inline void
-mcast_forward(struct rte_mbuf *m, struct lcore_queue_conf *qconf)
-{
-	struct rte_mbuf *mc;
-	struct ipv4_hdr *iphdr;
-	uint32_t dest_addr, port_mask, port_num, use_clone;
-	int32_t hash;
-	uint16_t port;
-	union {
-		uint64_t as_int;
-		struct ether_addr as_addr;
-	} dst_eth_addr;
-
-	/* Remove the Ethernet header from the input packet */
-	iphdr = (struct ipv4_hdr *)rte_pktmbuf_adj(m, (uint16_t)sizeof(struct ether_hdr));
-	RTE_ASSERT(iphdr != NULL);
-
-	dest_addr = rte_be_to_cpu_32(iphdr->dst_addr);
-
-	/*
-	 * Check that it is a valid multicast address and
-	 * we have some active ports assigned to it.
-	 */
-	if(!IS_IPV4_MCAST(dest_addr) ||
-	    (hash = rte_fbk_hash_lookup(mcast_hash, dest_addr)) <= 0 ||
-	    (port_mask = hash & enabled_port_mask) == 0) {
-		rte_pktmbuf_free(m);
-		return;
-	}
-
-	/* Calculate number of destination ports. */
-	port_num = bitcnt(port_mask);
-
-	/* Should we use rte_pktmbuf_clone() or not. */
-	use_clone = (port_num <= MCAST_CLONE_PORTS &&
-	    m->nb_segs <= MCAST_CLONE_SEGS);
-
-	/* Mark all packet's segments as referenced port_num times */
-	if (use_clone == 0)
-		rte_pktmbuf_refcnt_update(m, (uint16_t)port_num);
-
-	/* construct destination ethernet address */
-	dst_eth_addr.as_int = ETHER_ADDR_FOR_IPV4_MCAST(dest_addr);
-
-	for (port = 0; use_clone != port_mask; port_mask >>= 1, port++) {
-
-		/* Prepare output packet and send it out. */
-		if ((port_mask & 1) != 0) {
-			if (likely ((mc = mcast_out_pkt(m, use_clone)) != NULL))
-				mcast_send_pkt(mc, &dst_eth_addr.as_addr,
-						qconf, port);
-			else if (use_clone == 0)
-				rte_pktmbuf_free(m);
-		}
-	}
-
-	/*
-	 * If we making clone packets, then, for the last destination port,
-	 * we can overwrite input packet's metadata.
-	 */
-	if (use_clone != 0)
-		mcast_send_pkt(m, &dst_eth_addr.as_addr, qconf, port);
-	else
-		rte_pktmbuf_free(m);
-}
-
-/* Send burst of outgoing packet, if timeout expires. */
-static inline void
-send_timeout_burst(struct lcore_queue_conf *qconf)
-{
-	uint64_t cur_tsc;
-	uint16_t portid;
-	const uint64_t drain_tsc = (rte_get_tsc_hz() + US_PER_S - 1) / US_PER_S * BURST_TX_DRAIN_US;
-
-	cur_tsc = rte_rdtsc();
-	if (likely (cur_tsc < qconf->tx_tsc + drain_tsc))
-		return;
-
-	for (portid = 0; portid < MAX_PORTS; portid++) {
-		if (qconf->tx_mbufs[portid].len != 0)
-			send_burst(qconf, portid);
-	}
-	qconf->tx_tsc = cur_tsc;
-}
-
-/* main processing loop */
-static int
-main_loop(__rte_unused void *dummy)
-{
-	struct rte_mbuf *pkts_burst[MAX_PKT_BURST];
-	unsigned lcore_id;
-	int i, j, nb_rx;
-	uint16_t portid;
-	struct lcore_queue_conf *qconf;
-
-	lcore_id = rte_lcore_id();
-	qconf = &lcore_queue_conf[lcore_id];
-
-
-	if (qconf->n_rx_queue == 0) {
-		RTE_LOG(INFO, IPv4_MULTICAST, "lcore %u has nothing to do\n",
-		    lcore_id);
-		return 0;
-	}
-
-	RTE_LOG(INFO, IPv4_MULTICAST, "entering main loop on lcore %u\n",
-	    lcore_id);
-
-	for (i = 0; i < qconf->n_rx_queue; i++) {
-
-		portid = qconf->rx_queue_list[i];
-		RTE_LOG(INFO, IPv4_MULTICAST, " -- lcoreid=%u portid=%d\n",
-		    lcore_id, portid);
-	}
-
-	while (1) {
-
-		/*
-		 * Read packet from RX queues
-		 */
-		for (i = 0; i < qconf->n_rx_queue; i++) {
-
-			portid = qconf->rx_queue_list[i];
-			nb_rx = rte_eth_rx_burst(portid, 0, pkts_burst,
-						 MAX_PKT_BURST);
-
-			/* Prefetch first packets */
-			for (j = 0; j < PREFETCH_OFFSET && j < nb_rx; j++) {
-				rte_prefetch0(rte_pktmbuf_mtod(
-						pkts_burst[j], void *));
-			}
-
-			/* Prefetch and forward already prefetched packets */
-			for (j = 0; j < (nb_rx - PREFETCH_OFFSET); j++) {
-				rte_prefetch0(rte_pktmbuf_mtod(pkts_burst[
-						j + PREFETCH_OFFSET], void *));
-				mcast_forward(pkts_burst[j], qconf);
-			}
-
-			/* Forward remaining prefetched packets */
-			for (; j < nb_rx; j++) {
-				mcast_forward(pkts_burst[j], qconf);
-			}
-		}
-
-		/* Send out packets from TX queues */
-		send_timeout_burst(qconf);
-	}
-}
-
-/* display usage */
-static void
-print_usage(const char *prgname)
-{
-	printf("%s [EAL options] -- -p PORTMASK [-q NQ]\n"
-	    "  -p PORTMASK: hexadecimal bitmask of ports to configure\n"
-	    "  -q NQ: number of queue (=ports) per lcore (default is 1)\n",
-	    prgname);
-}
-
-static uint32_t
-parse_portmask(const char *portmask)
-{
-	char *end = NULL;
-	unsigned long pm;
-
-	/* parse hexadecimal string */
-	pm = strtoul(portmask, &end, 16);
-	if ((portmask[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return 0;
-
-	return (uint32_t)pm;
-}
-
-static int
-parse_nqueue(const char *q_arg)
-{
-	char *end = NULL;
-	unsigned long n;
-
-	/* parse numerical string */
-	errno = 0;
-	n = strtoul(q_arg, &end, 0);
-	if (errno != 0 || end == NULL || *end != '\0' ||
-			n == 0 || n >= MAX_RX_QUEUE_PER_LCORE)
-		return -1;
-
-	return n;
-}
-
-/* Parse the argument given in the command line of the application */
-static int
-parse_args(int argc, char **argv)
-{
-	int opt, ret;
-	char **argvopt;
-	int option_index;
-	char *prgname = argv[0];
-	static struct option lgopts[] = {
-		{NULL, 0, 0, 0}
-	};
-
-	argvopt = argv;
-
-	while ((opt = getopt_long(argc, argvopt, "p:q:",
-				  lgopts, &option_index)) != EOF) {
-
-		switch (opt) {
-		/* portmask */
-		case 'p':
-			enabled_port_mask = parse_portmask(optarg);
-			if (enabled_port_mask == 0) {
-				printf("invalid portmask\n");
-				print_usage(prgname);
-				return -1;
-			}
-			break;
-
-		/* nqueue */
-		case 'q':
-			rx_queue_per_lcore = parse_nqueue(optarg);
-			if (rx_queue_per_lcore < 0) {
-				printf("invalid queue number\n");
-				print_usage(prgname);
-				return -1;
-			}
-			break;
-
-		default:
-			print_usage(prgname);
-			return -1;
-		}
-	}
-
-	if (optind >= 0)
-		argv[optind-1] = prgname;
-
-	ret = optind-1;
-	optind = 1; /* reset getopt lib */
-	return ret;
-}
-
-static void
-print_ethaddr(const char *name, struct ether_addr *eth_addr)
-{
-	char buf[ETHER_ADDR_FMT_SIZE];
-	ether_format_addr(buf, ETHER_ADDR_FMT_SIZE, eth_addr);
-	printf("%s%s", name, buf);
-}
-
-static int
-init_mcast_hash(void)
-{
-	uint32_t i;
-
-	mcast_hash_params.socket_id = rte_socket_id();
-	mcast_hash = rte_fbk_hash_create(&mcast_hash_params);
-	if (mcast_hash == NULL){
-		return -1;
-	}
-
-	for (i = 0; i < N_MCAST_GROUPS; i ++){
-		if (rte_fbk_hash_add_key(mcast_hash,
-			mcast_group_table[i].ip,
-			mcast_group_table[i].port_mask) < 0) {
-			return -1;
-		}
-	}
-
-	return 0;
-}
-
-/* Check the link status of all ports in up to 9s, and print them finally */
-static void
-check_all_ports_link_status(uint32_t port_mask)
-{
-#define CHECK_INTERVAL 100 /* 100ms */
-#define MAX_CHECK_TIME 90 /* 9s (90 * 100ms) in total */
-	uint16_t portid;
-	uint8_t count, all_ports_up, print_flag = 0;
-	struct rte_eth_link link;
-
-	printf("\nChecking link status");
-	fflush(stdout);
-	for (count = 0; count <= MAX_CHECK_TIME; count++) {
-		all_ports_up = 1;
-		RTE_ETH_FOREACH_DEV(portid) {
-			if ((port_mask & (1 << portid)) == 0)
-				continue;
-			memset(&link, 0, sizeof(link));
-			rte_eth_link_get_nowait(portid, &link);
-			/* print link status if flag set */
-			if (print_flag == 1) {
-				if (link.link_status)
-					printf(
-					"Port%d Link Up. Speed %u Mbps - %s\n",
-					portid, link.link_speed,
-				(link.link_duplex == ETH_LINK_FULL_DUPLEX) ?
-					("full-duplex") : ("half-duplex\n"));
-				else
-					printf("Port %d Link Down\n", portid);
-				continue;
-			}
-			/* clear all_ports_up flag if any link down */
-			if (link.link_status == ETH_LINK_DOWN) {
-				all_ports_up = 0;
-				break;
-			}
-		}
-		/* after finally printing all link status, get out */
-		if (print_flag == 1)
-			break;
-
-		if (all_ports_up == 0) {
-			printf(".");
-			fflush(stdout);
-			rte_delay_ms(CHECK_INTERVAL);
-		}
-
-		/* set the print_flag if all ports up or timeout */
-		if (all_ports_up == 1 || count == (MAX_CHECK_TIME - 1)) {
-			print_flag = 1;
-			printf("done\n");
-		}
-	}
-}
-
-int
-main(int argc, char **argv)
-{
-	struct lcore_queue_conf *qconf;
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_txconf *txconf;
-	int ret;
-	uint16_t queueid;
-	unsigned lcore_id = 0, rx_lcore_id = 0;
-	uint32_t n_tx_queue, nb_lcores;
-	uint16_t portid;
-
-	/* init EAL */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid EAL parameters\n");
-	argc -= ret;
-	argv += ret;
-
-	/* parse application arguments (after the EAL ones) */
-	ret = parse_args(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid IPV4_MULTICAST parameters\n");
-
-	/* create the mbuf pools */
-	packet_pool = rte_pktmbuf_pool_create("packet_pool", NB_PKT_MBUF, 32,
-		0, PKT_MBUF_DATA_SIZE, rte_socket_id());
-
-	if (packet_pool == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot init packet mbuf pool\n");
-
-	header_pool = rte_pktmbuf_pool_create("header_pool", NB_HDR_MBUF, 32,
-		0, HDR_MBUF_DATA_SIZE, rte_socket_id());
-
-	if (header_pool == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot init header mbuf pool\n");
-
-	clone_pool = rte_pktmbuf_pool_create("clone_pool", NB_CLONE_MBUF, 32,
-		0, 0, rte_socket_id());
-
-	if (clone_pool == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot init clone mbuf pool\n");
-
-	nb_ports = rte_eth_dev_count();
-	if (nb_ports == 0)
-		rte_exit(EXIT_FAILURE, "No physical ports!\n");
-	if (nb_ports > MAX_PORTS)
-		nb_ports = MAX_PORTS;
-
-	nb_lcores = rte_lcore_count();
-
-	/* initialize all ports */
-	RTE_ETH_FOREACH_DEV(portid) {
-		struct rte_eth_rxconf rxq_conf;
-		struct rte_eth_conf local_port_conf = port_conf;
-
-		/* skip ports that are not enabled */
-		if ((enabled_port_mask & (1 << portid)) == 0) {
-			printf("Skipping disabled port %d\n", portid);
-			continue;
-		}
-
-		qconf = &lcore_queue_conf[rx_lcore_id];
-
-		/* limit the frame size to the maximum supported by NIC */
-		rte_eth_dev_info_get(portid, &dev_info);
-		local_port_conf.rxmode.max_rx_pkt_len = RTE_MIN(
-		    dev_info.max_rx_pktlen,
-		    local_port_conf.rxmode.max_rx_pkt_len);
-
-		/* get the lcore_id for this port */
-		while (rte_lcore_is_enabled(rx_lcore_id) == 0 ||
-		       qconf->n_rx_queue == (unsigned)rx_queue_per_lcore) {
-
-			rx_lcore_id ++;
-			qconf = &lcore_queue_conf[rx_lcore_id];
-
-			if (rx_lcore_id >= RTE_MAX_LCORE)
-				rte_exit(EXIT_FAILURE, "Not enough cores\n");
-		}
-		qconf->rx_queue_list[qconf->n_rx_queue] = portid;
-		qconf->n_rx_queue++;
-
-		/* init port */
-		printf("Initializing port %d on lcore %u... ", portid,
-		       rx_lcore_id);
-		fflush(stdout);
-
-		n_tx_queue = nb_lcores;
-		if (n_tx_queue > MAX_TX_QUEUE_PER_PORT)
-			n_tx_queue = MAX_TX_QUEUE_PER_PORT;
-
-		ret = rte_eth_dev_configure(portid, 1, (uint16_t)n_tx_queue,
-					    &local_port_conf);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "Cannot configure device: err=%d, port=%d\n",
-				  ret, portid);
-
-		ret = rte_eth_dev_adjust_nb_rx_tx_desc(portid, &nb_rxd,
-						       &nb_txd);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-				 "Cannot adjust number of descriptors: err=%d, port=%d\n",
-				 ret, portid);
-
-		rte_eth_macaddr_get(portid, &ports_eth_addr[portid]);
-		print_ethaddr(" Address:", &ports_eth_addr[portid]);
-		printf(", ");
-
-		/* init one RX queue */
-		queueid = 0;
-		printf("rxq=%hu ", queueid);
-		fflush(stdout);
-		rxq_conf = dev_info.default_rxconf;
-		rxq_conf.offloads = local_port_conf.rxmode.offloads;
-		ret = rte_eth_rx_queue_setup(portid, queueid, nb_rxd,
-					     rte_eth_dev_socket_id(portid),
-					     &rxq_conf,
-					     packet_pool);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "rte_eth_tx_queue_setup: err=%d, port=%d\n",
-				  ret, portid);
-
-		/* init one TX queue per couple (lcore,port) */
-		queueid = 0;
-
-		RTE_LCORE_FOREACH(lcore_id) {
-			if (rte_lcore_is_enabled(lcore_id) == 0)
-				continue;
-			printf("txq=%u,%hu ", lcore_id, queueid);
-			fflush(stdout);
-
-			txconf = &dev_info.default_txconf;
-			txconf->txq_flags = ETH_TXQ_FLAGS_IGNORE;
-			txconf->offloads = local_port_conf.txmode.offloads;
-			ret = rte_eth_tx_queue_setup(portid, queueid, nb_txd,
-						     rte_lcore_to_socket_id(lcore_id), txconf);
-			if (ret < 0)
-				rte_exit(EXIT_FAILURE, "rte_eth_tx_queue_setup: err=%d, "
-					  "port=%d\n", ret, portid);
-
-			qconf = &lcore_queue_conf[lcore_id];
-			qconf->tx_queue_id[portid] = queueid;
-			queueid++;
-		}
-
-		/* Start device */
-		ret = rte_eth_dev_start(portid);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "rte_eth_dev_start: err=%d, port=%d\n",
-				  ret, portid);
-
-		printf("done:\n");
-	}
-
-	check_all_ports_link_status(enabled_port_mask);
-
-	/* initialize the multicast hash */
-	int retval = init_mcast_hash();
-	if (retval != 0)
-		rte_exit(EXIT_FAILURE, "Cannot build the multicast hash\n");
-
-	/* launch per-lcore init on every lcore */
-	rte_eal_mp_remote_launch(main_loop, NULL, CALL_MASTER);
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		if (rte_eal_wait_lcore(lcore_id) < 0)
-			return -1;
-	}
-
-	return 0;
-}
diff --git a/examples/ipv4_multicast/meson.build b/examples/ipv4_multicast/meson.build
deleted file mode 100644
index 6969e2c..0000000
--- a/examples/ipv4_multicast/meson.build
+++ /dev/null
@@ -1,13 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-deps += 'hash'
-allow_experimental_apis = true
-sources = files(
-	'main.c'
-)
diff --git a/examples/kni/Makefile b/examples/kni/Makefile
deleted file mode 100644
index 96ae2fc..0000000
--- a/examples/kni/Makefile
+++ /dev/null
@@ -1,63 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-# binary name
-APP = kni
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else # Build using legacy build system
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-ifneq ($(CONFIG_RTE_EXEC_ENV),"linuxapp")
-$(error This application can only operate in a linuxapp environment, \
-please change the definition of the RTE_TARGET environment variable)
-endif
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-endif
diff --git a/examples/kni/main.c b/examples/kni/main.c
deleted file mode 100644
index 1855c64..0000000
--- a/examples/kni/main.c
+++ /dev/null
@@ -1,972 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <string.h>
-#include <sys/queue.h>
-#include <stdarg.h>
-#include <errno.h>
-#include <getopt.h>
-
-#include <netinet/in.h>
-#include <linux/if.h>
-#include <linux/if_tun.h>
-#include <fcntl.h>
-#include <sys/ioctl.h>
-#include <unistd.h>
-#include <signal.h>
-
-#include <rte_common.h>
-#include <rte_log.h>
-#include <rte_memory.h>
-#include <rte_memcpy.h>
-#include <rte_eal.h>
-#include <rte_per_lcore.h>
-#include <rte_launch.h>
-#include <rte_atomic.h>
-#include <rte_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_interrupts.h>
-#include <rte_bus_pci.h>
-#include <rte_debug.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-#include <rte_string_fns.h>
-#include <rte_cycles.h>
-#include <rte_malloc.h>
-#include <rte_kni.h>
-
-/* Macros for printing using RTE_LOG */
-#define RTE_LOGTYPE_APP RTE_LOGTYPE_USER1
-
-/* Max size of a single packet */
-#define MAX_PACKET_SZ           2048
-
-/* Size of the data buffer in each mbuf */
-#define MBUF_DATA_SZ (MAX_PACKET_SZ + RTE_PKTMBUF_HEADROOM)
-
-/* Number of mbufs in mempool that is created */
-#define NB_MBUF                 (8192 * 16)
-
-/* How many packets to attempt to read from NIC in one go */
-#define PKT_BURST_SZ            32
-
-/* How many objects (mbufs) to keep in per-lcore mempool cache */
-#define MEMPOOL_CACHE_SZ        PKT_BURST_SZ
-
-/* Number of RX ring descriptors */
-#define NB_RXD                  1024
-
-/* Number of TX ring descriptors */
-#define NB_TXD                  1024
-
-/* Total octets in ethernet header */
-#define KNI_ENET_HEADER_SIZE    14
-
-/* Total octets in the FCS */
-#define KNI_ENET_FCS_SIZE       4
-
-#define KNI_US_PER_SECOND       1000000
-#define KNI_SECOND_PER_DAY      86400
-
-#define KNI_MAX_KTHREAD 32
-/*
- * Structure of port parameters
- */
-struct kni_port_params {
-	uint16_t port_id;/* Port ID */
-	unsigned lcore_rx; /* lcore ID for RX */
-	unsigned lcore_tx; /* lcore ID for TX */
-	uint32_t nb_lcore_k; /* Number of lcores for KNI multi kernel threads */
-	uint32_t nb_kni; /* Number of KNI devices to be created */
-	unsigned lcore_k[KNI_MAX_KTHREAD]; /* lcore ID list for kthreads */
-	struct rte_kni *kni[KNI_MAX_KTHREAD]; /* KNI context pointers */
-} __rte_cache_aligned;
-
-static struct kni_port_params *kni_port_params_array[RTE_MAX_ETHPORTS];
-
-
-/* Options for configuring ethernet port */
-static struct rte_eth_conf port_conf = {
-	.rxmode = {
-		.ignore_offload_bitfield = 1,
-		.offloads = DEV_RX_OFFLOAD_CRC_STRIP,
-	},
-	.txmode = {
-		.mq_mode = ETH_MQ_TX_NONE,
-	},
-};
-
-/* Mempool for mbufs */
-static struct rte_mempool * pktmbuf_pool = NULL;
-
-/* Mask of enabled ports */
-static uint32_t ports_mask = 0;
-/* Ports set in promiscuous mode off by default. */
-static int promiscuous_on = 0;
-
-/* Structure type for recording kni interface specific stats */
-struct kni_interface_stats {
-	/* number of pkts received from NIC, and sent to KNI */
-	uint64_t rx_packets;
-
-	/* number of pkts received from NIC, but failed to send to KNI */
-	uint64_t rx_dropped;
-
-	/* number of pkts received from KNI, and sent to NIC */
-	uint64_t tx_packets;
-
-	/* number of pkts received from KNI, but failed to send to NIC */
-	uint64_t tx_dropped;
-};
-
-/* kni device statistics array */
-static struct kni_interface_stats kni_stats[RTE_MAX_ETHPORTS];
-
-static int kni_change_mtu(uint16_t port_id, unsigned int new_mtu);
-static int kni_config_network_interface(uint16_t port_id, uint8_t if_up);
-static int kni_config_mac_address(uint16_t port_id, uint8_t mac_addr[]);
-
-static rte_atomic32_t kni_stop = RTE_ATOMIC32_INIT(0);
-
-/* Print out statistics on packets handled */
-static void
-print_stats(void)
-{
-	uint16_t i;
-
-	printf("\n**KNI example application statistics**\n"
-	       "======  ==============  ============  ============  ============  ============\n"
-	       " Port    Lcore(RX/TX)    rx_packets    rx_dropped    tx_packets    tx_dropped\n"
-	       "------  --------------  ------------  ------------  ------------  ------------\n");
-	for (i = 0; i < RTE_MAX_ETHPORTS; i++) {
-		if (!kni_port_params_array[i])
-			continue;
-
-		printf("%7d %10u/%2u %13"PRIu64" %13"PRIu64" %13"PRIu64" "
-							"%13"PRIu64"\n", i,
-					kni_port_params_array[i]->lcore_rx,
-					kni_port_params_array[i]->lcore_tx,
-						kni_stats[i].rx_packets,
-						kni_stats[i].rx_dropped,
-						kni_stats[i].tx_packets,
-						kni_stats[i].tx_dropped);
-	}
-	printf("======  ==============  ============  ============  ============  ============\n");
-}
-
-/* Custom handling of signals to handle stats and kni processing */
-static void
-signal_handler(int signum)
-{
-	/* When we receive a USR1 signal, print stats */
-	if (signum == SIGUSR1) {
-		print_stats();
-	}
-
-	/* When we receive a USR2 signal, reset stats */
-	if (signum == SIGUSR2) {
-		memset(&kni_stats, 0, sizeof(kni_stats));
-		printf("\n**Statistics have been reset**\n");
-		return;
-	}
-
-	/* When we receive a RTMIN or SIGINT signal, stop kni processing */
-	if (signum == SIGRTMIN || signum == SIGINT){
-		printf("SIGRTMIN is received, and the KNI processing is "
-							"going to stop\n");
-		rte_atomic32_inc(&kni_stop);
-		return;
-        }
-}
-
-static void
-kni_burst_free_mbufs(struct rte_mbuf **pkts, unsigned num)
-{
-	unsigned i;
-
-	if (pkts == NULL)
-		return;
-
-	for (i = 0; i < num; i++) {
-		rte_pktmbuf_free(pkts[i]);
-		pkts[i] = NULL;
-	}
-}
-
-/**
- * Interface to burst rx and enqueue mbufs into rx_q
- */
-static void
-kni_ingress(struct kni_port_params *p)
-{
-	uint8_t i;
-	uint16_t port_id;
-	unsigned nb_rx, num;
-	uint32_t nb_kni;
-	struct rte_mbuf *pkts_burst[PKT_BURST_SZ];
-
-	if (p == NULL)
-		return;
-
-	nb_kni = p->nb_kni;
-	port_id = p->port_id;
-	for (i = 0; i < nb_kni; i++) {
-		/* Burst rx from eth */
-		nb_rx = rte_eth_rx_burst(port_id, 0, pkts_burst, PKT_BURST_SZ);
-		if (unlikely(nb_rx > PKT_BURST_SZ)) {
-			RTE_LOG(ERR, APP, "Error receiving from eth\n");
-			return;
-		}
-		/* Burst tx to kni */
-		num = rte_kni_tx_burst(p->kni[i], pkts_burst, nb_rx);
-		kni_stats[port_id].rx_packets += num;
-
-		rte_kni_handle_request(p->kni[i]);
-		if (unlikely(num < nb_rx)) {
-			/* Free mbufs not tx to kni interface */
-			kni_burst_free_mbufs(&pkts_burst[num], nb_rx - num);
-			kni_stats[port_id].rx_dropped += nb_rx - num;
-		}
-	}
-}
-
-/**
- * Interface to dequeue mbufs from tx_q and burst tx
- */
-static void
-kni_egress(struct kni_port_params *p)
-{
-	uint8_t i;
-	uint16_t port_id;
-	unsigned nb_tx, num;
-	uint32_t nb_kni;
-	struct rte_mbuf *pkts_burst[PKT_BURST_SZ];
-
-	if (p == NULL)
-		return;
-
-	nb_kni = p->nb_kni;
-	port_id = p->port_id;
-	for (i = 0; i < nb_kni; i++) {
-		/* Burst rx from kni */
-		num = rte_kni_rx_burst(p->kni[i], pkts_burst, PKT_BURST_SZ);
-		if (unlikely(num > PKT_BURST_SZ)) {
-			RTE_LOG(ERR, APP, "Error receiving from KNI\n");
-			return;
-		}
-		/* Burst tx to eth */
-		nb_tx = rte_eth_tx_burst(port_id, 0, pkts_burst, (uint16_t)num);
-		kni_stats[port_id].tx_packets += nb_tx;
-		if (unlikely(nb_tx < num)) {
-			/* Free mbufs not tx to NIC */
-			kni_burst_free_mbufs(&pkts_burst[nb_tx], num - nb_tx);
-			kni_stats[port_id].tx_dropped += num - nb_tx;
-		}
-	}
-}
-
-static int
-main_loop(__rte_unused void *arg)
-{
-	uint16_t i;
-	int32_t f_stop;
-	const unsigned lcore_id = rte_lcore_id();
-	enum lcore_rxtx {
-		LCORE_NONE,
-		LCORE_RX,
-		LCORE_TX,
-		LCORE_MAX
-	};
-	enum lcore_rxtx flag = LCORE_NONE;
-
-	RTE_ETH_FOREACH_DEV(i) {
-		if (!kni_port_params_array[i])
-			continue;
-		if (kni_port_params_array[i]->lcore_rx == (uint8_t)lcore_id) {
-			flag = LCORE_RX;
-			break;
-		} else if (kni_port_params_array[i]->lcore_tx ==
-						(uint8_t)lcore_id) {
-			flag = LCORE_TX;
-			break;
-		}
-	}
-
-	if (flag == LCORE_RX) {
-		RTE_LOG(INFO, APP, "Lcore %u is reading from port %d\n",
-					kni_port_params_array[i]->lcore_rx,
-					kni_port_params_array[i]->port_id);
-		while (1) {
-			f_stop = rte_atomic32_read(&kni_stop);
-			if (f_stop)
-				break;
-			kni_ingress(kni_port_params_array[i]);
-		}
-	} else if (flag == LCORE_TX) {
-		RTE_LOG(INFO, APP, "Lcore %u is writing to port %d\n",
-					kni_port_params_array[i]->lcore_tx,
-					kni_port_params_array[i]->port_id);
-		while (1) {
-			f_stop = rte_atomic32_read(&kni_stop);
-			if (f_stop)
-				break;
-			kni_egress(kni_port_params_array[i]);
-		}
-	} else
-		RTE_LOG(INFO, APP, "Lcore %u has nothing to do\n", lcore_id);
-
-	return 0;
-}
-
-/* Display usage instructions */
-static void
-print_usage(const char *prgname)
-{
-	RTE_LOG(INFO, APP, "\nUsage: %s [EAL options] -- -p PORTMASK -P "
-		   "[--config (port,lcore_rx,lcore_tx,lcore_kthread...)"
-		   "[,(port,lcore_rx,lcore_tx,lcore_kthread...)]]\n"
-		   "    -p PORTMASK: hex bitmask of ports to use\n"
-		   "    -P : enable promiscuous mode\n"
-		   "    --config (port,lcore_rx,lcore_tx,lcore_kthread...): "
-		   "port and lcore configurations\n",
-	           prgname);
-}
-
-/* Convert string to unsigned number. 0 is returned if error occurs */
-static uint32_t
-parse_unsigned(const char *portmask)
-{
-	char *end = NULL;
-	unsigned long num;
-
-	num = strtoul(portmask, &end, 16);
-	if ((portmask[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return 0;
-
-	return (uint32_t)num;
-}
-
-static void
-print_config(void)
-{
-	uint32_t i, j;
-	struct kni_port_params **p = kni_port_params_array;
-
-	for (i = 0; i < RTE_MAX_ETHPORTS; i++) {
-		if (!p[i])
-			continue;
-		RTE_LOG(DEBUG, APP, "Port ID: %d\n", p[i]->port_id);
-		RTE_LOG(DEBUG, APP, "Rx lcore ID: %u, Tx lcore ID: %u\n",
-					p[i]->lcore_rx, p[i]->lcore_tx);
-		for (j = 0; j < p[i]->nb_lcore_k; j++)
-			RTE_LOG(DEBUG, APP, "Kernel thread lcore ID: %u\n",
-							p[i]->lcore_k[j]);
-	}
-}
-
-static int
-parse_config(const char *arg)
-{
-	const char *p, *p0 = arg;
-	char s[256], *end;
-	unsigned size;
-	enum fieldnames {
-		FLD_PORT = 0,
-		FLD_LCORE_RX,
-		FLD_LCORE_TX,
-		_NUM_FLD = KNI_MAX_KTHREAD + 3,
-	};
-	int i, j, nb_token;
-	char *str_fld[_NUM_FLD];
-	unsigned long int_fld[_NUM_FLD];
-	uint16_t port_id, nb_kni_port_params = 0;
-
-	memset(&kni_port_params_array, 0, sizeof(kni_port_params_array));
-	while (((p = strchr(p0, '(')) != NULL) &&
-		nb_kni_port_params < RTE_MAX_ETHPORTS) {
-		p++;
-		if ((p0 = strchr(p, ')')) == NULL)
-			goto fail;
-		size = p0 - p;
-		if (size >= sizeof(s)) {
-			printf("Invalid config parameters\n");
-			goto fail;
-		}
-		snprintf(s, sizeof(s), "%.*s", size, p);
-		nb_token = rte_strsplit(s, sizeof(s), str_fld, _NUM_FLD, ',');
-		if (nb_token <= FLD_LCORE_TX) {
-			printf("Invalid config parameters\n");
-			goto fail;
-		}
-		for (i = 0; i < nb_token; i++) {
-			errno = 0;
-			int_fld[i] = strtoul(str_fld[i], &end, 0);
-			if (errno != 0 || end == str_fld[i]) {
-				printf("Invalid config parameters\n");
-				goto fail;
-			}
-		}
-
-		i = 0;
-		port_id = int_fld[i++];
-		if (port_id >= RTE_MAX_ETHPORTS) {
-			printf("Port ID %d could not exceed the maximum %d\n",
-						port_id, RTE_MAX_ETHPORTS);
-			goto fail;
-		}
-		if (kni_port_params_array[port_id]) {
-			printf("Port %d has been configured\n", port_id);
-			goto fail;
-		}
-		kni_port_params_array[port_id] =
-			rte_zmalloc("KNI_port_params",
-				    sizeof(struct kni_port_params), RTE_CACHE_LINE_SIZE);
-		kni_port_params_array[port_id]->port_id = port_id;
-		kni_port_params_array[port_id]->lcore_rx =
-					(uint8_t)int_fld[i++];
-		kni_port_params_array[port_id]->lcore_tx =
-					(uint8_t)int_fld[i++];
-		if (kni_port_params_array[port_id]->lcore_rx >= RTE_MAX_LCORE ||
-		kni_port_params_array[port_id]->lcore_tx >= RTE_MAX_LCORE) {
-			printf("lcore_rx %u or lcore_tx %u ID could not "
-						"exceed the maximum %u\n",
-				kni_port_params_array[port_id]->lcore_rx,
-				kni_port_params_array[port_id]->lcore_tx,
-						(unsigned)RTE_MAX_LCORE);
-			goto fail;
-		}
-		for (j = 0; i < nb_token && j < KNI_MAX_KTHREAD; i++, j++)
-			kni_port_params_array[port_id]->lcore_k[j] =
-						(uint8_t)int_fld[i];
-		kni_port_params_array[port_id]->nb_lcore_k = j;
-	}
-	print_config();
-
-	return 0;
-
-fail:
-	for (i = 0; i < RTE_MAX_ETHPORTS; i++) {
-		if (kni_port_params_array[i]) {
-			rte_free(kni_port_params_array[i]);
-			kni_port_params_array[i] = NULL;
-		}
-	}
-
-	return -1;
-}
-
-static int
-validate_parameters(uint32_t portmask)
-{
-	uint32_t i;
-
-	if (!portmask) {
-		printf("No port configured in port mask\n");
-		return -1;
-	}
-
-	for (i = 0; i < RTE_MAX_ETHPORTS; i++) {
-		if (((portmask & (1 << i)) && !kni_port_params_array[i]) ||
-			(!(portmask & (1 << i)) && kni_port_params_array[i]))
-			rte_exit(EXIT_FAILURE, "portmask is not consistent "
-				"to port ids specified in --config\n");
-
-		if (kni_port_params_array[i] && !rte_lcore_is_enabled(\
-			(unsigned)(kni_port_params_array[i]->lcore_rx)))
-			rte_exit(EXIT_FAILURE, "lcore id %u for "
-					"port %d receiving not enabled\n",
-					kni_port_params_array[i]->lcore_rx,
-					kni_port_params_array[i]->port_id);
-
-		if (kni_port_params_array[i] && !rte_lcore_is_enabled(\
-			(unsigned)(kni_port_params_array[i]->lcore_tx)))
-			rte_exit(EXIT_FAILURE, "lcore id %u for "
-					"port %d transmitting not enabled\n",
-					kni_port_params_array[i]->lcore_tx,
-					kni_port_params_array[i]->port_id);
-
-	}
-
-	return 0;
-}
-
-#define CMDLINE_OPT_CONFIG  "config"
-
-/* Parse the arguments given in the command line of the application */
-static int
-parse_args(int argc, char **argv)
-{
-	int opt, longindex, ret = 0;
-	const char *prgname = argv[0];
-	static struct option longopts[] = {
-		{CMDLINE_OPT_CONFIG, required_argument, NULL, 0},
-		{NULL, 0, NULL, 0}
-	};
-
-	/* Disable printing messages within getopt() */
-	opterr = 0;
-
-	/* Parse command line */
-	while ((opt = getopt_long(argc, argv, "p:P", longopts,
-						&longindex)) != EOF) {
-		switch (opt) {
-		case 'p':
-			ports_mask = parse_unsigned(optarg);
-			break;
-		case 'P':
-			promiscuous_on = 1;
-			break;
-		case 0:
-			if (!strncmp(longopts[longindex].name,
-				     CMDLINE_OPT_CONFIG,
-				     sizeof(CMDLINE_OPT_CONFIG))) {
-				ret = parse_config(optarg);
-				if (ret) {
-					printf("Invalid config\n");
-					print_usage(prgname);
-					return -1;
-				}
-			}
-			break;
-		default:
-			print_usage(prgname);
-			rte_exit(EXIT_FAILURE, "Invalid option specified\n");
-		}
-	}
-
-	/* Check that options were parsed ok */
-	if (validate_parameters(ports_mask) < 0) {
-		print_usage(prgname);
-		rte_exit(EXIT_FAILURE, "Invalid parameters\n");
-	}
-
-	return ret;
-}
-
-/* Initialize KNI subsystem */
-static void
-init_kni(void)
-{
-	unsigned int num_of_kni_ports = 0, i;
-	struct kni_port_params **params = kni_port_params_array;
-
-	/* Calculate the maximum number of KNI interfaces that will be used */
-	for (i = 0; i < RTE_MAX_ETHPORTS; i++) {
-		if (kni_port_params_array[i]) {
-			num_of_kni_ports += (params[i]->nb_lcore_k ?
-				params[i]->nb_lcore_k : 1);
-		}
-	}
-
-	/* Invoke rte KNI init to preallocate the ports */
-	rte_kni_init(num_of_kni_ports);
-}
-
-/* Initialise a single port on an Ethernet device */
-static void
-init_port(uint16_t port)
-{
-	int ret;
-	uint16_t nb_rxd = NB_RXD;
-	uint16_t nb_txd = NB_TXD;
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_rxconf rxq_conf;
-	struct rte_eth_txconf txq_conf;
-	struct rte_eth_conf local_port_conf = port_conf;
-
-	/* Initialise device and RX/TX queues */
-	RTE_LOG(INFO, APP, "Initialising port %u ...\n", (unsigned)port);
-	fflush(stdout);
-	rte_eth_dev_info_get(port, &dev_info);
-	if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-		local_port_conf.txmode.offloads |=
-			DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-	ret = rte_eth_dev_configure(port, 1, 1, &local_port_conf);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Could not configure port%u (%d)\n",
-		            (unsigned)port, ret);
-
-	ret = rte_eth_dev_adjust_nb_rx_tx_desc(port, &nb_rxd, &nb_txd);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Could not adjust number of descriptors "
-				"for port%u (%d)\n", (unsigned)port, ret);
-
-	rxq_conf = dev_info.default_rxconf;
-	rxq_conf.offloads = local_port_conf.rxmode.offloads;
-	ret = rte_eth_rx_queue_setup(port, 0, nb_rxd,
-		rte_eth_dev_socket_id(port), &rxq_conf, pktmbuf_pool);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Could not setup up RX queue for "
-				"port%u (%d)\n", (unsigned)port, ret);
-
-	txq_conf = dev_info.default_txconf;
-	txq_conf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-	txq_conf.offloads = local_port_conf.txmode.offloads;
-	ret = rte_eth_tx_queue_setup(port, 0, nb_txd,
-		rte_eth_dev_socket_id(port), &txq_conf);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Could not setup up TX queue for "
-				"port%u (%d)\n", (unsigned)port, ret);
-
-	ret = rte_eth_dev_start(port);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Could not start port%u (%d)\n",
-						(unsigned)port, ret);
-
-	if (promiscuous_on)
-		rte_eth_promiscuous_enable(port);
-}
-
-/* Check the link status of all ports in up to 9s, and print them finally */
-static void
-check_all_ports_link_status(uint32_t port_mask)
-{
-#define CHECK_INTERVAL 100 /* 100ms */
-#define MAX_CHECK_TIME 90 /* 9s (90 * 100ms) in total */
-	uint16_t portid;
-	uint8_t count, all_ports_up, print_flag = 0;
-	struct rte_eth_link link;
-
-	printf("\nChecking link status\n");
-	fflush(stdout);
-	for (count = 0; count <= MAX_CHECK_TIME; count++) {
-		all_ports_up = 1;
-		RTE_ETH_FOREACH_DEV(portid) {
-			if ((port_mask & (1 << portid)) == 0)
-				continue;
-			memset(&link, 0, sizeof(link));
-			rte_eth_link_get_nowait(portid, &link);
-			/* print link status if flag set */
-			if (print_flag == 1) {
-				if (link.link_status)
-					printf(
-					"Port%d Link Up - speed %uMbps - %s\n",
-						portid, link.link_speed,
-				(link.link_duplex == ETH_LINK_FULL_DUPLEX) ?
-					("full-duplex") : ("half-duplex\n"));
-				else
-					printf("Port %d Link Down\n", portid);
-				continue;
-			}
-			/* clear all_ports_up flag if any link down */
-			if (link.link_status == ETH_LINK_DOWN) {
-				all_ports_up = 0;
-				break;
-			}
-		}
-		/* after finally printing all link status, get out */
-		if (print_flag == 1)
-			break;
-
-		if (all_ports_up == 0) {
-			printf(".");
-			fflush(stdout);
-			rte_delay_ms(CHECK_INTERVAL);
-		}
-
-		/* set the print_flag if all ports up or timeout */
-		if (all_ports_up == 1 || count == (MAX_CHECK_TIME - 1)) {
-			print_flag = 1;
-			printf("done\n");
-		}
-	}
-}
-
-/* Callback for request of changing MTU */
-static int
-kni_change_mtu(uint16_t port_id, unsigned int new_mtu)
-{
-	int ret;
-	uint16_t nb_rxd = NB_RXD;
-	struct rte_eth_conf conf;
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_rxconf rxq_conf;
-
-	if (!rte_eth_dev_is_valid_port(port_id)) {
-		RTE_LOG(ERR, APP, "Invalid port id %d\n", port_id);
-		return -EINVAL;
-	}
-
-	RTE_LOG(INFO, APP, "Change MTU of port %d to %u\n", port_id, new_mtu);
-
-	/* Stop specific port */
-	rte_eth_dev_stop(port_id);
-
-	memcpy(&conf, &port_conf, sizeof(conf));
-	/* Set new MTU */
-	if (new_mtu > ETHER_MAX_LEN)
-		conf.rxmode.offloads |= DEV_RX_OFFLOAD_JUMBO_FRAME;
-	else
-		conf.rxmode.offloads &= ~DEV_RX_OFFLOAD_JUMBO_FRAME;
-
-	/* mtu + length of header + length of FCS = max pkt length */
-	conf.rxmode.max_rx_pkt_len = new_mtu + KNI_ENET_HEADER_SIZE +
-							KNI_ENET_FCS_SIZE;
-	ret = rte_eth_dev_configure(port_id, 1, 1, &conf);
-	if (ret < 0) {
-		RTE_LOG(ERR, APP, "Fail to reconfigure port %d\n", port_id);
-		return ret;
-	}
-
-	ret = rte_eth_dev_adjust_nb_rx_tx_desc(port_id, &nb_rxd, NULL);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Could not adjust number of descriptors "
-				"for port%u (%d)\n", (unsigned int)port_id,
-				ret);
-
-	rte_eth_dev_info_get(port_id, &dev_info);
-	rxq_conf = dev_info.default_rxconf;
-	rxq_conf.offloads = conf.rxmode.offloads;
-	ret = rte_eth_rx_queue_setup(port_id, 0, nb_rxd,
-		rte_eth_dev_socket_id(port_id), &rxq_conf, pktmbuf_pool);
-	if (ret < 0) {
-		RTE_LOG(ERR, APP, "Fail to setup Rx queue of port %d\n",
-				port_id);
-		return ret;
-	}
-
-	/* Restart specific port */
-	ret = rte_eth_dev_start(port_id);
-	if (ret < 0) {
-		RTE_LOG(ERR, APP, "Fail to restart port %d\n", port_id);
-		return ret;
-	}
-
-	return 0;
-}
-
-/* Callback for request of configuring network interface up/down */
-static int
-kni_config_network_interface(uint16_t port_id, uint8_t if_up)
-{
-	int ret = 0;
-
-	if (!rte_eth_dev_is_valid_port(port_id)) {
-		RTE_LOG(ERR, APP, "Invalid port id %d\n", port_id);
-		return -EINVAL;
-	}
-
-	RTE_LOG(INFO, APP, "Configure network interface of %d %s\n",
-					port_id, if_up ? "up" : "down");
-
-	if (if_up != 0) { /* Configure network interface up */
-		rte_eth_dev_stop(port_id);
-		ret = rte_eth_dev_start(port_id);
-	} else /* Configure network interface down */
-		rte_eth_dev_stop(port_id);
-
-	if (ret < 0)
-		RTE_LOG(ERR, APP, "Failed to start port %d\n", port_id);
-
-	return ret;
-}
-
-static void
-print_ethaddr(const char *name, struct ether_addr *mac_addr)
-{
-	char buf[ETHER_ADDR_FMT_SIZE];
-	ether_format_addr(buf, ETHER_ADDR_FMT_SIZE, mac_addr);
-	RTE_LOG(INFO, APP, "\t%s%s\n", name, buf);
-}
-
-/* Callback for request of configuring mac address */
-static int
-kni_config_mac_address(uint16_t port_id, uint8_t mac_addr[])
-{
-	int ret = 0;
-
-	if (!rte_eth_dev_is_valid_port(port_id)) {
-		RTE_LOG(ERR, APP, "Invalid port id %d\n", port_id);
-		return -EINVAL;
-	}
-
-	RTE_LOG(INFO, APP, "Configure mac address of %d\n", port_id);
-	print_ethaddr("Address:", (struct ether_addr *)mac_addr);
-
-	ret = rte_eth_dev_default_mac_addr_set(port_id,
-					       (struct ether_addr *)mac_addr);
-	if (ret < 0)
-		RTE_LOG(ERR, APP, "Failed to config mac_addr for port %d\n",
-			port_id);
-
-	return ret;
-}
-
-static int
-kni_alloc(uint16_t port_id)
-{
-	uint8_t i;
-	struct rte_kni *kni;
-	struct rte_kni_conf conf;
-	struct kni_port_params **params = kni_port_params_array;
-
-	if (port_id >= RTE_MAX_ETHPORTS || !params[port_id])
-		return -1;
-
-	params[port_id]->nb_kni = params[port_id]->nb_lcore_k ?
-				params[port_id]->nb_lcore_k : 1;
-
-	for (i = 0; i < params[port_id]->nb_kni; i++) {
-		/* Clear conf at first */
-		memset(&conf, 0, sizeof(conf));
-		if (params[port_id]->nb_lcore_k) {
-			snprintf(conf.name, RTE_KNI_NAMESIZE,
-					"vEth%u_%u", port_id, i);
-			conf.core_id = params[port_id]->lcore_k[i];
-			conf.force_bind = 1;
-		} else
-			snprintf(conf.name, RTE_KNI_NAMESIZE,
-						"vEth%u", port_id);
-		conf.group_id = port_id;
-		conf.mbuf_size = MAX_PACKET_SZ;
-		/*
-		 * The first KNI device associated to a port
-		 * is the master, for multiple kernel thread
-		 * environment.
-		 */
-		if (i == 0) {
-			struct rte_kni_ops ops;
-			struct rte_eth_dev_info dev_info;
-
-			memset(&dev_info, 0, sizeof(dev_info));
-			rte_eth_dev_info_get(port_id, &dev_info);
-
-			if (dev_info.pci_dev) {
-				conf.addr = dev_info.pci_dev->addr;
-				conf.id = dev_info.pci_dev->id;
-			}
-			/* Get the interface default mac address */
-			rte_eth_macaddr_get(port_id,
-					(struct ether_addr *)&conf.mac_addr);
-
-			rte_eth_dev_get_mtu(port_id, &conf.mtu);
-
-			memset(&ops, 0, sizeof(ops));
-			ops.port_id = port_id;
-			ops.change_mtu = kni_change_mtu;
-			ops.config_network_if = kni_config_network_interface;
-			ops.config_mac_address = kni_config_mac_address;
-
-			kni = rte_kni_alloc(pktmbuf_pool, &conf, &ops);
-		} else
-			kni = rte_kni_alloc(pktmbuf_pool, &conf, NULL);
-
-		if (!kni)
-			rte_exit(EXIT_FAILURE, "Fail to create kni for "
-						"port: %d\n", port_id);
-		params[port_id]->kni[i] = kni;
-	}
-
-	return 0;
-}
-
-static int
-kni_free_kni(uint16_t port_id)
-{
-	uint8_t i;
-	struct kni_port_params **p = kni_port_params_array;
-
-	if (port_id >= RTE_MAX_ETHPORTS || !p[port_id])
-		return -1;
-
-	for (i = 0; i < p[port_id]->nb_kni; i++) {
-		if (rte_kni_release(p[port_id]->kni[i]))
-			printf("Fail to release kni\n");
-		p[port_id]->kni[i] = NULL;
-	}
-	rte_eth_dev_stop(port_id);
-
-	return 0;
-}
-
-/* Initialise ports/queues etc. and start main loop on each core */
-int
-main(int argc, char** argv)
-{
-	int ret;
-	uint16_t nb_sys_ports, port;
-	unsigned i;
-
-	/* Associate signal_hanlder function with USR signals */
-	signal(SIGUSR1, signal_handler);
-	signal(SIGUSR2, signal_handler);
-	signal(SIGRTMIN, signal_handler);
-	signal(SIGINT, signal_handler);
-
-	/* Initialise EAL */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Could not initialise EAL (%d)\n", ret);
-	argc -= ret;
-	argv += ret;
-
-	/* Parse application arguments (after the EAL ones) */
-	ret = parse_args(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Could not parse input parameters\n");
-
-	/* Create the mbuf pool */
-	pktmbuf_pool = rte_pktmbuf_pool_create("mbuf_pool", NB_MBUF,
-		MEMPOOL_CACHE_SZ, 0, MBUF_DATA_SZ, rte_socket_id());
-	if (pktmbuf_pool == NULL) {
-		rte_exit(EXIT_FAILURE, "Could not initialise mbuf pool\n");
-		return -1;
-	}
-
-	/* Get number of ports found in scan */
-	nb_sys_ports = rte_eth_dev_count();
-	if (nb_sys_ports == 0)
-		rte_exit(EXIT_FAILURE, "No supported Ethernet device found\n");
-
-	/* Check if the configured port ID is valid */
-	for (i = 0; i < RTE_MAX_ETHPORTS; i++)
-		if (kni_port_params_array[i] && !rte_eth_dev_is_valid_port(i))
-			rte_exit(EXIT_FAILURE, "Configured invalid "
-						"port ID %u\n", i);
-
-	/* Initialize KNI subsystem */
-	init_kni();
-
-	/* Initialise each port */
-	RTE_ETH_FOREACH_DEV(port) {
-		/* Skip ports that are not enabled */
-		if (!(ports_mask & (1 << port)))
-			continue;
-		init_port(port);
-
-		if (port >= RTE_MAX_ETHPORTS)
-			rte_exit(EXIT_FAILURE, "Can not use more than "
-				"%d ports for kni\n", RTE_MAX_ETHPORTS);
-
-		kni_alloc(port);
-	}
-	check_all_ports_link_status(ports_mask);
-
-	/* Launch per-lcore function on every lcore */
-	rte_eal_mp_remote_launch(main_loop, NULL, CALL_MASTER);
-	RTE_LCORE_FOREACH_SLAVE(i) {
-		if (rte_eal_wait_lcore(i) < 0)
-			return -1;
-	}
-
-	/* Release resources */
-	RTE_ETH_FOREACH_DEV(port) {
-		if (!(ports_mask & (1 << port)))
-			continue;
-		kni_free_kni(port);
-	}
-	for (i = 0; i < RTE_MAX_ETHPORTS; i++)
-		if (kni_port_params_array[i]) {
-			rte_free(kni_port_params_array[i]);
-			kni_port_params_array[i] = NULL;
-		}
-
-	return 0;
-}
diff --git a/examples/kni/meson.build b/examples/kni/meson.build
deleted file mode 100644
index bf35617..0000000
--- a/examples/kni/meson.build
+++ /dev/null
@@ -1,13 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-deps += ['kni', 'bus_pci']
-allow_experimental_apis = true
-sources = files(
-	'main.c'
-)
diff --git a/examples/l2fwd-cat/Makefile b/examples/l2fwd-cat/Makefile
deleted file mode 100644
index fe0f200..0000000
--- a/examples/l2fwd-cat/Makefile
+++ /dev/null
@@ -1,77 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2016 Intel Corporation
-
-# binary name
-APP = l2fwd-cat
-
-# all source are stored in SRCS-y
-SRCS-y := l2fwd-cat.c cat.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -D_GNU_SOURCE
-LDFLAGS += -lpqos
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else # Build using legacy build system
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-ifeq ($(PQOS_INSTALL_PATH),)
-$(error "Please define PQOS_INSTALL_PATH environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += $(WERROR_FLAGS)
-
-# workaround for a gcc bug with noreturn attribute
-# http://gcc.gnu.org/bugzilla/show_bug.cgi?id=12603
-ifeq ($(CONFIG_RTE_TOOLCHAIN_GCC),y)
-CFLAGS_main.o += -Wno-return-type
-endif
-
-EXTRA_CFLAGS += -O3 -g -Wfatal-errors
-
-CFLAGS += -I$(PQOS_INSTALL_PATH)/../include
-CFLAGS_cat.o := -D_GNU_SOURCE
-
-LDLIBS += -L$(PQOS_INSTALL_PATH)
-LDLIBS += -lpqos
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-endif
diff --git a/examples/l2fwd-cat/cat.c b/examples/l2fwd-cat/cat.c
deleted file mode 100644
index a6081e6..0000000
--- a/examples/l2fwd-cat/cat.c
+++ /dev/null
@@ -1,1032 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016 Intel Corporation
- */
-
-#include <getopt.h>
-#include <inttypes.h>
-#include <limits.h>
-#include <sched.h>
-#include <signal.h>
-#include <stdio.h>
-
-#include <rte_common.h>
-#include <rte_memcpy.h>
-
-#include <pqos.h>
-
-#include "cat.h"
-
-#define BITS_PER_HEX		4
-#define PQOS_MAX_SOCKETS	8
-#define PQOS_MAX_SOCKET_CORES	64
-#define PQOS_MAX_CORES		(PQOS_MAX_SOCKET_CORES * PQOS_MAX_SOCKETS)
-
-static const struct pqos_cap *m_cap;
-static const struct pqos_cpuinfo *m_cpu;
-static const struct pqos_capability *m_cap_l3ca;
-#if PQOS_VERSION <= 103
-static unsigned m_sockets[PQOS_MAX_SOCKETS];
-#else
-static unsigned int *m_sockets;
-#endif
-static unsigned m_sock_count;
-static struct cat_config m_config[PQOS_MAX_CORES];
-static unsigned m_config_count;
-
-static unsigned
-bits_count(uint64_t bitmask)
-{
-	unsigned count = 0;
-
-	for (; bitmask != 0; count++)
-		bitmask &= bitmask - 1;
-
-	return count;
-}
-
-/*
- * Parse elem, the elem could be single number/range or '(' ')' group
- * 1) A single number elem, it's just a simple digit. e.g. 9
- * 2) A single range elem, two digits with a '-' between. e.g. 2-6
- * 3) A group elem, combines multiple 1) or 2) with '( )'. e.g (0,2-4,6)
- *    Within group elem, '-' used for a range separator;
- *                       ',' used for a single number.
- */
-static int
-parse_set(const char *input, rte_cpuset_t *cpusetp)
-{
-	unsigned idx;
-	const char *str = input;
-	char *end = NULL;
-	unsigned min, max;
-	const unsigned num = PQOS_MAX_CORES;
-
-	CPU_ZERO(cpusetp);
-
-	while (isblank(*str))
-		str++;
-
-	/* only digit or left bracket is qualify for start point */
-	if ((!isdigit(*str) && *str != '(') || *str == '\0')
-		return -1;
-
-	/* process single number or single range of number */
-	if (*str != '(') {
-		errno = 0;
-		idx = strtoul(str, &end, 10);
-
-		if (errno || end == NULL || idx >= num)
-			return -1;
-
-		while (isblank(*end))
-			end++;
-
-		min = idx;
-		max = idx;
-		if (*end == '-') {
-			/* process single <number>-<number> */
-			end++;
-			while (isblank(*end))
-				end++;
-			if (!isdigit(*end))
-				return -1;
-
-			errno = 0;
-			idx = strtoul(end, &end, 10);
-			if (errno || end == NULL || idx >= num)
-				return -1;
-			max = idx;
-			while (isblank(*end))
-				end++;
-			if (*end != ',' && *end != '\0')
-				return -1;
-		}
-
-		if (*end != ',' && *end != '\0' && *end != '@')
-			return -1;
-
-		for (idx = RTE_MIN(min, max); idx <= RTE_MAX(min, max);
-				idx++)
-			CPU_SET(idx, cpusetp);
-
-		return end - input;
-	}
-
-	/* process set within bracket */
-	str++;
-	while (isblank(*str))
-		str++;
-	if (*str == '\0')
-		return -1;
-
-	min = PQOS_MAX_CORES;
-	do {
-
-		/* go ahead to the first digit */
-		while (isblank(*str))
-			str++;
-		if (!isdigit(*str))
-			return -1;
-
-		/* get the digit value */
-		errno = 0;
-		idx = strtoul(str, &end, 10);
-		if (errno || end == NULL || idx >= num)
-			return -1;
-
-		/* go ahead to separator '-',',' and ')' */
-		while (isblank(*end))
-			end++;
-		if (*end == '-') {
-			if (min == PQOS_MAX_CORES)
-				min = idx;
-			else /* avoid continuous '-' */
-				return -1;
-		} else if ((*end == ',') || (*end == ')')) {
-			max = idx;
-			if (min == PQOS_MAX_CORES)
-				min = idx;
-			for (idx = RTE_MIN(min, max); idx <= RTE_MAX(min, max);
-					idx++)
-				CPU_SET(idx, cpusetp);
-
-			min = PQOS_MAX_CORES;
-		} else
-			return -1;
-
-		str = end + 1;
-	} while (*end != '\0' && *end != ')');
-
-	return str - input;
-}
-
-/* Test if bitmask is contiguous */
-static int
-is_contiguous(uint64_t bitmask)
-{
-	/* check if bitmask is contiguous */
-	unsigned i = 0;
-	unsigned j = 0;
-	const unsigned max_idx = (sizeof(bitmask) * CHAR_BIT);
-
-	if (bitmask == 0)
-		return 0;
-
-	for (i = 0; i < max_idx; i++) {
-		if (((1ULL << i) & bitmask) != 0)
-			j++;
-		else if (j > 0)
-			break;
-	}
-
-	if (bits_count(bitmask) != j) {
-		printf("PQOS: mask 0x%llx is not contiguous.\n",
-			(unsigned long long)bitmask);
-		return 0;
-	}
-
-	return 1;
-}
-
-/*
- * The format pattern: --l3ca='<cbm@cpus>[,<(ccbm,dcbm)@cpus>...]'
- * cbm could be a single mask or for a CDP enabled system, a group of two masks
- * ("code cbm" and "data cbm")
- * '(' and ')' are necessary if it's a group.
- * cpus could be a single digit/range or a group.
- * '(' and ')' are necessary if it's a group.
- *
- * e.g. '0x00F00@(1,3), 0x0FF00@(4-6), 0xF0000@7'
- * - CPUs 1 and 3 share its 4 ways with CPUs 4, 5 and 6;
- * - CPUs 4,5 and 6 share half (4 out of 8 ways) of its L3 with 1 and 3;
- * - CPUs 4,5 and 6 have exclusive access to 4 out of  8 ways;
- * - CPU 7 has exclusive access to all of its 4 ways;
- *
- * e.g. '(0x00C00,0x00300)@(1,3)' for a CDP enabled system
- * - cpus 1 and 3 have access to 2 ways for code and 2 ways for data,
- *   code and data ways are not overlapping.;
- */
-static int
-parse_l3ca(const char *l3ca)
-{
-	unsigned idx = 0;
-	const char *cbm_start = NULL;
-	char *cbm_end = NULL;
-	const char *end = NULL;
-	int offset;
-	rte_cpuset_t cpuset;
-	uint64_t mask = 0;
-	uint64_t cmask = 0;
-
-	if (l3ca == NULL)
-		goto err;
-
-	/* Get cbm */
-	do {
-		CPU_ZERO(&cpuset);
-		mask = 0;
-		cmask = 0;
-
-		while (isblank(*l3ca))
-			l3ca++;
-
-		if (*l3ca == '\0')
-			goto err;
-
-		/* record mask_set start point */
-		cbm_start = l3ca;
-
-		/* go across a complete bracket */
-		if (*cbm_start == '(') {
-			l3ca += strcspn(l3ca, ")");
-			if (*l3ca++ == '\0')
-				goto err;
-		}
-
-		/* scan the separator '@', ','(next) or '\0'(finish) */
-		l3ca += strcspn(l3ca, "@,");
-
-		if (*l3ca != '@')
-			goto err;
-
-		/* explicit assign cpu_set */
-		offset = parse_set(l3ca + 1, &cpuset);
-		if (offset < 0 || CPU_COUNT(&cpuset) == 0)
-			goto err;
-
-		end = l3ca + 1 + offset;
-
-		if (*end != ',' && *end != '\0')
-			goto err;
-
-		/* parse mask_set from start point */
-		if (*cbm_start == '(') {
-			cbm_start++;
-
-			while (isblank(*cbm_start))
-				cbm_start++;
-
-			if (!isxdigit(*cbm_start))
-				goto err;
-
-			errno = 0;
-			cmask = strtoul(cbm_start, &cbm_end, 16);
-			if (errno != 0 || cbm_end == NULL || cmask == 0)
-				goto err;
-
-			while (isblank(*cbm_end))
-				cbm_end++;
-
-			if (*cbm_end != ',')
-				goto err;
-
-			cbm_end++;
-
-			while (isblank(*cbm_end))
-				cbm_end++;
-
-			if (!isxdigit(*cbm_end))
-				goto err;
-
-			errno = 0;
-			mask = strtoul(cbm_end, &cbm_end, 16);
-			if (errno != 0 || cbm_end == NULL || mask == 0)
-				goto err;
-		} else {
-			while (isblank(*cbm_start))
-				cbm_start++;
-
-			if (!isxdigit(*cbm_start))
-				goto err;
-
-			errno = 0;
-			mask = strtoul(cbm_start, &cbm_end, 16);
-			if (errno != 0 || cbm_end == NULL || mask == 0)
-				goto err;
-
-		}
-
-		if (mask == 0 || is_contiguous(mask) == 0)
-			goto err;
-
-		if (cmask != 0 && is_contiguous(cmask) == 0)
-			goto err;
-
-		rte_memcpy(&m_config[idx].cpumask,
-			&cpuset, sizeof(rte_cpuset_t));
-
-		if (cmask != 0) {
-			m_config[idx].cdp = 1;
-			m_config[idx].code_mask = cmask;
-			m_config[idx].data_mask = mask;
-		} else
-			m_config[idx].mask = mask;
-
-		m_config_count++;
-
-		l3ca = end + 1;
-		idx++;
-	} while (*end != '\0' && idx < PQOS_MAX_CORES);
-
-	return 0;
-
-err:
-	return -EINVAL;
-}
-
-static int
-check_cpus_overlapping(void)
-{
-	unsigned i = 0;
-	unsigned j = 0;
-	rte_cpuset_t mask;
-
-	CPU_ZERO(&mask);
-
-	for (i = 0; i < m_config_count; i++) {
-		for (j = i + 1; j < m_config_count; j++) {
-			CPU_AND(&mask,
-				&m_config[i].cpumask,
-				&m_config[j].cpumask);
-
-			if (CPU_COUNT(&mask) != 0) {
-				printf("PQOS: Requested CPUs sets are "
-					"overlapping.\n");
-				return -EINVAL;
-			}
-		}
-	}
-
-	return 0;
-}
-
-static int
-check_cpus(void)
-{
-	unsigned i = 0;
-	unsigned cpu_id = 0;
-	unsigned cos_id = 0;
-	int ret = 0;
-
-	for (i = 0; i < m_config_count; i++) {
-		for (cpu_id = 0; cpu_id < PQOS_MAX_CORES; cpu_id++) {
-			if (CPU_ISSET(cpu_id, &m_config[i].cpumask) != 0) {
-
-				ret = pqos_cpu_check_core(m_cpu, cpu_id);
-				if (ret != PQOS_RETVAL_OK) {
-					printf("PQOS: %u is not a valid "
-						"logical core id.\n", cpu_id);
-					ret = -ENODEV;
-					goto exit;
-				}
-
-#if PQOS_VERSION <= 103
-				ret = pqos_l3ca_assoc_get(cpu_id, &cos_id);
-#else
-				ret = pqos_alloc_assoc_get(cpu_id, &cos_id);
-#endif
-				if (ret != PQOS_RETVAL_OK) {
-					printf("PQOS: Failed to read COS "
-						"associated to cpu %u.\n",
-						cpu_id);
-					ret = -EFAULT;
-					goto exit;
-				}
-
-				/*
-				 * Check if COS assigned to lcore is different
-				 * then default one (#0)
-				 */
-				if (cos_id != 0) {
-					printf("PQOS: cpu %u has already "
-						"associated COS#%u. "
-						"Please reset L3CA.\n",
-						cpu_id, cos_id);
-					ret = -EBUSY;
-					goto exit;
-				}
-			}
-		}
-	}
-
-exit:
-	return ret;
-}
-
-static int
-check_cdp(void)
-{
-	unsigned i = 0;
-
-	for (i = 0; i < m_config_count; i++) {
-		if (m_config[i].cdp == 1 && m_cap_l3ca->u.l3ca->cdp_on == 0) {
-			if (m_cap_l3ca->u.l3ca->cdp == 0) {
-				printf("PQOS: CDP requested but not "
-					"supported.\n");
-			} else {
-				printf("PQOS: CDP requested but not enabled. "
-					"Please enable CDP.\n");
-			}
-			return -ENOTSUP;
-		}
-	}
-
-	return 0;
-}
-
-static int
-check_cbm_len_and_contention(void)
-{
-	unsigned i = 0;
-	uint64_t mask = 0;
-	const uint64_t not_cbm = (UINT64_MAX << (m_cap_l3ca->u.l3ca->num_ways));
-	const uint64_t cbm_contention_mask = m_cap_l3ca->u.l3ca->way_contention;
-	int ret = 0;
-
-	for (i = 0; i < m_config_count; i++) {
-		if (m_config[i].cdp == 1)
-			mask = m_config[i].code_mask | m_config[i].data_mask;
-		else
-			mask = m_config[i].mask;
-
-		if ((mask & not_cbm) != 0) {
-			printf("PQOS: One or more of requested CBM masks not "
-				"supported by system (too long).\n");
-			ret = -ENOTSUP;
-			break;
-		}
-
-		/* Just a warning */
-		if ((mask & cbm_contention_mask) != 0) {
-			printf("PQOS: One or more of requested CBM  masks "
-				"overlap CBM contention mask.\n");
-			break;
-		}
-
-	}
-
-	return ret;
-}
-
-static int
-check_and_select_classes(unsigned cos_id_map[][PQOS_MAX_SOCKETS])
-{
-	unsigned i = 0;
-	unsigned j = 0;
-	unsigned phy_pkg_id = 0;
-	unsigned cos_id = 0;
-	unsigned cpu_id = 0;
-	unsigned phy_pkg_lcores[PQOS_MAX_SOCKETS][m_config_count];
-	const unsigned cos_num = m_cap_l3ca->u.l3ca->num_classes;
-	unsigned used_cos_table[PQOS_MAX_SOCKETS][cos_num];
-	int ret = 0;
-
-	memset(phy_pkg_lcores, 0, sizeof(phy_pkg_lcores));
-	memset(used_cos_table, 0, sizeof(used_cos_table));
-
-	/* detect currently used COS */
-	for (j = 0; j < m_cpu->num_cores; j++) {
-		cpu_id = m_cpu->cores[j].lcore;
-
-#if PQOS_VERSION <= 103
-		ret = pqos_l3ca_assoc_get(cpu_id, &cos_id);
-#else
-		ret = pqos_alloc_assoc_get(cpu_id, &cos_id);
-#endif
-		if (ret != PQOS_RETVAL_OK) {
-			printf("PQOS: Failed to read COS associated to "
-				"cpu %u on phy_pkg %u.\n", cpu_id, phy_pkg_id);
-			ret = -EFAULT;
-			goto exit;
-		}
-
-		ret = pqos_cpu_get_socketid(m_cpu, cpu_id, &phy_pkg_id);
-		if (ret != PQOS_RETVAL_OK) {
-			printf("PQOS: Failed to get socket for cpu %u\n",
-				cpu_id);
-			ret = -EFAULT;
-			goto exit;
-		}
-
-		/* Mark COS as used */
-		if (used_cos_table[phy_pkg_id][cos_id] == 0)
-			used_cos_table[phy_pkg_id][cos_id]++;
-	}
-
-	/* look for avail. COS to fulfill requested config */
-	for (i = 0; i < m_config_count; i++) {
-		for (j = 0; j < m_cpu->num_cores; j++) {
-			cpu_id = m_cpu->cores[j].lcore;
-			if (CPU_ISSET(cpu_id, &m_config[i].cpumask) == 0)
-				continue;
-
-			ret = pqos_cpu_get_socketid(m_cpu, cpu_id, &phy_pkg_id);
-			if (ret != PQOS_RETVAL_OK) {
-				printf("PQOS: Failed to get socket for "
-					"cpu %u\n", cpu_id);
-				ret = -EFAULT;
-				goto exit;
-			}
-
-			/*
-			 * Check if we already have COS selected
-			 * to be used for that group on that socket
-			 */
-			if (phy_pkg_lcores[phy_pkg_id][i] != 0)
-				continue;
-
-			phy_pkg_lcores[phy_pkg_id][i]++;
-
-			/* Search for avail. COS to be used on that socket */
-			for (cos_id = 0; cos_id < cos_num; cos_id++) {
-				if (used_cos_table[phy_pkg_id][cos_id] == 0) {
-					used_cos_table[phy_pkg_id][cos_id]++;
-					cos_id_map[i][phy_pkg_id] = cos_id;
-					break;
-				}
-			}
-
-			/* If there is no COS available ...*/
-			if (cos_id == cos_num) {
-				ret = -E2BIG;
-				goto exit;
-			}
-		}
-	}
-
-exit:
-	if (ret != 0)
-		printf("PQOS: Not enough available COS to configure "
-			"requested configuration.\n");
-
-	return ret;
-}
-
-static int
-configure_cat(unsigned cos_id_map[][PQOS_MAX_SOCKETS])
-{
-	unsigned phy_pkg_id = 0;
-	unsigned cpu_id = 0;
-	unsigned cos_id = 0;
-	unsigned i = 0;
-	unsigned j = 0;
-	struct pqos_l3ca l3ca = {0};
-	int ret = 0;
-
-	for (i = 0; i < m_config_count; i++) {
-		memset(&l3ca, 0, sizeof(l3ca));
-
-		l3ca.cdp = m_config[i].cdp;
-		if (m_config[i].cdp == 1) {
-#if PQOS_VERSION <= 103
-			l3ca.code_mask = m_config[i].code_mask;
-			l3ca.data_mask = m_config[i].data_mask;
-#else
-			l3ca.u.s.code_mask = m_config[i].code_mask;
-			l3ca.u.s.data_mask = m_config[i].data_mask;
-#endif
-		} else
-#if PQOS_VERSION <= 103
-			l3ca.ways_mask = m_config[i].mask;
-#else
-			l3ca.u.ways_mask = m_config[i].mask;
-#endif
-
-		for (j = 0; j < m_sock_count; j++) {
-			phy_pkg_id = m_sockets[j];
-			if (cos_id_map[i][phy_pkg_id] == 0)
-				continue;
-
-			l3ca.class_id = cos_id_map[i][phy_pkg_id];
-
-			ret = pqos_l3ca_set(phy_pkg_id, 1, &l3ca);
-			if (ret != PQOS_RETVAL_OK) {
-				printf("PQOS: Failed to set COS %u on "
-					"phy_pkg %u.\n", l3ca.class_id,
-					phy_pkg_id);
-				ret = -EFAULT;
-				goto exit;
-			}
-		}
-	}
-
-	for (i = 0; i < m_config_count; i++) {
-		for (j = 0; j < m_cpu->num_cores; j++) {
-			cpu_id = m_cpu->cores[j].lcore;
-			if (CPU_ISSET(cpu_id, &m_config[i].cpumask) == 0)
-				continue;
-
-			ret = pqos_cpu_get_socketid(m_cpu, cpu_id, &phy_pkg_id);
-			if (ret != PQOS_RETVAL_OK) {
-				printf("PQOS: Failed to get socket for "
-					"cpu %u\n", cpu_id);
-				ret = -EFAULT;
-				goto exit;
-			}
-
-			cos_id = cos_id_map[i][phy_pkg_id];
-
-#if PQOS_VERSION <= 103
-			ret = pqos_l3ca_assoc_set(cpu_id, cos_id);
-#else
-			ret = pqos_alloc_assoc_set(cpu_id, cos_id);
-#endif
-			if (ret != PQOS_RETVAL_OK) {
-				printf("PQOS: Failed to associate COS %u to "
-					"cpu %u\n", cos_id, cpu_id);
-				ret = -EFAULT;
-				goto exit;
-			}
-		}
-	}
-
-exit:
-	return ret;
-}
-
-
-/* Parse the argument given in the command line of the application */
-static int
-parse_args(int argc, char **argv)
-{
-	int opt = 0;
-	int retval = 0;
-	int oldopterr = 0;
-	char **argvopt = argv;
-	char *prgname = argv[0];
-
-	static struct option lgopts[] = {
-		{ "l3ca", required_argument, 0, 0 },
-		{ NULL, 0, 0, 0 }
-	};
-
-	/* Disable printing messages within getopt() */
-	oldopterr = opterr;
-	opterr = 0;
-
-	opt = getopt_long(argc, argvopt, "", lgopts, NULL);
-	if (opt == 0) {
-		retval = parse_l3ca(optarg);
-		if (retval != 0) {
-			printf("PQOS: Invalid L3CA parameters!\n");
-			goto exit;
-		}
-
-		argv[optind - 1] = prgname;
-		retval = optind - 1;
-	} else
-		retval = 0;
-
-exit:
-	/* reset getopt lib */
-	optind = 1;
-
-	/* Restore opterr value */
-	opterr = oldopterr;
-
-	return retval;
-}
-
-static void
-print_cmd_line_config(void)
-{
-	char cpustr[PQOS_MAX_CORES * 3] = {0};
-	unsigned i = 0;
-	unsigned j = 0;
-
-	for (i = 0; i < m_config_count; i++) {
-		unsigned len = 0;
-		memset(cpustr, 0, sizeof(cpustr));
-
-		/* Generate CPU list */
-		for (j = 0; j < PQOS_MAX_CORES; j++) {
-			if (CPU_ISSET(j, &m_config[i].cpumask) != 1)
-				continue;
-
-			len += snprintf(cpustr + len, sizeof(cpustr) - len - 1,
-				"%u,", j);
-
-			if (len >= sizeof(cpustr) - 1)
-				break;
-		}
-
-		if (m_config[i].cdp == 1) {
-			printf("PQOS: CPUs: %s cMASK: 0x%llx, dMASK: "
-				"0x%llx\n", cpustr,
-				(unsigned long long)m_config[i].code_mask,
-				(unsigned long long)m_config[i].data_mask);
-		} else {
-			printf("PQOS: CPUs: %s MASK: 0x%llx\n", cpustr,
-					(unsigned long long)m_config[i].mask);
-		}
-	}
-}
-
-/**
- * @brief Prints CAT configuration
- */
-static void
-print_cat_config(void)
-{
-	int ret = PQOS_RETVAL_OK;
-	unsigned i = 0;
-
-	for (i = 0; i < m_sock_count; i++) {
-		struct pqos_l3ca tab[PQOS_MAX_L3CA_COS] = {{0} };
-		unsigned num = 0;
-		unsigned n = 0;
-
-		ret = pqos_l3ca_get(m_sockets[i], PQOS_MAX_L3CA_COS, &num, tab);
-		if (ret != PQOS_RETVAL_OK) {
-			printf("PQOS: Error retrieving COS!\n");
-			return;
-		}
-
-		printf("PQOS: COS definitions for Socket %u:\n", m_sockets[i]);
-		for (n = 0; n < num; n++) {
-			if (tab[n].cdp == 1) {
-				printf("PQOS: COS: %u, cMASK: 0x%llx, "
-					"dMASK: 0x%llx\n", tab[n].class_id,
-#if PQOS_VERSION <= 103
-					(unsigned long long)tab[n].code_mask,
-					(unsigned long long)tab[n].data_mask);
-#else
-					(unsigned long long)tab[n].u.s.code_mask,
-					(unsigned long long)tab[n].u.s.data_mask);
-#endif
-			} else {
-				printf("PQOS: COS: %u, MASK: 0x%llx\n",
-					tab[n].class_id,
-#if PQOS_VERSION <= 103
-					(unsigned long long)tab[n].ways_mask);
-#else
-					(unsigned long long)tab[n].u.ways_mask);
-#endif
-			}
-		}
-	}
-
-	for (i = 0; i < m_sock_count; i++) {
-#if PQOS_VERSION <= 103
-		unsigned lcores[PQOS_MAX_SOCKET_CORES] = {0};
-#else
-		unsigned int *lcores = NULL;
-#endif
-		unsigned lcount = 0;
-		unsigned n = 0;
-
-#if PQOS_VERSION <= 103
-		ret = pqos_cpu_get_cores(m_cpu, m_sockets[i],
-				PQOS_MAX_SOCKET_CORES, &lcount, &lcores[0]);
-		if (ret != PQOS_RETVAL_OK) {
-#else
-		lcores = pqos_cpu_get_cores(m_cpu, m_sockets[i],
-				&lcount);
-		if (lcores == NULL || lcount == 0) {
-#endif
-			printf("PQOS: Error retrieving core information!\n");
-			return;
-		}
-
-		printf("PQOS: CPU information for socket %u:\n", m_sockets[i]);
-		for (n = 0; n < lcount; n++) {
-			unsigned class_id = 0;
-
-#if PQOS_VERSION <= 103
-			ret = pqos_l3ca_assoc_get(lcores[n], &class_id);
-#else
-			ret = pqos_alloc_assoc_get(lcores[n], &class_id);
-#endif
-			if (ret == PQOS_RETVAL_OK)
-				printf("PQOS: CPU: %u, COS: %u\n", lcores[n],
-					class_id);
-			else
-				printf("PQOS: CPU: %u, ERROR\n", lcores[n]);
-		}
-
-#if PQOS_VERSION > 103
-		free(lcores);
-#endif
-	}
-
-}
-
-static int
-cat_validate(void)
-{
-	int ret = 0;
-
-	ret = check_cpus();
-	if (ret != 0)
-		return ret;
-
-	ret = check_cdp();
-	if (ret != 0)
-		return ret;
-
-	ret = check_cbm_len_and_contention();
-	if (ret != 0)
-		return ret;
-
-	ret = check_cpus_overlapping();
-	if (ret != 0)
-		return ret;
-
-	return 0;
-}
-
-static int
-cat_set(void)
-{
-	int ret = 0;
-	unsigned cos_id_map[m_config_count][PQOS_MAX_SOCKETS];
-
-	memset(cos_id_map, 0, sizeof(cos_id_map));
-
-	ret = check_and_select_classes(cos_id_map);
-	if (ret != 0)
-		return ret;
-
-	ret = configure_cat(cos_id_map);
-	if (ret != 0)
-		return ret;
-
-	return 0;
-}
-
-static void
-cat_fini(void)
-{
-	int ret = 0;
-
-	printf("PQOS: Shutting down PQoS library...\n");
-
-	/* deallocate all the resources */
-	ret = pqos_fini();
-	if (ret != PQOS_RETVAL_OK && ret != PQOS_RETVAL_INIT)
-		printf("PQOS: Error shutting down PQoS library!\n");
-
-	m_cap = NULL;
-	m_cpu = NULL;
-	m_cap_l3ca = NULL;
-#if PQOS_VERSION <= 103
-	memset(m_sockets, 0, sizeof(m_sockets));
-#else
-	if (m_sockets != NULL)
-		free(m_sockets);
-#endif
-	m_sock_count = 0;
-	memset(m_config, 0, sizeof(m_config));
-	m_config_count = 0;
-}
-
-void
-cat_exit(void)
-{
-	unsigned i = 0;
-	unsigned j = 0;
-	unsigned cpu_id = 0;
-	int ret = 0;
-
-	/* if lib is not initialized, do nothing */
-	if (m_cap == NULL && m_cpu == NULL)
-		return;
-
-	printf("PQOS: Reverting CAT configuration...\n");
-
-	for (i = 0; i < m_config_count; i++) {
-		for (j = 0; j < m_cpu->num_cores; j++) {
-			cpu_id = m_cpu->cores[j].lcore;
-			if (CPU_ISSET(cpu_id, &m_config[i].cpumask) == 0)
-				continue;
-
-#if PQOS_VERSION <= 103
-			ret = pqos_l3ca_assoc_set(cpu_id, 0);
-#else
-			ret = pqos_alloc_assoc_set(cpu_id, 0);
-#endif
-			if (ret != PQOS_RETVAL_OK) {
-				printf("PQOS: Failed to associate COS 0 to "
-					"cpu %u\n", cpu_id);
-			}
-		}
-	}
-
-	cat_fini();
-}
-
-static void
-signal_handler(int signum)
-{
-	if (signum == SIGINT || signum == SIGTERM) {
-		printf("\nPQOS: Signal %d received, preparing to exit...\n",
-				signum);
-
-		cat_exit();
-
-		/* exit with the expected status */
-		signal(signum, SIG_DFL);
-		kill(getpid(), signum);
-	}
-}
-
-int
-cat_init(int argc, char **argv)
-{
-	int ret = 0;
-	int args_num = 0;
-	struct pqos_config cfg = {0};
-
-	if (m_cap != NULL || m_cpu != NULL) {
-		printf("PQOS: CAT module already initialized!\n");
-		return -EEXIST;
-	}
-
-	/* Parse cmd line args */
-	ret = parse_args(argc, argv);
-
-	if (ret <= 0)
-		goto err;
-
-	args_num = ret;
-
-	/* Print cmd line configuration */
-	print_cmd_line_config();
-
-	/* PQoS Initialization - Check and initialize CAT capability */
-	cfg.fd_log = STDOUT_FILENO;
-	cfg.verbose = 0;
-#if PQOS_VERSION <= 103
-	cfg.cdp_cfg = PQOS_REQUIRE_CDP_ANY;
-#endif
-	ret = pqos_init(&cfg);
-	if (ret != PQOS_RETVAL_OK) {
-		printf("PQOS: Error initializing PQoS library!\n");
-		ret = -EFAULT;
-		goto err;
-	}
-
-	/* Get capability and CPU info pointer */
-	ret = pqos_cap_get(&m_cap, &m_cpu);
-	if (ret != PQOS_RETVAL_OK || m_cap == NULL || m_cpu == NULL) {
-		printf("PQOS: Error retrieving PQoS capabilities!\n");
-		ret = -EFAULT;
-		goto err;
-	}
-
-	/* Get L3CA capabilities */
-	ret = pqos_cap_get_type(m_cap, PQOS_CAP_TYPE_L3CA, &m_cap_l3ca);
-	if (ret != PQOS_RETVAL_OK || m_cap_l3ca == NULL) {
-		printf("PQOS: Error retrieving PQOS_CAP_TYPE_L3CA "
-			"capabilities!\n");
-		ret = -EFAULT;
-		goto err;
-	}
-
-	/* Get CPU socket information */
-#if PQOS_VERSION <= 103
-	ret = pqos_cpu_get_sockets(m_cpu, PQOS_MAX_SOCKETS, &m_sock_count,
-		m_sockets);
-	if (ret != PQOS_RETVAL_OK) {
-#else
-	m_sockets = pqos_cpu_get_sockets(m_cpu, &m_sock_count);
-	if (m_sockets == NULL) {
-#endif
-		printf("PQOS: Error retrieving CPU socket information!\n");
-		ret = -EFAULT;
-		goto err;
-	}
-
-	/* Validate cmd line configuration */
-	ret = cat_validate();
-	if (ret != 0) {
-		printf("PQOS: Requested CAT configuration is not valid!\n");
-		goto err;
-	}
-
-	/* configure system */
-	ret = cat_set();
-	if (ret != 0) {
-		printf("PQOS: Failed to configure CAT!\n");
-		goto err;
-	}
-
-	signal(SIGINT, signal_handler);
-	signal(SIGTERM, signal_handler);
-
-	ret = atexit(cat_exit);
-	if (ret != 0) {
-		printf("PQOS: Cannot set exit function\n");
-		goto err;
-	}
-
-	/* Print CAT configuration */
-	print_cat_config();
-
-	return args_num;
-
-err:
-	/* deallocate all the resources */
-	cat_fini();
-	return ret;
-}
diff --git a/examples/l2fwd-cat/cat.h b/examples/l2fwd-cat/cat.h
deleted file mode 100644
index 1eb0543..0000000
--- a/examples/l2fwd-cat/cat.h
+++ /dev/null
@@ -1,43 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016 Intel Corporation
- */
-
-#ifndef _CAT_H
-#define _CAT_H
-
-/**
- * @file
- * PQoS CAT
- */
-
-#include <stdint.h>
-#include <string.h>
-
-#include <rte_lcore.h>
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-/* L3 cache allocation class of service data structure */
-struct cat_config {
-	rte_cpuset_t cpumask;		/* CPUs bitmask */
-	int cdp;			/* data & code masks used if true */
-	union {
-		uint64_t mask;		/* capacity bitmask (CBM) */
-		struct {
-			uint64_t data_mask; /* data capacity bitmask (CBM) */
-			uint64_t code_mask; /* code capacity bitmask (CBM) */
-		};
-	};
-};
-
-int cat_init(int argc, char **argv);
-
-void cat_exit(void);
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif /* _CAT_H */
diff --git a/examples/l2fwd-cat/l2fwd-cat.c b/examples/l2fwd-cat/l2fwd-cat.c
deleted file mode 100644
index ed48780..0000000
--- a/examples/l2fwd-cat/l2fwd-cat.c
+++ /dev/null
@@ -1,200 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016 Intel Corporation
- */
-
-#include <stdint.h>
-#include <inttypes.h>
-#include <rte_eal.h>
-#include <rte_ethdev.h>
-#include <rte_cycles.h>
-#include <rte_lcore.h>
-#include <rte_mbuf.h>
-
-#include "cat.h"
-
-#define RX_RING_SIZE 128
-#define TX_RING_SIZE 512
-
-#define NUM_MBUFS 8191
-#define MBUF_CACHE_SIZE 250
-#define BURST_SIZE 32
-
-static const struct rte_eth_conf port_conf_default = {
-	.rxmode = { .max_rx_pkt_len = ETHER_MAX_LEN }
-};
-
-/* l2fwd-cat.c: CAT enabled, basic DPDK skeleton forwarding example. */
-
-/*
- * Initializes a given port using global settings and with the RX buffers
- * coming from the mbuf_pool passed as a parameter.
- */
-static inline int
-port_init(uint16_t port, struct rte_mempool *mbuf_pool)
-{
-	struct rte_eth_conf port_conf = port_conf_default;
-	const uint16_t rx_rings = 1, tx_rings = 1;
-	int retval;
-	uint16_t q;
-	uint16_t nb_rxd = RX_RING_SIZE;
-	uint16_t nb_txd = TX_RING_SIZE;
-
-	if (!rte_eth_dev_is_valid_port(port))
-		return -1;
-
-	/* Configure the Ethernet device. */
-	retval = rte_eth_dev_configure(port, rx_rings, tx_rings, &port_conf);
-	if (retval != 0)
-		return retval;
-
-	retval = rte_eth_dev_adjust_nb_rx_tx_desc(port, &nb_rxd, &nb_txd);
-	if (retval != 0)
-		return retval;
-
-	/* Allocate and set up 1 RX queue per Ethernet port. */
-	for (q = 0; q < rx_rings; q++) {
-		retval = rte_eth_rx_queue_setup(port, q, nb_rxd,
-				rte_eth_dev_socket_id(port), NULL, mbuf_pool);
-		if (retval < 0)
-			return retval;
-	}
-
-	/* Allocate and set up 1 TX queue per Ethernet port. */
-	for (q = 0; q < tx_rings; q++) {
-		retval = rte_eth_tx_queue_setup(port, q, nb_txd,
-				rte_eth_dev_socket_id(port), NULL);
-		if (retval < 0)
-			return retval;
-	}
-
-	/* Start the Ethernet port. */
-	retval = rte_eth_dev_start(port);
-	if (retval < 0)
-		return retval;
-
-	/* Display the port MAC address. */
-	struct ether_addr addr;
-	rte_eth_macaddr_get(port, &addr);
-	printf("Port %u MAC: %02" PRIx8 " %02" PRIx8 " %02" PRIx8
-			   " %02" PRIx8 " %02" PRIx8 " %02" PRIx8 "\n",
-			port,
-			addr.addr_bytes[0], addr.addr_bytes[1],
-			addr.addr_bytes[2], addr.addr_bytes[3],
-			addr.addr_bytes[4], addr.addr_bytes[5]);
-
-	/* Enable RX in promiscuous mode for the Ethernet device. */
-	rte_eth_promiscuous_enable(port);
-
-	return 0;
-}
-
-/*
- * The lcore main. This is the main thread that does the work, reading from
- * an input port and writing to an output port.
- */
-static __attribute__((noreturn)) void
-lcore_main(void)
-{
-	uint16_t port;
-
-	/*
-	 * Check that the port is on the same NUMA node as the polling thread
-	 * for best performance.
-	 */
-	RTE_ETH_FOREACH_DEV(port)
-		if (rte_eth_dev_socket_id(port) > 0 &&
-				rte_eth_dev_socket_id(port) !=
-						(int)rte_socket_id())
-			printf("WARNING, port %u is on remote NUMA node to "
-					"polling thread.\n\tPerformance will "
-					"not be optimal.\n", port);
-
-	printf("\nCore %u forwarding packets. [Ctrl+C to quit]\n",
-			rte_lcore_id());
-
-	/* Run until the application is quit or killed. */
-	for (;;) {
-		/*
-		 * Receive packets on a port and forward them on the paired
-		 * port. The mapping is 0 -> 1, 1 -> 0, 2 -> 3, 3 -> 2, etc.
-		 */
-		RTE_ETH_FOREACH_DEV(port) {
-
-			/* Get burst of RX packets, from first port of pair. */
-			struct rte_mbuf *bufs[BURST_SIZE];
-			const uint16_t nb_rx = rte_eth_rx_burst(port, 0,
-					bufs, BURST_SIZE);
-
-			if (unlikely(nb_rx == 0))
-				continue;
-
-			/* Send burst of TX packets, to second port of pair. */
-			const uint16_t nb_tx = rte_eth_tx_burst(port ^ 1, 0,
-					bufs, nb_rx);
-
-			/* Free any unsent packets. */
-			if (unlikely(nb_tx < nb_rx)) {
-				uint16_t buf;
-				for (buf = nb_tx; buf < nb_rx; buf++)
-					rte_pktmbuf_free(bufs[buf]);
-			}
-		}
-	}
-}
-
-/*
- * The main function, which does initialization and calls the per-lcore
- * functions.
- */
-int
-main(int argc, char *argv[])
-{
-	struct rte_mempool *mbuf_pool;
-	unsigned nb_ports;
-	uint16_t portid;
-
-	/* Initialize the Environment Abstraction Layer (EAL). */
-	int ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Error with EAL initialization\n");
-
-	argc -= ret;
-	argv += ret;
-
-	/*
-	 * Initialize the PQoS library and configure CAT.
-	 * Please see l2fwd-cat documentation for more info.
-	 */
-	ret = cat_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "PQOS: L3CA init failed!\n");
-
-	argc -= ret;
-	argv += ret;
-
-	/* Check that there is an even number of ports to send/receive on. */
-	nb_ports = rte_eth_dev_count();
-	if (nb_ports < 2 || (nb_ports & 1))
-		rte_exit(EXIT_FAILURE, "Error: number of ports must be even\n");
-
-	/* Creates a new mempool in memory to hold the mbufs. */
-	mbuf_pool = rte_pktmbuf_pool_create("MBUF_POOL", NUM_MBUFS * nb_ports,
-		MBUF_CACHE_SIZE, 0, RTE_MBUF_DEFAULT_BUF_SIZE, rte_socket_id());
-
-	if (mbuf_pool == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot create mbuf pool\n");
-
-	/* Initialize all ports. */
-	RTE_ETH_FOREACH_DEV(portid)
-		if (port_init(portid, mbuf_pool) != 0)
-			rte_exit(EXIT_FAILURE, "Cannot init port %"PRIu16 "\n",
-					portid);
-
-	if (rte_lcore_count() > 1)
-		printf("\nWARNING: Too many lcores enabled. Only 1 used.\n");
-
-	/* Call lcore_main on the master core only. */
-	lcore_main();
-
-	return 0;
-}
diff --git a/examples/l2fwd-cat/meson.build b/examples/l2fwd-cat/meson.build
deleted file mode 100644
index 29e5d0c..0000000
--- a/examples/l2fwd-cat/meson.build
+++ /dev/null
@@ -1,15 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-ext_deps += cc.find_library('pqos')
-allow_experimental_apis = true
-cflags += '-D_GNU_SOURCE'
-cflags += '-I/usr/local/include' # assume pqos lib installed in /usr/local
-sources = files(
-	'cat.c', 'l2fwd-cat.c'
-)
diff --git a/examples/l2fwd-crypto/Makefile b/examples/l2fwd-crypto/Makefile
deleted file mode 100644
index 99afdd2..0000000
--- a/examples/l2fwd-crypto/Makefile
+++ /dev/null
@@ -1,58 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-# binary name
-APP = l2fwd-crypto
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else # Build using legacy build system
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-endif
diff --git a/examples/l2fwd-crypto/main.c b/examples/l2fwd-crypto/main.c
deleted file mode 100644
index 2fcc339..0000000
--- a/examples/l2fwd-crypto/main.c
+++ /dev/null
@@ -1,2617 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2015-2016 Intel Corporation
- */
-
-#include <time.h>
-#include <stdio.h>
-#include <stdlib.h>
-#include <string.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <sys/types.h>
-#include <sys/queue.h>
-#include <netinet/in.h>
-#include <setjmp.h>
-#include <stdarg.h>
-#include <ctype.h>
-#include <errno.h>
-#include <getopt.h>
-#include <fcntl.h>
-#include <unistd.h>
-
-#include <rte_atomic.h>
-#include <rte_branch_prediction.h>
-#include <rte_common.h>
-#include <rte_cryptodev.h>
-#include <rte_cycles.h>
-#include <rte_debug.h>
-#include <rte_eal.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_interrupts.h>
-#include <rte_ip.h>
-#include <rte_launch.h>
-#include <rte_lcore.h>
-#include <rte_log.h>
-#include <rte_malloc.h>
-#include <rte_mbuf.h>
-#include <rte_memcpy.h>
-#include <rte_memory.h>
-#include <rte_mempool.h>
-#include <rte_per_lcore.h>
-#include <rte_prefetch.h>
-#include <rte_random.h>
-#include <rte_hexdump.h>
-
-enum cdev_type {
-	CDEV_TYPE_ANY,
-	CDEV_TYPE_HW,
-	CDEV_TYPE_SW
-};
-
-#define RTE_LOGTYPE_L2FWD RTE_LOGTYPE_USER1
-
-#define NB_MBUF   8192
-
-#define MAX_STR_LEN 32
-#define MAX_KEY_SIZE 128
-#define MAX_IV_SIZE 16
-#define MAX_AAD_SIZE 65535
-#define MAX_PKT_BURST 32
-#define BURST_TX_DRAIN_US 100 /* TX drain every ~100us */
-#define MAX_SESSIONS 32
-#define SESSION_POOL_CACHE_SIZE 0
-
-#define MAXIMUM_IV_LENGTH	16
-#define IV_OFFSET		(sizeof(struct rte_crypto_op) + \
-				sizeof(struct rte_crypto_sym_op))
-
-/*
- * Configurable number of RX/TX ring descriptors
- */
-#define RTE_TEST_RX_DESC_DEFAULT 1024
-#define RTE_TEST_TX_DESC_DEFAULT 1024
-
-static uint16_t nb_rxd = RTE_TEST_RX_DESC_DEFAULT;
-static uint16_t nb_txd = RTE_TEST_TX_DESC_DEFAULT;
-
-/* ethernet addresses of ports */
-static struct ether_addr l2fwd_ports_eth_addr[RTE_MAX_ETHPORTS];
-
-/* mask of enabled ports */
-static uint64_t l2fwd_enabled_port_mask;
-static uint64_t l2fwd_enabled_crypto_mask;
-
-/* list of enabled ports */
-static uint16_t l2fwd_dst_ports[RTE_MAX_ETHPORTS];
-
-
-struct pkt_buffer {
-	unsigned len;
-	struct rte_mbuf *buffer[MAX_PKT_BURST];
-};
-
-struct op_buffer {
-	unsigned len;
-	struct rte_crypto_op *buffer[MAX_PKT_BURST];
-};
-
-#define MAX_RX_QUEUE_PER_LCORE 16
-#define MAX_TX_QUEUE_PER_PORT 16
-
-enum l2fwd_crypto_xform_chain {
-	L2FWD_CRYPTO_CIPHER_HASH,
-	L2FWD_CRYPTO_HASH_CIPHER,
-	L2FWD_CRYPTO_CIPHER_ONLY,
-	L2FWD_CRYPTO_HASH_ONLY,
-	L2FWD_CRYPTO_AEAD
-};
-
-struct l2fwd_key {
-	uint8_t *data;
-	uint32_t length;
-	rte_iova_t phys_addr;
-};
-
-struct l2fwd_iv {
-	uint8_t *data;
-	uint16_t length;
-};
-
-/** l2fwd crypto application command line options */
-struct l2fwd_crypto_options {
-	unsigned portmask;
-	unsigned nb_ports_per_lcore;
-	unsigned refresh_period;
-	unsigned single_lcore:1;
-
-	enum cdev_type type;
-	unsigned sessionless:1;
-
-	enum l2fwd_crypto_xform_chain xform_chain;
-
-	struct rte_crypto_sym_xform cipher_xform;
-	unsigned ckey_param;
-	int ckey_random_size;
-
-	struct l2fwd_iv cipher_iv;
-	unsigned int cipher_iv_param;
-	int cipher_iv_random_size;
-
-	struct rte_crypto_sym_xform auth_xform;
-	uint8_t akey_param;
-	int akey_random_size;
-
-	struct l2fwd_iv auth_iv;
-	unsigned int auth_iv_param;
-	int auth_iv_random_size;
-
-	struct rte_crypto_sym_xform aead_xform;
-	unsigned int aead_key_param;
-	int aead_key_random_size;
-
-	struct l2fwd_iv aead_iv;
-	unsigned int aead_iv_param;
-	int aead_iv_random_size;
-
-	struct l2fwd_key aad;
-	unsigned aad_param;
-	int aad_random_size;
-
-	int digest_size;
-
-	uint16_t block_size;
-	char string_type[MAX_STR_LEN];
-
-	uint64_t cryptodev_mask;
-
-	unsigned int mac_updating;
-};
-
-/** l2fwd crypto lcore params */
-struct l2fwd_crypto_params {
-	uint8_t dev_id;
-	uint8_t qp_id;
-
-	unsigned digest_length;
-	unsigned block_size;
-
-	struct l2fwd_iv cipher_iv;
-	struct l2fwd_iv auth_iv;
-	struct l2fwd_iv aead_iv;
-	struct l2fwd_key aad;
-	struct rte_cryptodev_sym_session *session;
-
-	uint8_t do_cipher;
-	uint8_t do_hash;
-	uint8_t do_aead;
-	uint8_t hash_verify;
-
-	enum rte_crypto_cipher_algorithm cipher_algo;
-	enum rte_crypto_auth_algorithm auth_algo;
-	enum rte_crypto_aead_algorithm aead_algo;
-};
-
-/** lcore configuration */
-struct lcore_queue_conf {
-	unsigned nb_rx_ports;
-	uint16_t rx_port_list[MAX_RX_QUEUE_PER_LCORE];
-
-	unsigned nb_crypto_devs;
-	unsigned cryptodev_list[MAX_RX_QUEUE_PER_LCORE];
-
-	struct op_buffer op_buf[RTE_CRYPTO_MAX_DEVS];
-	struct pkt_buffer pkt_buf[RTE_MAX_ETHPORTS];
-} __rte_cache_aligned;
-
-struct lcore_queue_conf lcore_queue_conf[RTE_MAX_LCORE];
-
-static struct rte_eth_conf port_conf = {
-	.rxmode = {
-		.mq_mode = ETH_MQ_RX_NONE,
-		.max_rx_pkt_len = ETHER_MAX_LEN,
-		.split_hdr_size = 0,
-		.ignore_offload_bitfield = 1,
-		.offloads = DEV_RX_OFFLOAD_CRC_STRIP,
-	},
-	.txmode = {
-		.mq_mode = ETH_MQ_TX_NONE,
-	},
-};
-
-struct rte_mempool *l2fwd_pktmbuf_pool;
-struct rte_mempool *l2fwd_crypto_op_pool;
-struct rte_mempool *session_pool_socket[RTE_MAX_NUMA_NODES] = { 0 };
-
-/* Per-port statistics struct */
-struct l2fwd_port_statistics {
-	uint64_t tx;
-	uint64_t rx;
-
-	uint64_t crypto_enqueued;
-	uint64_t crypto_dequeued;
-
-	uint64_t dropped;
-} __rte_cache_aligned;
-
-struct l2fwd_crypto_statistics {
-	uint64_t enqueued;
-	uint64_t dequeued;
-
-	uint64_t errors;
-} __rte_cache_aligned;
-
-struct l2fwd_port_statistics port_statistics[RTE_MAX_ETHPORTS];
-struct l2fwd_crypto_statistics crypto_statistics[RTE_CRYPTO_MAX_DEVS];
-
-/* A tsc-based timer responsible for triggering statistics printout */
-#define TIMER_MILLISECOND 2000000ULL /* around 1ms at 2 Ghz */
-#define MAX_TIMER_PERIOD 86400UL /* 1 day max */
-
-/* default period is 10 seconds */
-static int64_t timer_period = 10 * TIMER_MILLISECOND * 1000;
-
-/* Print out statistics on packets dropped */
-static void
-print_stats(void)
-{
-	uint64_t total_packets_dropped, total_packets_tx, total_packets_rx;
-	uint64_t total_packets_enqueued, total_packets_dequeued,
-		total_packets_errors;
-	uint16_t portid;
-	uint64_t cdevid;
-
-	total_packets_dropped = 0;
-	total_packets_tx = 0;
-	total_packets_rx = 0;
-	total_packets_enqueued = 0;
-	total_packets_dequeued = 0;
-	total_packets_errors = 0;
-
-	const char clr[] = { 27, '[', '2', 'J', '\0' };
-	const char topLeft[] = { 27, '[', '1', ';', '1', 'H', '\0' };
-
-		/* Clear screen and move to top left */
-	printf("%s%s", clr, topLeft);
-
-	printf("\nPort statistics ====================================");
-
-	for (portid = 0; portid < RTE_MAX_ETHPORTS; portid++) {
-		/* skip disabled ports */
-		if ((l2fwd_enabled_port_mask & (1 << portid)) == 0)
-			continue;
-		printf("\nStatistics for port %u ------------------------------"
-			   "\nPackets sent: %32"PRIu64
-			   "\nPackets received: %28"PRIu64
-			   "\nPackets dropped: %29"PRIu64,
-			   portid,
-			   port_statistics[portid].tx,
-			   port_statistics[portid].rx,
-			   port_statistics[portid].dropped);
-
-		total_packets_dropped += port_statistics[portid].dropped;
-		total_packets_tx += port_statistics[portid].tx;
-		total_packets_rx += port_statistics[portid].rx;
-	}
-	printf("\nCrypto statistics ==================================");
-
-	for (cdevid = 0; cdevid < RTE_CRYPTO_MAX_DEVS; cdevid++) {
-		/* skip disabled ports */
-		if ((l2fwd_enabled_crypto_mask & (((uint64_t)1) << cdevid)) == 0)
-			continue;
-		printf("\nStatistics for cryptodev %"PRIu64
-				" -------------------------"
-			   "\nPackets enqueued: %28"PRIu64
-			   "\nPackets dequeued: %28"PRIu64
-			   "\nPackets errors: %30"PRIu64,
-			   cdevid,
-			   crypto_statistics[cdevid].enqueued,
-			   crypto_statistics[cdevid].dequeued,
-			   crypto_statistics[cdevid].errors);
-
-		total_packets_enqueued += crypto_statistics[cdevid].enqueued;
-		total_packets_dequeued += crypto_statistics[cdevid].dequeued;
-		total_packets_errors += crypto_statistics[cdevid].errors;
-	}
-	printf("\nAggregate statistics ==============================="
-		   "\nTotal packets received: %22"PRIu64
-		   "\nTotal packets enqueued: %22"PRIu64
-		   "\nTotal packets dequeued: %22"PRIu64
-		   "\nTotal packets sent: %26"PRIu64
-		   "\nTotal packets dropped: %23"PRIu64
-		   "\nTotal packets crypto errors: %17"PRIu64,
-		   total_packets_rx,
-		   total_packets_enqueued,
-		   total_packets_dequeued,
-		   total_packets_tx,
-		   total_packets_dropped,
-		   total_packets_errors);
-	printf("\n====================================================\n");
-}
-
-static int
-l2fwd_crypto_send_burst(struct lcore_queue_conf *qconf, unsigned n,
-		struct l2fwd_crypto_params *cparams)
-{
-	struct rte_crypto_op **op_buffer;
-	unsigned ret;
-
-	op_buffer = (struct rte_crypto_op **)
-			qconf->op_buf[cparams->dev_id].buffer;
-
-	ret = rte_cryptodev_enqueue_burst(cparams->dev_id,
-			cparams->qp_id,	op_buffer, (uint16_t) n);
-
-	crypto_statistics[cparams->dev_id].enqueued += ret;
-	if (unlikely(ret < n)) {
-		crypto_statistics[cparams->dev_id].errors += (n - ret);
-		do {
-			rte_pktmbuf_free(op_buffer[ret]->sym->m_src);
-			rte_crypto_op_free(op_buffer[ret]);
-		} while (++ret < n);
-	}
-
-	return 0;
-}
-
-static int
-l2fwd_crypto_enqueue(struct rte_crypto_op *op,
-		struct l2fwd_crypto_params *cparams)
-{
-	unsigned lcore_id, len;
-	struct lcore_queue_conf *qconf;
-
-	lcore_id = rte_lcore_id();
-
-	qconf = &lcore_queue_conf[lcore_id];
-	len = qconf->op_buf[cparams->dev_id].len;
-	qconf->op_buf[cparams->dev_id].buffer[len] = op;
-	len++;
-
-	/* enough ops to be sent */
-	if (len == MAX_PKT_BURST) {
-		l2fwd_crypto_send_burst(qconf, MAX_PKT_BURST, cparams);
-		len = 0;
-	}
-
-	qconf->op_buf[cparams->dev_id].len = len;
-	return 0;
-}
-
-static int
-l2fwd_simple_crypto_enqueue(struct rte_mbuf *m,
-		struct rte_crypto_op *op,
-		struct l2fwd_crypto_params *cparams)
-{
-	struct ether_hdr *eth_hdr;
-	struct ipv4_hdr *ip_hdr;
-
-	uint32_t ipdata_offset, data_len;
-	uint32_t pad_len = 0;
-	char *padding;
-
-	eth_hdr = rte_pktmbuf_mtod(m, struct ether_hdr *);
-
-	if (eth_hdr->ether_type != rte_cpu_to_be_16(ETHER_TYPE_IPv4))
-		return -1;
-
-	ipdata_offset = sizeof(struct ether_hdr);
-
-	ip_hdr = (struct ipv4_hdr *)(rte_pktmbuf_mtod(m, char *) +
-			ipdata_offset);
-
-	ipdata_offset += (ip_hdr->version_ihl & IPV4_HDR_IHL_MASK)
-			* IPV4_IHL_MULTIPLIER;
-
-
-	/* Zero pad data to be crypto'd so it is block aligned */
-	data_len  = rte_pktmbuf_data_len(m) - ipdata_offset;
-
-	if (cparams->do_hash && cparams->hash_verify)
-		data_len -= cparams->digest_length;
-
-	if (cparams->do_cipher) {
-		/*
-		 * Following algorithms are block cipher algorithms,
-		 * and might need padding
-		 */
-		switch (cparams->cipher_algo) {
-		case RTE_CRYPTO_CIPHER_AES_CBC:
-		case RTE_CRYPTO_CIPHER_AES_ECB:
-		case RTE_CRYPTO_CIPHER_DES_CBC:
-		case RTE_CRYPTO_CIPHER_3DES_CBC:
-		case RTE_CRYPTO_CIPHER_3DES_ECB:
-			if (data_len % cparams->block_size)
-				pad_len = cparams->block_size -
-					(data_len % cparams->block_size);
-			break;
-		default:
-			pad_len = 0;
-		}
-
-		if (pad_len) {
-			padding = rte_pktmbuf_append(m, pad_len);
-			if (unlikely(!padding))
-				return -1;
-
-			data_len += pad_len;
-			memset(padding, 0, pad_len);
-		}
-	}
-
-	/* Set crypto operation data parameters */
-	rte_crypto_op_attach_sym_session(op, cparams->session);
-
-	if (cparams->do_hash) {
-		if (cparams->auth_iv.length) {
-			uint8_t *iv_ptr = rte_crypto_op_ctod_offset(op,
-						uint8_t *,
-						IV_OFFSET +
-						cparams->cipher_iv.length);
-			/*
-			 * Copy IV at the end of the crypto operation,
-			 * after the cipher IV, if added
-			 */
-			rte_memcpy(iv_ptr, cparams->auth_iv.data,
-					cparams->auth_iv.length);
-		}
-		if (!cparams->hash_verify) {
-			/* Append space for digest to end of packet */
-			op->sym->auth.digest.data = (uint8_t *)rte_pktmbuf_append(m,
-				cparams->digest_length);
-		} else {
-			op->sym->auth.digest.data = rte_pktmbuf_mtod(m,
-				uint8_t *) + ipdata_offset + data_len;
-		}
-
-		op->sym->auth.digest.phys_addr = rte_pktmbuf_iova_offset(m,
-				rte_pktmbuf_pkt_len(m) - cparams->digest_length);
-
-		/* For wireless algorithms, offset/length must be in bits */
-		if (cparams->auth_algo == RTE_CRYPTO_AUTH_SNOW3G_UIA2 ||
-				cparams->auth_algo == RTE_CRYPTO_AUTH_KASUMI_F9 ||
-				cparams->auth_algo == RTE_CRYPTO_AUTH_ZUC_EIA3) {
-			op->sym->auth.data.offset = ipdata_offset << 3;
-			op->sym->auth.data.length = data_len << 3;
-		} else {
-			op->sym->auth.data.offset = ipdata_offset;
-			op->sym->auth.data.length = data_len;
-		}
-	}
-
-	if (cparams->do_cipher) {
-		uint8_t *iv_ptr = rte_crypto_op_ctod_offset(op, uint8_t *,
-							IV_OFFSET);
-		/* Copy IV at the end of the crypto operation */
-		rte_memcpy(iv_ptr, cparams->cipher_iv.data,
-				cparams->cipher_iv.length);
-
-		/* For wireless algorithms, offset/length must be in bits */
-		if (cparams->cipher_algo == RTE_CRYPTO_CIPHER_SNOW3G_UEA2 ||
-				cparams->cipher_algo == RTE_CRYPTO_CIPHER_KASUMI_F8 ||
-				cparams->cipher_algo == RTE_CRYPTO_CIPHER_ZUC_EEA3) {
-			op->sym->cipher.data.offset = ipdata_offset << 3;
-			op->sym->cipher.data.length = data_len << 3;
-		} else {
-			op->sym->cipher.data.offset = ipdata_offset;
-			op->sym->cipher.data.length = data_len;
-		}
-	}
-
-	if (cparams->do_aead) {
-		uint8_t *iv_ptr = rte_crypto_op_ctod_offset(op, uint8_t *,
-							IV_OFFSET);
-		/* Copy IV at the end of the crypto operation */
-		/*
-		 * If doing AES-CCM, nonce is copied one byte
-		 * after the start of IV field
-		 */
-		if (cparams->aead_algo == RTE_CRYPTO_AEAD_AES_CCM)
-			rte_memcpy(iv_ptr + 1, cparams->aead_iv.data,
-					cparams->aead_iv.length);
-		else
-			rte_memcpy(iv_ptr, cparams->aead_iv.data,
-					cparams->aead_iv.length);
-
-		op->sym->aead.data.offset = ipdata_offset;
-		op->sym->aead.data.length = data_len;
-
-		if (!cparams->hash_verify) {
-			/* Append space for digest to end of packet */
-			op->sym->aead.digest.data = (uint8_t *)rte_pktmbuf_append(m,
-				cparams->digest_length);
-		} else {
-			op->sym->aead.digest.data = rte_pktmbuf_mtod(m,
-				uint8_t *) + ipdata_offset + data_len;
-		}
-
-		op->sym->aead.digest.phys_addr = rte_pktmbuf_iova_offset(m,
-				rte_pktmbuf_pkt_len(m) - cparams->digest_length);
-
-		if (cparams->aad.length) {
-			op->sym->aead.aad.data = cparams->aad.data;
-			op->sym->aead.aad.phys_addr = cparams->aad.phys_addr;
-		}
-	}
-
-	op->sym->m_src = m;
-
-	return l2fwd_crypto_enqueue(op, cparams);
-}
-
-
-/* Send the burst of packets on an output interface */
-static int
-l2fwd_send_burst(struct lcore_queue_conf *qconf, unsigned n,
-		uint16_t port)
-{
-	struct rte_mbuf **pkt_buffer;
-	unsigned ret;
-
-	pkt_buffer = (struct rte_mbuf **)qconf->pkt_buf[port].buffer;
-
-	ret = rte_eth_tx_burst(port, 0, pkt_buffer, (uint16_t)n);
-	port_statistics[port].tx += ret;
-	if (unlikely(ret < n)) {
-		port_statistics[port].dropped += (n - ret);
-		do {
-			rte_pktmbuf_free(pkt_buffer[ret]);
-		} while (++ret < n);
-	}
-
-	return 0;
-}
-
-/* Enqueue packets for TX and prepare them to be sent */
-static int
-l2fwd_send_packet(struct rte_mbuf *m, uint16_t port)
-{
-	unsigned lcore_id, len;
-	struct lcore_queue_conf *qconf;
-
-	lcore_id = rte_lcore_id();
-
-	qconf = &lcore_queue_conf[lcore_id];
-	len = qconf->pkt_buf[port].len;
-	qconf->pkt_buf[port].buffer[len] = m;
-	len++;
-
-	/* enough pkts to be sent */
-	if (unlikely(len == MAX_PKT_BURST)) {
-		l2fwd_send_burst(qconf, MAX_PKT_BURST, port);
-		len = 0;
-	}
-
-	qconf->pkt_buf[port].len = len;
-	return 0;
-}
-
-static void
-l2fwd_mac_updating(struct rte_mbuf *m, uint16_t dest_portid)
-{
-	struct ether_hdr *eth;
-	void *tmp;
-
-	eth = rte_pktmbuf_mtod(m, struct ether_hdr *);
-
-	/* 02:00:00:00:00:xx */
-	tmp = &eth->d_addr.addr_bytes[0];
-	*((uint64_t *)tmp) = 0x000000000002 + ((uint64_t)dest_portid << 40);
-
-	/* src addr */
-	ether_addr_copy(&l2fwd_ports_eth_addr[dest_portid], &eth->s_addr);
-}
-
-static void
-l2fwd_simple_forward(struct rte_mbuf *m, uint16_t portid,
-		struct l2fwd_crypto_options *options)
-{
-	uint16_t dst_port;
-
-	dst_port = l2fwd_dst_ports[portid];
-
-	if (options->mac_updating)
-		l2fwd_mac_updating(m, dst_port);
-
-	l2fwd_send_packet(m, dst_port);
-}
-
-/** Generate random key */
-static void
-generate_random_key(uint8_t *key, unsigned length)
-{
-	int fd;
-	int ret;
-
-	fd = open("/dev/urandom", O_RDONLY);
-	if (fd < 0)
-		rte_exit(EXIT_FAILURE, "Failed to generate random key\n");
-
-	ret = read(fd, key, length);
-	close(fd);
-
-	if (ret != (signed)length)
-		rte_exit(EXIT_FAILURE, "Failed to generate random key\n");
-}
-
-static struct rte_cryptodev_sym_session *
-initialize_crypto_session(struct l2fwd_crypto_options *options, uint8_t cdev_id)
-{
-	struct rte_crypto_sym_xform *first_xform;
-	struct rte_cryptodev_sym_session *session;
-	int retval = rte_cryptodev_socket_id(cdev_id);
-
-	if (retval < 0)
-		return NULL;
-
-	uint8_t socket_id = (uint8_t) retval;
-	struct rte_mempool *sess_mp = session_pool_socket[socket_id];
-
-	if (options->xform_chain == L2FWD_CRYPTO_AEAD) {
-		first_xform = &options->aead_xform;
-	} else if (options->xform_chain == L2FWD_CRYPTO_CIPHER_HASH) {
-		first_xform = &options->cipher_xform;
-		first_xform->next = &options->auth_xform;
-	} else if (options->xform_chain == L2FWD_CRYPTO_HASH_CIPHER) {
-		first_xform = &options->auth_xform;
-		first_xform->next = &options->cipher_xform;
-	} else if (options->xform_chain == L2FWD_CRYPTO_CIPHER_ONLY) {
-		first_xform = &options->cipher_xform;
-	} else {
-		first_xform = &options->auth_xform;
-	}
-
-	session = rte_cryptodev_sym_session_create(sess_mp);
-
-	if (session == NULL)
-		return NULL;
-
-	if (rte_cryptodev_sym_session_init(cdev_id, session,
-				first_xform, sess_mp) < 0)
-		return NULL;
-
-	return session;
-}
-
-static void
-l2fwd_crypto_options_print(struct l2fwd_crypto_options *options);
-
-/* main processing loop */
-static void
-l2fwd_main_loop(struct l2fwd_crypto_options *options)
-{
-	struct rte_mbuf *m, *pkts_burst[MAX_PKT_BURST];
-	struct rte_crypto_op *ops_burst[MAX_PKT_BURST];
-
-	unsigned lcore_id = rte_lcore_id();
-	uint64_t prev_tsc = 0, diff_tsc, cur_tsc, timer_tsc = 0;
-	unsigned int i, j, nb_rx, len;
-	uint16_t portid;
-	struct lcore_queue_conf *qconf = &lcore_queue_conf[lcore_id];
-	const uint64_t drain_tsc = (rte_get_tsc_hz() + US_PER_S - 1) /
-			US_PER_S * BURST_TX_DRAIN_US;
-	struct l2fwd_crypto_params *cparams;
-	struct l2fwd_crypto_params port_cparams[qconf->nb_crypto_devs];
-	struct rte_cryptodev_sym_session *session;
-
-	if (qconf->nb_rx_ports == 0) {
-		RTE_LOG(INFO, L2FWD, "lcore %u has nothing to do\n", lcore_id);
-		return;
-	}
-
-	RTE_LOG(INFO, L2FWD, "entering main loop on lcore %u\n", lcore_id);
-
-	for (i = 0; i < qconf->nb_rx_ports; i++) {
-
-		portid = qconf->rx_port_list[i];
-		RTE_LOG(INFO, L2FWD, " -- lcoreid=%u portid=%u\n", lcore_id,
-			portid);
-	}
-
-	for (i = 0; i < qconf->nb_crypto_devs; i++) {
-		port_cparams[i].do_cipher = 0;
-		port_cparams[i].do_hash = 0;
-		port_cparams[i].do_aead = 0;
-
-		switch (options->xform_chain) {
-		case L2FWD_CRYPTO_AEAD:
-			port_cparams[i].do_aead = 1;
-			break;
-		case L2FWD_CRYPTO_CIPHER_HASH:
-		case L2FWD_CRYPTO_HASH_CIPHER:
-			port_cparams[i].do_cipher = 1;
-			port_cparams[i].do_hash = 1;
-			break;
-		case L2FWD_CRYPTO_HASH_ONLY:
-			port_cparams[i].do_hash = 1;
-			break;
-		case L2FWD_CRYPTO_CIPHER_ONLY:
-			port_cparams[i].do_cipher = 1;
-			break;
-		}
-
-		port_cparams[i].dev_id = qconf->cryptodev_list[i];
-		port_cparams[i].qp_id = 0;
-
-		port_cparams[i].block_size = options->block_size;
-
-		if (port_cparams[i].do_hash) {
-			port_cparams[i].auth_iv.data = options->auth_iv.data;
-			port_cparams[i].auth_iv.length = options->auth_iv.length;
-			if (!options->auth_iv_param)
-				generate_random_key(port_cparams[i].auth_iv.data,
-						port_cparams[i].auth_iv.length);
-			if (options->auth_xform.auth.op == RTE_CRYPTO_AUTH_OP_VERIFY)
-				port_cparams[i].hash_verify = 1;
-			else
-				port_cparams[i].hash_verify = 0;
-
-			port_cparams[i].auth_algo = options->auth_xform.auth.algo;
-			port_cparams[i].digest_length =
-					options->auth_xform.auth.digest_length;
-			/* Set IV parameters */
-			if (options->auth_iv.length) {
-				options->auth_xform.auth.iv.offset =
-					IV_OFFSET + options->cipher_iv.length;
-				options->auth_xform.auth.iv.length =
-					options->auth_iv.length;
-			}
-		}
-
-		if (port_cparams[i].do_aead) {
-			port_cparams[i].aead_iv.data = options->aead_iv.data;
-			port_cparams[i].aead_iv.length = options->aead_iv.length;
-			if (!options->aead_iv_param)
-				generate_random_key(port_cparams[i].aead_iv.data,
-						port_cparams[i].aead_iv.length);
-			port_cparams[i].aead_algo = options->aead_xform.aead.algo;
-			port_cparams[i].digest_length =
-					options->aead_xform.aead.digest_length;
-			if (options->aead_xform.aead.aad_length) {
-				port_cparams[i].aad.data = options->aad.data;
-				port_cparams[i].aad.phys_addr = options->aad.phys_addr;
-				port_cparams[i].aad.length = options->aad.length;
-				if (!options->aad_param)
-					generate_random_key(port_cparams[i].aad.data,
-						port_cparams[i].aad.length);
-				/*
-				 * If doing AES-CCM, first 18 bytes has to be reserved,
-				 * and actual AAD should start from byte 18
-				 */
-				if (port_cparams[i].aead_algo == RTE_CRYPTO_AEAD_AES_CCM)
-					memmove(port_cparams[i].aad.data + 18,
-							port_cparams[i].aad.data,
-							port_cparams[i].aad.length);
-
-			} else
-				port_cparams[i].aad.length = 0;
-
-			if (options->aead_xform.aead.op == RTE_CRYPTO_AEAD_OP_DECRYPT)
-				port_cparams[i].hash_verify = 1;
-			else
-				port_cparams[i].hash_verify = 0;
-
-			/* Set IV parameters */
-			options->aead_xform.aead.iv.offset = IV_OFFSET;
-			options->aead_xform.aead.iv.length = options->aead_iv.length;
-		}
-
-		if (port_cparams[i].do_cipher) {
-			port_cparams[i].cipher_iv.data = options->cipher_iv.data;
-			port_cparams[i].cipher_iv.length = options->cipher_iv.length;
-			if (!options->cipher_iv_param)
-				generate_random_key(port_cparams[i].cipher_iv.data,
-						port_cparams[i].cipher_iv.length);
-
-			port_cparams[i].cipher_algo = options->cipher_xform.cipher.algo;
-			/* Set IV parameters */
-			options->cipher_xform.cipher.iv.offset = IV_OFFSET;
-			options->cipher_xform.cipher.iv.length =
-						options->cipher_iv.length;
-		}
-
-		session = initialize_crypto_session(options,
-				port_cparams[i].dev_id);
-		if (session == NULL)
-			rte_exit(EXIT_FAILURE, "Failed to initialize crypto session\n");
-
-		port_cparams[i].session = session;
-
-		RTE_LOG(INFO, L2FWD, " -- lcoreid=%u cryptoid=%u\n", lcore_id,
-				port_cparams[i].dev_id);
-	}
-
-	l2fwd_crypto_options_print(options);
-
-	/*
-	 * Initialize previous tsc timestamp before the loop,
-	 * to avoid showing the port statistics immediately,
-	 * so user can see the crypto information.
-	 */
-	prev_tsc = rte_rdtsc();
-	while (1) {
-
-		cur_tsc = rte_rdtsc();
-
-		/*
-		 * Crypto device/TX burst queue drain
-		 */
-		diff_tsc = cur_tsc - prev_tsc;
-		if (unlikely(diff_tsc > drain_tsc)) {
-			/* Enqueue all crypto ops remaining in buffers */
-			for (i = 0; i < qconf->nb_crypto_devs; i++) {
-				cparams = &port_cparams[i];
-				len = qconf->op_buf[cparams->dev_id].len;
-				l2fwd_crypto_send_burst(qconf, len, cparams);
-				qconf->op_buf[cparams->dev_id].len = 0;
-			}
-			/* Transmit all packets remaining in buffers */
-			for (portid = 0; portid < RTE_MAX_ETHPORTS; portid++) {
-				if (qconf->pkt_buf[portid].len == 0)
-					continue;
-				l2fwd_send_burst(&lcore_queue_conf[lcore_id],
-						 qconf->pkt_buf[portid].len,
-						 portid);
-				qconf->pkt_buf[portid].len = 0;
-			}
-
-			/* if timer is enabled */
-			if (timer_period > 0) {
-
-				/* advance the timer */
-				timer_tsc += diff_tsc;
-
-				/* if timer has reached its timeout */
-				if (unlikely(timer_tsc >=
-						(uint64_t)timer_period)) {
-
-					/* do this only on master core */
-					if (lcore_id == rte_get_master_lcore()
-						&& options->refresh_period) {
-						print_stats();
-						timer_tsc = 0;
-					}
-				}
-			}
-
-			prev_tsc = cur_tsc;
-		}
-
-		/*
-		 * Read packet from RX queues
-		 */
-		for (i = 0; i < qconf->nb_rx_ports; i++) {
-			portid = qconf->rx_port_list[i];
-
-			cparams = &port_cparams[i];
-
-			nb_rx = rte_eth_rx_burst(portid, 0,
-						 pkts_burst, MAX_PKT_BURST);
-
-			port_statistics[portid].rx += nb_rx;
-
-			if (nb_rx) {
-				/*
-				 * If we can't allocate a crypto_ops, then drop
-				 * the rest of the burst and dequeue and
-				 * process the packets to free offload structs
-				 */
-				if (rte_crypto_op_bulk_alloc(
-						l2fwd_crypto_op_pool,
-						RTE_CRYPTO_OP_TYPE_SYMMETRIC,
-						ops_burst, nb_rx) !=
-								nb_rx) {
-					for (j = 0; j < nb_rx; j++)
-						rte_pktmbuf_free(pkts_burst[j]);
-
-					nb_rx = 0;
-				}
-
-				/* Enqueue packets from Crypto device*/
-				for (j = 0; j < nb_rx; j++) {
-					m = pkts_burst[j];
-
-					l2fwd_simple_crypto_enqueue(m,
-							ops_burst[j], cparams);
-				}
-			}
-
-			/* Dequeue packets from Crypto device */
-			do {
-				nb_rx = rte_cryptodev_dequeue_burst(
-						cparams->dev_id, cparams->qp_id,
-						ops_burst, MAX_PKT_BURST);
-
-				crypto_statistics[cparams->dev_id].dequeued +=
-						nb_rx;
-
-				/* Forward crypto'd packets */
-				for (j = 0; j < nb_rx; j++) {
-					m = ops_burst[j]->sym->m_src;
-
-					rte_crypto_op_free(ops_burst[j]);
-					l2fwd_simple_forward(m, portid,
-							options);
-				}
-			} while (nb_rx == MAX_PKT_BURST);
-		}
-	}
-}
-
-static int
-l2fwd_launch_one_lcore(void *arg)
-{
-	l2fwd_main_loop((struct l2fwd_crypto_options *)arg);
-	return 0;
-}
-
-/* Display command line arguments usage */
-static void
-l2fwd_crypto_usage(const char *prgname)
-{
-	printf("%s [EAL options] --\n"
-		"  -p PORTMASK: hexadecimal bitmask of ports to configure\n"
-		"  -q NQ: number of queue (=ports) per lcore (default is 1)\n"
-		"  -s manage all ports from single lcore\n"
-		"  -T PERIOD: statistics will be refreshed each PERIOD seconds"
-		" (0 to disable, 10 default, 86400 maximum)\n"
-
-		"  --cdev_type HW / SW / ANY\n"
-		"  --chain HASH_CIPHER / CIPHER_HASH / CIPHER_ONLY /"
-		" HASH_ONLY / AEAD\n"
-
-		"  --cipher_algo ALGO\n"
-		"  --cipher_op ENCRYPT / DECRYPT\n"
-		"  --cipher_key KEY (bytes separated with \":\")\n"
-		"  --cipher_key_random_size SIZE: size of cipher key when generated randomly\n"
-		"  --cipher_iv IV (bytes separated with \":\")\n"
-		"  --cipher_iv_random_size SIZE: size of cipher IV when generated randomly\n"
-
-		"  --auth_algo ALGO\n"
-		"  --auth_op GENERATE / VERIFY\n"
-		"  --auth_key KEY (bytes separated with \":\")\n"
-		"  --auth_key_random_size SIZE: size of auth key when generated randomly\n"
-		"  --auth_iv IV (bytes separated with \":\")\n"
-		"  --auth_iv_random_size SIZE: size of auth IV when generated randomly\n"
-
-		"  --aead_algo ALGO\n"
-		"  --aead_op ENCRYPT / DECRYPT\n"
-		"  --aead_key KEY (bytes separated with \":\")\n"
-		"  --aead_key_random_size SIZE: size of AEAD key when generated randomly\n"
-		"  --aead_iv IV (bytes separated with \":\")\n"
-		"  --aead_iv_random_size SIZE: size of AEAD IV when generated randomly\n"
-		"  --aad AAD (bytes separated with \":\")\n"
-		"  --aad_random_size SIZE: size of AAD when generated randomly\n"
-
-		"  --digest_size SIZE: size of digest to be generated/verified\n"
-
-		"  --sessionless\n"
-		"  --cryptodev_mask MASK: hexadecimal bitmask of crypto devices to configure\n"
-
-		"  --[no-]mac-updating: Enable or disable MAC addresses updating (enabled by default)\n"
-		"      When enabled:\n"
-		"       - The source MAC address is replaced by the TX port MAC address\n"
-		"       - The destination MAC address is replaced by 02:00:00:00:00:TX_PORT_ID\n",
-	       prgname);
-}
-
-/** Parse crypto device type command line argument */
-static int
-parse_cryptodev_type(enum cdev_type *type, char *optarg)
-{
-	if (strcmp("HW", optarg) == 0) {
-		*type = CDEV_TYPE_HW;
-		return 0;
-	} else if (strcmp("SW", optarg) == 0) {
-		*type = CDEV_TYPE_SW;
-		return 0;
-	} else if (strcmp("ANY", optarg) == 0) {
-		*type = CDEV_TYPE_ANY;
-		return 0;
-	}
-
-	return -1;
-}
-
-/** Parse crypto chain xform command line argument */
-static int
-parse_crypto_opt_chain(struct l2fwd_crypto_options *options, char *optarg)
-{
-	if (strcmp("CIPHER_HASH", optarg) == 0) {
-		options->xform_chain = L2FWD_CRYPTO_CIPHER_HASH;
-		return 0;
-	} else if (strcmp("HASH_CIPHER", optarg) == 0) {
-		options->xform_chain = L2FWD_CRYPTO_HASH_CIPHER;
-		return 0;
-	} else if (strcmp("CIPHER_ONLY", optarg) == 0) {
-		options->xform_chain = L2FWD_CRYPTO_CIPHER_ONLY;
-		return 0;
-	} else if (strcmp("HASH_ONLY", optarg) == 0) {
-		options->xform_chain = L2FWD_CRYPTO_HASH_ONLY;
-		return 0;
-	} else if (strcmp("AEAD", optarg) == 0) {
-		options->xform_chain = L2FWD_CRYPTO_AEAD;
-		return 0;
-	}
-
-	return -1;
-}
-
-/** Parse crypto cipher algo option command line argument */
-static int
-parse_cipher_algo(enum rte_crypto_cipher_algorithm *algo, char *optarg)
-{
-
-	if (rte_cryptodev_get_cipher_algo_enum(algo, optarg) < 0) {
-		RTE_LOG(ERR, USER1, "Cipher algorithm specified "
-				"not supported!\n");
-		return -1;
-	}
-
-	return 0;
-}
-
-/** Parse crypto cipher operation command line argument */
-static int
-parse_cipher_op(enum rte_crypto_cipher_operation *op, char *optarg)
-{
-	if (strcmp("ENCRYPT", optarg) == 0) {
-		*op = RTE_CRYPTO_CIPHER_OP_ENCRYPT;
-		return 0;
-	} else if (strcmp("DECRYPT", optarg) == 0) {
-		*op = RTE_CRYPTO_CIPHER_OP_DECRYPT;
-		return 0;
-	}
-
-	printf("Cipher operation not supported!\n");
-	return -1;
-}
-
-/** Parse bytes from command line argument */
-static int
-parse_bytes(uint8_t *data, char *input_arg, uint16_t max_size)
-{
-	unsigned byte_count;
-	char *token;
-
-	errno = 0;
-	for (byte_count = 0, token = strtok(input_arg, ":");
-			(byte_count < max_size) && (token != NULL);
-			token = strtok(NULL, ":")) {
-
-		int number = (int)strtol(token, NULL, 16);
-
-		if (errno == EINVAL || errno == ERANGE || number > 0xFF)
-			return -1;
-
-		data[byte_count++] = (uint8_t)number;
-	}
-
-	return byte_count;
-}
-
-/** Parse size param*/
-static int
-parse_size(int *size, const char *q_arg)
-{
-	char *end = NULL;
-	unsigned long n;
-
-	/* parse hexadecimal string */
-	n = strtoul(q_arg, &end, 10);
-	if ((q_arg[0] == '\0') || (end == NULL) || (*end != '\0'))
-		n = 0;
-
-	if (n == 0) {
-		printf("invalid size\n");
-		return -1;
-	}
-
-	*size = n;
-	return 0;
-}
-
-/** Parse crypto cipher operation command line argument */
-static int
-parse_auth_algo(enum rte_crypto_auth_algorithm *algo, char *optarg)
-{
-	if (rte_cryptodev_get_auth_algo_enum(algo, optarg) < 0) {
-		RTE_LOG(ERR, USER1, "Authentication algorithm specified "
-				"not supported!\n");
-		return -1;
-	}
-
-	return 0;
-}
-
-static int
-parse_auth_op(enum rte_crypto_auth_operation *op, char *optarg)
-{
-	if (strcmp("VERIFY", optarg) == 0) {
-		*op = RTE_CRYPTO_AUTH_OP_VERIFY;
-		return 0;
-	} else if (strcmp("GENERATE", optarg) == 0) {
-		*op = RTE_CRYPTO_AUTH_OP_GENERATE;
-		return 0;
-	}
-
-	printf("Authentication operation specified not supported!\n");
-	return -1;
-}
-
-static int
-parse_aead_algo(enum rte_crypto_aead_algorithm *algo, char *optarg)
-{
-	if (rte_cryptodev_get_aead_algo_enum(algo, optarg) < 0) {
-		RTE_LOG(ERR, USER1, "AEAD algorithm specified "
-				"not supported!\n");
-		return -1;
-	}
-
-	return 0;
-}
-
-static int
-parse_aead_op(enum rte_crypto_aead_operation *op, char *optarg)
-{
-	if (strcmp("ENCRYPT", optarg) == 0) {
-		*op = RTE_CRYPTO_AEAD_OP_ENCRYPT;
-		return 0;
-	} else if (strcmp("DECRYPT", optarg) == 0) {
-		*op = RTE_CRYPTO_AEAD_OP_DECRYPT;
-		return 0;
-	}
-
-	printf("AEAD operation specified not supported!\n");
-	return -1;
-}
-static int
-parse_cryptodev_mask(struct l2fwd_crypto_options *options,
-		const char *q_arg)
-{
-	char *end = NULL;
-	uint64_t pm;
-
-	/* parse hexadecimal string */
-	pm = strtoul(q_arg, &end, 16);
-	if ((pm == '\0') || (end == NULL) || (*end != '\0'))
-		pm = 0;
-
-	options->cryptodev_mask = pm;
-	if (options->cryptodev_mask == 0) {
-		printf("invalid cryptodev_mask specified\n");
-		return -1;
-	}
-
-	return 0;
-}
-
-/** Parse long options */
-static int
-l2fwd_crypto_parse_args_long_options(struct l2fwd_crypto_options *options,
-		struct option *lgopts, int option_index)
-{
-	int retval;
-
-	if (strcmp(lgopts[option_index].name, "cdev_type") == 0) {
-		retval = parse_cryptodev_type(&options->type, optarg);
-		if (retval == 0)
-			snprintf(options->string_type, MAX_STR_LEN,
-				"%s", optarg);
-		return retval;
-	}
-
-	else if (strcmp(lgopts[option_index].name, "chain") == 0)
-		return parse_crypto_opt_chain(options, optarg);
-
-	/* Cipher options */
-	else if (strcmp(lgopts[option_index].name, "cipher_algo") == 0)
-		return parse_cipher_algo(&options->cipher_xform.cipher.algo,
-				optarg);
-
-	else if (strcmp(lgopts[option_index].name, "cipher_op") == 0)
-		return parse_cipher_op(&options->cipher_xform.cipher.op,
-				optarg);
-
-	else if (strcmp(lgopts[option_index].name, "cipher_key") == 0) {
-		options->ckey_param = 1;
-		options->cipher_xform.cipher.key.length =
-			parse_bytes(options->cipher_xform.cipher.key.data, optarg,
-					MAX_KEY_SIZE);
-		if (options->cipher_xform.cipher.key.length > 0)
-			return 0;
-		else
-			return -1;
-	}
-
-	else if (strcmp(lgopts[option_index].name, "cipher_key_random_size") == 0)
-		return parse_size(&options->ckey_random_size, optarg);
-
-	else if (strcmp(lgopts[option_index].name, "cipher_iv") == 0) {
-		options->cipher_iv_param = 1;
-		options->cipher_iv.length =
-			parse_bytes(options->cipher_iv.data, optarg, MAX_IV_SIZE);
-		if (options->cipher_iv.length > 0)
-			return 0;
-		else
-			return -1;
-	}
-
-	else if (strcmp(lgopts[option_index].name, "cipher_iv_random_size") == 0)
-		return parse_size(&options->cipher_iv_random_size, optarg);
-
-	/* Authentication options */
-	else if (strcmp(lgopts[option_index].name, "auth_algo") == 0) {
-		return parse_auth_algo(&options->auth_xform.auth.algo,
-				optarg);
-	}
-
-	else if (strcmp(lgopts[option_index].name, "auth_op") == 0)
-		return parse_auth_op(&options->auth_xform.auth.op,
-				optarg);
-
-	else if (strcmp(lgopts[option_index].name, "auth_key") == 0) {
-		options->akey_param = 1;
-		options->auth_xform.auth.key.length =
-			parse_bytes(options->auth_xform.auth.key.data, optarg,
-					MAX_KEY_SIZE);
-		if (options->auth_xform.auth.key.length > 0)
-			return 0;
-		else
-			return -1;
-	}
-
-	else if (strcmp(lgopts[option_index].name, "auth_key_random_size") == 0) {
-		return parse_size(&options->akey_random_size, optarg);
-	}
-
-	else if (strcmp(lgopts[option_index].name, "auth_iv") == 0) {
-		options->auth_iv_param = 1;
-		options->auth_iv.length =
-			parse_bytes(options->auth_iv.data, optarg, MAX_IV_SIZE);
-		if (options->auth_iv.length > 0)
-			return 0;
-		else
-			return -1;
-	}
-
-	else if (strcmp(lgopts[option_index].name, "auth_iv_random_size") == 0)
-		return parse_size(&options->auth_iv_random_size, optarg);
-
-	/* AEAD options */
-	else if (strcmp(lgopts[option_index].name, "aead_algo") == 0) {
-		return parse_aead_algo(&options->aead_xform.aead.algo,
-				optarg);
-	}
-
-	else if (strcmp(lgopts[option_index].name, "aead_op") == 0)
-		return parse_aead_op(&options->aead_xform.aead.op,
-				optarg);
-
-	else if (strcmp(lgopts[option_index].name, "aead_key") == 0) {
-		options->aead_key_param = 1;
-		options->aead_xform.aead.key.length =
-			parse_bytes(options->aead_xform.aead.key.data, optarg,
-					MAX_KEY_SIZE);
-		if (options->aead_xform.aead.key.length > 0)
-			return 0;
-		else
-			return -1;
-	}
-
-	else if (strcmp(lgopts[option_index].name, "aead_key_random_size") == 0)
-		return parse_size(&options->aead_key_random_size, optarg);
-
-
-	else if (strcmp(lgopts[option_index].name, "aead_iv") == 0) {
-		options->aead_iv_param = 1;
-		options->aead_iv.length =
-			parse_bytes(options->aead_iv.data, optarg, MAX_IV_SIZE);
-		if (options->aead_iv.length > 0)
-			return 0;
-		else
-			return -1;
-	}
-
-	else if (strcmp(lgopts[option_index].name, "aead_iv_random_size") == 0)
-		return parse_size(&options->aead_iv_random_size, optarg);
-
-	else if (strcmp(lgopts[option_index].name, "aad") == 0) {
-		options->aad_param = 1;
-		options->aad.length =
-			parse_bytes(options->aad.data, optarg, MAX_AAD_SIZE);
-		if (options->aad.length > 0)
-			return 0;
-		else
-			return -1;
-	}
-
-	else if (strcmp(lgopts[option_index].name, "aad_random_size") == 0) {
-		return parse_size(&options->aad_random_size, optarg);
-	}
-
-	else if (strcmp(lgopts[option_index].name, "digest_size") == 0) {
-		return parse_size(&options->digest_size, optarg);
-	}
-
-	else if (strcmp(lgopts[option_index].name, "sessionless") == 0) {
-		options->sessionless = 1;
-		return 0;
-	}
-
-	else if (strcmp(lgopts[option_index].name, "cryptodev_mask") == 0)
-		return parse_cryptodev_mask(options, optarg);
-
-	else if (strcmp(lgopts[option_index].name, "mac-updating") == 0) {
-		options->mac_updating = 1;
-		return 0;
-	}
-
-	else if (strcmp(lgopts[option_index].name, "no-mac-updating") == 0) {
-		options->mac_updating = 0;
-		return 0;
-	}
-
-	return -1;
-}
-
-/** Parse port mask */
-static int
-l2fwd_crypto_parse_portmask(struct l2fwd_crypto_options *options,
-		const char *q_arg)
-{
-	char *end = NULL;
-	unsigned long pm;
-
-	/* parse hexadecimal string */
-	pm = strtoul(q_arg, &end, 16);
-	if ((pm == '\0') || (end == NULL) || (*end != '\0'))
-		pm = 0;
-
-	options->portmask = pm;
-	if (options->portmask == 0) {
-		printf("invalid portmask specified\n");
-		return -1;
-	}
-
-	return pm;
-}
-
-/** Parse number of queues */
-static int
-l2fwd_crypto_parse_nqueue(struct l2fwd_crypto_options *options,
-		const char *q_arg)
-{
-	char *end = NULL;
-	unsigned long n;
-
-	/* parse hexadecimal string */
-	n = strtoul(q_arg, &end, 10);
-	if ((q_arg[0] == '\0') || (end == NULL) || (*end != '\0'))
-		n = 0;
-	else if (n >= MAX_RX_QUEUE_PER_LCORE)
-		n = 0;
-
-	options->nb_ports_per_lcore = n;
-	if (options->nb_ports_per_lcore == 0) {
-		printf("invalid number of ports selected\n");
-		return -1;
-	}
-
-	return 0;
-}
-
-/** Parse timer period */
-static int
-l2fwd_crypto_parse_timer_period(struct l2fwd_crypto_options *options,
-		const char *q_arg)
-{
-	char *end = NULL;
-	unsigned long n;
-
-	/* parse number string */
-	n = (unsigned)strtol(q_arg, &end, 10);
-	if ((q_arg[0] == '\0') || (end == NULL) || (*end != '\0'))
-		n = 0;
-
-	if (n >= MAX_TIMER_PERIOD) {
-		printf("Warning refresh period specified %lu is greater than "
-				"max value %lu! using max value",
-				n, MAX_TIMER_PERIOD);
-		n = MAX_TIMER_PERIOD;
-	}
-
-	options->refresh_period = n * 1000 * TIMER_MILLISECOND;
-
-	return 0;
-}
-
-/** Generate default options for application */
-static void
-l2fwd_crypto_default_options(struct l2fwd_crypto_options *options)
-{
-	options->portmask = 0xffffffff;
-	options->nb_ports_per_lcore = 1;
-	options->refresh_period = 10000;
-	options->single_lcore = 0;
-	options->sessionless = 0;
-
-	options->xform_chain = L2FWD_CRYPTO_CIPHER_HASH;
-
-	/* Cipher Data */
-	options->cipher_xform.type = RTE_CRYPTO_SYM_XFORM_CIPHER;
-	options->cipher_xform.next = NULL;
-	options->ckey_param = 0;
-	options->ckey_random_size = -1;
-	options->cipher_xform.cipher.key.length = 0;
-	options->cipher_iv_param = 0;
-	options->cipher_iv_random_size = -1;
-	options->cipher_iv.length = 0;
-
-	options->cipher_xform.cipher.algo = RTE_CRYPTO_CIPHER_AES_CBC;
-	options->cipher_xform.cipher.op = RTE_CRYPTO_CIPHER_OP_ENCRYPT;
-
-	/* Authentication Data */
-	options->auth_xform.type = RTE_CRYPTO_SYM_XFORM_AUTH;
-	options->auth_xform.next = NULL;
-	options->akey_param = 0;
-	options->akey_random_size = -1;
-	options->auth_xform.auth.key.length = 0;
-	options->auth_iv_param = 0;
-	options->auth_iv_random_size = -1;
-	options->auth_iv.length = 0;
-
-	options->auth_xform.auth.algo = RTE_CRYPTO_AUTH_SHA1_HMAC;
-	options->auth_xform.auth.op = RTE_CRYPTO_AUTH_OP_GENERATE;
-
-	/* AEAD Data */
-	options->aead_xform.type = RTE_CRYPTO_SYM_XFORM_AEAD;
-	options->aead_xform.next = NULL;
-	options->aead_key_param = 0;
-	options->aead_key_random_size = -1;
-	options->aead_xform.aead.key.length = 0;
-	options->aead_iv_param = 0;
-	options->aead_iv_random_size = -1;
-	options->aead_iv.length = 0;
-
-	options->aead_xform.aead.algo = RTE_CRYPTO_AEAD_AES_GCM;
-	options->aead_xform.aead.op = RTE_CRYPTO_AEAD_OP_ENCRYPT;
-
-	options->aad_param = 0;
-	options->aad_random_size = -1;
-	options->aad.length = 0;
-
-	options->digest_size = -1;
-
-	options->type = CDEV_TYPE_ANY;
-	options->cryptodev_mask = UINT64_MAX;
-
-	options->mac_updating = 1;
-}
-
-static void
-display_cipher_info(struct l2fwd_crypto_options *options)
-{
-	printf("\n---- Cipher information ---\n");
-	printf("Algorithm: %s\n",
-		rte_crypto_cipher_algorithm_strings[options->cipher_xform.cipher.algo]);
-	rte_hexdump(stdout, "Cipher key:",
-			options->cipher_xform.cipher.key.data,
-			options->cipher_xform.cipher.key.length);
-	rte_hexdump(stdout, "IV:", options->cipher_iv.data, options->cipher_iv.length);
-}
-
-static void
-display_auth_info(struct l2fwd_crypto_options *options)
-{
-	printf("\n---- Authentication information ---\n");
-	printf("Algorithm: %s\n",
-		rte_crypto_auth_algorithm_strings[options->auth_xform.auth.algo]);
-	rte_hexdump(stdout, "Auth key:",
-			options->auth_xform.auth.key.data,
-			options->auth_xform.auth.key.length);
-	rte_hexdump(stdout, "IV:", options->auth_iv.data, options->auth_iv.length);
-}
-
-static void
-display_aead_info(struct l2fwd_crypto_options *options)
-{
-	printf("\n---- AEAD information ---\n");
-	printf("Algorithm: %s\n",
-		rte_crypto_aead_algorithm_strings[options->aead_xform.aead.algo]);
-	rte_hexdump(stdout, "AEAD key:",
-			options->aead_xform.aead.key.data,
-			options->aead_xform.aead.key.length);
-	rte_hexdump(stdout, "IV:", options->aead_iv.data, options->aead_iv.length);
-	rte_hexdump(stdout, "AAD:", options->aad.data, options->aad.length);
-}
-
-static void
-l2fwd_crypto_options_print(struct l2fwd_crypto_options *options)
-{
-	char string_cipher_op[MAX_STR_LEN];
-	char string_auth_op[MAX_STR_LEN];
-	char string_aead_op[MAX_STR_LEN];
-
-	if (options->cipher_xform.cipher.op == RTE_CRYPTO_CIPHER_OP_ENCRYPT)
-		strcpy(string_cipher_op, "Encrypt");
-	else
-		strcpy(string_cipher_op, "Decrypt");
-
-	if (options->auth_xform.auth.op == RTE_CRYPTO_AUTH_OP_GENERATE)
-		strcpy(string_auth_op, "Auth generate");
-	else
-		strcpy(string_auth_op, "Auth verify");
-
-	if (options->aead_xform.aead.op == RTE_CRYPTO_AEAD_OP_ENCRYPT)
-		strcpy(string_aead_op, "Authenticated encryption");
-	else
-		strcpy(string_aead_op, "Authenticated decryption");
-
-
-	printf("Options:-\nn");
-	printf("portmask: %x\n", options->portmask);
-	printf("ports per lcore: %u\n", options->nb_ports_per_lcore);
-	printf("refresh period : %u\n", options->refresh_period);
-	printf("single lcore mode: %s\n",
-			options->single_lcore ? "enabled" : "disabled");
-	printf("stats_printing: %s\n",
-			options->refresh_period == 0 ? "disabled" : "enabled");
-
-	printf("sessionless crypto: %s\n",
-			options->sessionless ? "enabled" : "disabled");
-
-	if (options->ckey_param && (options->ckey_random_size != -1))
-		printf("Cipher key already parsed, ignoring size of random key\n");
-
-	if (options->akey_param && (options->akey_random_size != -1))
-		printf("Auth key already parsed, ignoring size of random key\n");
-
-	if (options->cipher_iv_param && (options->cipher_iv_random_size != -1))
-		printf("Cipher IV already parsed, ignoring size of random IV\n");
-
-	if (options->auth_iv_param && (options->auth_iv_random_size != -1))
-		printf("Auth IV already parsed, ignoring size of random IV\n");
-
-	if (options->aad_param && (options->aad_random_size != -1))
-		printf("AAD already parsed, ignoring size of random AAD\n");
-
-	printf("\nCrypto chain: ");
-	switch (options->xform_chain) {
-	case L2FWD_CRYPTO_AEAD:
-		printf("Input --> %s --> Output\n", string_aead_op);
-		display_aead_info(options);
-		break;
-	case L2FWD_CRYPTO_CIPHER_HASH:
-		printf("Input --> %s --> %s --> Output\n",
-			string_cipher_op, string_auth_op);
-		display_cipher_info(options);
-		display_auth_info(options);
-		break;
-	case L2FWD_CRYPTO_HASH_CIPHER:
-		printf("Input --> %s --> %s --> Output\n",
-			string_auth_op, string_cipher_op);
-		display_cipher_info(options);
-		display_auth_info(options);
-		break;
-	case L2FWD_CRYPTO_HASH_ONLY:
-		printf("Input --> %s --> Output\n", string_auth_op);
-		display_auth_info(options);
-		break;
-	case L2FWD_CRYPTO_CIPHER_ONLY:
-		printf("Input --> %s --> Output\n", string_cipher_op);
-		display_cipher_info(options);
-		break;
-	}
-}
-
-/* Parse the argument given in the command line of the application */
-static int
-l2fwd_crypto_parse_args(struct l2fwd_crypto_options *options,
-		int argc, char **argv)
-{
-	int opt, retval, option_index;
-	char **argvopt = argv, *prgname = argv[0];
-
-	static struct option lgopts[] = {
-			{ "sessionless", no_argument, 0, 0 },
-
-			{ "cdev_type", required_argument, 0, 0 },
-			{ "chain", required_argument, 0, 0 },
-
-			{ "cipher_algo", required_argument, 0, 0 },
-			{ "cipher_op", required_argument, 0, 0 },
-			{ "cipher_key", required_argument, 0, 0 },
-			{ "cipher_key_random_size", required_argument, 0, 0 },
-			{ "cipher_iv", required_argument, 0, 0 },
-			{ "cipher_iv_random_size", required_argument, 0, 0 },
-
-			{ "auth_algo", required_argument, 0, 0 },
-			{ "auth_op", required_argument, 0, 0 },
-			{ "auth_key", required_argument, 0, 0 },
-			{ "auth_key_random_size", required_argument, 0, 0 },
-			{ "auth_iv", required_argument, 0, 0 },
-			{ "auth_iv_random_size", required_argument, 0, 0 },
-
-			{ "aead_algo", required_argument, 0, 0 },
-			{ "aead_op", required_argument, 0, 0 },
-			{ "aead_key", required_argument, 0, 0 },
-			{ "aead_key_random_size", required_argument, 0, 0 },
-			{ "aead_iv", required_argument, 0, 0 },
-			{ "aead_iv_random_size", required_argument, 0, 0 },
-
-			{ "aad", required_argument, 0, 0 },
-			{ "aad_random_size", required_argument, 0, 0 },
-
-			{ "digest_size", required_argument, 0, 0 },
-
-			{ "sessionless", no_argument, 0, 0 },
-			{ "cryptodev_mask", required_argument, 0, 0},
-
-			{ "mac-updating", no_argument, 0, 0},
-			{ "no-mac-updating", no_argument, 0, 0},
-
-			{ NULL, 0, 0, 0 }
-	};
-
-	l2fwd_crypto_default_options(options);
-
-	while ((opt = getopt_long(argc, argvopt, "p:q:sT:", lgopts,
-			&option_index)) != EOF) {
-		switch (opt) {
-		/* long options */
-		case 0:
-			retval = l2fwd_crypto_parse_args_long_options(options,
-					lgopts, option_index);
-			if (retval < 0) {
-				l2fwd_crypto_usage(prgname);
-				return -1;
-			}
-			break;
-
-		/* portmask */
-		case 'p':
-			retval = l2fwd_crypto_parse_portmask(options, optarg);
-			if (retval < 0) {
-				l2fwd_crypto_usage(prgname);
-				return -1;
-			}
-			break;
-
-		/* nqueue */
-		case 'q':
-			retval = l2fwd_crypto_parse_nqueue(options, optarg);
-			if (retval < 0) {
-				l2fwd_crypto_usage(prgname);
-				return -1;
-			}
-			break;
-
-		/* single  */
-		case 's':
-			options->single_lcore = 1;
-
-			break;
-
-		/* timer period */
-		case 'T':
-			retval = l2fwd_crypto_parse_timer_period(options,
-					optarg);
-			if (retval < 0) {
-				l2fwd_crypto_usage(prgname);
-				return -1;
-			}
-			break;
-
-		default:
-			l2fwd_crypto_usage(prgname);
-			return -1;
-		}
-	}
-
-
-	if (optind >= 0)
-		argv[optind-1] = prgname;
-
-	retval = optind-1;
-	optind = 1; /* reset getopt lib */
-
-	return retval;
-}
-
-/* Check the link status of all ports in up to 9s, and print them finally */
-static void
-check_all_ports_link_status(uint32_t port_mask)
-{
-#define CHECK_INTERVAL 100 /* 100ms */
-#define MAX_CHECK_TIME 90 /* 9s (90 * 100ms) in total */
-	uint16_t portid;
-	uint8_t count, all_ports_up, print_flag = 0;
-	struct rte_eth_link link;
-
-	printf("\nChecking link status");
-	fflush(stdout);
-	for (count = 0; count <= MAX_CHECK_TIME; count++) {
-		all_ports_up = 1;
-		RTE_ETH_FOREACH_DEV(portid) {
-			if ((port_mask & (1 << portid)) == 0)
-				continue;
-			memset(&link, 0, sizeof(link));
-			rte_eth_link_get_nowait(portid, &link);
-			/* print link status if flag set */
-			if (print_flag == 1) {
-				if (link.link_status)
-					printf(
-					"Port%d Link Up. Speed %u Mbps - %s\n",
-						portid, link.link_speed,
-				(link.link_duplex == ETH_LINK_FULL_DUPLEX) ?
-					("full-duplex") : ("half-duplex\n"));
-				else
-					printf("Port %d Link Down\n", portid);
-				continue;
-			}
-			/* clear all_ports_up flag if any link down */
-			if (link.link_status == ETH_LINK_DOWN) {
-				all_ports_up = 0;
-				break;
-			}
-		}
-		/* after finally printing all link status, get out */
-		if (print_flag == 1)
-			break;
-
-		if (all_ports_up == 0) {
-			printf(".");
-			fflush(stdout);
-			rte_delay_ms(CHECK_INTERVAL);
-		}
-
-		/* set the print_flag if all ports up or timeout */
-		if (all_ports_up == 1 || count == (MAX_CHECK_TIME - 1)) {
-			print_flag = 1;
-			printf("done\n");
-		}
-	}
-}
-
-/* Check if device has to be HW/SW or any */
-static int
-check_type(const struct l2fwd_crypto_options *options,
-		const struct rte_cryptodev_info *dev_info)
-{
-	if (options->type == CDEV_TYPE_HW &&
-			(dev_info->feature_flags & RTE_CRYPTODEV_FF_HW_ACCELERATED))
-		return 0;
-	if (options->type == CDEV_TYPE_SW &&
-			!(dev_info->feature_flags & RTE_CRYPTODEV_FF_HW_ACCELERATED))
-		return 0;
-	if (options->type == CDEV_TYPE_ANY)
-		return 0;
-
-	return -1;
-}
-
-static const struct rte_cryptodev_capabilities *
-check_device_support_cipher_algo(const struct l2fwd_crypto_options *options,
-		const struct rte_cryptodev_info *dev_info,
-		uint8_t cdev_id)
-{
-	unsigned int i = 0;
-	const struct rte_cryptodev_capabilities *cap = &dev_info->capabilities[0];
-	enum rte_crypto_cipher_algorithm cap_cipher_algo;
-	enum rte_crypto_cipher_algorithm opt_cipher_algo =
-					options->cipher_xform.cipher.algo;
-
-	while (cap->op != RTE_CRYPTO_OP_TYPE_UNDEFINED) {
-		cap_cipher_algo = cap->sym.cipher.algo;
-		if (cap->sym.xform_type == RTE_CRYPTO_SYM_XFORM_CIPHER) {
-			if (cap_cipher_algo == opt_cipher_algo) {
-				if (check_type(options, dev_info) == 0)
-					break;
-			}
-		}
-		cap = &dev_info->capabilities[++i];
-	}
-
-	if (cap->op == RTE_CRYPTO_OP_TYPE_UNDEFINED) {
-		printf("Algorithm %s not supported by cryptodev %u"
-			" or device not of preferred type (%s)\n",
-			rte_crypto_cipher_algorithm_strings[opt_cipher_algo],
-			cdev_id,
-			options->string_type);
-		return NULL;
-	}
-
-	return cap;
-}
-
-static const struct rte_cryptodev_capabilities *
-check_device_support_auth_algo(const struct l2fwd_crypto_options *options,
-		const struct rte_cryptodev_info *dev_info,
-		uint8_t cdev_id)
-{
-	unsigned int i = 0;
-	const struct rte_cryptodev_capabilities *cap = &dev_info->capabilities[0];
-	enum rte_crypto_auth_algorithm cap_auth_algo;
-	enum rte_crypto_auth_algorithm opt_auth_algo =
-					options->auth_xform.auth.algo;
-
-	while (cap->op != RTE_CRYPTO_OP_TYPE_UNDEFINED) {
-		cap_auth_algo = cap->sym.auth.algo;
-		if (cap->sym.xform_type == RTE_CRYPTO_SYM_XFORM_AUTH) {
-			if (cap_auth_algo == opt_auth_algo) {
-				if (check_type(options, dev_info) == 0)
-					break;
-			}
-		}
-		cap = &dev_info->capabilities[++i];
-	}
-
-	if (cap->op == RTE_CRYPTO_OP_TYPE_UNDEFINED) {
-		printf("Algorithm %s not supported by cryptodev %u"
-			" or device not of preferred type (%s)\n",
-			rte_crypto_auth_algorithm_strings[opt_auth_algo],
-			cdev_id,
-			options->string_type);
-		return NULL;
-	}
-
-	return cap;
-}
-
-static const struct rte_cryptodev_capabilities *
-check_device_support_aead_algo(const struct l2fwd_crypto_options *options,
-		const struct rte_cryptodev_info *dev_info,
-		uint8_t cdev_id)
-{
-	unsigned int i = 0;
-	const struct rte_cryptodev_capabilities *cap = &dev_info->capabilities[0];
-	enum rte_crypto_aead_algorithm cap_aead_algo;
-	enum rte_crypto_aead_algorithm opt_aead_algo =
-					options->aead_xform.aead.algo;
-
-	while (cap->op != RTE_CRYPTO_OP_TYPE_UNDEFINED) {
-		cap_aead_algo = cap->sym.aead.algo;
-		if (cap->sym.xform_type == RTE_CRYPTO_SYM_XFORM_AEAD) {
-			if (cap_aead_algo == opt_aead_algo) {
-				if (check_type(options, dev_info) == 0)
-					break;
-			}
-		}
-		cap = &dev_info->capabilities[++i];
-	}
-
-	if (cap->op == RTE_CRYPTO_OP_TYPE_UNDEFINED) {
-		printf("Algorithm %s not supported by cryptodev %u"
-			" or device not of preferred type (%s)\n",
-			rte_crypto_aead_algorithm_strings[opt_aead_algo],
-			cdev_id,
-			options->string_type);
-		return NULL;
-	}
-
-	return cap;
-}
-
-/* Check if the device is enabled by cryptodev_mask */
-static int
-check_cryptodev_mask(struct l2fwd_crypto_options *options,
-		uint8_t cdev_id)
-{
-	if (options->cryptodev_mask & (1 << cdev_id))
-		return 0;
-
-	return -1;
-}
-
-static inline int
-check_supported_size(uint16_t length, uint16_t min, uint16_t max,
-		uint16_t increment)
-{
-	uint16_t supp_size;
-
-	/* Single value */
-	if (increment == 0) {
-		if (length == min)
-			return 0;
-		else
-			return -1;
-	}
-
-	/* Range of values */
-	for (supp_size = min; supp_size <= max; supp_size += increment) {
-		if (length == supp_size)
-			return 0;
-	}
-
-	return -1;
-}
-
-static int
-check_iv_param(const struct rte_crypto_param_range *iv_range_size,
-		unsigned int iv_param, int iv_random_size,
-		uint16_t *iv_length)
-{
-	/*
-	 * Check if length of provided IV is supported
-	 * by the algorithm chosen.
-	 */
-	if (iv_param) {
-		if (check_supported_size(*iv_length,
-				iv_range_size->min,
-				iv_range_size->max,
-				iv_range_size->increment)
-					!= 0) {
-			printf("Unsupported IV length\n");
-			return -1;
-		}
-	/*
-	 * Check if length of IV to be randomly generated
-	 * is supported by the algorithm chosen.
-	 */
-	} else if (iv_random_size != -1) {
-		if (check_supported_size(iv_random_size,
-				iv_range_size->min,
-				iv_range_size->max,
-				iv_range_size->increment)
-					!= 0) {
-			printf("Unsupported IV length\n");
-			return -1;
-		}
-		*iv_length = iv_random_size;
-	/* No size provided, use minimum size. */
-	} else
-		*iv_length = iv_range_size->min;
-
-	return 0;
-}
-
-static int
-initialize_cryptodevs(struct l2fwd_crypto_options *options, unsigned nb_ports,
-		uint8_t *enabled_cdevs)
-{
-	unsigned int cdev_id, cdev_count, enabled_cdev_count = 0;
-	const struct rte_cryptodev_capabilities *cap;
-	unsigned int sess_sz, max_sess_sz = 0;
-	int retval;
-
-	cdev_count = rte_cryptodev_count();
-	if (cdev_count == 0) {
-		printf("No crypto devices available\n");
-		return -1;
-	}
-
-	for (cdev_id = 0; cdev_id < cdev_count; cdev_id++) {
-		sess_sz = rte_cryptodev_get_private_session_size(cdev_id);
-		if (sess_sz > max_sess_sz)
-			max_sess_sz = sess_sz;
-	}
-
-	for (cdev_id = 0; cdev_id < cdev_count && enabled_cdev_count < nb_ports;
-			cdev_id++) {
-		struct rte_cryptodev_qp_conf qp_conf;
-		struct rte_cryptodev_info dev_info;
-		retval = rte_cryptodev_socket_id(cdev_id);
-
-		if (retval < 0) {
-			printf("Invalid crypto device id used\n");
-			return -1;
-		}
-
-		uint8_t socket_id = (uint8_t) retval;
-
-		struct rte_cryptodev_config conf = {
-			.nb_queue_pairs = 1,
-			.socket_id = socket_id,
-		};
-
-		if (check_cryptodev_mask(options, (uint8_t)cdev_id))
-			continue;
-
-		rte_cryptodev_info_get(cdev_id, &dev_info);
-
-		if (session_pool_socket[socket_id] == NULL) {
-			char mp_name[RTE_MEMPOOL_NAMESIZE];
-			struct rte_mempool *sess_mp;
-
-			snprintf(mp_name, RTE_MEMPOOL_NAMESIZE,
-				"sess_mp_%u", socket_id);
-
-			/*
-			 * Create enough objects for session headers and
-			 * device private data
-			 */
-			sess_mp = rte_mempool_create(mp_name,
-						MAX_SESSIONS * 2,
-						max_sess_sz,
-						SESSION_POOL_CACHE_SIZE,
-						0, NULL, NULL, NULL,
-						NULL, socket_id,
-						0);
-
-			if (sess_mp == NULL) {
-				printf("Cannot create session pool on socket %d\n",
-					socket_id);
-				return -ENOMEM;
-			}
-
-			printf("Allocated session pool on socket %d\n", socket_id);
-			session_pool_socket[socket_id] = sess_mp;
-		}
-
-		/* Set AEAD parameters */
-		if (options->xform_chain == L2FWD_CRYPTO_AEAD) {
-			/* Check if device supports AEAD algo */
-			cap = check_device_support_aead_algo(options, &dev_info,
-							cdev_id);
-			if (cap == NULL)
-				continue;
-
-			options->block_size = cap->sym.aead.block_size;
-
-			check_iv_param(&cap->sym.aead.iv_size,
-					options->aead_iv_param,
-					options->aead_iv_random_size,
-					&options->aead_iv.length);
-
-			/*
-			 * Check if length of provided AEAD key is supported
-			 * by the algorithm chosen.
-			 */
-			if (options->aead_key_param) {
-				if (check_supported_size(
-						options->aead_xform.aead.key.length,
-						cap->sym.aead.key_size.min,
-						cap->sym.aead.key_size.max,
-						cap->sym.aead.key_size.increment)
-							!= 0) {
-					printf("Unsupported aead key length\n");
-					return -1;
-				}
-			/*
-			 * Check if length of the aead key to be randomly generated
-			 * is supported by the algorithm chosen.
-			 */
-			} else if (options->aead_key_random_size != -1) {
-				if (check_supported_size(options->aead_key_random_size,
-						cap->sym.aead.key_size.min,
-						cap->sym.aead.key_size.max,
-						cap->sym.aead.key_size.increment)
-							!= 0) {
-					printf("Unsupported aead key length\n");
-					return -1;
-				}
-				options->aead_xform.aead.key.length =
-							options->aead_key_random_size;
-			/* No size provided, use minimum size. */
-			} else
-				options->aead_xform.aead.key.length =
-						cap->sym.aead.key_size.min;
-
-			if (!options->aead_key_param)
-				generate_random_key(
-					options->aead_xform.aead.key.data,
-					options->aead_xform.aead.key.length);
-
-			/*
-			 * Check if length of provided AAD is supported
-			 * by the algorithm chosen.
-			 */
-			if (options->aad_param) {
-				if (check_supported_size(options->aad.length,
-						cap->sym.aead.aad_size.min,
-						cap->sym.aead.aad_size.max,
-						cap->sym.aead.aad_size.increment)
-							!= 0) {
-					printf("Unsupported AAD length\n");
-					return -1;
-				}
-			/*
-			 * Check if length of AAD to be randomly generated
-			 * is supported by the algorithm chosen.
-			 */
-			} else if (options->aad_random_size != -1) {
-				if (check_supported_size(options->aad_random_size,
-						cap->sym.aead.aad_size.min,
-						cap->sym.aead.aad_size.max,
-						cap->sym.aead.aad_size.increment)
-							!= 0) {
-					printf("Unsupported AAD length\n");
-					return -1;
-				}
-				options->aad.length = options->aad_random_size;
-			/* No size provided, use minimum size. */
-			} else
-				options->aad.length = cap->sym.auth.aad_size.min;
-
-			options->aead_xform.aead.aad_length =
-						options->aad.length;
-
-			/* Check if digest size is supported by the algorithm. */
-			if (options->digest_size != -1) {
-				if (check_supported_size(options->digest_size,
-						cap->sym.aead.digest_size.min,
-						cap->sym.aead.digest_size.max,
-						cap->sym.aead.digest_size.increment)
-							!= 0) {
-					printf("Unsupported digest length\n");
-					return -1;
-				}
-				options->aead_xform.aead.digest_length =
-							options->digest_size;
-			/* No size provided, use minimum size. */
-			} else
-				options->aead_xform.aead.digest_length =
-						cap->sym.aead.digest_size.min;
-		}
-
-		/* Set cipher parameters */
-		if (options->xform_chain == L2FWD_CRYPTO_CIPHER_HASH ||
-				options->xform_chain == L2FWD_CRYPTO_HASH_CIPHER ||
-				options->xform_chain == L2FWD_CRYPTO_CIPHER_ONLY) {
-			/* Check if device supports cipher algo */
-			cap = check_device_support_cipher_algo(options, &dev_info,
-							cdev_id);
-			if (cap == NULL)
-				continue;
-
-			options->block_size = cap->sym.cipher.block_size;
-
-			check_iv_param(&cap->sym.cipher.iv_size,
-					options->cipher_iv_param,
-					options->cipher_iv_random_size,
-					&options->cipher_iv.length);
-
-			/*
-			 * Check if length of provided cipher key is supported
-			 * by the algorithm chosen.
-			 */
-			if (options->ckey_param) {
-				if (check_supported_size(
-						options->cipher_xform.cipher.key.length,
-						cap->sym.cipher.key_size.min,
-						cap->sym.cipher.key_size.max,
-						cap->sym.cipher.key_size.increment)
-							!= 0) {
-					printf("Unsupported cipher key length\n");
-					return -1;
-				}
-			/*
-			 * Check if length of the cipher key to be randomly generated
-			 * is supported by the algorithm chosen.
-			 */
-			} else if (options->ckey_random_size != -1) {
-				if (check_supported_size(options->ckey_random_size,
-						cap->sym.cipher.key_size.min,
-						cap->sym.cipher.key_size.max,
-						cap->sym.cipher.key_size.increment)
-							!= 0) {
-					printf("Unsupported cipher key length\n");
-					return -1;
-				}
-				options->cipher_xform.cipher.key.length =
-							options->ckey_random_size;
-			/* No size provided, use minimum size. */
-			} else
-				options->cipher_xform.cipher.key.length =
-						cap->sym.cipher.key_size.min;
-
-			if (!options->ckey_param)
-				generate_random_key(
-					options->cipher_xform.cipher.key.data,
-					options->cipher_xform.cipher.key.length);
-
-		}
-
-		/* Set auth parameters */
-		if (options->xform_chain == L2FWD_CRYPTO_CIPHER_HASH ||
-				options->xform_chain == L2FWD_CRYPTO_HASH_CIPHER ||
-				options->xform_chain == L2FWD_CRYPTO_HASH_ONLY) {
-			/* Check if device supports auth algo */
-			cap = check_device_support_auth_algo(options, &dev_info,
-							cdev_id);
-			if (cap == NULL)
-				continue;
-
-			check_iv_param(&cap->sym.auth.iv_size,
-					options->auth_iv_param,
-					options->auth_iv_random_size,
-					&options->auth_iv.length);
-			/*
-			 * Check if length of provided auth key is supported
-			 * by the algorithm chosen.
-			 */
-			if (options->akey_param) {
-				if (check_supported_size(
-						options->auth_xform.auth.key.length,
-						cap->sym.auth.key_size.min,
-						cap->sym.auth.key_size.max,
-						cap->sym.auth.key_size.increment)
-							!= 0) {
-					printf("Unsupported auth key length\n");
-					return -1;
-				}
-			/*
-			 * Check if length of the auth key to be randomly generated
-			 * is supported by the algorithm chosen.
-			 */
-			} else if (options->akey_random_size != -1) {
-				if (check_supported_size(options->akey_random_size,
-						cap->sym.auth.key_size.min,
-						cap->sym.auth.key_size.max,
-						cap->sym.auth.key_size.increment)
-							!= 0) {
-					printf("Unsupported auth key length\n");
-					return -1;
-				}
-				options->auth_xform.auth.key.length =
-							options->akey_random_size;
-			/* No size provided, use minimum size. */
-			} else
-				options->auth_xform.auth.key.length =
-						cap->sym.auth.key_size.min;
-
-			if (!options->akey_param)
-				generate_random_key(
-					options->auth_xform.auth.key.data,
-					options->auth_xform.auth.key.length);
-
-			/* Check if digest size is supported by the algorithm. */
-			if (options->digest_size != -1) {
-				if (check_supported_size(options->digest_size,
-						cap->sym.auth.digest_size.min,
-						cap->sym.auth.digest_size.max,
-						cap->sym.auth.digest_size.increment)
-							!= 0) {
-					printf("Unsupported digest length\n");
-					return -1;
-				}
-				options->auth_xform.auth.digest_length =
-							options->digest_size;
-			/* No size provided, use minimum size. */
-			} else
-				options->auth_xform.auth.digest_length =
-						cap->sym.auth.digest_size.min;
-		}
-
-		retval = rte_cryptodev_configure(cdev_id, &conf);
-		if (retval < 0) {
-			printf("Failed to configure cryptodev %u", cdev_id);
-			return -1;
-		}
-
-		qp_conf.nb_descriptors = 2048;
-
-		retval = rte_cryptodev_queue_pair_setup(cdev_id, 0, &qp_conf,
-				socket_id, session_pool_socket[socket_id]);
-		if (retval < 0) {
-			printf("Failed to setup queue pair %u on cryptodev %u",
-					0, cdev_id);
-			return -1;
-		}
-
-		retval = rte_cryptodev_start(cdev_id);
-		if (retval < 0) {
-			printf("Failed to start device %u: error %d\n",
-					cdev_id, retval);
-			return -1;
-		}
-
-		l2fwd_enabled_crypto_mask |= (((uint64_t)1) << cdev_id);
-
-		enabled_cdevs[cdev_id] = 1;
-		enabled_cdev_count++;
-	}
-
-	return enabled_cdev_count;
-}
-
-static int
-initialize_ports(struct l2fwd_crypto_options *options)
-{
-	uint16_t last_portid = 0, portid;
-	unsigned enabled_portcount = 0;
-	unsigned nb_ports = rte_eth_dev_count();
-
-	if (nb_ports == 0) {
-		printf("No Ethernet ports - bye\n");
-		return -1;
-	}
-
-	/* Reset l2fwd_dst_ports */
-	for (portid = 0; portid < RTE_MAX_ETHPORTS; portid++)
-		l2fwd_dst_ports[portid] = 0;
-
-	RTE_ETH_FOREACH_DEV(portid) {
-		int retval;
-		struct rte_eth_dev_info dev_info;
-		struct rte_eth_rxconf rxq_conf;
-		struct rte_eth_txconf txq_conf;
-		struct rte_eth_conf local_port_conf = port_conf;
-
-		/* Skip ports that are not enabled */
-		if ((options->portmask & (1 << portid)) == 0)
-			continue;
-
-		/* init port */
-		printf("Initializing port %u... ", portid);
-		fflush(stdout);
-		rte_eth_dev_info_get(portid, &dev_info);
-		if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-			local_port_conf.txmode.offloads |=
-				DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-		retval = rte_eth_dev_configure(portid, 1, 1, &local_port_conf);
-		if (retval < 0) {
-			printf("Cannot configure device: err=%d, port=%u\n",
-				  retval, portid);
-			return -1;
-		}
-
-		retval = rte_eth_dev_adjust_nb_rx_tx_desc(portid, &nb_rxd,
-							  &nb_txd);
-		if (retval < 0) {
-			printf("Cannot adjust number of descriptors: err=%d, port=%u\n",
-				retval, portid);
-			return -1;
-		}
-
-		/* init one RX queue */
-		fflush(stdout);
-		rxq_conf = dev_info.default_rxconf;
-		rxq_conf.offloads = local_port_conf.rxmode.offloads;
-		retval = rte_eth_rx_queue_setup(portid, 0, nb_rxd,
-					     rte_eth_dev_socket_id(portid),
-					     &rxq_conf, l2fwd_pktmbuf_pool);
-		if (retval < 0) {
-			printf("rte_eth_rx_queue_setup:err=%d, port=%u\n",
-					retval, portid);
-			return -1;
-		}
-
-		/* init one TX queue on each port */
-		fflush(stdout);
-		txq_conf = dev_info.default_txconf;
-		txq_conf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-		txq_conf.offloads = local_port_conf.txmode.offloads;
-		retval = rte_eth_tx_queue_setup(portid, 0, nb_txd,
-				rte_eth_dev_socket_id(portid),
-				&txq_conf);
-		if (retval < 0) {
-			printf("rte_eth_tx_queue_setup:err=%d, port=%u\n",
-				retval, portid);
-
-			return -1;
-		}
-
-		/* Start device */
-		retval = rte_eth_dev_start(portid);
-		if (retval < 0) {
-			printf("rte_eth_dev_start:err=%d, port=%u\n",
-					retval, portid);
-			return -1;
-		}
-
-		rte_eth_promiscuous_enable(portid);
-
-		rte_eth_macaddr_get(portid, &l2fwd_ports_eth_addr[portid]);
-
-		printf("Port %u, MAC address: %02X:%02X:%02X:%02X:%02X:%02X\n\n",
-				portid,
-				l2fwd_ports_eth_addr[portid].addr_bytes[0],
-				l2fwd_ports_eth_addr[portid].addr_bytes[1],
-				l2fwd_ports_eth_addr[portid].addr_bytes[2],
-				l2fwd_ports_eth_addr[portid].addr_bytes[3],
-				l2fwd_ports_eth_addr[portid].addr_bytes[4],
-				l2fwd_ports_eth_addr[portid].addr_bytes[5]);
-
-		/* initialize port stats */
-		memset(&port_statistics, 0, sizeof(port_statistics));
-
-		/* Setup port forwarding table */
-		if (enabled_portcount % 2) {
-			l2fwd_dst_ports[portid] = last_portid;
-			l2fwd_dst_ports[last_portid] = portid;
-		} else {
-			last_portid = portid;
-		}
-
-		l2fwd_enabled_port_mask |= (1 << portid);
-		enabled_portcount++;
-	}
-
-	if (enabled_portcount == 1) {
-		l2fwd_dst_ports[last_portid] = last_portid;
-	} else if (enabled_portcount % 2) {
-		printf("odd number of ports in portmask- bye\n");
-		return -1;
-	}
-
-	check_all_ports_link_status(l2fwd_enabled_port_mask);
-
-	return enabled_portcount;
-}
-
-static void
-reserve_key_memory(struct l2fwd_crypto_options *options)
-{
-	options->cipher_xform.cipher.key.data = rte_malloc("crypto key",
-						MAX_KEY_SIZE, 0);
-	if (options->cipher_xform.cipher.key.data == NULL)
-		rte_exit(EXIT_FAILURE, "Failed to allocate memory for cipher key");
-
-	options->auth_xform.auth.key.data = rte_malloc("auth key",
-						MAX_KEY_SIZE, 0);
-	if (options->auth_xform.auth.key.data == NULL)
-		rte_exit(EXIT_FAILURE, "Failed to allocate memory for auth key");
-
-	options->aead_xform.aead.key.data = rte_malloc("aead key",
-						MAX_KEY_SIZE, 0);
-	if (options->aead_xform.aead.key.data == NULL)
-		rte_exit(EXIT_FAILURE, "Failed to allocate memory for AEAD key");
-
-	options->cipher_iv.data = rte_malloc("cipher iv", MAX_KEY_SIZE, 0);
-	if (options->cipher_iv.data == NULL)
-		rte_exit(EXIT_FAILURE, "Failed to allocate memory for cipher IV");
-
-	options->auth_iv.data = rte_malloc("auth iv", MAX_KEY_SIZE, 0);
-	if (options->auth_iv.data == NULL)
-		rte_exit(EXIT_FAILURE, "Failed to allocate memory for auth IV");
-
-	options->aead_iv.data = rte_malloc("aead_iv", MAX_KEY_SIZE, 0);
-	if (options->aead_iv.data == NULL)
-		rte_exit(EXIT_FAILURE, "Failed to allocate memory for AEAD iv");
-
-	options->aad.data = rte_malloc("aad", MAX_KEY_SIZE, 0);
-	if (options->aad.data == NULL)
-		rte_exit(EXIT_FAILURE, "Failed to allocate memory for AAD");
-	options->aad.phys_addr = rte_malloc_virt2iova(options->aad.data);
-}
-
-int
-main(int argc, char **argv)
-{
-	struct lcore_queue_conf *qconf = NULL;
-	struct l2fwd_crypto_options options;
-
-	uint8_t nb_cryptodevs, cdev_id;
-	uint16_t portid;
-	unsigned lcore_id, rx_lcore_id = 0;
-	int ret, enabled_cdevcount, enabled_portcount;
-	uint8_t enabled_cdevs[RTE_CRYPTO_MAX_DEVS] = {0};
-
-	/* init EAL */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid EAL arguments\n");
-	argc -= ret;
-	argv += ret;
-
-	/* reserve memory for Cipher/Auth key and IV */
-	reserve_key_memory(&options);
-
-	/* parse application arguments (after the EAL ones) */
-	ret = l2fwd_crypto_parse_args(&options, argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid L2FWD-CRYPTO arguments\n");
-
-	printf("MAC updating %s\n",
-			options.mac_updating ? "enabled" : "disabled");
-
-	/* create the mbuf pool */
-	l2fwd_pktmbuf_pool = rte_pktmbuf_pool_create("mbuf_pool", NB_MBUF, 512,
-			sizeof(struct rte_crypto_op),
-			RTE_MBUF_DEFAULT_BUF_SIZE, rte_socket_id());
-	if (l2fwd_pktmbuf_pool == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot create mbuf pool\n");
-
-	/* create crypto op pool */
-	l2fwd_crypto_op_pool = rte_crypto_op_pool_create("crypto_op_pool",
-			RTE_CRYPTO_OP_TYPE_SYMMETRIC, NB_MBUF, 128, MAXIMUM_IV_LENGTH,
-			rte_socket_id());
-	if (l2fwd_crypto_op_pool == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot create crypto op pool\n");
-
-	/* Enable Ethernet ports */
-	enabled_portcount = initialize_ports(&options);
-	if (enabled_portcount < 1)
-		rte_exit(EXIT_FAILURE, "Failed to initial Ethernet ports\n");
-
-	/* Initialize the port/queue configuration of each logical core */
-	RTE_ETH_FOREACH_DEV(portid) {
-
-		/* skip ports that are not enabled */
-		if ((options.portmask & (1 << portid)) == 0)
-			continue;
-
-		if (options.single_lcore && qconf == NULL) {
-			while (rte_lcore_is_enabled(rx_lcore_id) == 0) {
-				rx_lcore_id++;
-				if (rx_lcore_id >= RTE_MAX_LCORE)
-					rte_exit(EXIT_FAILURE,
-							"Not enough cores\n");
-			}
-		} else if (!options.single_lcore) {
-			/* get the lcore_id for this port */
-			while (rte_lcore_is_enabled(rx_lcore_id) == 0 ||
-			       lcore_queue_conf[rx_lcore_id].nb_rx_ports ==
-			       options.nb_ports_per_lcore) {
-				rx_lcore_id++;
-				if (rx_lcore_id >= RTE_MAX_LCORE)
-					rte_exit(EXIT_FAILURE,
-							"Not enough cores\n");
-			}
-		}
-
-		/* Assigned a new logical core in the loop above. */
-		if (qconf != &lcore_queue_conf[rx_lcore_id])
-			qconf = &lcore_queue_conf[rx_lcore_id];
-
-		qconf->rx_port_list[qconf->nb_rx_ports] = portid;
-		qconf->nb_rx_ports++;
-
-		printf("Lcore %u: RX port %u\n", rx_lcore_id, portid);
-	}
-
-	/* Enable Crypto devices */
-	enabled_cdevcount = initialize_cryptodevs(&options, enabled_portcount,
-			enabled_cdevs);
-	if (enabled_cdevcount < 0)
-		rte_exit(EXIT_FAILURE, "Failed to initialize crypto devices\n");
-
-	if (enabled_cdevcount < enabled_portcount)
-		rte_exit(EXIT_FAILURE, "Number of capable crypto devices (%d) "
-				"has to be more or equal to number of ports (%d)\n",
-				enabled_cdevcount, enabled_portcount);
-
-	nb_cryptodevs = rte_cryptodev_count();
-
-	/* Initialize the port/cryptodev configuration of each logical core */
-	for (rx_lcore_id = 0, qconf = NULL, cdev_id = 0;
-			cdev_id < nb_cryptodevs && enabled_cdevcount;
-			cdev_id++) {
-		/* Crypto op not supported by crypto device */
-		if (!enabled_cdevs[cdev_id])
-			continue;
-
-		if (options.single_lcore && qconf == NULL) {
-			while (rte_lcore_is_enabled(rx_lcore_id) == 0) {
-				rx_lcore_id++;
-				if (rx_lcore_id >= RTE_MAX_LCORE)
-					rte_exit(EXIT_FAILURE,
-							"Not enough cores\n");
-			}
-		} else if (!options.single_lcore) {
-			/* get the lcore_id for this port */
-			while (rte_lcore_is_enabled(rx_lcore_id) == 0 ||
-			       lcore_queue_conf[rx_lcore_id].nb_crypto_devs ==
-			       options.nb_ports_per_lcore) {
-				rx_lcore_id++;
-				if (rx_lcore_id >= RTE_MAX_LCORE)
-					rte_exit(EXIT_FAILURE,
-							"Not enough cores\n");
-			}
-		}
-
-		/* Assigned a new logical core in the loop above. */
-		if (qconf != &lcore_queue_conf[rx_lcore_id])
-			qconf = &lcore_queue_conf[rx_lcore_id];
-
-		qconf->cryptodev_list[qconf->nb_crypto_devs] = cdev_id;
-		qconf->nb_crypto_devs++;
-
-		enabled_cdevcount--;
-
-		printf("Lcore %u: cryptodev %u\n", rx_lcore_id,
-				(unsigned)cdev_id);
-	}
-
-	/* launch per-lcore init on every lcore */
-	rte_eal_mp_remote_launch(l2fwd_launch_one_lcore, (void *)&options,
-			CALL_MASTER);
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		if (rte_eal_wait_lcore(lcore_id) < 0)
-			return -1;
-	}
-
-	return 0;
-}
diff --git a/examples/l2fwd-crypto/meson.build b/examples/l2fwd-crypto/meson.build
deleted file mode 100644
index 6c852ad..0000000
--- a/examples/l2fwd-crypto/meson.build
+++ /dev/null
@@ -1,13 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-deps += 'cryptodev'
-allow_experimental_apis = true
-sources = files(
-	'main.c'
-)
diff --git a/examples/l2fwd-jobstats/Makefile b/examples/l2fwd-jobstats/Makefile
deleted file mode 100644
index a9315d4..0000000
--- a/examples/l2fwd-jobstats/Makefile
+++ /dev/null
@@ -1,58 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2015 Intel Corporation
-
-# binary name
-APP = l2fwd-jobstats
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else # Build using legacy build system
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-endif
diff --git a/examples/l2fwd-jobstats/main.c b/examples/l2fwd-jobstats/main.c
deleted file mode 100644
index 2482248..0000000
--- a/examples/l2fwd-jobstats/main.c
+++ /dev/null
@@ -1,1006 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#include <locale.h>
-#include <stdlib.h>
-#include <string.h>
-#include <stdint.h>
-#include <ctype.h>
-#include <getopt.h>
-
-#include <rte_common.h>
-#include <rte_log.h>
-#include <rte_malloc.h>
-#include <rte_memory.h>
-#include <rte_memcpy.h>
-#include <rte_eal.h>
-#include <rte_launch.h>
-#include <rte_atomic.h>
-#include <rte_cycles.h>
-#include <rte_prefetch.h>
-#include <rte_lcore.h>
-#include <rte_per_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_interrupts.h>
-#include <rte_debug.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-#include <rte_spinlock.h>
-
-#include <rte_errno.h>
-#include <rte_jobstats.h>
-#include <rte_timer.h>
-#include <rte_alarm.h>
-#include <rte_pause.h>
-
-#define RTE_LOGTYPE_L2FWD RTE_LOGTYPE_USER1
-
-#define NB_MBUF   8192
-
-#define MAX_PKT_BURST 32
-#define BURST_TX_DRAIN_US 100 /* TX drain every ~100us */
-
-/*
- * Configurable number of RX/TX ring descriptors
- */
-#define RTE_TEST_RX_DESC_DEFAULT 1024
-#define RTE_TEST_TX_DESC_DEFAULT 1024
-static uint16_t nb_rxd = RTE_TEST_RX_DESC_DEFAULT;
-static uint16_t nb_txd = RTE_TEST_TX_DESC_DEFAULT;
-
-/* ethernet addresses of ports */
-static struct ether_addr l2fwd_ports_eth_addr[RTE_MAX_ETHPORTS];
-
-/* mask of enabled ports */
-static uint32_t l2fwd_enabled_port_mask;
-
-/* list of enabled ports */
-static uint32_t l2fwd_dst_ports[RTE_MAX_ETHPORTS];
-
-#define UPDATE_STEP_UP 1
-#define UPDATE_STEP_DOWN 32
-
-static unsigned int l2fwd_rx_queue_per_lcore = 1;
-
-#define MAX_RX_QUEUE_PER_LCORE 16
-#define MAX_TX_QUEUE_PER_PORT 16
-struct lcore_queue_conf {
-	unsigned n_rx_port;
-	unsigned rx_port_list[MAX_RX_QUEUE_PER_LCORE];
-	uint64_t next_flush_time[RTE_MAX_ETHPORTS];
-
-	struct rte_timer rx_timers[MAX_RX_QUEUE_PER_LCORE];
-	struct rte_jobstats port_fwd_jobs[MAX_RX_QUEUE_PER_LCORE];
-
-	struct rte_timer flush_timer;
-	struct rte_jobstats flush_job;
-	struct rte_jobstats idle_job;
-	struct rte_jobstats_context jobs_context;
-
-	rte_atomic16_t stats_read_pending;
-	rte_spinlock_t lock;
-} __rte_cache_aligned;
-struct lcore_queue_conf lcore_queue_conf[RTE_MAX_LCORE];
-
-struct rte_eth_dev_tx_buffer *tx_buffer[RTE_MAX_ETHPORTS];
-
-static struct rte_eth_conf port_conf = {
-	.rxmode = {
-		.split_hdr_size = 0,
-		.ignore_offload_bitfield = 1,
-		.offloads = DEV_RX_OFFLOAD_CRC_STRIP,
-	},
-	.txmode = {
-		.mq_mode = ETH_MQ_TX_NONE,
-	},
-};
-
-struct rte_mempool *l2fwd_pktmbuf_pool = NULL;
-
-/* Per-port statistics struct */
-struct l2fwd_port_statistics {
-	uint64_t tx;
-	uint64_t rx;
-	uint64_t dropped;
-} __rte_cache_aligned;
-struct l2fwd_port_statistics port_statistics[RTE_MAX_ETHPORTS];
-
-/* 1 day max */
-#define MAX_TIMER_PERIOD 86400
-/* default period is 10 seconds */
-static int64_t timer_period = 10;
-/* default timer frequency */
-static double hz;
-/* BURST_TX_DRAIN_US converted to cycles */
-uint64_t drain_tsc;
-/* Convert cycles to ns */
-static inline double
-cycles_to_ns(uint64_t cycles)
-{
-	double t = cycles;
-
-	t *= (double)NS_PER_S;
-	t /= hz;
-	return t;
-}
-
-static void
-show_lcore_stats(unsigned lcore_id)
-{
-	struct lcore_queue_conf *qconf = &lcore_queue_conf[lcore_id];
-	struct rte_jobstats_context *ctx = &qconf->jobs_context;
-	struct rte_jobstats *job;
-	uint8_t i;
-
-	/* LCore statistics. */
-	uint64_t stats_period, loop_count;
-	uint64_t exec, exec_min, exec_max;
-	uint64_t management, management_min, management_max;
-	uint64_t busy, busy_min, busy_max;
-
-	/* Jobs statistics. */
-	const uint16_t port_cnt = qconf->n_rx_port;
-	uint64_t jobs_exec_cnt[port_cnt], jobs_period[port_cnt];
-	uint64_t jobs_exec[port_cnt], jobs_exec_min[port_cnt],
-				jobs_exec_max[port_cnt];
-
-	uint64_t flush_exec_cnt, flush_period;
-	uint64_t flush_exec, flush_exec_min, flush_exec_max;
-
-	uint64_t idle_exec_cnt;
-	uint64_t idle_exec, idle_exec_min, idle_exec_max;
-	uint64_t collection_time = rte_get_timer_cycles();
-
-	/* Ask forwarding thread to give us stats. */
-	rte_atomic16_set(&qconf->stats_read_pending, 1);
-	rte_spinlock_lock(&qconf->lock);
-	rte_atomic16_set(&qconf->stats_read_pending, 0);
-
-	/* Collect context statistics. */
-	stats_period = ctx->state_time - ctx->start_time;
-	loop_count = ctx->loop_cnt;
-
-	exec = ctx->exec_time;
-	exec_min = ctx->min_exec_time;
-	exec_max = ctx->max_exec_time;
-
-	management = ctx->management_time;
-	management_min = ctx->min_management_time;
-	management_max = ctx->max_management_time;
-
-	rte_jobstats_context_reset(ctx);
-
-	for (i = 0; i < port_cnt; i++) {
-		job = &qconf->port_fwd_jobs[i];
-
-		jobs_exec_cnt[i] = job->exec_cnt;
-		jobs_period[i] = job->period;
-
-		jobs_exec[i] = job->exec_time;
-		jobs_exec_min[i] = job->min_exec_time;
-		jobs_exec_max[i] = job->max_exec_time;
-
-		rte_jobstats_reset(job);
-	}
-
-	flush_exec_cnt = qconf->flush_job.exec_cnt;
-	flush_period = qconf->flush_job.period;
-	flush_exec = qconf->flush_job.exec_time;
-	flush_exec_min = qconf->flush_job.min_exec_time;
-	flush_exec_max = qconf->flush_job.max_exec_time;
-	rte_jobstats_reset(&qconf->flush_job);
-
-	idle_exec_cnt = qconf->idle_job.exec_cnt;
-	idle_exec = qconf->idle_job.exec_time;
-	idle_exec_min = qconf->idle_job.min_exec_time;
-	idle_exec_max = qconf->idle_job.max_exec_time;
-	rte_jobstats_reset(&qconf->idle_job);
-
-	rte_spinlock_unlock(&qconf->lock);
-
-	exec -= idle_exec;
-	busy = exec + management;
-	busy_min = exec_min + management_min;
-	busy_max = exec_max + management_max;
-
-
-	collection_time = rte_get_timer_cycles() - collection_time;
-
-#define STAT_FMT "\n%-18s %'14.0f %6.1f%% %'10.0f %'10.0f %'10.0f"
-
-	printf("\n----------------"
-			"\nLCore %3u: statistics (time in ns, collected in %'9.0f)"
-			"\n%-18s %14s %7s %10s %10s %10s "
-			"\n%-18s %'14.0f"
-			"\n%-18s %'14" PRIu64
-			STAT_FMT /* Exec */
-			STAT_FMT /* Management */
-			STAT_FMT /* Busy */
-			STAT_FMT, /* Idle  */
-			lcore_id, cycles_to_ns(collection_time),
-			"Stat type", "total", "%total", "avg", "min", "max",
-			"Stats duration:", cycles_to_ns(stats_period),
-			"Loop count:", loop_count,
-			"Exec time",
-			cycles_to_ns(exec), exec * 100.0 / stats_period,
-			cycles_to_ns(loop_count  ? exec / loop_count : 0),
-			cycles_to_ns(exec_min),
-			cycles_to_ns(exec_max),
-			"Management time",
-			cycles_to_ns(management), management * 100.0 / stats_period,
-			cycles_to_ns(loop_count  ? management / loop_count : 0),
-			cycles_to_ns(management_min),
-			cycles_to_ns(management_max),
-			"Exec + management",
-			cycles_to_ns(busy),  busy * 100.0 / stats_period,
-			cycles_to_ns(loop_count ? busy / loop_count : 0),
-			cycles_to_ns(busy_min),
-			cycles_to_ns(busy_max),
-			"Idle (job)",
-			cycles_to_ns(idle_exec), idle_exec * 100.0 / stats_period,
-			cycles_to_ns(idle_exec_cnt ? idle_exec / idle_exec_cnt : 0),
-			cycles_to_ns(idle_exec_min),
-			cycles_to_ns(idle_exec_max));
-
-	for (i = 0; i < qconf->n_rx_port; i++) {
-		job = &qconf->port_fwd_jobs[i];
-		printf("\n\nJob %" PRIu32 ": %-20s "
-				"\n%-18s %'14" PRIu64
-				"\n%-18s %'14.0f"
-				STAT_FMT,
-				i, job->name,
-				"Exec count:", jobs_exec_cnt[i],
-				"Exec period: ", cycles_to_ns(jobs_period[i]),
-				"Exec time",
-				cycles_to_ns(jobs_exec[i]), jobs_exec[i] * 100.0 / stats_period,
-				cycles_to_ns(jobs_exec_cnt[i] ? jobs_exec[i] / jobs_exec_cnt[i]
-						: 0),
-				cycles_to_ns(jobs_exec_min[i]),
-				cycles_to_ns(jobs_exec_max[i]));
-	}
-
-	if (qconf->n_rx_port > 0) {
-		job = &qconf->flush_job;
-		printf("\n\nJob %" PRIu32 ": %-20s "
-				"\n%-18s %'14" PRIu64
-				"\n%-18s %'14.0f"
-				STAT_FMT,
-				i, job->name,
-				"Exec count:", flush_exec_cnt,
-				"Exec period: ", cycles_to_ns(flush_period),
-				"Exec time",
-				cycles_to_ns(flush_exec), flush_exec * 100.0 / stats_period,
-				cycles_to_ns(flush_exec_cnt ? flush_exec / flush_exec_cnt : 0),
-				cycles_to_ns(flush_exec_min),
-				cycles_to_ns(flush_exec_max));
-	}
-}
-
-/* Print out statistics on packets dropped */
-static void
-show_stats_cb(__rte_unused void *param)
-{
-	uint64_t total_packets_dropped, total_packets_tx, total_packets_rx;
-	unsigned portid, lcore_id;
-
-	total_packets_dropped = 0;
-	total_packets_tx = 0;
-	total_packets_rx = 0;
-
-	const char clr[] = { 27, '[', '2', 'J', '\0' };
-	const char topLeft[] = { 27, '[', '1', ';', '1', 'H', '\0' };
-
-	/* Clear screen and move to top left */
-	printf("%s%s"
-			"\nPort statistics ===================================",
-			clr, topLeft);
-
-	for (portid = 0; portid < RTE_MAX_ETHPORTS; portid++) {
-		/* skip disabled ports */
-		if ((l2fwd_enabled_port_mask & (1 << portid)) == 0)
-			continue;
-		printf("\nStatistics for port %u ------------------------------"
-				"\nPackets sent: %24"PRIu64
-				"\nPackets received: %20"PRIu64
-				"\nPackets dropped: %21"PRIu64,
-				portid,
-				port_statistics[portid].tx,
-				port_statistics[portid].rx,
-				port_statistics[portid].dropped);
-
-		total_packets_dropped += port_statistics[portid].dropped;
-		total_packets_tx += port_statistics[portid].tx;
-		total_packets_rx += port_statistics[portid].rx;
-	}
-
-	printf("\nAggregate statistics ==============================="
-			"\nTotal packets sent: %18"PRIu64
-			"\nTotal packets received: %14"PRIu64
-			"\nTotal packets dropped: %15"PRIu64
-			"\n====================================================",
-			total_packets_tx,
-			total_packets_rx,
-			total_packets_dropped);
-
-	RTE_LCORE_FOREACH(lcore_id) {
-		if (lcore_queue_conf[lcore_id].n_rx_port > 0)
-			show_lcore_stats(lcore_id);
-	}
-
-	printf("\n====================================================\n");
-	rte_eal_alarm_set(timer_period * US_PER_S, show_stats_cb, NULL);
-}
-
-static void
-l2fwd_simple_forward(struct rte_mbuf *m, unsigned portid)
-{
-	struct ether_hdr *eth;
-	void *tmp;
-	int sent;
-	unsigned dst_port;
-	struct rte_eth_dev_tx_buffer *buffer;
-
-	dst_port = l2fwd_dst_ports[portid];
-	eth = rte_pktmbuf_mtod(m, struct ether_hdr *);
-
-	/* 02:00:00:00:00:xx */
-	tmp = &eth->d_addr.addr_bytes[0];
-	*((uint64_t *)tmp) = 0x000000000002 + ((uint64_t)dst_port << 40);
-
-	/* src addr */
-	ether_addr_copy(&l2fwd_ports_eth_addr[dst_port], &eth->s_addr);
-
-	buffer = tx_buffer[dst_port];
-	sent = rte_eth_tx_buffer(dst_port, 0, buffer, m);
-	if (sent)
-		port_statistics[dst_port].tx += sent;
-}
-
-static void
-l2fwd_job_update_cb(struct rte_jobstats *job, int64_t result)
-{
-	int64_t err = job->target - result;
-	int64_t histeresis = job->target / 8;
-
-	if (err < -histeresis) {
-		if (job->min_period + UPDATE_STEP_DOWN < job->period)
-			job->period -= UPDATE_STEP_DOWN;
-	} else if (err > histeresis) {
-		if (job->period + UPDATE_STEP_UP < job->max_period)
-			job->period += UPDATE_STEP_UP;
-	}
-}
-
-static void
-l2fwd_fwd_job(__rte_unused struct rte_timer *timer, void *arg)
-{
-	struct rte_mbuf *pkts_burst[MAX_PKT_BURST];
-	struct rte_mbuf *m;
-
-	const uint16_t port_idx = (uintptr_t) arg;
-	const unsigned lcore_id = rte_lcore_id();
-	struct lcore_queue_conf *qconf = &lcore_queue_conf[lcore_id];
-	struct rte_jobstats *job = &qconf->port_fwd_jobs[port_idx];
-	const uint16_t portid = qconf->rx_port_list[port_idx];
-
-	uint8_t j;
-	uint16_t total_nb_rx;
-
-	rte_jobstats_start(&qconf->jobs_context, job);
-
-	/* Call rx burst 2 times. This allow rte_jobstats logic to see if this
-	 * function must be called more frequently. */
-
-	total_nb_rx = rte_eth_rx_burst(portid, 0, pkts_burst,
-			MAX_PKT_BURST);
-
-	for (j = 0; j < total_nb_rx; j++) {
-		m = pkts_burst[j];
-		rte_prefetch0(rte_pktmbuf_mtod(m, void *));
-		l2fwd_simple_forward(m, portid);
-	}
-
-	if (total_nb_rx == MAX_PKT_BURST) {
-		const uint16_t nb_rx = rte_eth_rx_burst(portid, 0, pkts_burst,
-				MAX_PKT_BURST);
-
-		total_nb_rx += nb_rx;
-		for (j = 0; j < nb_rx; j++) {
-			m = pkts_burst[j];
-			rte_prefetch0(rte_pktmbuf_mtod(m, void *));
-			l2fwd_simple_forward(m, portid);
-		}
-	}
-
-	port_statistics[portid].rx += total_nb_rx;
-
-	/* Adjust period time in which we are running here. */
-	if (rte_jobstats_finish(job, total_nb_rx) != 0) {
-		rte_timer_reset(&qconf->rx_timers[port_idx], job->period, PERIODICAL,
-				lcore_id, l2fwd_fwd_job, arg);
-	}
-}
-
-static void
-l2fwd_flush_job(__rte_unused struct rte_timer *timer, __rte_unused void *arg)
-{
-	uint64_t now;
-	unsigned lcore_id;
-	struct lcore_queue_conf *qconf;
-	uint16_t portid;
-	unsigned i;
-	uint32_t sent;
-	struct rte_eth_dev_tx_buffer *buffer;
-
-	lcore_id = rte_lcore_id();
-	qconf = &lcore_queue_conf[lcore_id];
-
-	rte_jobstats_start(&qconf->jobs_context, &qconf->flush_job);
-
-	now = rte_get_timer_cycles();
-	lcore_id = rte_lcore_id();
-	qconf = &lcore_queue_conf[lcore_id];
-
-	for (i = 0; i < qconf->n_rx_port; i++) {
-		portid = l2fwd_dst_ports[qconf->rx_port_list[i]];
-
-		if (qconf->next_flush_time[portid] <= now)
-			continue;
-
-		buffer = tx_buffer[portid];
-		sent = rte_eth_tx_buffer_flush(portid, 0, buffer);
-		if (sent)
-			port_statistics[portid].tx += sent;
-
-		qconf->next_flush_time[portid] = rte_get_timer_cycles() + drain_tsc;
-	}
-
-	/* Pass target to indicate that this job is happy of time interwal
-	 * in which it was called. */
-	rte_jobstats_finish(&qconf->flush_job, qconf->flush_job.target);
-}
-
-/* main processing loop */
-static void
-l2fwd_main_loop(void)
-{
-	unsigned lcore_id;
-	unsigned i, portid;
-	struct lcore_queue_conf *qconf;
-	uint8_t stats_read_pending = 0;
-	uint8_t need_manage;
-
-	lcore_id = rte_lcore_id();
-	qconf = &lcore_queue_conf[lcore_id];
-
-	if (qconf->n_rx_port == 0) {
-		RTE_LOG(INFO, L2FWD, "lcore %u has nothing to do\n", lcore_id);
-		return;
-	}
-
-	RTE_LOG(INFO, L2FWD, "entering main loop on lcore %u\n", lcore_id);
-
-	for (i = 0; i < qconf->n_rx_port; i++) {
-
-		portid = qconf->rx_port_list[i];
-		RTE_LOG(INFO, L2FWD, " -- lcoreid=%u portid=%u\n", lcore_id,
-			portid);
-	}
-
-	rte_jobstats_init(&qconf->idle_job, "idle", 0, 0, 0, 0);
-
-	for (;;) {
-		rte_spinlock_lock(&qconf->lock);
-
-		do {
-			rte_jobstats_context_start(&qconf->jobs_context);
-
-			/* Do the Idle job:
-			 * - Read stats_read_pending flag
-			 * - check if some real job need to be executed
-			 */
-			rte_jobstats_start(&qconf->jobs_context, &qconf->idle_job);
-
-			uint64_t repeats = 0;
-
-			do {
-				uint8_t i;
-				uint64_t now = rte_get_timer_cycles();
-
-				repeats++;
-				need_manage = qconf->flush_timer.expire < now;
-				/* Check if we was esked to give a stats. */
-				stats_read_pending =
-						rte_atomic16_read(&qconf->stats_read_pending);
-				need_manage |= stats_read_pending;
-
-				for (i = 0; i < qconf->n_rx_port && !need_manage; i++)
-					need_manage = qconf->rx_timers[i].expire < now;
-
-			} while (!need_manage);
-
-			if (likely(repeats != 1))
-				rte_jobstats_finish(&qconf->idle_job, qconf->idle_job.target);
-			else
-				rte_jobstats_abort(&qconf->idle_job);
-
-			rte_timer_manage();
-			rte_jobstats_context_finish(&qconf->jobs_context);
-		} while (likely(stats_read_pending == 0));
-
-		rte_spinlock_unlock(&qconf->lock);
-		rte_pause();
-	}
-}
-
-static int
-l2fwd_launch_one_lcore(__attribute__((unused)) void *dummy)
-{
-	l2fwd_main_loop();
-	return 0;
-}
-
-/* display usage */
-static void
-l2fwd_usage(const char *prgname)
-{
-	printf("%s [EAL options] -- -p PORTMASK [-q NQ]\n"
-	       "  -p PORTMASK: hexadecimal bitmask of ports to configure\n"
-	       "  -q NQ: number of queue (=ports) per lcore (default is 1)\n"
-		   "  -T PERIOD: statistics will be refreshed each PERIOD seconds (0 to disable, 10 default, 86400 maximum)\n"
-		   "  -l set system default locale instead of default (\"C\" locale) for thousands separator in stats.",
-	       prgname);
-}
-
-static int
-l2fwd_parse_portmask(const char *portmask)
-{
-	char *end = NULL;
-	unsigned long pm;
-
-	/* parse hexadecimal string */
-	pm = strtoul(portmask, &end, 16);
-	if ((portmask[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (pm == 0)
-		return -1;
-
-	return pm;
-}
-
-static unsigned int
-l2fwd_parse_nqueue(const char *q_arg)
-{
-	char *end = NULL;
-	unsigned long n;
-
-	/* parse hexadecimal string */
-	n = strtoul(q_arg, &end, 10);
-	if ((q_arg[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return 0;
-	if (n == 0)
-		return 0;
-	if (n >= MAX_RX_QUEUE_PER_LCORE)
-		return 0;
-
-	return n;
-}
-
-static int
-l2fwd_parse_timer_period(const char *q_arg)
-{
-	char *end = NULL;
-	int n;
-
-	/* parse number string */
-	n = strtol(q_arg, &end, 10);
-	if ((q_arg[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-	if (n >= MAX_TIMER_PERIOD)
-		return -1;
-
-	return n;
-}
-
-/* Parse the argument given in the command line of the application */
-static int
-l2fwd_parse_args(int argc, char **argv)
-{
-	int opt, ret;
-	char **argvopt;
-	int option_index;
-	char *prgname = argv[0];
-	static struct option lgopts[] = {
-		{NULL, 0, 0, 0}
-	};
-
-	argvopt = argv;
-
-	while ((opt = getopt_long(argc, argvopt, "p:q:T:l",
-				  lgopts, &option_index)) != EOF) {
-
-		switch (opt) {
-		/* portmask */
-		case 'p':
-			l2fwd_enabled_port_mask = l2fwd_parse_portmask(optarg);
-			if (l2fwd_enabled_port_mask == 0) {
-				printf("invalid portmask\n");
-				l2fwd_usage(prgname);
-				return -1;
-			}
-			break;
-
-		/* nqueue */
-		case 'q':
-			l2fwd_rx_queue_per_lcore = l2fwd_parse_nqueue(optarg);
-			if (l2fwd_rx_queue_per_lcore == 0) {
-				printf("invalid queue number\n");
-				l2fwd_usage(prgname);
-				return -1;
-			}
-			break;
-
-		/* timer period */
-		case 'T':
-			timer_period = l2fwd_parse_timer_period(optarg);
-			if (timer_period < 0) {
-				printf("invalid timer period\n");
-				l2fwd_usage(prgname);
-				return -1;
-			}
-			break;
-
-		/* For thousands separator in printf. */
-		case 'l':
-			setlocale(LC_ALL, "");
-			break;
-
-		/* long options */
-		case 0:
-			l2fwd_usage(prgname);
-			return -1;
-
-		default:
-			l2fwd_usage(prgname);
-			return -1;
-		}
-	}
-
-	if (optind >= 0)
-		argv[optind-1] = prgname;
-
-	ret = optind-1;
-	optind = 1; /* reset getopt lib */
-	return ret;
-}
-
-/* Check the link status of all ports in up to 9s, and print them finally */
-static void
-check_all_ports_link_status(uint32_t port_mask)
-{
-#define CHECK_INTERVAL 100 /* 100ms */
-#define MAX_CHECK_TIME 90 /* 9s (90 * 100ms) in total */
-	uint16_t portid;
-	uint8_t count, all_ports_up, print_flag = 0;
-	struct rte_eth_link link;
-
-	printf("\nChecking link status");
-	fflush(stdout);
-	for (count = 0; count <= MAX_CHECK_TIME; count++) {
-		all_ports_up = 1;
-		RTE_ETH_FOREACH_DEV(portid) {
-			if ((port_mask & (1 << portid)) == 0)
-				continue;
-			memset(&link, 0, sizeof(link));
-			rte_eth_link_get_nowait(portid, &link);
-			/* print link status if flag set */
-			if (print_flag == 1) {
-				if (link.link_status)
-					printf(
-					"Port%d Link Up. Speed %u Mbps - %s\n",
-						portid, link.link_speed,
-				(link.link_duplex == ETH_LINK_FULL_DUPLEX) ?
-					("full-duplex") : ("half-duplex\n"));
-				else
-					printf("Port %d Link Down\n", portid);
-				continue;
-			}
-			/* clear all_ports_up flag if any link down */
-			if (link.link_status == ETH_LINK_DOWN) {
-				all_ports_up = 0;
-				break;
-			}
-		}
-		/* after finally printing all link status, get out */
-		if (print_flag == 1)
-			break;
-
-		if (all_ports_up == 0) {
-			printf(".");
-			fflush(stdout);
-			rte_delay_ms(CHECK_INTERVAL);
-		}
-
-		/* set the print_flag if all ports up or timeout */
-		if (all_ports_up == 1 || count == (MAX_CHECK_TIME - 1)) {
-			print_flag = 1;
-			printf("done\n");
-		}
-	}
-}
-
-int
-main(int argc, char **argv)
-{
-	struct lcore_queue_conf *qconf;
-	unsigned lcore_id, rx_lcore_id;
-	unsigned nb_ports_in_mask = 0;
-	int ret;
-	char name[RTE_JOBSTATS_NAMESIZE];
-	uint16_t nb_ports;
-	uint16_t nb_ports_available = 0;
-	uint16_t portid, last_port;
-	uint8_t i;
-
-	/* init EAL */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid EAL arguments\n");
-	argc -= ret;
-	argv += ret;
-
-	/* parse application arguments (after the EAL ones) */
-	ret = l2fwd_parse_args(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid L2FWD arguments\n");
-
-	rte_timer_subsystem_init();
-
-	/* fetch default timer frequency. */
-	hz = rte_get_timer_hz();
-
-	/* create the mbuf pool */
-	l2fwd_pktmbuf_pool =
-		rte_pktmbuf_pool_create("mbuf_pool", NB_MBUF, 32,
-			0, RTE_MBUF_DEFAULT_BUF_SIZE, rte_socket_id());
-	if (l2fwd_pktmbuf_pool == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot init mbuf pool\n");
-
-	nb_ports = rte_eth_dev_count();
-	if (nb_ports == 0)
-		rte_exit(EXIT_FAILURE, "No Ethernet ports - bye\n");
-
-	/* reset l2fwd_dst_ports */
-	for (portid = 0; portid < RTE_MAX_ETHPORTS; portid++)
-		l2fwd_dst_ports[portid] = 0;
-	last_port = 0;
-
-	/*
-	 * Each logical core is assigned a dedicated TX queue on each port.
-	 */
-	RTE_ETH_FOREACH_DEV(portid) {
-		/* skip ports that are not enabled */
-		if ((l2fwd_enabled_port_mask & (1 << portid)) == 0)
-			continue;
-
-		if (nb_ports_in_mask % 2) {
-			l2fwd_dst_ports[portid] = last_port;
-			l2fwd_dst_ports[last_port] = portid;
-		} else
-			last_port = portid;
-
-		nb_ports_in_mask++;
-	}
-	if (nb_ports_in_mask % 2) {
-		printf("Notice: odd number of ports in portmask.\n");
-		l2fwd_dst_ports[last_port] = last_port;
-	}
-
-	rx_lcore_id = 0;
-	qconf = NULL;
-
-	/* Initialize the port/queue configuration of each logical core */
-	RTE_ETH_FOREACH_DEV(portid) {
-		/* skip ports that are not enabled */
-		if ((l2fwd_enabled_port_mask & (1 << portid)) == 0)
-			continue;
-
-		/* get the lcore_id for this port */
-		while (rte_lcore_is_enabled(rx_lcore_id) == 0 ||
-		       lcore_queue_conf[rx_lcore_id].n_rx_port ==
-		       l2fwd_rx_queue_per_lcore) {
-			rx_lcore_id++;
-			if (rx_lcore_id >= RTE_MAX_LCORE)
-				rte_exit(EXIT_FAILURE, "Not enough cores\n");
-		}
-
-		if (qconf != &lcore_queue_conf[rx_lcore_id])
-			/* Assigned a new logical core in the loop above. */
-			qconf = &lcore_queue_conf[rx_lcore_id];
-
-		qconf->rx_port_list[qconf->n_rx_port] = portid;
-		qconf->n_rx_port++;
-		printf("Lcore %u: RX port %u\n", rx_lcore_id, portid);
-	}
-
-	/* Initialise each port */
-	RTE_ETH_FOREACH_DEV(portid) {
-		struct rte_eth_dev_info dev_info;
-		struct rte_eth_rxconf rxq_conf;
-		struct rte_eth_txconf txq_conf;
-		struct rte_eth_conf local_port_conf = port_conf;
-
-		/* skip ports that are not enabled */
-		if ((l2fwd_enabled_port_mask & (1 << portid)) == 0) {
-			printf("Skipping disabled port %u\n", portid);
-			continue;
-		}
-		nb_ports_available++;
-
-		/* init port */
-		printf("Initializing port %u... ", portid);
-		fflush(stdout);
-		rte_eth_dev_info_get(portid, &dev_info);
-		if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-			local_port_conf.txmode.offloads |=
-				DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-		ret = rte_eth_dev_configure(portid, 1, 1, &local_port_conf);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "Cannot configure device: err=%d, port=%u\n",
-				  ret, portid);
-
-		ret = rte_eth_dev_adjust_nb_rx_tx_desc(portid, &nb_rxd,
-						       &nb_txd);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-				 "Cannot adjust number of descriptors: err=%d, port=%u\n",
-				 ret, portid);
-
-		rte_eth_macaddr_get(portid, &l2fwd_ports_eth_addr[portid]);
-
-		/* init one RX queue */
-		fflush(stdout);
-		rxq_conf = dev_info.default_rxconf;
-		rxq_conf.offloads = local_port_conf.rxmode.offloads;
-		ret = rte_eth_rx_queue_setup(portid, 0, nb_rxd,
-					     rte_eth_dev_socket_id(portid),
-					     &rxq_conf,
-					     l2fwd_pktmbuf_pool);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "rte_eth_rx_queue_setup:err=%d, port=%u\n",
-				  ret, portid);
-
-		/* init one TX queue on each port */
-		txq_conf = dev_info.default_txconf;
-		txq_conf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-		txq_conf.offloads = local_port_conf.txmode.offloads;
-		fflush(stdout);
-		ret = rte_eth_tx_queue_setup(portid, 0, nb_txd,
-				rte_eth_dev_socket_id(portid),
-				&txq_conf);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-			"rte_eth_tx_queue_setup:err=%d, port=%u\n",
-				ret, portid);
-
-		/* Initialize TX buffers */
-		tx_buffer[portid] = rte_zmalloc_socket("tx_buffer",
-				RTE_ETH_TX_BUFFER_SIZE(MAX_PKT_BURST), 0,
-				rte_eth_dev_socket_id(portid));
-		if (tx_buffer[portid] == NULL)
-			rte_exit(EXIT_FAILURE, "Cannot allocate buffer for tx on port %u\n",
-					portid);
-
-		rte_eth_tx_buffer_init(tx_buffer[portid], MAX_PKT_BURST);
-
-		ret = rte_eth_tx_buffer_set_err_callback(tx_buffer[portid],
-				rte_eth_tx_buffer_count_callback,
-				&port_statistics[portid].dropped);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-			"Cannot set error callback for tx buffer on port %u\n",
-				 portid);
-
-		/* Start device */
-		ret = rte_eth_dev_start(portid);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "rte_eth_dev_start:err=%d, port=%u\n",
-				  ret, portid);
-
-		printf("done:\n");
-
-		rte_eth_promiscuous_enable(portid);
-
-		printf("Port %u, MAC address: %02X:%02X:%02X:%02X:%02X:%02X\n\n",
-				portid,
-				l2fwd_ports_eth_addr[portid].addr_bytes[0],
-				l2fwd_ports_eth_addr[portid].addr_bytes[1],
-				l2fwd_ports_eth_addr[portid].addr_bytes[2],
-				l2fwd_ports_eth_addr[portid].addr_bytes[3],
-				l2fwd_ports_eth_addr[portid].addr_bytes[4],
-				l2fwd_ports_eth_addr[portid].addr_bytes[5]);
-
-		/* initialize port stats */
-		memset(&port_statistics, 0, sizeof(port_statistics));
-	}
-
-	if (!nb_ports_available) {
-		rte_exit(EXIT_FAILURE,
-			"All available ports are disabled. Please set portmask.\n");
-	}
-
-	check_all_ports_link_status(l2fwd_enabled_port_mask);
-
-	drain_tsc = (hz + US_PER_S - 1) / US_PER_S * BURST_TX_DRAIN_US;
-
-	RTE_LCORE_FOREACH(lcore_id) {
-		qconf = &lcore_queue_conf[lcore_id];
-
-		rte_spinlock_init(&qconf->lock);
-
-		if (rte_jobstats_context_init(&qconf->jobs_context) != 0)
-			rte_panic("Jobs stats context for core %u init failed\n", lcore_id);
-
-		if (qconf->n_rx_port == 0) {
-			RTE_LOG(INFO, L2FWD,
-				"lcore %u: no ports so no jobs stats context initialization\n",
-				lcore_id);
-			continue;
-		}
-		/* Add flush job.
-		 * Set fixed period by setting min = max = initial period. Set target to
-		 * zero as it is irrelevant for this job. */
-		rte_jobstats_init(&qconf->flush_job, "flush", drain_tsc, drain_tsc,
-				drain_tsc, 0);
-
-		rte_timer_init(&qconf->flush_timer);
-		ret = rte_timer_reset(&qconf->flush_timer, drain_tsc, PERIODICAL,
-				lcore_id, &l2fwd_flush_job, NULL);
-
-		if (ret < 0) {
-			rte_exit(1, "Failed to reset flush job timer for lcore %u: %s",
-					lcore_id, rte_strerror(-ret));
-		}
-
-		for (i = 0; i < qconf->n_rx_port; i++) {
-			struct rte_jobstats *job = &qconf->port_fwd_jobs[i];
-
-			portid = qconf->rx_port_list[i];
-			printf("Setting forward job for port %u\n", portid);
-
-			snprintf(name, RTE_DIM(name), "port %u fwd", portid);
-			/* Setup forward job.
-			 * Set min, max and initial period. Set target to MAX_PKT_BURST as
-			 * this is desired optimal RX/TX burst size. */
-			rte_jobstats_init(job, name, 0, drain_tsc, 0, MAX_PKT_BURST);
-			rte_jobstats_set_update_period_function(job, l2fwd_job_update_cb);
-
-			rte_timer_init(&qconf->rx_timers[i]);
-			ret = rte_timer_reset(&qconf->rx_timers[i], 0, PERIODICAL, lcore_id,
-					&l2fwd_fwd_job, (void *)(uintptr_t)i);
-
-			if (ret < 0) {
-				rte_exit(1, "Failed to reset lcore %u port %u job timer: %s",
-						lcore_id, qconf->rx_port_list[i], rte_strerror(-ret));
-			}
-		}
-	}
-
-	if (timer_period)
-		rte_eal_alarm_set(timer_period * MS_PER_S, show_stats_cb, NULL);
-	else
-		RTE_LOG(INFO, L2FWD, "Stats display disabled\n");
-
-	/* launch per-lcore init on every lcore */
-	rte_eal_mp_remote_launch(l2fwd_launch_one_lcore, NULL, CALL_MASTER);
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		if (rte_eal_wait_lcore(lcore_id) < 0)
-			return -1;
-	}
-
-	return 0;
-}
diff --git a/examples/l2fwd-jobstats/meson.build b/examples/l2fwd-jobstats/meson.build
deleted file mode 100644
index 3653aa7..0000000
--- a/examples/l2fwd-jobstats/meson.build
+++ /dev/null
@@ -1,13 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-deps += ['jobstats', 'timer']
-allow_experimental_apis = true
-sources = files(
-	'main.c'
-)
diff --git a/examples/l2fwd-keepalive/Makefile b/examples/l2fwd-keepalive/Makefile
deleted file mode 100644
index af28956..0000000
--- a/examples/l2fwd-keepalive/Makefile
+++ /dev/null
@@ -1,61 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2016 Intel Corporation
-
-# binary name
-APP = l2fwd-keepalive
-
-# all source are stored in SRCS-y
-SRCS-y := main.c shm.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-LDFLAGS += -pthread -lrt
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else # Build using legacy build system
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-LDFLAGS += -lrt
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-endif
diff --git a/examples/l2fwd-keepalive/ka-agent/Makefile b/examples/l2fwd-keepalive/ka-agent/Makefile
deleted file mode 100644
index ddb6e83..0000000
--- a/examples/l2fwd-keepalive/ka-agent/Makefile
+++ /dev/null
@@ -1,21 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2016 Intel Corporation
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-# binary name
-APP = ka-agent
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-
-CFLAGS += $(WERROR_FLAGS) -I$(SRCDIR)/../
-LDFLAGS += -lrt
-include $(RTE_SDK)/mk/rte.extapp.mk
diff --git a/examples/l2fwd-keepalive/ka-agent/main.c b/examples/l2fwd-keepalive/ka-agent/main.c
deleted file mode 100644
index b8a755d..0000000
--- a/examples/l2fwd-keepalive/ka-agent/main.c
+++ /dev/null
@@ -1,120 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016 Intel Corporation
- */
-
-#include <stdio.h>
-#include <string.h>
-#include <stdint.h>
-#include <errno.h>
-#include <unistd.h>
-#include <fcntl.h>
-#include <sys/wait.h>
-#include <sys/queue.h>
-#include <sys/mman.h>
-#include <sys/stat.h>
-#include <time.h>
-
-#include <rte_keepalive.h>
-
-#include <shm.h>
-
-#define MAX_TIMEOUTS 4
-#define SEM_TIMEOUT_SECS 2
-
-static struct rte_keepalive_shm *ka_shm_create(void)
-{
-	int fd = shm_open(RTE_KEEPALIVE_SHM_NAME, O_RDWR, 0666);
-	size_t size = sizeof(struct rte_keepalive_shm);
-	struct rte_keepalive_shm *shm;
-
-	if (fd < 0)
-		printf("Failed to open %s as SHM:%s\n",
-			RTE_KEEPALIVE_SHM_NAME,
-		strerror(errno));
-	else {
-		shm = (struct rte_keepalive_shm *) mmap(
-			0, size, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);
-		close(fd);
-		if (shm == MAP_FAILED)
-			printf("Failed to mmap SHM:%s\n", strerror(errno));
-		else
-			return shm;
-	}
-
-	/* Reset to zero, as it was set to MAP_FAILED aka: (void *)-1 */
-	shm = 0;
-	return NULL;
-}
-
-int main(void)
-{
-	struct rte_keepalive_shm *shm = ka_shm_create();
-	struct timespec timeout = { .tv_nsec = 0 };
-	int idx_core;
-	int cnt_cores;
-	uint64_t last_seen_alive_time = 0;
-	uint64_t most_recent_alive_time;
-	int cnt_timeouts = 0;
-	int sem_errno;
-
-	if (shm == NULL) {
-		printf("Unable to access shared core state\n");
-		return 1;
-	}
-	while (1) {
-		most_recent_alive_time = 0;
-		for (idx_core = 0; idx_core < RTE_KEEPALIVE_MAXCORES;
-				idx_core++)
-			if (shm->core_last_seen_times[idx_core] >
-					most_recent_alive_time)
-				most_recent_alive_time =
-					shm->core_last_seen_times[idx_core];
-
-		timeout.tv_sec = time(NULL) + SEM_TIMEOUT_SECS;
-		if (sem_timedwait(&shm->core_died, &timeout) == -1) {
-			/* Assume no core death signals and no change in any
-			 * last-seen times is the keepalive monitor itself
-			 * failing.
-			 */
-			sem_errno = errno;
-			last_seen_alive_time = most_recent_alive_time;
-			if (sem_errno == ETIMEDOUT) {
-				if (last_seen_alive_time ==
-						most_recent_alive_time &&
-						cnt_timeouts++ >
-						MAX_TIMEOUTS) {
-					printf("No updates. Exiting..\n");
-					break;
-					}
-			} else
-				printf("sem_timedwait() error (%s)\n",
-					strerror(sem_errno));
-			continue;
-		}
-		cnt_timeouts = 0;
-
-		cnt_cores = 0;
-		for (idx_core = 0; idx_core < RTE_KEEPALIVE_MAXCORES;
-				idx_core++)
-			if (shm->core_state[idx_core] == RTE_KA_STATE_DEAD)
-				cnt_cores++;
-		if (cnt_cores == 0) {
-			/* Can happen if core was restarted since Semaphore
-			 * was sent, due to agent being offline.
-			 */
-			printf("Warning: Empty dead core report\n");
-			continue;
-		}
-
-		printf("%i dead cores: ", cnt_cores);
-		for (idx_core = 0;
-				idx_core < RTE_KEEPALIVE_MAXCORES;
-				idx_core++)
-			if (shm->core_state[idx_core] == RTE_KA_STATE_DEAD)
-				printf("%d, ", idx_core);
-		printf("\b\b\n");
-	}
-	if (munmap(shm, sizeof(struct rte_keepalive_shm)) != 0)
-		printf("Warning: munmap() failed\n");
-	return 0;
-}
diff --git a/examples/l2fwd-keepalive/main.c b/examples/l2fwd-keepalive/main.c
deleted file mode 100644
index e9ad91a..0000000
--- a/examples/l2fwd-keepalive/main.c
+++ /dev/null
@@ -1,801 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <string.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <sys/types.h>
-#include <sys/queue.h>
-#include <netinet/in.h>
-#include <setjmp.h>
-#include <stdarg.h>
-#include <ctype.h>
-#include <errno.h>
-#include <getopt.h>
-#include <signal.h>
-
-#include <rte_common.h>
-#include <rte_log.h>
-#include <rte_malloc.h>
-#include <rte_memory.h>
-#include <rte_memcpy.h>
-#include <rte_eal.h>
-#include <rte_launch.h>
-#include <rte_atomic.h>
-#include <rte_cycles.h>
-#include <rte_prefetch.h>
-#include <rte_lcore.h>
-#include <rte_per_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_interrupts.h>
-#include <rte_random.h>
-#include <rte_debug.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-#include <rte_timer.h>
-#include <rte_keepalive.h>
-
-#include "shm.h"
-
-#define RTE_LOGTYPE_L2FWD RTE_LOGTYPE_USER1
-
-#define NB_MBUF   8192
-
-#define MAX_PKT_BURST 32
-#define BURST_TX_DRAIN_US 100 /* TX drain every ~100us */
-
-/*
- * Configurable number of RX/TX ring descriptors
- */
-#define RTE_TEST_RX_DESC_DEFAULT 1024
-#define RTE_TEST_TX_DESC_DEFAULT 1024
-static uint16_t nb_rxd = RTE_TEST_RX_DESC_DEFAULT;
-static uint16_t nb_txd = RTE_TEST_TX_DESC_DEFAULT;
-
-/* ethernet addresses of ports */
-static struct ether_addr l2fwd_ports_eth_addr[RTE_MAX_ETHPORTS];
-
-/* mask of enabled ports */
-static uint32_t l2fwd_enabled_port_mask;
-
-/* list of enabled ports */
-static uint32_t l2fwd_dst_ports[RTE_MAX_ETHPORTS];
-
-static unsigned int l2fwd_rx_queue_per_lcore = 1;
-
-#define MAX_RX_QUEUE_PER_LCORE 16
-#define MAX_TX_QUEUE_PER_PORT 16
-struct lcore_queue_conf {
-	unsigned n_rx_port;
-	unsigned rx_port_list[MAX_RX_QUEUE_PER_LCORE];
-} __rte_cache_aligned;
-struct lcore_queue_conf lcore_queue_conf[RTE_MAX_LCORE];
-
-struct rte_eth_dev_tx_buffer *tx_buffer[RTE_MAX_ETHPORTS];
-
-static struct rte_eth_conf port_conf = {
-	.rxmode = {
-		.split_hdr_size = 0,
-		.ignore_offload_bitfield = 1,
-		.offloads = DEV_RX_OFFLOAD_CRC_STRIP,
-	},
-	.txmode = {
-		.mq_mode = ETH_MQ_TX_NONE,
-	},
-};
-
-struct rte_mempool *l2fwd_pktmbuf_pool = NULL;
-
-/* Per-port statistics struct */
-struct l2fwd_port_statistics {
-	uint64_t tx;
-	uint64_t rx;
-	uint64_t dropped;
-} __rte_cache_aligned;
-struct l2fwd_port_statistics port_statistics[RTE_MAX_ETHPORTS];
-
-/* A tsc-based timer responsible for triggering statistics printout */
-#define TIMER_MILLISECOND 1
-#define MAX_TIMER_PERIOD 86400 /* 1 day max */
-static int64_t timer_period = 10 * TIMER_MILLISECOND * 1000; /* 10 seconds */
-static int64_t check_period = 5; /* default check cycle is 5ms */
-
-/* Keepalive structure */
-struct rte_keepalive *rte_global_keepalive_info;
-
-/* Termination signalling */
-static int terminate_signal_received;
-
-/* Termination signal handler */
-static void handle_sigterm(__rte_unused int value)
-{
-	terminate_signal_received = 1;
-}
-
-/* Print out statistics on packets dropped */
-static void
-print_stats(__attribute__((unused)) struct rte_timer *ptr_timer,
-	__attribute__((unused)) void *ptr_data)
-{
-	uint64_t total_packets_dropped, total_packets_tx, total_packets_rx;
-	uint16_t portid;
-
-	total_packets_dropped = 0;
-	total_packets_tx = 0;
-	total_packets_rx = 0;
-
-	const char clr[] = { 27, '[', '2', 'J', '\0' };
-	const char topLeft[] = { 27, '[', '1', ';', '1', 'H', '\0' };
-
-		/* Clear screen and move to top left */
-	printf("%s%s", clr, topLeft);
-
-	printf("\nPort statistics ====================================");
-
-	for (portid = 0; portid < RTE_MAX_ETHPORTS; portid++) {
-		/* skip disabled ports */
-		if ((l2fwd_enabled_port_mask & (1 << portid)) == 0)
-			continue;
-		printf("\nStatistics for port %u ------------------------------"
-			   "\nPackets sent: %24"PRIu64
-			   "\nPackets received: %20"PRIu64
-			   "\nPackets dropped: %21"PRIu64,
-			   portid,
-			   port_statistics[portid].tx,
-			   port_statistics[portid].rx,
-			   port_statistics[portid].dropped);
-
-		total_packets_dropped += port_statistics[portid].dropped;
-		total_packets_tx += port_statistics[portid].tx;
-		total_packets_rx += port_statistics[portid].rx;
-	}
-	printf("\nAggregate statistics ==============================="
-		   "\nTotal packets sent: %18"PRIu64
-		   "\nTotal packets received: %14"PRIu64
-		   "\nTotal packets dropped: %15"PRIu64,
-		   total_packets_tx,
-		   total_packets_rx,
-		   total_packets_dropped);
-	printf("\n====================================================\n");
-}
-
-static void
-l2fwd_simple_forward(struct rte_mbuf *m, unsigned portid)
-{
-	struct ether_hdr *eth;
-	void *tmp;
-	int sent;
-	unsigned dst_port;
-	struct rte_eth_dev_tx_buffer *buffer;
-
-	dst_port = l2fwd_dst_ports[portid];
-	eth = rte_pktmbuf_mtod(m, struct ether_hdr *);
-
-	/* 02:00:00:00:00:xx */
-	tmp = &eth->d_addr.addr_bytes[0];
-	*((uint64_t *)tmp) = 0x000000000002 + ((uint64_t)dst_port << 40);
-
-	/* src addr */
-	ether_addr_copy(&l2fwd_ports_eth_addr[dst_port], &eth->s_addr);
-
-	buffer = tx_buffer[dst_port];
-	sent = rte_eth_tx_buffer(dst_port, 0, buffer, m);
-	if (sent)
-		port_statistics[dst_port].tx += sent;
-}
-
-/* main processing loop */
-static void
-l2fwd_main_loop(void)
-{
-	struct rte_mbuf *pkts_burst[MAX_PKT_BURST];
-	struct rte_mbuf *m;
-	int sent;
-	unsigned lcore_id;
-	uint64_t prev_tsc, diff_tsc, cur_tsc;
-	unsigned i, j, portid, nb_rx;
-	struct lcore_queue_conf *qconf;
-	const uint64_t drain_tsc = (rte_get_tsc_hz() + US_PER_S - 1)
-		/ US_PER_S * BURST_TX_DRAIN_US;
-	struct rte_eth_dev_tx_buffer *buffer;
-
-	prev_tsc = 0;
-
-	lcore_id = rte_lcore_id();
-	qconf = &lcore_queue_conf[lcore_id];
-
-	if (qconf->n_rx_port == 0) {
-		RTE_LOG(INFO, L2FWD, "lcore %u has nothing to do\n", lcore_id);
-		return;
-	}
-
-	RTE_LOG(INFO, L2FWD, "entering main loop on lcore %u\n", lcore_id);
-
-	for (i = 0; i < qconf->n_rx_port; i++) {
-
-		portid = qconf->rx_port_list[i];
-		RTE_LOG(INFO, L2FWD, " -- lcoreid=%u portid=%u\n", lcore_id,
-			portid);
-	}
-
-	uint64_t tsc_initial = rte_rdtsc();
-	uint64_t tsc_lifetime = (rand()&0x07) * rte_get_tsc_hz();
-
-	while (!terminate_signal_received) {
-		/* Keepalive heartbeat */
-		rte_keepalive_mark_alive(rte_global_keepalive_info);
-
-		cur_tsc = rte_rdtsc();
-
-		/*
-		 * Die randomly within 7 secs for demo purposes if
-		 * keepalive enabled
-		 */
-		if (check_period > 0 && cur_tsc - tsc_initial > tsc_lifetime)
-			break;
-
-		/*
-		 * TX burst queue drain
-		 */
-		diff_tsc = cur_tsc - prev_tsc;
-		if (unlikely(diff_tsc > drain_tsc)) {
-
-			for (i = 0; i < qconf->n_rx_port; i++) {
-
-				portid = l2fwd_dst_ports[qconf->rx_port_list[i]];
-				buffer = tx_buffer[portid];
-
-				sent = rte_eth_tx_buffer_flush(portid, 0, buffer);
-				if (sent)
-					port_statistics[portid].tx += sent;
-
-			}
-
-			prev_tsc = cur_tsc;
-		}
-
-		/*
-		 * Read packet from RX queues
-		 */
-		for (i = 0; i < qconf->n_rx_port; i++) {
-
-			portid = qconf->rx_port_list[i];
-			nb_rx = rte_eth_rx_burst(portid, 0,
-						 pkts_burst, MAX_PKT_BURST);
-
-			port_statistics[portid].rx += nb_rx;
-
-			for (j = 0; j < nb_rx; j++) {
-				m = pkts_burst[j];
-				rte_prefetch0(rte_pktmbuf_mtod(m, void *));
-				l2fwd_simple_forward(m, portid);
-			}
-		}
-	}
-}
-
-static int
-l2fwd_launch_one_lcore(__attribute__((unused)) void *dummy)
-{
-	l2fwd_main_loop();
-	return 0;
-}
-
-/* display usage */
-static void
-l2fwd_usage(const char *prgname)
-{
-	printf("%s [EAL options] -- -p PORTMASK [-q NQ]\n"
-	       "  -p PORTMASK: hexadecimal bitmask of ports to configure\n"
-	       "  -q NQ: number of queue (=ports) per lcore (default is 1)\n"
-	       "  -K PERIOD: Keepalive check period (5 default; 86400 max)\n"
-		   "  -T PERIOD: statistics will be refreshed each PERIOD seconds (0 to disable, 10 default, 86400 maximum)\n",
-	       prgname);
-}
-
-static int
-l2fwd_parse_portmask(const char *portmask)
-{
-	char *end = NULL;
-	unsigned long pm;
-
-	/* parse hexadecimal string */
-	pm = strtoul(portmask, &end, 16);
-	if ((portmask[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (pm == 0)
-		return -1;
-
-	return pm;
-}
-
-static unsigned int
-l2fwd_parse_nqueue(const char *q_arg)
-{
-	char *end = NULL;
-	unsigned long n;
-
-	/* parse hexadecimal string */
-	n = strtoul(q_arg, &end, 10);
-	if ((q_arg[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return 0;
-	if (n == 0)
-		return 0;
-	if (n >= MAX_RX_QUEUE_PER_LCORE)
-		return 0;
-
-	return n;
-}
-
-static int
-l2fwd_parse_timer_period(const char *q_arg)
-{
-	char *end = NULL;
-	int n;
-
-	/* parse number string */
-	n = strtol(q_arg, &end, 10);
-	if ((q_arg[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-	if (n >= MAX_TIMER_PERIOD)
-		return -1;
-
-	return n;
-}
-
-static int
-l2fwd_parse_check_period(const char *q_arg)
-{
-	char *end = NULL;
-	int n;
-
-	/* parse number string */
-	n = strtol(q_arg, &end, 10);
-	if ((q_arg[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-	if (n >= MAX_TIMER_PERIOD)
-		return -1;
-
-	return n;
-}
-
-/* Parse the argument given in the command line of the application */
-static int
-l2fwd_parse_args(int argc, char **argv)
-{
-	int opt, ret;
-	char **argvopt;
-	int option_index;
-	char *prgname = argv[0];
-	static struct option lgopts[] = {
-		{NULL, 0, 0, 0}
-	};
-
-	argvopt = argv;
-
-	while ((opt = getopt_long(argc, argvopt, "p:q:T:K:",
-				  lgopts, &option_index)) != EOF) {
-
-		switch (opt) {
-		/* portmask */
-		case 'p':
-			l2fwd_enabled_port_mask = l2fwd_parse_portmask(optarg);
-			if (l2fwd_enabled_port_mask == 0) {
-				printf("invalid portmask\n");
-				l2fwd_usage(prgname);
-				return -1;
-			}
-			break;
-
-		/* nqueue */
-		case 'q':
-			l2fwd_rx_queue_per_lcore = l2fwd_parse_nqueue(optarg);
-			if (l2fwd_rx_queue_per_lcore == 0) {
-				printf("invalid queue number\n");
-				l2fwd_usage(prgname);
-				return -1;
-			}
-			break;
-
-		/* timer period */
-		case 'T':
-			timer_period = l2fwd_parse_timer_period(optarg)
-				* (int64_t)(1000 * TIMER_MILLISECOND);
-			if (timer_period < 0) {
-				printf("invalid timer period\n");
-				l2fwd_usage(prgname);
-				return -1;
-			}
-			break;
-
-		/* Check period */
-		case 'K':
-			check_period = l2fwd_parse_check_period(optarg);
-			if (check_period < 0) {
-				printf("invalid check period\n");
-				l2fwd_usage(prgname);
-				return -1;
-			}
-			break;
-
-		/* long options */
-		case 0:
-			l2fwd_usage(prgname);
-			return -1;
-
-		default:
-			l2fwd_usage(prgname);
-			return -1;
-		}
-	}
-
-	if (optind >= 0)
-		argv[optind-1] = prgname;
-
-	ret = optind-1;
-	optind = 1; /* reset getopt lib */
-	return ret;
-}
-
-/* Check the link status of all ports in up to 9s, and print them finally */
-static void
-check_all_ports_link_status(uint32_t port_mask)
-{
-#define CHECK_INTERVAL 100 /* 100ms */
-#define MAX_CHECK_TIME 90 /* 9s (90 * 100ms) in total */
-	uint16_t portid;
-	uint8_t count, all_ports_up, print_flag = 0;
-	struct rte_eth_link link;
-
-	printf("\nChecking link status");
-	fflush(stdout);
-	for (count = 0; count <= MAX_CHECK_TIME; count++) {
-		all_ports_up = 1;
-		RTE_ETH_FOREACH_DEV(portid) {
-			if ((port_mask & (1 << portid)) == 0)
-				continue;
-			memset(&link, 0, sizeof(link));
-			rte_eth_link_get_nowait(portid, &link);
-			/* print link status if flag set */
-			if (print_flag == 1) {
-				if (link.link_status)
-					printf(
-					"Port%d Link Up. Speed %u Mbps - %s\n",
-						portid, link.link_speed,
-				(link.link_duplex == ETH_LINK_FULL_DUPLEX) ?
-					("full-duplex") : ("half-duplex\n"));
-				else
-					printf("Port %d Link Down\n", portid);
-				continue;
-			}
-			/* clear all_ports_up flag if any link down */
-			if (link.link_status == ETH_LINK_DOWN) {
-				all_ports_up = 0;
-				break;
-			}
-		}
-		/* after finally printing all link status, get out */
-		if (print_flag == 1)
-			break;
-
-		if (all_ports_up == 0) {
-			printf(".");
-			fflush(stdout);
-			rte_delay_ms(CHECK_INTERVAL);
-		}
-
-		/* set the print_flag if all ports up or timeout */
-		if (all_ports_up == 1 || count == (MAX_CHECK_TIME - 1)) {
-			print_flag = 1;
-			printf("done\n");
-		}
-	}
-}
-
-static void
-dead_core(__rte_unused void *ptr_data, const int id_core)
-{
-	if (terminate_signal_received)
-		return;
-	printf("Dead core %i - restarting..\n", id_core);
-	if (rte_eal_get_lcore_state(id_core) == FINISHED) {
-		rte_eal_wait_lcore(id_core);
-		rte_eal_remote_launch(l2fwd_launch_one_lcore, NULL, id_core);
-	} else {
-		printf("..false positive!\n");
-	}
-}
-
-static void
-relay_core_state(void *ptr_data, const int id_core,
-	const enum rte_keepalive_state core_state, uint64_t last_alive)
-{
-	rte_keepalive_relayed_state((struct rte_keepalive_shm *)ptr_data,
-		id_core, core_state, last_alive);
-}
-
-int
-main(int argc, char **argv)
-{
-	struct lcore_queue_conf *qconf;
-	int ret;
-	uint16_t nb_ports;
-	uint16_t nb_ports_available = 0;
-	uint16_t portid, last_port;
-	unsigned lcore_id, rx_lcore_id;
-	unsigned nb_ports_in_mask = 0;
-	struct sigaction signal_handler;
-	struct rte_keepalive_shm *ka_shm;
-
-	memset(&signal_handler, 0, sizeof(signal_handler));
-	terminate_signal_received = 0;
-	signal_handler.sa_handler = &handle_sigterm;
-	if (sigaction(SIGINT, &signal_handler, NULL) == -1 ||
-			sigaction(SIGTERM, &signal_handler, NULL) == -1)
-		rte_exit(EXIT_FAILURE, "SIGNAL\n");
-
-
-	/* init EAL */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid EAL arguments\n");
-	argc -= ret;
-	argv += ret;
-
-	l2fwd_enabled_port_mask = 0;
-
-	/* parse application arguments (after the EAL ones) */
-	ret = l2fwd_parse_args(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid L2FWD arguments\n");
-
-	/* create the mbuf pool */
-	l2fwd_pktmbuf_pool = rte_pktmbuf_pool_create("mbuf_pool", NB_MBUF, 32,
-		0, RTE_MBUF_DEFAULT_BUF_SIZE, rte_socket_id());
-	if (l2fwd_pktmbuf_pool == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot init mbuf pool\n");
-
-	nb_ports = rte_eth_dev_count();
-	if (nb_ports == 0)
-		rte_exit(EXIT_FAILURE, "No Ethernet ports - bye\n");
-
-	/* reset l2fwd_dst_ports */
-	for (portid = 0; portid < RTE_MAX_ETHPORTS; portid++)
-		l2fwd_dst_ports[portid] = 0;
-	last_port = 0;
-
-	/*
-	 * Each logical core is assigned a dedicated TX queue on each port.
-	 */
-	RTE_ETH_FOREACH_DEV(portid) {
-		/* skip ports that are not enabled */
-		if ((l2fwd_enabled_port_mask & (1 << portid)) == 0)
-			continue;
-
-		if (nb_ports_in_mask % 2) {
-			l2fwd_dst_ports[portid] = last_port;
-			l2fwd_dst_ports[last_port] = portid;
-		} else
-			last_port = portid;
-
-		nb_ports_in_mask++;
-	}
-	if (nb_ports_in_mask % 2) {
-		printf("Notice: odd number of ports in portmask.\n");
-		l2fwd_dst_ports[last_port] = last_port;
-	}
-
-	rx_lcore_id = 1;
-	qconf = NULL;
-
-	/* Initialize the port/queue configuration of each logical core */
-	RTE_ETH_FOREACH_DEV(portid) {
-		/* skip ports that are not enabled */
-		if ((l2fwd_enabled_port_mask & (1 << portid)) == 0)
-			continue;
-
-		/* get the lcore_id for this port */
-		while (rte_lcore_is_enabled(rx_lcore_id) == 0 ||
-		       lcore_queue_conf[rx_lcore_id].n_rx_port ==
-		       l2fwd_rx_queue_per_lcore) {
-			rx_lcore_id++;
-			if (rx_lcore_id >= RTE_MAX_LCORE)
-				rte_exit(EXIT_FAILURE, "Not enough cores\n");
-		}
-
-		if (qconf != &lcore_queue_conf[rx_lcore_id])
-			/* Assigned a new logical core in the loop above. */
-			qconf = &lcore_queue_conf[rx_lcore_id];
-
-		qconf->rx_port_list[qconf->n_rx_port] = portid;
-		qconf->n_rx_port++;
-		printf("Lcore %u: RX port %u\n",
-			rx_lcore_id, portid);
-	}
-
-	/* Initialise each port */
-	RTE_ETH_FOREACH_DEV(portid) {
-		struct rte_eth_dev_info dev_info;
-		struct rte_eth_rxconf rxq_conf;
-		struct rte_eth_txconf txq_conf;
-		struct rte_eth_conf local_port_conf = port_conf;
-
-		/* skip ports that are not enabled */
-		if ((l2fwd_enabled_port_mask & (1 << portid)) == 0) {
-			printf("Skipping disabled port %u\n", portid);
-			continue;
-		}
-		nb_ports_available++;
-
-		/* init port */
-		printf("Initializing port %u... ", portid);
-		fflush(stdout);
-		rte_eth_dev_info_get(portid, &dev_info);
-		if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-			local_port_conf.txmode.offloads |=
-				DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-		ret = rte_eth_dev_configure(portid, 1, 1, &local_port_conf);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-				"Cannot configure device: err=%d, port=%u\n",
-				ret, portid);
-
-		ret = rte_eth_dev_adjust_nb_rx_tx_desc(portid, &nb_rxd,
-						       &nb_txd);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-				"Cannot adjust number of descriptors: err=%d, port=%u\n",
-				ret, portid);
-
-		rte_eth_macaddr_get(portid, &l2fwd_ports_eth_addr[portid]);
-
-		/* init one RX queue */
-		fflush(stdout);
-		rxq_conf = dev_info.default_rxconf;
-		rxq_conf.offloads = local_port_conf.rxmode.offloads;
-		ret = rte_eth_rx_queue_setup(portid, 0, nb_rxd,
-					     rte_eth_dev_socket_id(portid),
-					     &rxq_conf,
-					     l2fwd_pktmbuf_pool);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-				"rte_eth_rx_queue_setup:err=%d, port=%u\n",
-				ret, portid);
-
-		/* init one TX queue on each port */
-		fflush(stdout);
-		txq_conf = dev_info.default_txconf;
-		txq_conf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-		txq_conf.offloads = local_port_conf.txmode.offloads;
-		ret = rte_eth_tx_queue_setup(portid, 0, nb_txd,
-				rte_eth_dev_socket_id(portid),
-				&txq_conf);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-				"rte_eth_tx_queue_setup:err=%d, port=%u\n",
-				ret, portid);
-
-		/* Initialize TX buffers */
-		tx_buffer[portid] = rte_zmalloc_socket("tx_buffer",
-				RTE_ETH_TX_BUFFER_SIZE(MAX_PKT_BURST), 0,
-				rte_eth_dev_socket_id(portid));
-		if (tx_buffer[portid] == NULL)
-			rte_exit(EXIT_FAILURE, "Cannot allocate buffer for tx on port %u\n",
-						portid);
-
-		rte_eth_tx_buffer_init(tx_buffer[portid], MAX_PKT_BURST);
-
-		ret = rte_eth_tx_buffer_set_err_callback(tx_buffer[portid],
-				rte_eth_tx_buffer_count_callback,
-				&port_statistics[portid].dropped);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-			"Cannot set error callback for tx buffer on port %u\n",
-				 portid);
-
-		/* Start device */
-		ret = rte_eth_dev_start(portid);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-				"rte_eth_dev_start:err=%d, port=%u\n",
-				  ret, portid);
-
-		rte_eth_promiscuous_enable(portid);
-
-		printf("Port %u, MAC address: "
-			"%02X:%02X:%02X:%02X:%02X:%02X\n\n",
-			portid,
-			l2fwd_ports_eth_addr[portid].addr_bytes[0],
-			l2fwd_ports_eth_addr[portid].addr_bytes[1],
-			l2fwd_ports_eth_addr[portid].addr_bytes[2],
-			l2fwd_ports_eth_addr[portid].addr_bytes[3],
-			l2fwd_ports_eth_addr[portid].addr_bytes[4],
-			l2fwd_ports_eth_addr[portid].addr_bytes[5]);
-
-		/* initialize port stats */
-		memset(&port_statistics, 0, sizeof(port_statistics));
-	}
-
-	if (!nb_ports_available) {
-		rte_exit(EXIT_FAILURE,
-			"All available ports are disabled. Please set portmask.\n");
-	}
-
-	check_all_ports_link_status(l2fwd_enabled_port_mask);
-
-	struct rte_timer hb_timer, stats_timer;
-
-	rte_timer_subsystem_init();
-	rte_timer_init(&stats_timer);
-
-	ka_shm = NULL;
-	if (check_period > 0) {
-		ka_shm = rte_keepalive_shm_create();
-		if (ka_shm == NULL)
-			rte_exit(EXIT_FAILURE,
-				"rte_keepalive_shm_create() failed");
-		rte_global_keepalive_info =
-			rte_keepalive_create(&dead_core, ka_shm);
-		if (rte_global_keepalive_info == NULL)
-			rte_exit(EXIT_FAILURE, "init_keep_alive() failed");
-		rte_keepalive_register_relay_callback(rte_global_keepalive_info,
-			relay_core_state, ka_shm);
-		rte_timer_init(&hb_timer);
-		if (rte_timer_reset(&hb_timer,
-				(check_period * rte_get_timer_hz()) / 1000,
-				PERIODICAL,
-				rte_lcore_id(),
-				(void(*)(struct rte_timer*, void*))
-				&rte_keepalive_dispatch_pings,
-				rte_global_keepalive_info
-				) != 0 )
-			rte_exit(EXIT_FAILURE, "Keepalive setup failure.\n");
-	}
-	if (timer_period > 0) {
-		if (rte_timer_reset(&stats_timer,
-				(timer_period * rte_get_timer_hz()) / 1000,
-				PERIODICAL,
-				rte_lcore_id(),
-				&print_stats, NULL
-				) != 0 )
-			rte_exit(EXIT_FAILURE, "Stats setup failure.\n");
-	}
-	/* launch per-lcore init on every slave lcore */
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		struct lcore_queue_conf *qconf = &lcore_queue_conf[lcore_id];
-
-		if (qconf->n_rx_port == 0)
-			RTE_LOG(INFO, L2FWD,
-				"lcore %u has nothing to do\n",
-				lcore_id
-				);
-		else {
-			rte_eal_remote_launch(
-				l2fwd_launch_one_lcore,
-				NULL,
-				lcore_id
-				);
-			rte_keepalive_register_core(rte_global_keepalive_info,
-				lcore_id);
-		}
-	}
-	while (!terminate_signal_received) {
-		rte_timer_manage();
-		rte_delay_ms(5);
-		}
-
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		if (rte_eal_wait_lcore(lcore_id) < 0)
-			return -1;
-	}
-
-	if (ka_shm != NULL)
-		rte_keepalive_shm_cleanup(ka_shm);
-	return 0;
-}
diff --git a/examples/l2fwd-keepalive/meson.build b/examples/l2fwd-keepalive/meson.build
deleted file mode 100644
index 2dffffa..0000000
--- a/examples/l2fwd-keepalive/meson.build
+++ /dev/null
@@ -1,14 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-ext_deps += cc.find_library('rt')
-deps += 'timer'
-allow_experimental_apis = true
-sources = files(
-	'main.c', 'shm.c'
-)
diff --git a/examples/l2fwd-keepalive/shm.c b/examples/l2fwd-keepalive/shm.c
deleted file mode 100644
index 7c7a9ea..0000000
--- a/examples/l2fwd-keepalive/shm.c
+++ /dev/null
@@ -1,112 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016 Intel Corporation
- */
-
-#include <time.h>
-
-#include <rte_common.h>
-#include <rte_log.h>
-#include <rte_keepalive.h>
-
-#include "shm.h"
-
-struct rte_keepalive_shm *rte_keepalive_shm_create(void)
-{
-	int fd;
-	int idx_core;
-	struct rte_keepalive_shm *ka_shm;
-
-	/* If any existing object is not unlinked, it makes it all too easy
-	 * for clients to end up with stale shared memory blocks when
-	 * restarted. Unlinking makes sure subsequent shm_open by clients
-	 * will get the new block mapped below.
-	 */
-	if (shm_unlink(RTE_KEEPALIVE_SHM_NAME) == -1 && errno != ENOENT)
-		printf("Warning: Error unlinking stale %s (%s)\n",
-			RTE_KEEPALIVE_SHM_NAME, strerror(errno));
-
-	fd = shm_open(RTE_KEEPALIVE_SHM_NAME,
-		O_CREAT | O_TRUNC | O_RDWR, 0666);
-	if (fd < 0)
-		RTE_LOG(INFO, EAL,
-			"Failed to open %s as SHM (%s)\n",
-			RTE_KEEPALIVE_SHM_NAME,
-			strerror(errno));
-	else if (ftruncate(fd, sizeof(struct rte_keepalive_shm)) != 0)
-		RTE_LOG(INFO, EAL,
-			"Failed to resize SHM (%s)\n", strerror(errno));
-	else {
-		ka_shm = (struct rte_keepalive_shm *) mmap(
-			0, sizeof(struct rte_keepalive_shm),
-			PROT_READ | PROT_WRITE,	MAP_SHARED, fd, 0);
-		close(fd);
-		if (ka_shm == MAP_FAILED)
-			RTE_LOG(INFO, EAL,
-				"Failed to mmap SHM (%s)\n", strerror(errno));
-		else {
-			memset(ka_shm, 0, sizeof(struct rte_keepalive_shm));
-
-			/* Initialize the semaphores for IPC/SHM use */
-			if (sem_init(&ka_shm->core_died, 1, 0) != 0) {
-				RTE_LOG(INFO, EAL,
-					"Failed to setup SHM semaphore (%s)\n",
-					strerror(errno));
-				munmap(ka_shm,
-					sizeof(struct rte_keepalive_shm));
-				return NULL;
-			}
-
-			/* Set all cores to 'not present' */
-			for (idx_core = 0;
-					idx_core < RTE_KEEPALIVE_MAXCORES;
-					idx_core++) {
-				ka_shm->core_state[idx_core] =
-					RTE_KA_STATE_UNUSED;
-				ka_shm->core_last_seen_times[idx_core] = 0;
-			}
-
-			return ka_shm;
-		}
-	}
-return NULL;
-}
-
-void rte_keepalive_relayed_state(struct rte_keepalive_shm *shm,
-	const int id_core, const enum rte_keepalive_state core_state,
-	__rte_unused uint64_t last_alive)
-{
-	int count;
-
-	shm->core_state[id_core] = core_state;
-	shm->core_last_seen_times[id_core] = last_alive;
-
-	if (core_state == RTE_KEEPALIVE_SHM_DEAD) {
-		/* Since core has died, also signal ka_agent.
-		 *
-		 * Limit number of times semaphore can be incremented, in case
-		 * ka_agent is not active.
-		 */
-		if (sem_getvalue(&shm->core_died, &count) == -1) {
-			RTE_LOG(INFO, EAL, "Semaphore check failed(%s)\n",
-				strerror(errno));
-			return;
-		}
-		if (count > 1)
-			return;
-
-		if (sem_post(&shm->core_died) != 0)
-			RTE_LOG(INFO, EAL,
-				"Failed to increment semaphore (%s)\n",
-				strerror(errno));
-	}
-}
-
-void rte_keepalive_shm_cleanup(struct rte_keepalive_shm *ka_shm)
-{
-	if (shm_unlink(RTE_KEEPALIVE_SHM_NAME) == -1 && errno != ENOENT)
-		printf("Warning: Error unlinking  %s (%s)\n",
-			RTE_KEEPALIVE_SHM_NAME, strerror(errno));
-
-	if (ka_shm && munmap(ka_shm, sizeof(struct rte_keepalive_shm)) != 0)
-		printf("Warning: munmap() failed\n");
-}
diff --git a/examples/l2fwd-keepalive/shm.h b/examples/l2fwd-keepalive/shm.h
deleted file mode 100644
index 7a9d597..0000000
--- a/examples/l2fwd-keepalive/shm.h
+++ /dev/null
@@ -1,69 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016 Intel Corporation
- */
-
-#define RTE_KEEPALIVE_SHM_NAME "/dpdk_keepalive_shm_name"
-
-#define RTE_KEEPALIVE_SHM_ALIVE 1
-#define RTE_KEEPALIVE_SHM_DEAD 2
-
-#include <fcntl.h>
-#include <string.h>
-#include <unistd.h>
-#include <sys/mman.h>
-#include <sys/stat.h>
-#include <semaphore.h>
-#include <rte_keepalive.h>
-
-/**
- * Keepalive SHM structure.
- *
- * The shared memory allocated by the primary is this size, and contains the
- * information as contained within this struct. A secondary may open the SHM,
- * and read the contents.
- */
-struct rte_keepalive_shm {
-	/** IPC semaphore. Posted when a core dies */
-	sem_t core_died;
-
-	/**
-	 * Relayed status of each core.
-	 */
-	enum rte_keepalive_state core_state[RTE_KEEPALIVE_MAXCORES];
-
-	/**
-	 * Last-seen-alive timestamps for the cores
-	 */
-	uint64_t core_last_seen_times[RTE_KEEPALIVE_MAXCORES];
-};
-
-/**
- * Create shared host memory keepalive object.
- * @return
- *  Pointer to SHM keepalive structure, or NULL on failure.
- */
-struct rte_keepalive_shm *rte_keepalive_shm_create(void);
-
-/**
- * Relays state for given core
- * @param *shm
- *  Pointer to SHM keepalive structure.
- * @param id_core
- *  Id of core
- * @param core_state
- *  State of core
- * @param last_alive
- *  Last seen timestamp for core
- */
-void rte_keepalive_relayed_state(struct rte_keepalive_shm *shm,
-	const int id_core, const enum rte_keepalive_state core_state,
-	uint64_t last_alive);
-
-/** Shutdown cleanup of shared host memory keepalive object.
- * @param *shm
- *  Pointer to SHM keepalive structure. May be NULL.
- *
- *  If *shm is NULL, this function will only attempt to remove the
- *  shared host memory handle and not unmap the underlying memory.
- */
-void rte_keepalive_shm_cleanup(struct rte_keepalive_shm *ka_shm);
diff --git a/examples/l2fwd/Makefile b/examples/l2fwd/Makefile
deleted file mode 100644
index 1d7760d..0000000
--- a/examples/l2fwd/Makefile
+++ /dev/null
@@ -1,58 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-# binary name
-APP = l2fwd
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else # Build using legacy build system
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-endif
diff --git a/examples/l2fwd/main.c b/examples/l2fwd/main.c
deleted file mode 100644
index f8ca29c..0000000
--- a/examples/l2fwd/main.c
+++ /dev/null
@@ -1,751 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <string.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <sys/types.h>
-#include <sys/queue.h>
-#include <netinet/in.h>
-#include <setjmp.h>
-#include <stdarg.h>
-#include <ctype.h>
-#include <errno.h>
-#include <getopt.h>
-#include <signal.h>
-#include <stdbool.h>
-
-#include <rte_common.h>
-#include <rte_log.h>
-#include <rte_malloc.h>
-#include <rte_memory.h>
-#include <rte_memcpy.h>
-#include <rte_eal.h>
-#include <rte_launch.h>
-#include <rte_atomic.h>
-#include <rte_cycles.h>
-#include <rte_prefetch.h>
-#include <rte_lcore.h>
-#include <rte_per_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_interrupts.h>
-#include <rte_random.h>
-#include <rte_debug.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-
-static volatile bool force_quit;
-
-/* MAC updating enabled by default */
-static int mac_updating = 1;
-
-#define RTE_LOGTYPE_L2FWD RTE_LOGTYPE_USER1
-
-#define MAX_PKT_BURST 32
-#define BURST_TX_DRAIN_US 100 /* TX drain every ~100us */
-#define MEMPOOL_CACHE_SIZE 256
-
-/*
- * Configurable number of RX/TX ring descriptors
- */
-#define RTE_TEST_RX_DESC_DEFAULT 1024
-#define RTE_TEST_TX_DESC_DEFAULT 1024
-static uint16_t nb_rxd = RTE_TEST_RX_DESC_DEFAULT;
-static uint16_t nb_txd = RTE_TEST_TX_DESC_DEFAULT;
-
-/* ethernet addresses of ports */
-static struct ether_addr l2fwd_ports_eth_addr[RTE_MAX_ETHPORTS];
-
-/* mask of enabled ports */
-static uint32_t l2fwd_enabled_port_mask = 0;
-
-/* list of enabled ports */
-static uint32_t l2fwd_dst_ports[RTE_MAX_ETHPORTS];
-
-static unsigned int l2fwd_rx_queue_per_lcore = 1;
-
-#define MAX_RX_QUEUE_PER_LCORE 16
-#define MAX_TX_QUEUE_PER_PORT 16
-struct lcore_queue_conf {
-	unsigned n_rx_port;
-	unsigned rx_port_list[MAX_RX_QUEUE_PER_LCORE];
-} __rte_cache_aligned;
-struct lcore_queue_conf lcore_queue_conf[RTE_MAX_LCORE];
-
-static struct rte_eth_dev_tx_buffer *tx_buffer[RTE_MAX_ETHPORTS];
-
-static struct rte_eth_conf port_conf = {
-	.rxmode = {
-		.split_hdr_size = 0,
-		.ignore_offload_bitfield = 1,
-		.offloads = DEV_RX_OFFLOAD_CRC_STRIP,
-	},
-	.txmode = {
-		.mq_mode = ETH_MQ_TX_NONE,
-	},
-};
-
-struct rte_mempool * l2fwd_pktmbuf_pool = NULL;
-
-/* Per-port statistics struct */
-struct l2fwd_port_statistics {
-	uint64_t tx;
-	uint64_t rx;
-	uint64_t dropped;
-} __rte_cache_aligned;
-struct l2fwd_port_statistics port_statistics[RTE_MAX_ETHPORTS];
-
-#define MAX_TIMER_PERIOD 86400 /* 1 day max */
-/* A tsc-based timer responsible for triggering statistics printout */
-static uint64_t timer_period = 10; /* default period is 10 seconds */
-
-/* Print out statistics on packets dropped */
-static void
-print_stats(void)
-{
-	uint64_t total_packets_dropped, total_packets_tx, total_packets_rx;
-	unsigned portid;
-
-	total_packets_dropped = 0;
-	total_packets_tx = 0;
-	total_packets_rx = 0;
-
-	const char clr[] = { 27, '[', '2', 'J', '\0' };
-	const char topLeft[] = { 27, '[', '1', ';', '1', 'H','\0' };
-
-		/* Clear screen and move to top left */
-	printf("%s%s", clr, topLeft);
-
-	printf("\nPort statistics ====================================");
-
-	for (portid = 0; portid < RTE_MAX_ETHPORTS; portid++) {
-		/* skip disabled ports */
-		if ((l2fwd_enabled_port_mask & (1 << portid)) == 0)
-			continue;
-		printf("\nStatistics for port %u ------------------------------"
-			   "\nPackets sent: %24"PRIu64
-			   "\nPackets received: %20"PRIu64
-			   "\nPackets dropped: %21"PRIu64,
-			   portid,
-			   port_statistics[portid].tx,
-			   port_statistics[portid].rx,
-			   port_statistics[portid].dropped);
-
-		total_packets_dropped += port_statistics[portid].dropped;
-		total_packets_tx += port_statistics[portid].tx;
-		total_packets_rx += port_statistics[portid].rx;
-	}
-	printf("\nAggregate statistics ==============================="
-		   "\nTotal packets sent: %18"PRIu64
-		   "\nTotal packets received: %14"PRIu64
-		   "\nTotal packets dropped: %15"PRIu64,
-		   total_packets_tx,
-		   total_packets_rx,
-		   total_packets_dropped);
-	printf("\n====================================================\n");
-}
-
-static void
-l2fwd_mac_updating(struct rte_mbuf *m, unsigned dest_portid)
-{
-	struct ether_hdr *eth;
-	void *tmp;
-
-	eth = rte_pktmbuf_mtod(m, struct ether_hdr *);
-
-	/* 02:00:00:00:00:xx */
-	tmp = &eth->d_addr.addr_bytes[0];
-	*((uint64_t *)tmp) = 0x000000000002 + ((uint64_t)dest_portid << 40);
-
-	/* src addr */
-	ether_addr_copy(&l2fwd_ports_eth_addr[dest_portid], &eth->s_addr);
-}
-
-static void
-l2fwd_simple_forward(struct rte_mbuf *m, unsigned portid)
-{
-	unsigned dst_port;
-	int sent;
-	struct rte_eth_dev_tx_buffer *buffer;
-
-	dst_port = l2fwd_dst_ports[portid];
-
-	if (mac_updating)
-		l2fwd_mac_updating(m, dst_port);
-
-	buffer = tx_buffer[dst_port];
-	sent = rte_eth_tx_buffer(dst_port, 0, buffer, m);
-	if (sent)
-		port_statistics[dst_port].tx += sent;
-}
-
-/* main processing loop */
-static void
-l2fwd_main_loop(void)
-{
-	struct rte_mbuf *pkts_burst[MAX_PKT_BURST];
-	struct rte_mbuf *m;
-	int sent;
-	unsigned lcore_id;
-	uint64_t prev_tsc, diff_tsc, cur_tsc, timer_tsc;
-	unsigned i, j, portid, nb_rx;
-	struct lcore_queue_conf *qconf;
-	const uint64_t drain_tsc = (rte_get_tsc_hz() + US_PER_S - 1) / US_PER_S *
-			BURST_TX_DRAIN_US;
-	struct rte_eth_dev_tx_buffer *buffer;
-
-	prev_tsc = 0;
-	timer_tsc = 0;
-
-	lcore_id = rte_lcore_id();
-	qconf = &lcore_queue_conf[lcore_id];
-
-	if (qconf->n_rx_port == 0) {
-		RTE_LOG(INFO, L2FWD, "lcore %u has nothing to do\n", lcore_id);
-		return;
-	}
-
-	RTE_LOG(INFO, L2FWD, "entering main loop on lcore %u\n", lcore_id);
-
-	for (i = 0; i < qconf->n_rx_port; i++) {
-
-		portid = qconf->rx_port_list[i];
-		RTE_LOG(INFO, L2FWD, " -- lcoreid=%u portid=%u\n", lcore_id,
-			portid);
-
-	}
-
-	while (!force_quit) {
-
-		cur_tsc = rte_rdtsc();
-
-		/*
-		 * TX burst queue drain
-		 */
-		diff_tsc = cur_tsc - prev_tsc;
-		if (unlikely(diff_tsc > drain_tsc)) {
-
-			for (i = 0; i < qconf->n_rx_port; i++) {
-
-				portid = l2fwd_dst_ports[qconf->rx_port_list[i]];
-				buffer = tx_buffer[portid];
-
-				sent = rte_eth_tx_buffer_flush(portid, 0, buffer);
-				if (sent)
-					port_statistics[portid].tx += sent;
-
-			}
-
-			/* if timer is enabled */
-			if (timer_period > 0) {
-
-				/* advance the timer */
-				timer_tsc += diff_tsc;
-
-				/* if timer has reached its timeout */
-				if (unlikely(timer_tsc >= timer_period)) {
-
-					/* do this only on master core */
-					if (lcore_id == rte_get_master_lcore()) {
-						print_stats();
-						/* reset the timer */
-						timer_tsc = 0;
-					}
-				}
-			}
-
-			prev_tsc = cur_tsc;
-		}
-
-		/*
-		 * Read packet from RX queues
-		 */
-		for (i = 0; i < qconf->n_rx_port; i++) {
-
-			portid = qconf->rx_port_list[i];
-			nb_rx = rte_eth_rx_burst(portid, 0,
-						 pkts_burst, MAX_PKT_BURST);
-
-			port_statistics[portid].rx += nb_rx;
-
-			for (j = 0; j < nb_rx; j++) {
-				m = pkts_burst[j];
-				rte_prefetch0(rte_pktmbuf_mtod(m, void *));
-				l2fwd_simple_forward(m, portid);
-			}
-		}
-	}
-}
-
-static int
-l2fwd_launch_one_lcore(__attribute__((unused)) void *dummy)
-{
-	l2fwd_main_loop();
-	return 0;
-}
-
-/* display usage */
-static void
-l2fwd_usage(const char *prgname)
-{
-	printf("%s [EAL options] -- -p PORTMASK [-q NQ]\n"
-	       "  -p PORTMASK: hexadecimal bitmask of ports to configure\n"
-	       "  -q NQ: number of queue (=ports) per lcore (default is 1)\n"
-		   "  -T PERIOD: statistics will be refreshed each PERIOD seconds (0 to disable, 10 default, 86400 maximum)\n"
-		   "  --[no-]mac-updating: Enable or disable MAC addresses updating (enabled by default)\n"
-		   "      When enabled:\n"
-		   "       - The source MAC address is replaced by the TX port MAC address\n"
-		   "       - The destination MAC address is replaced by 02:00:00:00:00:TX_PORT_ID\n",
-	       prgname);
-}
-
-static int
-l2fwd_parse_portmask(const char *portmask)
-{
-	char *end = NULL;
-	unsigned long pm;
-
-	/* parse hexadecimal string */
-	pm = strtoul(portmask, &end, 16);
-	if ((portmask[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (pm == 0)
-		return -1;
-
-	return pm;
-}
-
-static unsigned int
-l2fwd_parse_nqueue(const char *q_arg)
-{
-	char *end = NULL;
-	unsigned long n;
-
-	/* parse hexadecimal string */
-	n = strtoul(q_arg, &end, 10);
-	if ((q_arg[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return 0;
-	if (n == 0)
-		return 0;
-	if (n >= MAX_RX_QUEUE_PER_LCORE)
-		return 0;
-
-	return n;
-}
-
-static int
-l2fwd_parse_timer_period(const char *q_arg)
-{
-	char *end = NULL;
-	int n;
-
-	/* parse number string */
-	n = strtol(q_arg, &end, 10);
-	if ((q_arg[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-	if (n >= MAX_TIMER_PERIOD)
-		return -1;
-
-	return n;
-}
-
-static const char short_options[] =
-	"p:"  /* portmask */
-	"q:"  /* number of queues */
-	"T:"  /* timer period */
-	;
-
-#define CMD_LINE_OPT_MAC_UPDATING "mac-updating"
-#define CMD_LINE_OPT_NO_MAC_UPDATING "no-mac-updating"
-
-enum {
-	/* long options mapped to a short option */
-
-	/* first long only option value must be >= 256, so that we won't
-	 * conflict with short options */
-	CMD_LINE_OPT_MIN_NUM = 256,
-};
-
-static const struct option lgopts[] = {
-	{ CMD_LINE_OPT_MAC_UPDATING, no_argument, &mac_updating, 1},
-	{ CMD_LINE_OPT_NO_MAC_UPDATING, no_argument, &mac_updating, 0},
-	{NULL, 0, 0, 0}
-};
-
-/* Parse the argument given in the command line of the application */
-static int
-l2fwd_parse_args(int argc, char **argv)
-{
-	int opt, ret, timer_secs;
-	char **argvopt;
-	int option_index;
-	char *prgname = argv[0];
-
-	argvopt = argv;
-
-	while ((opt = getopt_long(argc, argvopt, short_options,
-				  lgopts, &option_index)) != EOF) {
-
-		switch (opt) {
-		/* portmask */
-		case 'p':
-			l2fwd_enabled_port_mask = l2fwd_parse_portmask(optarg);
-			if (l2fwd_enabled_port_mask == 0) {
-				printf("invalid portmask\n");
-				l2fwd_usage(prgname);
-				return -1;
-			}
-			break;
-
-		/* nqueue */
-		case 'q':
-			l2fwd_rx_queue_per_lcore = l2fwd_parse_nqueue(optarg);
-			if (l2fwd_rx_queue_per_lcore == 0) {
-				printf("invalid queue number\n");
-				l2fwd_usage(prgname);
-				return -1;
-			}
-			break;
-
-		/* timer period */
-		case 'T':
-			timer_secs = l2fwd_parse_timer_period(optarg);
-			if (timer_secs < 0) {
-				printf("invalid timer period\n");
-				l2fwd_usage(prgname);
-				return -1;
-			}
-			timer_period = timer_secs;
-			break;
-
-		/* long options */
-		case 0:
-			break;
-
-		default:
-			l2fwd_usage(prgname);
-			return -1;
-		}
-	}
-
-	if (optind >= 0)
-		argv[optind-1] = prgname;
-
-	ret = optind-1;
-	optind = 1; /* reset getopt lib */
-	return ret;
-}
-
-/* Check the link status of all ports in up to 9s, and print them finally */
-static void
-check_all_ports_link_status(uint32_t port_mask)
-{
-#define CHECK_INTERVAL 100 /* 100ms */
-#define MAX_CHECK_TIME 90 /* 9s (90 * 100ms) in total */
-	uint16_t portid;
-	uint8_t count, all_ports_up, print_flag = 0;
-	struct rte_eth_link link;
-
-	printf("\nChecking link status");
-	fflush(stdout);
-	for (count = 0; count <= MAX_CHECK_TIME; count++) {
-		if (force_quit)
-			return;
-		all_ports_up = 1;
-		RTE_ETH_FOREACH_DEV(portid) {
-			if (force_quit)
-				return;
-			if ((port_mask & (1 << portid)) == 0)
-				continue;
-			memset(&link, 0, sizeof(link));
-			rte_eth_link_get_nowait(portid, &link);
-			/* print link status if flag set */
-			if (print_flag == 1) {
-				if (link.link_status)
-					printf(
-					"Port%d Link Up. Speed %u Mbps - %s\n",
-						portid, link.link_speed,
-				(link.link_duplex == ETH_LINK_FULL_DUPLEX) ?
-					("full-duplex") : ("half-duplex\n"));
-				else
-					printf("Port %d Link Down\n", portid);
-				continue;
-			}
-			/* clear all_ports_up flag if any link down */
-			if (link.link_status == ETH_LINK_DOWN) {
-				all_ports_up = 0;
-				break;
-			}
-		}
-		/* after finally printing all link status, get out */
-		if (print_flag == 1)
-			break;
-
-		if (all_ports_up == 0) {
-			printf(".");
-			fflush(stdout);
-			rte_delay_ms(CHECK_INTERVAL);
-		}
-
-		/* set the print_flag if all ports up or timeout */
-		if (all_ports_up == 1 || count == (MAX_CHECK_TIME - 1)) {
-			print_flag = 1;
-			printf("done\n");
-		}
-	}
-}
-
-static void
-signal_handler(int signum)
-{
-	if (signum == SIGINT || signum == SIGTERM) {
-		printf("\n\nSignal %d received, preparing to exit...\n",
-				signum);
-		force_quit = true;
-	}
-}
-
-int
-main(int argc, char **argv)
-{
-	struct lcore_queue_conf *qconf;
-	int ret;
-	uint16_t nb_ports;
-	uint16_t nb_ports_available = 0;
-	uint16_t portid, last_port;
-	unsigned lcore_id, rx_lcore_id;
-	unsigned nb_ports_in_mask = 0;
-	unsigned int nb_lcores = 0;
-	unsigned int nb_mbufs;
-
-	/* init EAL */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid EAL arguments\n");
-	argc -= ret;
-	argv += ret;
-
-	force_quit = false;
-	signal(SIGINT, signal_handler);
-	signal(SIGTERM, signal_handler);
-
-	/* parse application arguments (after the EAL ones) */
-	ret = l2fwd_parse_args(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid L2FWD arguments\n");
-
-	printf("MAC updating %s\n", mac_updating ? "enabled" : "disabled");
-
-	/* convert to number of cycles */
-	timer_period *= rte_get_timer_hz();
-
-	nb_ports = rte_eth_dev_count();
-	if (nb_ports == 0)
-		rte_exit(EXIT_FAILURE, "No Ethernet ports - bye\n");
-
-	/* check port mask to possible port mask */
-	if (l2fwd_enabled_port_mask & ~((1 << nb_ports) - 1))
-		rte_exit(EXIT_FAILURE, "Invalid portmask; possible (0x%x)\n",
-			(1 << nb_ports) - 1);
-
-	/* reset l2fwd_dst_ports */
-	for (portid = 0; portid < RTE_MAX_ETHPORTS; portid++)
-		l2fwd_dst_ports[portid] = 0;
-	last_port = 0;
-
-	/*
-	 * Each logical core is assigned a dedicated TX queue on each port.
-	 */
-	RTE_ETH_FOREACH_DEV(portid) {
-		/* skip ports that are not enabled */
-		if ((l2fwd_enabled_port_mask & (1 << portid)) == 0)
-			continue;
-
-		if (nb_ports_in_mask % 2) {
-			l2fwd_dst_ports[portid] = last_port;
-			l2fwd_dst_ports[last_port] = portid;
-		}
-		else
-			last_port = portid;
-
-		nb_ports_in_mask++;
-	}
-	if (nb_ports_in_mask % 2) {
-		printf("Notice: odd number of ports in portmask.\n");
-		l2fwd_dst_ports[last_port] = last_port;
-	}
-
-	rx_lcore_id = 0;
-	qconf = NULL;
-
-	/* Initialize the port/queue configuration of each logical core */
-	RTE_ETH_FOREACH_DEV(portid) {
-		/* skip ports that are not enabled */
-		if ((l2fwd_enabled_port_mask & (1 << portid)) == 0)
-			continue;
-
-		/* get the lcore_id for this port */
-		while (rte_lcore_is_enabled(rx_lcore_id) == 0 ||
-		       lcore_queue_conf[rx_lcore_id].n_rx_port ==
-		       l2fwd_rx_queue_per_lcore) {
-			rx_lcore_id++;
-			if (rx_lcore_id >= RTE_MAX_LCORE)
-				rte_exit(EXIT_FAILURE, "Not enough cores\n");
-		}
-
-		if (qconf != &lcore_queue_conf[rx_lcore_id]) {
-			/* Assigned a new logical core in the loop above. */
-			qconf = &lcore_queue_conf[rx_lcore_id];
-			nb_lcores++;
-		}
-
-		qconf->rx_port_list[qconf->n_rx_port] = portid;
-		qconf->n_rx_port++;
-		printf("Lcore %u: RX port %u\n", rx_lcore_id, portid);
-	}
-
-	nb_mbufs = RTE_MAX(nb_ports * (nb_rxd + nb_txd + MAX_PKT_BURST +
-		nb_lcores * MEMPOOL_CACHE_SIZE), 8192U);
-
-	/* create the mbuf pool */
-	l2fwd_pktmbuf_pool = rte_pktmbuf_pool_create("mbuf_pool", nb_mbufs,
-		MEMPOOL_CACHE_SIZE, 0, RTE_MBUF_DEFAULT_BUF_SIZE,
-		rte_socket_id());
-	if (l2fwd_pktmbuf_pool == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot init mbuf pool\n");
-
-	/* Initialise each port */
-	RTE_ETH_FOREACH_DEV(portid) {
-		struct rte_eth_rxconf rxq_conf;
-		struct rte_eth_txconf txq_conf;
-		struct rte_eth_conf local_port_conf = port_conf;
-		struct rte_eth_dev_info dev_info;
-
-		/* skip ports that are not enabled */
-		if ((l2fwd_enabled_port_mask & (1 << portid)) == 0) {
-			printf("Skipping disabled port %u\n", portid);
-			continue;
-		}
-		nb_ports_available++;
-
-		/* init port */
-		printf("Initializing port %u... ", portid);
-		fflush(stdout);
-		rte_eth_dev_info_get(portid, &dev_info);
-		if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-			local_port_conf.txmode.offloads |=
-				DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-		ret = rte_eth_dev_configure(portid, 1, 1, &local_port_conf);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "Cannot configure device: err=%d, port=%u\n",
-				  ret, portid);
-
-		ret = rte_eth_dev_adjust_nb_rx_tx_desc(portid, &nb_rxd,
-						       &nb_txd);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-				 "Cannot adjust number of descriptors: err=%d, port=%u\n",
-				 ret, portid);
-
-		rte_eth_macaddr_get(portid,&l2fwd_ports_eth_addr[portid]);
-
-		/* init one RX queue */
-		fflush(stdout);
-		rxq_conf = dev_info.default_rxconf;
-		rxq_conf.offloads = local_port_conf.rxmode.offloads;
-		ret = rte_eth_rx_queue_setup(portid, 0, nb_rxd,
-					     rte_eth_dev_socket_id(portid),
-					     &rxq_conf,
-					     l2fwd_pktmbuf_pool);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "rte_eth_rx_queue_setup:err=%d, port=%u\n",
-				  ret, portid);
-
-		/* init one TX queue on each port */
-		fflush(stdout);
-		txq_conf = dev_info.default_txconf;
-		txq_conf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-		txq_conf.offloads = local_port_conf.txmode.offloads;
-		ret = rte_eth_tx_queue_setup(portid, 0, nb_txd,
-				rte_eth_dev_socket_id(portid),
-				&txq_conf);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "rte_eth_tx_queue_setup:err=%d, port=%u\n",
-				ret, portid);
-
-		/* Initialize TX buffers */
-		tx_buffer[portid] = rte_zmalloc_socket("tx_buffer",
-				RTE_ETH_TX_BUFFER_SIZE(MAX_PKT_BURST), 0,
-				rte_eth_dev_socket_id(portid));
-		if (tx_buffer[portid] == NULL)
-			rte_exit(EXIT_FAILURE, "Cannot allocate buffer for tx on port %u\n",
-					portid);
-
-		rte_eth_tx_buffer_init(tx_buffer[portid], MAX_PKT_BURST);
-
-		ret = rte_eth_tx_buffer_set_err_callback(tx_buffer[portid],
-				rte_eth_tx_buffer_count_callback,
-				&port_statistics[portid].dropped);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-			"Cannot set error callback for tx buffer on port %u\n",
-				 portid);
-
-		/* Start device */
-		ret = rte_eth_dev_start(portid);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "rte_eth_dev_start:err=%d, port=%u\n",
-				  ret, portid);
-
-		printf("done: \n");
-
-		rte_eth_promiscuous_enable(portid);
-
-		printf("Port %u, MAC address: %02X:%02X:%02X:%02X:%02X:%02X\n\n",
-				portid,
-				l2fwd_ports_eth_addr[portid].addr_bytes[0],
-				l2fwd_ports_eth_addr[portid].addr_bytes[1],
-				l2fwd_ports_eth_addr[portid].addr_bytes[2],
-				l2fwd_ports_eth_addr[portid].addr_bytes[3],
-				l2fwd_ports_eth_addr[portid].addr_bytes[4],
-				l2fwd_ports_eth_addr[portid].addr_bytes[5]);
-
-		/* initialize port stats */
-		memset(&port_statistics, 0, sizeof(port_statistics));
-	}
-
-	if (!nb_ports_available) {
-		rte_exit(EXIT_FAILURE,
-			"All available ports are disabled. Please set portmask.\n");
-	}
-
-	check_all_ports_link_status(l2fwd_enabled_port_mask);
-
-	ret = 0;
-	/* launch per-lcore init on every lcore */
-	rte_eal_mp_remote_launch(l2fwd_launch_one_lcore, NULL, CALL_MASTER);
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		if (rte_eal_wait_lcore(lcore_id) < 0) {
-			ret = -1;
-			break;
-		}
-	}
-
-	RTE_ETH_FOREACH_DEV(portid) {
-		if ((l2fwd_enabled_port_mask & (1 << portid)) == 0)
-			continue;
-		printf("Closing port %d...", portid);
-		rte_eth_dev_stop(portid);
-		rte_eth_dev_close(portid);
-		printf(" Done\n");
-	}
-	printf("Bye...\n");
-
-	return ret;
-}
diff --git a/examples/l2fwd/meson.build b/examples/l2fwd/meson.build
deleted file mode 100644
index 2b0a250..0000000
--- a/examples/l2fwd/meson.build
+++ /dev/null
@@ -1,12 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-allow_experimental_apis = true
-sources = files(
-	'main.c'
-)
diff --git a/examples/l3fwd-acl/Makefile b/examples/l3fwd-acl/Makefile
deleted file mode 100644
index eabca1e..0000000
--- a/examples/l3fwd-acl/Makefile
+++ /dev/null
@@ -1,64 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-# binary name
-APP = l3fwd-acl
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else # Build using legacy build system
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-
-# workaround for a gcc bug with noreturn attribute
-# http://gcc.gnu.org/bugzilla/show_bug.cgi?id=12603
-ifeq ($(CONFIG_RTE_TOOLCHAIN_GCC),y)
-CFLAGS_main.o += -Wno-return-type
-endif
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-endif
diff --git a/examples/l3fwd-acl/main.c b/examples/l3fwd-acl/main.c
deleted file mode 100644
index 2c891b4..0000000
--- a/examples/l3fwd-acl/main.c
+++ /dev/null
@@ -1,2077 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <sys/types.h>
-#include <string.h>
-#include <sys/queue.h>
-#include <stdarg.h>
-#include <errno.h>
-#include <getopt.h>
-
-#include <rte_common.h>
-#include <rte_byteorder.h>
-#include <rte_log.h>
-#include <rte_memory.h>
-#include <rte_memcpy.h>
-#include <rte_eal.h>
-#include <rte_launch.h>
-#include <rte_atomic.h>
-#include <rte_cycles.h>
-#include <rte_prefetch.h>
-#include <rte_lcore.h>
-#include <rte_per_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_interrupts.h>
-#include <rte_random.h>
-#include <rte_debug.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-#include <rte_ip.h>
-#include <rte_tcp.h>
-#include <rte_udp.h>
-#include <rte_string_fns.h>
-#include <rte_acl.h>
-
-#if RTE_LOG_DP_LEVEL >= RTE_LOG_DEBUG
-#define L3FWDACL_DEBUG
-#endif
-#define DO_RFC_1812_CHECKS
-
-#define RTE_LOGTYPE_L3FWD RTE_LOGTYPE_USER1
-
-#define MAX_JUMBO_PKT_LEN  9600
-
-#define MEMPOOL_CACHE_SIZE 256
-
-/*
- * This expression is used to calculate the number of mbufs needed
- * depending on user input, taking into account memory for rx and tx hardware
- * rings, cache per lcore and mtable per port per lcore.
- * RTE_MAX is used to ensure that NB_MBUF never goes below a
- * minimum value of 8192
- */
-
-#define NB_MBUF	RTE_MAX(\
-	(nb_ports * nb_rx_queue * nb_rxd +	\
-	nb_ports * nb_lcores * MAX_PKT_BURST +	\
-	nb_ports * n_tx_queue * nb_txd +	\
-	nb_lcores * MEMPOOL_CACHE_SIZE),	\
-	(unsigned)8192)
-
-#define MAX_PKT_BURST 32
-#define BURST_TX_DRAIN_US 100 /* TX drain every ~100us */
-
-#define NB_SOCKETS 8
-
-/* Configure how many packets ahead to prefetch, when reading packets */
-#define PREFETCH_OFFSET	3
-
-/*
- * Configurable number of RX/TX ring descriptors
- */
-#define RTE_TEST_RX_DESC_DEFAULT 1024
-#define RTE_TEST_TX_DESC_DEFAULT 1024
-static uint16_t nb_rxd = RTE_TEST_RX_DESC_DEFAULT;
-static uint16_t nb_txd = RTE_TEST_TX_DESC_DEFAULT;
-
-/* ethernet addresses of ports */
-static struct ether_addr ports_eth_addr[RTE_MAX_ETHPORTS];
-
-/* mask of enabled ports */
-static uint32_t enabled_port_mask;
-static int promiscuous_on; /**< Ports set in promiscuous mode off by default. */
-static int numa_on = 1; /**< NUMA is enabled by default. */
-
-struct lcore_rx_queue {
-	uint16_t port_id;
-	uint8_t queue_id;
-} __rte_cache_aligned;
-
-#define MAX_RX_QUEUE_PER_LCORE 16
-#define MAX_TX_QUEUE_PER_PORT RTE_MAX_ETHPORTS
-#define MAX_RX_QUEUE_PER_PORT 128
-
-#define MAX_LCORE_PARAMS 1024
-struct lcore_params {
-	uint16_t port_id;
-	uint8_t queue_id;
-	uint8_t lcore_id;
-} __rte_cache_aligned;
-
-static struct lcore_params lcore_params_array[MAX_LCORE_PARAMS];
-static struct lcore_params lcore_params_array_default[] = {
-	{0, 0, 2},
-	{0, 1, 2},
-	{0, 2, 2},
-	{1, 0, 2},
-	{1, 1, 2},
-	{1, 2, 2},
-	{2, 0, 2},
-	{3, 0, 3},
-	{3, 1, 3},
-};
-
-static struct lcore_params *lcore_params = lcore_params_array_default;
-static uint16_t nb_lcore_params = sizeof(lcore_params_array_default) /
-				sizeof(lcore_params_array_default[0]);
-
-static struct rte_eth_conf port_conf = {
-	.rxmode = {
-		.mq_mode	= ETH_MQ_RX_RSS,
-		.max_rx_pkt_len = ETHER_MAX_LEN,
-		.split_hdr_size = 0,
-		.ignore_offload_bitfield = 1,
-		.offloads = (DEV_RX_OFFLOAD_CRC_STRIP |
-			     DEV_RX_OFFLOAD_CHECKSUM),
-	},
-	.rx_adv_conf = {
-		.rss_conf = {
-			.rss_key = NULL,
-			.rss_hf = ETH_RSS_IP | ETH_RSS_UDP |
-				ETH_RSS_TCP | ETH_RSS_SCTP,
-		},
-	},
-	.txmode = {
-		.mq_mode = ETH_MQ_TX_NONE,
-	},
-};
-
-static struct rte_mempool *pktmbuf_pool[NB_SOCKETS];
-
-/***********************start of ACL part******************************/
-#ifdef DO_RFC_1812_CHECKS
-static inline int
-is_valid_ipv4_pkt(struct ipv4_hdr *pkt, uint32_t link_len);
-#endif
-static inline void
-send_single_packet(struct rte_mbuf *m, uint16_t port);
-
-#define MAX_ACL_RULE_NUM	100000
-#define DEFAULT_MAX_CATEGORIES	1
-#define L3FWD_ACL_IPV4_NAME	"l3fwd-acl-ipv4"
-#define L3FWD_ACL_IPV6_NAME	"l3fwd-acl-ipv6"
-#define ACL_LEAD_CHAR		('@')
-#define ROUTE_LEAD_CHAR		('R')
-#define COMMENT_LEAD_CHAR	('#')
-#define OPTION_CONFIG		"config"
-#define OPTION_NONUMA		"no-numa"
-#define OPTION_ENBJMO		"enable-jumbo"
-#define OPTION_RULE_IPV4	"rule_ipv4"
-#define OPTION_RULE_IPV6	"rule_ipv6"
-#define OPTION_SCALAR		"scalar"
-#define ACL_DENY_SIGNATURE	0xf0000000
-#define RTE_LOGTYPE_L3FWDACL	RTE_LOGTYPE_USER3
-#define acl_log(format, ...)	RTE_LOG(ERR, L3FWDACL, format, ##__VA_ARGS__)
-#define uint32_t_to_char(ip, a, b, c, d) do {\
-		*a = (unsigned char)(ip >> 24 & 0xff);\
-		*b = (unsigned char)(ip >> 16 & 0xff);\
-		*c = (unsigned char)(ip >> 8 & 0xff);\
-		*d = (unsigned char)(ip & 0xff);\
-	} while (0)
-#define OFF_ETHHEAD	(sizeof(struct ether_hdr))
-#define OFF_IPV42PROTO (offsetof(struct ipv4_hdr, next_proto_id))
-#define OFF_IPV62PROTO (offsetof(struct ipv6_hdr, proto))
-#define MBUF_IPV4_2PROTO(m)	\
-	rte_pktmbuf_mtod_offset((m), uint8_t *, OFF_ETHHEAD + OFF_IPV42PROTO)
-#define MBUF_IPV6_2PROTO(m)	\
-	rte_pktmbuf_mtod_offset((m), uint8_t *, OFF_ETHHEAD + OFF_IPV62PROTO)
-
-#define GET_CB_FIELD(in, fd, base, lim, dlm)	do {            \
-	unsigned long val;                                      \
-	char *end;                                              \
-	errno = 0;                                              \
-	val = strtoul((in), &end, (base));                      \
-	if (errno != 0 || end[0] != (dlm) || val > (lim))       \
-		return -EINVAL;                               \
-	(fd) = (typeof(fd))val;                                 \
-	(in) = end + 1;                                         \
-} while (0)
-
-/*
-  * ACL rules should have higher priorities than route ones to ensure ACL rule
-  * always be found when input packets have multi-matches in the database.
-  * A exception case is performance measure, which can define route rules with
-  * higher priority and route rules will always be returned in each lookup.
-  * Reserve range from ACL_RULE_PRIORITY_MAX + 1 to
-  * RTE_ACL_MAX_PRIORITY for route entries in performance measure
-  */
-#define ACL_RULE_PRIORITY_MAX 0x10000000
-
-/*
-  * Forward port info save in ACL lib starts from 1
-  * since ACL assume 0 is invalid.
-  * So, need add 1 when saving and minus 1 when forwarding packets.
-  */
-#define FWD_PORT_SHIFT 1
-
-/*
- * Rule and trace formats definitions.
- */
-
-enum {
-	PROTO_FIELD_IPV4,
-	SRC_FIELD_IPV4,
-	DST_FIELD_IPV4,
-	SRCP_FIELD_IPV4,
-	DSTP_FIELD_IPV4,
-	NUM_FIELDS_IPV4
-};
-
-/*
- * That effectively defines order of IPV4VLAN classifications:
- *  - PROTO
- *  - VLAN (TAG and DOMAIN)
- *  - SRC IP ADDRESS
- *  - DST IP ADDRESS
- *  - PORTS (SRC and DST)
- */
-enum {
-	RTE_ACL_IPV4VLAN_PROTO,
-	RTE_ACL_IPV4VLAN_VLAN,
-	RTE_ACL_IPV4VLAN_SRC,
-	RTE_ACL_IPV4VLAN_DST,
-	RTE_ACL_IPV4VLAN_PORTS,
-	RTE_ACL_IPV4VLAN_NUM
-};
-
-struct rte_acl_field_def ipv4_defs[NUM_FIELDS_IPV4] = {
-	{
-		.type = RTE_ACL_FIELD_TYPE_BITMASK,
-		.size = sizeof(uint8_t),
-		.field_index = PROTO_FIELD_IPV4,
-		.input_index = RTE_ACL_IPV4VLAN_PROTO,
-		.offset = 0,
-	},
-	{
-		.type = RTE_ACL_FIELD_TYPE_MASK,
-		.size = sizeof(uint32_t),
-		.field_index = SRC_FIELD_IPV4,
-		.input_index = RTE_ACL_IPV4VLAN_SRC,
-		.offset = offsetof(struct ipv4_hdr, src_addr) -
-			offsetof(struct ipv4_hdr, next_proto_id),
-	},
-	{
-		.type = RTE_ACL_FIELD_TYPE_MASK,
-		.size = sizeof(uint32_t),
-		.field_index = DST_FIELD_IPV4,
-		.input_index = RTE_ACL_IPV4VLAN_DST,
-		.offset = offsetof(struct ipv4_hdr, dst_addr) -
-			offsetof(struct ipv4_hdr, next_proto_id),
-	},
-	{
-		.type = RTE_ACL_FIELD_TYPE_RANGE,
-		.size = sizeof(uint16_t),
-		.field_index = SRCP_FIELD_IPV4,
-		.input_index = RTE_ACL_IPV4VLAN_PORTS,
-		.offset = sizeof(struct ipv4_hdr) -
-			offsetof(struct ipv4_hdr, next_proto_id),
-	},
-	{
-		.type = RTE_ACL_FIELD_TYPE_RANGE,
-		.size = sizeof(uint16_t),
-		.field_index = DSTP_FIELD_IPV4,
-		.input_index = RTE_ACL_IPV4VLAN_PORTS,
-		.offset = sizeof(struct ipv4_hdr) -
-			offsetof(struct ipv4_hdr, next_proto_id) +
-			sizeof(uint16_t),
-	},
-};
-
-#define	IPV6_ADDR_LEN	16
-#define	IPV6_ADDR_U16	(IPV6_ADDR_LEN / sizeof(uint16_t))
-#define	IPV6_ADDR_U32	(IPV6_ADDR_LEN / sizeof(uint32_t))
-
-enum {
-	PROTO_FIELD_IPV6,
-	SRC1_FIELD_IPV6,
-	SRC2_FIELD_IPV6,
-	SRC3_FIELD_IPV6,
-	SRC4_FIELD_IPV6,
-	DST1_FIELD_IPV6,
-	DST2_FIELD_IPV6,
-	DST3_FIELD_IPV6,
-	DST4_FIELD_IPV6,
-	SRCP_FIELD_IPV6,
-	DSTP_FIELD_IPV6,
-	NUM_FIELDS_IPV6
-};
-
-struct rte_acl_field_def ipv6_defs[NUM_FIELDS_IPV6] = {
-	{
-		.type = RTE_ACL_FIELD_TYPE_BITMASK,
-		.size = sizeof(uint8_t),
-		.field_index = PROTO_FIELD_IPV6,
-		.input_index = PROTO_FIELD_IPV6,
-		.offset = 0,
-	},
-	{
-		.type = RTE_ACL_FIELD_TYPE_MASK,
-		.size = sizeof(uint32_t),
-		.field_index = SRC1_FIELD_IPV6,
-		.input_index = SRC1_FIELD_IPV6,
-		.offset = offsetof(struct ipv6_hdr, src_addr) -
-			offsetof(struct ipv6_hdr, proto),
-	},
-	{
-		.type = RTE_ACL_FIELD_TYPE_MASK,
-		.size = sizeof(uint32_t),
-		.field_index = SRC2_FIELD_IPV6,
-		.input_index = SRC2_FIELD_IPV6,
-		.offset = offsetof(struct ipv6_hdr, src_addr) -
-			offsetof(struct ipv6_hdr, proto) + sizeof(uint32_t),
-	},
-	{
-		.type = RTE_ACL_FIELD_TYPE_MASK,
-		.size = sizeof(uint32_t),
-		.field_index = SRC3_FIELD_IPV6,
-		.input_index = SRC3_FIELD_IPV6,
-		.offset = offsetof(struct ipv6_hdr, src_addr) -
-			offsetof(struct ipv6_hdr, proto) + 2 * sizeof(uint32_t),
-	},
-	{
-		.type = RTE_ACL_FIELD_TYPE_MASK,
-		.size = sizeof(uint32_t),
-		.field_index = SRC4_FIELD_IPV6,
-		.input_index = SRC4_FIELD_IPV6,
-		.offset = offsetof(struct ipv6_hdr, src_addr) -
-			offsetof(struct ipv6_hdr, proto) + 3 * sizeof(uint32_t),
-	},
-	{
-		.type = RTE_ACL_FIELD_TYPE_MASK,
-		.size = sizeof(uint32_t),
-		.field_index = DST1_FIELD_IPV6,
-		.input_index = DST1_FIELD_IPV6,
-		.offset = offsetof(struct ipv6_hdr, dst_addr)
-				- offsetof(struct ipv6_hdr, proto),
-	},
-	{
-		.type = RTE_ACL_FIELD_TYPE_MASK,
-		.size = sizeof(uint32_t),
-		.field_index = DST2_FIELD_IPV6,
-		.input_index = DST2_FIELD_IPV6,
-		.offset = offsetof(struct ipv6_hdr, dst_addr) -
-			offsetof(struct ipv6_hdr, proto) + sizeof(uint32_t),
-	},
-	{
-		.type = RTE_ACL_FIELD_TYPE_MASK,
-		.size = sizeof(uint32_t),
-		.field_index = DST3_FIELD_IPV6,
-		.input_index = DST3_FIELD_IPV6,
-		.offset = offsetof(struct ipv6_hdr, dst_addr) -
-			offsetof(struct ipv6_hdr, proto) + 2 * sizeof(uint32_t),
-	},
-	{
-		.type = RTE_ACL_FIELD_TYPE_MASK,
-		.size = sizeof(uint32_t),
-		.field_index = DST4_FIELD_IPV6,
-		.input_index = DST4_FIELD_IPV6,
-		.offset = offsetof(struct ipv6_hdr, dst_addr) -
-			offsetof(struct ipv6_hdr, proto) + 3 * sizeof(uint32_t),
-	},
-	{
-		.type = RTE_ACL_FIELD_TYPE_RANGE,
-		.size = sizeof(uint16_t),
-		.field_index = SRCP_FIELD_IPV6,
-		.input_index = SRCP_FIELD_IPV6,
-		.offset = sizeof(struct ipv6_hdr) -
-			offsetof(struct ipv6_hdr, proto),
-	},
-	{
-		.type = RTE_ACL_FIELD_TYPE_RANGE,
-		.size = sizeof(uint16_t),
-		.field_index = DSTP_FIELD_IPV6,
-		.input_index = SRCP_FIELD_IPV6,
-		.offset = sizeof(struct ipv6_hdr) -
-			offsetof(struct ipv6_hdr, proto) + sizeof(uint16_t),
-	},
-};
-
-enum {
-	CB_FLD_SRC_ADDR,
-	CB_FLD_DST_ADDR,
-	CB_FLD_SRC_PORT_LOW,
-	CB_FLD_SRC_PORT_DLM,
-	CB_FLD_SRC_PORT_HIGH,
-	CB_FLD_DST_PORT_LOW,
-	CB_FLD_DST_PORT_DLM,
-	CB_FLD_DST_PORT_HIGH,
-	CB_FLD_PROTO,
-	CB_FLD_USERDATA,
-	CB_FLD_NUM,
-};
-
-RTE_ACL_RULE_DEF(acl4_rule, RTE_DIM(ipv4_defs));
-RTE_ACL_RULE_DEF(acl6_rule, RTE_DIM(ipv6_defs));
-
-struct acl_search_t {
-	const uint8_t *data_ipv4[MAX_PKT_BURST];
-	struct rte_mbuf *m_ipv4[MAX_PKT_BURST];
-	uint32_t res_ipv4[MAX_PKT_BURST];
-	int num_ipv4;
-
-	const uint8_t *data_ipv6[MAX_PKT_BURST];
-	struct rte_mbuf *m_ipv6[MAX_PKT_BURST];
-	uint32_t res_ipv6[MAX_PKT_BURST];
-	int num_ipv6;
-};
-
-static struct {
-	char mapped[NB_SOCKETS];
-	struct rte_acl_ctx *acx_ipv4[NB_SOCKETS];
-	struct rte_acl_ctx *acx_ipv6[NB_SOCKETS];
-#ifdef L3FWDACL_DEBUG
-	struct acl4_rule *rule_ipv4;
-	struct acl6_rule *rule_ipv6;
-#endif
-} acl_config;
-
-static struct{
-	const char *rule_ipv4_name;
-	const char *rule_ipv6_name;
-	int scalar;
-} parm_config;
-
-const char cb_port_delim[] = ":";
-
-static inline void
-print_one_ipv4_rule(struct acl4_rule *rule, int extra)
-{
-	unsigned char a, b, c, d;
-
-	uint32_t_to_char(rule->field[SRC_FIELD_IPV4].value.u32,
-			&a, &b, &c, &d);
-	printf("%hhu.%hhu.%hhu.%hhu/%u ", a, b, c, d,
-			rule->field[SRC_FIELD_IPV4].mask_range.u32);
-	uint32_t_to_char(rule->field[DST_FIELD_IPV4].value.u32,
-			&a, &b, &c, &d);
-	printf("%hhu.%hhu.%hhu.%hhu/%u ", a, b, c, d,
-			rule->field[DST_FIELD_IPV4].mask_range.u32);
-	printf("%hu : %hu %hu : %hu 0x%hhx/0x%hhx ",
-		rule->field[SRCP_FIELD_IPV4].value.u16,
-		rule->field[SRCP_FIELD_IPV4].mask_range.u16,
-		rule->field[DSTP_FIELD_IPV4].value.u16,
-		rule->field[DSTP_FIELD_IPV4].mask_range.u16,
-		rule->field[PROTO_FIELD_IPV4].value.u8,
-		rule->field[PROTO_FIELD_IPV4].mask_range.u8);
-	if (extra)
-		printf("0x%x-0x%x-0x%x ",
-			rule->data.category_mask,
-			rule->data.priority,
-			rule->data.userdata);
-}
-
-static inline void
-print_one_ipv6_rule(struct acl6_rule *rule, int extra)
-{
-	unsigned char a, b, c, d;
-
-	uint32_t_to_char(rule->field[SRC1_FIELD_IPV6].value.u32,
-		&a, &b, &c, &d);
-	printf("%.2x%.2x:%.2x%.2x", a, b, c, d);
-	uint32_t_to_char(rule->field[SRC2_FIELD_IPV6].value.u32,
-		&a, &b, &c, &d);
-	printf(":%.2x%.2x:%.2x%.2x", a, b, c, d);
-	uint32_t_to_char(rule->field[SRC3_FIELD_IPV6].value.u32,
-		&a, &b, &c, &d);
-	printf(":%.2x%.2x:%.2x%.2x", a, b, c, d);
-	uint32_t_to_char(rule->field[SRC4_FIELD_IPV6].value.u32,
-		&a, &b, &c, &d);
-	printf(":%.2x%.2x:%.2x%.2x/%u ", a, b, c, d,
-			rule->field[SRC1_FIELD_IPV6].mask_range.u32
-			+ rule->field[SRC2_FIELD_IPV6].mask_range.u32
-			+ rule->field[SRC3_FIELD_IPV6].mask_range.u32
-			+ rule->field[SRC4_FIELD_IPV6].mask_range.u32);
-
-	uint32_t_to_char(rule->field[DST1_FIELD_IPV6].value.u32,
-		&a, &b, &c, &d);
-	printf("%.2x%.2x:%.2x%.2x", a, b, c, d);
-	uint32_t_to_char(rule->field[DST2_FIELD_IPV6].value.u32,
-		&a, &b, &c, &d);
-	printf(":%.2x%.2x:%.2x%.2x", a, b, c, d);
-	uint32_t_to_char(rule->field[DST3_FIELD_IPV6].value.u32,
-		&a, &b, &c, &d);
-	printf(":%.2x%.2x:%.2x%.2x", a, b, c, d);
-	uint32_t_to_char(rule->field[DST4_FIELD_IPV6].value.u32,
-		&a, &b, &c, &d);
-	printf(":%.2x%.2x:%.2x%.2x/%u ", a, b, c, d,
-			rule->field[DST1_FIELD_IPV6].mask_range.u32
-			+ rule->field[DST2_FIELD_IPV6].mask_range.u32
-			+ rule->field[DST3_FIELD_IPV6].mask_range.u32
-			+ rule->field[DST4_FIELD_IPV6].mask_range.u32);
-
-	printf("%hu : %hu %hu : %hu 0x%hhx/0x%hhx ",
-		rule->field[SRCP_FIELD_IPV6].value.u16,
-		rule->field[SRCP_FIELD_IPV6].mask_range.u16,
-		rule->field[DSTP_FIELD_IPV6].value.u16,
-		rule->field[DSTP_FIELD_IPV6].mask_range.u16,
-		rule->field[PROTO_FIELD_IPV6].value.u8,
-		rule->field[PROTO_FIELD_IPV6].mask_range.u8);
-	if (extra)
-		printf("0x%x-0x%x-0x%x ",
-			rule->data.category_mask,
-			rule->data.priority,
-			rule->data.userdata);
-}
-
-/* Bypass comment and empty lines */
-static inline int
-is_bypass_line(char *buff)
-{
-	int i = 0;
-
-	/* comment line */
-	if (buff[0] == COMMENT_LEAD_CHAR)
-		return 1;
-	/* empty line */
-	while (buff[i] != '\0') {
-		if (!isspace(buff[i]))
-			return 0;
-		i++;
-	}
-	return 1;
-}
-
-#ifdef L3FWDACL_DEBUG
-static inline void
-dump_acl4_rule(struct rte_mbuf *m, uint32_t sig)
-{
-	uint32_t offset = sig & ~ACL_DENY_SIGNATURE;
-	unsigned char a, b, c, d;
-	struct ipv4_hdr *ipv4_hdr = rte_pktmbuf_mtod_offset(m,
-							    struct ipv4_hdr *,
-							    sizeof(struct ether_hdr));
-
-	uint32_t_to_char(rte_bswap32(ipv4_hdr->src_addr), &a, &b, &c, &d);
-	printf("Packet Src:%hhu.%hhu.%hhu.%hhu ", a, b, c, d);
-	uint32_t_to_char(rte_bswap32(ipv4_hdr->dst_addr), &a, &b, &c, &d);
-	printf("Dst:%hhu.%hhu.%hhu.%hhu ", a, b, c, d);
-
-	printf("Src port:%hu,Dst port:%hu ",
-			rte_bswap16(*(uint16_t *)(ipv4_hdr + 1)),
-			rte_bswap16(*((uint16_t *)(ipv4_hdr + 1) + 1)));
-	printf("hit ACL %d - ", offset);
-
-	print_one_ipv4_rule(acl_config.rule_ipv4 + offset, 1);
-
-	printf("\n\n");
-}
-
-static inline void
-dump_acl6_rule(struct rte_mbuf *m, uint32_t sig)
-{
-	unsigned i;
-	uint32_t offset = sig & ~ACL_DENY_SIGNATURE;
-	struct ipv6_hdr *ipv6_hdr = rte_pktmbuf_mtod_offset(m,
-							    struct ipv6_hdr *,
-							    sizeof(struct ether_hdr));
-
-	printf("Packet Src");
-	for (i = 0; i < RTE_DIM(ipv6_hdr->src_addr); i += sizeof(uint16_t))
-		printf(":%.2x%.2x",
-			ipv6_hdr->src_addr[i], ipv6_hdr->src_addr[i + 1]);
-
-	printf("\nDst");
-	for (i = 0; i < RTE_DIM(ipv6_hdr->dst_addr); i += sizeof(uint16_t))
-		printf(":%.2x%.2x",
-			ipv6_hdr->dst_addr[i], ipv6_hdr->dst_addr[i + 1]);
-
-	printf("\nSrc port:%hu,Dst port:%hu ",
-			rte_bswap16(*(uint16_t *)(ipv6_hdr + 1)),
-			rte_bswap16(*((uint16_t *)(ipv6_hdr + 1) + 1)));
-	printf("hit ACL %d - ", offset);
-
-	print_one_ipv6_rule(acl_config.rule_ipv6 + offset, 1);
-
-	printf("\n\n");
-}
-#endif /* L3FWDACL_DEBUG */
-
-static inline void
-dump_ipv4_rules(struct acl4_rule *rule, int num, int extra)
-{
-	int i;
-
-	for (i = 0; i < num; i++, rule++) {
-		printf("\t%d:", i + 1);
-		print_one_ipv4_rule(rule, extra);
-		printf("\n");
-	}
-}
-
-static inline void
-dump_ipv6_rules(struct acl6_rule *rule, int num, int extra)
-{
-	int i;
-
-	for (i = 0; i < num; i++, rule++) {
-		printf("\t%d:", i + 1);
-		print_one_ipv6_rule(rule, extra);
-		printf("\n");
-	}
-}
-
-#ifdef DO_RFC_1812_CHECKS
-static inline void
-prepare_one_packet(struct rte_mbuf **pkts_in, struct acl_search_t *acl,
-	int index)
-{
-	struct ipv4_hdr *ipv4_hdr;
-	struct rte_mbuf *pkt = pkts_in[index];
-
-	if (RTE_ETH_IS_IPV4_HDR(pkt->packet_type)) {
-		ipv4_hdr = rte_pktmbuf_mtod_offset(pkt, struct ipv4_hdr *,
-						   sizeof(struct ether_hdr));
-
-		/* Check to make sure the packet is valid (RFC1812) */
-		if (is_valid_ipv4_pkt(ipv4_hdr, pkt->pkt_len) >= 0) {
-
-			/* Update time to live and header checksum */
-			--(ipv4_hdr->time_to_live);
-			++(ipv4_hdr->hdr_checksum);
-
-			/* Fill acl structure */
-			acl->data_ipv4[acl->num_ipv4] = MBUF_IPV4_2PROTO(pkt);
-			acl->m_ipv4[(acl->num_ipv4)++] = pkt;
-
-		} else {
-			/* Not a valid IPv4 packet */
-			rte_pktmbuf_free(pkt);
-		}
-	} else if (RTE_ETH_IS_IPV6_HDR(pkt->packet_type)) {
-		/* Fill acl structure */
-		acl->data_ipv6[acl->num_ipv6] = MBUF_IPV6_2PROTO(pkt);
-		acl->m_ipv6[(acl->num_ipv6)++] = pkt;
-
-	} else {
-		/* Unknown type, drop the packet */
-		rte_pktmbuf_free(pkt);
-	}
-}
-
-#else
-static inline void
-prepare_one_packet(struct rte_mbuf **pkts_in, struct acl_search_t *acl,
-	int index)
-{
-	struct rte_mbuf *pkt = pkts_in[index];
-
-	if (RTE_ETH_IS_IPV4_HDR(pkt->packet_type)) {
-		/* Fill acl structure */
-		acl->data_ipv4[acl->num_ipv4] = MBUF_IPV4_2PROTO(pkt);
-		acl->m_ipv4[(acl->num_ipv4)++] = pkt;
-
-	} else if (RTE_ETH_IS_IPV6_HDR(pkt->packet_type)) {
-		/* Fill acl structure */
-		acl->data_ipv6[acl->num_ipv6] = MBUF_IPV6_2PROTO(pkt);
-		acl->m_ipv6[(acl->num_ipv6)++] = pkt;
-	} else {
-		/* Unknown type, drop the packet */
-		rte_pktmbuf_free(pkt);
-	}
-}
-#endif /* DO_RFC_1812_CHECKS */
-
-static inline void
-prepare_acl_parameter(struct rte_mbuf **pkts_in, struct acl_search_t *acl,
-	int nb_rx)
-{
-	int i;
-
-	acl->num_ipv4 = 0;
-	acl->num_ipv6 = 0;
-
-	/* Prefetch first packets */
-	for (i = 0; i < PREFETCH_OFFSET && i < nb_rx; i++) {
-		rte_prefetch0(rte_pktmbuf_mtod(
-				pkts_in[i], void *));
-	}
-
-	for (i = 0; i < (nb_rx - PREFETCH_OFFSET); i++) {
-		rte_prefetch0(rte_pktmbuf_mtod(pkts_in[
-				i + PREFETCH_OFFSET], void *));
-		prepare_one_packet(pkts_in, acl, i);
-	}
-
-	/* Process left packets */
-	for (; i < nb_rx; i++)
-		prepare_one_packet(pkts_in, acl, i);
-}
-
-static inline void
-send_one_packet(struct rte_mbuf *m, uint32_t res)
-{
-	if (likely((res & ACL_DENY_SIGNATURE) == 0 && res != 0)) {
-		/* forward packets */
-		send_single_packet(m,
-			(uint8_t)(res - FWD_PORT_SHIFT));
-	} else{
-		/* in the ACL list, drop it */
-#ifdef L3FWDACL_DEBUG
-		if ((res & ACL_DENY_SIGNATURE) != 0) {
-			if (RTE_ETH_IS_IPV4_HDR(m->packet_type))
-				dump_acl4_rule(m, res);
-			else if (RTE_ETH_IS_IPV6_HDR(m->packet_type))
-				dump_acl6_rule(m, res);
-		}
-#endif
-		rte_pktmbuf_free(m);
-	}
-}
-
-
-
-static inline void
-send_packets(struct rte_mbuf **m, uint32_t *res, int num)
-{
-	int i;
-
-	/* Prefetch first packets */
-	for (i = 0; i < PREFETCH_OFFSET && i < num; i++) {
-		rte_prefetch0(rte_pktmbuf_mtod(
-				m[i], void *));
-	}
-
-	for (i = 0; i < (num - PREFETCH_OFFSET); i++) {
-		rte_prefetch0(rte_pktmbuf_mtod(m[
-				i + PREFETCH_OFFSET], void *));
-		send_one_packet(m[i], res[i]);
-	}
-
-	/* Process left packets */
-	for (; i < num; i++)
-		send_one_packet(m[i], res[i]);
-}
-
-/*
- * Parses IPV6 address, exepcts the following format:
- * XXXX:XXXX:XXXX:XXXX:XXXX:XXXX:XXXX:XXXX (where X - is a hexedecimal digit).
- */
-static int
-parse_ipv6_addr(const char *in, const char **end, uint32_t v[IPV6_ADDR_U32],
-	char dlm)
-{
-	uint32_t addr[IPV6_ADDR_U16];
-
-	GET_CB_FIELD(in, addr[0], 16, UINT16_MAX, ':');
-	GET_CB_FIELD(in, addr[1], 16, UINT16_MAX, ':');
-	GET_CB_FIELD(in, addr[2], 16, UINT16_MAX, ':');
-	GET_CB_FIELD(in, addr[3], 16, UINT16_MAX, ':');
-	GET_CB_FIELD(in, addr[4], 16, UINT16_MAX, ':');
-	GET_CB_FIELD(in, addr[5], 16, UINT16_MAX, ':');
-	GET_CB_FIELD(in, addr[6], 16, UINT16_MAX, ':');
-	GET_CB_FIELD(in, addr[7], 16, UINT16_MAX, dlm);
-
-	*end = in;
-
-	v[0] = (addr[0] << 16) + addr[1];
-	v[1] = (addr[2] << 16) + addr[3];
-	v[2] = (addr[4] << 16) + addr[5];
-	v[3] = (addr[6] << 16) + addr[7];
-
-	return 0;
-}
-
-static int
-parse_ipv6_net(const char *in, struct rte_acl_field field[4])
-{
-	int32_t rc;
-	const char *mp;
-	uint32_t i, m, v[4];
-	const uint32_t nbu32 = sizeof(uint32_t) * CHAR_BIT;
-
-	/* get address. */
-	rc = parse_ipv6_addr(in, &mp, v, '/');
-	if (rc != 0)
-		return rc;
-
-	/* get mask. */
-	GET_CB_FIELD(mp, m, 0, CHAR_BIT * sizeof(v), 0);
-
-	/* put all together. */
-	for (i = 0; i != RTE_DIM(v); i++) {
-		if (m >= (i + 1) * nbu32)
-			field[i].mask_range.u32 = nbu32;
-		else
-			field[i].mask_range.u32 = m > (i * nbu32) ?
-				m - (i * 32) : 0;
-
-		field[i].value.u32 = v[i];
-	}
-
-	return 0;
-}
-
-static int
-parse_cb_ipv6_rule(char *str, struct rte_acl_rule *v, int has_userdata)
-{
-	int i, rc;
-	char *s, *sp, *in[CB_FLD_NUM];
-	static const char *dlm = " \t\n";
-	int dim = has_userdata ? CB_FLD_NUM : CB_FLD_USERDATA;
-	s = str;
-
-	for (i = 0; i != dim; i++, s = NULL) {
-		in[i] = strtok_r(s, dlm, &sp);
-		if (in[i] == NULL)
-			return -EINVAL;
-	}
-
-	rc = parse_ipv6_net(in[CB_FLD_SRC_ADDR], v->field + SRC1_FIELD_IPV6);
-	if (rc != 0) {
-		acl_log("failed to read source address/mask: %s\n",
-			in[CB_FLD_SRC_ADDR]);
-		return rc;
-	}
-
-	rc = parse_ipv6_net(in[CB_FLD_DST_ADDR], v->field + DST1_FIELD_IPV6);
-	if (rc != 0) {
-		acl_log("failed to read destination address/mask: %s\n",
-			in[CB_FLD_DST_ADDR]);
-		return rc;
-	}
-
-	/* source port. */
-	GET_CB_FIELD(in[CB_FLD_SRC_PORT_LOW],
-		v->field[SRCP_FIELD_IPV6].value.u16,
-		0, UINT16_MAX, 0);
-	GET_CB_FIELD(in[CB_FLD_SRC_PORT_HIGH],
-		v->field[SRCP_FIELD_IPV6].mask_range.u16,
-		0, UINT16_MAX, 0);
-
-	if (strncmp(in[CB_FLD_SRC_PORT_DLM], cb_port_delim,
-			sizeof(cb_port_delim)) != 0)
-		return -EINVAL;
-
-	/* destination port. */
-	GET_CB_FIELD(in[CB_FLD_DST_PORT_LOW],
-		v->field[DSTP_FIELD_IPV6].value.u16,
-		0, UINT16_MAX, 0);
-	GET_CB_FIELD(in[CB_FLD_DST_PORT_HIGH],
-		v->field[DSTP_FIELD_IPV6].mask_range.u16,
-		0, UINT16_MAX, 0);
-
-	if (strncmp(in[CB_FLD_DST_PORT_DLM], cb_port_delim,
-			sizeof(cb_port_delim)) != 0)
-		return -EINVAL;
-
-	if (v->field[SRCP_FIELD_IPV6].mask_range.u16
-			< v->field[SRCP_FIELD_IPV6].value.u16
-			|| v->field[DSTP_FIELD_IPV6].mask_range.u16
-			< v->field[DSTP_FIELD_IPV6].value.u16)
-		return -EINVAL;
-
-	GET_CB_FIELD(in[CB_FLD_PROTO], v->field[PROTO_FIELD_IPV6].value.u8,
-		0, UINT8_MAX, '/');
-	GET_CB_FIELD(in[CB_FLD_PROTO], v->field[PROTO_FIELD_IPV6].mask_range.u8,
-		0, UINT8_MAX, 0);
-
-	if (has_userdata)
-		GET_CB_FIELD(in[CB_FLD_USERDATA], v->data.userdata,
-			0, UINT32_MAX, 0);
-
-	return 0;
-}
-
-/*
- * Parse ClassBench rules file.
- * Expected format:
- * '@'<src_ipv4_addr>'/'<masklen> <space> \
- * <dst_ipv4_addr>'/'<masklen> <space> \
- * <src_port_low> <space> ":" <src_port_high> <space> \
- * <dst_port_low> <space> ":" <dst_port_high> <space> \
- * <proto>'/'<mask>
- */
-static int
-parse_ipv4_net(const char *in, uint32_t *addr, uint32_t *mask_len)
-{
-	uint8_t a, b, c, d, m;
-
-	GET_CB_FIELD(in, a, 0, UINT8_MAX, '.');
-	GET_CB_FIELD(in, b, 0, UINT8_MAX, '.');
-	GET_CB_FIELD(in, c, 0, UINT8_MAX, '.');
-	GET_CB_FIELD(in, d, 0, UINT8_MAX, '/');
-	GET_CB_FIELD(in, m, 0, sizeof(uint32_t) * CHAR_BIT, 0);
-
-	addr[0] = IPv4(a, b, c, d);
-	mask_len[0] = m;
-
-	return 0;
-}
-
-static int
-parse_cb_ipv4vlan_rule(char *str, struct rte_acl_rule *v, int has_userdata)
-{
-	int i, rc;
-	char *s, *sp, *in[CB_FLD_NUM];
-	static const char *dlm = " \t\n";
-	int dim = has_userdata ? CB_FLD_NUM : CB_FLD_USERDATA;
-	s = str;
-
-	for (i = 0; i != dim; i++, s = NULL) {
-		in[i] = strtok_r(s, dlm, &sp);
-		if (in[i] == NULL)
-			return -EINVAL;
-	}
-
-	rc = parse_ipv4_net(in[CB_FLD_SRC_ADDR],
-			&v->field[SRC_FIELD_IPV4].value.u32,
-			&v->field[SRC_FIELD_IPV4].mask_range.u32);
-	if (rc != 0) {
-			acl_log("failed to read source address/mask: %s\n",
-			in[CB_FLD_SRC_ADDR]);
-		return rc;
-	}
-
-	rc = parse_ipv4_net(in[CB_FLD_DST_ADDR],
-			&v->field[DST_FIELD_IPV4].value.u32,
-			&v->field[DST_FIELD_IPV4].mask_range.u32);
-	if (rc != 0) {
-		acl_log("failed to read destination address/mask: %s\n",
-			in[CB_FLD_DST_ADDR]);
-		return rc;
-	}
-
-	GET_CB_FIELD(in[CB_FLD_SRC_PORT_LOW],
-		v->field[SRCP_FIELD_IPV4].value.u16,
-		0, UINT16_MAX, 0);
-	GET_CB_FIELD(in[CB_FLD_SRC_PORT_HIGH],
-		v->field[SRCP_FIELD_IPV4].mask_range.u16,
-		0, UINT16_MAX, 0);
-
-	if (strncmp(in[CB_FLD_SRC_PORT_DLM], cb_port_delim,
-			sizeof(cb_port_delim)) != 0)
-		return -EINVAL;
-
-	GET_CB_FIELD(in[CB_FLD_DST_PORT_LOW],
-		v->field[DSTP_FIELD_IPV4].value.u16,
-		0, UINT16_MAX, 0);
-	GET_CB_FIELD(in[CB_FLD_DST_PORT_HIGH],
-		v->field[DSTP_FIELD_IPV4].mask_range.u16,
-		0, UINT16_MAX, 0);
-
-	if (strncmp(in[CB_FLD_DST_PORT_DLM], cb_port_delim,
-			sizeof(cb_port_delim)) != 0)
-		return -EINVAL;
-
-	if (v->field[SRCP_FIELD_IPV4].mask_range.u16
-			< v->field[SRCP_FIELD_IPV4].value.u16
-			|| v->field[DSTP_FIELD_IPV4].mask_range.u16
-			< v->field[DSTP_FIELD_IPV4].value.u16)
-		return -EINVAL;
-
-	GET_CB_FIELD(in[CB_FLD_PROTO], v->field[PROTO_FIELD_IPV4].value.u8,
-		0, UINT8_MAX, '/');
-	GET_CB_FIELD(in[CB_FLD_PROTO], v->field[PROTO_FIELD_IPV4].mask_range.u8,
-		0, UINT8_MAX, 0);
-
-	if (has_userdata)
-		GET_CB_FIELD(in[CB_FLD_USERDATA], v->data.userdata, 0,
-			UINT32_MAX, 0);
-
-	return 0;
-}
-
-static int
-add_rules(const char *rule_path,
-		struct rte_acl_rule **proute_base,
-		unsigned int *proute_num,
-		struct rte_acl_rule **pacl_base,
-		unsigned int *pacl_num, uint32_t rule_size,
-		int (*parser)(char *, struct rte_acl_rule*, int))
-{
-	uint8_t *acl_rules, *route_rules;
-	struct rte_acl_rule *next;
-	unsigned int acl_num = 0, route_num = 0, total_num = 0;
-	unsigned int acl_cnt = 0, route_cnt = 0;
-	char buff[LINE_MAX];
-	FILE *fh = fopen(rule_path, "rb");
-	unsigned int i = 0;
-	int val;
-
-	if (fh == NULL)
-		rte_exit(EXIT_FAILURE, "%s: Open %s failed\n", __func__,
-			rule_path);
-
-	while ((fgets(buff, LINE_MAX, fh) != NULL)) {
-		if (buff[0] == ROUTE_LEAD_CHAR)
-			route_num++;
-		else if (buff[0] == ACL_LEAD_CHAR)
-			acl_num++;
-	}
-
-	if (0 == route_num)
-		rte_exit(EXIT_FAILURE, "Not find any route entries in %s!\n",
-				rule_path);
-
-	val = fseek(fh, 0, SEEK_SET);
-	if (val < 0) {
-		rte_exit(EXIT_FAILURE, "%s: File seek operation failed\n",
-			__func__);
-	}
-
-	acl_rules = calloc(acl_num, rule_size);
-
-	if (NULL == acl_rules)
-		rte_exit(EXIT_FAILURE, "%s: failed to malloc memory\n",
-			__func__);
-
-	route_rules = calloc(route_num, rule_size);
-
-	if (NULL == route_rules)
-		rte_exit(EXIT_FAILURE, "%s: failed to malloc memory\n",
-			__func__);
-
-	i = 0;
-	while (fgets(buff, LINE_MAX, fh) != NULL) {
-		i++;
-
-		if (is_bypass_line(buff))
-			continue;
-
-		char s = buff[0];
-
-		/* Route entry */
-		if (s == ROUTE_LEAD_CHAR)
-			next = (struct rte_acl_rule *)(route_rules +
-				route_cnt * rule_size);
-
-		/* ACL entry */
-		else if (s == ACL_LEAD_CHAR)
-			next = (struct rte_acl_rule *)(acl_rules +
-				acl_cnt * rule_size);
-
-		/* Illegal line */
-		else
-			rte_exit(EXIT_FAILURE,
-				"%s Line %u: should start with leading "
-				"char %c or %c\n",
-				rule_path, i, ROUTE_LEAD_CHAR, ACL_LEAD_CHAR);
-
-		if (parser(buff + 1, next, s == ROUTE_LEAD_CHAR) != 0)
-			rte_exit(EXIT_FAILURE,
-				"%s Line %u: parse rules error\n",
-				rule_path, i);
-
-		if (s == ROUTE_LEAD_CHAR) {
-			/* Check the forwarding port number */
-			if ((enabled_port_mask & (1 << next->data.userdata)) ==
-					0)
-				rte_exit(EXIT_FAILURE,
-					"%s Line %u: fwd number illegal:%u\n",
-					rule_path, i, next->data.userdata);
-			next->data.userdata += FWD_PORT_SHIFT;
-			route_cnt++;
-		} else {
-			next->data.userdata = ACL_DENY_SIGNATURE + acl_cnt;
-			acl_cnt++;
-		}
-
-		next->data.priority = RTE_ACL_MAX_PRIORITY - total_num;
-		next->data.category_mask = -1;
-		total_num++;
-	}
-
-	fclose(fh);
-
-	*pacl_base = (struct rte_acl_rule *)acl_rules;
-	*pacl_num = acl_num;
-	*proute_base = (struct rte_acl_rule *)route_rules;
-	*proute_num = route_cnt;
-
-	return 0;
-}
-
-static void
-dump_acl_config(void)
-{
-	printf("ACL option are:\n");
-	printf(OPTION_RULE_IPV4": %s\n", parm_config.rule_ipv4_name);
-	printf(OPTION_RULE_IPV6": %s\n", parm_config.rule_ipv6_name);
-	printf(OPTION_SCALAR": %d\n", parm_config.scalar);
-}
-
-static int
-check_acl_config(void)
-{
-	if (parm_config.rule_ipv4_name == NULL) {
-		acl_log("ACL IPv4 rule file not specified\n");
-		return -1;
-	} else if (parm_config.rule_ipv6_name == NULL) {
-		acl_log("ACL IPv6 rule file not specified\n");
-		return -1;
-	}
-
-	return 0;
-}
-
-static struct rte_acl_ctx*
-setup_acl(struct rte_acl_rule *route_base,
-		struct rte_acl_rule *acl_base, unsigned int route_num,
-		unsigned int acl_num, int ipv6, int socketid)
-{
-	char name[PATH_MAX];
-	struct rte_acl_param acl_param;
-	struct rte_acl_config acl_build_param;
-	struct rte_acl_ctx *context;
-	int dim = ipv6 ? RTE_DIM(ipv6_defs) : RTE_DIM(ipv4_defs);
-
-	/* Create ACL contexts */
-	snprintf(name, sizeof(name), "%s%d",
-			ipv6 ? L3FWD_ACL_IPV6_NAME : L3FWD_ACL_IPV4_NAME,
-			socketid);
-
-	acl_param.name = name;
-	acl_param.socket_id = socketid;
-	acl_param.rule_size = RTE_ACL_RULE_SZ(dim);
-	acl_param.max_rule_num = MAX_ACL_RULE_NUM;
-
-	if ((context = rte_acl_create(&acl_param)) == NULL)
-		rte_exit(EXIT_FAILURE, "Failed to create ACL context\n");
-
-	if (parm_config.scalar && rte_acl_set_ctx_classify(context,
-			RTE_ACL_CLASSIFY_SCALAR) != 0)
-		rte_exit(EXIT_FAILURE,
-			"Failed to setup classify method for  ACL context\n");
-
-	if (rte_acl_add_rules(context, route_base, route_num) < 0)
-			rte_exit(EXIT_FAILURE, "add rules failed\n");
-
-	if (rte_acl_add_rules(context, acl_base, acl_num) < 0)
-			rte_exit(EXIT_FAILURE, "add rules failed\n");
-
-	/* Perform builds */
-	memset(&acl_build_param, 0, sizeof(acl_build_param));
-
-	acl_build_param.num_categories = DEFAULT_MAX_CATEGORIES;
-	acl_build_param.num_fields = dim;
-	memcpy(&acl_build_param.defs, ipv6 ? ipv6_defs : ipv4_defs,
-		ipv6 ? sizeof(ipv6_defs) : sizeof(ipv4_defs));
-
-	if (rte_acl_build(context, &acl_build_param) != 0)
-		rte_exit(EXIT_FAILURE, "Failed to build ACL trie\n");
-
-	rte_acl_dump(context);
-
-	return context;
-}
-
-static int
-app_acl_init(void)
-{
-	unsigned lcore_id;
-	unsigned int i;
-	int socketid;
-	struct rte_acl_rule *acl_base_ipv4, *route_base_ipv4,
-		*acl_base_ipv6, *route_base_ipv6;
-	unsigned int acl_num_ipv4 = 0, route_num_ipv4 = 0,
-		acl_num_ipv6 = 0, route_num_ipv6 = 0;
-
-	if (check_acl_config() != 0)
-		rte_exit(EXIT_FAILURE, "Failed to get valid ACL options\n");
-
-	dump_acl_config();
-
-	/* Load  rules from the input file */
-	if (add_rules(parm_config.rule_ipv4_name, &route_base_ipv4,
-			&route_num_ipv4, &acl_base_ipv4, &acl_num_ipv4,
-			sizeof(struct acl4_rule), &parse_cb_ipv4vlan_rule) < 0)
-		rte_exit(EXIT_FAILURE, "Failed to add rules\n");
-
-	acl_log("IPv4 Route entries %u:\n", route_num_ipv4);
-	dump_ipv4_rules((struct acl4_rule *)route_base_ipv4, route_num_ipv4, 1);
-
-	acl_log("IPv4 ACL entries %u:\n", acl_num_ipv4);
-	dump_ipv4_rules((struct acl4_rule *)acl_base_ipv4, acl_num_ipv4, 1);
-
-	if (add_rules(parm_config.rule_ipv6_name, &route_base_ipv6,
-			&route_num_ipv6,
-			&acl_base_ipv6, &acl_num_ipv6,
-			sizeof(struct acl6_rule), &parse_cb_ipv6_rule) < 0)
-		rte_exit(EXIT_FAILURE, "Failed to add rules\n");
-
-	acl_log("IPv6 Route entries %u:\n", route_num_ipv6);
-	dump_ipv6_rules((struct acl6_rule *)route_base_ipv6, route_num_ipv6, 1);
-
-	acl_log("IPv6 ACL entries %u:\n", acl_num_ipv6);
-	dump_ipv6_rules((struct acl6_rule *)acl_base_ipv6, acl_num_ipv6, 1);
-
-	memset(&acl_config, 0, sizeof(acl_config));
-
-	/* Check sockets a context should be created on */
-	if (!numa_on)
-		acl_config.mapped[0] = 1;
-	else {
-		for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-			if (rte_lcore_is_enabled(lcore_id) == 0)
-				continue;
-
-			socketid = rte_lcore_to_socket_id(lcore_id);
-			if (socketid >= NB_SOCKETS) {
-				acl_log("Socket %d of lcore %u is out "
-					"of range %d\n",
-					socketid, lcore_id, NB_SOCKETS);
-				free(route_base_ipv4);
-				free(route_base_ipv6);
-				free(acl_base_ipv4);
-				free(acl_base_ipv6);
-				return -1;
-			}
-
-			acl_config.mapped[socketid] = 1;
-		}
-	}
-
-	for (i = 0; i < NB_SOCKETS; i++) {
-		if (acl_config.mapped[i]) {
-			acl_config.acx_ipv4[i] = setup_acl(route_base_ipv4,
-				acl_base_ipv4, route_num_ipv4, acl_num_ipv4,
-				0, i);
-
-			acl_config.acx_ipv6[i] = setup_acl(route_base_ipv6,
-				acl_base_ipv6, route_num_ipv6, acl_num_ipv6,
-				1, i);
-		}
-	}
-
-	free(route_base_ipv4);
-	free(route_base_ipv6);
-
-#ifdef L3FWDACL_DEBUG
-	acl_config.rule_ipv4 = (struct acl4_rule *)acl_base_ipv4;
-	acl_config.rule_ipv6 = (struct acl6_rule *)acl_base_ipv6;
-#else
-	free(acl_base_ipv4);
-	free(acl_base_ipv6);
-#endif
-
-	return 0;
-}
-
-/***********************end of ACL part******************************/
-
-struct lcore_conf {
-	uint16_t n_rx_queue;
-	struct lcore_rx_queue rx_queue_list[MAX_RX_QUEUE_PER_LCORE];
-	uint16_t n_tx_port;
-	uint16_t tx_port_id[RTE_MAX_ETHPORTS];
-	uint16_t tx_queue_id[RTE_MAX_ETHPORTS];
-	struct rte_eth_dev_tx_buffer *tx_buffer[RTE_MAX_ETHPORTS];
-} __rte_cache_aligned;
-
-static struct lcore_conf lcore_conf[RTE_MAX_LCORE];
-
-/* Enqueue a single packet, and send burst if queue is filled */
-static inline void
-send_single_packet(struct rte_mbuf *m, uint16_t port)
-{
-	uint32_t lcore_id;
-	struct lcore_conf *qconf;
-
-	lcore_id = rte_lcore_id();
-
-	qconf = &lcore_conf[lcore_id];
-	rte_eth_tx_buffer(port, qconf->tx_queue_id[port],
-			qconf->tx_buffer[port], m);
-}
-
-#ifdef DO_RFC_1812_CHECKS
-static inline int
-is_valid_ipv4_pkt(struct ipv4_hdr *pkt, uint32_t link_len)
-{
-	/* From http://www.rfc-editor.org/rfc/rfc1812.txt section 5.2.2 */
-	/*
-	 * 1. The packet length reported by the Link Layer must be large
-	 * enough to hold the minimum length legal IP datagram (20 bytes).
-	 */
-	if (link_len < sizeof(struct ipv4_hdr))
-		return -1;
-
-	/* 2. The IP checksum must be correct. */
-	/* this is checked in H/W */
-
-	/*
-	 * 3. The IP version number must be 4. If the version number is not 4
-	 * then the packet may be another version of IP, such as IPng or
-	 * ST-II.
-	 */
-	if (((pkt->version_ihl) >> 4) != 4)
-		return -3;
-	/*
-	 * 4. The IP header length field must be large enough to hold the
-	 * minimum length legal IP datagram (20 bytes = 5 words).
-	 */
-	if ((pkt->version_ihl & 0xf) < 5)
-		return -4;
-
-	/*
-	 * 5. The IP total length field must be large enough to hold the IP
-	 * datagram header, whose length is specified in the IP header length
-	 * field.
-	 */
-	if (rte_cpu_to_be_16(pkt->total_length) < sizeof(struct ipv4_hdr))
-		return -5;
-
-	return 0;
-}
-#endif
-
-/* main processing loop */
-static int
-main_loop(__attribute__((unused)) void *dummy)
-{
-	struct rte_mbuf *pkts_burst[MAX_PKT_BURST];
-	unsigned lcore_id;
-	uint64_t prev_tsc, diff_tsc, cur_tsc;
-	int i, nb_rx;
-	uint16_t portid;
-	uint8_t queueid;
-	struct lcore_conf *qconf;
-	int socketid;
-	const uint64_t drain_tsc = (rte_get_tsc_hz() + US_PER_S - 1)
-			/ US_PER_S * BURST_TX_DRAIN_US;
-
-	prev_tsc = 0;
-	lcore_id = rte_lcore_id();
-	qconf = &lcore_conf[lcore_id];
-	socketid = rte_lcore_to_socket_id(lcore_id);
-
-	if (qconf->n_rx_queue == 0) {
-		RTE_LOG(INFO, L3FWD, "lcore %u has nothing to do\n", lcore_id);
-		return 0;
-	}
-
-	RTE_LOG(INFO, L3FWD, "entering main loop on lcore %u\n", lcore_id);
-
-	for (i = 0; i < qconf->n_rx_queue; i++) {
-
-		portid = qconf->rx_queue_list[i].port_id;
-		queueid = qconf->rx_queue_list[i].queue_id;
-		RTE_LOG(INFO, L3FWD,
-			" -- lcoreid=%u portid=%u rxqueueid=%hhu\n",
-			lcore_id, portid, queueid);
-	}
-
-	while (1) {
-
-		cur_tsc = rte_rdtsc();
-
-		/*
-		 * TX burst queue drain
-		 */
-		diff_tsc = cur_tsc - prev_tsc;
-		if (unlikely(diff_tsc > drain_tsc)) {
-			for (i = 0; i < qconf->n_tx_port; ++i) {
-				portid = qconf->tx_port_id[i];
-				rte_eth_tx_buffer_flush(portid,
-						qconf->tx_queue_id[portid],
-						qconf->tx_buffer[portid]);
-			}
-			prev_tsc = cur_tsc;
-		}
-
-		/*
-		 * Read packet from RX queues
-		 */
-		for (i = 0; i < qconf->n_rx_queue; ++i) {
-
-			portid = qconf->rx_queue_list[i].port_id;
-			queueid = qconf->rx_queue_list[i].queue_id;
-			nb_rx = rte_eth_rx_burst(portid, queueid,
-				pkts_burst, MAX_PKT_BURST);
-
-			if (nb_rx > 0) {
-				struct acl_search_t acl_search;
-
-				prepare_acl_parameter(pkts_burst, &acl_search,
-					nb_rx);
-
-				if (acl_search.num_ipv4) {
-					rte_acl_classify(
-						acl_config.acx_ipv4[socketid],
-						acl_search.data_ipv4,
-						acl_search.res_ipv4,
-						acl_search.num_ipv4,
-						DEFAULT_MAX_CATEGORIES);
-
-					send_packets(acl_search.m_ipv4,
-						acl_search.res_ipv4,
-						acl_search.num_ipv4);
-				}
-
-				if (acl_search.num_ipv6) {
-					rte_acl_classify(
-						acl_config.acx_ipv6[socketid],
-						acl_search.data_ipv6,
-						acl_search.res_ipv6,
-						acl_search.num_ipv6,
-						DEFAULT_MAX_CATEGORIES);
-
-					send_packets(acl_search.m_ipv6,
-						acl_search.res_ipv6,
-						acl_search.num_ipv6);
-				}
-			}
-		}
-	}
-}
-
-static int
-check_lcore_params(void)
-{
-	uint8_t queue, lcore;
-	uint16_t i;
-	int socketid;
-
-	for (i = 0; i < nb_lcore_params; ++i) {
-		queue = lcore_params[i].queue_id;
-		if (queue >= MAX_RX_QUEUE_PER_PORT) {
-			printf("invalid queue number: %hhu\n", queue);
-			return -1;
-		}
-		lcore = lcore_params[i].lcore_id;
-		if (!rte_lcore_is_enabled(lcore)) {
-			printf("error: lcore %hhu is not enabled in "
-				"lcore mask\n", lcore);
-			return -1;
-		}
-		socketid = rte_lcore_to_socket_id(lcore);
-		if (socketid != 0 && numa_on == 0) {
-			printf("warning: lcore %hhu is on socket %d "
-				"with numa off\n",
-				lcore, socketid);
-		}
-	}
-	return 0;
-}
-
-static int
-check_port_config(void)
-{
-	unsigned portid;
-	uint16_t i;
-
-	for (i = 0; i < nb_lcore_params; ++i) {
-		portid = lcore_params[i].port_id;
-
-		if ((enabled_port_mask & (1 << portid)) == 0) {
-			printf("port %u is not enabled in port mask\n", portid);
-			return -1;
-		}
-		if (!rte_eth_dev_is_valid_port(portid)) {
-			printf("port %u is not present on the board\n", portid);
-			return -1;
-		}
-	}
-	return 0;
-}
-
-static uint8_t
-get_port_n_rx_queues(const uint16_t port)
-{
-	int queue = -1;
-	uint16_t i;
-
-	for (i = 0; i < nb_lcore_params; ++i) {
-		if (lcore_params[i].port_id == port &&
-				lcore_params[i].queue_id > queue)
-			queue = lcore_params[i].queue_id;
-	}
-	return (uint8_t)(++queue);
-}
-
-static int
-init_lcore_rx_queues(void)
-{
-	uint16_t i, nb_rx_queue;
-	uint8_t lcore;
-
-	for (i = 0; i < nb_lcore_params; ++i) {
-		lcore = lcore_params[i].lcore_id;
-		nb_rx_queue = lcore_conf[lcore].n_rx_queue;
-		if (nb_rx_queue >= MAX_RX_QUEUE_PER_LCORE) {
-			printf("error: too many queues (%u) for lcore: %u\n",
-				(unsigned)nb_rx_queue + 1, (unsigned)lcore);
-			return -1;
-		} else {
-			lcore_conf[lcore].rx_queue_list[nb_rx_queue].port_id =
-				lcore_params[i].port_id;
-			lcore_conf[lcore].rx_queue_list[nb_rx_queue].queue_id =
-				lcore_params[i].queue_id;
-			lcore_conf[lcore].n_rx_queue++;
-		}
-	}
-	return 0;
-}
-
-/* display usage */
-static void
-print_usage(const char *prgname)
-{
-	printf("%s [EAL options] -- -p PORTMASK -P"
-		"--"OPTION_RULE_IPV4"=FILE"
-		"--"OPTION_RULE_IPV6"=FILE"
-		"  [--"OPTION_CONFIG" (port,queue,lcore)[,(port,queue,lcore]]"
-		"  [--"OPTION_ENBJMO" [--max-pkt-len PKTLEN]]\n"
-		"  -p PORTMASK: hexadecimal bitmask of ports to configure\n"
-		"  -P : enable promiscuous mode\n"
-		"  --"OPTION_CONFIG": (port,queue,lcore): "
-		"rx queues configuration\n"
-		"  --"OPTION_NONUMA": optional, disable numa awareness\n"
-		"  --"OPTION_ENBJMO": enable jumbo frame"
-		" which max packet len is PKTLEN in decimal (64-9600)\n"
-		"  --"OPTION_RULE_IPV4"=FILE: specify the ipv4 rules entries "
-		"file. "
-		"Each rule occupy one line. "
-		"2 kinds of rules are supported. "
-		"One is ACL entry at while line leads with character '%c', "
-		"another is route entry at while line leads with "
-		"character '%c'.\n"
-		"  --"OPTION_RULE_IPV6"=FILE: specify the ipv6 rules "
-		"entries file.\n"
-		"  --"OPTION_SCALAR": Use scalar function to do lookup\n",
-		prgname, ACL_LEAD_CHAR, ROUTE_LEAD_CHAR);
-}
-
-static int
-parse_max_pkt_len(const char *pktlen)
-{
-	char *end = NULL;
-	unsigned long len;
-
-	/* parse decimal string */
-	len = strtoul(pktlen, &end, 10);
-	if ((pktlen[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (len == 0)
-		return -1;
-
-	return len;
-}
-
-static int
-parse_portmask(const char *portmask)
-{
-	char *end = NULL;
-	unsigned long pm;
-
-	/* parse hexadecimal string */
-	pm = strtoul(portmask, &end, 16);
-	if ((portmask[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (pm == 0)
-		return -1;
-
-	return pm;
-}
-
-static int
-parse_config(const char *q_arg)
-{
-	char s[256];
-	const char *p, *p0 = q_arg;
-	char *end;
-	enum fieldnames {
-		FLD_PORT = 0,
-		FLD_QUEUE,
-		FLD_LCORE,
-		_NUM_FLD
-	};
-	unsigned long int_fld[_NUM_FLD];
-	char *str_fld[_NUM_FLD];
-	int i;
-	unsigned size;
-
-	nb_lcore_params = 0;
-
-	while ((p = strchr(p0, '(')) != NULL) {
-		++p;
-		if ((p0 = strchr(p, ')')) == NULL)
-			return -1;
-
-		size = p0 - p;
-		if (size >= sizeof(s))
-			return -1;
-
-		snprintf(s, sizeof(s), "%.*s", size, p);
-		if (rte_strsplit(s, sizeof(s), str_fld, _NUM_FLD, ',') !=
-				_NUM_FLD)
-			return -1;
-		for (i = 0; i < _NUM_FLD; i++) {
-			errno = 0;
-			int_fld[i] = strtoul(str_fld[i], &end, 0);
-			if (errno != 0 || end == str_fld[i] || int_fld[i] > 255)
-				return -1;
-		}
-		if (nb_lcore_params >= MAX_LCORE_PARAMS) {
-			printf("exceeded max number of lcore params: %hu\n",
-				nb_lcore_params);
-			return -1;
-		}
-		lcore_params_array[nb_lcore_params].port_id =
-			(uint8_t)int_fld[FLD_PORT];
-		lcore_params_array[nb_lcore_params].queue_id =
-			(uint8_t)int_fld[FLD_QUEUE];
-		lcore_params_array[nb_lcore_params].lcore_id =
-			(uint8_t)int_fld[FLD_LCORE];
-		++nb_lcore_params;
-	}
-	lcore_params = lcore_params_array;
-	return 0;
-}
-
-/* Parse the argument given in the command line of the application */
-static int
-parse_args(int argc, char **argv)
-{
-	int opt, ret;
-	char **argvopt;
-	int option_index;
-	char *prgname = argv[0];
-	static struct option lgopts[] = {
-		{OPTION_CONFIG, 1, 0, 0},
-		{OPTION_NONUMA, 0, 0, 0},
-		{OPTION_ENBJMO, 0, 0, 0},
-		{OPTION_RULE_IPV4, 1, 0, 0},
-		{OPTION_RULE_IPV6, 1, 0, 0},
-		{OPTION_SCALAR, 0, 0, 0},
-		{NULL, 0, 0, 0}
-	};
-
-	argvopt = argv;
-
-	while ((opt = getopt_long(argc, argvopt, "p:P",
-				lgopts, &option_index)) != EOF) {
-
-		switch (opt) {
-		/* portmask */
-		case 'p':
-			enabled_port_mask = parse_portmask(optarg);
-			if (enabled_port_mask == 0) {
-				printf("invalid portmask\n");
-				print_usage(prgname);
-				return -1;
-			}
-			break;
-		case 'P':
-			printf("Promiscuous mode selected\n");
-			promiscuous_on = 1;
-			break;
-
-		/* long options */
-		case 0:
-			if (!strncmp(lgopts[option_index].name,
-					OPTION_CONFIG,
-					sizeof(OPTION_CONFIG))) {
-				ret = parse_config(optarg);
-				if (ret) {
-					printf("invalid config\n");
-					print_usage(prgname);
-					return -1;
-				}
-			}
-
-			if (!strncmp(lgopts[option_index].name,
-					OPTION_NONUMA,
-					sizeof(OPTION_NONUMA))) {
-				printf("numa is disabled\n");
-				numa_on = 0;
-			}
-
-			if (!strncmp(lgopts[option_index].name,
-					OPTION_ENBJMO, sizeof(OPTION_ENBJMO))) {
-				struct option lenopts = {
-					"max-pkt-len",
-					required_argument,
-					0,
-					0
-				};
-
-				printf("jumbo frame is enabled\n");
-				port_conf.rxmode.offloads |=
-						DEV_RX_OFFLOAD_JUMBO_FRAME;
-				port_conf.txmode.offloads |=
-						DEV_TX_OFFLOAD_MULTI_SEGS;
-
-				/*
-				 * if no max-pkt-len set, then use the
-				 * default value ETHER_MAX_LEN
-				 */
-				if (0 == getopt_long(argc, argvopt, "",
-						&lenopts, &option_index)) {
-					ret = parse_max_pkt_len(optarg);
-					if ((ret < 64) ||
-						(ret > MAX_JUMBO_PKT_LEN)) {
-						printf("invalid packet "
-							"length\n");
-						print_usage(prgname);
-						return -1;
-					}
-					port_conf.rxmode.max_rx_pkt_len = ret;
-				}
-				printf("set jumbo frame max packet length "
-					"to %u\n",
-					(unsigned int)
-					port_conf.rxmode.max_rx_pkt_len);
-			}
-
-			if (!strncmp(lgopts[option_index].name,
-					OPTION_RULE_IPV4,
-					sizeof(OPTION_RULE_IPV4)))
-				parm_config.rule_ipv4_name = optarg;
-
-			if (!strncmp(lgopts[option_index].name,
-					OPTION_RULE_IPV6,
-					sizeof(OPTION_RULE_IPV6))) {
-				parm_config.rule_ipv6_name = optarg;
-			}
-
-			if (!strncmp(lgopts[option_index].name,
-					OPTION_SCALAR, sizeof(OPTION_SCALAR)))
-				parm_config.scalar = 1;
-
-
-			break;
-
-		default:
-			print_usage(prgname);
-			return -1;
-		}
-	}
-
-	if (optind >= 0)
-		argv[optind-1] = prgname;
-
-	ret = optind-1;
-	optind = 1; /* reset getopt lib */
-	return ret;
-}
-
-static void
-print_ethaddr(const char *name, const struct ether_addr *eth_addr)
-{
-	char buf[ETHER_ADDR_FMT_SIZE];
-	ether_format_addr(buf, ETHER_ADDR_FMT_SIZE, eth_addr);
-	printf("%s%s", name, buf);
-}
-
-static int
-init_mem(unsigned nb_mbuf)
-{
-	int socketid;
-	unsigned lcore_id;
-	char s[64];
-
-	for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-		if (rte_lcore_is_enabled(lcore_id) == 0)
-			continue;
-
-		if (numa_on)
-			socketid = rte_lcore_to_socket_id(lcore_id);
-		else
-			socketid = 0;
-
-		if (socketid >= NB_SOCKETS) {
-			rte_exit(EXIT_FAILURE,
-				"Socket %d of lcore %u is out of range %d\n",
-				socketid, lcore_id, NB_SOCKETS);
-		}
-		if (pktmbuf_pool[socketid] == NULL) {
-			snprintf(s, sizeof(s), "mbuf_pool_%d", socketid);
-			pktmbuf_pool[socketid] =
-				rte_pktmbuf_pool_create(s, nb_mbuf,
-					MEMPOOL_CACHE_SIZE, 0,
-					RTE_MBUF_DEFAULT_BUF_SIZE,
-					socketid);
-			if (pktmbuf_pool[socketid] == NULL)
-				rte_exit(EXIT_FAILURE,
-					"Cannot init mbuf pool on socket %d\n",
-					socketid);
-			else
-				printf("Allocated mbuf pool on socket %d\n",
-					socketid);
-		}
-	}
-	return 0;
-}
-
-/* Check the link status of all ports in up to 9s, and print them finally */
-static void
-check_all_ports_link_status(uint32_t port_mask)
-{
-#define CHECK_INTERVAL 100 /* 100ms */
-#define MAX_CHECK_TIME 90 /* 9s (90 * 100ms) in total */
-	uint16_t portid;
-	uint8_t count, all_ports_up, print_flag = 0;
-	struct rte_eth_link link;
-
-	printf("\nChecking link status");
-	fflush(stdout);
-	for (count = 0; count <= MAX_CHECK_TIME; count++) {
-		all_ports_up = 1;
-		RTE_ETH_FOREACH_DEV(portid) {
-			if ((port_mask & (1 << portid)) == 0)
-				continue;
-			memset(&link, 0, sizeof(link));
-			rte_eth_link_get_nowait(portid, &link);
-			/* print link status if flag set */
-			if (print_flag == 1) {
-				if (link.link_status)
-					printf(
-					"Port%d Link Up. Speed %u Mbps %s\n",
-						portid, link.link_speed,
-				(link.link_duplex == ETH_LINK_FULL_DUPLEX) ?
-					("full-duplex") : ("half-duplex\n"));
-				else
-					printf("Port %d Link Down\n", portid);
-				continue;
-			}
-			/* clear all_ports_up flag if any link down */
-			if (link.link_status == ETH_LINK_DOWN) {
-				all_ports_up = 0;
-				break;
-			}
-		}
-		/* after finally printing all link status, get out */
-		if (print_flag == 1)
-			break;
-
-		if (all_ports_up == 0) {
-			printf(".");
-			fflush(stdout);
-			rte_delay_ms(CHECK_INTERVAL);
-		}
-
-		/* set the print_flag if all ports up or timeout */
-		if (all_ports_up == 1 || count == (MAX_CHECK_TIME - 1)) {
-			print_flag = 1;
-			printf("done\n");
-		}
-	}
-}
-
-int
-main(int argc, char **argv)
-{
-	struct lcore_conf *qconf;
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_txconf *txconf;
-	int ret;
-	unsigned nb_ports;
-	uint16_t queueid;
-	unsigned lcore_id;
-	uint32_t n_tx_queue, nb_lcores;
-	uint16_t portid;
-	uint8_t nb_rx_queue, queue, socketid;
-
-	/* init EAL */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid EAL parameters\n");
-	argc -= ret;
-	argv += ret;
-
-	/* parse application arguments (after the EAL ones) */
-	ret = parse_args(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid L3FWD parameters\n");
-
-	if (check_lcore_params() < 0)
-		rte_exit(EXIT_FAILURE, "check_lcore_params failed\n");
-
-	ret = init_lcore_rx_queues();
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "init_lcore_rx_queues failed\n");
-
-	nb_ports = rte_eth_dev_count();
-
-	if (check_port_config() < 0)
-		rte_exit(EXIT_FAILURE, "check_port_config failed\n");
-
-	/* Add ACL rules and route entries, build trie */
-	if (app_acl_init() < 0)
-		rte_exit(EXIT_FAILURE, "app_acl_init failed\n");
-
-	nb_lcores = rte_lcore_count();
-
-	/* initialize all ports */
-	RTE_ETH_FOREACH_DEV(portid) {
-		struct rte_eth_conf local_port_conf = port_conf;
-
-		/* skip ports that are not enabled */
-		if ((enabled_port_mask & (1 << portid)) == 0) {
-			printf("\nSkipping disabled port %d\n", portid);
-			continue;
-		}
-
-		/* init port */
-		printf("Initializing port %d ... ", portid);
-		fflush(stdout);
-
-		nb_rx_queue = get_port_n_rx_queues(portid);
-		n_tx_queue = nb_lcores;
-		if (n_tx_queue > MAX_TX_QUEUE_PER_PORT)
-			n_tx_queue = MAX_TX_QUEUE_PER_PORT;
-		printf("Creating queues: nb_rxq=%d nb_txq=%u... ",
-			nb_rx_queue, (unsigned)n_tx_queue);
-		rte_eth_dev_info_get(portid, &dev_info);
-		if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-			local_port_conf.txmode.offloads |=
-				DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-		ret = rte_eth_dev_configure(portid, nb_rx_queue,
-					(uint16_t)n_tx_queue, &local_port_conf);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-				"Cannot configure device: err=%d, port=%d\n",
-				ret, portid);
-
-		ret = rte_eth_dev_adjust_nb_rx_tx_desc(portid, &nb_rxd,
-						       &nb_txd);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-				"rte_eth_dev_adjust_nb_rx_tx_desc: err=%d, port=%d\n",
-				ret, portid);
-
-		rte_eth_macaddr_get(portid, &ports_eth_addr[portid]);
-		print_ethaddr(" Address:", &ports_eth_addr[portid]);
-		printf(", ");
-
-		/* init memory */
-		ret = init_mem(NB_MBUF);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "init_mem failed\n");
-
-		for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-			if (rte_lcore_is_enabled(lcore_id) == 0)
-				continue;
-
-			/* Initialize TX buffers */
-			qconf = &lcore_conf[lcore_id];
-			qconf->tx_buffer[portid] = rte_zmalloc_socket("tx_buffer",
-					RTE_ETH_TX_BUFFER_SIZE(MAX_PKT_BURST), 0,
-					rte_eth_dev_socket_id(portid));
-			if (qconf->tx_buffer[portid] == NULL)
-				rte_exit(EXIT_FAILURE, "Can't allocate tx buffer for port %u\n",
-						(unsigned) portid);
-
-			rte_eth_tx_buffer_init(qconf->tx_buffer[portid], MAX_PKT_BURST);
-		}
-
-		/* init one TX queue per couple (lcore,port) */
-		queueid = 0;
-		for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-			if (rte_lcore_is_enabled(lcore_id) == 0)
-				continue;
-
-			if (numa_on)
-				socketid = (uint8_t)
-					rte_lcore_to_socket_id(lcore_id);
-			else
-				socketid = 0;
-
-			printf("txq=%u,%d,%d ", lcore_id, queueid, socketid);
-			fflush(stdout);
-
-			rte_eth_dev_info_get(portid, &dev_info);
-			txconf = &dev_info.default_txconf;
-			txconf->txq_flags = ETH_TXQ_FLAGS_IGNORE;
-			txconf->offloads = local_port_conf.txmode.offloads;
-			ret = rte_eth_tx_queue_setup(portid, queueid, nb_txd,
-						     socketid, txconf);
-			if (ret < 0)
-				rte_exit(EXIT_FAILURE,
-					"rte_eth_tx_queue_setup: err=%d, "
-					"port=%d\n", ret, portid);
-
-			qconf = &lcore_conf[lcore_id];
-			qconf->tx_queue_id[portid] = queueid;
-			queueid++;
-
-			qconf->tx_port_id[qconf->n_tx_port] = portid;
-			qconf->n_tx_port++;
-		}
-		printf("\n");
-	}
-
-	for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-		if (rte_lcore_is_enabled(lcore_id) == 0)
-			continue;
-		qconf = &lcore_conf[lcore_id];
-		printf("\nInitializing rx queues on lcore %u ... ", lcore_id);
-		fflush(stdout);
-		/* init RX queues */
-		for (queue = 0; queue < qconf->n_rx_queue; ++queue) {
-			struct rte_eth_dev *dev;
-			struct rte_eth_conf *conf;
-			struct rte_eth_rxconf rxq_conf;
-
-			portid = qconf->rx_queue_list[queue].port_id;
-			queueid = qconf->rx_queue_list[queue].queue_id;
-			dev = &rte_eth_devices[portid];
-			conf = &dev->data->dev_conf;
-
-			if (numa_on)
-				socketid = (uint8_t)
-					rte_lcore_to_socket_id(lcore_id);
-			else
-				socketid = 0;
-
-			printf("rxq=%d,%d,%d ", portid, queueid, socketid);
-			fflush(stdout);
-
-			rte_eth_dev_info_get(portid, &dev_info);
-			rxq_conf = dev_info.default_rxconf;
-			rxq_conf.offloads = conf->rxmode.offloads;
-			ret = rte_eth_rx_queue_setup(portid, queueid, nb_rxd,
-					socketid, &rxq_conf,
-					pktmbuf_pool[socketid]);
-			if (ret < 0)
-				rte_exit(EXIT_FAILURE,
-					"rte_eth_rx_queue_setup: err=%d,"
-					"port=%d\n", ret, portid);
-		}
-	}
-
-	printf("\n");
-
-	/* start ports */
-	RTE_ETH_FOREACH_DEV(portid) {
-		if ((enabled_port_mask & (1 << portid)) == 0)
-			continue;
-
-		/* Start device */
-		ret = rte_eth_dev_start(portid);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-				"rte_eth_dev_start: err=%d, port=%d\n",
-				ret, portid);
-
-		/*
-		 * If enabled, put device in promiscuous mode.
-		 * This allows IO forwarding mode to forward packets
-		 * to itself through 2 cross-connected  ports of the
-		 * target machine.
-		 */
-		if (promiscuous_on)
-			rte_eth_promiscuous_enable(portid);
-	}
-
-	check_all_ports_link_status(enabled_port_mask);
-
-	/* launch per-lcore init on every lcore */
-	rte_eal_mp_remote_launch(main_loop, NULL, CALL_MASTER);
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		if (rte_eal_wait_lcore(lcore_id) < 0)
-			return -1;
-	}
-
-	return 0;
-}
diff --git a/examples/l3fwd-acl/meson.build b/examples/l3fwd-acl/meson.build
deleted file mode 100644
index 68cebd6..0000000
--- a/examples/l3fwd-acl/meson.build
+++ /dev/null
@@ -1,13 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-deps += ['acl', 'lpm', 'hash']
-allow_experimental_apis = true
-sources = files(
-	'main.c'
-)
diff --git a/examples/l3fwd-power/Makefile b/examples/l3fwd-power/Makefile
deleted file mode 100644
index d4e1ac6..0000000
--- a/examples/l3fwd-power/Makefile
+++ /dev/null
@@ -1,71 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-# binary name
-APP = l3fwd-power
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else # Build using legacy build system
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-ifneq ($(CONFIG_RTE_EXEC_ENV),"linuxapp")
-$(info This application can only operate in a linuxapp environment, \
-please change the definition of the RTE_TARGET environment variable)
-all:
-else
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-
-# workaround for a gcc bug with noreturn attribute
-# http://gcc.gnu.org/bugzilla/show_bug.cgi?id=12603
-ifeq ($(CONFIG_RTE_TOOLCHAIN_GCC),y)
-CFLAGS_main.o += -Wno-return-type
-endif
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-endif
-endif
diff --git a/examples/l3fwd-power/main.c b/examples/l3fwd-power/main.c
deleted file mode 100644
index d6a0926..0000000
--- a/examples/l3fwd-power/main.c
+++ /dev/null
@@ -1,1867 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <sys/types.h>
-#include <string.h>
-#include <sys/queue.h>
-#include <stdarg.h>
-#include <errno.h>
-#include <getopt.h>
-#include <unistd.h>
-#include <signal.h>
-
-#include <rte_common.h>
-#include <rte_byteorder.h>
-#include <rte_log.h>
-#include <rte_malloc.h>
-#include <rte_memory.h>
-#include <rte_memcpy.h>
-#include <rte_eal.h>
-#include <rte_launch.h>
-#include <rte_atomic.h>
-#include <rte_cycles.h>
-#include <rte_prefetch.h>
-#include <rte_lcore.h>
-#include <rte_per_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_interrupts.h>
-#include <rte_random.h>
-#include <rte_debug.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-#include <rte_ip.h>
-#include <rte_tcp.h>
-#include <rte_udp.h>
-#include <rte_string_fns.h>
-#include <rte_timer.h>
-#include <rte_power.h>
-#include <rte_spinlock.h>
-
-#define RTE_LOGTYPE_L3FWD_POWER RTE_LOGTYPE_USER1
-
-#define MAX_PKT_BURST 32
-
-#define MIN_ZERO_POLL_COUNT 10
-
-/* 100 ms interval */
-#define TIMER_NUMBER_PER_SECOND           10
-/* 100000 us */
-#define SCALING_PERIOD                    (1000000/TIMER_NUMBER_PER_SECOND)
-#define SCALING_DOWN_TIME_RATIO_THRESHOLD 0.25
-
-#define APP_LOOKUP_EXACT_MATCH          0
-#define APP_LOOKUP_LPM                  1
-#define DO_RFC_1812_CHECKS
-
-#ifndef APP_LOOKUP_METHOD
-#define APP_LOOKUP_METHOD             APP_LOOKUP_LPM
-#endif
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_EXACT_MATCH)
-#include <rte_hash.h>
-#elif (APP_LOOKUP_METHOD == APP_LOOKUP_LPM)
-#include <rte_lpm.h>
-#else
-#error "APP_LOOKUP_METHOD set to incorrect value"
-#endif
-
-#ifndef IPv6_BYTES
-#define IPv6_BYTES_FMT "%02x%02x:%02x%02x:%02x%02x:%02x%02x:"\
-                       "%02x%02x:%02x%02x:%02x%02x:%02x%02x"
-#define IPv6_BYTES(addr) \
-	addr[0],  addr[1], addr[2],  addr[3], \
-	addr[4],  addr[5], addr[6],  addr[7], \
-	addr[8],  addr[9], addr[10], addr[11],\
-	addr[12], addr[13],addr[14], addr[15]
-#endif
-
-#define MAX_JUMBO_PKT_LEN  9600
-
-#define IPV6_ADDR_LEN 16
-
-#define MEMPOOL_CACHE_SIZE 256
-
-/*
- * This expression is used to calculate the number of mbufs needed depending on
- * user input, taking into account memory for rx and tx hardware rings, cache
- * per lcore and mtable per port per lcore. RTE_MAX is used to ensure that
- * NB_MBUF never goes below a minimum value of 8192.
- */
-
-#define NB_MBUF RTE_MAX	( \
-	(nb_ports*nb_rx_queue*nb_rxd + \
-	nb_ports*nb_lcores*MAX_PKT_BURST + \
-	nb_ports*n_tx_queue*nb_txd + \
-	nb_lcores*MEMPOOL_CACHE_SIZE), \
-	(unsigned)8192)
-
-#define BURST_TX_DRAIN_US 100 /* TX drain every ~100us */
-
-#define NB_SOCKETS 8
-
-/* Configure how many packets ahead to prefetch, when reading packets */
-#define PREFETCH_OFFSET	3
-
-/*
- * Configurable number of RX/TX ring descriptors
- */
-#define RTE_TEST_RX_DESC_DEFAULT 1024
-#define RTE_TEST_TX_DESC_DEFAULT 1024
-static uint16_t nb_rxd = RTE_TEST_RX_DESC_DEFAULT;
-static uint16_t nb_txd = RTE_TEST_TX_DESC_DEFAULT;
-
-/* ethernet addresses of ports */
-static struct ether_addr ports_eth_addr[RTE_MAX_ETHPORTS];
-
-/* ethernet addresses of ports */
-static rte_spinlock_t locks[RTE_MAX_ETHPORTS];
-
-/* mask of enabled ports */
-static uint32_t enabled_port_mask = 0;
-/* Ports set in promiscuous mode off by default. */
-static int promiscuous_on = 0;
-/* NUMA is enabled by default. */
-static int numa_on = 1;
-static int parse_ptype; /**< Parse packet type using rx callback, and */
-			/**< disabled by default */
-
-enum freq_scale_hint_t
-{
-	FREQ_LOWER    =      -1,
-	FREQ_CURRENT  =       0,
-	FREQ_HIGHER   =       1,
-	FREQ_HIGHEST  =       2
-};
-
-struct lcore_rx_queue {
-	uint16_t port_id;
-	uint8_t queue_id;
-	enum freq_scale_hint_t freq_up_hint;
-	uint32_t zero_rx_packet_count;
-	uint32_t idle_hint;
-} __rte_cache_aligned;
-
-#define MAX_RX_QUEUE_PER_LCORE 16
-#define MAX_TX_QUEUE_PER_PORT RTE_MAX_ETHPORTS
-#define MAX_RX_QUEUE_PER_PORT 128
-
-#define MAX_RX_QUEUE_INTERRUPT_PER_PORT 16
-
-
-#define MAX_LCORE_PARAMS 1024
-struct lcore_params {
-	uint16_t port_id;
-	uint8_t queue_id;
-	uint8_t lcore_id;
-} __rte_cache_aligned;
-
-static struct lcore_params lcore_params_array[MAX_LCORE_PARAMS];
-static struct lcore_params lcore_params_array_default[] = {
-	{0, 0, 2},
-	{0, 1, 2},
-	{0, 2, 2},
-	{1, 0, 2},
-	{1, 1, 2},
-	{1, 2, 2},
-	{2, 0, 2},
-	{3, 0, 3},
-	{3, 1, 3},
-};
-
-static struct lcore_params * lcore_params = lcore_params_array_default;
-static uint16_t nb_lcore_params = sizeof(lcore_params_array_default) /
-				sizeof(lcore_params_array_default[0]);
-
-static struct rte_eth_conf port_conf = {
-	.rxmode = {
-		.mq_mode        = ETH_MQ_RX_RSS,
-		.max_rx_pkt_len = ETHER_MAX_LEN,
-		.split_hdr_size = 0,
-		.ignore_offload_bitfield = 1,
-		.offloads = (DEV_RX_OFFLOAD_CRC_STRIP |
-			     DEV_RX_OFFLOAD_CHECKSUM),
-	},
-	.rx_adv_conf = {
-		.rss_conf = {
-			.rss_key = NULL,
-			.rss_hf = ETH_RSS_UDP,
-		},
-	},
-	.txmode = {
-		.mq_mode = ETH_MQ_TX_NONE,
-	},
-	.intr_conf = {
-		.rxq = 1,
-	},
-};
-
-static struct rte_mempool * pktmbuf_pool[NB_SOCKETS];
-
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_EXACT_MATCH)
-
-#ifdef RTE_ARCH_X86
-#include <rte_hash_crc.h>
-#define DEFAULT_HASH_FUNC       rte_hash_crc
-#else
-#include <rte_jhash.h>
-#define DEFAULT_HASH_FUNC       rte_jhash
-#endif
-
-struct ipv4_5tuple {
-	uint32_t ip_dst;
-	uint32_t ip_src;
-	uint16_t port_dst;
-	uint16_t port_src;
-	uint8_t  proto;
-} __attribute__((__packed__));
-
-struct ipv6_5tuple {
-	uint8_t  ip_dst[IPV6_ADDR_LEN];
-	uint8_t  ip_src[IPV6_ADDR_LEN];
-	uint16_t port_dst;
-	uint16_t port_src;
-	uint8_t  proto;
-} __attribute__((__packed__));
-
-struct ipv4_l3fwd_route {
-	struct ipv4_5tuple key;
-	uint8_t if_out;
-};
-
-struct ipv6_l3fwd_route {
-	struct ipv6_5tuple key;
-	uint8_t if_out;
-};
-
-static struct ipv4_l3fwd_route ipv4_l3fwd_route_array[] = {
-	{{IPv4(100,10,0,1), IPv4(200,10,0,1), 101, 11, IPPROTO_TCP}, 0},
-	{{IPv4(100,20,0,2), IPv4(200,20,0,2), 102, 12, IPPROTO_TCP}, 1},
-	{{IPv4(100,30,0,3), IPv4(200,30,0,3), 103, 13, IPPROTO_TCP}, 2},
-	{{IPv4(100,40,0,4), IPv4(200,40,0,4), 104, 14, IPPROTO_TCP}, 3},
-};
-
-static struct ipv6_l3fwd_route ipv6_l3fwd_route_array[] = {
-	{
-		{
-			{0xfe, 0x80, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
-			 0x02, 0x1b, 0x21, 0xff, 0xfe, 0x91, 0x38, 0x05},
-			{0xfe, 0x80, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
-			 0x02, 0x1e, 0x67, 0xff, 0xfe, 0x0d, 0xb6, 0x0a},
-			 1, 10, IPPROTO_UDP
-		}, 4
-	},
-};
-
-typedef struct rte_hash lookup_struct_t;
-static lookup_struct_t *ipv4_l3fwd_lookup_struct[NB_SOCKETS];
-static lookup_struct_t *ipv6_l3fwd_lookup_struct[NB_SOCKETS];
-
-#define L3FWD_HASH_ENTRIES	1024
-
-#define IPV4_L3FWD_NUM_ROUTES \
-	(sizeof(ipv4_l3fwd_route_array) / sizeof(ipv4_l3fwd_route_array[0]))
-
-#define IPV6_L3FWD_NUM_ROUTES \
-	(sizeof(ipv6_l3fwd_route_array) / sizeof(ipv6_l3fwd_route_array[0]))
-
-static uint16_t ipv4_l3fwd_out_if[L3FWD_HASH_ENTRIES] __rte_cache_aligned;
-static uint16_t ipv6_l3fwd_out_if[L3FWD_HASH_ENTRIES] __rte_cache_aligned;
-#endif
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_LPM)
-struct ipv4_l3fwd_route {
-	uint32_t ip;
-	uint8_t  depth;
-	uint8_t  if_out;
-};
-
-static struct ipv4_l3fwd_route ipv4_l3fwd_route_array[] = {
-	{IPv4(1,1,1,0), 24, 0},
-	{IPv4(2,1,1,0), 24, 1},
-	{IPv4(3,1,1,0), 24, 2},
-	{IPv4(4,1,1,0), 24, 3},
-	{IPv4(5,1,1,0), 24, 4},
-	{IPv4(6,1,1,0), 24, 5},
-	{IPv4(7,1,1,0), 24, 6},
-	{IPv4(8,1,1,0), 24, 7},
-};
-
-#define IPV4_L3FWD_NUM_ROUTES \
-	(sizeof(ipv4_l3fwd_route_array) / sizeof(ipv4_l3fwd_route_array[0]))
-
-#define IPV4_L3FWD_LPM_MAX_RULES     1024
-
-typedef struct rte_lpm lookup_struct_t;
-static lookup_struct_t *ipv4_l3fwd_lookup_struct[NB_SOCKETS];
-#endif
-
-struct lcore_conf {
-	uint16_t n_rx_queue;
-	struct lcore_rx_queue rx_queue_list[MAX_RX_QUEUE_PER_LCORE];
-	uint16_t n_tx_port;
-	uint16_t tx_port_id[RTE_MAX_ETHPORTS];
-	uint16_t tx_queue_id[RTE_MAX_ETHPORTS];
-	struct rte_eth_dev_tx_buffer *tx_buffer[RTE_MAX_ETHPORTS];
-	lookup_struct_t * ipv4_lookup_struct;
-	lookup_struct_t * ipv6_lookup_struct;
-} __rte_cache_aligned;
-
-struct lcore_stats {
-	/* total sleep time in ms since last frequency scaling down */
-	uint32_t sleep_time;
-	/* number of long sleep recently */
-	uint32_t nb_long_sleep;
-	/* freq. scaling up trend */
-	uint32_t trend;
-	/* total packet processed recently */
-	uint64_t nb_rx_processed;
-	/* total iterations looped recently */
-	uint64_t nb_iteration_looped;
-	uint32_t padding[9];
-} __rte_cache_aligned;
-
-static struct lcore_conf lcore_conf[RTE_MAX_LCORE] __rte_cache_aligned;
-static struct lcore_stats stats[RTE_MAX_LCORE] __rte_cache_aligned;
-static struct rte_timer power_timers[RTE_MAX_LCORE];
-
-static inline uint32_t power_idle_heuristic(uint32_t zero_rx_packet_count);
-static inline enum freq_scale_hint_t power_freq_scaleup_heuristic( \
-		unsigned int lcore_id, uint16_t port_id, uint16_t queue_id);
-
-/* exit signal handler */
-static void
-signal_exit_now(int sigtype)
-{
-	unsigned lcore_id;
-	unsigned int portid;
-	int ret;
-
-	if (sigtype == SIGINT) {
-		for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-			if (rte_lcore_is_enabled(lcore_id) == 0)
-				continue;
-
-			/* init power management library */
-			ret = rte_power_exit(lcore_id);
-			if (ret)
-				rte_exit(EXIT_FAILURE, "Power management "
-					"library de-initialization failed on "
-							"core%u\n", lcore_id);
-		}
-
-		RTE_ETH_FOREACH_DEV(portid) {
-			if ((enabled_port_mask & (1 << portid)) == 0)
-				continue;
-
-			rte_eth_dev_stop(portid);
-			rte_eth_dev_close(portid);
-		}
-	}
-
-	rte_exit(EXIT_SUCCESS, "User forced exit\n");
-}
-
-/*  Freqency scale down timer callback */
-static void
-power_timer_cb(__attribute__((unused)) struct rte_timer *tim,
-			  __attribute__((unused)) void *arg)
-{
-	uint64_t hz;
-	float sleep_time_ratio;
-	unsigned lcore_id = rte_lcore_id();
-
-	/* accumulate total execution time in us when callback is invoked */
-	sleep_time_ratio = (float)(stats[lcore_id].sleep_time) /
-					(float)SCALING_PERIOD;
-	/**
-	 * check whether need to scale down frequency a step if it sleep a lot.
-	 */
-	if (sleep_time_ratio >= SCALING_DOWN_TIME_RATIO_THRESHOLD) {
-		if (rte_power_freq_down)
-			rte_power_freq_down(lcore_id);
-	}
-	else if ( (unsigned)(stats[lcore_id].nb_rx_processed /
-		stats[lcore_id].nb_iteration_looped) < MAX_PKT_BURST) {
-		/**
-		 * scale down a step if average packet per iteration less
-		 * than expectation.
-		 */
-		if (rte_power_freq_down)
-			rte_power_freq_down(lcore_id);
-	}
-
-	/**
-	 * initialize another timer according to current frequency to ensure
-	 * timer interval is relatively fixed.
-	 */
-	hz = rte_get_timer_hz();
-	rte_timer_reset(&power_timers[lcore_id], hz/TIMER_NUMBER_PER_SECOND,
-				SINGLE, lcore_id, power_timer_cb, NULL);
-
-	stats[lcore_id].nb_rx_processed = 0;
-	stats[lcore_id].nb_iteration_looped = 0;
-
-	stats[lcore_id].sleep_time = 0;
-}
-
-/* Enqueue a single packet, and send burst if queue is filled */
-static inline int
-send_single_packet(struct rte_mbuf *m, uint16_t port)
-{
-	uint32_t lcore_id;
-	struct lcore_conf *qconf;
-
-	lcore_id = rte_lcore_id();
-	qconf = &lcore_conf[lcore_id];
-
-	rte_eth_tx_buffer(port, qconf->tx_queue_id[port],
-			qconf->tx_buffer[port], m);
-
-	return 0;
-}
-
-#ifdef DO_RFC_1812_CHECKS
-static inline int
-is_valid_ipv4_pkt(struct ipv4_hdr *pkt, uint32_t link_len)
-{
-	/* From http://www.rfc-editor.org/rfc/rfc1812.txt section 5.2.2 */
-	/*
-	 * 1. The packet length reported by the Link Layer must be large
-	 * enough to hold the minimum length legal IP datagram (20 bytes).
-	 */
-	if (link_len < sizeof(struct ipv4_hdr))
-		return -1;
-
-	/* 2. The IP checksum must be correct. */
-	/* this is checked in H/W */
-
-	/*
-	 * 3. The IP version number must be 4. If the version number is not 4
-	 * then the packet may be another version of IP, such as IPng or
-	 * ST-II.
-	 */
-	if (((pkt->version_ihl) >> 4) != 4)
-		return -3;
-	/*
-	 * 4. The IP header length field must be large enough to hold the
-	 * minimum length legal IP datagram (20 bytes = 5 words).
-	 */
-	if ((pkt->version_ihl & 0xf) < 5)
-		return -4;
-
-	/*
-	 * 5. The IP total length field must be large enough to hold the IP
-	 * datagram header, whose length is specified in the IP header length
-	 * field.
-	 */
-	if (rte_cpu_to_be_16(pkt->total_length) < sizeof(struct ipv4_hdr))
-		return -5;
-
-	return 0;
-}
-#endif
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_EXACT_MATCH)
-static void
-print_ipv4_key(struct ipv4_5tuple key)
-{
-	printf("IP dst = %08x, IP src = %08x, port dst = %d, port src = %d, "
-		"proto = %d\n", (unsigned)key.ip_dst, (unsigned)key.ip_src,
-				key.port_dst, key.port_src, key.proto);
-}
-static void
-print_ipv6_key(struct ipv6_5tuple key)
-{
-	printf( "IP dst = " IPv6_BYTES_FMT ", IP src = " IPv6_BYTES_FMT ", "
-	        "port dst = %d, port src = %d, proto = %d\n",
-	        IPv6_BYTES(key.ip_dst), IPv6_BYTES(key.ip_src),
-	        key.port_dst, key.port_src, key.proto);
-}
-
-static inline uint16_t
-get_ipv4_dst_port(struct ipv4_hdr *ipv4_hdr, uint16_t portid,
-		lookup_struct_t * ipv4_l3fwd_lookup_struct)
-{
-	struct ipv4_5tuple key;
-	struct tcp_hdr *tcp;
-	struct udp_hdr *udp;
-	int ret = 0;
-
-	key.ip_dst = rte_be_to_cpu_32(ipv4_hdr->dst_addr);
-	key.ip_src = rte_be_to_cpu_32(ipv4_hdr->src_addr);
-	key.proto = ipv4_hdr->next_proto_id;
-
-	switch (ipv4_hdr->next_proto_id) {
-	case IPPROTO_TCP:
-		tcp = (struct tcp_hdr *)((unsigned char *)ipv4_hdr +
-					sizeof(struct ipv4_hdr));
-		key.port_dst = rte_be_to_cpu_16(tcp->dst_port);
-		key.port_src = rte_be_to_cpu_16(tcp->src_port);
-		break;
-
-	case IPPROTO_UDP:
-		udp = (struct udp_hdr *)((unsigned char *)ipv4_hdr +
-					sizeof(struct ipv4_hdr));
-		key.port_dst = rte_be_to_cpu_16(udp->dst_port);
-		key.port_src = rte_be_to_cpu_16(udp->src_port);
-		break;
-
-	default:
-		key.port_dst = 0;
-		key.port_src = 0;
-		break;
-	}
-
-	/* Find destination port */
-	ret = rte_hash_lookup(ipv4_l3fwd_lookup_struct, (const void *)&key);
-	return ((ret < 0) ? portid : ipv4_l3fwd_out_if[ret]);
-}
-
-static inline uint16_t
-get_ipv6_dst_port(struct ipv6_hdr *ipv6_hdr, uint16_t portid,
-			lookup_struct_t *ipv6_l3fwd_lookup_struct)
-{
-	struct ipv6_5tuple key;
-	struct tcp_hdr *tcp;
-	struct udp_hdr *udp;
-	int ret = 0;
-
-	memcpy(key.ip_dst, ipv6_hdr->dst_addr, IPV6_ADDR_LEN);
-	memcpy(key.ip_src, ipv6_hdr->src_addr, IPV6_ADDR_LEN);
-
-	key.proto = ipv6_hdr->proto;
-
-	switch (ipv6_hdr->proto) {
-	case IPPROTO_TCP:
-		tcp = (struct tcp_hdr *)((unsigned char *) ipv6_hdr +
-					sizeof(struct ipv6_hdr));
-		key.port_dst = rte_be_to_cpu_16(tcp->dst_port);
-		key.port_src = rte_be_to_cpu_16(tcp->src_port);
-		break;
-
-	case IPPROTO_UDP:
-		udp = (struct udp_hdr *)((unsigned char *) ipv6_hdr +
-					sizeof(struct ipv6_hdr));
-		key.port_dst = rte_be_to_cpu_16(udp->dst_port);
-		key.port_src = rte_be_to_cpu_16(udp->src_port);
-		break;
-
-	default:
-		key.port_dst = 0;
-		key.port_src = 0;
-		break;
-	}
-
-	/* Find destination port */
-	ret = rte_hash_lookup(ipv6_l3fwd_lookup_struct, (const void *)&key);
-	return ((ret < 0) ? portid : ipv6_l3fwd_out_if[ret]);
-}
-#endif
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_LPM)
-static inline uint16_t
-get_ipv4_dst_port(struct ipv4_hdr *ipv4_hdr, uint16_t portid,
-		lookup_struct_t *ipv4_l3fwd_lookup_struct)
-{
-	uint32_t next_hop;
-
-	return ((rte_lpm_lookup(ipv4_l3fwd_lookup_struct,
-			rte_be_to_cpu_32(ipv4_hdr->dst_addr), &next_hop) == 0)?
-			next_hop : portid);
-}
-#endif
-
-static inline void
-parse_ptype_one(struct rte_mbuf *m)
-{
-	struct ether_hdr *eth_hdr;
-	uint32_t packet_type = RTE_PTYPE_UNKNOWN;
-	uint16_t ether_type;
-
-	eth_hdr = rte_pktmbuf_mtod(m, struct ether_hdr *);
-	ether_type = eth_hdr->ether_type;
-	if (ether_type == rte_cpu_to_be_16(ETHER_TYPE_IPv4))
-		packet_type |= RTE_PTYPE_L3_IPV4_EXT_UNKNOWN;
-	else if (ether_type == rte_cpu_to_be_16(ETHER_TYPE_IPv6))
-		packet_type |= RTE_PTYPE_L3_IPV6_EXT_UNKNOWN;
-
-	m->packet_type = packet_type;
-}
-
-static uint16_t
-cb_parse_ptype(uint16_t port __rte_unused, uint16_t queue __rte_unused,
-	       struct rte_mbuf *pkts[], uint16_t nb_pkts,
-	       uint16_t max_pkts __rte_unused,
-	       void *user_param __rte_unused)
-{
-	unsigned int i;
-
-	for (i = 0; i < nb_pkts; ++i)
-		parse_ptype_one(pkts[i]);
-
-	return nb_pkts;
-}
-
-static int
-add_cb_parse_ptype(uint16_t portid, uint16_t queueid)
-{
-	printf("Port %d: softly parse packet type info\n", portid);
-	if (rte_eth_add_rx_callback(portid, queueid, cb_parse_ptype, NULL))
-		return 0;
-
-	printf("Failed to add rx callback: port=%d\n", portid);
-	return -1;
-}
-
-static inline void
-l3fwd_simple_forward(struct rte_mbuf *m, uint16_t portid,
-				struct lcore_conf *qconf)
-{
-	struct ether_hdr *eth_hdr;
-	struct ipv4_hdr *ipv4_hdr;
-	void *d_addr_bytes;
-	uint16_t dst_port;
-
-	eth_hdr = rte_pktmbuf_mtod(m, struct ether_hdr *);
-
-	if (RTE_ETH_IS_IPV4_HDR(m->packet_type)) {
-		/* Handle IPv4 headers.*/
-		ipv4_hdr =
-			rte_pktmbuf_mtod_offset(m, struct ipv4_hdr *,
-						sizeof(struct ether_hdr));
-
-#ifdef DO_RFC_1812_CHECKS
-		/* Check to make sure the packet is valid (RFC1812) */
-		if (is_valid_ipv4_pkt(ipv4_hdr, m->pkt_len) < 0) {
-			rte_pktmbuf_free(m);
-			return;
-		}
-#endif
-
-		dst_port = get_ipv4_dst_port(ipv4_hdr, portid,
-					qconf->ipv4_lookup_struct);
-		if (dst_port >= RTE_MAX_ETHPORTS ||
-				(enabled_port_mask & 1 << dst_port) == 0)
-			dst_port = portid;
-
-		/* 02:00:00:00:00:xx */
-		d_addr_bytes = &eth_hdr->d_addr.addr_bytes[0];
-		*((uint64_t *)d_addr_bytes) =
-			0x000000000002 + ((uint64_t)dst_port << 40);
-
-#ifdef DO_RFC_1812_CHECKS
-		/* Update time to live and header checksum */
-		--(ipv4_hdr->time_to_live);
-		++(ipv4_hdr->hdr_checksum);
-#endif
-
-		/* src addr */
-		ether_addr_copy(&ports_eth_addr[dst_port], &eth_hdr->s_addr);
-
-		send_single_packet(m, dst_port);
-	} else if (RTE_ETH_IS_IPV6_HDR(m->packet_type)) {
-		/* Handle IPv6 headers.*/
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_EXACT_MATCH)
-		struct ipv6_hdr *ipv6_hdr;
-
-		ipv6_hdr =
-			rte_pktmbuf_mtod_offset(m, struct ipv6_hdr *,
-						sizeof(struct ether_hdr));
-
-		dst_port = get_ipv6_dst_port(ipv6_hdr, portid,
-					qconf->ipv6_lookup_struct);
-
-		if (dst_port >= RTE_MAX_ETHPORTS ||
-				(enabled_port_mask & 1 << dst_port) == 0)
-			dst_port = portid;
-
-		/* 02:00:00:00:00:xx */
-		d_addr_bytes = &eth_hdr->d_addr.addr_bytes[0];
-		*((uint64_t *)d_addr_bytes) =
-			0x000000000002 + ((uint64_t)dst_port << 40);
-
-		/* src addr */
-		ether_addr_copy(&ports_eth_addr[dst_port], &eth_hdr->s_addr);
-
-		send_single_packet(m, dst_port);
-#else
-		/* We don't currently handle IPv6 packets in LPM mode. */
-		rte_pktmbuf_free(m);
-#endif
-	} else
-		rte_pktmbuf_free(m);
-
-}
-
-#define MINIMUM_SLEEP_TIME         1
-#define SUSPEND_THRESHOLD          300
-
-static inline uint32_t
-power_idle_heuristic(uint32_t zero_rx_packet_count)
-{
-	/* If zero count is less than 100,  sleep 1us */
-	if (zero_rx_packet_count < SUSPEND_THRESHOLD)
-		return MINIMUM_SLEEP_TIME;
-	/* If zero count is less than 1000, sleep 100 us which is the
-		minimum latency switching from C3/C6 to C0
-	*/
-	else
-		return SUSPEND_THRESHOLD;
-}
-
-static inline enum freq_scale_hint_t
-power_freq_scaleup_heuristic(unsigned lcore_id,
-			     uint16_t port_id,
-			     uint16_t queue_id)
-{
-	uint32_t rxq_count = rte_eth_rx_queue_count(port_id, queue_id);
-/**
- * HW Rx queue size is 128 by default, Rx burst read at maximum 32 entries
- * per iteration
- */
-#define FREQ_GEAR1_RX_PACKET_THRESHOLD             MAX_PKT_BURST
-#define FREQ_GEAR2_RX_PACKET_THRESHOLD             (MAX_PKT_BURST*2)
-#define FREQ_GEAR3_RX_PACKET_THRESHOLD             (MAX_PKT_BURST*3)
-#define FREQ_UP_TREND1_ACC   1
-#define FREQ_UP_TREND2_ACC   100
-#define FREQ_UP_THRESHOLD    10000
-
-	if (likely(rxq_count > FREQ_GEAR3_RX_PACKET_THRESHOLD)) {
-		stats[lcore_id].trend = 0;
-		return FREQ_HIGHEST;
-	} else if (likely(rxq_count > FREQ_GEAR2_RX_PACKET_THRESHOLD))
-		stats[lcore_id].trend += FREQ_UP_TREND2_ACC;
-	else if (likely(rxq_count > FREQ_GEAR1_RX_PACKET_THRESHOLD))
-		stats[lcore_id].trend += FREQ_UP_TREND1_ACC;
-
-	if (likely(stats[lcore_id].trend > FREQ_UP_THRESHOLD)) {
-		stats[lcore_id].trend = 0;
-		return FREQ_HIGHER;
-	}
-
-	return FREQ_CURRENT;
-}
-
-/**
- * force polling thread sleep until one-shot rx interrupt triggers
- * @param port_id
- *  Port id.
- * @param queue_id
- *  Rx queue id.
- * @return
- *  0 on success
- */
-static int
-sleep_until_rx_interrupt(int num)
-{
-	struct rte_epoll_event event[num];
-	int n, i;
-	uint16_t port_id;
-	uint8_t queue_id;
-	void *data;
-
-	RTE_LOG(INFO, L3FWD_POWER,
-		"lcore %u sleeps until interrupt triggers\n",
-		rte_lcore_id());
-
-	n = rte_epoll_wait(RTE_EPOLL_PER_THREAD, event, num, -1);
-	for (i = 0; i < n; i++) {
-		data = event[i].epdata.data;
-		port_id = ((uintptr_t)data) >> CHAR_BIT;
-		queue_id = ((uintptr_t)data) &
-			RTE_LEN2MASK(CHAR_BIT, uint8_t);
-		rte_eth_dev_rx_intr_disable(port_id, queue_id);
-		RTE_LOG(INFO, L3FWD_POWER,
-			"lcore %u is waked up from rx interrupt on"
-			" port %d queue %d\n",
-			rte_lcore_id(), port_id, queue_id);
-	}
-
-	return 0;
-}
-
-static void turn_on_intr(struct lcore_conf *qconf)
-{
-	int i;
-	struct lcore_rx_queue *rx_queue;
-	uint8_t queue_id;
-	uint16_t port_id;
-
-	for (i = 0; i < qconf->n_rx_queue; ++i) {
-		rx_queue = &(qconf->rx_queue_list[i]);
-		port_id = rx_queue->port_id;
-		queue_id = rx_queue->queue_id;
-
-		rte_spinlock_lock(&(locks[port_id]));
-		rte_eth_dev_rx_intr_enable(port_id, queue_id);
-		rte_spinlock_unlock(&(locks[port_id]));
-	}
-}
-
-static int event_register(struct lcore_conf *qconf)
-{
-	struct lcore_rx_queue *rx_queue;
-	uint8_t queueid;
-	uint16_t portid;
-	uint32_t data;
-	int ret;
-	int i;
-
-	for (i = 0; i < qconf->n_rx_queue; ++i) {
-		rx_queue = &(qconf->rx_queue_list[i]);
-		portid = rx_queue->port_id;
-		queueid = rx_queue->queue_id;
-		data = portid << CHAR_BIT | queueid;
-
-		ret = rte_eth_dev_rx_intr_ctl_q(portid, queueid,
-						RTE_EPOLL_PER_THREAD,
-						RTE_INTR_EVENT_ADD,
-						(void *)((uintptr_t)data));
-		if (ret)
-			return ret;
-	}
-
-	return 0;
-}
-
-/* main processing loop */
-static int
-main_loop(__attribute__((unused)) void *dummy)
-{
-	struct rte_mbuf *pkts_burst[MAX_PKT_BURST];
-	unsigned lcore_id;
-	uint64_t prev_tsc, diff_tsc, cur_tsc, tim_res_tsc, hz;
-	uint64_t prev_tsc_power = 0, cur_tsc_power, diff_tsc_power;
-	int i, j, nb_rx;
-	uint8_t queueid;
-	uint16_t portid;
-	struct lcore_conf *qconf;
-	struct lcore_rx_queue *rx_queue;
-	enum freq_scale_hint_t lcore_scaleup_hint;
-	uint32_t lcore_rx_idle_count = 0;
-	uint32_t lcore_idle_hint = 0;
-	int intr_en = 0;
-
-	const uint64_t drain_tsc = (rte_get_tsc_hz() + US_PER_S - 1) / US_PER_S * BURST_TX_DRAIN_US;
-
-	prev_tsc = 0;
-	hz = rte_get_timer_hz();
-	tim_res_tsc = hz/TIMER_NUMBER_PER_SECOND;
-
-	lcore_id = rte_lcore_id();
-	qconf = &lcore_conf[lcore_id];
-
-	if (qconf->n_rx_queue == 0) {
-		RTE_LOG(INFO, L3FWD_POWER, "lcore %u has nothing to do\n", lcore_id);
-		return 0;
-	}
-
-	RTE_LOG(INFO, L3FWD_POWER, "entering main loop on lcore %u\n", lcore_id);
-
-	for (i = 0; i < qconf->n_rx_queue; i++) {
-		portid = qconf->rx_queue_list[i].port_id;
-		queueid = qconf->rx_queue_list[i].queue_id;
-		RTE_LOG(INFO, L3FWD_POWER, " -- lcoreid=%u portid=%u "
-			"rxqueueid=%hhu\n", lcore_id, portid, queueid);
-	}
-
-	/* add into event wait list */
-	if (event_register(qconf) == 0)
-		intr_en = 1;
-	else
-		RTE_LOG(INFO, L3FWD_POWER, "RX interrupt won't enable.\n");
-
-	while (1) {
-		stats[lcore_id].nb_iteration_looped++;
-
-		cur_tsc = rte_rdtsc();
-		cur_tsc_power = cur_tsc;
-
-		/*
-		 * TX burst queue drain
-		 */
-		diff_tsc = cur_tsc - prev_tsc;
-		if (unlikely(diff_tsc > drain_tsc)) {
-			for (i = 0; i < qconf->n_tx_port; ++i) {
-				portid = qconf->tx_port_id[i];
-				rte_eth_tx_buffer_flush(portid,
-						qconf->tx_queue_id[portid],
-						qconf->tx_buffer[portid]);
-			}
-			prev_tsc = cur_tsc;
-		}
-
-		diff_tsc_power = cur_tsc_power - prev_tsc_power;
-		if (diff_tsc_power > tim_res_tsc) {
-			rte_timer_manage();
-			prev_tsc_power = cur_tsc_power;
-		}
-
-start_rx:
-		/*
-		 * Read packet from RX queues
-		 */
-		lcore_scaleup_hint = FREQ_CURRENT;
-		lcore_rx_idle_count = 0;
-		for (i = 0; i < qconf->n_rx_queue; ++i) {
-			rx_queue = &(qconf->rx_queue_list[i]);
-			rx_queue->idle_hint = 0;
-			portid = rx_queue->port_id;
-			queueid = rx_queue->queue_id;
-
-			nb_rx = rte_eth_rx_burst(portid, queueid, pkts_burst,
-								MAX_PKT_BURST);
-
-			stats[lcore_id].nb_rx_processed += nb_rx;
-			if (unlikely(nb_rx == 0)) {
-				/**
-				 * no packet received from rx queue, try to
-				 * sleep for a while forcing CPU enter deeper
-				 * C states.
-				 */
-				rx_queue->zero_rx_packet_count++;
-
-				if (rx_queue->zero_rx_packet_count <=
-							MIN_ZERO_POLL_COUNT)
-					continue;
-
-				rx_queue->idle_hint = power_idle_heuristic(\
-					rx_queue->zero_rx_packet_count);
-				lcore_rx_idle_count++;
-			} else {
-				rx_queue->zero_rx_packet_count = 0;
-
-				/**
-				 * do not scale up frequency immediately as
-				 * user to kernel space communication is costly
-				 * which might impact packet I/O for received
-				 * packets.
-				 */
-				rx_queue->freq_up_hint =
-					power_freq_scaleup_heuristic(lcore_id,
-							portid, queueid);
-			}
-
-			/* Prefetch first packets */
-			for (j = 0; j < PREFETCH_OFFSET && j < nb_rx; j++) {
-				rte_prefetch0(rte_pktmbuf_mtod(
-						pkts_burst[j], void *));
-			}
-
-			/* Prefetch and forward already prefetched packets */
-			for (j = 0; j < (nb_rx - PREFETCH_OFFSET); j++) {
-				rte_prefetch0(rte_pktmbuf_mtod(pkts_burst[
-						j + PREFETCH_OFFSET], void *));
-				l3fwd_simple_forward(pkts_burst[j], portid,
-								qconf);
-			}
-
-			/* Forward remaining prefetched packets */
-			for (; j < nb_rx; j++) {
-				l3fwd_simple_forward(pkts_burst[j], portid,
-								qconf);
-			}
-		}
-
-		if (likely(lcore_rx_idle_count != qconf->n_rx_queue)) {
-			for (i = 1, lcore_scaleup_hint =
-				qconf->rx_queue_list[0].freq_up_hint;
-					i < qconf->n_rx_queue; ++i) {
-				rx_queue = &(qconf->rx_queue_list[i]);
-				if (rx_queue->freq_up_hint >
-						lcore_scaleup_hint)
-					lcore_scaleup_hint =
-						rx_queue->freq_up_hint;
-			}
-
-			if (lcore_scaleup_hint == FREQ_HIGHEST) {
-				if (rte_power_freq_max)
-					rte_power_freq_max(lcore_id);
-			} else if (lcore_scaleup_hint == FREQ_HIGHER) {
-				if (rte_power_freq_up)
-					rte_power_freq_up(lcore_id);
-			}
-		} else {
-			/**
-			 * All Rx queues empty in recent consecutive polls,
-			 * sleep in a conservative manner, meaning sleep as
-			 * less as possible.
-			 */
-			for (i = 1, lcore_idle_hint =
-				qconf->rx_queue_list[0].idle_hint;
-					i < qconf->n_rx_queue; ++i) {
-				rx_queue = &(qconf->rx_queue_list[i]);
-				if (rx_queue->idle_hint < lcore_idle_hint)
-					lcore_idle_hint = rx_queue->idle_hint;
-			}
-
-			if (lcore_idle_hint < SUSPEND_THRESHOLD)
-				/**
-				 * execute "pause" instruction to avoid context
-				 * switch which generally take hundred of
-				 * microseconds for short sleep.
-				 */
-				rte_delay_us(lcore_idle_hint);
-			else {
-				/* suspend until rx interrupt trigges */
-				if (intr_en) {
-					turn_on_intr(qconf);
-					sleep_until_rx_interrupt(
-						qconf->n_rx_queue);
-					/**
-					 * start receiving packets immediately
-					 */
-					goto start_rx;
-				}
-			}
-			stats[lcore_id].sleep_time += lcore_idle_hint;
-		}
-	}
-}
-
-static int
-check_lcore_params(void)
-{
-	uint8_t queue, lcore;
-	uint16_t i;
-	int socketid;
-
-	for (i = 0; i < nb_lcore_params; ++i) {
-		queue = lcore_params[i].queue_id;
-		if (queue >= MAX_RX_QUEUE_PER_PORT) {
-			printf("invalid queue number: %hhu\n", queue);
-			return -1;
-		}
-		lcore = lcore_params[i].lcore_id;
-		if (!rte_lcore_is_enabled(lcore)) {
-			printf("error: lcore %hhu is not enabled in lcore "
-							"mask\n", lcore);
-			return -1;
-		}
-		if ((socketid = rte_lcore_to_socket_id(lcore) != 0) &&
-							(numa_on == 0)) {
-			printf("warning: lcore %hhu is on socket %d with numa "
-						"off\n", lcore, socketid);
-		}
-	}
-	return 0;
-}
-
-static int
-check_port_config(void)
-{
-	unsigned portid;
-	uint16_t i;
-
-	for (i = 0; i < nb_lcore_params; ++i) {
-		portid = lcore_params[i].port_id;
-		if ((enabled_port_mask & (1 << portid)) == 0) {
-			printf("port %u is not enabled in port mask\n",
-								portid);
-			return -1;
-		}
-		if (!rte_eth_dev_is_valid_port(portid)) {
-			printf("port %u is not present on the board\n",
-								portid);
-			return -1;
-		}
-	}
-	return 0;
-}
-
-static uint8_t
-get_port_n_rx_queues(const uint16_t port)
-{
-	int queue = -1;
-	uint16_t i;
-
-	for (i = 0; i < nb_lcore_params; ++i) {
-		if (lcore_params[i].port_id == port &&
-				lcore_params[i].queue_id > queue)
-			queue = lcore_params[i].queue_id;
-	}
-	return (uint8_t)(++queue);
-}
-
-static int
-init_lcore_rx_queues(void)
-{
-	uint16_t i, nb_rx_queue;
-	uint8_t lcore;
-
-	for (i = 0; i < nb_lcore_params; ++i) {
-		lcore = lcore_params[i].lcore_id;
-		nb_rx_queue = lcore_conf[lcore].n_rx_queue;
-		if (nb_rx_queue >= MAX_RX_QUEUE_PER_LCORE) {
-			printf("error: too many queues (%u) for lcore: %u\n",
-				(unsigned)nb_rx_queue + 1, (unsigned)lcore);
-			return -1;
-		} else {
-			lcore_conf[lcore].rx_queue_list[nb_rx_queue].port_id =
-				lcore_params[i].port_id;
-			lcore_conf[lcore].rx_queue_list[nb_rx_queue].queue_id =
-				lcore_params[i].queue_id;
-			lcore_conf[lcore].n_rx_queue++;
-		}
-	}
-	return 0;
-}
-
-/* display usage */
-static void
-print_usage(const char *prgname)
-{
-	printf ("%s [EAL options] -- -p PORTMASK -P"
-		"  [--config (port,queue,lcore)[,(port,queue,lcore]]"
-		"  [--enable-jumbo [--max-pkt-len PKTLEN]]\n"
-		"  -p PORTMASK: hexadecimal bitmask of ports to configure\n"
-		"  -P : enable promiscuous mode\n"
-		"  --config (port,queue,lcore): rx queues configuration\n"
-		"  --no-numa: optional, disable numa awareness\n"
-		"  --enable-jumbo: enable jumbo frame"
-		" which max packet len is PKTLEN in decimal (64-9600)\n"
-		"  --parse-ptype: parse packet type by software\n",
-		prgname);
-}
-
-static int parse_max_pkt_len(const char *pktlen)
-{
-	char *end = NULL;
-	unsigned long len;
-
-	/* parse decimal string */
-	len = strtoul(pktlen, &end, 10);
-	if ((pktlen[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (len == 0)
-		return -1;
-
-	return len;
-}
-
-static int
-parse_portmask(const char *portmask)
-{
-	char *end = NULL;
-	unsigned long pm;
-
-	/* parse hexadecimal string */
-	pm = strtoul(portmask, &end, 16);
-	if ((portmask[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (pm == 0)
-		return -1;
-
-	return pm;
-}
-
-static int
-parse_config(const char *q_arg)
-{
-	char s[256];
-	const char *p, *p0 = q_arg;
-	char *end;
-	enum fieldnames {
-		FLD_PORT = 0,
-		FLD_QUEUE,
-		FLD_LCORE,
-		_NUM_FLD
-	};
-	unsigned long int_fld[_NUM_FLD];
-	char *str_fld[_NUM_FLD];
-	int i;
-	unsigned size;
-
-	nb_lcore_params = 0;
-
-	while ((p = strchr(p0,'(')) != NULL) {
-		++p;
-		if((p0 = strchr(p,')')) == NULL)
-			return -1;
-
-		size = p0 - p;
-		if(size >= sizeof(s))
-			return -1;
-
-		snprintf(s, sizeof(s), "%.*s", size, p);
-		if (rte_strsplit(s, sizeof(s), str_fld, _NUM_FLD, ',') !=
-								_NUM_FLD)
-			return -1;
-		for (i = 0; i < _NUM_FLD; i++){
-			errno = 0;
-			int_fld[i] = strtoul(str_fld[i], &end, 0);
-			if (errno != 0 || end == str_fld[i] || int_fld[i] >
-									255)
-				return -1;
-		}
-		if (nb_lcore_params >= MAX_LCORE_PARAMS) {
-			printf("exceeded max number of lcore params: %hu\n",
-				nb_lcore_params);
-			return -1;
-		}
-		lcore_params_array[nb_lcore_params].port_id =
-				(uint8_t)int_fld[FLD_PORT];
-		lcore_params_array[nb_lcore_params].queue_id =
-				(uint8_t)int_fld[FLD_QUEUE];
-		lcore_params_array[nb_lcore_params].lcore_id =
-				(uint8_t)int_fld[FLD_LCORE];
-		++nb_lcore_params;
-	}
-	lcore_params = lcore_params_array;
-
-	return 0;
-}
-
-#define CMD_LINE_OPT_PARSE_PTYPE "parse-ptype"
-
-/* Parse the argument given in the command line of the application */
-static int
-parse_args(int argc, char **argv)
-{
-	int opt, ret;
-	char **argvopt;
-	int option_index;
-	char *prgname = argv[0];
-	static struct option lgopts[] = {
-		{"config", 1, 0, 0},
-		{"no-numa", 0, 0, 0},
-		{"enable-jumbo", 0, 0, 0},
-		{CMD_LINE_OPT_PARSE_PTYPE, 0, 0, 0},
-		{NULL, 0, 0, 0}
-	};
-
-	argvopt = argv;
-
-	while ((opt = getopt_long(argc, argvopt, "p:P",
-				lgopts, &option_index)) != EOF) {
-
-		switch (opt) {
-		/* portmask */
-		case 'p':
-			enabled_port_mask = parse_portmask(optarg);
-			if (enabled_port_mask == 0) {
-				printf("invalid portmask\n");
-				print_usage(prgname);
-				return -1;
-			}
-			break;
-		case 'P':
-			printf("Promiscuous mode selected\n");
-			promiscuous_on = 1;
-			break;
-
-		/* long options */
-		case 0:
-			if (!strncmp(lgopts[option_index].name, "config", 6)) {
-				ret = parse_config(optarg);
-				if (ret) {
-					printf("invalid config\n");
-					print_usage(prgname);
-					return -1;
-				}
-			}
-
-			if (!strncmp(lgopts[option_index].name,
-						"no-numa", 7)) {
-				printf("numa is disabled \n");
-				numa_on = 0;
-			}
-
-			if (!strncmp(lgopts[option_index].name,
-					"enable-jumbo", 12)) {
-				struct option lenopts =
-					{"max-pkt-len", required_argument, \
-									0, 0};
-
-				printf("jumbo frame is enabled \n");
-				port_conf.rxmode.offloads |=
-						DEV_RX_OFFLOAD_JUMBO_FRAME;
-				port_conf.txmode.offloads |=
-						DEV_TX_OFFLOAD_MULTI_SEGS;
-
-				/**
-				 * if no max-pkt-len set, use the default value
-				 * ETHER_MAX_LEN
-				 */
-				if (0 == getopt_long(argc, argvopt, "",
-						&lenopts, &option_index)) {
-					ret = parse_max_pkt_len(optarg);
-					if ((ret < 64) ||
-						(ret > MAX_JUMBO_PKT_LEN)){
-						printf("invalid packet "
-								"length\n");
-						print_usage(prgname);
-						return -1;
-					}
-					port_conf.rxmode.max_rx_pkt_len = ret;
-				}
-				printf("set jumbo frame "
-					"max packet length to %u\n",
-				(unsigned int)port_conf.rxmode.max_rx_pkt_len);
-			}
-
-			if (!strncmp(lgopts[option_index].name,
-				     CMD_LINE_OPT_PARSE_PTYPE,
-				     sizeof(CMD_LINE_OPT_PARSE_PTYPE))) {
-				printf("soft parse-ptype is enabled\n");
-				parse_ptype = 1;
-			}
-
-			break;
-
-		default:
-			print_usage(prgname);
-			return -1;
-		}
-	}
-
-	if (optind >= 0)
-		argv[optind-1] = prgname;
-
-	ret = optind-1;
-	optind = 1; /* reset getopt lib */
-	return ret;
-}
-
-static void
-print_ethaddr(const char *name, const struct ether_addr *eth_addr)
-{
-	char buf[ETHER_ADDR_FMT_SIZE];
-	ether_format_addr(buf, ETHER_ADDR_FMT_SIZE, eth_addr);
-	printf("%s%s", name, buf);
-}
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_EXACT_MATCH)
-static void
-setup_hash(int socketid)
-{
-	struct rte_hash_parameters ipv4_l3fwd_hash_params = {
-		.name = NULL,
-		.entries = L3FWD_HASH_ENTRIES,
-		.key_len = sizeof(struct ipv4_5tuple),
-		.hash_func = DEFAULT_HASH_FUNC,
-		.hash_func_init_val = 0,
-	};
-
-	struct rte_hash_parameters ipv6_l3fwd_hash_params = {
-		.name = NULL,
-		.entries = L3FWD_HASH_ENTRIES,
-		.key_len = sizeof(struct ipv6_5tuple),
-		.hash_func = DEFAULT_HASH_FUNC,
-		.hash_func_init_val = 0,
-	};
-
-	unsigned i;
-	int ret;
-	char s[64];
-
-	/* create ipv4 hash */
-	snprintf(s, sizeof(s), "ipv4_l3fwd_hash_%d", socketid);
-	ipv4_l3fwd_hash_params.name = s;
-	ipv4_l3fwd_hash_params.socket_id = socketid;
-	ipv4_l3fwd_lookup_struct[socketid] =
-		rte_hash_create(&ipv4_l3fwd_hash_params);
-	if (ipv4_l3fwd_lookup_struct[socketid] == NULL)
-		rte_exit(EXIT_FAILURE, "Unable to create the l3fwd hash on "
-				"socket %d\n", socketid);
-
-	/* create ipv6 hash */
-	snprintf(s, sizeof(s), "ipv6_l3fwd_hash_%d", socketid);
-	ipv6_l3fwd_hash_params.name = s;
-	ipv6_l3fwd_hash_params.socket_id = socketid;
-	ipv6_l3fwd_lookup_struct[socketid] =
-		rte_hash_create(&ipv6_l3fwd_hash_params);
-	if (ipv6_l3fwd_lookup_struct[socketid] == NULL)
-		rte_exit(EXIT_FAILURE, "Unable to create the l3fwd hash on "
-				"socket %d\n", socketid);
-
-
-	/* populate the ipv4 hash */
-	for (i = 0; i < IPV4_L3FWD_NUM_ROUTES; i++) {
-		ret = rte_hash_add_key (ipv4_l3fwd_lookup_struct[socketid],
-				(void *) &ipv4_l3fwd_route_array[i].key);
-		if (ret < 0) {
-			rte_exit(EXIT_FAILURE, "Unable to add entry %u to the"
-				"l3fwd hash on socket %d\n", i, socketid);
-		}
-		ipv4_l3fwd_out_if[ret] = ipv4_l3fwd_route_array[i].if_out;
-		printf("Hash: Adding key\n");
-		print_ipv4_key(ipv4_l3fwd_route_array[i].key);
-	}
-
-	/* populate the ipv6 hash */
-	for (i = 0; i < IPV6_L3FWD_NUM_ROUTES; i++) {
-		ret = rte_hash_add_key (ipv6_l3fwd_lookup_struct[socketid],
-				(void *) &ipv6_l3fwd_route_array[i].key);
-		if (ret < 0) {
-			rte_exit(EXIT_FAILURE, "Unable to add entry %u to the"
-				"l3fwd hash on socket %d\n", i, socketid);
-		}
-		ipv6_l3fwd_out_if[ret] = ipv6_l3fwd_route_array[i].if_out;
-		printf("Hash: Adding key\n");
-		print_ipv6_key(ipv6_l3fwd_route_array[i].key);
-	}
-}
-#endif
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_LPM)
-static void
-setup_lpm(int socketid)
-{
-	unsigned i;
-	int ret;
-	char s[64];
-
-	/* create the LPM table */
-	struct rte_lpm_config lpm_ipv4_config;
-
-	lpm_ipv4_config.max_rules = IPV4_L3FWD_LPM_MAX_RULES;
-	lpm_ipv4_config.number_tbl8s = 256;
-	lpm_ipv4_config.flags = 0;
-
-	snprintf(s, sizeof(s), "IPV4_L3FWD_LPM_%d", socketid);
-	ipv4_l3fwd_lookup_struct[socketid] =
-			rte_lpm_create(s, socketid, &lpm_ipv4_config);
-	if (ipv4_l3fwd_lookup_struct[socketid] == NULL)
-		rte_exit(EXIT_FAILURE, "Unable to create the l3fwd LPM table"
-				" on socket %d\n", socketid);
-
-	/* populate the LPM table */
-	for (i = 0; i < IPV4_L3FWD_NUM_ROUTES; i++) {
-		ret = rte_lpm_add(ipv4_l3fwd_lookup_struct[socketid],
-			ipv4_l3fwd_route_array[i].ip,
-			ipv4_l3fwd_route_array[i].depth,
-			ipv4_l3fwd_route_array[i].if_out);
-
-		if (ret < 0) {
-			rte_exit(EXIT_FAILURE, "Unable to add entry %u to the "
-				"l3fwd LPM table on socket %d\n",
-				i, socketid);
-		}
-
-		printf("LPM: Adding route 0x%08x / %d (%d)\n",
-			(unsigned)ipv4_l3fwd_route_array[i].ip,
-			ipv4_l3fwd_route_array[i].depth,
-			ipv4_l3fwd_route_array[i].if_out);
-	}
-}
-#endif
-
-static int
-init_mem(unsigned nb_mbuf)
-{
-	struct lcore_conf *qconf;
-	int socketid;
-	unsigned lcore_id;
-	char s[64];
-
-	for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-		if (rte_lcore_is_enabled(lcore_id) == 0)
-			continue;
-
-		if (numa_on)
-			socketid = rte_lcore_to_socket_id(lcore_id);
-		else
-			socketid = 0;
-
-		if (socketid >= NB_SOCKETS) {
-			rte_exit(EXIT_FAILURE, "Socket %d of lcore %u is "
-					"out of range %d\n", socketid,
-						lcore_id, NB_SOCKETS);
-		}
-		if (pktmbuf_pool[socketid] == NULL) {
-			snprintf(s, sizeof(s), "mbuf_pool_%d", socketid);
-			pktmbuf_pool[socketid] =
-				rte_pktmbuf_pool_create(s, nb_mbuf,
-					MEMPOOL_CACHE_SIZE, 0,
-					RTE_MBUF_DEFAULT_BUF_SIZE,
-					socketid);
-			if (pktmbuf_pool[socketid] == NULL)
-				rte_exit(EXIT_FAILURE,
-					"Cannot init mbuf pool on socket %d\n",
-								socketid);
-			else
-				printf("Allocated mbuf pool on socket %d\n",
-								socketid);
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_LPM)
-			setup_lpm(socketid);
-#else
-			setup_hash(socketid);
-#endif
-		}
-		qconf = &lcore_conf[lcore_id];
-		qconf->ipv4_lookup_struct = ipv4_l3fwd_lookup_struct[socketid];
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_EXACT_MATCH)
-		qconf->ipv6_lookup_struct = ipv6_l3fwd_lookup_struct[socketid];
-#endif
-	}
-	return 0;
-}
-
-/* Check the link status of all ports in up to 9s, and print them finally */
-static void
-check_all_ports_link_status(uint32_t port_mask)
-{
-#define CHECK_INTERVAL 100 /* 100ms */
-#define MAX_CHECK_TIME 90 /* 9s (90 * 100ms) in total */
-	uint8_t count, all_ports_up, print_flag = 0;
-	uint16_t portid;
-	struct rte_eth_link link;
-
-	printf("\nChecking link status");
-	fflush(stdout);
-	for (count = 0; count <= MAX_CHECK_TIME; count++) {
-		all_ports_up = 1;
-		RTE_ETH_FOREACH_DEV(portid) {
-			if ((port_mask & (1 << portid)) == 0)
-				continue;
-			memset(&link, 0, sizeof(link));
-			rte_eth_link_get_nowait(portid, &link);
-			/* print link status if flag set */
-			if (print_flag == 1) {
-				if (link.link_status)
-					printf("Port %d Link Up - speed %u "
-						"Mbps - %s\n", (uint8_t)portid,
-						(unsigned)link.link_speed,
-				(link.link_duplex == ETH_LINK_FULL_DUPLEX) ?
-					("full-duplex") : ("half-duplex\n"));
-				else
-					printf("Port %d Link Down\n",
-						(uint8_t)portid);
-				continue;
-			}
-			/* clear all_ports_up flag if any link down */
-			if (link.link_status == ETH_LINK_DOWN) {
-				all_ports_up = 0;
-				break;
-			}
-		}
-		/* after finally printing all link status, get out */
-		if (print_flag == 1)
-			break;
-
-		if (all_ports_up == 0) {
-			printf(".");
-			fflush(stdout);
-			rte_delay_ms(CHECK_INTERVAL);
-		}
-
-		/* set the print_flag if all ports up or timeout */
-		if (all_ports_up == 1 || count == (MAX_CHECK_TIME - 1)) {
-			print_flag = 1;
-			printf("done\n");
-		}
-	}
-}
-
-static int check_ptype(uint16_t portid)
-{
-	int i, ret;
-	int ptype_l3_ipv4 = 0;
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_EXACT_MATCH)
-	int ptype_l3_ipv6 = 0;
-#endif
-	uint32_t ptype_mask = RTE_PTYPE_L3_MASK;
-
-	ret = rte_eth_dev_get_supported_ptypes(portid, ptype_mask, NULL, 0);
-	if (ret <= 0)
-		return 0;
-
-	uint32_t ptypes[ret];
-
-	ret = rte_eth_dev_get_supported_ptypes(portid, ptype_mask, ptypes, ret);
-	for (i = 0; i < ret; ++i) {
-		if (ptypes[i] & RTE_PTYPE_L3_IPV4)
-			ptype_l3_ipv4 = 1;
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_EXACT_MATCH)
-		if (ptypes[i] & RTE_PTYPE_L3_IPV6)
-			ptype_l3_ipv6 = 1;
-#endif
-	}
-
-	if (ptype_l3_ipv4 == 0)
-		printf("port %d cannot parse RTE_PTYPE_L3_IPV4\n", portid);
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_EXACT_MATCH)
-	if (ptype_l3_ipv6 == 0)
-		printf("port %d cannot parse RTE_PTYPE_L3_IPV6\n", portid);
-#endif
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_LPM)
-	if (ptype_l3_ipv4)
-#else /* APP_LOOKUP_EXACT_MATCH */
-	if (ptype_l3_ipv4 && ptype_l3_ipv6)
-#endif
-		return 1;
-
-	return 0;
-
-}
-
-int
-main(int argc, char **argv)
-{
-	struct lcore_conf *qconf;
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_txconf *txconf;
-	int ret;
-	uint16_t nb_ports;
-	uint16_t queueid;
-	unsigned lcore_id;
-	uint64_t hz;
-	uint32_t n_tx_queue, nb_lcores;
-	uint32_t dev_rxq_num, dev_txq_num;
-	uint8_t nb_rx_queue, queue, socketid;
-	uint16_t portid;
-
-	/* catch SIGINT and restore cpufreq governor to ondemand */
-	signal(SIGINT, signal_exit_now);
-
-	/* init EAL */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid EAL parameters\n");
-	argc -= ret;
-	argv += ret;
-
-	/* init RTE timer library to be used late */
-	rte_timer_subsystem_init();
-
-	/* parse application arguments (after the EAL ones) */
-	ret = parse_args(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid L3FWD parameters\n");
-
-	if (check_lcore_params() < 0)
-		rte_exit(EXIT_FAILURE, "check_lcore_params failed\n");
-
-	ret = init_lcore_rx_queues();
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "init_lcore_rx_queues failed\n");
-
-	nb_ports = rte_eth_dev_count();
-
-	if (check_port_config() < 0)
-		rte_exit(EXIT_FAILURE, "check_port_config failed\n");
-
-	nb_lcores = rte_lcore_count();
-
-	/* initialize all ports */
-	RTE_ETH_FOREACH_DEV(portid) {
-		struct rte_eth_conf local_port_conf = port_conf;
-
-		/* skip ports that are not enabled */
-		if ((enabled_port_mask & (1 << portid)) == 0) {
-			printf("\nSkipping disabled port %d\n", portid);
-			continue;
-		}
-
-		/* init port */
-		printf("Initializing port %d ... ", portid );
-		fflush(stdout);
-
-		rte_eth_dev_info_get(portid, &dev_info);
-		dev_rxq_num = dev_info.max_rx_queues;
-		dev_txq_num = dev_info.max_tx_queues;
-
-		nb_rx_queue = get_port_n_rx_queues(portid);
-		if (nb_rx_queue > dev_rxq_num)
-			rte_exit(EXIT_FAILURE,
-				"Cannot configure not existed rxq: "
-				"port=%d\n", portid);
-
-		n_tx_queue = nb_lcores;
-		if (n_tx_queue > dev_txq_num)
-			n_tx_queue = dev_txq_num;
-		printf("Creating queues: nb_rxq=%d nb_txq=%u... ",
-			nb_rx_queue, (unsigned)n_tx_queue );
-		/* If number of Rx queue is 0, no need to enable Rx interrupt */
-		if (nb_rx_queue == 0)
-			local_port_conf.intr_conf.rxq = 0;
-		rte_eth_dev_info_get(portid, &dev_info);
-		if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-			local_port_conf.txmode.offloads |=
-				DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-		ret = rte_eth_dev_configure(portid, nb_rx_queue,
-					(uint16_t)n_tx_queue, &local_port_conf);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "Cannot configure device: "
-					"err=%d, port=%d\n", ret, portid);
-
-		ret = rte_eth_dev_adjust_nb_rx_tx_desc(portid, &nb_rxd,
-						       &nb_txd);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-				 "Cannot adjust number of descriptors: err=%d, port=%d\n",
-				 ret, portid);
-
-		rte_eth_macaddr_get(portid, &ports_eth_addr[portid]);
-		print_ethaddr(" Address:", &ports_eth_addr[portid]);
-		printf(", ");
-
-		/* init memory */
-		ret = init_mem(NB_MBUF);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "init_mem failed\n");
-
-		for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-			if (rte_lcore_is_enabled(lcore_id) == 0)
-				continue;
-
-			/* Initialize TX buffers */
-			qconf = &lcore_conf[lcore_id];
-			qconf->tx_buffer[portid] = rte_zmalloc_socket("tx_buffer",
-				RTE_ETH_TX_BUFFER_SIZE(MAX_PKT_BURST), 0,
-				rte_eth_dev_socket_id(portid));
-			if (qconf->tx_buffer[portid] == NULL)
-				rte_exit(EXIT_FAILURE, "Can't allocate tx buffer for port %u\n",
-						 portid);
-
-			rte_eth_tx_buffer_init(qconf->tx_buffer[portid], MAX_PKT_BURST);
-		}
-
-		/* init one TX queue per couple (lcore,port) */
-		queueid = 0;
-		for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-			if (rte_lcore_is_enabled(lcore_id) == 0)
-				continue;
-
-			if (queueid >= dev_txq_num)
-				continue;
-
-			if (numa_on)
-				socketid = \
-				(uint8_t)rte_lcore_to_socket_id(lcore_id);
-			else
-				socketid = 0;
-
-			printf("txq=%u,%d,%d ", lcore_id, queueid, socketid);
-			fflush(stdout);
-
-			txconf = &dev_info.default_txconf;
-			txconf->txq_flags = ETH_TXQ_FLAGS_IGNORE;
-			txconf->offloads = local_port_conf.txmode.offloads;
-			ret = rte_eth_tx_queue_setup(portid, queueid, nb_txd,
-						     socketid, txconf);
-			if (ret < 0)
-				rte_exit(EXIT_FAILURE,
-					"rte_eth_tx_queue_setup: err=%d, "
-						"port=%d\n", ret, portid);
-
-			qconf = &lcore_conf[lcore_id];
-			qconf->tx_queue_id[portid] = queueid;
-			queueid++;
-
-			qconf->tx_port_id[qconf->n_tx_port] = portid;
-			qconf->n_tx_port++;
-		}
-		printf("\n");
-	}
-
-	for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-		if (rte_lcore_is_enabled(lcore_id) == 0)
-			continue;
-
-		/* init power management library */
-		ret = rte_power_init(lcore_id);
-		if (ret)
-			RTE_LOG(ERR, POWER,
-				"Library initialization failed on core %u\n", lcore_id);
-
-		/* init timer structures for each enabled lcore */
-		rte_timer_init(&power_timers[lcore_id]);
-		hz = rte_get_timer_hz();
-		rte_timer_reset(&power_timers[lcore_id],
-			hz/TIMER_NUMBER_PER_SECOND, SINGLE, lcore_id,
-						power_timer_cb, NULL);
-
-		qconf = &lcore_conf[lcore_id];
-		printf("\nInitializing rx queues on lcore %u ... ", lcore_id );
-		fflush(stdout);
-		/* init RX queues */
-		for(queue = 0; queue < qconf->n_rx_queue; ++queue) {
-			struct rte_eth_rxconf rxq_conf;
-			struct rte_eth_dev *dev;
-			struct rte_eth_conf *conf;
-
-			portid = qconf->rx_queue_list[queue].port_id;
-			queueid = qconf->rx_queue_list[queue].queue_id;
-			dev = &rte_eth_devices[portid];
-			conf = &dev->data->dev_conf;
-
-			if (numa_on)
-				socketid = \
-				(uint8_t)rte_lcore_to_socket_id(lcore_id);
-			else
-				socketid = 0;
-
-			printf("rxq=%d,%d,%d ", portid, queueid, socketid);
-			fflush(stdout);
-
-			rte_eth_dev_info_get(portid, &dev_info);
-			rxq_conf = dev_info.default_rxconf;
-			rxq_conf.offloads = conf->rxmode.offloads;
-			ret = rte_eth_rx_queue_setup(portid, queueid, nb_rxd,
-				socketid, &rxq_conf,
-				pktmbuf_pool[socketid]);
-			if (ret < 0)
-				rte_exit(EXIT_FAILURE,
-					"rte_eth_rx_queue_setup: err=%d, "
-						"port=%d\n", ret, portid);
-
-			if (parse_ptype) {
-				if (add_cb_parse_ptype(portid, queueid) < 0)
-					rte_exit(EXIT_FAILURE,
-						 "Fail to add ptype cb\n");
-			} else if (!check_ptype(portid))
-				rte_exit(EXIT_FAILURE,
-					 "PMD can not provide needed ptypes\n");
-		}
-	}
-
-	printf("\n");
-
-	/* start ports */
-	RTE_ETH_FOREACH_DEV(portid) {
-		if ((enabled_port_mask & (1 << portid)) == 0) {
-			continue;
-		}
-		/* Start device */
-		ret = rte_eth_dev_start(portid);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "rte_eth_dev_start: err=%d, "
-						"port=%d\n", ret, portid);
-		/*
-		 * If enabled, put device in promiscuous mode.
-		 * This allows IO forwarding mode to forward packets
-		 * to itself through 2 cross-connected  ports of the
-		 * target machine.
-		 */
-		if (promiscuous_on)
-			rte_eth_promiscuous_enable(portid);
-		/* initialize spinlock for each port */
-		rte_spinlock_init(&(locks[portid]));
-	}
-
-	check_all_ports_link_status(enabled_port_mask);
-
-	/* launch per-lcore init on every lcore */
-	rte_eal_mp_remote_launch(main_loop, NULL, CALL_MASTER);
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		if (rte_eal_wait_lcore(lcore_id) < 0)
-			return -1;
-	}
-
-	return 0;
-}
diff --git a/examples/l3fwd-power/meson.build b/examples/l3fwd-power/meson.build
deleted file mode 100644
index cb50c7a..0000000
--- a/examples/l3fwd-power/meson.build
+++ /dev/null
@@ -1,13 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-deps += ['power', 'timer', 'lpm', 'hash']
-allow_experimental_apis = true
-sources = files(
-	'main.c'
-)
diff --git a/examples/l3fwd-vf/Makefile b/examples/l3fwd-vf/Makefile
deleted file mode 100644
index d776689..0000000
--- a/examples/l3fwd-vf/Makefile
+++ /dev/null
@@ -1,64 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-# binary name
-APP = l3fwd-vf
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else # Build using legacy build system
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -O3 $(USER_FLAGS)
-CFLAGS += $(WERROR_FLAGS)
-
-# workaround for a gcc bug with noreturn attribute
-# http://gcc.gnu.org/bugzilla/show_bug.cgi?id=12603
-ifeq ($(CONFIG_RTE_TOOLCHAIN_GCC),y)
-CFLAGS_main.o += -Wno-return-type
-endif
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-endif
diff --git a/examples/l3fwd-vf/main.c b/examples/l3fwd-vf/main.c
deleted file mode 100644
index dd0e057..0000000
--- a/examples/l3fwd-vf/main.c
+++ /dev/null
@@ -1,1087 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <sys/types.h>
-#include <string.h>
-#include <sys/queue.h>
-#include <stdarg.h>
-#include <errno.h>
-#include <getopt.h>
-#include <signal.h>
-
-#include <rte_common.h>
-#include <rte_byteorder.h>
-#include <rte_log.h>
-#include <rte_memory.h>
-#include <rte_memcpy.h>
-#include <rte_eal.h>
-#include <rte_launch.h>
-#include <rte_atomic.h>
-#include <rte_spinlock.h>
-#include <rte_cycles.h>
-#include <rte_prefetch.h>
-#include <rte_lcore.h>
-#include <rte_per_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_interrupts.h>
-#include <rte_random.h>
-#include <rte_debug.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-#include <rte_ip.h>
-#include <rte_tcp.h>
-#include <rte_udp.h>
-#include <rte_string_fns.h>
-
-#define APP_LOOKUP_EXACT_MATCH          0
-#define APP_LOOKUP_LPM                  1
-#define DO_RFC_1812_CHECKS
-
-//#define APP_LOOKUP_METHOD             APP_LOOKUP_EXACT_MATCH
-#ifndef APP_LOOKUP_METHOD
-#define APP_LOOKUP_METHOD             APP_LOOKUP_LPM
-#endif
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_EXACT_MATCH)
-#include <rte_hash.h>
-#elif (APP_LOOKUP_METHOD == APP_LOOKUP_LPM)
-#include <rte_lpm.h>
-#else
-#error "APP_LOOKUP_METHOD set to incorrect value"
-#endif
-
-#define RTE_LOGTYPE_L3FWD RTE_LOGTYPE_USER1
-
-#define MEMPOOL_CACHE_SIZE 256
-
-/*
- * This expression is used to calculate the number of mbufs needed depending on user input, taking
- *  into account memory for rx and tx hardware rings, cache per lcore and mtable per port per lcore.
- *  RTE_MAX is used to ensure that NB_MBUF never goes below a minimum value of 8192
- */
-
-#define NB_MBUF RTE_MAX	(						\
-				(nb_ports*nb_rx_queue*nb_rxd +		\
-				nb_ports*nb_lcores*MAX_PKT_BURST +	\
-				nb_ports*n_tx_queue*nb_txd +		\
-				nb_lcores*MEMPOOL_CACHE_SIZE),		\
-				(unsigned)8192)
-
-/*
- * RX and TX Prefetch, Host, and Write-back threshold values should be
- * carefully set for optimal performance. Consult the network
- * controller's datasheet and supporting DPDK documentation for guidance
- * on how these parameters should be set.
- */
-#define RX_PTHRESH 8 /**< Default values of RX prefetch threshold reg. */
-#define RX_HTHRESH 8 /**< Default values of RX host threshold reg. */
-#define RX_WTHRESH 4 /**< Default values of RX write-back threshold reg. */
-
-/*
- * These default values are optimized for use with the Intel(R) 82599 10 GbE
- * Controller and the DPDK ixgbe PMD. Consider using other values for other
- * network controllers and/or network drivers.
- */
-#define TX_PTHRESH 36 /**< Default values of TX prefetch threshold reg. */
-#define TX_HTHRESH 0  /**< Default values of TX host threshold reg. */
-#define TX_WTHRESH 0  /**< Default values of TX write-back threshold reg. */
-
-#define MAX_PKT_BURST 32
-#define BURST_TX_DRAIN_US 100 /* TX drain every ~100us */
-
-#define NB_SOCKETS 8
-
-#define SOCKET0 0
-
-/* Configure how many packets ahead to prefetch, when reading packets */
-#define PREFETCH_OFFSET	3
-
-/*
- * Configurable number of RX/TX ring descriptors
- */
-#define RTE_TEST_RX_DESC_DEFAULT 1024
-#define RTE_TEST_TX_DESC_DEFAULT 1024
-static uint16_t nb_rxd = RTE_TEST_RX_DESC_DEFAULT;
-static uint16_t nb_txd = RTE_TEST_TX_DESC_DEFAULT;
-
-/* ethernet addresses of ports */
-static struct ether_addr ports_eth_addr[RTE_MAX_ETHPORTS];
-
-/* mask of enabled ports */
-static uint32_t enabled_port_mask = 0;
-static int numa_on = 1; /**< NUMA is enabled by default. */
-
-struct mbuf_table {
-	uint16_t len;
-	struct rte_mbuf *m_table[MAX_PKT_BURST];
-};
-
-struct lcore_rx_queue {
-	uint16_t port_id;
-	uint8_t queue_id;
-} __rte_cache_aligned;
-
-#define MAX_RX_QUEUE_PER_LCORE 16
-#define MAX_TX_QUEUE_PER_PORT 1
-#define MAX_RX_QUEUE_PER_PORT 1
-
-#define MAX_LCORE_PARAMS 1024
-struct lcore_params {
-	uint16_t port_id;
-	uint8_t queue_id;
-	uint8_t lcore_id;
-} __rte_cache_aligned;
-
-static struct lcore_params lcore_params_array[MAX_LCORE_PARAMS];
-static struct lcore_params lcore_params_array_default[] = {
-	{0, 0, 2},
-	{0, 1, 2},
-	{0, 2, 2},
-	{1, 0, 2},
-	{1, 1, 2},
-	{1, 2, 2},
-	{2, 0, 2},
-	{3, 0, 3},
-	{3, 1, 3},
-};
-
-static struct lcore_params * lcore_params = lcore_params_array_default;
-static uint16_t nb_lcore_params = sizeof(lcore_params_array_default) /
-				sizeof(lcore_params_array_default[0]);
-
-static struct rte_eth_conf port_conf = {
-	.rxmode = {
-		.mq_mode	= ETH_MQ_RX_RSS,
-		.max_rx_pkt_len = ETHER_MAX_LEN,
-		.split_hdr_size = 0,
-		.ignore_offload_bitfield = 1,
-		.offloads = (DEV_RX_OFFLOAD_CRC_STRIP |
-			     DEV_RX_OFFLOAD_CHECKSUM),
-	},
-	.rx_adv_conf = {
-		.rss_conf = {
-			.rss_key = NULL,
-			.rss_hf = ETH_RSS_IP,
-		},
-	},
-	.txmode = {
-		.mq_mode = ETH_MQ_TX_NONE,
-	},
-};
-
-static struct rte_mempool * pktmbuf_pool[NB_SOCKETS];
-
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_EXACT_MATCH)
-
-#ifdef RTE_ARCH_X86
-#include <rte_hash_crc.h>
-#define DEFAULT_HASH_FUNC       rte_hash_crc
-#else
-#include <rte_jhash.h>
-#define DEFAULT_HASH_FUNC       rte_jhash
-#endif
-
-struct ipv4_5tuple {
-	uint32_t ip_dst;
-	uint32_t ip_src;
-	uint16_t port_dst;
-	uint16_t port_src;
-	uint8_t proto;
-} __attribute__((__packed__));
-
-struct l3fwd_route {
-	struct ipv4_5tuple key;
-	uint8_t if_out;
-};
-
-static struct l3fwd_route l3fwd_route_array[] = {
-	{{IPv4(100,10,0,1), IPv4(200,10,0,1), 101, 11, IPPROTO_TCP}, 0},
-	{{IPv4(100,20,0,2), IPv4(200,20,0,2), 102, 12, IPPROTO_TCP}, 1},
-	{{IPv4(100,30,0,3), IPv4(200,30,0,3), 103, 13, IPPROTO_TCP}, 2},
-	{{IPv4(100,40,0,4), IPv4(200,40,0,4), 104, 14, IPPROTO_TCP}, 3},
-};
-
-typedef struct rte_hash lookup_struct_t;
-static lookup_struct_t *l3fwd_lookup_struct[NB_SOCKETS];
-
-#define L3FWD_HASH_ENTRIES	1024
-struct rte_hash_parameters l3fwd_hash_params = {
-	.name = "l3fwd_hash_0",
-	.entries = L3FWD_HASH_ENTRIES,
-	.key_len = sizeof(struct ipv4_5tuple),
-	.hash_func = DEFAULT_HASH_FUNC,
-	.hash_func_init_val = 0,
-	.socket_id = SOCKET0,
-};
-
-#define L3FWD_NUM_ROUTES \
-	(sizeof(l3fwd_route_array) / sizeof(l3fwd_route_array[0]))
-
-static uint8_t l3fwd_out_if[L3FWD_HASH_ENTRIES] __rte_cache_aligned;
-#endif
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_LPM)
-struct l3fwd_route {
-	uint32_t ip;
-	uint8_t  depth;
-	uint8_t  if_out;
-};
-
-static struct l3fwd_route l3fwd_route_array[] = {
-	{IPv4(1,1,1,0), 24, 0},
-	{IPv4(2,1,1,0), 24, 1},
-	{IPv4(3,1,1,0), 24, 2},
-	{IPv4(4,1,1,0), 24, 3},
-	{IPv4(5,1,1,0), 24, 4},
-	{IPv4(6,1,1,0), 24, 5},
-	{IPv4(7,1,1,0), 24, 6},
-	{IPv4(8,1,1,0), 24, 7},
-};
-
-#define L3FWD_NUM_ROUTES \
-	(sizeof(l3fwd_route_array) / sizeof(l3fwd_route_array[0]))
-
-#define L3FWD_LPM_MAX_RULES     1024
-
-typedef struct rte_lpm lookup_struct_t;
-static lookup_struct_t *l3fwd_lookup_struct[NB_SOCKETS];
-#endif
-
-struct lcore_conf {
-	uint16_t n_rx_queue;
-	struct lcore_rx_queue rx_queue_list[MAX_RX_QUEUE_PER_LCORE];
-	uint16_t tx_queue_id;
-	struct mbuf_table tx_mbufs[RTE_MAX_ETHPORTS];
-	lookup_struct_t * lookup_struct;
-} __rte_cache_aligned;
-
-static struct lcore_conf lcore_conf[RTE_MAX_LCORE];
-static rte_spinlock_t spinlock_conf[RTE_MAX_ETHPORTS] = {RTE_SPINLOCK_INITIALIZER};
-/* Send burst of packets on an output interface */
-static inline int
-send_burst(struct lcore_conf *qconf, uint16_t n, uint16_t port)
-{
-	struct rte_mbuf **m_table;
-	int ret;
-	uint16_t queueid;
-
-	queueid = qconf->tx_queue_id;
-	m_table = (struct rte_mbuf **)qconf->tx_mbufs[port].m_table;
-
-	rte_spinlock_lock(&spinlock_conf[port]);
-	ret = rte_eth_tx_burst(port, queueid, m_table, n);
-	rte_spinlock_unlock(&spinlock_conf[port]);
-
-	if (unlikely(ret < n)) {
-		do {
-			rte_pktmbuf_free(m_table[ret]);
-		} while (++ret < n);
-	}
-
-	return 0;
-}
-
-/* Enqueue a single packet, and send burst if queue is filled */
-static inline int
-send_single_packet(struct rte_mbuf *m, uint16_t port)
-{
-	uint32_t lcore_id;
-	uint16_t len;
-	struct lcore_conf *qconf;
-
-	lcore_id = rte_lcore_id();
-
-	qconf = &lcore_conf[lcore_id];
-	len = qconf->tx_mbufs[port].len;
-	qconf->tx_mbufs[port].m_table[len] = m;
-	len++;
-
-	/* enough pkts to be sent */
-	if (unlikely(len == MAX_PKT_BURST)) {
-		send_burst(qconf, MAX_PKT_BURST, port);
-		len = 0;
-	}
-
-	qconf->tx_mbufs[port].len = len;
-	return 0;
-}
-
-#ifdef DO_RFC_1812_CHECKS
-static inline int
-is_valid_ipv4_pkt(struct ipv4_hdr *pkt, uint32_t link_len)
-{
-	/* From http://www.rfc-editor.org/rfc/rfc1812.txt section 5.2.2 */
-	/*
-	 * 1. The packet length reported by the Link Layer must be large
-	 * enough to hold the minimum length legal IP datagram (20 bytes).
-	 */
-	if (link_len < sizeof(struct ipv4_hdr))
-		return -1;
-
-	/* 2. The IP checksum must be correct. */
-	/* this is checked in H/W */
-
-	/*
-	 * 3. The IP version number must be 4. If the version number is not 4
-	 * then the packet may be another version of IP, such as IPng or
-	 * ST-II.
-	 */
-	if (((pkt->version_ihl) >> 4) != 4)
-		return -3;
-	/*
-	 * 4. The IP header length field must be large enough to hold the
-	 * minimum length legal IP datagram (20 bytes = 5 words).
-	 */
-	if ((pkt->version_ihl & 0xf) < 5)
-		return -4;
-
-	/*
-	 * 5. The IP total length field must be large enough to hold the IP
-	 * datagram header, whose length is specified in the IP header length
-	 * field.
-	 */
-	if (rte_cpu_to_be_16(pkt->total_length) < sizeof(struct ipv4_hdr))
-		return -5;
-
-	return 0;
-}
-#endif
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_EXACT_MATCH)
-static void
-print_key(struct ipv4_5tuple key)
-{
-	printf("IP dst = %08x, IP src = %08x, port dst = %d, port src = %d, proto = %d\n",
-	       (unsigned)key.ip_dst, (unsigned)key.ip_src, key.port_dst, key.port_src, key.proto);
-}
-
-static inline uint16_t
-get_dst_port(struct ipv4_hdr *ipv4_hdr, uint16_t portid,
-	      lookup_struct_t *l3fwd_lookup_struct)
-{
-	struct ipv4_5tuple key;
-	struct tcp_hdr *tcp;
-	struct udp_hdr *udp;
-	int ret = 0;
-
-	key.ip_dst = rte_be_to_cpu_32(ipv4_hdr->dst_addr);
-	key.ip_src = rte_be_to_cpu_32(ipv4_hdr->src_addr);
-	key.proto = ipv4_hdr->next_proto_id;
-
-	switch (ipv4_hdr->next_proto_id) {
-	case IPPROTO_TCP:
-		tcp = (struct tcp_hdr *)((unsigned char *) ipv4_hdr +
-					sizeof(struct ipv4_hdr));
-		key.port_dst = rte_be_to_cpu_16(tcp->dst_port);
-		key.port_src = rte_be_to_cpu_16(tcp->src_port);
-		break;
-
-	case IPPROTO_UDP:
-		udp = (struct udp_hdr *)((unsigned char *) ipv4_hdr +
-					sizeof(struct ipv4_hdr));
-		key.port_dst = rte_be_to_cpu_16(udp->dst_port);
-		key.port_src = rte_be_to_cpu_16(udp->src_port);
-		break;
-
-	default:
-		key.port_dst = 0;
-		key.port_src = 0;
-	}
-
-	/* Find destination port */
-	ret = rte_hash_lookup(l3fwd_lookup_struct, (const void *)&key);
-	return ((ret < 0) ? portid : l3fwd_out_if[ret]);
-}
-#endif
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_LPM)
-static inline uint32_t
-get_dst_port(struct ipv4_hdr *ipv4_hdr, uint16_t portid,
-	      lookup_struct_t *l3fwd_lookup_struct)
-{
-	uint32_t next_hop;
-
-	return ((rte_lpm_lookup(l3fwd_lookup_struct,
-		rte_be_to_cpu_32(ipv4_hdr->dst_addr), &next_hop) == 0) ?
-		next_hop : portid);
-}
-#endif
-
-static inline void
-l3fwd_simple_forward(struct rte_mbuf *m, uint16_t portid,
-		      lookup_struct_t *l3fwd_lookup_struct)
-{
-	struct ether_hdr *eth_hdr;
-	struct ipv4_hdr *ipv4_hdr;
-	void *tmp;
-	uint16_t dst_port;
-
-	eth_hdr = rte_pktmbuf_mtod(m, struct ether_hdr *);
-
-	ipv4_hdr = rte_pktmbuf_mtod_offset(m, struct ipv4_hdr *,
-					   sizeof(struct ether_hdr));
-
-#ifdef DO_RFC_1812_CHECKS
-	/* Check to make sure the packet is valid (RFC1812) */
-	if (is_valid_ipv4_pkt(ipv4_hdr, m->pkt_len) < 0) {
-		rte_pktmbuf_free(m);
-		return;
-	}
-#endif
-
-	dst_port = get_dst_port(ipv4_hdr, portid, l3fwd_lookup_struct);
-	if (dst_port >= RTE_MAX_ETHPORTS || (enabled_port_mask & 1 << dst_port) == 0)
-		dst_port = portid;
-
-	/* 02:00:00:00:00:xx */
-	tmp = &eth_hdr->d_addr.addr_bytes[0];
-	*((uint64_t *)tmp) = 0x000000000002 + ((uint64_t)dst_port << 40);
-
-#ifdef DO_RFC_1812_CHECKS
-	/* Update time to live and header checksum */
-	--(ipv4_hdr->time_to_live);
-	++(ipv4_hdr->hdr_checksum);
-#endif
-
-	/* src addr */
-	ether_addr_copy(&ports_eth_addr[dst_port], &eth_hdr->s_addr);
-
-	send_single_packet(m, dst_port);
-
-}
-
-/* main processing loop */
-static int
-main_loop(__attribute__((unused)) void *dummy)
-{
-	struct rte_mbuf *pkts_burst[MAX_PKT_BURST];
-	unsigned lcore_id;
-	uint64_t prev_tsc, diff_tsc, cur_tsc;
-	int i, j, nb_rx;
-	uint8_t queueid;
-	uint16_t portid;
-	struct lcore_conf *qconf;
-	const uint64_t drain_tsc = (rte_get_tsc_hz() + US_PER_S - 1) / US_PER_S * BURST_TX_DRAIN_US;
-
-	prev_tsc = 0;
-
-	lcore_id = rte_lcore_id();
-	qconf = &lcore_conf[lcore_id];
-
-	if (qconf->n_rx_queue == 0) {
-		RTE_LOG(INFO, L3FWD, "lcore %u has nothing to do\n", lcore_id);
-		return 0;
-	}
-
-	RTE_LOG(INFO, L3FWD, "entering main loop on lcore %u\n", lcore_id);
-
-	for (i = 0; i < qconf->n_rx_queue; i++) {
-
-		portid = qconf->rx_queue_list[i].port_id;
-		queueid = qconf->rx_queue_list[i].queue_id;
-		RTE_LOG(INFO, L3FWD, " --lcoreid=%u portid=%u rxqueueid=%hhu\n",
-		lcore_id, portid, queueid);
-	}
-
-	while (1) {
-
-		cur_tsc = rte_rdtsc();
-
-		/*
-		 * TX burst queue drain
-		 */
-		diff_tsc = cur_tsc - prev_tsc;
-		if (unlikely(diff_tsc > drain_tsc)) {
-
-			/*
-			 * This could be optimized (use queueid instead of
-			 * portid), but it is not called so often
-			 */
-			for (portid = 0; portid < RTE_MAX_ETHPORTS; portid++) {
-				if (qconf->tx_mbufs[portid].len == 0)
-					continue;
-				send_burst(&lcore_conf[lcore_id],
-					qconf->tx_mbufs[portid].len,
-					portid);
-				qconf->tx_mbufs[portid].len = 0;
-			}
-
-			prev_tsc = cur_tsc;
-		}
-
-		/*
-		 * Read packet from RX queues
-		 */
-		for (i = 0; i < qconf->n_rx_queue; ++i) {
-
-			portid = qconf->rx_queue_list[i].port_id;
-			queueid = qconf->rx_queue_list[i].queue_id;
-			nb_rx = rte_eth_rx_burst(portid, queueid, pkts_burst, MAX_PKT_BURST);
-
-			/* Prefetch first packets */
-			for (j = 0; j < PREFETCH_OFFSET && j < nb_rx; j++) {
-				rte_prefetch0(rte_pktmbuf_mtod(
-						pkts_burst[j], void *));
-			}
-
-			/* Prefetch and forward already prefetched packets */
-			for (j = 0; j < (nb_rx - PREFETCH_OFFSET); j++) {
-				rte_prefetch0(rte_pktmbuf_mtod(pkts_burst[
-						j + PREFETCH_OFFSET], void *));
-				l3fwd_simple_forward(pkts_burst[j], portid, qconf->lookup_struct);
-			}
-
-			/* Forward remaining prefetched packets */
-			for (; j < nb_rx; j++) {
-				l3fwd_simple_forward(pkts_burst[j], portid, qconf->lookup_struct);
-			}
-		}
-	}
-}
-
-static int
-check_lcore_params(void)
-{
-	uint8_t queue, lcore;
-	uint16_t i;
-	int socketid;
-
-	for (i = 0; i < nb_lcore_params; ++i) {
-		queue = lcore_params[i].queue_id;
-		if (queue >= MAX_RX_QUEUE_PER_PORT) {
-			printf("invalid queue number: %hhu\n", queue);
-			return -1;
-		}
-		lcore = lcore_params[i].lcore_id;
-		if (!rte_lcore_is_enabled(lcore)) {
-			printf("error: lcore %hhu is not enabled in lcore mask\n", lcore);
-			return -1;
-		}
-		if ((socketid = rte_lcore_to_socket_id(lcore) != 0) &&
-			(numa_on == 0)) {
-			printf("warning: lcore %hhu is on socket %d with numa off \n",
-				lcore, socketid);
-		}
-	}
-	return 0;
-}
-
-static int
-check_port_config(void)
-{
-	unsigned portid;
-	uint16_t i;
-
-	for (i = 0; i < nb_lcore_params; ++i) {
-		portid = lcore_params[i].port_id;
-		if ((enabled_port_mask & (1 << portid)) == 0) {
-			printf("port %u is not enabled in port mask\n", portid);
-			return -1;
-		}
-		if (!rte_eth_dev_is_valid_port(portid)) {
-			printf("port %u is not present on the board\n", portid);
-			return -1;
-		}
-	}
-	return 0;
-}
-
-static uint8_t
-get_port_n_rx_queues(const uint16_t port)
-{
-	int queue = -1;
-	uint16_t i;
-
-	for (i = 0; i < nb_lcore_params; ++i) {
-		if (lcore_params[i].port_id == port && lcore_params[i].queue_id > queue)
-			queue = lcore_params[i].queue_id;
-	}
-	return (uint8_t)(++queue);
-}
-
-static int
-init_lcore_rx_queues(void)
-{
-	uint16_t i, nb_rx_queue;
-	uint8_t lcore;
-
-	for (i = 0; i < nb_lcore_params; ++i) {
-		lcore = lcore_params[i].lcore_id;
-		nb_rx_queue = lcore_conf[lcore].n_rx_queue;
-		if (nb_rx_queue >= MAX_RX_QUEUE_PER_LCORE) {
-			printf("error: too many queues (%u) for lcore: %u\n",
-				(unsigned)nb_rx_queue + 1, (unsigned)lcore);
-			return -1;
-		} else {
-			lcore_conf[lcore].rx_queue_list[nb_rx_queue].port_id =
-				lcore_params[i].port_id;
-			lcore_conf[lcore].rx_queue_list[nb_rx_queue].queue_id =
-				lcore_params[i].queue_id;
-			lcore_conf[lcore].n_rx_queue++;
-		}
-	}
-	return 0;
-}
-
-/* display usage */
-static void
-print_usage(const char *prgname)
-{
-	printf ("%s [EAL options] -- -p PORTMASK"
-		"  [--config (port,queue,lcore)[,(port,queue,lcore]]\n"
-		"  -p PORTMASK: hexadecimal bitmask of ports to configure\n"
-		"  --config (port,queue,lcore): rx queues configuration\n"
-		"  --no-numa: optional, disable numa awareness\n",
-		prgname);
-}
-
-/* Custom handling of signals to handle process terminal */
-static void
-signal_handler(int signum)
-{
-	uint16_t portid;
-
-	/* When we receive a SIGINT signal */
-	if (signum == SIGINT) {
-		RTE_ETH_FOREACH_DEV(portid) {
-			/* skip ports that are not enabled */
-			if ((enabled_port_mask & (1 << portid)) == 0)
-				continue;
-			rte_eth_dev_close(portid);
-		}
-	}
-	rte_exit(EXIT_SUCCESS, "\n User forced exit\n");
-}
-static int
-parse_portmask(const char *portmask)
-{
-	char *end = NULL;
-	unsigned long pm;
-
-	/* parse hexadecimal string */
-	pm = strtoul(portmask, &end, 16);
-	if ((portmask[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (pm == 0)
-		return -1;
-
-	return pm;
-}
-
-static int
-parse_config(const char *q_arg)
-{
-	char s[256];
-	const char *p, *p0 = q_arg;
-	char *end;
-	enum fieldnames {
-		FLD_PORT = 0,
-		FLD_QUEUE,
-		FLD_LCORE,
-		_NUM_FLD
-	};
-	unsigned long int_fld[_NUM_FLD];
-	char *str_fld[_NUM_FLD];
-	int i;
-	unsigned size;
-
-	nb_lcore_params = 0;
-
-	while ((p = strchr(p0,'(')) != NULL) {
-		++p;
-		if((p0 = strchr(p,')')) == NULL)
-			return -1;
-
-		size = p0 - p;
-		if(size >= sizeof(s))
-			return -1;
-
-		snprintf(s, sizeof(s), "%.*s", size, p);
-		if (rte_strsplit(s, sizeof(s), str_fld, _NUM_FLD, ',') != _NUM_FLD)
-			return -1;
-		for (i = 0; i < _NUM_FLD; i++){
-			errno = 0;
-			int_fld[i] = strtoul(str_fld[i], &end, 0);
-			if (errno != 0 || end == str_fld[i] || int_fld[i] > 255)
-				return -1;
-		}
-		if (nb_lcore_params >= MAX_LCORE_PARAMS) {
-			printf("exceeded max number of lcore params: %hu\n",
-				nb_lcore_params);
-			return -1;
-		}
-		lcore_params_array[nb_lcore_params].port_id = int_fld[FLD_PORT];
-		lcore_params_array[nb_lcore_params].queue_id = (uint8_t)int_fld[FLD_QUEUE];
-		lcore_params_array[nb_lcore_params].lcore_id = (uint8_t)int_fld[FLD_LCORE];
-		++nb_lcore_params;
-	}
-	lcore_params = lcore_params_array;
-	return 0;
-}
-
-/* Parse the argument given in the command line of the application */
-static int
-parse_args(int argc, char **argv)
-{
-	int opt, ret;
-	char **argvopt;
-	int option_index;
-	char *prgname = argv[0];
-	static struct option lgopts[] = {
-		{"config", 1, 0, 0},
-		{"no-numa", 0, 0, 0},
-		{NULL, 0, 0, 0}
-	};
-
-	argvopt = argv;
-
-	while ((opt = getopt_long(argc, argvopt, "p:",
-				lgopts, &option_index)) != EOF) {
-
-		switch (opt) {
-		/* portmask */
-		case 'p':
-			enabled_port_mask = parse_portmask(optarg);
-			if (enabled_port_mask == 0) {
-				printf("invalid portmask\n");
-				print_usage(prgname);
-				return -1;
-			}
-			break;
-
-		/* long options */
-		case 0:
-			if (!strcmp(lgopts[option_index].name, "config")) {
-				ret = parse_config(optarg);
-				if (ret) {
-					printf("invalid config\n");
-					print_usage(prgname);
-					return -1;
-				}
-			}
-
-			if (!strcmp(lgopts[option_index].name, "no-numa")) {
-				printf("numa is disabled \n");
-				numa_on = 0;
-			}
-			break;
-
-		default:
-			print_usage(prgname);
-			return -1;
-		}
-	}
-
-	if (optind >= 0)
-		argv[optind-1] = prgname;
-
-	ret = optind-1;
-	optind = 1; /* reset getopt lib */
-	return ret;
-}
-
-static void
-print_ethaddr(const char *name, const struct ether_addr *eth_addr)
-{
-	char buf[ETHER_ADDR_FMT_SIZE];
-	ether_format_addr(buf, ETHER_ADDR_FMT_SIZE, eth_addr);
-	printf("%s%s", name, buf);
-}
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_EXACT_MATCH)
-static void
-setup_hash(int socketid)
-{
-	unsigned i;
-	int ret;
-	char s[64];
-
-	/* create  hashes */
-	snprintf(s, sizeof(s), "l3fwd_hash_%d", socketid);
-	l3fwd_hash_params.name = s;
-	l3fwd_hash_params.socket_id = socketid;
-	l3fwd_lookup_struct[socketid] = rte_hash_create(&l3fwd_hash_params);
-	if (l3fwd_lookup_struct[socketid] == NULL)
-		rte_exit(EXIT_FAILURE, "Unable to create the l3fwd hash on "
-				"socket %d\n", socketid);
-
-	/* populate the hash */
-	for (i = 0; i < L3FWD_NUM_ROUTES; i++) {
-		ret = rte_hash_add_key (l3fwd_lookup_struct[socketid],
-				(void *) &l3fwd_route_array[i].key);
-		if (ret < 0) {
-			rte_exit(EXIT_FAILURE, "Unable to add entry %u to the"
-				"l3fwd hash on socket %d\n", i, socketid);
-		}
-		l3fwd_out_if[ret] = l3fwd_route_array[i].if_out;
-		printf("Hash: Adding key\n");
-		print_key(l3fwd_route_array[i].key);
-	}
-}
-#endif
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_LPM)
-static void
-setup_lpm(int socketid)
-{
-	unsigned i;
-	int ret;
-	char s[64];
-
-	struct rte_lpm_config lpm_ipv4_config;
-
-	lpm_ipv4_config.max_rules = L3FWD_LPM_MAX_RULES;
-	lpm_ipv4_config.number_tbl8s = 256;
-	lpm_ipv4_config.flags = 0;
-
-	/* create the LPM table */
-	snprintf(s, sizeof(s), "L3FWD_LPM_%d", socketid);
-	l3fwd_lookup_struct[socketid] =
-			rte_lpm_create(s, socketid, &lpm_ipv4_config);
-	if (l3fwd_lookup_struct[socketid] == NULL)
-		rte_exit(EXIT_FAILURE, "Unable to create the l3fwd LPM table"
-				" on socket %d\n", socketid);
-
-	/* populate the LPM table */
-	for (i = 0; i < L3FWD_NUM_ROUTES; i++) {
-		ret = rte_lpm_add(l3fwd_lookup_struct[socketid],
-			l3fwd_route_array[i].ip,
-			l3fwd_route_array[i].depth,
-			l3fwd_route_array[i].if_out);
-
-		if (ret < 0) {
-			rte_exit(EXIT_FAILURE, "Unable to add entry %u to the "
-				"l3fwd LPM table on socket %d\n",
-				i, socketid);
-		}
-
-		printf("LPM: Adding route 0x%08x / %d (%d)\n",
-			(unsigned)l3fwd_route_array[i].ip,
-			l3fwd_route_array[i].depth,
-			l3fwd_route_array[i].if_out);
-	}
-}
-#endif
-
-static int
-init_mem(unsigned nb_mbuf)
-{
-	struct lcore_conf *qconf;
-	int socketid;
-	unsigned lcore_id;
-	char s[64];
-
-	for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-		if (rte_lcore_is_enabled(lcore_id) == 0)
-			continue;
-
-		if (numa_on)
-			socketid = rte_lcore_to_socket_id(lcore_id);
-		else
-			socketid = 0;
-
-		if (socketid >= NB_SOCKETS) {
-			rte_exit(EXIT_FAILURE, "Socket %d of lcore %u is out of range %d\n",
-				socketid, lcore_id, NB_SOCKETS);
-		}
-		if (pktmbuf_pool[socketid] == NULL) {
-			snprintf(s, sizeof(s), "mbuf_pool_%d", socketid);
-			pktmbuf_pool[socketid] = rte_pktmbuf_pool_create(s,
-				nb_mbuf, MEMPOOL_CACHE_SIZE, 0,
-				RTE_MBUF_DEFAULT_BUF_SIZE, socketid);
-			if (pktmbuf_pool[socketid] == NULL)
-				rte_exit(EXIT_FAILURE, "Cannot init mbuf pool on socket %d\n", socketid);
-			else
-				printf("Allocated mbuf pool on socket %d\n", socketid);
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_LPM)
-			setup_lpm(socketid);
-#else
-			setup_hash(socketid);
-#endif
-		}
-		qconf = &lcore_conf[lcore_id];
-		qconf->lookup_struct = l3fwd_lookup_struct[socketid];
-	}
-	return 0;
-}
-
-int
-main(int argc, char **argv)
-{
-	struct lcore_conf *qconf;
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_txconf *txconf;
-	int ret;
-	unsigned nb_ports;
-	uint16_t queueid, portid;
-	unsigned lcore_id;
-	uint32_t nb_lcores;
-	uint16_t n_tx_queue;
-	uint8_t nb_rx_queue, queue, socketid;
-
-	signal(SIGINT, signal_handler);
-	/* init EAL */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid EAL parameters\n");
-	argc -= ret;
-	argv += ret;
-
-	/* parse application arguments (after the EAL ones) */
-	ret = parse_args(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid L3FWD-VF parameters\n");
-
-	if (check_lcore_params() < 0)
-		rte_exit(EXIT_FAILURE, "check_lcore_params failed\n");
-
-	ret = init_lcore_rx_queues();
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "init_lcore_rx_queues failed\n");
-
-	nb_ports = rte_eth_dev_count();
-
-	if (check_port_config() < 0)
-		rte_exit(EXIT_FAILURE, "check_port_config failed\n");
-
-	nb_lcores = rte_lcore_count();
-
-	/* initialize all ports */
-	RTE_ETH_FOREACH_DEV(portid) {
-		struct rte_eth_conf local_port_conf = port_conf;
-
-		/* skip ports that are not enabled */
-		if ((enabled_port_mask & (1 << portid)) == 0) {
-			printf("\nSkipping disabled port %d\n", portid);
-			continue;
-		}
-
-		/* init port */
-		printf("Initializing port %d ... ", portid );
-		fflush(stdout);
-
-		/* must always equal(=1) */
-		nb_rx_queue = get_port_n_rx_queues(portid);
-		n_tx_queue = MAX_TX_QUEUE_PER_PORT;
-
-		printf("Creating queues: nb_rxq=%d nb_txq=%u... ",
-			nb_rx_queue, (unsigned)1 );
-
-		rte_eth_dev_info_get(portid, &dev_info);
-		if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-			local_port_conf.txmode.offloads |=
-				DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-		ret = rte_eth_dev_configure(portid, nb_rx_queue,
-					    n_tx_queue, &local_port_conf);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "Cannot configure device: err=%d, port=%d\n",
-				ret, portid);
-
-		ret = rte_eth_dev_adjust_nb_rx_tx_desc(portid, &nb_rxd,
-						       &nb_txd);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-				 "Cannot adjust number of descriptors: err=%d, port=%d\n",
-				 ret, portid);
-
-		rte_eth_macaddr_get(portid, &ports_eth_addr[portid]);
-		print_ethaddr(" Address:", &ports_eth_addr[portid]);
-		printf(", ");
-
-		ret = init_mem(NB_MBUF);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "init_mem failed\n");
-
-		/* init one TX queue */
-		socketid = (uint8_t)rte_lcore_to_socket_id(rte_get_master_lcore());
-
-		printf("txq=%d,%d,%d ", portid, 0, socketid);
-		fflush(stdout);
-
-		txconf = &dev_info.default_txconf;
-		txconf->txq_flags = ETH_TXQ_FLAGS_IGNORE;
-		txconf->offloads = local_port_conf.txmode.offloads;
-		ret = rte_eth_tx_queue_setup(portid, 0, nb_txd,
-						 socketid, txconf);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "rte_eth_tx_queue_setup: err=%d, "
-				"port=%d\n", ret, portid);
-
-		printf("\n");
-	}
-
-	for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-		struct rte_eth_rxconf rxq_conf;
-
-		if (rte_lcore_is_enabled(lcore_id) == 0)
-			continue;
-		qconf = &lcore_conf[lcore_id];
-		qconf->tx_queue_id = 0;
-
-		printf("\nInitializing rx queues on lcore %u ... ", lcore_id );
-		fflush(stdout);
-		/* init RX queues */
-		for(queue = 0; queue < qconf->n_rx_queue; ++queue) {
-			struct rte_eth_dev *dev;
-			struct rte_eth_conf *conf;
-
-			portid = qconf->rx_queue_list[queue].port_id;
-			queueid = qconf->rx_queue_list[queue].queue_id;
-			dev = &rte_eth_devices[portid];
-			conf = &dev->data->dev_conf;
-
-			if (numa_on)
-				socketid = (uint8_t)rte_lcore_to_socket_id(lcore_id);
-			else
-				socketid = 0;
-
-			printf("rxq=%d,%d,%d ", portid, queueid, socketid);
-			fflush(stdout);
-
-			rte_eth_dev_info_get(portid, &dev_info);
-			rxq_conf = dev_info.default_rxconf;
-			rxq_conf.offloads = conf->rxmode.offloads;
-			ret = rte_eth_rx_queue_setup(portid, queueid, nb_rxd,
-						socketid, &rxq_conf,
-						pktmbuf_pool[socketid]);
-			if (ret < 0)
-				rte_exit(EXIT_FAILURE, "rte_eth_rx_queue_setup: err=%d,"
-						"port=%d\n", ret, portid);
-		}
-	}
-	printf("\n");
-
-	/* start ports */
-	RTE_ETH_FOREACH_DEV(portid) {
-		if ((enabled_port_mask & (1 << portid)) == 0) {
-			continue;
-		}
-		/* Start device */
-		ret = rte_eth_dev_start(portid);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "rte_eth_dev_start: err=%d, port=%d\n",
-				ret, portid);
-
-		printf("done: Port %d\n", portid);
-
-	}
-
-	/* launch per-lcore init on every lcore */
-	rte_eal_mp_remote_launch(main_loop, NULL, CALL_MASTER);
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		if (rte_eal_wait_lcore(lcore_id) < 0)
-			return -1;
-	}
-
-	return 0;
-}
diff --git a/examples/l3fwd-vf/meson.build b/examples/l3fwd-vf/meson.build
deleted file mode 100644
index 00f3c38..0000000
--- a/examples/l3fwd-vf/meson.build
+++ /dev/null
@@ -1,13 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-deps += ['lpm', 'hash']
-allow_experimental_apis = true
-sources = files(
-	'main.c'
-)
diff --git a/examples/l3fwd/Makefile b/examples/l3fwd/Makefile
deleted file mode 100644
index 8cc8f6a..0000000
--- a/examples/l3fwd/Makefile
+++ /dev/null
@@ -1,59 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2016 Intel Corporation
-
-# binary name
-APP = l3fwd
-
-# all source are stored in SRCS-y
-SRCS-y := main.c l3fwd_lpm.c l3fwd_em.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else # Build using legacy build system
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -I$(SRCDIR)
-CFLAGS += -O3 $(USER_FLAGS)
-CFLAGS += $(WERROR_FLAGS)
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-endif
diff --git a/examples/l3fwd/l3fwd.h b/examples/l3fwd/l3fwd.h
deleted file mode 100644
index c962dea..0000000
--- a/examples/l3fwd/l3fwd.h
+++ /dev/null
@@ -1,212 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#ifndef __L3_FWD_H__
-#define __L3_FWD_H__
-
-#include <rte_vect.h>
-
-#define DO_RFC_1812_CHECKS
-
-#define RTE_LOGTYPE_L3FWD RTE_LOGTYPE_USER1
-
-#if !defined(NO_HASH_MULTI_LOOKUP) && defined(RTE_MACHINE_CPUFLAG_NEON)
-#define NO_HASH_MULTI_LOOKUP 1
-#endif
-
-#define MAX_PKT_BURST     32
-#define BURST_TX_DRAIN_US 100 /* TX drain every ~100us */
-
-#define MAX_RX_QUEUE_PER_LCORE 16
-
-/*
- * Try to avoid TX buffering if we have at least MAX_TX_BURST packets to send.
- */
-#define	MAX_TX_BURST	  (MAX_PKT_BURST / 2)
-
-#define NB_SOCKETS        8
-
-/* Configure how many packets ahead to prefetch, when reading packets */
-#define PREFETCH_OFFSET	  3
-
-/* Used to mark destination port as 'invalid'. */
-#define	BAD_PORT ((uint16_t)-1)
-
-#define FWDSTEP	4
-
-/* replace first 12B of the ethernet header. */
-#define	MASK_ETH 0x3f
-
-/* Hash parameters. */
-#ifdef RTE_ARCH_64
-/* default to 4 million hash entries (approx) */
-#define L3FWD_HASH_ENTRIES		(1024*1024*4)
-#else
-/* 32-bit has less address-space for hugepage memory, limit to 1M entries */
-#define L3FWD_HASH_ENTRIES		(1024*1024*1)
-#endif
-#define HASH_ENTRY_NUMBER_DEFAULT	4
-
-struct mbuf_table {
-	uint16_t len;
-	struct rte_mbuf *m_table[MAX_PKT_BURST];
-};
-
-struct lcore_rx_queue {
-	uint16_t port_id;
-	uint8_t queue_id;
-} __rte_cache_aligned;
-
-struct lcore_conf {
-	uint16_t n_rx_queue;
-	struct lcore_rx_queue rx_queue_list[MAX_RX_QUEUE_PER_LCORE];
-	uint16_t n_tx_port;
-	uint16_t tx_port_id[RTE_MAX_ETHPORTS];
-	uint16_t tx_queue_id[RTE_MAX_ETHPORTS];
-	struct mbuf_table tx_mbufs[RTE_MAX_ETHPORTS];
-	void *ipv4_lookup_struct;
-	void *ipv6_lookup_struct;
-} __rte_cache_aligned;
-
-extern volatile bool force_quit;
-
-/* ethernet addresses of ports */
-extern uint64_t dest_eth_addr[RTE_MAX_ETHPORTS];
-extern struct ether_addr ports_eth_addr[RTE_MAX_ETHPORTS];
-
-/* mask of enabled ports */
-extern uint32_t enabled_port_mask;
-
-/* Used only in exact match mode. */
-extern int ipv6; /**< ipv6 is false by default. */
-extern uint32_t hash_entry_number;
-
-extern xmm_t val_eth[RTE_MAX_ETHPORTS];
-
-extern struct lcore_conf lcore_conf[RTE_MAX_LCORE];
-
-/* Send burst of packets on an output interface */
-static inline int
-send_burst(struct lcore_conf *qconf, uint16_t n, uint16_t port)
-{
-	struct rte_mbuf **m_table;
-	int ret;
-	uint16_t queueid;
-
-	queueid = qconf->tx_queue_id[port];
-	m_table = (struct rte_mbuf **)qconf->tx_mbufs[port].m_table;
-
-	ret = rte_eth_tx_burst(port, queueid, m_table, n);
-	if (unlikely(ret < n)) {
-		do {
-			rte_pktmbuf_free(m_table[ret]);
-		} while (++ret < n);
-	}
-
-	return 0;
-}
-
-/* Enqueue a single packet, and send burst if queue is filled */
-static inline int
-send_single_packet(struct lcore_conf *qconf,
-		   struct rte_mbuf *m, uint16_t port)
-{
-	uint16_t len;
-
-	len = qconf->tx_mbufs[port].len;
-	qconf->tx_mbufs[port].m_table[len] = m;
-	len++;
-
-	/* enough pkts to be sent */
-	if (unlikely(len == MAX_PKT_BURST)) {
-		send_burst(qconf, MAX_PKT_BURST, port);
-		len = 0;
-	}
-
-	qconf->tx_mbufs[port].len = len;
-	return 0;
-}
-
-#ifdef DO_RFC_1812_CHECKS
-static inline int
-is_valid_ipv4_pkt(struct ipv4_hdr *pkt, uint32_t link_len)
-{
-	/* From http://www.rfc-editor.org/rfc/rfc1812.txt section 5.2.2 */
-	/*
-	 * 1. The packet length reported by the Link Layer must be large
-	 * enough to hold the minimum length legal IP datagram (20 bytes).
-	 */
-	if (link_len < sizeof(struct ipv4_hdr))
-		return -1;
-
-	/* 2. The IP checksum must be correct. */
-	/* this is checked in H/W */
-
-	/*
-	 * 3. The IP version number must be 4. If the version number is not 4
-	 * then the packet may be another version of IP, such as IPng or
-	 * ST-II.
-	 */
-	if (((pkt->version_ihl) >> 4) != 4)
-		return -3;
-	/*
-	 * 4. The IP header length field must be large enough to hold the
-	 * minimum length legal IP datagram (20 bytes = 5 words).
-	 */
-	if ((pkt->version_ihl & 0xf) < 5)
-		return -4;
-
-	/*
-	 * 5. The IP total length field must be large enough to hold the IP
-	 * datagram header, whose length is specified in the IP header length
-	 * field.
-	 */
-	if (rte_cpu_to_be_16(pkt->total_length) < sizeof(struct ipv4_hdr))
-		return -5;
-
-	return 0;
-}
-#endif /* DO_RFC_1812_CHECKS */
-
-/* Function pointers for LPM or EM functionality. */
-void
-setup_lpm(const int socketid);
-
-void
-setup_hash(const int socketid);
-
-int
-em_check_ptype(int portid);
-
-int
-lpm_check_ptype(int portid);
-
-uint16_t
-em_cb_parse_ptype(uint16_t port, uint16_t queue, struct rte_mbuf *pkts[],
-		  uint16_t nb_pkts, uint16_t max_pkts, void *user_param);
-
-uint16_t
-lpm_cb_parse_ptype(uint16_t port, uint16_t queue, struct rte_mbuf *pkts[],
-		   uint16_t nb_pkts, uint16_t max_pkts, void *user_param);
-
-int
-em_main_loop(__attribute__((unused)) void *dummy);
-
-int
-lpm_main_loop(__attribute__((unused)) void *dummy);
-
-/* Return ipv4/ipv6 fwd lookup struct for LPM or EM. */
-void *
-em_get_ipv4_l3fwd_lookup_struct(const int socketid);
-
-void *
-em_get_ipv6_l3fwd_lookup_struct(const int socketid);
-
-void *
-lpm_get_ipv4_l3fwd_lookup_struct(const int socketid);
-
-void *
-lpm_get_ipv6_l3fwd_lookup_struct(const int socketid);
-
-#endif  /* __L3_FWD_H__ */
diff --git a/examples/l3fwd/l3fwd_altivec.h b/examples/l3fwd/l3fwd_altivec.h
deleted file mode 100644
index 5ec99f9..0000000
--- a/examples/l3fwd/l3fwd_altivec.h
+++ /dev/null
@@ -1,255 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016 Intel Corporation.
- * Copyright(c) 2017 IBM Corporation.
- * All rights reserved.
- */
-
-#ifndef _L3FWD_ALTIVEC_H_
-#define _L3FWD_ALTIVEC_H_
-
-#include "l3fwd.h"
-#include "l3fwd_common.h"
-
-/*
- * Update source and destination MAC addresses in the ethernet header.
- * Perform RFC1812 checks and updates for IPV4 packets.
- */
-static inline void
-processx4_step3(struct rte_mbuf *pkt[FWDSTEP], uint16_t dst_port[FWDSTEP])
-{
-	vector unsigned int te[FWDSTEP];
-	vector unsigned int ve[FWDSTEP];
-	vector unsigned int *p[FWDSTEP];
-
-	p[0] = rte_pktmbuf_mtod(pkt[0], vector unsigned int *);
-	p[1] = rte_pktmbuf_mtod(pkt[1], vector unsigned int *);
-	p[2] = rte_pktmbuf_mtod(pkt[2], vector unsigned int *);
-	p[3] = rte_pktmbuf_mtod(pkt[3], vector unsigned int *);
-
-	ve[0] = (vector unsigned int)val_eth[dst_port[0]];
-	te[0] = *p[0];
-
-	ve[1] = (vector unsigned int)val_eth[dst_port[1]];
-	te[1] = *p[1];
-
-	ve[2] = (vector unsigned int)val_eth[dst_port[2]];
-	te[2] = *p[2];
-
-	ve[3] = (vector unsigned int)val_eth[dst_port[3]];
-	te[3] = *p[3];
-
-	/* Update first 12 bytes, keep rest bytes intact. */
-	te[0] = (vector unsigned int)vec_sel(
-			(vector unsigned short)ve[0],
-			(vector unsigned short)te[0],
-			(vector unsigned short) {0, 0, 0, 0,
-						0, 0, 0xffff, 0xffff});
-
-	te[1] = (vector unsigned int)vec_sel(
-			(vector unsigned short)ve[1],
-			(vector unsigned short)te[1],
-			(vector unsigned short) {0, 0, 0, 0,
-						0, 0, 0xffff, 0xffff});
-
-	te[2] = (vector unsigned int)vec_sel(
-			(vector unsigned short)ve[2],
-			(vector unsigned short)te[2],
-			(vector unsigned short) {0, 0, 0, 0, 0,
-						0, 0xffff, 0xffff});
-
-	te[3] = (vector unsigned int)vec_sel(
-			(vector unsigned short)ve[3],
-			(vector unsigned short)te[3],
-			(vector unsigned short) {0, 0, 0, 0,
-						0, 0, 0xffff, 0xffff});
-
-	*p[0] = te[0];
-	*p[1] = te[1];
-	*p[2] = te[2];
-	*p[3] = te[3];
-
-	rfc1812_process((struct ipv4_hdr *)((struct ether_hdr *)p[0] + 1),
-		&dst_port[0], pkt[0]->packet_type);
-	rfc1812_process((struct ipv4_hdr *)((struct ether_hdr *)p[1] + 1),
-		&dst_port[1], pkt[1]->packet_type);
-	rfc1812_process((struct ipv4_hdr *)((struct ether_hdr *)p[2] + 1),
-		&dst_port[2], pkt[2]->packet_type);
-	rfc1812_process((struct ipv4_hdr *)((struct ether_hdr *)p[3] + 1),
-		&dst_port[3], pkt[3]->packet_type);
-}
-
-/*
- * Group consecutive packets with the same destination port in bursts of 4.
- * Suppose we have array of destination ports:
- * dst_port[] = {a, b, c, d,, e, ... }
- * dp1 should contain: <a, b, c, d>, dp2: <b, c, d, e>.
- * We doing 4 comparisons at once and the result is 4 bit mask.
- * This mask is used as an index into prebuild array of pnum values.
- */
-static inline uint16_t *
-port_groupx4(uint16_t pn[FWDSTEP + 1], uint16_t *lp, vector unsigned short dp1,
-	vector unsigned short dp2)
-{
-	union {
-		uint16_t u16[FWDSTEP + 1];
-		uint64_t u64;
-	} *pnum = (void *)pn;
-
-	int32_t v;
-
-	v = vec_any_eq(dp1, dp2);
-
-
-	/* update last port counter. */
-	lp[0] += gptbl[v].lpv;
-
-	/* if dest port value has changed. */
-	if (v != GRPMSK) {
-		pnum->u64 = gptbl[v].pnum;
-		pnum->u16[FWDSTEP] = 1;
-		lp = pnum->u16 + gptbl[v].idx;
-	}
-
-	return lp;
-}
-
-/**
- * Process one packet:
- * Update source and destination MAC addresses in the ethernet header.
- * Perform RFC1812 checks and updates for IPV4 packets.
- */
-static inline void
-process_packet(struct rte_mbuf *pkt, uint16_t *dst_port)
-{
-	struct ether_hdr *eth_hdr;
-	vector unsigned int te, ve;
-
-	eth_hdr = rte_pktmbuf_mtod(pkt, struct ether_hdr *);
-
-	te = *(vector unsigned int *)eth_hdr;
-	ve = (vector unsigned int)val_eth[dst_port[0]];
-
-	rfc1812_process((struct ipv4_hdr *)(eth_hdr + 1), dst_port,
-			pkt->packet_type);
-
-	/* dynamically vec_sel te and ve for MASK_ETH (0x3f) */
-	te = (vector unsigned int)vec_sel(
-		(vector unsigned short)ve,
-		(vector unsigned short)te,
-		(vector unsigned short){0, 0, 0, 0,
-					0, 0, 0xffff, 0xffff});
-
-	*(vector unsigned int *)eth_hdr = te;
-}
-
-/**
- * Send packets burst from pkts_burst to the ports in dst_port array
- */
-static __rte_always_inline void
-send_packets_multi(struct lcore_conf *qconf, struct rte_mbuf **pkts_burst,
-		uint16_t dst_port[MAX_PKT_BURST], int nb_rx)
-{
-	int32_t k;
-	int j = 0;
-	uint16_t dlp;
-	uint16_t *lp;
-	uint16_t pnum[MAX_PKT_BURST + 1];
-
-	/*
-	 * Finish packet processing and group consecutive
-	 * packets with the same destination port.
-	 */
-	k = RTE_ALIGN_FLOOR(nb_rx, FWDSTEP);
-	if (k != 0) {
-		vector unsigned short dp1, dp2;
-
-		lp = pnum;
-		lp[0] = 1;
-
-		processx4_step3(pkts_burst, dst_port);
-
-		/* dp1: <d[0], d[1], d[2], d[3], ... > */
-		dp1 = *(vector unsigned short *)dst_port;
-
-		for (j = FWDSTEP; j != k; j += FWDSTEP) {
-			processx4_step3(&pkts_burst[j], &dst_port[j]);
-
-			/*
-			 * dp2:
-			 * <d[j-3], d[j-2], d[j-1], d[j], ... >
-			 */
-			dp2 = *((vector unsigned short *)
-					&dst_port[j - FWDSTEP + 1]);
-			lp  = port_groupx4(&pnum[j - FWDSTEP], lp, dp1, dp2);
-
-			/*
-			 * dp1:
-			 * <d[j], d[j+1], d[j+2], d[j+3], ... >
-			 */
-			dp1 = vec_sro(dp2, (vector unsigned char) {
-				0, 0, 0, 0, 0, 0, 0, 0,
-				0, 0, 0, (FWDSTEP - 1) * sizeof(dst_port[0])});
-		}
-
-		/*
-		 * dp2: <d[j-3], d[j-2], d[j-1], d[j-1], ... >
-		 */
-		dp2 = vec_perm(dp1, (vector unsigned short){},
-				(vector unsigned char){0xf9});
-		lp  = port_groupx4(&pnum[j - FWDSTEP], lp, dp1, dp2);
-
-		/*
-		 * remove values added by the last repeated
-		 * dst port.
-		 */
-		lp[0]--;
-		dlp = dst_port[j - 1];
-	} else {
-		/* set dlp and lp to the never used values. */
-		dlp = BAD_PORT - 1;
-		lp = pnum + MAX_PKT_BURST;
-	}
-
-	/* Process up to last 3 packets one by one. */
-	switch (nb_rx % FWDSTEP) {
-	case 3:
-		process_packet(pkts_burst[j], dst_port + j);
-		GROUP_PORT_STEP(dlp, dst_port, lp, pnum, j);
-		j++;
-		/* fall-through */
-	case 2:
-		process_packet(pkts_burst[j], dst_port + j);
-		GROUP_PORT_STEP(dlp, dst_port, lp, pnum, j);
-		j++;
-		/* fall-through */
-	case 1:
-		process_packet(pkts_burst[j], dst_port + j);
-		GROUP_PORT_STEP(dlp, dst_port, lp, pnum, j);
-		j++;
-	}
-
-	/*
-	 * Send packets out, through destination port.
-	 * Consecutive packets with the same destination port
-	 * are already grouped together.
-	 * If destination port for the packet equals BAD_PORT,
-	 * then free the packet without sending it out.
-	 */
-	for (j = 0; j < nb_rx; j += k) {
-
-		int32_t m;
-		uint16_t pn;
-
-		pn = dst_port[j];
-		k = pnum[j];
-
-		if (likely(pn != BAD_PORT))
-			send_packetsx4(qconf, pn, pkts_burst + j, k);
-		else
-			for (m = j; m != j + k; m++)
-				rte_pktmbuf_free(pkts_burst[m]);
-
-	}
-}
-
-#endif /* _L3FWD_ALTIVEC_H_ */
diff --git a/examples/l3fwd/l3fwd_common.h b/examples/l3fwd/l3fwd_common.h
deleted file mode 100644
index 7002a43..0000000
--- a/examples/l3fwd/l3fwd_common.h
+++ /dev/null
@@ -1,293 +0,0 @@
-/*-
- *   BSD LICENSE
- *
- *   Copyright(c) 2016 Intel Corporation. All rights reserved.
- *   Copyright(c) 2017, Linaro Limited
- *   All rights reserved.
- *
- *   Redistribution and use in source and binary forms, with or without
- *   modification, are permitted provided that the following conditions
- *   are met:
- *
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above copyright
- *       notice, this list of conditions and the following disclaimer in
- *       the documentation and/or other materials provided with the
- *       distribution.
- *     * Neither the name of Intel Corporation nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-
-#ifndef _L3FWD_COMMON_H_
-#define _L3FWD_COMMON_H_
-
-#ifdef DO_RFC_1812_CHECKS
-
-#define	IPV4_MIN_VER_IHL	0x45
-#define	IPV4_MAX_VER_IHL	0x4f
-#define	IPV4_MAX_VER_IHL_DIFF	(IPV4_MAX_VER_IHL - IPV4_MIN_VER_IHL)
-
-/* Minimum value of IPV4 total length (20B) in network byte order. */
-#define	IPV4_MIN_LEN_BE	(sizeof(struct ipv4_hdr) << 8)
-
-/*
- * From http://www.rfc-editor.org/rfc/rfc1812.txt section 5.2.2:
- * - The IP version number must be 4.
- * - The IP header length field must be large enough to hold the
- *    minimum length legal IP datagram (20 bytes = 5 words).
- * - The IP total length field must be large enough to hold the IP
- *   datagram header, whose length is specified in the IP header length
- *   field.
- * If we encounter invalid IPV4 packet, then set destination port for it
- * to BAD_PORT value.
- */
-static __rte_always_inline void
-rfc1812_process(struct ipv4_hdr *ipv4_hdr, uint16_t *dp, uint32_t ptype)
-{
-	uint8_t ihl;
-
-	if (RTE_ETH_IS_IPV4_HDR(ptype)) {
-		ihl = ipv4_hdr->version_ihl - IPV4_MIN_VER_IHL;
-
-		ipv4_hdr->time_to_live--;
-		ipv4_hdr->hdr_checksum++;
-
-		if (ihl > IPV4_MAX_VER_IHL_DIFF ||
-				((uint8_t)ipv4_hdr->total_length == 0 &&
-				ipv4_hdr->total_length < IPV4_MIN_LEN_BE))
-			dp[0] = BAD_PORT;
-
-	}
-}
-
-#else
-#define	rfc1812_process(mb, dp, ptype)	do { } while (0)
-#endif /* DO_RFC_1812_CHECKS */
-
-/*
- * We group consecutive packets with the same destionation port into one burst.
- * To avoid extra latency this is done together with some other packet
- * processing, but after we made a final decision about packet's destination.
- * To do this we maintain:
- * pnum - array of number of consecutive packets with the same dest port for
- * each packet in the input burst.
- * lp - pointer to the last updated element in the pnum.
- * dlp - dest port value lp corresponds to.
- */
-
-#define	GRPSZ	(1 << FWDSTEP)
-#define	GRPMSK	(GRPSZ - 1)
-
-#define GROUP_PORT_STEP(dlp, dcp, lp, pn, idx)	do { \
-	if (likely((dlp) == (dcp)[(idx)])) {             \
-		(lp)[0]++;                                   \
-	} else {                                         \
-		(dlp) = (dcp)[idx];                          \
-		(lp) = (pn) + (idx);                         \
-		(lp)[0] = 1;                                 \
-	}                                                \
-} while (0)
-
-static const struct {
-	uint64_t pnum; /* prebuild 4 values for pnum[]. */
-	int32_t  idx;  /* index for new last updated elemnet. */
-	uint16_t lpv;  /* add value to the last updated element. */
-} gptbl[GRPSZ] = {
-	{
-		/* 0: a != b, b != c, c != d, d != e */
-		.pnum = UINT64_C(0x0001000100010001),
-		.idx = 4,
-		.lpv = 0,
-	},
-	{
-		/* 1: a == b, b != c, c != d, d != e */
-		.pnum = UINT64_C(0x0001000100010002),
-		.idx = 4,
-		.lpv = 1,
-	},
-	{
-		/* 2: a != b, b == c, c != d, d != e */
-		.pnum = UINT64_C(0x0001000100020001),
-		.idx = 4,
-		.lpv = 0,
-	},
-	{
-		/* 3: a == b, b == c, c != d, d != e */
-		.pnum = UINT64_C(0x0001000100020003),
-		.idx = 4,
-		.lpv = 2,
-	},
-	{
-		/* 4: a != b, b != c, c == d, d != e */
-		.pnum = UINT64_C(0x0001000200010001),
-		.idx = 4,
-		.lpv = 0,
-	},
-	{
-		/* 5: a == b, b != c, c == d, d != e */
-		.pnum = UINT64_C(0x0001000200010002),
-		.idx = 4,
-		.lpv = 1,
-	},
-	{
-		/* 6: a != b, b == c, c == d, d != e */
-		.pnum = UINT64_C(0x0001000200030001),
-		.idx = 4,
-		.lpv = 0,
-	},
-	{
-		/* 7: a == b, b == c, c == d, d != e */
-		.pnum = UINT64_C(0x0001000200030004),
-		.idx = 4,
-		.lpv = 3,
-	},
-	{
-		/* 8: a != b, b != c, c != d, d == e */
-		.pnum = UINT64_C(0x0002000100010001),
-		.idx = 3,
-		.lpv = 0,
-	},
-	{
-		/* 9: a == b, b != c, c != d, d == e */
-		.pnum = UINT64_C(0x0002000100010002),
-		.idx = 3,
-		.lpv = 1,
-	},
-	{
-		/* 0xa: a != b, b == c, c != d, d == e */
-		.pnum = UINT64_C(0x0002000100020001),
-		.idx = 3,
-		.lpv = 0,
-	},
-	{
-		/* 0xb: a == b, b == c, c != d, d == e */
-		.pnum = UINT64_C(0x0002000100020003),
-		.idx = 3,
-		.lpv = 2,
-	},
-	{
-		/* 0xc: a != b, b != c, c == d, d == e */
-		.pnum = UINT64_C(0x0002000300010001),
-		.idx = 2,
-		.lpv = 0,
-	},
-	{
-		/* 0xd: a == b, b != c, c == d, d == e */
-		.pnum = UINT64_C(0x0002000300010002),
-		.idx = 2,
-		.lpv = 1,
-	},
-	{
-		/* 0xe: a != b, b == c, c == d, d == e */
-		.pnum = UINT64_C(0x0002000300040001),
-		.idx = 1,
-		.lpv = 0,
-	},
-	{
-		/* 0xf: a == b, b == c, c == d, d == e */
-		.pnum = UINT64_C(0x0002000300040005),
-		.idx = 0,
-		.lpv = 4,
-	},
-};
-
-static __rte_always_inline void
-send_packetsx4(struct lcore_conf *qconf, uint16_t port, struct rte_mbuf *m[],
-		uint32_t num)
-{
-	uint32_t len, j, n;
-
-	len = qconf->tx_mbufs[port].len;
-
-	/*
-	 * If TX buffer for that queue is empty, and we have enough packets,
-	 * then send them straightway.
-	 */
-	if (num >= MAX_TX_BURST && len == 0) {
-		n = rte_eth_tx_burst(port, qconf->tx_queue_id[port], m, num);
-		if (unlikely(n < num)) {
-			do {
-				rte_pktmbuf_free(m[n]);
-			} while (++n < num);
-		}
-		return;
-	}
-
-	/*
-	 * Put packets into TX buffer for that queue.
-	 */
-
-	n = len + num;
-	n = (n > MAX_PKT_BURST) ? MAX_PKT_BURST - len : num;
-
-	j = 0;
-	switch (n % FWDSTEP) {
-	while (j < n) {
-	case 0:
-		qconf->tx_mbufs[port].m_table[len + j] = m[j];
-		j++;
-		/* fallthrough */
-	case 3:
-		qconf->tx_mbufs[port].m_table[len + j] = m[j];
-		j++;
-		/* fallthrough */
-	case 2:
-		qconf->tx_mbufs[port].m_table[len + j] = m[j];
-		j++;
-		/* fallthrough */
-	case 1:
-		qconf->tx_mbufs[port].m_table[len + j] = m[j];
-		j++;
-	}
-	}
-
-	len += n;
-
-	/* enough pkts to be sent */
-	if (unlikely(len == MAX_PKT_BURST)) {
-
-		send_burst(qconf, MAX_PKT_BURST, port);
-
-		/* copy rest of the packets into the TX buffer. */
-		len = num - n;
-		j = 0;
-		switch (len % FWDSTEP) {
-		while (j < len) {
-		case 0:
-			qconf->tx_mbufs[port].m_table[j] = m[n + j];
-			j++;
-			/* fallthrough */
-		case 3:
-			qconf->tx_mbufs[port].m_table[j] = m[n + j];
-			j++;
-			/* fallthrough */
-		case 2:
-			qconf->tx_mbufs[port].m_table[j] = m[n + j];
-			j++;
-			/* fallthrough */
-		case 1:
-			qconf->tx_mbufs[port].m_table[j] = m[n + j];
-			j++;
-		}
-		}
-	}
-
-	qconf->tx_mbufs[port].len = len;
-}
-
-#endif /* _L3FWD_COMMON_H_ */
diff --git a/examples/l3fwd/l3fwd_em.c b/examples/l3fwd/l3fwd_em.c
deleted file mode 100644
index 9dc3b8c..0000000
--- a/examples/l3fwd/l3fwd_em.c
+++ /dev/null
@@ -1,786 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <sys/types.h>
-#include <string.h>
-#include <sys/queue.h>
-#include <stdarg.h>
-#include <errno.h>
-#include <getopt.h>
-#include <stdbool.h>
-#include <netinet/in.h>
-
-#include <rte_debug.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_mempool.h>
-#include <rte_cycles.h>
-#include <rte_mbuf.h>
-#include <rte_ip.h>
-#include <rte_tcp.h>
-#include <rte_udp.h>
-#include <rte_hash.h>
-
-#include "l3fwd.h"
-
-#if defined(RTE_ARCH_X86) || defined(RTE_MACHINE_CPUFLAG_CRC32)
-#define EM_HASH_CRC 1
-#endif
-
-#ifdef EM_HASH_CRC
-#include <rte_hash_crc.h>
-#define DEFAULT_HASH_FUNC       rte_hash_crc
-#else
-#include <rte_jhash.h>
-#define DEFAULT_HASH_FUNC       rte_jhash
-#endif
-
-#define IPV6_ADDR_LEN 16
-
-struct ipv4_5tuple {
-	uint32_t ip_dst;
-	uint32_t ip_src;
-	uint16_t port_dst;
-	uint16_t port_src;
-	uint8_t  proto;
-} __attribute__((__packed__));
-
-union ipv4_5tuple_host {
-	struct {
-		uint8_t  pad0;
-		uint8_t  proto;
-		uint16_t pad1;
-		uint32_t ip_src;
-		uint32_t ip_dst;
-		uint16_t port_src;
-		uint16_t port_dst;
-	};
-	xmm_t xmm;
-};
-
-#define XMM_NUM_IN_IPV6_5TUPLE 3
-
-struct ipv6_5tuple {
-	uint8_t  ip_dst[IPV6_ADDR_LEN];
-	uint8_t  ip_src[IPV6_ADDR_LEN];
-	uint16_t port_dst;
-	uint16_t port_src;
-	uint8_t  proto;
-} __attribute__((__packed__));
-
-union ipv6_5tuple_host {
-	struct {
-		uint16_t pad0;
-		uint8_t  proto;
-		uint8_t  pad1;
-		uint8_t  ip_src[IPV6_ADDR_LEN];
-		uint8_t  ip_dst[IPV6_ADDR_LEN];
-		uint16_t port_src;
-		uint16_t port_dst;
-		uint64_t reserve;
-	};
-	xmm_t xmm[XMM_NUM_IN_IPV6_5TUPLE];
-};
-
-
-
-struct ipv4_l3fwd_em_route {
-	struct ipv4_5tuple key;
-	uint8_t if_out;
-};
-
-struct ipv6_l3fwd_em_route {
-	struct ipv6_5tuple key;
-	uint8_t if_out;
-};
-
-static struct ipv4_l3fwd_em_route ipv4_l3fwd_em_route_array[] = {
-	{{IPv4(101, 0, 0, 0), IPv4(100, 10, 0, 1),  101, 11, IPPROTO_TCP}, 0},
-	{{IPv4(201, 0, 0, 0), IPv4(200, 20, 0, 1),  102, 12, IPPROTO_TCP}, 1},
-	{{IPv4(111, 0, 0, 0), IPv4(100, 30, 0, 1),  101, 11, IPPROTO_TCP}, 2},
-	{{IPv4(211, 0, 0, 0), IPv4(200, 40, 0, 1),  102, 12, IPPROTO_TCP}, 3},
-};
-
-static struct ipv6_l3fwd_em_route ipv6_l3fwd_em_route_array[] = {
-	{{
-	{0xfe, 0x80, 0, 0, 0, 0, 0, 0, 0x02, 0x1e, 0x67, 0xff, 0xfe, 0, 0, 0},
-	{0xfe, 0x80, 0, 0, 0, 0, 0, 0, 0x02, 0x1b, 0x21, 0xff, 0xfe, 0x91, 0x38, 0x05},
-	101, 11, IPPROTO_TCP}, 0},
-
-	{{
-	{0xfe, 0x90, 0, 0, 0, 0, 0, 0, 0x02, 0x1e, 0x67, 0xff, 0xfe, 0, 0, 0},
-	{0xfe, 0x90, 0, 0, 0, 0, 0, 0, 0x02, 0x1b, 0x21, 0xff, 0xfe, 0x91, 0x38, 0x05},
-	102, 12, IPPROTO_TCP}, 1},
-
-	{{
-	{0xfe, 0xa0, 0, 0, 0, 0, 0, 0, 0x02, 0x1e, 0x67, 0xff, 0xfe, 0, 0, 0},
-	{0xfe, 0xa0, 0, 0, 0, 0, 0, 0, 0x02, 0x1b, 0x21, 0xff, 0xfe, 0x91, 0x38, 0x05},
-	101, 11, IPPROTO_TCP}, 2},
-
-	{{
-	{0xfe, 0xb0, 0, 0, 0, 0, 0, 0, 0x02, 0x1e, 0x67, 0xff, 0xfe, 0, 0, 0},
-	{0xfe, 0xb0, 0, 0, 0, 0, 0, 0, 0x02, 0x1b, 0x21, 0xff, 0xfe, 0x91, 0x38, 0x05},
-	102, 12, IPPROTO_TCP}, 3},
-};
-
-struct rte_hash *ipv4_l3fwd_em_lookup_struct[NB_SOCKETS];
-struct rte_hash *ipv6_l3fwd_em_lookup_struct[NB_SOCKETS];
-
-static inline uint32_t
-ipv4_hash_crc(const void *data, __rte_unused uint32_t data_len,
-		uint32_t init_val)
-{
-	const union ipv4_5tuple_host *k;
-	uint32_t t;
-	const uint32_t *p;
-
-	k = data;
-	t = k->proto;
-	p = (const uint32_t *)&k->port_src;
-
-#ifdef EM_HASH_CRC
-	init_val = rte_hash_crc_4byte(t, init_val);
-	init_val = rte_hash_crc_4byte(k->ip_src, init_val);
-	init_val = rte_hash_crc_4byte(k->ip_dst, init_val);
-	init_val = rte_hash_crc_4byte(*p, init_val);
-#else
-	init_val = rte_jhash_1word(t, init_val);
-	init_val = rte_jhash_1word(k->ip_src, init_val);
-	init_val = rte_jhash_1word(k->ip_dst, init_val);
-	init_val = rte_jhash_1word(*p, init_val);
-#endif
-
-	return init_val;
-}
-
-static inline uint32_t
-ipv6_hash_crc(const void *data, __rte_unused uint32_t data_len,
-		uint32_t init_val)
-{
-	const union ipv6_5tuple_host *k;
-	uint32_t t;
-	const uint32_t *p;
-#ifdef EM_HASH_CRC
-	const uint32_t  *ip_src0, *ip_src1, *ip_src2, *ip_src3;
-	const uint32_t  *ip_dst0, *ip_dst1, *ip_dst2, *ip_dst3;
-#endif
-
-	k = data;
-	t = k->proto;
-	p = (const uint32_t *)&k->port_src;
-
-#ifdef EM_HASH_CRC
-	ip_src0 = (const uint32_t *) k->ip_src;
-	ip_src1 = (const uint32_t *)(k->ip_src+4);
-	ip_src2 = (const uint32_t *)(k->ip_src+8);
-	ip_src3 = (const uint32_t *)(k->ip_src+12);
-	ip_dst0 = (const uint32_t *) k->ip_dst;
-	ip_dst1 = (const uint32_t *)(k->ip_dst+4);
-	ip_dst2 = (const uint32_t *)(k->ip_dst+8);
-	ip_dst3 = (const uint32_t *)(k->ip_dst+12);
-	init_val = rte_hash_crc_4byte(t, init_val);
-	init_val = rte_hash_crc_4byte(*ip_src0, init_val);
-	init_val = rte_hash_crc_4byte(*ip_src1, init_val);
-	init_val = rte_hash_crc_4byte(*ip_src2, init_val);
-	init_val = rte_hash_crc_4byte(*ip_src3, init_val);
-	init_val = rte_hash_crc_4byte(*ip_dst0, init_val);
-	init_val = rte_hash_crc_4byte(*ip_dst1, init_val);
-	init_val = rte_hash_crc_4byte(*ip_dst2, init_val);
-	init_val = rte_hash_crc_4byte(*ip_dst3, init_val);
-	init_val = rte_hash_crc_4byte(*p, init_val);
-#else
-	init_val = rte_jhash_1word(t, init_val);
-	init_val = rte_jhash(k->ip_src,
-			sizeof(uint8_t) * IPV6_ADDR_LEN, init_val);
-	init_val = rte_jhash(k->ip_dst,
-			sizeof(uint8_t) * IPV6_ADDR_LEN, init_val);
-	init_val = rte_jhash_1word(*p, init_val);
-#endif
-	return init_val;
-}
-
-#define IPV4_L3FWD_EM_NUM_ROUTES \
-	(sizeof(ipv4_l3fwd_em_route_array) / sizeof(ipv4_l3fwd_em_route_array[0]))
-
-#define IPV6_L3FWD_EM_NUM_ROUTES \
-	(sizeof(ipv6_l3fwd_em_route_array) / sizeof(ipv6_l3fwd_em_route_array[0]))
-
-static uint8_t ipv4_l3fwd_out_if[L3FWD_HASH_ENTRIES] __rte_cache_aligned;
-static uint8_t ipv6_l3fwd_out_if[L3FWD_HASH_ENTRIES] __rte_cache_aligned;
-
-static rte_xmm_t mask0;
-static rte_xmm_t mask1;
-static rte_xmm_t mask2;
-
-#if defined(RTE_MACHINE_CPUFLAG_SSE2)
-static inline xmm_t
-em_mask_key(void *key, xmm_t mask)
-{
-	__m128i data = _mm_loadu_si128((__m128i *)(key));
-
-	return _mm_and_si128(data, mask);
-}
-#elif defined(RTE_MACHINE_CPUFLAG_NEON)
-static inline xmm_t
-em_mask_key(void *key, xmm_t mask)
-{
-	int32x4_t data = vld1q_s32((int32_t *)key);
-
-	return vandq_s32(data, mask);
-}
-#elif defined(RTE_MACHINE_CPUFLAG_ALTIVEC)
-static inline xmm_t
-em_mask_key(void *key, xmm_t mask)
-{
-	xmm_t data = vec_ld(0, (xmm_t *)(key));
-
-	return vec_and(data, mask);
-}
-#else
-#error No vector engine (SSE, NEON, ALTIVEC) available, check your toolchain
-#endif
-
-static inline uint16_t
-em_get_ipv4_dst_port(void *ipv4_hdr, uint16_t portid, void *lookup_struct)
-{
-	int ret = 0;
-	union ipv4_5tuple_host key;
-	struct rte_hash *ipv4_l3fwd_lookup_struct =
-		(struct rte_hash *)lookup_struct;
-
-	ipv4_hdr = (uint8_t *)ipv4_hdr + offsetof(struct ipv4_hdr, time_to_live);
-
-	/*
-	 * Get 5 tuple: dst port, src port, dst IP address,
-	 * src IP address and protocol.
-	 */
-	key.xmm = em_mask_key(ipv4_hdr, mask0.x);
-
-	/* Find destination port */
-	ret = rte_hash_lookup(ipv4_l3fwd_lookup_struct, (const void *)&key);
-	return (ret < 0) ? portid : ipv4_l3fwd_out_if[ret];
-}
-
-static inline uint16_t
-em_get_ipv6_dst_port(void *ipv6_hdr, uint16_t portid, void *lookup_struct)
-{
-	int ret = 0;
-	union ipv6_5tuple_host key;
-	struct rte_hash *ipv6_l3fwd_lookup_struct =
-		(struct rte_hash *)lookup_struct;
-
-	ipv6_hdr = (uint8_t *)ipv6_hdr + offsetof(struct ipv6_hdr, payload_len);
-	void *data0 = ipv6_hdr;
-	void *data1 = ((uint8_t *)ipv6_hdr) + sizeof(xmm_t);
-	void *data2 = ((uint8_t *)ipv6_hdr) + sizeof(xmm_t) + sizeof(xmm_t);
-
-	/* Get part of 5 tuple: src IP address lower 96 bits and protocol */
-	key.xmm[0] = em_mask_key(data0, mask1.x);
-
-	/*
-	 * Get part of 5 tuple: dst IP address lower 96 bits
-	 * and src IP address higher 32 bits.
-	 */
-	key.xmm[1] = *(xmm_t *)data1;
-
-	/*
-	 * Get part of 5 tuple: dst port and src port
-	 * and dst IP address higher 32 bits.
-	 */
-	key.xmm[2] = em_mask_key(data2, mask2.x);
-
-	/* Find destination port */
-	ret = rte_hash_lookup(ipv6_l3fwd_lookup_struct, (const void *)&key);
-	return (ret < 0) ? portid : ipv6_l3fwd_out_if[ret];
-}
-
-#if defined RTE_ARCH_X86 || defined RTE_MACHINE_CPUFLAG_NEON
-#if defined(NO_HASH_MULTI_LOOKUP)
-#include "l3fwd_em_sequential.h"
-#else
-#include "l3fwd_em_hlm.h"
-#endif
-#else
-#include "l3fwd_em.h"
-#endif
-
-static void
-convert_ipv4_5tuple(struct ipv4_5tuple *key1,
-		union ipv4_5tuple_host *key2)
-{
-	key2->ip_dst = rte_cpu_to_be_32(key1->ip_dst);
-	key2->ip_src = rte_cpu_to_be_32(key1->ip_src);
-	key2->port_dst = rte_cpu_to_be_16(key1->port_dst);
-	key2->port_src = rte_cpu_to_be_16(key1->port_src);
-	key2->proto = key1->proto;
-	key2->pad0 = 0;
-	key2->pad1 = 0;
-}
-
-static void
-convert_ipv6_5tuple(struct ipv6_5tuple *key1,
-		union ipv6_5tuple_host *key2)
-{
-	uint32_t i;
-
-	for (i = 0; i < 16; i++) {
-		key2->ip_dst[i] = key1->ip_dst[i];
-		key2->ip_src[i] = key1->ip_src[i];
-	}
-	key2->port_dst = rte_cpu_to_be_16(key1->port_dst);
-	key2->port_src = rte_cpu_to_be_16(key1->port_src);
-	key2->proto = key1->proto;
-	key2->pad0 = 0;
-	key2->pad1 = 0;
-	key2->reserve = 0;
-}
-
-#define BYTE_VALUE_MAX 256
-#define ALL_32_BITS 0xffffffff
-#define BIT_8_TO_15 0x0000ff00
-
-static inline void
-populate_ipv4_few_flow_into_table(const struct rte_hash *h)
-{
-	uint32_t i;
-	int32_t ret;
-
-	mask0 = (rte_xmm_t){.u32 = {BIT_8_TO_15, ALL_32_BITS,
-				ALL_32_BITS, ALL_32_BITS} };
-
-	for (i = 0; i < IPV4_L3FWD_EM_NUM_ROUTES; i++) {
-		struct ipv4_l3fwd_em_route  entry;
-		union ipv4_5tuple_host newkey;
-
-		entry = ipv4_l3fwd_em_route_array[i];
-		convert_ipv4_5tuple(&entry.key, &newkey);
-		ret = rte_hash_add_key(h, (void *) &newkey);
-		if (ret < 0) {
-			rte_exit(EXIT_FAILURE, "Unable to add entry %" PRIu32
-				" to the l3fwd hash.\n", i);
-		}
-		ipv4_l3fwd_out_if[ret] = entry.if_out;
-	}
-	printf("Hash: Adding 0x%" PRIx64 " keys\n",
-		(uint64_t)IPV4_L3FWD_EM_NUM_ROUTES);
-}
-
-#define BIT_16_TO_23 0x00ff0000
-static inline void
-populate_ipv6_few_flow_into_table(const struct rte_hash *h)
-{
-	uint32_t i;
-	int32_t ret;
-
-	mask1 = (rte_xmm_t){.u32 = {BIT_16_TO_23, ALL_32_BITS,
-				ALL_32_BITS, ALL_32_BITS} };
-
-	mask2 = (rte_xmm_t){.u32 = {ALL_32_BITS, ALL_32_BITS, 0, 0} };
-
-	for (i = 0; i < IPV6_L3FWD_EM_NUM_ROUTES; i++) {
-		struct ipv6_l3fwd_em_route entry;
-		union ipv6_5tuple_host newkey;
-
-		entry = ipv6_l3fwd_em_route_array[i];
-		convert_ipv6_5tuple(&entry.key, &newkey);
-		ret = rte_hash_add_key(h, (void *) &newkey);
-		if (ret < 0) {
-			rte_exit(EXIT_FAILURE, "Unable to add entry %" PRIu32
-				" to the l3fwd hash.\n", i);
-		}
-		ipv6_l3fwd_out_if[ret] = entry.if_out;
-	}
-	printf("Hash: Adding 0x%" PRIx64 "keys\n",
-		(uint64_t)IPV6_L3FWD_EM_NUM_ROUTES);
-}
-
-#define NUMBER_PORT_USED 4
-static inline void
-populate_ipv4_many_flow_into_table(const struct rte_hash *h,
-		unsigned int nr_flow)
-{
-	unsigned i;
-
-	mask0 = (rte_xmm_t){.u32 = {BIT_8_TO_15, ALL_32_BITS,
-				ALL_32_BITS, ALL_32_BITS} };
-
-	for (i = 0; i < nr_flow; i++) {
-		struct ipv4_l3fwd_em_route entry;
-		union ipv4_5tuple_host newkey;
-
-		uint8_t a = (uint8_t)
-			((i/NUMBER_PORT_USED)%BYTE_VALUE_MAX);
-		uint8_t b = (uint8_t)
-			(((i/NUMBER_PORT_USED)/BYTE_VALUE_MAX)%BYTE_VALUE_MAX);
-		uint8_t c = (uint8_t)
-			((i/NUMBER_PORT_USED)/(BYTE_VALUE_MAX*BYTE_VALUE_MAX));
-
-		/* Create the ipv4 exact match flow */
-		memset(&entry, 0, sizeof(entry));
-		switch (i & (NUMBER_PORT_USED - 1)) {
-		case 0:
-			entry = ipv4_l3fwd_em_route_array[0];
-			entry.key.ip_dst = IPv4(101, c, b, a);
-			break;
-		case 1:
-			entry = ipv4_l3fwd_em_route_array[1];
-			entry.key.ip_dst = IPv4(201, c, b, a);
-			break;
-		case 2:
-			entry = ipv4_l3fwd_em_route_array[2];
-			entry.key.ip_dst = IPv4(111, c, b, a);
-			break;
-		case 3:
-			entry = ipv4_l3fwd_em_route_array[3];
-			entry.key.ip_dst = IPv4(211, c, b, a);
-			break;
-		};
-		convert_ipv4_5tuple(&entry.key, &newkey);
-		int32_t ret = rte_hash_add_key(h, (void *) &newkey);
-
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "Unable to add entry %u\n", i);
-
-		ipv4_l3fwd_out_if[ret] = (uint8_t) entry.if_out;
-
-	}
-	printf("Hash: Adding 0x%x keys\n", nr_flow);
-}
-
-static inline void
-populate_ipv6_many_flow_into_table(const struct rte_hash *h,
-		unsigned int nr_flow)
-{
-	unsigned i;
-
-	mask1 = (rte_xmm_t){.u32 = {BIT_16_TO_23, ALL_32_BITS,
-				ALL_32_BITS, ALL_32_BITS} };
-	mask2 = (rte_xmm_t){.u32 = {ALL_32_BITS, ALL_32_BITS, 0, 0} };
-
-	for (i = 0; i < nr_flow; i++) {
-		struct ipv6_l3fwd_em_route entry;
-		union ipv6_5tuple_host newkey;
-
-		uint8_t a = (uint8_t)
-			((i/NUMBER_PORT_USED)%BYTE_VALUE_MAX);
-		uint8_t b = (uint8_t)
-			(((i/NUMBER_PORT_USED)/BYTE_VALUE_MAX)%BYTE_VALUE_MAX);
-		uint8_t c = (uint8_t)
-			((i/NUMBER_PORT_USED)/(BYTE_VALUE_MAX*BYTE_VALUE_MAX));
-
-		/* Create the ipv6 exact match flow */
-		memset(&entry, 0, sizeof(entry));
-		switch (i & (NUMBER_PORT_USED - 1)) {
-		case 0:
-			entry = ipv6_l3fwd_em_route_array[0];
-			break;
-		case 1:
-			entry = ipv6_l3fwd_em_route_array[1];
-			break;
-		case 2:
-			entry = ipv6_l3fwd_em_route_array[2];
-			break;
-		case 3:
-			entry = ipv6_l3fwd_em_route_array[3];
-			break;
-		};
-		entry.key.ip_dst[13] = c;
-		entry.key.ip_dst[14] = b;
-		entry.key.ip_dst[15] = a;
-		convert_ipv6_5tuple(&entry.key, &newkey);
-		int32_t ret = rte_hash_add_key(h, (void *) &newkey);
-
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "Unable to add entry %u\n", i);
-
-		ipv6_l3fwd_out_if[ret] = (uint8_t) entry.if_out;
-
-	}
-	printf("Hash: Adding 0x%x keys\n", nr_flow);
-}
-
-/* Requirements:
- * 1. IP packets without extension;
- * 2. L4 payload should be either TCP or UDP.
- */
-int
-em_check_ptype(int portid)
-{
-	int i, ret;
-	int ptype_l3_ipv4_ext = 0;
-	int ptype_l3_ipv6_ext = 0;
-	int ptype_l4_tcp = 0;
-	int ptype_l4_udp = 0;
-	uint32_t ptype_mask = RTE_PTYPE_L3_MASK | RTE_PTYPE_L4_MASK;
-
-	ret = rte_eth_dev_get_supported_ptypes(portid, ptype_mask, NULL, 0);
-	if (ret <= 0)
-		return 0;
-
-	uint32_t ptypes[ret];
-
-	ret = rte_eth_dev_get_supported_ptypes(portid, ptype_mask, ptypes, ret);
-	for (i = 0; i < ret; ++i) {
-		switch (ptypes[i]) {
-		case RTE_PTYPE_L3_IPV4_EXT:
-			ptype_l3_ipv4_ext = 1;
-			break;
-		case RTE_PTYPE_L3_IPV6_EXT:
-			ptype_l3_ipv6_ext = 1;
-			break;
-		case RTE_PTYPE_L4_TCP:
-			ptype_l4_tcp = 1;
-			break;
-		case RTE_PTYPE_L4_UDP:
-			ptype_l4_udp = 1;
-			break;
-		}
-	}
-
-	if (ptype_l3_ipv4_ext == 0)
-		printf("port %d cannot parse RTE_PTYPE_L3_IPV4_EXT\n", portid);
-	if (ptype_l3_ipv6_ext == 0)
-		printf("port %d cannot parse RTE_PTYPE_L3_IPV6_EXT\n", portid);
-	if (!ptype_l3_ipv4_ext || !ptype_l3_ipv6_ext)
-		return 0;
-
-	if (ptype_l4_tcp == 0)
-		printf("port %d cannot parse RTE_PTYPE_L4_TCP\n", portid);
-	if (ptype_l4_udp == 0)
-		printf("port %d cannot parse RTE_PTYPE_L4_UDP\n", portid);
-	if (ptype_l4_tcp && ptype_l4_udp)
-		return 1;
-
-	return 0;
-}
-
-static inline void
-em_parse_ptype(struct rte_mbuf *m)
-{
-	struct ether_hdr *eth_hdr;
-	uint32_t packet_type = RTE_PTYPE_UNKNOWN;
-	uint16_t ether_type;
-	void *l3;
-	int hdr_len;
-	struct ipv4_hdr *ipv4_hdr;
-	struct ipv6_hdr *ipv6_hdr;
-
-	eth_hdr = rte_pktmbuf_mtod(m, struct ether_hdr *);
-	ether_type = eth_hdr->ether_type;
-	l3 = (uint8_t *)eth_hdr + sizeof(struct ether_hdr);
-	if (ether_type == rte_cpu_to_be_16(ETHER_TYPE_IPv4)) {
-		ipv4_hdr = (struct ipv4_hdr *)l3;
-		hdr_len = (ipv4_hdr->version_ihl & IPV4_HDR_IHL_MASK) *
-			  IPV4_IHL_MULTIPLIER;
-		if (hdr_len == sizeof(struct ipv4_hdr)) {
-			packet_type |= RTE_PTYPE_L3_IPV4;
-			if (ipv4_hdr->next_proto_id == IPPROTO_TCP)
-				packet_type |= RTE_PTYPE_L4_TCP;
-			else if (ipv4_hdr->next_proto_id == IPPROTO_UDP)
-				packet_type |= RTE_PTYPE_L4_UDP;
-		} else
-			packet_type |= RTE_PTYPE_L3_IPV4_EXT;
-	} else if (ether_type == rte_cpu_to_be_16(ETHER_TYPE_IPv6)) {
-		ipv6_hdr = (struct ipv6_hdr *)l3;
-		if (ipv6_hdr->proto == IPPROTO_TCP)
-			packet_type |= RTE_PTYPE_L3_IPV6 | RTE_PTYPE_L4_TCP;
-		else if (ipv6_hdr->proto == IPPROTO_UDP)
-			packet_type |= RTE_PTYPE_L3_IPV6 | RTE_PTYPE_L4_UDP;
-		else
-			packet_type |= RTE_PTYPE_L3_IPV6_EXT_UNKNOWN;
-	}
-
-	m->packet_type = packet_type;
-}
-
-uint16_t
-em_cb_parse_ptype(uint16_t port __rte_unused, uint16_t queue __rte_unused,
-		  struct rte_mbuf *pkts[], uint16_t nb_pkts,
-		  uint16_t max_pkts __rte_unused,
-		  void *user_param __rte_unused)
-{
-	unsigned i;
-
-	for (i = 0; i < nb_pkts; ++i)
-		em_parse_ptype(pkts[i]);
-
-	return nb_pkts;
-}
-
-/* main processing loop */
-int
-em_main_loop(__attribute__((unused)) void *dummy)
-{
-	struct rte_mbuf *pkts_burst[MAX_PKT_BURST];
-	unsigned lcore_id;
-	uint64_t prev_tsc, diff_tsc, cur_tsc;
-	int i, nb_rx;
-	uint8_t queueid;
-	uint16_t portid;
-	struct lcore_conf *qconf;
-	const uint64_t drain_tsc = (rte_get_tsc_hz() + US_PER_S - 1) /
-		US_PER_S * BURST_TX_DRAIN_US;
-
-	prev_tsc = 0;
-
-	lcore_id = rte_lcore_id();
-	qconf = &lcore_conf[lcore_id];
-
-	if (qconf->n_rx_queue == 0) {
-		RTE_LOG(INFO, L3FWD, "lcore %u has nothing to do\n", lcore_id);
-		return 0;
-	}
-
-	RTE_LOG(INFO, L3FWD, "entering main loop on lcore %u\n", lcore_id);
-
-	for (i = 0; i < qconf->n_rx_queue; i++) {
-
-		portid = qconf->rx_queue_list[i].port_id;
-		queueid = qconf->rx_queue_list[i].queue_id;
-		RTE_LOG(INFO, L3FWD,
-			" -- lcoreid=%u portid=%u rxqueueid=%hhu\n",
-			lcore_id, portid, queueid);
-	}
-
-	while (!force_quit) {
-
-		cur_tsc = rte_rdtsc();
-
-		/*
-		 * TX burst queue drain
-		 */
-		diff_tsc = cur_tsc - prev_tsc;
-		if (unlikely(diff_tsc > drain_tsc)) {
-
-			for (i = 0; i < qconf->n_tx_port; ++i) {
-				portid = qconf->tx_port_id[i];
-				if (qconf->tx_mbufs[portid].len == 0)
-					continue;
-				send_burst(qconf,
-					qconf->tx_mbufs[portid].len,
-					portid);
-				qconf->tx_mbufs[portid].len = 0;
-			}
-
-			prev_tsc = cur_tsc;
-		}
-
-		/*
-		 * Read packet from RX queues
-		 */
-		for (i = 0; i < qconf->n_rx_queue; ++i) {
-			portid = qconf->rx_queue_list[i].port_id;
-			queueid = qconf->rx_queue_list[i].queue_id;
-			nb_rx = rte_eth_rx_burst(portid, queueid, pkts_burst,
-				MAX_PKT_BURST);
-			if (nb_rx == 0)
-				continue;
-
-#if defined RTE_ARCH_X86 || defined RTE_MACHINE_CPUFLAG_NEON
-			l3fwd_em_send_packets(nb_rx, pkts_burst,
-							portid, qconf);
-#else
-			l3fwd_em_no_opt_send_packets(nb_rx, pkts_burst,
-							portid, qconf);
-#endif
-		}
-	}
-
-	return 0;
-}
-
-/*
- * Initialize exact match (hash) parameters.
- */
-void
-setup_hash(const int socketid)
-{
-	struct rte_hash_parameters ipv4_l3fwd_hash_params = {
-		.name = NULL,
-		.entries = L3FWD_HASH_ENTRIES,
-		.key_len = sizeof(union ipv4_5tuple_host),
-		.hash_func = ipv4_hash_crc,
-		.hash_func_init_val = 0,
-	};
-
-	struct rte_hash_parameters ipv6_l3fwd_hash_params = {
-		.name = NULL,
-		.entries = L3FWD_HASH_ENTRIES,
-		.key_len = sizeof(union ipv6_5tuple_host),
-		.hash_func = ipv6_hash_crc,
-		.hash_func_init_val = 0,
-	};
-
-	char s[64];
-
-	/* create ipv4 hash */
-	snprintf(s, sizeof(s), "ipv4_l3fwd_hash_%d", socketid);
-	ipv4_l3fwd_hash_params.name = s;
-	ipv4_l3fwd_hash_params.socket_id = socketid;
-	ipv4_l3fwd_em_lookup_struct[socketid] =
-		rte_hash_create(&ipv4_l3fwd_hash_params);
-	if (ipv4_l3fwd_em_lookup_struct[socketid] == NULL)
-		rte_exit(EXIT_FAILURE,
-			"Unable to create the l3fwd hash on socket %d\n",
-			socketid);
-
-	/* create ipv6 hash */
-	snprintf(s, sizeof(s), "ipv6_l3fwd_hash_%d", socketid);
-	ipv6_l3fwd_hash_params.name = s;
-	ipv6_l3fwd_hash_params.socket_id = socketid;
-	ipv6_l3fwd_em_lookup_struct[socketid] =
-		rte_hash_create(&ipv6_l3fwd_hash_params);
-	if (ipv6_l3fwd_em_lookup_struct[socketid] == NULL)
-		rte_exit(EXIT_FAILURE,
-			"Unable to create the l3fwd hash on socket %d\n",
-			socketid);
-
-	if (hash_entry_number != HASH_ENTRY_NUMBER_DEFAULT) {
-		/* For testing hash matching with a large number of flows we
-		 * generate millions of IP 5-tuples with an incremented dst
-		 * address to initialize the hash table. */
-		if (ipv6 == 0) {
-			/* populate the ipv4 hash */
-			populate_ipv4_many_flow_into_table(
-				ipv4_l3fwd_em_lookup_struct[socketid],
-				hash_entry_number);
-		} else {
-			/* populate the ipv6 hash */
-			populate_ipv6_many_flow_into_table(
-				ipv6_l3fwd_em_lookup_struct[socketid],
-				hash_entry_number);
-		}
-	} else {
-		/*
-		 * Use data in ipv4/ipv6 l3fwd lookup table
-		 * directly to initialize the hash table.
-		 */
-		if (ipv6 == 0) {
-			/* populate the ipv4 hash */
-			populate_ipv4_few_flow_into_table(
-				ipv4_l3fwd_em_lookup_struct[socketid]);
-		} else {
-			/* populate the ipv6 hash */
-			populate_ipv6_few_flow_into_table(
-				ipv6_l3fwd_em_lookup_struct[socketid]);
-		}
-	}
-}
-
-/* Return ipv4/ipv6 em fwd lookup struct. */
-void *
-em_get_ipv4_l3fwd_lookup_struct(const int socketid)
-{
-	return ipv4_l3fwd_em_lookup_struct[socketid];
-}
-
-void *
-em_get_ipv6_l3fwd_lookup_struct(const int socketid)
-{
-	return ipv6_l3fwd_em_lookup_struct[socketid];
-}
diff --git a/examples/l3fwd/l3fwd_em.h b/examples/l3fwd/l3fwd_em.h
deleted file mode 100644
index 228164e..0000000
--- a/examples/l3fwd/l3fwd_em.h
+++ /dev/null
@@ -1,109 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#ifndef __L3FWD_EM_H__
-#define __L3FWD_EM_H__
-
-static __rte_always_inline void
-l3fwd_em_simple_forward(struct rte_mbuf *m, uint16_t portid,
-		struct lcore_conf *qconf)
-{
-	struct ether_hdr *eth_hdr;
-	struct ipv4_hdr *ipv4_hdr;
-	uint16_t dst_port;
-	uint32_t tcp_or_udp;
-	uint32_t l3_ptypes;
-
-	eth_hdr = rte_pktmbuf_mtod(m, struct ether_hdr *);
-	tcp_or_udp = m->packet_type & (RTE_PTYPE_L4_TCP | RTE_PTYPE_L4_UDP);
-	l3_ptypes = m->packet_type & RTE_PTYPE_L3_MASK;
-
-	if (tcp_or_udp && (l3_ptypes == RTE_PTYPE_L3_IPV4)) {
-		/* Handle IPv4 headers.*/
-		ipv4_hdr = rte_pktmbuf_mtod_offset(m, struct ipv4_hdr *,
-						   sizeof(struct ether_hdr));
-
-#ifdef DO_RFC_1812_CHECKS
-		/* Check to make sure the packet is valid (RFC1812) */
-		if (is_valid_ipv4_pkt(ipv4_hdr, m->pkt_len) < 0) {
-			rte_pktmbuf_free(m);
-			return;
-		}
-#endif
-		dst_port = em_get_ipv4_dst_port(ipv4_hdr, portid,
-						qconf->ipv4_lookup_struct);
-
-		if (dst_port >= RTE_MAX_ETHPORTS ||
-			(enabled_port_mask & 1 << dst_port) == 0)
-			dst_port = portid;
-
-#ifdef DO_RFC_1812_CHECKS
-		/* Update time to live and header checksum */
-		--(ipv4_hdr->time_to_live);
-		++(ipv4_hdr->hdr_checksum);
-#endif
-		/* dst addr */
-		*(uint64_t *)&eth_hdr->d_addr = dest_eth_addr[dst_port];
-
-		/* src addr */
-		ether_addr_copy(&ports_eth_addr[dst_port], &eth_hdr->s_addr);
-
-		send_single_packet(qconf, m, dst_port);
-	} else if (tcp_or_udp && (l3_ptypes == RTE_PTYPE_L3_IPV6)) {
-		/* Handle IPv6 headers.*/
-		struct ipv6_hdr *ipv6_hdr;
-
-		ipv6_hdr = rte_pktmbuf_mtod_offset(m, struct ipv6_hdr *,
-						   sizeof(struct ether_hdr));
-
-		dst_port = em_get_ipv6_dst_port(ipv6_hdr, portid,
-					qconf->ipv6_lookup_struct);
-
-		if (dst_port >= RTE_MAX_ETHPORTS ||
-			(enabled_port_mask & 1 << dst_port) == 0)
-			dst_port = portid;
-
-		/* dst addr */
-		*(uint64_t *)&eth_hdr->d_addr = dest_eth_addr[dst_port];
-
-		/* src addr */
-		ether_addr_copy(&ports_eth_addr[dst_port], &eth_hdr->s_addr);
-
-		send_single_packet(qconf, m, dst_port);
-	} else {
-		/* Free the mbuf that contains non-IPV4/IPV6 packet */
-		rte_pktmbuf_free(m);
-	}
-}
-
-/*
- * Buffer non-optimized handling of packets, invoked
- * from main_loop.
- */
-static inline void
-l3fwd_em_no_opt_send_packets(int nb_rx, struct rte_mbuf **pkts_burst,
-			uint16_t portid, struct lcore_conf *qconf)
-{
-	int32_t j;
-
-	/* Prefetch first packets */
-	for (j = 0; j < PREFETCH_OFFSET && j < nb_rx; j++)
-		rte_prefetch0(rte_pktmbuf_mtod(pkts_burst[j], void *));
-
-	/*
-	 * Prefetch and forward already prefetched
-	 * packets.
-	 */
-	for (j = 0; j < (nb_rx - PREFETCH_OFFSET); j++) {
-		rte_prefetch0(rte_pktmbuf_mtod(pkts_burst[
-				j + PREFETCH_OFFSET], void *));
-		l3fwd_em_simple_forward(pkts_burst[j], portid, qconf);
-	}
-
-	/* Forward remaining prefetched packets */
-	for (; j < nb_rx; j++)
-		l3fwd_em_simple_forward(pkts_burst[j], portid, qconf);
-}
-
-#endif /* __L3FWD_EM_H__ */
diff --git a/examples/l3fwd/l3fwd_em_hlm.h b/examples/l3fwd/l3fwd_em_hlm.h
deleted file mode 100644
index 9d7afe0..0000000
--- a/examples/l3fwd/l3fwd_em_hlm.h
+++ /dev/null
@@ -1,218 +0,0 @@
-/*-
- *   BSD LICENSE
- *
- *   Copyright(c) 2016 Intel Corporation. All rights reserved.
- *   Copyright(c) 2017, Linaro Limited
- *   All rights reserved.
- *
- *   Redistribution and use in source and binary forms, with or without
- *   modification, are permitted provided that the following conditions
- *   are met:
- *
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above copyright
- *       notice, this list of conditions and the following disclaimer in
- *       the documentation and/or other materials provided with the
- *       distribution.
- *     * Neither the name of Intel Corporation nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#ifndef __L3FWD_EM_HLM_H__
-#define __L3FWD_EM_HLM_H__
-
-#if defined RTE_ARCH_X86
-#include "l3fwd_sse.h"
-#include "l3fwd_em_hlm_sse.h"
-#elif defined RTE_MACHINE_CPUFLAG_NEON
-#include "l3fwd_neon.h"
-#include "l3fwd_em_hlm_neon.h"
-#endif
-
-#ifdef RTE_ARCH_ARM64
-#define EM_HASH_LOOKUP_COUNT 16
-#else
-#define EM_HASH_LOOKUP_COUNT 8
-#endif
-
-
-static __rte_always_inline void
-em_get_dst_port_ipv4xN(struct lcore_conf *qconf, struct rte_mbuf *m[],
-		uint16_t portid, uint16_t dst_port[])
-{
-	int i;
-	int32_t ret[EM_HASH_LOOKUP_COUNT];
-	union ipv4_5tuple_host key[EM_HASH_LOOKUP_COUNT];
-	const void *key_array[EM_HASH_LOOKUP_COUNT];
-
-	for (i = 0; i < EM_HASH_LOOKUP_COUNT; i++) {
-		get_ipv4_5tuple(m[i], mask0.x, &key[i]);
-		key_array[i] = &key[i];
-	}
-
-	rte_hash_lookup_bulk(qconf->ipv4_lookup_struct, &key_array[0],
-			     EM_HASH_LOOKUP_COUNT, ret);
-
-	for (i = 0; i < EM_HASH_LOOKUP_COUNT; i++) {
-		dst_port[i] = ((ret[i] < 0) ?
-				portid : ipv4_l3fwd_out_if[ret[i]]);
-
-		if (dst_port[i] >= RTE_MAX_ETHPORTS ||
-				(enabled_port_mask & 1 << dst_port[i]) == 0)
-			dst_port[i] = portid;
-	}
-}
-
-static __rte_always_inline void
-em_get_dst_port_ipv6xN(struct lcore_conf *qconf, struct rte_mbuf *m[],
-		uint16_t portid, uint16_t dst_port[])
-{
-	int i;
-	int32_t ret[EM_HASH_LOOKUP_COUNT];
-	union ipv6_5tuple_host key[EM_HASH_LOOKUP_COUNT];
-	const void *key_array[EM_HASH_LOOKUP_COUNT];
-
-	for (i = 0; i < EM_HASH_LOOKUP_COUNT; i++) {
-		get_ipv6_5tuple(m[i], mask1.x, mask2.x, &key[i]);
-		key_array[i] = &key[i];
-	}
-
-	rte_hash_lookup_bulk(qconf->ipv6_lookup_struct, &key_array[0],
-			     EM_HASH_LOOKUP_COUNT, ret);
-
-	for (i = 0; i < EM_HASH_LOOKUP_COUNT; i++) {
-		dst_port[i] = ((ret[i] < 0) ?
-				portid : ipv6_l3fwd_out_if[ret[i]]);
-
-		if (dst_port[i] >= RTE_MAX_ETHPORTS ||
-				(enabled_port_mask & 1 << dst_port[i]) == 0)
-			dst_port[i] = portid;
-	}
-}
-
-static __rte_always_inline uint16_t
-em_get_dst_port(const struct lcore_conf *qconf, struct rte_mbuf *pkt,
-		uint16_t portid)
-{
-	uint16_t next_hop;
-	struct ipv4_hdr *ipv4_hdr;
-	struct ipv6_hdr *ipv6_hdr;
-	uint32_t tcp_or_udp;
-	uint32_t l3_ptypes;
-
-	tcp_or_udp = pkt->packet_type & (RTE_PTYPE_L4_TCP | RTE_PTYPE_L4_UDP);
-	l3_ptypes = pkt->packet_type & RTE_PTYPE_L3_MASK;
-
-	if (tcp_or_udp && (l3_ptypes == RTE_PTYPE_L3_IPV4)) {
-
-		/* Handle IPv4 headers.*/
-		ipv4_hdr = rte_pktmbuf_mtod_offset(pkt, struct ipv4_hdr *,
-				sizeof(struct ether_hdr));
-
-		next_hop = em_get_ipv4_dst_port(ipv4_hdr, portid,
-				qconf->ipv4_lookup_struct);
-
-		if (next_hop >= RTE_MAX_ETHPORTS ||
-				(enabled_port_mask & 1 << next_hop) == 0)
-			next_hop = portid;
-
-		return next_hop;
-
-	} else if (tcp_or_udp && (l3_ptypes == RTE_PTYPE_L3_IPV6)) {
-
-		/* Handle IPv6 headers.*/
-		ipv6_hdr = rte_pktmbuf_mtod_offset(pkt, struct ipv6_hdr *,
-				sizeof(struct ether_hdr));
-
-		next_hop = em_get_ipv6_dst_port(ipv6_hdr, portid,
-				qconf->ipv6_lookup_struct);
-
-		if (next_hop >= RTE_MAX_ETHPORTS ||
-				(enabled_port_mask & 1 << next_hop) == 0)
-			next_hop = portid;
-
-		return next_hop;
-
-	}
-
-	return portid;
-}
-
-/*
- * Buffer optimized handling of packets, invoked
- * from main_loop.
- */
-static inline void
-l3fwd_em_send_packets(int nb_rx, struct rte_mbuf **pkts_burst,
-		uint16_t portid, struct lcore_conf *qconf)
-{
-	int32_t i, j, pos;
-	uint16_t dst_port[MAX_PKT_BURST];
-
-	/*
-	 * Send nb_rx - nb_rx % EM_HASH_LOOKUP_COUNT packets
-	 * in groups of EM_HASH_LOOKUP_COUNT.
-	 */
-	int32_t n = RTE_ALIGN_FLOOR(nb_rx, EM_HASH_LOOKUP_COUNT);
-
-	for (j = 0; j < EM_HASH_LOOKUP_COUNT && j < nb_rx; j++) {
-		rte_prefetch0(rte_pktmbuf_mtod(pkts_burst[j],
-					       struct ether_hdr *) + 1);
-	}
-
-	for (j = 0; j < n; j += EM_HASH_LOOKUP_COUNT) {
-
-		uint32_t pkt_type = RTE_PTYPE_L3_MASK |
-				    RTE_PTYPE_L4_TCP | RTE_PTYPE_L4_UDP;
-		uint32_t l3_type, tcp_or_udp;
-
-		for (i = 0; i < EM_HASH_LOOKUP_COUNT; i++)
-			pkt_type &= pkts_burst[j + i]->packet_type;
-
-		l3_type = pkt_type & RTE_PTYPE_L3_MASK;
-		tcp_or_udp = pkt_type & (RTE_PTYPE_L4_TCP | RTE_PTYPE_L4_UDP);
-
-		for (i = 0, pos = j + EM_HASH_LOOKUP_COUNT;
-		     i < EM_HASH_LOOKUP_COUNT && pos < nb_rx; i++, pos++) {
-			rte_prefetch0(rte_pktmbuf_mtod(pkts_burst[pos],
-						       struct ether_hdr *) + 1);
-		}
-
-		if (tcp_or_udp && (l3_type == RTE_PTYPE_L3_IPV4)) {
-
-			em_get_dst_port_ipv4xN(qconf, &pkts_burst[j], portid,
-					       &dst_port[j]);
-
-		} else if (tcp_or_udp && (l3_type == RTE_PTYPE_L3_IPV6)) {
-
-			em_get_dst_port_ipv6xN(qconf, &pkts_burst[j], portid,
-					       &dst_port[j]);
-
-		} else {
-			for (i = 0; i < EM_HASH_LOOKUP_COUNT; i++)
-				dst_port[j + i] = em_get_dst_port(qconf,
-						pkts_burst[j + i], portid);
-		}
-	}
-
-	for (; j < nb_rx; j++)
-		dst_port[j] = em_get_dst_port(qconf, pkts_burst[j], portid);
-
-	send_packets_multi(qconf, pkts_burst, dst_port, nb_rx);
-
-}
-#endif /* __L3FWD_EM_HLM_H__ */
diff --git a/examples/l3fwd/l3fwd_em_hlm_neon.h b/examples/l3fwd/l3fwd_em_hlm_neon.h
deleted file mode 100644
index dae1acf..0000000
--- a/examples/l3fwd/l3fwd_em_hlm_neon.h
+++ /dev/null
@@ -1,74 +0,0 @@
-/*-
- *   BSD LICENSE
- *
- *   Copyright(c) 2016 Intel Corporation. All rights reserved.
- *   Copyright(c) 2017, Linaro Limited
- *   All rights reserved.
- *
- *   Redistribution and use in source and binary forms, with or without
- *   modification, are permitted provided that the following conditions
- *   are met:
- *
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above copyright
- *       notice, this list of conditions and the following disclaimer in
- *       the documentation and/or other materials provided with the
- *       distribution.
- *     * Neither the name of Intel Corporation nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#ifndef __L3FWD_EM_HLM_NEON_H__
-#define __L3FWD_EM_HLM_NEON_H__
-
-#include <arm_neon.h>
-
-static inline void
-get_ipv4_5tuple(struct rte_mbuf *m0, int32x4_t mask0,
-		union ipv4_5tuple_host *key)
-{
-	int32x4_t tmpdata0 = vld1q_s32(rte_pktmbuf_mtod_offset(m0, int32_t *,
-				sizeof(struct ether_hdr) +
-				offsetof(struct ipv4_hdr, time_to_live)));
-
-	key->xmm = vandq_s32(tmpdata0, mask0);
-}
-
-static inline void
-get_ipv6_5tuple(struct rte_mbuf *m0, int32x4_t mask0,
-		int32x4_t mask1, union ipv6_5tuple_host *key)
-{
-	int32x4_t tmpdata0 = vld1q_s32(
-			rte_pktmbuf_mtod_offset(m0, int *,
-				sizeof(struct ether_hdr) +
-				offsetof(struct ipv6_hdr, payload_len)));
-
-	int32x4_t tmpdata1 = vld1q_s32(
-			rte_pktmbuf_mtod_offset(m0, int *,
-				sizeof(struct ether_hdr) +
-				offsetof(struct ipv6_hdr, payload_len) + 8));
-
-	int32x4_t tmpdata2 = vld1q_s32(
-			rte_pktmbuf_mtod_offset(m0, int *,
-				sizeof(struct ether_hdr) +
-				offsetof(struct ipv6_hdr, payload_len) + 16));
-
-	key->xmm[0] = vandq_s32(tmpdata0, mask0);
-	key->xmm[1] = tmpdata1;
-	key->xmm[2] = vandq_s32(tmpdata2, mask1);
-}
-#endif /* __L3FWD_EM_HLM_NEON_H__ */
diff --git a/examples/l3fwd/l3fwd_em_hlm_sse.h b/examples/l3fwd/l3fwd_em_hlm_sse.h
deleted file mode 100644
index 41e2be9..0000000
--- a/examples/l3fwd/l3fwd_em_hlm_sse.h
+++ /dev/null
@@ -1,47 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016 Intel Corporation
- */
-
-#ifndef __L3FWD_EM_HLM_SSE_H__
-#define __L3FWD_EM_HLM_SSE_H__
-
-#include "l3fwd_sse.h"
-
-static __rte_always_inline void
-get_ipv4_5tuple(struct rte_mbuf *m0, __m128i mask0,
-		union ipv4_5tuple_host *key)
-{
-	 __m128i tmpdata0 = _mm_loadu_si128(
-			rte_pktmbuf_mtod_offset(m0, __m128i *,
-				sizeof(struct ether_hdr) +
-				offsetof(struct ipv4_hdr, time_to_live)));
-
-	key->xmm = _mm_and_si128(tmpdata0, mask0);
-}
-
-static inline void
-get_ipv6_5tuple(struct rte_mbuf *m0, __m128i mask0,
-		__m128i mask1, union ipv6_5tuple_host *key)
-{
-	__m128i tmpdata0 = _mm_loadu_si128(
-			rte_pktmbuf_mtod_offset(m0, __m128i *,
-				sizeof(struct ether_hdr) +
-				offsetof(struct ipv6_hdr, payload_len)));
-
-	__m128i tmpdata1 = _mm_loadu_si128(
-			rte_pktmbuf_mtod_offset(m0, __m128i *,
-				sizeof(struct ether_hdr) +
-				offsetof(struct ipv6_hdr, payload_len) +
-				sizeof(__m128i)));
-
-	__m128i tmpdata2 = _mm_loadu_si128(
-			rte_pktmbuf_mtod_offset(m0, __m128i *,
-				sizeof(struct ether_hdr) +
-				offsetof(struct ipv6_hdr, payload_len) +
-				sizeof(__m128i) + sizeof(__m128i)));
-
-	key->xmm[0] = _mm_and_si128(tmpdata0, mask0);
-	key->xmm[1] = tmpdata1;
-	key->xmm[2] = _mm_and_si128(tmpdata2, mask1);
-}
-#endif /* __L3FWD_EM_SSE_HLM_H__ */
diff --git a/examples/l3fwd/l3fwd_em_sequential.h b/examples/l3fwd/l3fwd_em_sequential.h
deleted file mode 100644
index 35cf5ea..0000000
--- a/examples/l3fwd/l3fwd_em_sequential.h
+++ /dev/null
@@ -1,97 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#ifndef __L3FWD_EM_SEQUENTIAL_H__
-#define __L3FWD_EM_SEQUENTIAL_H__
-
-/**
- * @file
- * This is an optional implementation of packet classification in Exact-Match
- * path using sequential packet classification method.
- * While hash lookup multi seems to provide better performance, it's disabled
- * by default and can be enabled with NO_HASH_LOOKUP_MULTI global define in
- * compilation time.
- */
-
-#if defined RTE_ARCH_X86
-#include "l3fwd_sse.h"
-#elif defined RTE_MACHINE_CPUFLAG_NEON
-#include "l3fwd_neon.h"
-#endif
-
-static __rte_always_inline uint16_t
-em_get_dst_port(const struct lcore_conf *qconf, struct rte_mbuf *pkt,
-		uint16_t portid)
-{
-	uint8_t next_hop;
-	struct ipv4_hdr *ipv4_hdr;
-	struct ipv6_hdr *ipv6_hdr;
-	uint32_t tcp_or_udp;
-	uint32_t l3_ptypes;
-
-	tcp_or_udp = pkt->packet_type & (RTE_PTYPE_L4_TCP | RTE_PTYPE_L4_UDP);
-	l3_ptypes = pkt->packet_type & RTE_PTYPE_L3_MASK;
-
-	if (tcp_or_udp && (l3_ptypes == RTE_PTYPE_L3_IPV4)) {
-
-		/* Handle IPv4 headers.*/
-		ipv4_hdr = rte_pktmbuf_mtod_offset(pkt, struct ipv4_hdr *,
-				sizeof(struct ether_hdr));
-
-		next_hop = em_get_ipv4_dst_port(ipv4_hdr, portid,
-				qconf->ipv4_lookup_struct);
-
-		if (next_hop >= RTE_MAX_ETHPORTS ||
-				(enabled_port_mask & 1 << next_hop) == 0)
-			next_hop = portid;
-
-		return next_hop;
-
-	} else if (tcp_or_udp && (l3_ptypes == RTE_PTYPE_L3_IPV6)) {
-
-		/* Handle IPv6 headers.*/
-		ipv6_hdr = rte_pktmbuf_mtod_offset(pkt, struct ipv6_hdr *,
-				sizeof(struct ether_hdr));
-
-		next_hop = em_get_ipv6_dst_port(ipv6_hdr, portid,
-				qconf->ipv6_lookup_struct);
-
-		if (next_hop >= RTE_MAX_ETHPORTS ||
-				(enabled_port_mask & 1 << next_hop) == 0)
-			next_hop = portid;
-
-		return next_hop;
-
-	}
-
-	return portid;
-}
-
-/*
- * Buffer optimized handling of packets, invoked
- * from main_loop.
- */
-static inline void
-l3fwd_em_send_packets(int nb_rx, struct rte_mbuf **pkts_burst,
-			uint16_t portid, struct lcore_conf *qconf)
-{
-	int32_t i, j;
-	uint16_t dst_port[MAX_PKT_BURST];
-
-	if (nb_rx > 0) {
-		rte_prefetch0(rte_pktmbuf_mtod(pkts_burst[0],
-					       struct ether_hdr *) + 1);
-	}
-
-	for (i = 1, j = 0; j < nb_rx; i++, j++) {
-		if (i < nb_rx) {
-			rte_prefetch0(rte_pktmbuf_mtod(pkts_burst[i],
-						       struct ether_hdr *) + 1);
-		}
-		dst_port[j] = em_get_dst_port(qconf, pkts_burst[j], portid);
-	}
-
-	send_packets_multi(qconf, pkts_burst, dst_port, nb_rx);
-}
-#endif /* __L3FWD_EM_SEQUENTIAL_H__ */
diff --git a/examples/l3fwd/l3fwd_lpm.c b/examples/l3fwd/l3fwd_lpm.c
deleted file mode 100644
index a747126..0000000
--- a/examples/l3fwd/l3fwd_lpm.c
+++ /dev/null
@@ -1,415 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <sys/types.h>
-#include <string.h>
-#include <sys/queue.h>
-#include <stdarg.h>
-#include <errno.h>
-#include <getopt.h>
-#include <stdbool.h>
-
-#include <rte_debug.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_mempool.h>
-#include <rte_cycles.h>
-#include <rte_mbuf.h>
-#include <rte_ip.h>
-#include <rte_tcp.h>
-#include <rte_udp.h>
-#include <rte_lpm.h>
-#include <rte_lpm6.h>
-
-#include "l3fwd.h"
-
-struct ipv4_l3fwd_lpm_route {
-	uint32_t ip;
-	uint8_t  depth;
-	uint8_t  if_out;
-};
-
-struct ipv6_l3fwd_lpm_route {
-	uint8_t ip[16];
-	uint8_t  depth;
-	uint8_t  if_out;
-};
-
-static struct ipv4_l3fwd_lpm_route ipv4_l3fwd_lpm_route_array[] = {
-	{IPv4(1, 1, 1, 0), 24, 0},
-	{IPv4(2, 1, 1, 0), 24, 1},
-	{IPv4(3, 1, 1, 0), 24, 2},
-	{IPv4(4, 1, 1, 0), 24, 3},
-	{IPv4(5, 1, 1, 0), 24, 4},
-	{IPv4(6, 1, 1, 0), 24, 5},
-	{IPv4(7, 1, 1, 0), 24, 6},
-	{IPv4(8, 1, 1, 0), 24, 7},
-};
-
-static struct ipv6_l3fwd_lpm_route ipv6_l3fwd_lpm_route_array[] = {
-	{{1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1}, 48, 0},
-	{{2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1}, 48, 1},
-	{{3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1}, 48, 2},
-	{{4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1}, 48, 3},
-	{{5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1}, 48, 4},
-	{{6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1}, 48, 5},
-	{{7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1}, 48, 6},
-	{{8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1}, 48, 7},
-};
-
-#define IPV4_L3FWD_LPM_NUM_ROUTES \
-	(sizeof(ipv4_l3fwd_lpm_route_array) / sizeof(ipv4_l3fwd_lpm_route_array[0]))
-#define IPV6_L3FWD_LPM_NUM_ROUTES \
-	(sizeof(ipv6_l3fwd_lpm_route_array) / sizeof(ipv6_l3fwd_lpm_route_array[0]))
-
-#define IPV4_L3FWD_LPM_MAX_RULES         1024
-#define IPV4_L3FWD_LPM_NUMBER_TBL8S (1 << 8)
-#define IPV6_L3FWD_LPM_MAX_RULES         1024
-#define IPV6_L3FWD_LPM_NUMBER_TBL8S (1 << 16)
-
-struct rte_lpm *ipv4_l3fwd_lpm_lookup_struct[NB_SOCKETS];
-struct rte_lpm6 *ipv6_l3fwd_lpm_lookup_struct[NB_SOCKETS];
-
-static inline uint16_t
-lpm_get_ipv4_dst_port(void *ipv4_hdr, uint16_t portid, void *lookup_struct)
-{
-	uint32_t next_hop;
-	struct rte_lpm *ipv4_l3fwd_lookup_struct =
-		(struct rte_lpm *)lookup_struct;
-
-	return (uint16_t) ((rte_lpm_lookup(ipv4_l3fwd_lookup_struct,
-		rte_be_to_cpu_32(((struct ipv4_hdr *)ipv4_hdr)->dst_addr),
-		&next_hop) == 0) ? next_hop : portid);
-}
-
-static inline uint16_t
-lpm_get_ipv6_dst_port(void *ipv6_hdr, uint16_t portid, void *lookup_struct)
-{
-	uint32_t next_hop;
-	struct rte_lpm6 *ipv6_l3fwd_lookup_struct =
-		(struct rte_lpm6 *)lookup_struct;
-
-	return (uint16_t) ((rte_lpm6_lookup(ipv6_l3fwd_lookup_struct,
-			((struct ipv6_hdr *)ipv6_hdr)->dst_addr,
-			&next_hop) == 0) ?  next_hop : portid);
-}
-
-static __rte_always_inline uint16_t
-lpm_get_dst_port(const struct lcore_conf *qconf, struct rte_mbuf *pkt,
-		uint16_t portid)
-{
-	struct ipv6_hdr *ipv6_hdr;
-	struct ipv4_hdr *ipv4_hdr;
-	struct ether_hdr *eth_hdr;
-
-	if (RTE_ETH_IS_IPV4_HDR(pkt->packet_type)) {
-
-		eth_hdr = rte_pktmbuf_mtod(pkt, struct ether_hdr *);
-		ipv4_hdr = (struct ipv4_hdr *)(eth_hdr + 1);
-
-		return lpm_get_ipv4_dst_port(ipv4_hdr, portid,
-					     qconf->ipv4_lookup_struct);
-	} else if (RTE_ETH_IS_IPV6_HDR(pkt->packet_type)) {
-
-		eth_hdr = rte_pktmbuf_mtod(pkt, struct ether_hdr *);
-		ipv6_hdr = (struct ipv6_hdr *)(eth_hdr + 1);
-
-		return lpm_get_ipv6_dst_port(ipv6_hdr, portid,
-					     qconf->ipv6_lookup_struct);
-	}
-
-	return portid;
-}
-
-/*
- * lpm_get_dst_port optimized routine for packets where dst_ipv4 is already
- * precalculated. If packet is ipv6 dst_addr is taken directly from packet
- * header and dst_ipv4 value is not used.
- */
-static __rte_always_inline uint16_t
-lpm_get_dst_port_with_ipv4(const struct lcore_conf *qconf, struct rte_mbuf *pkt,
-	uint32_t dst_ipv4, uint16_t portid)
-{
-	uint32_t next_hop;
-	struct ipv6_hdr *ipv6_hdr;
-	struct ether_hdr *eth_hdr;
-
-	if (RTE_ETH_IS_IPV4_HDR(pkt->packet_type)) {
-		return (uint16_t) ((rte_lpm_lookup(qconf->ipv4_lookup_struct,
-						   dst_ipv4, &next_hop) == 0)
-				   ? next_hop : portid);
-
-	} else if (RTE_ETH_IS_IPV6_HDR(pkt->packet_type)) {
-
-		eth_hdr = rte_pktmbuf_mtod(pkt, struct ether_hdr *);
-		ipv6_hdr = (struct ipv6_hdr *)(eth_hdr + 1);
-
-		return (uint16_t) ((rte_lpm6_lookup(qconf->ipv6_lookup_struct,
-				ipv6_hdr->dst_addr, &next_hop) == 0)
-				? next_hop : portid);
-
-	}
-
-	return portid;
-}
-
-#if defined(RTE_ARCH_X86)
-#include "l3fwd_lpm_sse.h"
-#elif defined RTE_MACHINE_CPUFLAG_NEON
-#include "l3fwd_lpm_neon.h"
-#elif defined(RTE_ARCH_PPC_64)
-#include "l3fwd_lpm_altivec.h"
-#else
-#include "l3fwd_lpm.h"
-#endif
-
-/* main processing loop */
-int
-lpm_main_loop(__attribute__((unused)) void *dummy)
-{
-	struct rte_mbuf *pkts_burst[MAX_PKT_BURST];
-	unsigned lcore_id;
-	uint64_t prev_tsc, diff_tsc, cur_tsc;
-	int i, nb_rx;
-	uint16_t portid;
-	uint8_t queueid;
-	struct lcore_conf *qconf;
-	const uint64_t drain_tsc = (rte_get_tsc_hz() + US_PER_S - 1) /
-		US_PER_S * BURST_TX_DRAIN_US;
-
-	prev_tsc = 0;
-
-	lcore_id = rte_lcore_id();
-	qconf = &lcore_conf[lcore_id];
-
-	if (qconf->n_rx_queue == 0) {
-		RTE_LOG(INFO, L3FWD, "lcore %u has nothing to do\n", lcore_id);
-		return 0;
-	}
-
-	RTE_LOG(INFO, L3FWD, "entering main loop on lcore %u\n", lcore_id);
-
-	for (i = 0; i < qconf->n_rx_queue; i++) {
-
-		portid = qconf->rx_queue_list[i].port_id;
-		queueid = qconf->rx_queue_list[i].queue_id;
-		RTE_LOG(INFO, L3FWD,
-			" -- lcoreid=%u portid=%u rxqueueid=%hhu\n",
-			lcore_id, portid, queueid);
-	}
-
-	while (!force_quit) {
-
-		cur_tsc = rte_rdtsc();
-
-		/*
-		 * TX burst queue drain
-		 */
-		diff_tsc = cur_tsc - prev_tsc;
-		if (unlikely(diff_tsc > drain_tsc)) {
-
-			for (i = 0; i < qconf->n_tx_port; ++i) {
-				portid = qconf->tx_port_id[i];
-				if (qconf->tx_mbufs[portid].len == 0)
-					continue;
-				send_burst(qconf,
-					qconf->tx_mbufs[portid].len,
-					portid);
-				qconf->tx_mbufs[portid].len = 0;
-			}
-
-			prev_tsc = cur_tsc;
-		}
-
-		/*
-		 * Read packet from RX queues
-		 */
-		for (i = 0; i < qconf->n_rx_queue; ++i) {
-			portid = qconf->rx_queue_list[i].port_id;
-			queueid = qconf->rx_queue_list[i].queue_id;
-			nb_rx = rte_eth_rx_burst(portid, queueid, pkts_burst,
-				MAX_PKT_BURST);
-			if (nb_rx == 0)
-				continue;
-
-#if defined RTE_ARCH_X86 || defined RTE_MACHINE_CPUFLAG_NEON \
-			 || defined RTE_ARCH_PPC_64
-			l3fwd_lpm_send_packets(nb_rx, pkts_burst,
-						portid, qconf);
-#else
-			l3fwd_lpm_no_opt_send_packets(nb_rx, pkts_burst,
-							portid, qconf);
-#endif /* X86 */
-		}
-	}
-
-	return 0;
-}
-
-void
-setup_lpm(const int socketid)
-{
-	struct rte_lpm6_config config;
-	struct rte_lpm_config config_ipv4;
-	unsigned i;
-	int ret;
-	char s[64];
-
-	/* create the LPM table */
-	config_ipv4.max_rules = IPV4_L3FWD_LPM_MAX_RULES;
-	config_ipv4.number_tbl8s = IPV4_L3FWD_LPM_NUMBER_TBL8S;
-	config_ipv4.flags = 0;
-	snprintf(s, sizeof(s), "IPV4_L3FWD_LPM_%d", socketid);
-	ipv4_l3fwd_lpm_lookup_struct[socketid] =
-			rte_lpm_create(s, socketid, &config_ipv4);
-	if (ipv4_l3fwd_lpm_lookup_struct[socketid] == NULL)
-		rte_exit(EXIT_FAILURE,
-			"Unable to create the l3fwd LPM table on socket %d\n",
-			socketid);
-
-	/* populate the LPM table */
-	for (i = 0; i < IPV4_L3FWD_LPM_NUM_ROUTES; i++) {
-
-		/* skip unused ports */
-		if ((1 << ipv4_l3fwd_lpm_route_array[i].if_out &
-				enabled_port_mask) == 0)
-			continue;
-
-		ret = rte_lpm_add(ipv4_l3fwd_lpm_lookup_struct[socketid],
-			ipv4_l3fwd_lpm_route_array[i].ip,
-			ipv4_l3fwd_lpm_route_array[i].depth,
-			ipv4_l3fwd_lpm_route_array[i].if_out);
-
-		if (ret < 0) {
-			rte_exit(EXIT_FAILURE,
-				"Unable to add entry %u to the l3fwd LPM table on socket %d\n",
-				i, socketid);
-		}
-
-		printf("LPM: Adding route 0x%08x / %d (%d)\n",
-			(unsigned)ipv4_l3fwd_lpm_route_array[i].ip,
-			ipv4_l3fwd_lpm_route_array[i].depth,
-			ipv4_l3fwd_lpm_route_array[i].if_out);
-	}
-
-	/* create the LPM6 table */
-	snprintf(s, sizeof(s), "IPV6_L3FWD_LPM_%d", socketid);
-
-	config.max_rules = IPV6_L3FWD_LPM_MAX_RULES;
-	config.number_tbl8s = IPV6_L3FWD_LPM_NUMBER_TBL8S;
-	config.flags = 0;
-	ipv6_l3fwd_lpm_lookup_struct[socketid] = rte_lpm6_create(s, socketid,
-				&config);
-	if (ipv6_l3fwd_lpm_lookup_struct[socketid] == NULL)
-		rte_exit(EXIT_FAILURE,
-			"Unable to create the l3fwd LPM table on socket %d\n",
-			socketid);
-
-	/* populate the LPM table */
-	for (i = 0; i < IPV6_L3FWD_LPM_NUM_ROUTES; i++) {
-
-		/* skip unused ports */
-		if ((1 << ipv6_l3fwd_lpm_route_array[i].if_out &
-				enabled_port_mask) == 0)
-			continue;
-
-		ret = rte_lpm6_add(ipv6_l3fwd_lpm_lookup_struct[socketid],
-			ipv6_l3fwd_lpm_route_array[i].ip,
-			ipv6_l3fwd_lpm_route_array[i].depth,
-			ipv6_l3fwd_lpm_route_array[i].if_out);
-
-		if (ret < 0) {
-			rte_exit(EXIT_FAILURE,
-				"Unable to add entry %u to the l3fwd LPM table on socket %d\n",
-				i, socketid);
-		}
-
-		printf("LPM: Adding route %s / %d (%d)\n",
-			"IPV6",
-			ipv6_l3fwd_lpm_route_array[i].depth,
-			ipv6_l3fwd_lpm_route_array[i].if_out);
-	}
-}
-
-int
-lpm_check_ptype(int portid)
-{
-	int i, ret;
-	int ptype_l3_ipv4 = 0, ptype_l3_ipv6 = 0;
-	uint32_t ptype_mask = RTE_PTYPE_L3_MASK;
-
-	ret = rte_eth_dev_get_supported_ptypes(portid, ptype_mask, NULL, 0);
-	if (ret <= 0)
-		return 0;
-
-	uint32_t ptypes[ret];
-
-	ret = rte_eth_dev_get_supported_ptypes(portid, ptype_mask, ptypes, ret);
-	for (i = 0; i < ret; ++i) {
-		if (ptypes[i] & RTE_PTYPE_L3_IPV4)
-			ptype_l3_ipv4 = 1;
-		if (ptypes[i] & RTE_PTYPE_L3_IPV6)
-			ptype_l3_ipv6 = 1;
-	}
-
-	if (ptype_l3_ipv4 == 0)
-		printf("port %d cannot parse RTE_PTYPE_L3_IPV4\n", portid);
-
-	if (ptype_l3_ipv6 == 0)
-		printf("port %d cannot parse RTE_PTYPE_L3_IPV6\n", portid);
-
-	if (ptype_l3_ipv4 && ptype_l3_ipv6)
-		return 1;
-
-	return 0;
-
-}
-
-static inline void
-lpm_parse_ptype(struct rte_mbuf *m)
-{
-	struct ether_hdr *eth_hdr;
-	uint32_t packet_type = RTE_PTYPE_UNKNOWN;
-	uint16_t ether_type;
-
-	eth_hdr = rte_pktmbuf_mtod(m, struct ether_hdr *);
-	ether_type = eth_hdr->ether_type;
-	if (ether_type == rte_cpu_to_be_16(ETHER_TYPE_IPv4))
-		packet_type |= RTE_PTYPE_L3_IPV4_EXT_UNKNOWN;
-	else if (ether_type == rte_cpu_to_be_16(ETHER_TYPE_IPv6))
-		packet_type |= RTE_PTYPE_L3_IPV6_EXT_UNKNOWN;
-
-	m->packet_type = packet_type;
-}
-
-uint16_t
-lpm_cb_parse_ptype(uint16_t port __rte_unused, uint16_t queue __rte_unused,
-		   struct rte_mbuf *pkts[], uint16_t nb_pkts,
-		   uint16_t max_pkts __rte_unused,
-		   void *user_param __rte_unused)
-{
-	unsigned i;
-
-	for (i = 0; i < nb_pkts; ++i)
-		lpm_parse_ptype(pkts[i]);
-
-	return nb_pkts;
-}
-
-/* Return ipv4/ipv6 lpm fwd lookup struct. */
-void *
-lpm_get_ipv4_l3fwd_lookup_struct(const int socketid)
-{
-	return ipv4_l3fwd_lpm_lookup_struct[socketid];
-}
-
-void *
-lpm_get_ipv6_l3fwd_lookup_struct(const int socketid)
-{
-	return ipv6_l3fwd_lpm_lookup_struct[socketid];
-}
diff --git a/examples/l3fwd/l3fwd_lpm.h b/examples/l3fwd/l3fwd_lpm.h
deleted file mode 100644
index b68868f..0000000
--- a/examples/l3fwd/l3fwd_lpm.h
+++ /dev/null
@@ -1,98 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#ifndef __L3FWD_LPM_H__
-#define __L3FWD_LPM_H__
-
-static __rte_always_inline void
-l3fwd_lpm_simple_forward(struct rte_mbuf *m, uint16_t portid,
-		struct lcore_conf *qconf)
-{
-	struct ether_hdr *eth_hdr;
-	struct ipv4_hdr *ipv4_hdr;
-	uint16_t dst_port;
-
-	eth_hdr = rte_pktmbuf_mtod(m, struct ether_hdr *);
-
-	if (RTE_ETH_IS_IPV4_HDR(m->packet_type)) {
-		/* Handle IPv4 headers.*/
-		ipv4_hdr = rte_pktmbuf_mtod_offset(m, struct ipv4_hdr *,
-						   sizeof(struct ether_hdr));
-
-#ifdef DO_RFC_1812_CHECKS
-		/* Check to make sure the packet is valid (RFC1812) */
-		if (is_valid_ipv4_pkt(ipv4_hdr, m->pkt_len) < 0) {
-			rte_pktmbuf_free(m);
-			return;
-		}
-#endif
-		 dst_port = lpm_get_ipv4_dst_port(ipv4_hdr, portid,
-						qconf->ipv4_lookup_struct);
-
-		if (dst_port >= RTE_MAX_ETHPORTS ||
-			(enabled_port_mask & 1 << dst_port) == 0)
-			dst_port = portid;
-
-#ifdef DO_RFC_1812_CHECKS
-		/* Update time to live and header checksum */
-		--(ipv4_hdr->time_to_live);
-		++(ipv4_hdr->hdr_checksum);
-#endif
-		/* dst addr */
-		*(uint64_t *)&eth_hdr->d_addr = dest_eth_addr[dst_port];
-
-		/* src addr */
-		ether_addr_copy(&ports_eth_addr[dst_port], &eth_hdr->s_addr);
-
-		send_single_packet(qconf, m, dst_port);
-	} else if (RTE_ETH_IS_IPV6_HDR(m->packet_type)) {
-		/* Handle IPv6 headers.*/
-		struct ipv6_hdr *ipv6_hdr;
-
-		ipv6_hdr = rte_pktmbuf_mtod_offset(m, struct ipv6_hdr *,
-						   sizeof(struct ether_hdr));
-
-		dst_port = lpm_get_ipv6_dst_port(ipv6_hdr, portid,
-					qconf->ipv6_lookup_struct);
-
-		if (dst_port >= RTE_MAX_ETHPORTS ||
-			(enabled_port_mask & 1 << dst_port) == 0)
-			dst_port = portid;
-
-		/* dst addr */
-		*(uint64_t *)&eth_hdr->d_addr = dest_eth_addr[dst_port];
-
-		/* src addr */
-		ether_addr_copy(&ports_eth_addr[dst_port], &eth_hdr->s_addr);
-
-		send_single_packet(qconf, m, dst_port);
-	} else {
-		/* Free the mbuf that contains non-IPV4/IPV6 packet */
-		rte_pktmbuf_free(m);
-	}
-}
-
-static inline void
-l3fwd_lpm_no_opt_send_packets(int nb_rx, struct rte_mbuf **pkts_burst,
-				uint16_t portid, struct lcore_conf *qconf)
-{
-	int32_t j;
-
-	/* Prefetch first packets */
-	for (j = 0; j < PREFETCH_OFFSET && j < nb_rx; j++)
-		rte_prefetch0(rte_pktmbuf_mtod(pkts_burst[j], void *));
-
-	/* Prefetch and forward already prefetched packets. */
-	for (j = 0; j < (nb_rx - PREFETCH_OFFSET); j++) {
-		rte_prefetch0(rte_pktmbuf_mtod(pkts_burst[
-				j + PREFETCH_OFFSET], void *));
-		l3fwd_lpm_simple_forward(pkts_burst[j], portid, qconf);
-	}
-
-	/* Forward remaining prefetched packets */
-	for (; j < nb_rx; j++)
-		l3fwd_lpm_simple_forward(pkts_burst[j], portid, qconf);
-}
-
-#endif /* __L3FWD_LPM_H__ */
diff --git a/examples/l3fwd/l3fwd_lpm_altivec.h b/examples/l3fwd/l3fwd_lpm_altivec.h
deleted file mode 100644
index 4c9e243..0000000
--- a/examples/l3fwd/l3fwd_lpm_altivec.h
+++ /dev/null
@@ -1,136 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation.
- * Copyright(c) 2017 IBM Corporation.
- * All rights reserved.
- */
-
-#ifndef __L3FWD_LPM_ALTIVEC_H__
-#define __L3FWD_LPM_ALTIVEC_H__
-
-#include "l3fwd_altivec.h"
-
-/*
- * Read packet_type and destination IPV4 addresses from 4 mbufs.
- */
-static inline void
-processx4_step1(struct rte_mbuf *pkt[FWDSTEP],
-		vector unsigned int *dip,
-		uint32_t *ipv4_flag)
-{
-	struct ipv4_hdr *ipv4_hdr;
-	struct ether_hdr *eth_hdr;
-	uint32_t x0, x1, x2, x3;
-
-	eth_hdr = rte_pktmbuf_mtod(pkt[0], struct ether_hdr *);
-	ipv4_hdr = (struct ipv4_hdr *)(eth_hdr + 1);
-	x0 = ipv4_hdr->dst_addr;
-	ipv4_flag[0] = pkt[0]->packet_type & RTE_PTYPE_L3_IPV4;
-
-	rte_compiler_barrier();
-	eth_hdr = rte_pktmbuf_mtod(pkt[1], struct ether_hdr *);
-	ipv4_hdr = (struct ipv4_hdr *)(eth_hdr + 1);
-	x1 = ipv4_hdr->dst_addr;
-	ipv4_flag[0] &= pkt[1]->packet_type;
-
-	rte_compiler_barrier();
-	eth_hdr = rte_pktmbuf_mtod(pkt[2], struct ether_hdr *);
-	ipv4_hdr = (struct ipv4_hdr *)(eth_hdr + 1);
-	x2 = ipv4_hdr->dst_addr;
-	ipv4_flag[0] &= pkt[2]->packet_type;
-
-	rte_compiler_barrier();
-	eth_hdr = rte_pktmbuf_mtod(pkt[3], struct ether_hdr *);
-	ipv4_hdr = (struct ipv4_hdr *)(eth_hdr + 1);
-	x3 = ipv4_hdr->dst_addr;
-	ipv4_flag[0] &= pkt[3]->packet_type;
-
-	rte_compiler_barrier();
-	dip[0] = (vector unsigned int){x0, x1, x2, x3};
-}
-
-/*
- * Lookup into LPM for destination port.
- * If lookup fails, use incoming port (portid) as destination port.
- */
-static inline void
-processx4_step2(const struct lcore_conf *qconf,
-		vector unsigned int dip,
-		uint32_t ipv4_flag,
-		uint8_t portid,
-		struct rte_mbuf *pkt[FWDSTEP],
-		uint16_t dprt[FWDSTEP])
-{
-	rte_xmm_t dst;
-	const vector unsigned char bswap_mask = (vector unsigned char){
-							3, 2, 1, 0,
-							7, 6, 5, 4,
-							11, 10, 9, 8,
-							15, 14, 13, 12};
-
-	/* Byte swap 4 IPV4 addresses. */
-	dip = (vector unsigned int)vec_perm(*(vector unsigned char *)&dip,
-					(vector unsigned char){}, bswap_mask);
-
-	/* if all 4 packets are IPV4. */
-	if (likely(ipv4_flag)) {
-		rte_lpm_lookupx4(qconf->ipv4_lookup_struct, (xmm_t)dip,
-			(uint32_t *)&dst, portid);
-		/* get rid of unused upper 16 bit for each dport. */
-		dst.x = (xmm_t)vec_packs(dst.x, dst.x);
-		*(uint64_t *)dprt = dst.u64[0];
-	} else {
-		dst.x = (xmm_t)dip;
-		dprt[0] = lpm_get_dst_port_with_ipv4(qconf, pkt[0],
-							dst.u32[0], portid);
-		dprt[1] = lpm_get_dst_port_with_ipv4(qconf, pkt[1],
-							dst.u32[1], portid);
-		dprt[2] = lpm_get_dst_port_with_ipv4(qconf, pkt[2],
-							dst.u32[2], portid);
-		dprt[3] = lpm_get_dst_port_with_ipv4(qconf, pkt[3],
-							dst.u32[3], portid);
-	}
-}
-
-/*
- * Buffer optimized handling of packets, invoked
- * from main_loop.
- */
-static inline void
-l3fwd_lpm_send_packets(int nb_rx, struct rte_mbuf **pkts_burst,
-			uint8_t portid, struct lcore_conf *qconf)
-{
-	int32_t j;
-	uint16_t dst_port[MAX_PKT_BURST];
-	vector unsigned int dip[MAX_PKT_BURST / FWDSTEP];
-	uint32_t ipv4_flag[MAX_PKT_BURST / FWDSTEP];
-	const int32_t k = RTE_ALIGN_FLOOR(nb_rx, FWDSTEP);
-
-	for (j = 0; j != k; j += FWDSTEP)
-		processx4_step1(&pkts_burst[j], &dip[j / FWDSTEP],
-				&ipv4_flag[j / FWDSTEP]);
-
-	for (j = 0; j != k; j += FWDSTEP)
-		processx4_step2(qconf, dip[j / FWDSTEP],
-				ipv4_flag[j / FWDSTEP],
-				portid, &pkts_burst[j], &dst_port[j]);
-
-	/* Classify last up to 3 packets one by one */
-	switch (nb_rx % FWDSTEP) {
-	case 3:
-		dst_port[j] = lpm_get_dst_port(qconf, pkts_burst[j], portid);
-		j++;
-		/* fall-through */
-	case 2:
-		dst_port[j] = lpm_get_dst_port(qconf, pkts_burst[j], portid);
-		j++;
-		/* fall-through */
-	case 1:
-		dst_port[j] = lpm_get_dst_port(qconf, pkts_burst[j], portid);
-		j++;
-		/* fall-through */
-	}
-
-	send_packets_multi(qconf, pkts_burst, dst_port, nb_rx);
-}
-
-#endif /* __L3FWD_LPM_ALTIVEC_H__ */
diff --git a/examples/l3fwd/l3fwd_lpm_neon.h b/examples/l3fwd/l3fwd_lpm_neon.h
deleted file mode 100644
index 85f314d..0000000
--- a/examples/l3fwd/l3fwd_lpm_neon.h
+++ /dev/null
@@ -1,193 +0,0 @@
-/*-
- *   BSD LICENSE
- *
- *   Copyright(c) 2010-2016 Intel Corporation. All rights reserved.
- *   Copyright(c) 2017, Linaro Limited
- *   All rights reserved.
- *
- *   Redistribution and use in source and binary forms, with or without
- *   modification, are permitted provided that the following conditions
- *   are met:
- *
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above copyright
- *       notice, this list of conditions and the following disclaimer in
- *       the documentation and/or other materials provided with the
- *       distribution.
- *     * Neither the name of Intel Corporation nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#ifndef __L3FWD_LPM_NEON_H__
-#define __L3FWD_LPM_NEON_H__
-
-#include <arm_neon.h>
-
-#include "l3fwd_neon.h"
-
-/*
- * Read packet_type and destination IPV4 addresses from 4 mbufs.
- */
-static inline void
-processx4_step1(struct rte_mbuf *pkt[FWDSTEP],
-		int32x4_t *dip,
-		uint32_t *ipv4_flag)
-{
-	struct ipv4_hdr *ipv4_hdr;
-	struct ether_hdr *eth_hdr;
-	int32_t dst[FWDSTEP];
-
-	eth_hdr = rte_pktmbuf_mtod(pkt[0], struct ether_hdr *);
-	ipv4_hdr = (struct ipv4_hdr *)(eth_hdr + 1);
-	dst[0] = ipv4_hdr->dst_addr;
-	ipv4_flag[0] = pkt[0]->packet_type & RTE_PTYPE_L3_IPV4;
-
-	eth_hdr = rte_pktmbuf_mtod(pkt[1], struct ether_hdr *);
-	ipv4_hdr = (struct ipv4_hdr *)(eth_hdr + 1);
-	dst[1] = ipv4_hdr->dst_addr;
-	ipv4_flag[0] &= pkt[1]->packet_type;
-
-	eth_hdr = rte_pktmbuf_mtod(pkt[2], struct ether_hdr *);
-	ipv4_hdr = (struct ipv4_hdr *)(eth_hdr + 1);
-	dst[2] = ipv4_hdr->dst_addr;
-	ipv4_flag[0] &= pkt[2]->packet_type;
-
-	eth_hdr = rte_pktmbuf_mtod(pkt[3], struct ether_hdr *);
-	ipv4_hdr = (struct ipv4_hdr *)(eth_hdr + 1);
-	dst[3] = ipv4_hdr->dst_addr;
-	ipv4_flag[0] &= pkt[3]->packet_type;
-
-	dip[0] = vld1q_s32(dst);
-}
-
-/*
- * Lookup into LPM for destination port.
- * If lookup fails, use incoming port (portid) as destination port.
- */
-static inline void
-processx4_step2(const struct lcore_conf *qconf,
-		int32x4_t dip,
-		uint32_t ipv4_flag,
-		uint16_t portid,
-		struct rte_mbuf *pkt[FWDSTEP],
-		uint16_t dprt[FWDSTEP])
-{
-	rte_xmm_t dst;
-
-	dip = vreinterpretq_s32_u8(vrev32q_u8(vreinterpretq_u8_s32(dip)));
-
-	/* if all 4 packets are IPV4. */
-	if (likely(ipv4_flag)) {
-		rte_lpm_lookupx4(qconf->ipv4_lookup_struct, dip, dst.u32,
-			portid);
-		/* get rid of unused upper 16 bit for each dport. */
-		vst1_s16((int16_t *)dprt, vqmovn_s32(dst.x));
-	} else {
-		dst.x = dip;
-		dprt[0] = lpm_get_dst_port_with_ipv4(qconf, pkt[0],
-						     dst.u32[0], portid);
-		dprt[1] = lpm_get_dst_port_with_ipv4(qconf, pkt[1],
-						     dst.u32[1], portid);
-		dprt[2] = lpm_get_dst_port_with_ipv4(qconf, pkt[2],
-						     dst.u32[2], portid);
-		dprt[3] = lpm_get_dst_port_with_ipv4(qconf, pkt[3],
-						     dst.u32[3], portid);
-	}
-}
-
-/*
- * Buffer optimized handling of packets, invoked
- * from main_loop.
- */
-static inline void
-l3fwd_lpm_send_packets(int nb_rx, struct rte_mbuf **pkts_burst,
-			uint16_t portid, struct lcore_conf *qconf)
-{
-	int32_t i = 0, j = 0;
-	uint16_t dst_port[MAX_PKT_BURST];
-	int32x4_t dip;
-	uint32_t ipv4_flag;
-	const int32_t k = RTE_ALIGN_FLOOR(nb_rx, FWDSTEP);
-	const int32_t m = nb_rx % FWDSTEP;
-
-	if (k) {
-		for (i = 0; i < FWDSTEP; i++) {
-			rte_prefetch0(rte_pktmbuf_mtod(pkts_burst[i],
-						struct ether_hdr *) + 1);
-		}
-
-		for (j = 0; j != k - FWDSTEP; j += FWDSTEP) {
-			for (i = 0; i < FWDSTEP; i++) {
-				rte_prefetch0(rte_pktmbuf_mtod(
-						pkts_burst[j + i + FWDSTEP],
-						struct ether_hdr *) + 1);
-			}
-
-			processx4_step1(&pkts_burst[j], &dip, &ipv4_flag);
-			processx4_step2(qconf, dip, ipv4_flag, portid,
-					&pkts_burst[j], &dst_port[j]);
-		}
-
-		processx4_step1(&pkts_burst[j], &dip, &ipv4_flag);
-		processx4_step2(qconf, dip, ipv4_flag, portid, &pkts_burst[j],
-				&dst_port[j]);
-
-		j += FWDSTEP;
-	}
-
-	if (m) {
-		/* Prefetch last up to 3 packets one by one */
-		switch (m) {
-		case 3:
-			rte_prefetch0(rte_pktmbuf_mtod(pkts_burst[j],
-						struct ether_hdr *) + 1);
-			j++;
-			/* fallthrough */
-		case 2:
-			rte_prefetch0(rte_pktmbuf_mtod(pkts_burst[j],
-						struct ether_hdr *) + 1);
-			j++;
-			/* fallthrough */
-		case 1:
-			rte_prefetch0(rte_pktmbuf_mtod(pkts_burst[j],
-						struct ether_hdr *) + 1);
-			j++;
-		}
-
-		j -= m;
-		/* Classify last up to 3 packets one by one */
-		switch (m) {
-		case 3:
-			dst_port[j] = lpm_get_dst_port(qconf, pkts_burst[j],
-						       portid);
-			j++;
-			/* fallthrough */
-		case 2:
-			dst_port[j] = lpm_get_dst_port(qconf, pkts_burst[j],
-						       portid);
-			j++;
-			/* fallthrough */
-		case 1:
-			dst_port[j] = lpm_get_dst_port(qconf, pkts_burst[j],
-						       portid);
-		}
-	}
-
-	send_packets_multi(qconf, pkts_burst, dst_port, nb_rx);
-}
-
-#endif /* __L3FWD_LPM_NEON_H__ */
diff --git a/examples/l3fwd/l3fwd_lpm_sse.h b/examples/l3fwd/l3fwd_lpm_sse.h
deleted file mode 100644
index 1d16159..0000000
--- a/examples/l3fwd/l3fwd_lpm_sse.h
+++ /dev/null
@@ -1,120 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#ifndef __L3FWD_LPM_SSE_H__
-#define __L3FWD_LPM_SSE_H__
-
-#include "l3fwd_sse.h"
-
-/*
- * Read packet_type and destination IPV4 addresses from 4 mbufs.
- */
-static inline void
-processx4_step1(struct rte_mbuf *pkt[FWDSTEP],
-		__m128i *dip,
-		uint32_t *ipv4_flag)
-{
-	struct ipv4_hdr *ipv4_hdr;
-	struct ether_hdr *eth_hdr;
-	uint32_t x0, x1, x2, x3;
-
-	eth_hdr = rte_pktmbuf_mtod(pkt[0], struct ether_hdr *);
-	ipv4_hdr = (struct ipv4_hdr *)(eth_hdr + 1);
-	x0 = ipv4_hdr->dst_addr;
-	ipv4_flag[0] = pkt[0]->packet_type & RTE_PTYPE_L3_IPV4;
-
-	eth_hdr = rte_pktmbuf_mtod(pkt[1], struct ether_hdr *);
-	ipv4_hdr = (struct ipv4_hdr *)(eth_hdr + 1);
-	x1 = ipv4_hdr->dst_addr;
-	ipv4_flag[0] &= pkt[1]->packet_type;
-
-	eth_hdr = rte_pktmbuf_mtod(pkt[2], struct ether_hdr *);
-	ipv4_hdr = (struct ipv4_hdr *)(eth_hdr + 1);
-	x2 = ipv4_hdr->dst_addr;
-	ipv4_flag[0] &= pkt[2]->packet_type;
-
-	eth_hdr = rte_pktmbuf_mtod(pkt[3], struct ether_hdr *);
-	ipv4_hdr = (struct ipv4_hdr *)(eth_hdr + 1);
-	x3 = ipv4_hdr->dst_addr;
-	ipv4_flag[0] &= pkt[3]->packet_type;
-
-	dip[0] = _mm_set_epi32(x3, x2, x1, x0);
-}
-
-/*
- * Lookup into LPM for destination port.
- * If lookup fails, use incoming port (portid) as destination port.
- */
-static inline void
-processx4_step2(const struct lcore_conf *qconf,
-		__m128i dip,
-		uint32_t ipv4_flag,
-		uint16_t portid,
-		struct rte_mbuf *pkt[FWDSTEP],
-		uint16_t dprt[FWDSTEP])
-{
-	rte_xmm_t dst;
-	const  __m128i bswap_mask = _mm_set_epi8(12, 13, 14, 15, 8, 9, 10, 11,
-						4, 5, 6, 7, 0, 1, 2, 3);
-
-	/* Byte swap 4 IPV4 addresses. */
-	dip = _mm_shuffle_epi8(dip, bswap_mask);
-
-	/* if all 4 packets are IPV4. */
-	if (likely(ipv4_flag)) {
-		rte_lpm_lookupx4(qconf->ipv4_lookup_struct, dip, dst.u32,
-			portid);
-		/* get rid of unused upper 16 bit for each dport. */
-		dst.x = _mm_packs_epi32(dst.x, dst.x);
-		*(uint64_t *)dprt = dst.u64[0];
-	} else {
-		dst.x = dip;
-		dprt[0] = lpm_get_dst_port_with_ipv4(qconf, pkt[0], dst.u32[0], portid);
-		dprt[1] = lpm_get_dst_port_with_ipv4(qconf, pkt[1], dst.u32[1], portid);
-		dprt[2] = lpm_get_dst_port_with_ipv4(qconf, pkt[2], dst.u32[2], portid);
-		dprt[3] = lpm_get_dst_port_with_ipv4(qconf, pkt[3], dst.u32[3], portid);
-	}
-}
-
-/*
- * Buffer optimized handling of packets, invoked
- * from main_loop.
- */
-static inline void
-l3fwd_lpm_send_packets(int nb_rx, struct rte_mbuf **pkts_burst,
-			uint16_t portid, struct lcore_conf *qconf)
-{
-	int32_t j;
-	uint16_t dst_port[MAX_PKT_BURST];
-	__m128i dip[MAX_PKT_BURST / FWDSTEP];
-	uint32_t ipv4_flag[MAX_PKT_BURST / FWDSTEP];
-	const int32_t k = RTE_ALIGN_FLOOR(nb_rx, FWDSTEP);
-
-	for (j = 0; j != k; j += FWDSTEP)
-		processx4_step1(&pkts_burst[j], &dip[j / FWDSTEP],
-				&ipv4_flag[j / FWDSTEP]);
-
-	for (j = 0; j != k; j += FWDSTEP)
-		processx4_step2(qconf, dip[j / FWDSTEP],
-				ipv4_flag[j / FWDSTEP], portid, &pkts_burst[j], &dst_port[j]);
-
-	/* Classify last up to 3 packets one by one */
-	switch (nb_rx % FWDSTEP) {
-	case 3:
-		dst_port[j] = lpm_get_dst_port(qconf, pkts_burst[j], portid);
-		j++;
-		/* fall-through */
-	case 2:
-		dst_port[j] = lpm_get_dst_port(qconf, pkts_burst[j], portid);
-		j++;
-		/* fall-through */
-	case 1:
-		dst_port[j] = lpm_get_dst_port(qconf, pkts_burst[j], portid);
-		j++;
-	}
-
-	send_packets_multi(qconf, pkts_burst, dst_port, nb_rx);
-}
-
-#endif /* __L3FWD_LPM_SSE_H__ */
diff --git a/examples/l3fwd/l3fwd_neon.h b/examples/l3fwd/l3fwd_neon.h
deleted file mode 100644
index b319b5a..0000000
--- a/examples/l3fwd/l3fwd_neon.h
+++ /dev/null
@@ -1,260 +0,0 @@
-/*-
- *   BSD LICENSE
- *
- *   Copyright(c) 2016 Intel Corporation. All rights reserved.
- *   Copyright(c) 2017, Linaro Limited
- *   All rights reserved.
- *
- *   Redistribution and use in source and binary forms, with or without
- *   modification, are permitted provided that the following conditions
- *   are met:
- *
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above copyright
- *       notice, this list of conditions and the following disclaimer in
- *       the documentation and/or other materials provided with the
- *       distribution.
- *     * Neither the name of Intel Corporation nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-
-#ifndef _L3FWD_NEON_H_
-#define _L3FWD_NEON_H_
-
-#include "l3fwd.h"
-#include "l3fwd_common.h"
-
-/*
- * Update source and destination MAC addresses in the ethernet header.
- * Perform RFC1812 checks and updates for IPV4 packets.
- */
-static inline void
-processx4_step3(struct rte_mbuf *pkt[FWDSTEP], uint16_t dst_port[FWDSTEP])
-{
-	uint32x4_t te[FWDSTEP];
-	uint32x4_t ve[FWDSTEP];
-	uint32_t *p[FWDSTEP];
-
-	p[0] = rte_pktmbuf_mtod(pkt[0], uint32_t *);
-	p[1] = rte_pktmbuf_mtod(pkt[1], uint32_t *);
-	p[2] = rte_pktmbuf_mtod(pkt[2], uint32_t *);
-	p[3] = rte_pktmbuf_mtod(pkt[3], uint32_t *);
-
-	ve[0] = vreinterpretq_u32_s32(val_eth[dst_port[0]]);
-	te[0] = vld1q_u32(p[0]);
-
-	ve[1] = vreinterpretq_u32_s32(val_eth[dst_port[1]]);
-	te[1] = vld1q_u32(p[1]);
-
-	ve[2] = vreinterpretq_u32_s32(val_eth[dst_port[2]]);
-	te[2] = vld1q_u32(p[2]);
-
-	ve[3] = vreinterpretq_u32_s32(val_eth[dst_port[3]]);
-	te[3] = vld1q_u32(p[3]);
-
-	/* Update last 4 bytes */
-	ve[0] = vsetq_lane_u32(vgetq_lane_u32(te[0], 3), ve[0], 3);
-	ve[1] = vsetq_lane_u32(vgetq_lane_u32(te[1], 3), ve[1], 3);
-	ve[2] = vsetq_lane_u32(vgetq_lane_u32(te[2], 3), ve[2], 3);
-	ve[3] = vsetq_lane_u32(vgetq_lane_u32(te[3], 3), ve[3], 3);
-
-	vst1q_u32(p[0], ve[0]);
-	vst1q_u32(p[1], ve[1]);
-	vst1q_u32(p[2], ve[2]);
-	vst1q_u32(p[3], ve[3]);
-
-	rfc1812_process((struct ipv4_hdr *)((struct ether_hdr *)p[0] + 1),
-		&dst_port[0], pkt[0]->packet_type);
-	rfc1812_process((struct ipv4_hdr *)((struct ether_hdr *)p[1] + 1),
-		&dst_port[1], pkt[1]->packet_type);
-	rfc1812_process((struct ipv4_hdr *)((struct ether_hdr *)p[2] + 1),
-		&dst_port[2], pkt[2]->packet_type);
-	rfc1812_process((struct ipv4_hdr *)((struct ether_hdr *)p[3] + 1),
-		&dst_port[3], pkt[3]->packet_type);
-}
-
-/*
- * Group consecutive packets with the same destination port in bursts of 4.
- * Suppose we have array of destionation ports:
- * dst_port[] = {a, b, c, d,, e, ... }
- * dp1 should contain: <a, b, c, d>, dp2: <b, c, d, e>.
- * We doing 4 comparisons at once and the result is 4 bit mask.
- * This mask is used as an index into prebuild array of pnum values.
- */
-static inline uint16_t *
-port_groupx4(uint16_t pn[FWDSTEP + 1], uint16_t *lp, uint16x8_t dp1,
-	     uint16x8_t dp2)
-{
-	union {
-		uint16_t u16[FWDSTEP + 1];
-		uint64_t u64;
-	} *pnum = (void *)pn;
-
-	int32_t v;
-	uint16x8_t mask = {1, 2, 4, 8, 0, 0, 0, 0};
-
-	dp1 = vceqq_u16(dp1, dp2);
-	dp1 = vandq_u16(dp1, mask);
-	v = vaddvq_u16(dp1);
-
-	/* update last port counter. */
-	lp[0] += gptbl[v].lpv;
-	rte_compiler_barrier();
-
-	/* if dest port value has changed. */
-	if (v != GRPMSK) {
-		pnum->u64 = gptbl[v].pnum;
-		pnum->u16[FWDSTEP] = 1;
-		lp = pnum->u16 + gptbl[v].idx;
-	}
-
-	return lp;
-}
-
-/**
- * Process one packet:
- * Update source and destination MAC addresses in the ethernet header.
- * Perform RFC1812 checks and updates for IPV4 packets.
- */
-static inline void
-process_packet(struct rte_mbuf *pkt, uint16_t *dst_port)
-{
-	struct ether_hdr *eth_hdr;
-	uint32x4_t te, ve;
-
-	eth_hdr = rte_pktmbuf_mtod(pkt, struct ether_hdr *);
-
-	te = vld1q_u32((uint32_t *)eth_hdr);
-	ve = vreinterpretq_u32_s32(val_eth[dst_port[0]]);
-
-
-	rfc1812_process((struct ipv4_hdr *)(eth_hdr + 1), dst_port,
-			pkt->packet_type);
-
-	ve = vcopyq_laneq_u32(ve, 3, te, 3);
-	vst1q_u32((uint32_t *)eth_hdr, ve);
-}
-
-/**
- * Send packets burst from pkts_burst to the ports in dst_port array
- */
-static __rte_always_inline void
-send_packets_multi(struct lcore_conf *qconf, struct rte_mbuf **pkts_burst,
-		uint16_t dst_port[MAX_PKT_BURST], int nb_rx)
-{
-	int32_t k;
-	int j = 0;
-	uint16_t dlp;
-	uint16_t *lp;
-	uint16_t pnum[MAX_PKT_BURST + 1];
-
-	/*
-	 * Finish packet processing and group consecutive
-	 * packets with the same destination port.
-	 */
-	k = RTE_ALIGN_FLOOR(nb_rx, FWDSTEP);
-	if (k != 0) {
-		uint16x8_t dp1, dp2;
-
-		lp = pnum;
-		lp[0] = 1;
-
-		processx4_step3(pkts_burst, dst_port);
-
-		/* dp1: <d[0], d[1], d[2], d[3], ... > */
-		dp1 = vld1q_u16(dst_port);
-
-		for (j = FWDSTEP; j != k; j += FWDSTEP) {
-			processx4_step3(&pkts_burst[j], &dst_port[j]);
-
-			/*
-			 * dp2:
-			 * <d[j-3], d[j-2], d[j-1], d[j], ... >
-			 */
-			dp2 = vld1q_u16(&dst_port[j - FWDSTEP + 1]);
-			lp  = port_groupx4(&pnum[j - FWDSTEP], lp, dp1, dp2);
-
-			/*
-			 * dp1:
-			 * <d[j], d[j+1], d[j+2], d[j+3], ... >
-			 */
-			dp1 = vextq_u16(dp2, dp1, FWDSTEP - 1);
-		}
-
-		/*
-		 * dp2: <d[j-3], d[j-2], d[j-1], d[j-1], ... >
-		 */
-		dp2 = vextq_u16(dp1, dp1, 1);
-		dp2 = vsetq_lane_u16(vgetq_lane_u16(dp2, 2), dp2, 3);
-		lp  = port_groupx4(&pnum[j - FWDSTEP], lp, dp1, dp2);
-
-		/*
-		 * remove values added by the last repeated
-		 * dst port.
-		 */
-		lp[0]--;
-		dlp = dst_port[j - 1];
-	} else {
-		/* set dlp and lp to the never used values. */
-		dlp = BAD_PORT - 1;
-		lp = pnum + MAX_PKT_BURST;
-	}
-
-	/* Process up to last 3 packets one by one. */
-	switch (nb_rx % FWDSTEP) {
-	case 3:
-		process_packet(pkts_burst[j], dst_port + j);
-		GROUP_PORT_STEP(dlp, dst_port, lp, pnum, j);
-		j++;
-		/* fallthrough */
-	case 2:
-		process_packet(pkts_burst[j], dst_port + j);
-		GROUP_PORT_STEP(dlp, dst_port, lp, pnum, j);
-		j++;
-		/* fallthrough */
-	case 1:
-		process_packet(pkts_burst[j], dst_port + j);
-		GROUP_PORT_STEP(dlp, dst_port, lp, pnum, j);
-		j++;
-	}
-
-	/*
-	 * Send packets out, through destination port.
-	 * Consecutive packets with the same destination port
-	 * are already grouped together.
-	 * If destination port for the packet equals BAD_PORT,
-	 * then free the packet without sending it out.
-	 */
-	for (j = 0; j < nb_rx; j += k) {
-
-		int32_t m;
-		uint16_t pn;
-
-		pn = dst_port[j];
-		k = pnum[j];
-
-		if (likely(pn != BAD_PORT))
-			send_packetsx4(qconf, pn, pkts_burst + j, k);
-		else
-			for (m = j; m != j + k; m++)
-				rte_pktmbuf_free(pkts_burst[m]);
-
-	}
-}
-
-#endif /* _L3FWD_NEON_H_ */
diff --git a/examples/l3fwd/l3fwd_sse.h b/examples/l3fwd/l3fwd_sse.h
deleted file mode 100644
index ed5267c..0000000
--- a/examples/l3fwd/l3fwd_sse.h
+++ /dev/null
@@ -1,227 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016 Intel Corporation
- */
-
-
-#ifndef _L3FWD_SSE_H_
-#define _L3FWD_SSE_H_
-
-#include "l3fwd.h"
-#include "l3fwd_common.h"
-
-/*
- * Update source and destination MAC addresses in the ethernet header.
- * Perform RFC1812 checks and updates for IPV4 packets.
- */
-static inline void
-processx4_step3(struct rte_mbuf *pkt[FWDSTEP], uint16_t dst_port[FWDSTEP])
-{
-	__m128i te[FWDSTEP];
-	__m128i ve[FWDSTEP];
-	__m128i *p[FWDSTEP];
-
-	p[0] = rte_pktmbuf_mtod(pkt[0], __m128i *);
-	p[1] = rte_pktmbuf_mtod(pkt[1], __m128i *);
-	p[2] = rte_pktmbuf_mtod(pkt[2], __m128i *);
-	p[3] = rte_pktmbuf_mtod(pkt[3], __m128i *);
-
-	ve[0] = val_eth[dst_port[0]];
-	te[0] = _mm_loadu_si128(p[0]);
-
-	ve[1] = val_eth[dst_port[1]];
-	te[1] = _mm_loadu_si128(p[1]);
-
-	ve[2] = val_eth[dst_port[2]];
-	te[2] = _mm_loadu_si128(p[2]);
-
-	ve[3] = val_eth[dst_port[3]];
-	te[3] = _mm_loadu_si128(p[3]);
-
-	/* Update first 12 bytes, keep rest bytes intact. */
-	te[0] =  _mm_blend_epi16(te[0], ve[0], MASK_ETH);
-	te[1] =  _mm_blend_epi16(te[1], ve[1], MASK_ETH);
-	te[2] =  _mm_blend_epi16(te[2], ve[2], MASK_ETH);
-	te[3] =  _mm_blend_epi16(te[3], ve[3], MASK_ETH);
-
-	_mm_storeu_si128(p[0], te[0]);
-	_mm_storeu_si128(p[1], te[1]);
-	_mm_storeu_si128(p[2], te[2]);
-	_mm_storeu_si128(p[3], te[3]);
-
-	rfc1812_process((struct ipv4_hdr *)((struct ether_hdr *)p[0] + 1),
-		&dst_port[0], pkt[0]->packet_type);
-	rfc1812_process((struct ipv4_hdr *)((struct ether_hdr *)p[1] + 1),
-		&dst_port[1], pkt[1]->packet_type);
-	rfc1812_process((struct ipv4_hdr *)((struct ether_hdr *)p[2] + 1),
-		&dst_port[2], pkt[2]->packet_type);
-	rfc1812_process((struct ipv4_hdr *)((struct ether_hdr *)p[3] + 1),
-		&dst_port[3], pkt[3]->packet_type);
-}
-
-/*
- * Group consecutive packets with the same destination port in bursts of 4.
- * Suppose we have array of destionation ports:
- * dst_port[] = {a, b, c, d,, e, ... }
- * dp1 should contain: <a, b, c, d>, dp2: <b, c, d, e>.
- * We doing 4 comparisons at once and the result is 4 bit mask.
- * This mask is used as an index into prebuild array of pnum values.
- */
-static inline uint16_t *
-port_groupx4(uint16_t pn[FWDSTEP + 1], uint16_t *lp, __m128i dp1, __m128i dp2)
-{
-	union {
-		uint16_t u16[FWDSTEP + 1];
-		uint64_t u64;
-	} *pnum = (void *)pn;
-
-	int32_t v;
-
-	dp1 = _mm_cmpeq_epi16(dp1, dp2);
-	dp1 = _mm_unpacklo_epi16(dp1, dp1);
-	v = _mm_movemask_ps((__m128)dp1);
-
-	/* update last port counter. */
-	lp[0] += gptbl[v].lpv;
-
-	/* if dest port value has changed. */
-	if (v != GRPMSK) {
-		pnum->u64 = gptbl[v].pnum;
-		pnum->u16[FWDSTEP] = 1;
-		lp = pnum->u16 + gptbl[v].idx;
-	}
-
-	return lp;
-}
-
-/**
- * Process one packet:
- * Update source and destination MAC addresses in the ethernet header.
- * Perform RFC1812 checks and updates for IPV4 packets.
- */
-static inline void
-process_packet(struct rte_mbuf *pkt, uint16_t *dst_port)
-{
-	struct ether_hdr *eth_hdr;
-	__m128i te, ve;
-
-	eth_hdr = rte_pktmbuf_mtod(pkt, struct ether_hdr *);
-
-	te = _mm_loadu_si128((__m128i *)eth_hdr);
-	ve = val_eth[dst_port[0]];
-
-	rfc1812_process((struct ipv4_hdr *)(eth_hdr + 1), dst_port,
-			pkt->packet_type);
-
-	te =  _mm_blend_epi16(te, ve, MASK_ETH);
-	_mm_storeu_si128((__m128i *)eth_hdr, te);
-}
-
-/**
- * Send packets burst from pkts_burst to the ports in dst_port array
- */
-static __rte_always_inline void
-send_packets_multi(struct lcore_conf *qconf, struct rte_mbuf **pkts_burst,
-		uint16_t dst_port[MAX_PKT_BURST], int nb_rx)
-{
-	int32_t k;
-	int j = 0;
-	uint16_t dlp;
-	uint16_t *lp;
-	uint16_t pnum[MAX_PKT_BURST + 1];
-
-	/*
-	 * Finish packet processing and group consecutive
-	 * packets with the same destination port.
-	 */
-	k = RTE_ALIGN_FLOOR(nb_rx, FWDSTEP);
-	if (k != 0) {
-		__m128i dp1, dp2;
-
-		lp = pnum;
-		lp[0] = 1;
-
-		processx4_step3(pkts_burst, dst_port);
-
-		/* dp1: <d[0], d[1], d[2], d[3], ... > */
-		dp1 = _mm_loadu_si128((__m128i *)dst_port);
-
-		for (j = FWDSTEP; j != k; j += FWDSTEP) {
-			processx4_step3(&pkts_burst[j], &dst_port[j]);
-
-			/*
-			 * dp2:
-			 * <d[j-3], d[j-2], d[j-1], d[j], ... >
-			 */
-			dp2 = _mm_loadu_si128((__m128i *)
-					&dst_port[j - FWDSTEP + 1]);
-			lp  = port_groupx4(&pnum[j - FWDSTEP], lp, dp1, dp2);
-
-			/*
-			 * dp1:
-			 * <d[j], d[j+1], d[j+2], d[j+3], ... >
-			 */
-			dp1 = _mm_srli_si128(dp2, (FWDSTEP - 1) *
-						sizeof(dst_port[0]));
-		}
-
-		/*
-		 * dp2: <d[j-3], d[j-2], d[j-1], d[j-1], ... >
-		 */
-		dp2 = _mm_shufflelo_epi16(dp1, 0xf9);
-		lp  = port_groupx4(&pnum[j - FWDSTEP], lp, dp1, dp2);
-
-		/*
-		 * remove values added by the last repeated
-		 * dst port.
-		 */
-		lp[0]--;
-		dlp = dst_port[j - 1];
-	} else {
-		/* set dlp and lp to the never used values. */
-		dlp = BAD_PORT - 1;
-		lp = pnum + MAX_PKT_BURST;
-	}
-
-	/* Process up to last 3 packets one by one. */
-	switch (nb_rx % FWDSTEP) {
-	case 3:
-		process_packet(pkts_burst[j], dst_port + j);
-		GROUP_PORT_STEP(dlp, dst_port, lp, pnum, j);
-		j++;
-		/* fall-through */
-	case 2:
-		process_packet(pkts_burst[j], dst_port + j);
-		GROUP_PORT_STEP(dlp, dst_port, lp, pnum, j);
-		j++;
-		/* fall-through */
-	case 1:
-		process_packet(pkts_burst[j], dst_port + j);
-		GROUP_PORT_STEP(dlp, dst_port, lp, pnum, j);
-		j++;
-	}
-
-	/*
-	 * Send packets out, through destination port.
-	 * Consecutive packets with the same destination port
-	 * are already grouped together.
-	 * If destination port for the packet equals BAD_PORT,
-	 * then free the packet without sending it out.
-	 */
-	for (j = 0; j < nb_rx; j += k) {
-
-		int32_t m;
-		uint16_t pn;
-
-		pn = dst_port[j];
-		k = pnum[j];
-
-		if (likely(pn != BAD_PORT))
-			send_packetsx4(qconf, pn, pkts_burst + j, k);
-		else
-			for (m = j; m != j + k; m++)
-				rte_pktmbuf_free(pkts_burst[m]);
-
-	}
-}
-
-#endif /* _L3FWD_SSE_H_ */
diff --git a/examples/l3fwd/main.c b/examples/l3fwd/main.c
deleted file mode 100644
index ec1da5c..0000000
--- a/examples/l3fwd/main.c
+++ /dev/null
@@ -1,1034 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <sys/types.h>
-#include <string.h>
-#include <sys/queue.h>
-#include <stdarg.h>
-#include <errno.h>
-#include <getopt.h>
-#include <signal.h>
-#include <stdbool.h>
-
-#include <rte_common.h>
-#include <rte_vect.h>
-#include <rte_byteorder.h>
-#include <rte_log.h>
-#include <rte_memory.h>
-#include <rte_memcpy.h>
-#include <rte_eal.h>
-#include <rte_launch.h>
-#include <rte_atomic.h>
-#include <rte_cycles.h>
-#include <rte_prefetch.h>
-#include <rte_lcore.h>
-#include <rte_per_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_interrupts.h>
-#include <rte_random.h>
-#include <rte_debug.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-#include <rte_ip.h>
-#include <rte_tcp.h>
-#include <rte_udp.h>
-#include <rte_string_fns.h>
-#include <rte_cpuflags.h>
-
-#include <cmdline_parse.h>
-#include <cmdline_parse_etheraddr.h>
-
-#include "l3fwd.h"
-
-/*
- * Configurable number of RX/TX ring descriptors
- */
-#define RTE_TEST_RX_DESC_DEFAULT 1024
-#define RTE_TEST_TX_DESC_DEFAULT 1024
-
-#define MAX_TX_QUEUE_PER_PORT RTE_MAX_ETHPORTS
-#define MAX_RX_QUEUE_PER_PORT 128
-
-#define MAX_LCORE_PARAMS 1024
-
-/* Static global variables used within this file. */
-static uint16_t nb_rxd = RTE_TEST_RX_DESC_DEFAULT;
-static uint16_t nb_txd = RTE_TEST_TX_DESC_DEFAULT;
-
-/**< Ports set in promiscuous mode off by default. */
-static int promiscuous_on;
-
-/* Select Longest-Prefix or Exact match. */
-static int l3fwd_lpm_on;
-static int l3fwd_em_on;
-
-static int numa_on = 1; /**< NUMA is enabled by default. */
-static int parse_ptype; /**< Parse packet type using rx callback, and */
-			/**< disabled by default */
-
-/* Global variables. */
-
-volatile bool force_quit;
-
-/* ethernet addresses of ports */
-uint64_t dest_eth_addr[RTE_MAX_ETHPORTS];
-struct ether_addr ports_eth_addr[RTE_MAX_ETHPORTS];
-
-xmm_t val_eth[RTE_MAX_ETHPORTS];
-
-/* mask of enabled ports */
-uint32_t enabled_port_mask;
-
-/* Used only in exact match mode. */
-int ipv6; /**< ipv6 is false by default. */
-uint32_t hash_entry_number = HASH_ENTRY_NUMBER_DEFAULT;
-
-struct lcore_conf lcore_conf[RTE_MAX_LCORE];
-
-struct lcore_params {
-	uint16_t port_id;
-	uint8_t queue_id;
-	uint8_t lcore_id;
-} __rte_cache_aligned;
-
-static struct lcore_params lcore_params_array[MAX_LCORE_PARAMS];
-static struct lcore_params lcore_params_array_default[] = {
-	{0, 0, 2},
-	{0, 1, 2},
-	{0, 2, 2},
-	{1, 0, 2},
-	{1, 1, 2},
-	{1, 2, 2},
-	{2, 0, 2},
-	{3, 0, 3},
-	{3, 1, 3},
-};
-
-static struct lcore_params * lcore_params = lcore_params_array_default;
-static uint16_t nb_lcore_params = sizeof(lcore_params_array_default) /
-				sizeof(lcore_params_array_default[0]);
-
-static struct rte_eth_conf port_conf = {
-	.rxmode = {
-		.mq_mode = ETH_MQ_RX_RSS,
-		.max_rx_pkt_len = ETHER_MAX_LEN,
-		.split_hdr_size = 0,
-		.ignore_offload_bitfield = 1,
-		.offloads = (DEV_RX_OFFLOAD_CRC_STRIP |
-			     DEV_RX_OFFLOAD_CHECKSUM),
-	},
-	.rx_adv_conf = {
-		.rss_conf = {
-			.rss_key = NULL,
-			.rss_hf = ETH_RSS_IP,
-		},
-	},
-	.txmode = {
-		.mq_mode = ETH_MQ_TX_NONE,
-	},
-};
-
-static struct rte_mempool * pktmbuf_pool[NB_SOCKETS];
-
-struct l3fwd_lkp_mode {
-	void  (*setup)(int);
-	int   (*check_ptype)(int);
-	rte_rx_callback_fn cb_parse_ptype;
-	int   (*main_loop)(void *);
-	void* (*get_ipv4_lookup_struct)(int);
-	void* (*get_ipv6_lookup_struct)(int);
-};
-
-static struct l3fwd_lkp_mode l3fwd_lkp;
-
-static struct l3fwd_lkp_mode l3fwd_em_lkp = {
-	.setup                  = setup_hash,
-	.check_ptype		= em_check_ptype,
-	.cb_parse_ptype		= em_cb_parse_ptype,
-	.main_loop              = em_main_loop,
-	.get_ipv4_lookup_struct = em_get_ipv4_l3fwd_lookup_struct,
-	.get_ipv6_lookup_struct = em_get_ipv6_l3fwd_lookup_struct,
-};
-
-static struct l3fwd_lkp_mode l3fwd_lpm_lkp = {
-	.setup                  = setup_lpm,
-	.check_ptype		= lpm_check_ptype,
-	.cb_parse_ptype		= lpm_cb_parse_ptype,
-	.main_loop              = lpm_main_loop,
-	.get_ipv4_lookup_struct = lpm_get_ipv4_l3fwd_lookup_struct,
-	.get_ipv6_lookup_struct = lpm_get_ipv6_l3fwd_lookup_struct,
-};
-
-/*
- * Setup lookup methods for forwarding.
- * Currently exact-match and longest-prefix-match
- * are supported ones.
- */
-static void
-setup_l3fwd_lookup_tables(void)
-{
-	/* Setup HASH lookup functions. */
-	if (l3fwd_em_on)
-		l3fwd_lkp = l3fwd_em_lkp;
-	/* Setup LPM lookup functions. */
-	else
-		l3fwd_lkp = l3fwd_lpm_lkp;
-}
-
-static int
-check_lcore_params(void)
-{
-	uint8_t queue, lcore;
-	uint16_t i;
-	int socketid;
-
-	for (i = 0; i < nb_lcore_params; ++i) {
-		queue = lcore_params[i].queue_id;
-		if (queue >= MAX_RX_QUEUE_PER_PORT) {
-			printf("invalid queue number: %hhu\n", queue);
-			return -1;
-		}
-		lcore = lcore_params[i].lcore_id;
-		if (!rte_lcore_is_enabled(lcore)) {
-			printf("error: lcore %hhu is not enabled in lcore mask\n", lcore);
-			return -1;
-		}
-		if ((socketid = rte_lcore_to_socket_id(lcore) != 0) &&
-			(numa_on == 0)) {
-			printf("warning: lcore %hhu is on socket %d with numa off \n",
-				lcore, socketid);
-		}
-	}
-	return 0;
-}
-
-static int
-check_port_config(void)
-{
-	uint16_t portid;
-	uint16_t i;
-
-	for (i = 0; i < nb_lcore_params; ++i) {
-		portid = lcore_params[i].port_id;
-		if ((enabled_port_mask & (1 << portid)) == 0) {
-			printf("port %u is not enabled in port mask\n", portid);
-			return -1;
-		}
-		if (!rte_eth_dev_is_valid_port(portid)) {
-			printf("port %u is not present on the board\n", portid);
-			return -1;
-		}
-	}
-	return 0;
-}
-
-static uint8_t
-get_port_n_rx_queues(const uint16_t port)
-{
-	int queue = -1;
-	uint16_t i;
-
-	for (i = 0; i < nb_lcore_params; ++i) {
-		if (lcore_params[i].port_id == port) {
-			if (lcore_params[i].queue_id == queue+1)
-				queue = lcore_params[i].queue_id;
-			else
-				rte_exit(EXIT_FAILURE, "queue ids of the port %d must be"
-						" in sequence and must start with 0\n",
-						lcore_params[i].port_id);
-		}
-	}
-	return (uint8_t)(++queue);
-}
-
-static int
-init_lcore_rx_queues(void)
-{
-	uint16_t i, nb_rx_queue;
-	uint8_t lcore;
-
-	for (i = 0; i < nb_lcore_params; ++i) {
-		lcore = lcore_params[i].lcore_id;
-		nb_rx_queue = lcore_conf[lcore].n_rx_queue;
-		if (nb_rx_queue >= MAX_RX_QUEUE_PER_LCORE) {
-			printf("error: too many queues (%u) for lcore: %u\n",
-				(unsigned)nb_rx_queue + 1, (unsigned)lcore);
-			return -1;
-		} else {
-			lcore_conf[lcore].rx_queue_list[nb_rx_queue].port_id =
-				lcore_params[i].port_id;
-			lcore_conf[lcore].rx_queue_list[nb_rx_queue].queue_id =
-				lcore_params[i].queue_id;
-			lcore_conf[lcore].n_rx_queue++;
-		}
-	}
-	return 0;
-}
-
-/* display usage */
-static void
-print_usage(const char *prgname)
-{
-	fprintf(stderr, "%s [EAL options] --"
-		" -p PORTMASK"
-		" [-P]"
-		" [-E]"
-		" [-L]"
-		" --config (port,queue,lcore)[,(port,queue,lcore)]"
-		" [--eth-dest=X,MM:MM:MM:MM:MM:MM]"
-		" [--enable-jumbo [--max-pkt-len PKTLEN]]"
-		" [--no-numa]"
-		" [--hash-entry-num]"
-		" [--ipv6]"
-		" [--parse-ptype]\n\n"
-
-		"  -p PORTMASK: Hexadecimal bitmask of ports to configure\n"
-		"  -P : Enable promiscuous mode\n"
-		"  -E : Enable exact match\n"
-		"  -L : Enable longest prefix match (default)\n"
-		"  --config (port,queue,lcore): Rx queue configuration\n"
-		"  --eth-dest=X,MM:MM:MM:MM:MM:MM: Ethernet destination for port X\n"
-		"  --enable-jumbo: Enable jumbo frames\n"
-		"  --max-pkt-len: Under the premise of enabling jumbo,\n"
-		"                 maximum packet length in decimal (64-9600)\n"
-		"  --no-numa: Disable numa awareness\n"
-		"  --hash-entry-num: Specify the hash entry number in hexadecimal to be setup\n"
-		"  --ipv6: Set if running ipv6 packets\n"
-		"  --parse-ptype: Set to use software to analyze packet type\n\n",
-		prgname);
-}
-
-static int
-parse_max_pkt_len(const char *pktlen)
-{
-	char *end = NULL;
-	unsigned long len;
-
-	/* parse decimal string */
-	len = strtoul(pktlen, &end, 10);
-	if ((pktlen[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (len == 0)
-		return -1;
-
-	return len;
-}
-
-static int
-parse_portmask(const char *portmask)
-{
-	char *end = NULL;
-	unsigned long pm;
-
-	/* parse hexadecimal string */
-	pm = strtoul(portmask, &end, 16);
-	if ((portmask[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (pm == 0)
-		return -1;
-
-	return pm;
-}
-
-static int
-parse_hash_entry_number(const char *hash_entry_num)
-{
-	char *end = NULL;
-	unsigned long hash_en;
-	/* parse hexadecimal string */
-	hash_en = strtoul(hash_entry_num, &end, 16);
-	if ((hash_entry_num[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (hash_en == 0)
-		return -1;
-
-	return hash_en;
-}
-
-static int
-parse_config(const char *q_arg)
-{
-	char s[256];
-	const char *p, *p0 = q_arg;
-	char *end;
-	enum fieldnames {
-		FLD_PORT = 0,
-		FLD_QUEUE,
-		FLD_LCORE,
-		_NUM_FLD
-	};
-	unsigned long int_fld[_NUM_FLD];
-	char *str_fld[_NUM_FLD];
-	int i;
-	unsigned size;
-
-	nb_lcore_params = 0;
-
-	while ((p = strchr(p0,'(')) != NULL) {
-		++p;
-		if((p0 = strchr(p,')')) == NULL)
-			return -1;
-
-		size = p0 - p;
-		if(size >= sizeof(s))
-			return -1;
-
-		snprintf(s, sizeof(s), "%.*s", size, p);
-		if (rte_strsplit(s, sizeof(s), str_fld, _NUM_FLD, ',') != _NUM_FLD)
-			return -1;
-		for (i = 0; i < _NUM_FLD; i++){
-			errno = 0;
-			int_fld[i] = strtoul(str_fld[i], &end, 0);
-			if (errno != 0 || end == str_fld[i] || int_fld[i] > 255)
-				return -1;
-		}
-		if (nb_lcore_params >= MAX_LCORE_PARAMS) {
-			printf("exceeded max number of lcore params: %hu\n",
-				nb_lcore_params);
-			return -1;
-		}
-		lcore_params_array[nb_lcore_params].port_id =
-			(uint8_t)int_fld[FLD_PORT];
-		lcore_params_array[nb_lcore_params].queue_id =
-			(uint8_t)int_fld[FLD_QUEUE];
-		lcore_params_array[nb_lcore_params].lcore_id =
-			(uint8_t)int_fld[FLD_LCORE];
-		++nb_lcore_params;
-	}
-	lcore_params = lcore_params_array;
-	return 0;
-}
-
-static void
-parse_eth_dest(const char *optarg)
-{
-	uint16_t portid;
-	char *port_end;
-	uint8_t c, *dest, peer_addr[6];
-
-	errno = 0;
-	portid = strtoul(optarg, &port_end, 10);
-	if (errno != 0 || port_end == optarg || *port_end++ != ',')
-		rte_exit(EXIT_FAILURE,
-		"Invalid eth-dest: %s", optarg);
-	if (portid >= RTE_MAX_ETHPORTS)
-		rte_exit(EXIT_FAILURE,
-		"eth-dest: port %d >= RTE_MAX_ETHPORTS(%d)\n",
-		portid, RTE_MAX_ETHPORTS);
-
-	if (cmdline_parse_etheraddr(NULL, port_end,
-		&peer_addr, sizeof(peer_addr)) < 0)
-		rte_exit(EXIT_FAILURE,
-		"Invalid ethernet address: %s\n",
-		port_end);
-	dest = (uint8_t *)&dest_eth_addr[portid];
-	for (c = 0; c < 6; c++)
-		dest[c] = peer_addr[c];
-	*(uint64_t *)(val_eth + portid) = dest_eth_addr[portid];
-}
-
-#define MAX_JUMBO_PKT_LEN  9600
-#define MEMPOOL_CACHE_SIZE 256
-
-static const char short_options[] =
-	"p:"  /* portmask */
-	"P"   /* promiscuous */
-	"L"   /* enable long prefix match */
-	"E"   /* enable exact match */
-	;
-
-#define CMD_LINE_OPT_CONFIG "config"
-#define CMD_LINE_OPT_ETH_DEST "eth-dest"
-#define CMD_LINE_OPT_NO_NUMA "no-numa"
-#define CMD_LINE_OPT_IPV6 "ipv6"
-#define CMD_LINE_OPT_ENABLE_JUMBO "enable-jumbo"
-#define CMD_LINE_OPT_HASH_ENTRY_NUM "hash-entry-num"
-#define CMD_LINE_OPT_PARSE_PTYPE "parse-ptype"
-enum {
-	/* long options mapped to a short option */
-
-	/* first long only option value must be >= 256, so that we won't
-	 * conflict with short options */
-	CMD_LINE_OPT_MIN_NUM = 256,
-	CMD_LINE_OPT_CONFIG_NUM,
-	CMD_LINE_OPT_ETH_DEST_NUM,
-	CMD_LINE_OPT_NO_NUMA_NUM,
-	CMD_LINE_OPT_IPV6_NUM,
-	CMD_LINE_OPT_ENABLE_JUMBO_NUM,
-	CMD_LINE_OPT_HASH_ENTRY_NUM_NUM,
-	CMD_LINE_OPT_PARSE_PTYPE_NUM,
-};
-
-static const struct option lgopts[] = {
-	{CMD_LINE_OPT_CONFIG, 1, 0, CMD_LINE_OPT_CONFIG_NUM},
-	{CMD_LINE_OPT_ETH_DEST, 1, 0, CMD_LINE_OPT_ETH_DEST_NUM},
-	{CMD_LINE_OPT_NO_NUMA, 0, 0, CMD_LINE_OPT_NO_NUMA_NUM},
-	{CMD_LINE_OPT_IPV6, 0, 0, CMD_LINE_OPT_IPV6_NUM},
-	{CMD_LINE_OPT_ENABLE_JUMBO, 0, 0, CMD_LINE_OPT_ENABLE_JUMBO_NUM},
-	{CMD_LINE_OPT_HASH_ENTRY_NUM, 1, 0, CMD_LINE_OPT_HASH_ENTRY_NUM_NUM},
-	{CMD_LINE_OPT_PARSE_PTYPE, 0, 0, CMD_LINE_OPT_PARSE_PTYPE_NUM},
-	{NULL, 0, 0, 0}
-};
-
-/*
- * This expression is used to calculate the number of mbufs needed
- * depending on user input, taking  into account memory for rx and
- * tx hardware rings, cache per lcore and mtable per port per lcore.
- * RTE_MAX is used to ensure that NB_MBUF never goes below a minimum
- * value of 8192
- */
-#define NB_MBUF RTE_MAX(	\
-	(nb_ports*nb_rx_queue*nb_rxd +		\
-	nb_ports*nb_lcores*MAX_PKT_BURST +	\
-	nb_ports*n_tx_queue*nb_txd +		\
-	nb_lcores*MEMPOOL_CACHE_SIZE),		\
-	(unsigned)8192)
-
-/* Parse the argument given in the command line of the application */
-static int
-parse_args(int argc, char **argv)
-{
-	int opt, ret;
-	char **argvopt;
-	int option_index;
-	char *prgname = argv[0];
-
-	argvopt = argv;
-
-	/* Error or normal output strings. */
-	while ((opt = getopt_long(argc, argvopt, short_options,
-				lgopts, &option_index)) != EOF) {
-
-		switch (opt) {
-		/* portmask */
-		case 'p':
-			enabled_port_mask = parse_portmask(optarg);
-			if (enabled_port_mask == 0) {
-				fprintf(stderr, "Invalid portmask\n");
-				print_usage(prgname);
-				return -1;
-			}
-			break;
-
-		case 'P':
-			promiscuous_on = 1;
-			break;
-
-		case 'E':
-			l3fwd_em_on = 1;
-			break;
-
-		case 'L':
-			l3fwd_lpm_on = 1;
-			break;
-
-		/* long options */
-		case CMD_LINE_OPT_CONFIG_NUM:
-			ret = parse_config(optarg);
-			if (ret) {
-				fprintf(stderr, "Invalid config\n");
-				print_usage(prgname);
-				return -1;
-			}
-			break;
-
-		case CMD_LINE_OPT_ETH_DEST_NUM:
-			parse_eth_dest(optarg);
-			break;
-
-		case CMD_LINE_OPT_NO_NUMA_NUM:
-			numa_on = 0;
-			break;
-
-		case CMD_LINE_OPT_IPV6_NUM:
-			ipv6 = 1;
-			break;
-
-		case CMD_LINE_OPT_ENABLE_JUMBO_NUM: {
-			const struct option lenopts = {
-				"max-pkt-len", required_argument, 0, 0
-			};
-
-			port_conf.rxmode.offloads |= DEV_RX_OFFLOAD_JUMBO_FRAME;
-			port_conf.txmode.offloads |= DEV_TX_OFFLOAD_MULTI_SEGS;
-
-			/*
-			 * if no max-pkt-len set, use the default
-			 * value ETHER_MAX_LEN.
-			 */
-			if (getopt_long(argc, argvopt, "",
-					&lenopts, &option_index) == 0) {
-				ret = parse_max_pkt_len(optarg);
-				if (ret < 64 || ret > MAX_JUMBO_PKT_LEN) {
-					fprintf(stderr,
-						"invalid maximum packet length\n");
-					print_usage(prgname);
-					return -1;
-				}
-				port_conf.rxmode.max_rx_pkt_len = ret;
-			}
-			break;
-		}
-
-		case CMD_LINE_OPT_HASH_ENTRY_NUM_NUM:
-			ret = parse_hash_entry_number(optarg);
-			if ((ret > 0) && (ret <= L3FWD_HASH_ENTRIES)) {
-				hash_entry_number = ret;
-			} else {
-				fprintf(stderr, "invalid hash entry number\n");
-				print_usage(prgname);
-				return -1;
-			}
-			break;
-
-		case CMD_LINE_OPT_PARSE_PTYPE_NUM:
-			printf("soft parse-ptype is enabled\n");
-			parse_ptype = 1;
-			break;
-
-		default:
-			print_usage(prgname);
-			return -1;
-		}
-	}
-
-	/* If both LPM and EM are selected, return error. */
-	if (l3fwd_lpm_on && l3fwd_em_on) {
-		fprintf(stderr, "LPM and EM are mutually exclusive, select only one\n");
-		return -1;
-	}
-
-	/*
-	 * Nothing is selected, pick longest-prefix match
-	 * as default match.
-	 */
-	if (!l3fwd_lpm_on && !l3fwd_em_on) {
-		fprintf(stderr, "LPM or EM none selected, default LPM on\n");
-		l3fwd_lpm_on = 1;
-	}
-
-	/*
-	 * ipv6 and hash flags are valid only for
-	 * exact macth, reset them to default for
-	 * longest-prefix match.
-	 */
-	if (l3fwd_lpm_on) {
-		ipv6 = 0;
-		hash_entry_number = HASH_ENTRY_NUMBER_DEFAULT;
-	}
-
-	if (optind >= 0)
-		argv[optind-1] = prgname;
-
-	ret = optind-1;
-	optind = 1; /* reset getopt lib */
-	return ret;
-}
-
-static void
-print_ethaddr(const char *name, const struct ether_addr *eth_addr)
-{
-	char buf[ETHER_ADDR_FMT_SIZE];
-	ether_format_addr(buf, ETHER_ADDR_FMT_SIZE, eth_addr);
-	printf("%s%s", name, buf);
-}
-
-static int
-init_mem(unsigned nb_mbuf)
-{
-	struct lcore_conf *qconf;
-	int socketid;
-	unsigned lcore_id;
-	char s[64];
-
-	for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-		if (rte_lcore_is_enabled(lcore_id) == 0)
-			continue;
-
-		if (numa_on)
-			socketid = rte_lcore_to_socket_id(lcore_id);
-		else
-			socketid = 0;
-
-		if (socketid >= NB_SOCKETS) {
-			rte_exit(EXIT_FAILURE,
-				"Socket %d of lcore %u is out of range %d\n",
-				socketid, lcore_id, NB_SOCKETS);
-		}
-
-		if (pktmbuf_pool[socketid] == NULL) {
-			snprintf(s, sizeof(s), "mbuf_pool_%d", socketid);
-			pktmbuf_pool[socketid] =
-				rte_pktmbuf_pool_create(s, nb_mbuf,
-					MEMPOOL_CACHE_SIZE, 0,
-					RTE_MBUF_DEFAULT_BUF_SIZE, socketid);
-			if (pktmbuf_pool[socketid] == NULL)
-				rte_exit(EXIT_FAILURE,
-					"Cannot init mbuf pool on socket %d\n",
-					socketid);
-			else
-				printf("Allocated mbuf pool on socket %d\n",
-					socketid);
-
-			/* Setup either LPM or EM(f.e Hash).  */
-			l3fwd_lkp.setup(socketid);
-		}
-		qconf = &lcore_conf[lcore_id];
-		qconf->ipv4_lookup_struct =
-			l3fwd_lkp.get_ipv4_lookup_struct(socketid);
-		qconf->ipv6_lookup_struct =
-			l3fwd_lkp.get_ipv6_lookup_struct(socketid);
-	}
-	return 0;
-}
-
-/* Check the link status of all ports in up to 9s, and print them finally */
-static void
-check_all_ports_link_status(uint32_t port_mask)
-{
-#define CHECK_INTERVAL 100 /* 100ms */
-#define MAX_CHECK_TIME 90 /* 9s (90 * 100ms) in total */
-	uint16_t portid;
-	uint8_t count, all_ports_up, print_flag = 0;
-	struct rte_eth_link link;
-
-	printf("\nChecking link status");
-	fflush(stdout);
-	for (count = 0; count <= MAX_CHECK_TIME; count++) {
-		if (force_quit)
-			return;
-		all_ports_up = 1;
-		RTE_ETH_FOREACH_DEV(portid) {
-			if (force_quit)
-				return;
-			if ((port_mask & (1 << portid)) == 0)
-				continue;
-			memset(&link, 0, sizeof(link));
-			rte_eth_link_get_nowait(portid, &link);
-			/* print link status if flag set */
-			if (print_flag == 1) {
-				if (link.link_status)
-					printf(
-					"Port%d Link Up. Speed %u Mbps -%s\n",
-						portid, link.link_speed,
-				(link.link_duplex == ETH_LINK_FULL_DUPLEX) ?
-					("full-duplex") : ("half-duplex\n"));
-				else
-					printf("Port %d Link Down\n", portid);
-				continue;
-			}
-			/* clear all_ports_up flag if any link down */
-			if (link.link_status == ETH_LINK_DOWN) {
-				all_ports_up = 0;
-				break;
-			}
-		}
-		/* after finally printing all link status, get out */
-		if (print_flag == 1)
-			break;
-
-		if (all_ports_up == 0) {
-			printf(".");
-			fflush(stdout);
-			rte_delay_ms(CHECK_INTERVAL);
-		}
-
-		/* set the print_flag if all ports up or timeout */
-		if (all_ports_up == 1 || count == (MAX_CHECK_TIME - 1)) {
-			print_flag = 1;
-			printf("done\n");
-		}
-	}
-}
-
-static void
-signal_handler(int signum)
-{
-	if (signum == SIGINT || signum == SIGTERM) {
-		printf("\n\nSignal %d received, preparing to exit...\n",
-				signum);
-		force_quit = true;
-	}
-}
-
-static int
-prepare_ptype_parser(uint16_t portid, uint16_t queueid)
-{
-	if (parse_ptype) {
-		printf("Port %d: softly parse packet type info\n", portid);
-		if (rte_eth_add_rx_callback(portid, queueid,
-					    l3fwd_lkp.cb_parse_ptype,
-					    NULL))
-			return 1;
-
-		printf("Failed to add rx callback: port=%d\n", portid);
-		return 0;
-	}
-
-	if (l3fwd_lkp.check_ptype(portid))
-		return 1;
-
-	printf("port %d cannot parse packet type, please add --%s\n",
-	       portid, CMD_LINE_OPT_PARSE_PTYPE);
-	return 0;
-}
-
-int
-main(int argc, char **argv)
-{
-	struct lcore_conf *qconf;
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_txconf *txconf;
-	int ret;
-	unsigned nb_ports;
-	uint16_t queueid, portid;
-	unsigned lcore_id;
-	uint32_t n_tx_queue, nb_lcores;
-	uint8_t nb_rx_queue, queue, socketid;
-
-	/* init EAL */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid EAL parameters\n");
-	argc -= ret;
-	argv += ret;
-
-	force_quit = false;
-	signal(SIGINT, signal_handler);
-	signal(SIGTERM, signal_handler);
-
-	/* pre-init dst MACs for all ports to 02:00:00:00:00:xx */
-	for (portid = 0; portid < RTE_MAX_ETHPORTS; portid++) {
-		dest_eth_addr[portid] =
-			ETHER_LOCAL_ADMIN_ADDR + ((uint64_t)portid << 40);
-		*(uint64_t *)(val_eth + portid) = dest_eth_addr[portid];
-	}
-
-	/* parse application arguments (after the EAL ones) */
-	ret = parse_args(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid L3FWD parameters\n");
-
-	if (check_lcore_params() < 0)
-		rte_exit(EXIT_FAILURE, "check_lcore_params failed\n");
-
-	ret = init_lcore_rx_queues();
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "init_lcore_rx_queues failed\n");
-
-	nb_ports = rte_eth_dev_count();
-
-	if (check_port_config() < 0)
-		rte_exit(EXIT_FAILURE, "check_port_config failed\n");
-
-	nb_lcores = rte_lcore_count();
-
-	/* Setup function pointers for lookup method. */
-	setup_l3fwd_lookup_tables();
-
-	/* initialize all ports */
-	RTE_ETH_FOREACH_DEV(portid) {
-		struct rte_eth_conf local_port_conf = port_conf;
-
-		/* skip ports that are not enabled */
-		if ((enabled_port_mask & (1 << portid)) == 0) {
-			printf("\nSkipping disabled port %d\n", portid);
-			continue;
-		}
-
-		/* init port */
-		printf("Initializing port %d ... ", portid );
-		fflush(stdout);
-
-		nb_rx_queue = get_port_n_rx_queues(portid);
-		n_tx_queue = nb_lcores;
-		if (n_tx_queue > MAX_TX_QUEUE_PER_PORT)
-			n_tx_queue = MAX_TX_QUEUE_PER_PORT;
-		printf("Creating queues: nb_rxq=%d nb_txq=%u... ",
-			nb_rx_queue, (unsigned)n_tx_queue );
-
-		rte_eth_dev_info_get(portid, &dev_info);
-		if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-			local_port_conf.txmode.offloads |=
-				DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-		ret = rte_eth_dev_configure(portid, nb_rx_queue,
-					(uint16_t)n_tx_queue, &local_port_conf);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-				"Cannot configure device: err=%d, port=%d\n",
-				ret, portid);
-
-		ret = rte_eth_dev_adjust_nb_rx_tx_desc(portid, &nb_rxd,
-						       &nb_txd);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-				 "Cannot adjust number of descriptors: err=%d, "
-				 "port=%d\n", ret, portid);
-
-		rte_eth_macaddr_get(portid, &ports_eth_addr[portid]);
-		print_ethaddr(" Address:", &ports_eth_addr[portid]);
-		printf(", ");
-		print_ethaddr("Destination:",
-			(const struct ether_addr *)&dest_eth_addr[portid]);
-		printf(", ");
-
-		/*
-		 * prepare src MACs for each port.
-		 */
-		ether_addr_copy(&ports_eth_addr[portid],
-			(struct ether_addr *)(val_eth + portid) + 1);
-
-		/* init memory */
-		ret = init_mem(NB_MBUF);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "init_mem failed\n");
-
-		/* init one TX queue per couple (lcore,port) */
-		queueid = 0;
-		for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-			if (rte_lcore_is_enabled(lcore_id) == 0)
-				continue;
-
-			if (numa_on)
-				socketid =
-				(uint8_t)rte_lcore_to_socket_id(lcore_id);
-			else
-				socketid = 0;
-
-			printf("txq=%u,%d,%d ", lcore_id, queueid, socketid);
-			fflush(stdout);
-
-			txconf = &dev_info.default_txconf;
-			txconf->txq_flags = ETH_TXQ_FLAGS_IGNORE;
-			txconf->offloads = local_port_conf.txmode.offloads;
-			ret = rte_eth_tx_queue_setup(portid, queueid, nb_txd,
-						     socketid, txconf);
-			if (ret < 0)
-				rte_exit(EXIT_FAILURE,
-					"rte_eth_tx_queue_setup: err=%d, "
-					"port=%d\n", ret, portid);
-
-			qconf = &lcore_conf[lcore_id];
-			qconf->tx_queue_id[portid] = queueid;
-			queueid++;
-
-			qconf->tx_port_id[qconf->n_tx_port] = portid;
-			qconf->n_tx_port++;
-		}
-		printf("\n");
-	}
-
-	for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-		if (rte_lcore_is_enabled(lcore_id) == 0)
-			continue;
-		qconf = &lcore_conf[lcore_id];
-		printf("\nInitializing rx queues on lcore %u ... ", lcore_id );
-		fflush(stdout);
-		/* init RX queues */
-		for(queue = 0; queue < qconf->n_rx_queue; ++queue) {
-			struct rte_eth_dev *dev;
-			struct rte_eth_conf *conf;
-			struct rte_eth_rxconf rxq_conf;
-
-			portid = qconf->rx_queue_list[queue].port_id;
-			queueid = qconf->rx_queue_list[queue].queue_id;
-			dev = &rte_eth_devices[portid];
-			conf = &dev->data->dev_conf;
-
-			if (numa_on)
-				socketid =
-				(uint8_t)rte_lcore_to_socket_id(lcore_id);
-			else
-				socketid = 0;
-
-			printf("rxq=%d,%d,%d ", portid, queueid, socketid);
-			fflush(stdout);
-
-			rte_eth_dev_info_get(portid, &dev_info);
-			rxq_conf = dev_info.default_rxconf;
-			rxq_conf.offloads = conf->rxmode.offloads;
-			ret = rte_eth_rx_queue_setup(portid, queueid, nb_rxd,
-					socketid,
-					&rxq_conf,
-					pktmbuf_pool[socketid]);
-			if (ret < 0)
-				rte_exit(EXIT_FAILURE,
-				"rte_eth_rx_queue_setup: err=%d, port=%d\n",
-				ret, portid);
-		}
-	}
-
-	printf("\n");
-
-	/* start ports */
-	RTE_ETH_FOREACH_DEV(portid) {
-		if ((enabled_port_mask & (1 << portid)) == 0) {
-			continue;
-		}
-		/* Start device */
-		ret = rte_eth_dev_start(portid);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-				"rte_eth_dev_start: err=%d, port=%d\n",
-				ret, portid);
-
-		/*
-		 * If enabled, put device in promiscuous mode.
-		 * This allows IO forwarding mode to forward packets
-		 * to itself through 2 cross-connected  ports of the
-		 * target machine.
-		 */
-		if (promiscuous_on)
-			rte_eth_promiscuous_enable(portid);
-	}
-
-	printf("\n");
-
-	for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-		if (rte_lcore_is_enabled(lcore_id) == 0)
-			continue;
-		qconf = &lcore_conf[lcore_id];
-		for (queue = 0; queue < qconf->n_rx_queue; ++queue) {
-			portid = qconf->rx_queue_list[queue].port_id;
-			queueid = qconf->rx_queue_list[queue].queue_id;
-			if (prepare_ptype_parser(portid, queueid) == 0)
-				rte_exit(EXIT_FAILURE, "ptype check fails\n");
-		}
-	}
-
-
-	check_all_ports_link_status(enabled_port_mask);
-
-	ret = 0;
-	/* launch per-lcore init on every lcore */
-	rte_eal_mp_remote_launch(l3fwd_lkp.main_loop, NULL, CALL_MASTER);
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		if (rte_eal_wait_lcore(lcore_id) < 0) {
-			ret = -1;
-			break;
-		}
-	}
-
-	/* stop ports */
-	RTE_ETH_FOREACH_DEV(portid) {
-		if ((enabled_port_mask & (1 << portid)) == 0)
-			continue;
-		printf("Closing port %d...", portid);
-		rte_eth_dev_stop(portid);
-		rte_eth_dev_close(portid);
-		printf(" Done\n");
-	}
-	printf("Bye...\n");
-
-	return ret;
-}
diff --git a/examples/l3fwd/meson.build b/examples/l3fwd/meson.build
deleted file mode 100644
index cbef07f..0000000
--- a/examples/l3fwd/meson.build
+++ /dev/null
@@ -1,13 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-deps += ['hash', 'lpm']
-allow_experimental_apis = true
-sources = files(
-	'l3fwd_em.c', 'l3fwd_lpm.c', 'main.c'
-)
diff --git a/examples/link_status_interrupt/Makefile b/examples/link_status_interrupt/Makefile
deleted file mode 100644
index 1606821..0000000
--- a/examples/link_status_interrupt/Makefile
+++ /dev/null
@@ -1,55 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-# binary name
-APP = link_status_interrupt
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else # Build using legacy build system
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-endif
diff --git a/examples/link_status_interrupt/main.c b/examples/link_status_interrupt/main.c
deleted file mode 100644
index ad0dd39..0000000
--- a/examples/link_status_interrupt/main.c
+++ /dev/null
@@ -1,714 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <string.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <sys/types.h>
-#include <sys/queue.h>
-#include <netinet/in.h>
-#include <setjmp.h>
-#include <stdarg.h>
-#include <ctype.h>
-#include <errno.h>
-#include <getopt.h>
-
-#include <rte_common.h>
-#include <rte_log.h>
-#include <rte_malloc.h>
-#include <rte_memory.h>
-#include <rte_memcpy.h>
-#include <rte_eal.h>
-#include <rte_launch.h>
-#include <rte_atomic.h>
-#include <rte_cycles.h>
-#include <rte_prefetch.h>
-#include <rte_lcore.h>
-#include <rte_per_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_interrupts.h>
-#include <rte_random.h>
-#include <rte_debug.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-
-#define RTE_LOGTYPE_LSI RTE_LOGTYPE_USER1
-
-#define NB_MBUF   8192
-
-#define MAX_PKT_BURST 32
-#define BURST_TX_DRAIN_US 100 /* TX drain every ~100us */
-
-/*
- * Configurable number of RX/TX ring descriptors
- */
-#define RTE_TEST_RX_DESC_DEFAULT 1024
-#define RTE_TEST_TX_DESC_DEFAULT 1024
-static uint16_t nb_rxd = RTE_TEST_RX_DESC_DEFAULT;
-static uint16_t nb_txd = RTE_TEST_TX_DESC_DEFAULT;
-
-/* ethernet addresses of ports */
-static struct ether_addr lsi_ports_eth_addr[RTE_MAX_ETHPORTS];
-
-/* mask of enabled ports */
-static uint32_t lsi_enabled_port_mask = 0;
-
-static unsigned int lsi_rx_queue_per_lcore = 1;
-
-/* destination port for L2 forwarding */
-static unsigned lsi_dst_ports[RTE_MAX_ETHPORTS] = {0};
-
-#define MAX_PKT_BURST 32
-
-#define MAX_RX_QUEUE_PER_LCORE 16
-#define MAX_TX_QUEUE_PER_PORT 16
-struct lcore_queue_conf {
-	unsigned n_rx_port;
-	unsigned rx_port_list[MAX_RX_QUEUE_PER_LCORE];
-	unsigned tx_queue_id;
-} __rte_cache_aligned;
-struct lcore_queue_conf lcore_queue_conf[RTE_MAX_LCORE];
-
-struct rte_eth_dev_tx_buffer *tx_buffer[RTE_MAX_ETHPORTS];
-
-static struct rte_eth_conf port_conf = {
-	.rxmode = {
-		.split_hdr_size = 0,
-		.ignore_offload_bitfield = 1,
-		.offloads = DEV_RX_OFFLOAD_CRC_STRIP,
-	},
-	.txmode = {
-		.mq_mode = ETH_MQ_TX_NONE,
-	},
-	.intr_conf = {
-		.lsc = 1, /**< lsc interrupt feature enabled */
-	},
-};
-
-struct rte_mempool * lsi_pktmbuf_pool = NULL;
-
-/* Per-port statistics struct */
-struct lsi_port_statistics {
-	uint64_t tx;
-	uint64_t rx;
-	uint64_t dropped;
-} __rte_cache_aligned;
-struct lsi_port_statistics port_statistics[RTE_MAX_ETHPORTS];
-
-/* A tsc-based timer responsible for triggering statistics printout */
-#define TIMER_MILLISECOND 2000000ULL /* around 1ms at 2 Ghz */
-#define MAX_TIMER_PERIOD 86400 /* 1 day max */
-static int64_t timer_period = 10 * TIMER_MILLISECOND * 1000; /* default period is 10 seconds */
-
-/* Print out statistics on packets dropped */
-static void
-print_stats(void)
-{
-	struct rte_eth_link link;
-	uint64_t total_packets_dropped, total_packets_tx, total_packets_rx;
-	uint16_t portid;
-
-	total_packets_dropped = 0;
-	total_packets_tx = 0;
-	total_packets_rx = 0;
-
-	const char clr[] = { 27, '[', '2', 'J', '\0' };
-	const char topLeft[] = { 27, '[', '1', ';', '1', 'H','\0' };
-
-		/* Clear screen and move to top left */
-	printf("%s%s", clr, topLeft);
-
-	printf("\nPort statistics ====================================");
-
-	for (portid = 0; portid < RTE_MAX_ETHPORTS; portid++) {
-		/* skip ports that are not enabled */
-		if ((lsi_enabled_port_mask & (1 << portid)) == 0)
-			continue;
-
-		memset(&link, 0, sizeof(link));
-		rte_eth_link_get_nowait(portid, &link);
-		printf("\nStatistics for port %u ------------------------------"
-			   "\nLink status: %25s"
-			   "\nLink speed: %26u"
-			   "\nLink duplex: %25s"
-			   "\nPackets sent: %24"PRIu64
-			   "\nPackets received: %20"PRIu64
-			   "\nPackets dropped: %21"PRIu64,
-			   portid,
-			   (link.link_status ? "Link up" : "Link down"),
-			   (unsigned)link.link_speed,
-			   (link.link_duplex == ETH_LINK_FULL_DUPLEX ? \
-					"full-duplex" : "half-duplex"),
-			   port_statistics[portid].tx,
-			   port_statistics[portid].rx,
-			   port_statistics[portid].dropped);
-
-		total_packets_dropped += port_statistics[portid].dropped;
-		total_packets_tx += port_statistics[portid].tx;
-		total_packets_rx += port_statistics[portid].rx;
-	}
-	printf("\nAggregate statistics ==============================="
-		   "\nTotal packets sent: %18"PRIu64
-		   "\nTotal packets received: %14"PRIu64
-		   "\nTotal packets dropped: %15"PRIu64,
-		   total_packets_tx,
-		   total_packets_rx,
-		   total_packets_dropped);
-	printf("\n====================================================\n");
-}
-
-static void
-lsi_simple_forward(struct rte_mbuf *m, unsigned portid)
-{
-	struct ether_hdr *eth;
-	void *tmp;
-	unsigned dst_port = lsi_dst_ports[portid];
-	int sent;
-	struct rte_eth_dev_tx_buffer *buffer;
-
-	eth = rte_pktmbuf_mtod(m, struct ether_hdr *);
-
-	/* 02:00:00:00:00:xx */
-	tmp = &eth->d_addr.addr_bytes[0];
-	*((uint64_t *)tmp) = 0x000000000002 + ((uint64_t)dst_port << 40);
-
-	/* src addr */
-	ether_addr_copy(&lsi_ports_eth_addr[dst_port], &eth->s_addr);
-
-	buffer = tx_buffer[dst_port];
-	sent = rte_eth_tx_buffer(dst_port, 0, buffer, m);
-	if (sent)
-		port_statistics[dst_port].tx += sent;
-}
-
-/* main processing loop */
-static void
-lsi_main_loop(void)
-{
-	struct rte_mbuf *pkts_burst[MAX_PKT_BURST];
-	struct rte_mbuf *m;
-	unsigned lcore_id;
-	unsigned sent;
-	uint64_t prev_tsc, diff_tsc, cur_tsc, timer_tsc;
-	unsigned i, j, portid, nb_rx;
-	struct lcore_queue_conf *qconf;
-	const uint64_t drain_tsc = (rte_get_tsc_hz() + US_PER_S - 1) / US_PER_S *
-			BURST_TX_DRAIN_US;
-	struct rte_eth_dev_tx_buffer *buffer;
-
-	prev_tsc = 0;
-	timer_tsc = 0;
-
-	lcore_id = rte_lcore_id();
-	qconf = &lcore_queue_conf[lcore_id];
-
-	if (qconf->n_rx_port == 0) {
-		RTE_LOG(INFO, LSI, "lcore %u has nothing to do\n", lcore_id);
-		return;
-	}
-
-	RTE_LOG(INFO, LSI, "entering main loop on lcore %u\n", lcore_id);
-
-	for (i = 0; i < qconf->n_rx_port; i++) {
-
-		portid = qconf->rx_port_list[i];
-		RTE_LOG(INFO, LSI, " -- lcoreid=%u portid=%u\n", lcore_id,
-			portid);
-	}
-
-	while (1) {
-
-		cur_tsc = rte_rdtsc();
-
-		/*
-		 * TX burst queue drain
-		 */
-		diff_tsc = cur_tsc - prev_tsc;
-		if (unlikely(diff_tsc > drain_tsc)) {
-
-			for (i = 0; i < qconf->n_rx_port; i++) {
-
-				portid = lsi_dst_ports[qconf->rx_port_list[i]];
-				buffer = tx_buffer[portid];
-
-				sent = rte_eth_tx_buffer_flush(portid, 0, buffer);
-				if (sent)
-					port_statistics[portid].tx += sent;
-
-			}
-
-			/* if timer is enabled */
-			if (timer_period > 0) {
-
-				/* advance the timer */
-				timer_tsc += diff_tsc;
-
-				/* if timer has reached its timeout */
-				if (unlikely(timer_tsc >= (uint64_t) timer_period)) {
-
-					/* do this only on master core */
-					if (lcore_id == rte_get_master_lcore()) {
-						print_stats();
-						/* reset the timer */
-						timer_tsc = 0;
-					}
-				}
-			}
-
-			prev_tsc = cur_tsc;
-		}
-
-		/*
-		 * Read packet from RX queues
-		 */
-		for (i = 0; i < qconf->n_rx_port; i++) {
-
-			portid = qconf->rx_port_list[i];
-			nb_rx = rte_eth_rx_burst((uint8_t) portid, 0,
-						 pkts_burst, MAX_PKT_BURST);
-
-			port_statistics[portid].rx += nb_rx;
-
-			for (j = 0; j < nb_rx; j++) {
-				m = pkts_burst[j];
-				rte_prefetch0(rte_pktmbuf_mtod(m, void *));
-				lsi_simple_forward(m, portid);
-			}
-		}
-	}
-}
-
-static int
-lsi_launch_one_lcore(__attribute__((unused)) void *dummy)
-{
-	lsi_main_loop();
-	return 0;
-}
-
-/* display usage */
-static void
-lsi_usage(const char *prgname)
-{
-	printf("%s [EAL options] -- -p PORTMASK [-q NQ]\n"
-		"  -p PORTMASK: hexadecimal bitmask of ports to configure\n"
-		"  -q NQ: number of queue (=ports) per lcore (default is 1)\n"
-		"  -T PERIOD: statistics will be refreshed each PERIOD seconds (0 to disable, 10 default, 86400 maximum)\n",
-			prgname);
-}
-
-static int
-lsi_parse_portmask(const char *portmask)
-{
-	char *end = NULL;
-	unsigned long pm;
-
-	/* parse hexadecimal string */
-	pm = strtoul(portmask, &end, 16);
-	if ((portmask[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (pm == 0)
-		return -1;
-
-	return pm;
-}
-
-static unsigned int
-lsi_parse_nqueue(const char *q_arg)
-{
-	char *end = NULL;
-	unsigned long n;
-
-	/* parse hexadecimal string */
-	n = strtoul(q_arg, &end, 10);
-	if ((q_arg[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return 0;
-	if (n == 0)
-		return 0;
-	if (n >= MAX_RX_QUEUE_PER_LCORE)
-		return 0;
-
-	return n;
-}
-
-static int
-lsi_parse_timer_period(const char *q_arg)
-{
-	char *end = NULL;
-	int n;
-
-	/* parse number string */
-	n = strtol(q_arg, &end, 10);
-	if ((q_arg[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-	if (n >= MAX_TIMER_PERIOD)
-		return -1;
-
-	return n;
-}
-
-/* Parse the argument given in the command line of the application */
-static int
-lsi_parse_args(int argc, char **argv)
-{
-	int opt, ret;
-	char **argvopt;
-	int option_index;
-	char *prgname = argv[0];
-	static struct option lgopts[] = {
-		{NULL, 0, 0, 0}
-	};
-
-	argvopt = argv;
-
-	while ((opt = getopt_long(argc, argvopt, "p:q:T:",
-				  lgopts, &option_index)) != EOF) {
-
-		switch (opt) {
-		/* portmask */
-		case 'p':
-			lsi_enabled_port_mask = lsi_parse_portmask(optarg);
-			if (lsi_enabled_port_mask == 0) {
-				printf("invalid portmask\n");
-				lsi_usage(prgname);
-				return -1;
-			}
-			break;
-
-		/* nqueue */
-		case 'q':
-			lsi_rx_queue_per_lcore = lsi_parse_nqueue(optarg);
-			if (lsi_rx_queue_per_lcore == 0) {
-				printf("invalid queue number\n");
-				lsi_usage(prgname);
-				return -1;
-			}
-			break;
-
-		/* timer period */
-		case 'T':
-			timer_period = lsi_parse_timer_period(optarg) * 1000 * TIMER_MILLISECOND;
-			if (timer_period < 0) {
-				printf("invalid timer period\n");
-				lsi_usage(prgname);
-				return -1;
-			}
-			break;
-
-		/* long options */
-		case 0:
-			lsi_usage(prgname);
-			return -1;
-
-		default:
-			lsi_usage(prgname);
-			return -1;
-		}
-	}
-
-	if (optind >= 0)
-		argv[optind-1] = prgname;
-
-	ret = optind-1;
-	optind = 1; /* reset getopt lib */
-	return ret;
-}
-
-/**
- * It will be called as the callback for specified port after a LSI interrupt
- * has been fully handled. This callback needs to be implemented carefully as
- * it will be called in the interrupt host thread which is different from the
- * application main thread.
- *
- * @param port_id
- *  Port id.
- * @param type
- *  event type.
- * @param param
- *  Pointer to(address of) the parameters.
- *
- * @return
- *  int.
- */
-static int
-lsi_event_callback(uint16_t port_id, enum rte_eth_event_type type, void *param,
-		    void *ret_param)
-{
-	struct rte_eth_link link;
-
-	RTE_SET_USED(param);
-	RTE_SET_USED(ret_param);
-
-	printf("\n\nIn registered callback...\n");
-	printf("Event type: %s\n", type == RTE_ETH_EVENT_INTR_LSC ? "LSC interrupt" : "unknown event");
-	rte_eth_link_get_nowait(port_id, &link);
-	if (link.link_status) {
-		printf("Port %d Link Up - speed %u Mbps - %s\n\n",
-				port_id, (unsigned)link.link_speed,
-			(link.link_duplex == ETH_LINK_FULL_DUPLEX) ?
-				("full-duplex") : ("half-duplex"));
-	} else
-		printf("Port %d Link Down\n\n", port_id);
-
-	return 0;
-}
-
-/* Check the link status of all ports in up to 9s, and print them finally */
-static void
-check_all_ports_link_status(uint16_t port_num, uint32_t port_mask)
-{
-#define CHECK_INTERVAL 100 /* 100ms */
-#define MAX_CHECK_TIME 90 /* 9s (90 * 100ms) in total */
-	uint8_t count, all_ports_up, print_flag = 0;
-	uint16_t portid;
-	struct rte_eth_link link;
-
-	printf("\nChecking link status");
-	fflush(stdout);
-	for (count = 0; count <= MAX_CHECK_TIME; count++) {
-		all_ports_up = 1;
-		for (portid = 0; portid < port_num; portid++) {
-			if ((port_mask & (1 << portid)) == 0)
-				continue;
-			memset(&link, 0, sizeof(link));
-			rte_eth_link_get_nowait(portid, &link);
-			/* print link status if flag set */
-			if (print_flag == 1) {
-				if (link.link_status)
-					printf(
-					"Port%d Link Up. Speed %u Mbps - %s\n",
-						portid, link.link_speed,
-				(link.link_duplex == ETH_LINK_FULL_DUPLEX) ?
-					("full-duplex") : ("half-duplex\n"));
-				else
-					printf("Port %d Link Down\n", portid);
-				continue;
-			}
-			/* clear all_ports_up flag if any link down */
-			if (link.link_status == ETH_LINK_DOWN) {
-				all_ports_up = 0;
-				break;
-			}
-		}
-		/* after finally printing all link status, get out */
-		if (print_flag == 1)
-			break;
-
-		if (all_ports_up == 0) {
-			printf(".");
-			fflush(stdout);
-			rte_delay_ms(CHECK_INTERVAL);
-		}
-
-		/* set the print_flag if all ports up or timeout */
-		if (all_ports_up == 1 || count == (MAX_CHECK_TIME - 1)) {
-			print_flag = 1;
-			printf("done\n");
-		}
-	}
-}
-
-int
-main(int argc, char **argv)
-{
-	struct lcore_queue_conf *qconf;
-	int ret;
-	uint16_t nb_ports;
-	uint16_t portid, portid_last = 0;
-	unsigned lcore_id, rx_lcore_id;
-	unsigned nb_ports_in_mask = 0;
-
-	/* init EAL */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "rte_eal_init failed");
-	argc -= ret;
-	argv += ret;
-
-	/* parse application arguments (after the EAL ones) */
-	ret = lsi_parse_args(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid arguments");
-
-	/* create the mbuf pool */
-	lsi_pktmbuf_pool =
-		rte_pktmbuf_pool_create("mbuf_pool", NB_MBUF, 32, 0,
-			RTE_MBUF_DEFAULT_BUF_SIZE, rte_socket_id());
-	if (lsi_pktmbuf_pool == NULL)
-		rte_panic("Cannot init mbuf pool\n");
-
-	nb_ports = rte_eth_dev_count();
-	if (nb_ports == 0)
-		rte_panic("No Ethernet port - bye\n");
-
-	/*
-	 * Each logical core is assigned a dedicated TX queue on each port.
-	 */
-	for (portid = 0; portid < nb_ports; portid++) {
-		/* skip ports that are not enabled */
-		if ((lsi_enabled_port_mask & (1 << portid)) == 0)
-			continue;
-
-		/* save the destination port id */
-		if (nb_ports_in_mask % 2) {
-			lsi_dst_ports[portid] = portid_last;
-			lsi_dst_ports[portid_last] = portid;
-		}
-		else
-			portid_last = portid;
-
-		nb_ports_in_mask++;
-	}
-	if (nb_ports_in_mask < 2 || nb_ports_in_mask % 2)
-		rte_exit(EXIT_FAILURE, "Current enabled port number is %u, "
-				"but it should be even and at least 2\n",
-				nb_ports_in_mask);
-
-	rx_lcore_id = 0;
-	qconf = &lcore_queue_conf[rx_lcore_id];
-
-	/* Initialize the port/queue configuration of each logical core */
-	for (portid = 0; portid < nb_ports; portid++) {
-		/* skip ports that are not enabled */
-		if ((lsi_enabled_port_mask & (1 << portid)) == 0)
-			continue;
-
-		/* get the lcore_id for this port */
-		while (rte_lcore_is_enabled(rx_lcore_id) == 0 ||
-		       lcore_queue_conf[rx_lcore_id].n_rx_port ==
-		       lsi_rx_queue_per_lcore) {
-
-			rx_lcore_id++;
-			if (rx_lcore_id >= RTE_MAX_LCORE)
-				rte_exit(EXIT_FAILURE, "Not enough cores\n");
-		}
-		if (qconf != &lcore_queue_conf[rx_lcore_id])
-			/* Assigned a new logical core in the loop above. */
-			qconf = &lcore_queue_conf[rx_lcore_id];
-
-		qconf->rx_port_list[qconf->n_rx_port] = portid;
-		qconf->n_rx_port++;
-		printf("Lcore %u: RX port %u\n",rx_lcore_id, (unsigned) portid);
-	}
-
-	/* Initialise each port */
-	for (portid = 0; portid < nb_ports; portid++) {
-		struct rte_eth_rxconf rxq_conf;
-		struct rte_eth_txconf txq_conf;
-		struct rte_eth_conf local_port_conf = port_conf;
-		struct rte_eth_dev_info dev_info;
-
-		/* skip ports that are not enabled */
-		if ((lsi_enabled_port_mask & (1 << portid)) == 0) {
-			printf("Skipping disabled port %u\n", (unsigned) portid);
-			continue;
-		}
-		/* init port */
-		printf("Initializing port %u... ", (unsigned) portid);
-		fflush(stdout);
-		rte_eth_dev_info_get(portid, &dev_info);
-		if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-			local_port_conf.txmode.offloads |=
-				DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-		ret = rte_eth_dev_configure(portid, 1, 1, &local_port_conf);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "Cannot configure device: err=%d, port=%u\n",
-				  ret, (unsigned) portid);
-
-		ret = rte_eth_dev_adjust_nb_rx_tx_desc(portid, &nb_rxd,
-						       &nb_txd);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-				 "rte_eth_dev_adjust_nb_rx_tx_desc: err=%d, port=%u\n",
-				 ret, (unsigned) portid);
-
-		/* register lsi interrupt callback, need to be after
-		 * rte_eth_dev_configure(). if (intr_conf.lsc == 0), no
-		 * lsc interrupt will be present, and below callback to
-		 * be registered will never be called.
-		 */
-		rte_eth_dev_callback_register(portid,
-			RTE_ETH_EVENT_INTR_LSC, lsi_event_callback, NULL);
-
-		rte_eth_macaddr_get(portid,
-				    &lsi_ports_eth_addr[portid]);
-
-		/* init one RX queue */
-		fflush(stdout);
-		rxq_conf = dev_info.default_rxconf;
-		rxq_conf.offloads = local_port_conf.rxmode.offloads;
-		ret = rte_eth_rx_queue_setup(portid, 0, nb_rxd,
-					     rte_eth_dev_socket_id(portid),
-					     &rxq_conf,
-					     lsi_pktmbuf_pool);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "rte_eth_rx_queue_setup: err=%d, port=%u\n",
-				  ret, (unsigned) portid);
-
-		/* init one TX queue logical core on each port */
-		fflush(stdout);
-		txq_conf = dev_info.default_txconf;
-		txq_conf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-		txq_conf.offloads = local_port_conf.txmode.offloads;
-		ret = rte_eth_tx_queue_setup(portid, 0, nb_txd,
-				rte_eth_dev_socket_id(portid),
-				&txq_conf);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "rte_eth_tx_queue_setup: err=%d,port=%u\n",
-				  ret, (unsigned) portid);
-
-		/* Initialize TX buffers */
-		tx_buffer[portid] = rte_zmalloc_socket("tx_buffer",
-				RTE_ETH_TX_BUFFER_SIZE(MAX_PKT_BURST), 0,
-				rte_eth_dev_socket_id(portid));
-		if (tx_buffer[portid] == NULL)
-			rte_exit(EXIT_FAILURE, "Cannot allocate buffer for tx on port %u\n",
-					(unsigned) portid);
-
-		rte_eth_tx_buffer_init(tx_buffer[portid], MAX_PKT_BURST);
-
-		ret = rte_eth_tx_buffer_set_err_callback(tx_buffer[portid],
-				rte_eth_tx_buffer_count_callback,
-				&port_statistics[portid].dropped);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "Cannot set error callback for "
-					"tx buffer on port %u\n", (unsigned) portid);
-
-		/* Start device */
-		ret = rte_eth_dev_start(portid);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "rte_eth_dev_start: err=%d, port=%u\n",
-				  ret, (unsigned) portid);
-		printf("done:\n");
-
-		rte_eth_promiscuous_enable(portid);
-
-		printf("Port %u, MAC address: %02X:%02X:%02X:%02X:%02X:%02X\n\n",
-				(unsigned) portid,
-				lsi_ports_eth_addr[portid].addr_bytes[0],
-				lsi_ports_eth_addr[portid].addr_bytes[1],
-				lsi_ports_eth_addr[portid].addr_bytes[2],
-				lsi_ports_eth_addr[portid].addr_bytes[3],
-				lsi_ports_eth_addr[portid].addr_bytes[4],
-				lsi_ports_eth_addr[portid].addr_bytes[5]);
-
-		/* initialize port stats */
-		memset(&port_statistics, 0, sizeof(port_statistics));
-	}
-
-	check_all_ports_link_status(nb_ports, lsi_enabled_port_mask);
-
-	/* launch per-lcore init on every lcore */
-	rte_eal_mp_remote_launch(lsi_launch_one_lcore, NULL, CALL_MASTER);
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		if (rte_eal_wait_lcore(lcore_id) < 0)
-			return -1;
-	}
-
-	return 0;
-}
diff --git a/examples/link_status_interrupt/meson.build b/examples/link_status_interrupt/meson.build
deleted file mode 100644
index c34e11e..0000000
--- a/examples/link_status_interrupt/meson.build
+++ /dev/null
@@ -1,11 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-sources = files(
-	'main.c'
-)
diff --git a/examples/load_balancer/Makefile b/examples/load_balancer/Makefile
deleted file mode 100644
index fc8df71..0000000
--- a/examples/load_balancer/Makefile
+++ /dev/null
@@ -1,62 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-# binary name
-APP = load_balancer
-
-# all source are stored in SRCS-y
-SRCS-y := main.c config.c init.c runtime.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else # Build using legacy build system
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -O3 -g
-CFLAGS += $(WERROR_FLAGS)
-CFLAGS_config.o := -D_GNU_SOURCE
-
-# workaround for a gcc bug with noreturn attribute
-# http://gcc.gnu.org/bugzilla/show_bug.cgi?id=12603
-ifeq ($(CONFIG_RTE_TOOLCHAIN_GCC),y)
-CFLAGS_main.o += -Wno-return-type
-endif
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-endif
diff --git a/examples/load_balancer/config.c b/examples/load_balancer/config.c
deleted file mode 100644
index b5b6636..0000000
--- a/examples/load_balancer/config.c
+++ /dev/null
@@ -1,1030 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <sys/types.h>
-#include <string.h>
-#include <sys/queue.h>
-#include <stdarg.h>
-#include <errno.h>
-#include <getopt.h>
-
-#include <rte_common.h>
-#include <rte_byteorder.h>
-#include <rte_log.h>
-#include <rte_memory.h>
-#include <rte_memcpy.h>
-#include <rte_eal.h>
-#include <rte_launch.h>
-#include <rte_atomic.h>
-#include <rte_cycles.h>
-#include <rte_prefetch.h>
-#include <rte_lcore.h>
-#include <rte_per_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_interrupts.h>
-#include <rte_random.h>
-#include <rte_debug.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-#include <rte_ip.h>
-#include <rte_tcp.h>
-#include <rte_lpm.h>
-#include <rte_string_fns.h>
-
-#include "main.h"
-
-struct app_params app;
-
-static const char usage[] =
-"                                                                               \n"
-"    load_balancer <EAL PARAMS> -- <APP PARAMS>                                 \n"
-"                                                                               \n"
-"Application manadatory parameters:                                             \n"
-"    --rx \"(PORT, QUEUE, LCORE), ...\" : List of NIC RX ports and queues       \n"
-"           handled by the I/O RX lcores                                        \n"
-"    --tx \"(PORT, LCORE), ...\" : List of NIC TX ports handled by the I/O TX   \n"
-"           lcores                                                              \n"
-"    --w \"LCORE, ...\" : List of the worker lcores                             \n"
-"    --lpm \"IP / PREFIX => PORT; ...\" : List of LPM rules used by the worker  \n"
-"           lcores for packet forwarding                                        \n"
-"                                                                               \n"
-"Application optional parameters:                                               \n"
-"    --rsz \"A, B, C, D\" : Ring sizes                                          \n"
-"           A = Size (in number of buffer descriptors) of each of the NIC RX    \n"
-"               rings read by the I/O RX lcores (default value is %u)           \n"
-"           B = Size (in number of elements) of each of the SW rings used by the\n"
-"               I/O RX lcores to send packets to worker lcores (default value is\n"
-"               %u)                                                             \n"
-"           C = Size (in number of elements) of each of the SW rings used by the\n"
-"               worker lcores to send packets to I/O TX lcores (default value is\n"
-"               %u)                                                             \n"
-"           D = Size (in number of buffer descriptors) of each of the NIC TX    \n"
-"               rings written by I/O TX lcores (default value is %u)            \n"
-"    --bsz \"(A, B), (C, D), (E, F)\" :  Burst sizes                            \n"
-"           A = I/O RX lcore read burst size from NIC RX (default value is %u)  \n"
-"           B = I/O RX lcore write burst size to output SW rings (default value \n"
-"               is %u)                                                          \n"
-"           C = Worker lcore read burst size from input SW rings (default value \n"
-"               is %u)                                                          \n"
-"           D = Worker lcore write burst size to output SW rings (default value \n"
-"               is %u)                                                          \n"
-"           E = I/O TX lcore read burst size from input SW rings (default value \n"
-"               is %u)                                                          \n"
-"           F = I/O TX lcore write burst size to NIC TX (default value is %u)   \n"
-"    --pos-lb POS : Position of the 1-byte field within the input packet used by\n"
-"           the I/O RX lcores to identify the worker lcore for the current      \n"
-"           packet (default value is %u)                                        \n";
-
-void
-app_print_usage(void)
-{
-	printf(usage,
-		APP_DEFAULT_NIC_RX_RING_SIZE,
-		APP_DEFAULT_RING_RX_SIZE,
-		APP_DEFAULT_RING_TX_SIZE,
-		APP_DEFAULT_NIC_TX_RING_SIZE,
-		APP_DEFAULT_BURST_SIZE_IO_RX_READ,
-		APP_DEFAULT_BURST_SIZE_IO_RX_WRITE,
-		APP_DEFAULT_BURST_SIZE_WORKER_READ,
-		APP_DEFAULT_BURST_SIZE_WORKER_WRITE,
-		APP_DEFAULT_BURST_SIZE_IO_TX_READ,
-		APP_DEFAULT_BURST_SIZE_IO_TX_WRITE,
-		APP_DEFAULT_IO_RX_LB_POS
-	);
-}
-
-#ifndef APP_ARG_RX_MAX_CHARS
-#define APP_ARG_RX_MAX_CHARS     4096
-#endif
-
-#ifndef APP_ARG_RX_MAX_TUPLES
-#define APP_ARG_RX_MAX_TUPLES    128
-#endif
-
-static int
-str_to_unsigned_array(
-	const char *s, size_t sbuflen,
-	char separator,
-	unsigned num_vals,
-	unsigned *vals)
-{
-	char str[sbuflen+1];
-	char *splits[num_vals];
-	char *endptr = NULL;
-	int i, num_splits = 0;
-
-	/* copy s so we don't modify original string */
-	snprintf(str, sizeof(str), "%s", s);
-	num_splits = rte_strsplit(str, sizeof(str), splits, num_vals, separator);
-
-	errno = 0;
-	for (i = 0; i < num_splits; i++) {
-		vals[i] = strtoul(splits[i], &endptr, 0);
-		if (errno != 0 || *endptr != '\0')
-			return -1;
-	}
-
-	return num_splits;
-}
-
-static int
-str_to_unsigned_vals(
-	const char *s,
-	size_t sbuflen,
-	char separator,
-	unsigned num_vals, ...)
-{
-	unsigned i, vals[num_vals];
-	va_list ap;
-
-	num_vals = str_to_unsigned_array(s, sbuflen, separator, num_vals, vals);
-
-	va_start(ap, num_vals);
-	for (i = 0; i < num_vals; i++) {
-		unsigned *u = va_arg(ap, unsigned *);
-		*u = vals[i];
-	}
-	va_end(ap);
-	return num_vals;
-}
-
-static int
-parse_arg_rx(const char *arg)
-{
-	const char *p0 = arg, *p = arg;
-	uint32_t n_tuples;
-
-	if (strnlen(arg, APP_ARG_RX_MAX_CHARS + 1) == APP_ARG_RX_MAX_CHARS + 1) {
-		return -1;
-	}
-
-	n_tuples = 0;
-	while ((p = strchr(p0,'(')) != NULL) {
-		struct app_lcore_params *lp;
-		uint32_t port, queue, lcore, i;
-
-		p0 = strchr(p++, ')');
-		if ((p0 == NULL) ||
-		    (str_to_unsigned_vals(p, p0 - p, ',', 3, &port, &queue, &lcore) !=  3)) {
-			return -2;
-		}
-
-		/* Enable port and queue for later initialization */
-		if ((port >= APP_MAX_NIC_PORTS) || (queue >= APP_MAX_RX_QUEUES_PER_NIC_PORT)) {
-			return -3;
-		}
-		if (app.nic_rx_queue_mask[port][queue] != 0) {
-			return -4;
-		}
-		app.nic_rx_queue_mask[port][queue] = 1;
-
-		/* Check and assign (port, queue) to I/O lcore */
-		if (rte_lcore_is_enabled(lcore) == 0) {
-			return -5;
-		}
-
-		if (lcore >= APP_MAX_LCORES) {
-			return -6;
-		}
-		lp = &app.lcore_params[lcore];
-		if (lp->type == e_APP_LCORE_WORKER) {
-			return -7;
-		}
-		lp->type = e_APP_LCORE_IO;
-		const size_t n_queues = RTE_MIN(lp->io.rx.n_nic_queues,
-		                                RTE_DIM(lp->io.rx.nic_queues));
-		for (i = 0; i < n_queues; i ++) {
-			if ((lp->io.rx.nic_queues[i].port == port) &&
-			    (lp->io.rx.nic_queues[i].queue == queue)) {
-				return -8;
-			}
-		}
-		if (lp->io.rx.n_nic_queues >= APP_MAX_NIC_RX_QUEUES_PER_IO_LCORE) {
-			return -9;
-		}
-		lp->io.rx.nic_queues[lp->io.rx.n_nic_queues].port = port;
-		lp->io.rx.nic_queues[lp->io.rx.n_nic_queues].queue = (uint8_t) queue;
-		lp->io.rx.n_nic_queues ++;
-
-		n_tuples ++;
-		if (n_tuples > APP_ARG_RX_MAX_TUPLES) {
-			return -10;
-		}
-	}
-
-	if (n_tuples == 0) {
-		return -11;
-	}
-
-	return 0;
-}
-
-#ifndef APP_ARG_TX_MAX_CHARS
-#define APP_ARG_TX_MAX_CHARS     4096
-#endif
-
-#ifndef APP_ARG_TX_MAX_TUPLES
-#define APP_ARG_TX_MAX_TUPLES    128
-#endif
-
-static int
-parse_arg_tx(const char *arg)
-{
-	const char *p0 = arg, *p = arg;
-	uint32_t n_tuples;
-
-	if (strnlen(arg, APP_ARG_TX_MAX_CHARS + 1) == APP_ARG_TX_MAX_CHARS + 1) {
-		return -1;
-	}
-
-	n_tuples = 0;
-	while ((p = strchr(p0,'(')) != NULL) {
-		struct app_lcore_params *lp;
-		uint32_t port, lcore, i;
-
-		p0 = strchr(p++, ')');
-		if ((p0 == NULL) ||
-		    (str_to_unsigned_vals(p, p0 - p, ',', 2, &port, &lcore) !=  2)) {
-			return -2;
-		}
-
-		/* Enable port and queue for later initialization */
-		if (port >= APP_MAX_NIC_PORTS) {
-			return -3;
-		}
-		if (app.nic_tx_port_mask[port] != 0) {
-			return -4;
-		}
-		app.nic_tx_port_mask[port] = 1;
-
-		/* Check and assign (port, queue) to I/O lcore */
-		if (rte_lcore_is_enabled(lcore) == 0) {
-			return -5;
-		}
-
-		if (lcore >= APP_MAX_LCORES) {
-			return -6;
-		}
-		lp = &app.lcore_params[lcore];
-		if (lp->type == e_APP_LCORE_WORKER) {
-			return -7;
-		}
-		lp->type = e_APP_LCORE_IO;
-		const size_t n_ports = RTE_MIN(lp->io.tx.n_nic_ports,
-		                               RTE_DIM(lp->io.tx.nic_ports));
-		for (i = 0; i < n_ports; i ++) {
-			if (lp->io.tx.nic_ports[i] == port) {
-				return -8;
-			}
-		}
-		if (lp->io.tx.n_nic_ports >= APP_MAX_NIC_TX_PORTS_PER_IO_LCORE) {
-			return -9;
-		}
-		lp->io.tx.nic_ports[lp->io.tx.n_nic_ports] = port;
-		lp->io.tx.n_nic_ports ++;
-
-		n_tuples ++;
-		if (n_tuples > APP_ARG_TX_MAX_TUPLES) {
-			return -10;
-		}
-	}
-
-	if (n_tuples == 0) {
-		return -11;
-	}
-
-	return 0;
-}
-
-#ifndef APP_ARG_W_MAX_CHARS
-#define APP_ARG_W_MAX_CHARS     4096
-#endif
-
-#ifndef APP_ARG_W_MAX_TUPLES
-#define APP_ARG_W_MAX_TUPLES    APP_MAX_WORKER_LCORES
-#endif
-
-static int
-parse_arg_w(const char *arg)
-{
-	const char *p = arg;
-	uint32_t n_tuples;
-
-	if (strnlen(arg, APP_ARG_W_MAX_CHARS + 1) == APP_ARG_W_MAX_CHARS + 1) {
-		return -1;
-	}
-
-	n_tuples = 0;
-	while (*p != 0) {
-		struct app_lcore_params *lp;
-		uint32_t lcore;
-
-		errno = 0;
-		lcore = strtoul(p, NULL, 0);
-		if (errno != 0) {
-			return -2;
-		}
-
-		/* Check and enable worker lcore */
-		if (rte_lcore_is_enabled(lcore) == 0) {
-			return -3;
-		}
-
-		if (lcore >= APP_MAX_LCORES) {
-			return -4;
-		}
-		lp = &app.lcore_params[lcore];
-		if (lp->type == e_APP_LCORE_IO) {
-			return -5;
-		}
-		lp->type = e_APP_LCORE_WORKER;
-
-		n_tuples ++;
-		if (n_tuples > APP_ARG_W_MAX_TUPLES) {
-			return -6;
-		}
-
-		p = strchr(p, ',');
-		if (p == NULL) {
-			break;
-		}
-		p ++;
-	}
-
-	if (n_tuples == 0) {
-		return -7;
-	}
-
-	if ((n_tuples & (n_tuples - 1)) != 0) {
-		return -8;
-	}
-
-	return 0;
-}
-
-#ifndef APP_ARG_LPM_MAX_CHARS
-#define APP_ARG_LPM_MAX_CHARS     4096
-#endif
-
-static int
-parse_arg_lpm(const char *arg)
-{
-	const char *p = arg, *p0;
-
-	if (strnlen(arg, APP_ARG_LPM_MAX_CHARS + 1) == APP_ARG_TX_MAX_CHARS + 1) {
-		return -1;
-	}
-
-	while (*p != 0) {
-		uint32_t ip_a, ip_b, ip_c, ip_d, ip, depth, if_out;
-		char *endptr;
-
-		p0 = strchr(p, '/');
-		if ((p0 == NULL) ||
-		    (str_to_unsigned_vals(p, p0 - p, '.', 4, &ip_a, &ip_b, &ip_c, &ip_d) != 4)) {
-			return -2;
-		}
-
-		p = p0 + 1;
-		errno = 0;
-		depth = strtoul(p, &endptr, 0);
-		if (errno != 0 || *endptr != '=') {
-			return -3;
-		}
-		p = strchr(p, '>');
-		if (p == NULL) {
-			return -4;
-		}
-		if_out = strtoul(++p, &endptr, 0);
-		if (errno != 0 || (*endptr != '\0' && *endptr != ';')) {
-			return -5;
-		}
-
-		if ((ip_a >= 256) || (ip_b >= 256) || (ip_c >= 256) || (ip_d >= 256) ||
-		     (depth == 0) || (depth >= 32) ||
-			 (if_out >= APP_MAX_NIC_PORTS)) {
-			return -6;
-		}
-		ip = (ip_a << 24) | (ip_b << 16) | (ip_c << 8) | ip_d;
-
-		if (app.n_lpm_rules >= APP_MAX_LPM_RULES) {
-			return -7;
-		}
-		app.lpm_rules[app.n_lpm_rules].ip = ip;
-		app.lpm_rules[app.n_lpm_rules].depth = (uint8_t) depth;
-		app.lpm_rules[app.n_lpm_rules].if_out = (uint8_t) if_out;
-		app.n_lpm_rules ++;
-
-		p = strchr(p, ';');
-		if (p == NULL) {
-			return -8;
-		}
-		p ++;
-	}
-
-	if (app.n_lpm_rules == 0) {
-		return -9;
-	}
-
-	return 0;
-}
-
-static int
-app_check_lpm_table(void)
-{
-	uint32_t rule;
-
-	/* For each rule, check that the output I/F is enabled */
-	for (rule = 0; rule < app.n_lpm_rules; rule ++)
-	{
-		uint32_t port = app.lpm_rules[rule].if_out;
-
-		if (app.nic_tx_port_mask[port] == 0) {
-			return -1;
-		}
-	}
-
-	return 0;
-}
-
-static int
-app_check_every_rx_port_is_tx_enabled(void)
-{
-	uint16_t port;
-
-	for (port = 0; port < APP_MAX_NIC_PORTS; port ++) {
-		if ((app_get_nic_rx_queues_per_port(port) > 0) && (app.nic_tx_port_mask[port] == 0)) {
-			return -1;
-		}
-	}
-
-	return 0;
-}
-
-#ifndef APP_ARG_RSZ_CHARS
-#define APP_ARG_RSZ_CHARS 63
-#endif
-
-static int
-parse_arg_rsz(const char *arg)
-{
-	if (strnlen(arg, APP_ARG_RSZ_CHARS + 1) == APP_ARG_RSZ_CHARS + 1) {
-		return -1;
-	}
-
-	if (str_to_unsigned_vals(arg, APP_ARG_RSZ_CHARS, ',', 4,
-			&app.nic_rx_ring_size,
-			&app.ring_rx_size,
-			&app.ring_tx_size,
-			&app.nic_tx_ring_size) !=  4)
-		return -2;
-
-
-	if ((app.nic_rx_ring_size == 0) ||
-		(app.nic_tx_ring_size == 0) ||
-		(app.ring_rx_size == 0) ||
-		(app.ring_tx_size == 0)) {
-		return -3;
-	}
-
-	return 0;
-}
-
-#ifndef APP_ARG_BSZ_CHARS
-#define APP_ARG_BSZ_CHARS 63
-#endif
-
-static int
-parse_arg_bsz(const char *arg)
-{
-	const char *p = arg, *p0;
-	if (strnlen(arg, APP_ARG_BSZ_CHARS + 1) == APP_ARG_BSZ_CHARS + 1) {
-		return -1;
-	}
-
-	p0 = strchr(p++, ')');
-	if ((p0 == NULL) ||
-	    (str_to_unsigned_vals(p, p0 - p, ',', 2, &app.burst_size_io_rx_read, &app.burst_size_io_rx_write) !=  2)) {
-		return -2;
-	}
-
-	p = strchr(p0, '(');
-	if (p == NULL) {
-		return -3;
-	}
-
-	p0 = strchr(p++, ')');
-	if ((p0 == NULL) ||
-	    (str_to_unsigned_vals(p, p0 - p, ',', 2, &app.burst_size_worker_read, &app.burst_size_worker_write) !=  2)) {
-		return -4;
-	}
-
-	p = strchr(p0, '(');
-	if (p == NULL) {
-		return -5;
-	}
-
-	p0 = strchr(p++, ')');
-	if ((p0 == NULL) ||
-	    (str_to_unsigned_vals(p, p0 - p, ',', 2, &app.burst_size_io_tx_read, &app.burst_size_io_tx_write) !=  2)) {
-		return -6;
-	}
-
-	if ((app.burst_size_io_rx_read == 0) ||
-		(app.burst_size_io_rx_write == 0) ||
-		(app.burst_size_worker_read == 0) ||
-		(app.burst_size_worker_write == 0) ||
-		(app.burst_size_io_tx_read == 0) ||
-		(app.burst_size_io_tx_write == 0)) {
-		return -7;
-	}
-
-	if ((app.burst_size_io_rx_read > APP_MBUF_ARRAY_SIZE) ||
-		(app.burst_size_io_rx_write > APP_MBUF_ARRAY_SIZE) ||
-		(app.burst_size_worker_read > APP_MBUF_ARRAY_SIZE) ||
-		(app.burst_size_worker_write > APP_MBUF_ARRAY_SIZE) ||
-		((2 * app.burst_size_io_tx_read) > APP_MBUF_ARRAY_SIZE) ||
-		(app.burst_size_io_tx_write > APP_MBUF_ARRAY_SIZE)) {
-		return -8;
-	}
-
-	return 0;
-}
-
-#ifndef APP_ARG_NUMERICAL_SIZE_CHARS
-#define APP_ARG_NUMERICAL_SIZE_CHARS 15
-#endif
-
-static int
-parse_arg_pos_lb(const char *arg)
-{
-	uint32_t x;
-	char *endpt;
-
-	if (strnlen(arg, APP_ARG_NUMERICAL_SIZE_CHARS + 1) == APP_ARG_NUMERICAL_SIZE_CHARS + 1) {
-		return -1;
-	}
-
-	errno = 0;
-	x = strtoul(arg, &endpt, 10);
-	if (errno != 0 || endpt == arg || *endpt != '\0'){
-		return -2;
-	}
-
-	if (x >= 64) {
-		return -3;
-	}
-
-	app.pos_lb = (uint8_t) x;
-
-	return 0;
-}
-
-/* Parse the argument given in the command line of the application */
-int
-app_parse_args(int argc, char **argv)
-{
-	int opt, ret;
-	char **argvopt;
-	int option_index;
-	char *prgname = argv[0];
-	static struct option lgopts[] = {
-		{"rx", 1, 0, 0},
-		{"tx", 1, 0, 0},
-		{"w", 1, 0, 0},
-		{"lpm", 1, 0, 0},
-		{"rsz", 1, 0, 0},
-		{"bsz", 1, 0, 0},
-		{"pos-lb", 1, 0, 0},
-		{NULL, 0, 0, 0}
-	};
-	uint32_t arg_w = 0;
-	uint32_t arg_rx = 0;
-	uint32_t arg_tx = 0;
-	uint32_t arg_lpm = 0;
-	uint32_t arg_rsz = 0;
-	uint32_t arg_bsz = 0;
-	uint32_t arg_pos_lb = 0;
-
-	argvopt = argv;
-
-	while ((opt = getopt_long(argc, argvopt, "",
-				lgopts, &option_index)) != EOF) {
-
-		switch (opt) {
-		/* long options */
-		case 0:
-			if (!strcmp(lgopts[option_index].name, "rx")) {
-				arg_rx = 1;
-				ret = parse_arg_rx(optarg);
-				if (ret) {
-					printf("Incorrect value for --rx argument (%d)\n", ret);
-					return -1;
-				}
-			}
-			if (!strcmp(lgopts[option_index].name, "tx")) {
-				arg_tx = 1;
-				ret = parse_arg_tx(optarg);
-				if (ret) {
-					printf("Incorrect value for --tx argument (%d)\n", ret);
-					return -1;
-				}
-			}
-			if (!strcmp(lgopts[option_index].name, "w")) {
-				arg_w = 1;
-				ret = parse_arg_w(optarg);
-				if (ret) {
-					printf("Incorrect value for --w argument (%d)\n", ret);
-					return -1;
-				}
-			}
-			if (!strcmp(lgopts[option_index].name, "lpm")) {
-				arg_lpm = 1;
-				ret = parse_arg_lpm(optarg);
-				if (ret) {
-					printf("Incorrect value for --lpm argument (%d)\n", ret);
-					return -1;
-				}
-			}
-			if (!strcmp(lgopts[option_index].name, "rsz")) {
-				arg_rsz = 1;
-				ret = parse_arg_rsz(optarg);
-				if (ret) {
-					printf("Incorrect value for --rsz argument (%d)\n", ret);
-					return -1;
-				}
-			}
-			if (!strcmp(lgopts[option_index].name, "bsz")) {
-				arg_bsz = 1;
-				ret = parse_arg_bsz(optarg);
-				if (ret) {
-					printf("Incorrect value for --bsz argument (%d)\n", ret);
-					return -1;
-				}
-			}
-			if (!strcmp(lgopts[option_index].name, "pos-lb")) {
-				arg_pos_lb = 1;
-				ret = parse_arg_pos_lb(optarg);
-				if (ret) {
-					printf("Incorrect value for --pos-lb argument (%d)\n", ret);
-					return -1;
-				}
-			}
-			break;
-
-		default:
-			return -1;
-		}
-	}
-
-	/* Check that all mandatory arguments are provided */
-	if ((arg_rx == 0) || (arg_tx == 0) || (arg_w == 0) || (arg_lpm == 0)){
-		printf("Not all mandatory arguments are present\n");
-		return -1;
-	}
-
-	/* Assign default values for the optional arguments not provided */
-	if (arg_rsz == 0) {
-		app.nic_rx_ring_size = APP_DEFAULT_NIC_RX_RING_SIZE;
-		app.nic_tx_ring_size = APP_DEFAULT_NIC_TX_RING_SIZE;
-		app.ring_rx_size = APP_DEFAULT_RING_RX_SIZE;
-		app.ring_tx_size = APP_DEFAULT_RING_TX_SIZE;
-	}
-
-	if (arg_bsz == 0) {
-		app.burst_size_io_rx_read = APP_DEFAULT_BURST_SIZE_IO_RX_READ;
-		app.burst_size_io_rx_write = APP_DEFAULT_BURST_SIZE_IO_RX_WRITE;
-		app.burst_size_io_tx_read = APP_DEFAULT_BURST_SIZE_IO_TX_READ;
-		app.burst_size_io_tx_write = APP_DEFAULT_BURST_SIZE_IO_TX_WRITE;
-		app.burst_size_worker_read = APP_DEFAULT_BURST_SIZE_WORKER_READ;
-		app.burst_size_worker_write = APP_DEFAULT_BURST_SIZE_WORKER_WRITE;
-	}
-
-	if (arg_pos_lb == 0) {
-		app.pos_lb = APP_DEFAULT_IO_RX_LB_POS;
-	}
-
-	/* Check cross-consistency of arguments */
-	if ((ret = app_check_lpm_table()) < 0) {
-		printf("At least one LPM rule is inconsistent (%d)\n", ret);
-		return -1;
-	}
-	if (app_check_every_rx_port_is_tx_enabled() < 0) {
-		printf("On LPM lookup miss, packet is sent back on the input port.\n");
-		printf("At least one RX port is not enabled for TX.\n");
-		return -2;
-	}
-
-	if (optind >= 0)
-		argv[optind - 1] = prgname;
-
-	ret = optind - 1;
-	optind = 1; /* reset getopt lib */
-	return ret;
-}
-
-int
-app_get_nic_rx_queues_per_port(uint16_t port)
-{
-	uint32_t i, count;
-
-	if (port >= APP_MAX_NIC_PORTS) {
-		return -1;
-	}
-
-	count = 0;
-	for (i = 0; i < APP_MAX_RX_QUEUES_PER_NIC_PORT; i ++) {
-		if (app.nic_rx_queue_mask[port][i] == 1) {
-			count ++;
-		}
-	}
-
-	return count;
-}
-
-int
-app_get_lcore_for_nic_rx(uint16_t port, uint8_t queue, uint32_t *lcore_out)
-{
-	uint32_t lcore;
-
-	for (lcore = 0; lcore < APP_MAX_LCORES; lcore ++) {
-		struct app_lcore_params_io *lp = &app.lcore_params[lcore].io;
-		uint32_t i;
-
-		if (app.lcore_params[lcore].type != e_APP_LCORE_IO) {
-			continue;
-		}
-
-		const size_t n_queues = RTE_MIN(lp->rx.n_nic_queues,
-		                                RTE_DIM(lp->rx.nic_queues));
-		for (i = 0; i < n_queues; i ++) {
-			if ((lp->rx.nic_queues[i].port == port) &&
-			    (lp->rx.nic_queues[i].queue == queue)) {
-				*lcore_out = lcore;
-				return 0;
-			}
-		}
-	}
-
-	return -1;
-}
-
-int
-app_get_lcore_for_nic_tx(uint16_t port, uint32_t *lcore_out)
-{
-	uint32_t lcore;
-
-	for (lcore = 0; lcore < APP_MAX_LCORES; lcore ++) {
-		struct app_lcore_params_io *lp = &app.lcore_params[lcore].io;
-		uint32_t i;
-
-		if (app.lcore_params[lcore].type != e_APP_LCORE_IO) {
-			continue;
-		}
-
-		const size_t n_ports = RTE_MIN(lp->tx.n_nic_ports,
-		                               RTE_DIM(lp->tx.nic_ports));
-		for (i = 0; i < n_ports; i ++) {
-			if (lp->tx.nic_ports[i] == port) {
-				*lcore_out = lcore;
-				return 0;
-			}
-		}
-	}
-
-	return -1;
-}
-
-int
-app_is_socket_used(uint32_t socket)
-{
-	uint32_t lcore;
-
-	for (lcore = 0; lcore < APP_MAX_LCORES; lcore ++) {
-		if (app.lcore_params[lcore].type == e_APP_LCORE_DISABLED) {
-			continue;
-		}
-
-		if (socket == rte_lcore_to_socket_id(lcore)) {
-			return 1;
-		}
-	}
-
-	return 0;
-}
-
-uint32_t
-app_get_lcores_io_rx(void)
-{
-	uint32_t lcore, count;
-
-	count = 0;
-	for (lcore = 0; lcore < APP_MAX_LCORES; lcore ++) {
-		struct app_lcore_params_io *lp_io = &app.lcore_params[lcore].io;
-
-		if ((app.lcore_params[lcore].type != e_APP_LCORE_IO) ||
-		    (lp_io->rx.n_nic_queues == 0)) {
-			continue;
-		}
-
-		count ++;
-	}
-
-	return count;
-}
-
-uint32_t
-app_get_lcores_worker(void)
-{
-	uint32_t lcore, count;
-
-	count = 0;
-	for (lcore = 0; lcore < APP_MAX_LCORES; lcore ++) {
-		if (app.lcore_params[lcore].type != e_APP_LCORE_WORKER) {
-			continue;
-		}
-
-		count ++;
-	}
-
-	if (count > APP_MAX_WORKER_LCORES) {
-		rte_panic("Algorithmic error (too many worker lcores)\n");
-		return 0;
-	}
-
-	return count;
-}
-
-void
-app_print_params(void)
-{
-	unsigned port, queue, lcore, rule, i, j;
-
-	/* Print NIC RX configuration */
-	printf("NIC RX ports: ");
-	for (port = 0; port < APP_MAX_NIC_PORTS; port ++) {
-		uint32_t n_rx_queues = app_get_nic_rx_queues_per_port(port);
-
-		if (n_rx_queues == 0) {
-			continue;
-		}
-
-		printf("%u (", port);
-		for (queue = 0; queue < APP_MAX_RX_QUEUES_PER_NIC_PORT; queue ++) {
-			if (app.nic_rx_queue_mask[port][queue] == 1) {
-				printf("%u ", queue);
-			}
-		}
-		printf(")  ");
-	}
-	printf(";\n");
-
-	/* Print I/O lcore RX params */
-	for (lcore = 0; lcore < APP_MAX_LCORES; lcore ++) {
-		struct app_lcore_params_io *lp = &app.lcore_params[lcore].io;
-
-		if ((app.lcore_params[lcore].type != e_APP_LCORE_IO) ||
-		    (lp->rx.n_nic_queues == 0)) {
-			continue;
-		}
-
-		printf("I/O lcore %u (socket %u): ", lcore, rte_lcore_to_socket_id(lcore));
-
-		printf("RX ports  ");
-		for (i = 0; i < lp->rx.n_nic_queues; i ++) {
-			printf("(%u, %u)  ",
-				(unsigned) lp->rx.nic_queues[i].port,
-				(unsigned) lp->rx.nic_queues[i].queue);
-		}
-		printf("; ");
-
-		printf("Output rings  ");
-		for (i = 0; i < lp->rx.n_rings; i ++) {
-			printf("%p  ", lp->rx.rings[i]);
-		}
-		printf(";\n");
-	}
-
-	/* Print worker lcore RX params */
-	for (lcore = 0; lcore < APP_MAX_LCORES; lcore ++) {
-		struct app_lcore_params_worker *lp = &app.lcore_params[lcore].worker;
-
-		if (app.lcore_params[lcore].type != e_APP_LCORE_WORKER) {
-			continue;
-		}
-
-		printf("Worker lcore %u (socket %u) ID %u: ",
-			lcore,
-			rte_lcore_to_socket_id(lcore),
-			(unsigned)lp->worker_id);
-
-		printf("Input rings  ");
-		for (i = 0; i < lp->n_rings_in; i ++) {
-			printf("%p  ", lp->rings_in[i]);
-		}
-
-		printf(";\n");
-	}
-
-	printf("\n");
-
-	/* Print NIC TX configuration */
-	printf("NIC TX ports:  ");
-	for (port = 0; port < APP_MAX_NIC_PORTS; port ++) {
-		if (app.nic_tx_port_mask[port] == 1) {
-			printf("%u  ", port);
-		}
-	}
-	printf(";\n");
-
-	/* Print I/O TX lcore params */
-	for (lcore = 0; lcore < APP_MAX_LCORES; lcore ++) {
-		struct app_lcore_params_io *lp = &app.lcore_params[lcore].io;
-		uint32_t n_workers = app_get_lcores_worker();
-
-		if ((app.lcore_params[lcore].type != e_APP_LCORE_IO) ||
-		     (lp->tx.n_nic_ports == 0)) {
-			continue;
-		}
-
-		printf("I/O lcore %u (socket %u): ", lcore, rte_lcore_to_socket_id(lcore));
-
-		printf("Input rings per TX port  ");
-		for (i = 0; i < lp->tx.n_nic_ports; i ++) {
-			port = lp->tx.nic_ports[i];
-
-			printf("%u (", port);
-			for (j = 0; j < n_workers; j ++) {
-				printf("%p  ", lp->tx.rings[port][j]);
-			}
-			printf(")  ");
-
-		}
-
-		printf(";\n");
-	}
-
-	/* Print worker lcore TX params */
-	for (lcore = 0; lcore < APP_MAX_LCORES; lcore ++) {
-		struct app_lcore_params_worker *lp = &app.lcore_params[lcore].worker;
-
-		if (app.lcore_params[lcore].type != e_APP_LCORE_WORKER) {
-			continue;
-		}
-
-		printf("Worker lcore %u (socket %u) ID %u: \n",
-			lcore,
-			rte_lcore_to_socket_id(lcore),
-			(unsigned)lp->worker_id);
-
-		printf("Output rings per TX port  ");
-		for (port = 0; port < APP_MAX_NIC_PORTS; port ++) {
-			if (lp->rings_out[port] != NULL) {
-				printf("%u (%p)  ", port, lp->rings_out[port]);
-			}
-		}
-
-		printf(";\n");
-	}
-
-	/* Print LPM rules */
-	printf("LPM rules: \n");
-	for (rule = 0; rule < app.n_lpm_rules; rule ++) {
-		uint32_t ip = app.lpm_rules[rule].ip;
-		uint8_t depth = app.lpm_rules[rule].depth;
-		uint8_t if_out = app.lpm_rules[rule].if_out;
-
-		printf("\t%u: %u.%u.%u.%u/%u => %u;\n",
-			rule,
-			(unsigned) (ip & 0xFF000000) >> 24,
-			(unsigned) (ip & 0x00FF0000) >> 16,
-			(unsigned) (ip & 0x0000FF00) >> 8,
-			(unsigned) ip & 0x000000FF,
-			(unsigned) depth,
-			(unsigned) if_out
-		);
-	}
-
-	/* Rings */
-	printf("Ring sizes: NIC RX = %u; Worker in = %u; Worker out = %u; NIC TX = %u;\n",
-		(unsigned) app.nic_rx_ring_size,
-		(unsigned) app.ring_rx_size,
-		(unsigned) app.ring_tx_size,
-		(unsigned) app.nic_tx_ring_size);
-
-	/* Bursts */
-	printf("Burst sizes: I/O RX (rd = %u, wr = %u); Worker (rd = %u, wr = %u); I/O TX (rd = %u, wr = %u)\n",
-		(unsigned) app.burst_size_io_rx_read,
-		(unsigned) app.burst_size_io_rx_write,
-		(unsigned) app.burst_size_worker_read,
-		(unsigned) app.burst_size_worker_write,
-		(unsigned) app.burst_size_io_tx_read,
-		(unsigned) app.burst_size_io_tx_write);
-}
diff --git a/examples/load_balancer/init.c b/examples/load_balancer/init.c
deleted file mode 100644
index 8d8dbe6..0000000
--- a/examples/load_balancer/init.c
+++ /dev/null
@@ -1,511 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <sys/types.h>
-#include <string.h>
-#include <sys/queue.h>
-#include <stdarg.h>
-#include <errno.h>
-#include <getopt.h>
-
-#include <rte_common.h>
-#include <rte_byteorder.h>
-#include <rte_log.h>
-#include <rte_memory.h>
-#include <rte_memcpy.h>
-#include <rte_eal.h>
-#include <rte_launch.h>
-#include <rte_atomic.h>
-#include <rte_cycles.h>
-#include <rte_prefetch.h>
-#include <rte_lcore.h>
-#include <rte_per_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_interrupts.h>
-#include <rte_random.h>
-#include <rte_debug.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_ring.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-#include <rte_string_fns.h>
-#include <rte_ip.h>
-#include <rte_tcp.h>
-#include <rte_lpm.h>
-
-#include "main.h"
-
-static struct rte_eth_conf port_conf = {
-	.rxmode = {
-		.mq_mode	= ETH_MQ_RX_RSS,
-		.split_hdr_size = 0,
-		.ignore_offload_bitfield = 1,
-		.offloads = (DEV_RX_OFFLOAD_CHECKSUM |
-			     DEV_RX_OFFLOAD_CRC_STRIP),
-	},
-	.rx_adv_conf = {
-		.rss_conf = {
-			.rss_key = NULL,
-			.rss_hf = ETH_RSS_IP,
-		},
-	},
-	.txmode = {
-		.mq_mode = ETH_MQ_TX_NONE,
-	},
-};
-
-static void
-app_assign_worker_ids(void)
-{
-	uint32_t lcore, worker_id;
-
-	/* Assign ID for each worker */
-	worker_id = 0;
-	for (lcore = 0; lcore < APP_MAX_LCORES; lcore ++) {
-		struct app_lcore_params_worker *lp_worker = &app.lcore_params[lcore].worker;
-
-		if (app.lcore_params[lcore].type != e_APP_LCORE_WORKER) {
-			continue;
-		}
-
-		lp_worker->worker_id = worker_id;
-		worker_id ++;
-	}
-}
-
-static void
-app_init_mbuf_pools(void)
-{
-	unsigned socket, lcore;
-
-	/* Init the buffer pools */
-	for (socket = 0; socket < APP_MAX_SOCKETS; socket ++) {
-		char name[32];
-		if (app_is_socket_used(socket) == 0) {
-			continue;
-		}
-
-		snprintf(name, sizeof(name), "mbuf_pool_%u", socket);
-		printf("Creating the mbuf pool for socket %u ...\n", socket);
-		app.pools[socket] = rte_pktmbuf_pool_create(
-			name, APP_DEFAULT_MEMPOOL_BUFFERS,
-			APP_DEFAULT_MEMPOOL_CACHE_SIZE,
-			0, APP_DEFAULT_MBUF_DATA_SIZE, socket);
-		if (app.pools[socket] == NULL) {
-			rte_panic("Cannot create mbuf pool on socket %u\n", socket);
-		}
-	}
-
-	for (lcore = 0; lcore < APP_MAX_LCORES; lcore ++) {
-		if (app.lcore_params[lcore].type == e_APP_LCORE_DISABLED) {
-			continue;
-		}
-
-		socket = rte_lcore_to_socket_id(lcore);
-		app.lcore_params[lcore].pool = app.pools[socket];
-	}
-}
-
-static void
-app_init_lpm_tables(void)
-{
-	unsigned socket, lcore;
-
-	/* Init the LPM tables */
-	for (socket = 0; socket < APP_MAX_SOCKETS; socket ++) {
-		char name[32];
-		uint32_t rule;
-
-		if (app_is_socket_used(socket) == 0) {
-			continue;
-		}
-
-		struct rte_lpm_config lpm_config;
-
-		lpm_config.max_rules = APP_MAX_LPM_RULES;
-		lpm_config.number_tbl8s = 256;
-		lpm_config.flags = 0;
-		snprintf(name, sizeof(name), "lpm_table_%u", socket);
-		printf("Creating the LPM table for socket %u ...\n", socket);
-		app.lpm_tables[socket] = rte_lpm_create(
-			name,
-			socket,
-			&lpm_config);
-		if (app.lpm_tables[socket] == NULL) {
-			rte_panic("Unable to create LPM table on socket %u\n", socket);
-		}
-
-		for (rule = 0; rule < app.n_lpm_rules; rule ++) {
-			int ret;
-
-			ret = rte_lpm_add(app.lpm_tables[socket],
-				app.lpm_rules[rule].ip,
-				app.lpm_rules[rule].depth,
-				app.lpm_rules[rule].if_out);
-
-			if (ret < 0) {
-				rte_panic("Unable to add entry %u (%x/%u => %u) to the LPM table on socket %u (%d)\n",
-					(unsigned) rule,
-					(unsigned) app.lpm_rules[rule].ip,
-					(unsigned) app.lpm_rules[rule].depth,
-					(unsigned) app.lpm_rules[rule].if_out,
-					socket,
-					ret);
-			}
-		}
-
-	}
-
-	for (lcore = 0; lcore < APP_MAX_LCORES; lcore ++) {
-		if (app.lcore_params[lcore].type != e_APP_LCORE_WORKER) {
-			continue;
-		}
-
-		socket = rte_lcore_to_socket_id(lcore);
-		app.lcore_params[lcore].worker.lpm_table = app.lpm_tables[socket];
-	}
-}
-
-static void
-app_init_rings_rx(void)
-{
-	unsigned lcore;
-
-	/* Initialize the rings for the RX side */
-	for (lcore = 0; lcore < APP_MAX_LCORES; lcore ++) {
-		struct app_lcore_params_io *lp_io = &app.lcore_params[lcore].io;
-		unsigned socket_io, lcore_worker;
-
-		if ((app.lcore_params[lcore].type != e_APP_LCORE_IO) ||
-		    (lp_io->rx.n_nic_queues == 0)) {
-			continue;
-		}
-
-		socket_io = rte_lcore_to_socket_id(lcore);
-
-		for (lcore_worker = 0; lcore_worker < APP_MAX_LCORES; lcore_worker ++) {
-			char name[32];
-			struct app_lcore_params_worker *lp_worker = &app.lcore_params[lcore_worker].worker;
-			struct rte_ring *ring = NULL;
-
-			if (app.lcore_params[lcore_worker].type != e_APP_LCORE_WORKER) {
-				continue;
-			}
-
-			printf("Creating ring to connect I/O lcore %u (socket %u) with worker lcore %u ...\n",
-				lcore,
-				socket_io,
-				lcore_worker);
-			snprintf(name, sizeof(name), "app_ring_rx_s%u_io%u_w%u",
-				socket_io,
-				lcore,
-				lcore_worker);
-			ring = rte_ring_create(
-				name,
-				app.ring_rx_size,
-				socket_io,
-				RING_F_SP_ENQ | RING_F_SC_DEQ);
-			if (ring == NULL) {
-				rte_panic("Cannot create ring to connect I/O core %u with worker core %u\n",
-					lcore,
-					lcore_worker);
-			}
-
-			lp_io->rx.rings[lp_io->rx.n_rings] = ring;
-			lp_io->rx.n_rings ++;
-
-			lp_worker->rings_in[lp_worker->n_rings_in] = ring;
-			lp_worker->n_rings_in ++;
-		}
-	}
-
-	for (lcore = 0; lcore < APP_MAX_LCORES; lcore ++) {
-		struct app_lcore_params_io *lp_io = &app.lcore_params[lcore].io;
-
-		if ((app.lcore_params[lcore].type != e_APP_LCORE_IO) ||
-		    (lp_io->rx.n_nic_queues == 0)) {
-			continue;
-		}
-
-		if (lp_io->rx.n_rings != app_get_lcores_worker()) {
-			rte_panic("Algorithmic error (I/O RX rings)\n");
-		}
-	}
-
-	for (lcore = 0; lcore < APP_MAX_LCORES; lcore ++) {
-		struct app_lcore_params_worker *lp_worker = &app.lcore_params[lcore].worker;
-
-		if (app.lcore_params[lcore].type != e_APP_LCORE_WORKER) {
-			continue;
-		}
-
-		if (lp_worker->n_rings_in != app_get_lcores_io_rx()) {
-			rte_panic("Algorithmic error (worker input rings)\n");
-		}
-	}
-}
-
-static void
-app_init_rings_tx(void)
-{
-	unsigned lcore;
-
-	/* Initialize the rings for the TX side */
-	for (lcore = 0; lcore < APP_MAX_LCORES; lcore ++) {
-		struct app_lcore_params_worker *lp_worker = &app.lcore_params[lcore].worker;
-		unsigned port;
-
-		if (app.lcore_params[lcore].type != e_APP_LCORE_WORKER) {
-			continue;
-		}
-
-		for (port = 0; port < APP_MAX_NIC_PORTS; port ++) {
-			char name[32];
-			struct app_lcore_params_io *lp_io = NULL;
-			struct rte_ring *ring;
-			uint32_t socket_io, lcore_io;
-
-			if (app.nic_tx_port_mask[port] == 0) {
-				continue;
-			}
-
-			if (app_get_lcore_for_nic_tx(port, &lcore_io) < 0) {
-				rte_panic("Algorithmic error (no I/O core to handle TX of port %u)\n",
-					port);
-			}
-
-			lp_io = &app.lcore_params[lcore_io].io;
-			socket_io = rte_lcore_to_socket_id(lcore_io);
-
-			printf("Creating ring to connect worker lcore %u with TX port %u (through I/O lcore %u) (socket %u) ...\n",
-				lcore, port, (unsigned)lcore_io, (unsigned)socket_io);
-			snprintf(name, sizeof(name), "app_ring_tx_s%u_w%u_p%u", socket_io, lcore, port);
-			ring = rte_ring_create(
-				name,
-				app.ring_tx_size,
-				socket_io,
-				RING_F_SP_ENQ | RING_F_SC_DEQ);
-			if (ring == NULL) {
-				rte_panic("Cannot create ring to connect worker core %u with TX port %u\n",
-					lcore,
-					port);
-			}
-
-			lp_worker->rings_out[port] = ring;
-			lp_io->tx.rings[port][lp_worker->worker_id] = ring;
-		}
-	}
-
-	for (lcore = 0; lcore < APP_MAX_LCORES; lcore ++) {
-		struct app_lcore_params_io *lp_io = &app.lcore_params[lcore].io;
-		unsigned i;
-
-		if ((app.lcore_params[lcore].type != e_APP_LCORE_IO) ||
-		    (lp_io->tx.n_nic_ports == 0)) {
-			continue;
-		}
-
-		for (i = 0; i < lp_io->tx.n_nic_ports; i ++){
-			unsigned port, j;
-
-			port = lp_io->tx.nic_ports[i];
-			for (j = 0; j < app_get_lcores_worker(); j ++) {
-				if (lp_io->tx.rings[port][j] == NULL) {
-					rte_panic("Algorithmic error (I/O TX rings)\n");
-				}
-			}
-		}
-	}
-}
-
-/* Check the link status of all ports in up to 9s, and print them finally */
-static void
-check_all_ports_link_status(uint16_t port_num, uint32_t port_mask)
-{
-#define CHECK_INTERVAL 100 /* 100ms */
-#define MAX_CHECK_TIME 90 /* 9s (90 * 100ms) in total */
-	uint16_t portid;
-	uint8_t count, all_ports_up, print_flag = 0;
-	struct rte_eth_link link;
-	uint32_t n_rx_queues, n_tx_queues;
-
-	printf("\nChecking link status");
-	fflush(stdout);
-	for (count = 0; count <= MAX_CHECK_TIME; count++) {
-		all_ports_up = 1;
-		for (portid = 0; portid < port_num; portid++) {
-			if ((port_mask & (1 << portid)) == 0)
-				continue;
-			n_rx_queues = app_get_nic_rx_queues_per_port(portid);
-			n_tx_queues = app.nic_tx_port_mask[portid];
-			if ((n_rx_queues == 0) && (n_tx_queues == 0))
-				continue;
-			memset(&link, 0, sizeof(link));
-			rte_eth_link_get_nowait(portid, &link);
-			/* print link status if flag set */
-			if (print_flag == 1) {
-				if (link.link_status)
-					printf(
-					"Port%d Link Up - speed %uMbps - %s\n",
-						portid, link.link_speed,
-				(link.link_duplex == ETH_LINK_FULL_DUPLEX) ?
-					("full-duplex") : ("half-duplex\n"));
-				else
-					printf("Port %d Link Down\n", portid);
-				continue;
-			}
-			/* clear all_ports_up flag if any link down */
-			if (link.link_status == ETH_LINK_DOWN) {
-				all_ports_up = 0;
-				break;
-			}
-		}
-		/* after finally printing all link status, get out */
-		if (print_flag == 1)
-			break;
-
-		if (all_ports_up == 0) {
-			printf(".");
-			fflush(stdout);
-			rte_delay_ms(CHECK_INTERVAL);
-		}
-
-		/* set the print_flag if all ports up or timeout */
-		if (all_ports_up == 1 || count == (MAX_CHECK_TIME - 1)) {
-			print_flag = 1;
-			printf("done\n");
-		}
-	}
-}
-
-static void
-app_init_nics(void)
-{
-	unsigned socket;
-	uint32_t lcore;
-	uint16_t port;
-	uint8_t queue;
-	int ret;
-	uint32_t n_rx_queues, n_tx_queues;
-
-	/* Init NIC ports and queues, then start the ports */
-	for (port = 0; port < APP_MAX_NIC_PORTS; port ++) {
-		struct rte_mempool *pool;
-		uint16_t nic_rx_ring_size;
-		uint16_t nic_tx_ring_size;
-		struct rte_eth_rxconf rxq_conf;
-		struct rte_eth_txconf txq_conf;
-		struct rte_eth_dev_info dev_info;
-		struct rte_eth_conf local_port_conf = port_conf;
-
-		n_rx_queues = app_get_nic_rx_queues_per_port(port);
-		n_tx_queues = app.nic_tx_port_mask[port];
-
-		if ((n_rx_queues == 0) && (n_tx_queues == 0)) {
-			continue;
-		}
-
-		/* Init port */
-		printf("Initializing NIC port %u ...\n", port);
-		rte_eth_dev_info_get(port, &dev_info);
-		if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-			local_port_conf.txmode.offloads |=
-				DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-		ret = rte_eth_dev_configure(
-			port,
-			(uint8_t) n_rx_queues,
-			(uint8_t) n_tx_queues,
-			&local_port_conf);
-		if (ret < 0) {
-			rte_panic("Cannot init NIC port %u (%d)\n", port, ret);
-		}
-		rte_eth_promiscuous_enable(port);
-
-		nic_rx_ring_size = app.nic_rx_ring_size;
-		nic_tx_ring_size = app.nic_tx_ring_size;
-		ret = rte_eth_dev_adjust_nb_rx_tx_desc(
-			port, &nic_rx_ring_size, &nic_tx_ring_size);
-		if (ret < 0) {
-			rte_panic("Cannot adjust number of descriptors for port %u (%d)\n",
-				  port, ret);
-		}
-		app.nic_rx_ring_size = nic_rx_ring_size;
-		app.nic_tx_ring_size = nic_tx_ring_size;
-
-		rxq_conf = dev_info.default_rxconf;
-		rxq_conf.offloads = local_port_conf.rxmode.offloads;
-		/* Init RX queues */
-		for (queue = 0; queue < APP_MAX_RX_QUEUES_PER_NIC_PORT; queue ++) {
-			if (app.nic_rx_queue_mask[port][queue] == 0) {
-				continue;
-			}
-
-			app_get_lcore_for_nic_rx(port, queue, &lcore);
-			socket = rte_lcore_to_socket_id(lcore);
-			pool = app.lcore_params[lcore].pool;
-
-			printf("Initializing NIC port %u RX queue %u ...\n",
-				port, queue);
-			ret = rte_eth_rx_queue_setup(
-				port,
-				queue,
-				(uint16_t) app.nic_rx_ring_size,
-				socket,
-				&rxq_conf,
-				pool);
-			if (ret < 0) {
-				rte_panic("Cannot init RX queue %u for port %u (%d)\n",
-					  queue, port, ret);
-			}
-		}
-
-		txq_conf = dev_info.default_txconf;
-		txq_conf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-		txq_conf.offloads = local_port_conf.txmode.offloads;
-		/* Init TX queues */
-		if (app.nic_tx_port_mask[port] == 1) {
-			app_get_lcore_for_nic_tx(port, &lcore);
-			socket = rte_lcore_to_socket_id(lcore);
-			printf("Initializing NIC port %u TX queue 0 ...\n",
-				port);
-			ret = rte_eth_tx_queue_setup(
-				port,
-				0,
-				(uint16_t) app.nic_tx_ring_size,
-				socket,
-				&txq_conf);
-			if (ret < 0) {
-				rte_panic("Cannot init TX queue 0 for port %d (%d)\n",
-					port,
-					ret);
-			}
-		}
-
-		/* Start port */
-		ret = rte_eth_dev_start(port);
-		if (ret < 0) {
-			rte_panic("Cannot start port %d (%d)\n", port, ret);
-		}
-	}
-
-	check_all_ports_link_status(APP_MAX_NIC_PORTS, (~0x0));
-}
-
-void
-app_init(void)
-{
-	app_assign_worker_ids();
-	app_init_mbuf_pools();
-	app_init_lpm_tables();
-	app_init_rings_rx();
-	app_init_rings_tx();
-	app_init_nics();
-
-	printf("Initialization completed.\n");
-}
diff --git a/examples/load_balancer/main.c b/examples/load_balancer/main.c
deleted file mode 100644
index d3dcb23..0000000
--- a/examples/load_balancer/main.c
+++ /dev/null
@@ -1,76 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <sys/types.h>
-#include <string.h>
-#include <sys/queue.h>
-#include <stdarg.h>
-#include <errno.h>
-#include <getopt.h>
-#include <unistd.h>
-
-#include <rte_common.h>
-#include <rte_byteorder.h>
-#include <rte_log.h>
-#include <rte_memory.h>
-#include <rte_memcpy.h>
-#include <rte_eal.h>
-#include <rte_launch.h>
-#include <rte_atomic.h>
-#include <rte_cycles.h>
-#include <rte_prefetch.h>
-#include <rte_lcore.h>
-#include <rte_per_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_interrupts.h>
-#include <rte_random.h>
-#include <rte_debug.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-#include <rte_ip.h>
-#include <rte_tcp.h>
-#include <rte_lpm.h>
-
-#include "main.h"
-
-int
-main(int argc, char **argv)
-{
-	uint32_t lcore;
-	int ret;
-
-	/* Init EAL */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		return -1;
-	argc -= ret;
-	argv += ret;
-
-	/* Parse application arguments (after the EAL ones) */
-	ret = app_parse_args(argc, argv);
-	if (ret < 0) {
-		app_print_usage();
-		return -1;
-	}
-
-	/* Init */
-	app_init();
-	app_print_params();
-
-	/* Launch per-lcore init on every lcore */
-	rte_eal_mp_remote_launch(app_lcore_main_loop, NULL, CALL_MASTER);
-	RTE_LCORE_FOREACH_SLAVE(lcore) {
-		if (rte_eal_wait_lcore(lcore) < 0) {
-			return -1;
-		}
-	}
-
-	return 0;
-}
diff --git a/examples/load_balancer/main.h b/examples/load_balancer/main.h
deleted file mode 100644
index 9fefb62..0000000
--- a/examples/load_balancer/main.h
+++ /dev/null
@@ -1,351 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#ifndef _MAIN_H_
-#define _MAIN_H_
-
-/* Logical cores */
-#ifndef APP_MAX_SOCKETS
-#define APP_MAX_SOCKETS 2
-#endif
-
-#ifndef APP_MAX_LCORES
-#define APP_MAX_LCORES       RTE_MAX_LCORE
-#endif
-
-#ifndef APP_MAX_NIC_PORTS
-#define APP_MAX_NIC_PORTS    RTE_MAX_ETHPORTS
-#endif
-
-#ifndef APP_MAX_RX_QUEUES_PER_NIC_PORT
-#define APP_MAX_RX_QUEUES_PER_NIC_PORT 128
-#endif
-
-#ifndef APP_MAX_TX_QUEUES_PER_NIC_PORT
-#define APP_MAX_TX_QUEUES_PER_NIC_PORT 128
-#endif
-
-#ifndef APP_MAX_IO_LCORES
-#if (APP_MAX_LCORES > 16)
-#define APP_MAX_IO_LCORES 16
-#else
-#define APP_MAX_IO_LCORES APP_MAX_LCORES
-#endif
-#endif
-#if (APP_MAX_IO_LCORES > APP_MAX_LCORES)
-#error "APP_MAX_IO_LCORES is too big"
-#endif
-
-#ifndef APP_MAX_NIC_RX_QUEUES_PER_IO_LCORE
-#define APP_MAX_NIC_RX_QUEUES_PER_IO_LCORE 16
-#endif
-
-#ifndef APP_MAX_NIC_TX_PORTS_PER_IO_LCORE
-#define APP_MAX_NIC_TX_PORTS_PER_IO_LCORE 16
-#endif
-#if (APP_MAX_NIC_TX_PORTS_PER_IO_LCORE > APP_MAX_NIC_PORTS)
-#error "APP_MAX_NIC_TX_PORTS_PER_IO_LCORE too big"
-#endif
-
-#ifndef APP_MAX_WORKER_LCORES
-#if (APP_MAX_LCORES > 16)
-#define APP_MAX_WORKER_LCORES 16
-#else
-#define APP_MAX_WORKER_LCORES APP_MAX_LCORES
-#endif
-#endif
-#if (APP_MAX_WORKER_LCORES > APP_MAX_LCORES)
-#error "APP_MAX_WORKER_LCORES is too big"
-#endif
-
-
-/* Mempools */
-#ifndef APP_DEFAULT_MBUF_DATA_SIZE
-#define APP_DEFAULT_MBUF_DATA_SIZE  RTE_MBUF_DEFAULT_BUF_SIZE
-#endif
-
-#ifndef APP_DEFAULT_MEMPOOL_BUFFERS
-#define APP_DEFAULT_MEMPOOL_BUFFERS   8192 * 4
-#endif
-
-#ifndef APP_DEFAULT_MEMPOOL_CACHE_SIZE
-#define APP_DEFAULT_MEMPOOL_CACHE_SIZE  256
-#endif
-
-/* LPM Tables */
-#ifndef APP_MAX_LPM_RULES
-#define APP_MAX_LPM_RULES 1024
-#endif
-
-/* NIC RX */
-#ifndef APP_DEFAULT_NIC_RX_RING_SIZE
-#define APP_DEFAULT_NIC_RX_RING_SIZE 1024
-#endif
-
-/*
- * RX and TX Prefetch, Host, and Write-back threshold values should be
- * carefully set for optimal performance. Consult the network
- * controller's datasheet and supporting DPDK documentation for guidance
- * on how these parameters should be set.
- */
-#ifndef APP_DEFAULT_NIC_RX_PTHRESH
-#define APP_DEFAULT_NIC_RX_PTHRESH  8
-#endif
-
-#ifndef APP_DEFAULT_NIC_RX_HTHRESH
-#define APP_DEFAULT_NIC_RX_HTHRESH  8
-#endif
-
-#ifndef APP_DEFAULT_NIC_RX_WTHRESH
-#define APP_DEFAULT_NIC_RX_WTHRESH  4
-#endif
-
-#ifndef APP_DEFAULT_NIC_RX_FREE_THRESH
-#define APP_DEFAULT_NIC_RX_FREE_THRESH  64
-#endif
-
-#ifndef APP_DEFAULT_NIC_RX_DROP_EN
-#define APP_DEFAULT_NIC_RX_DROP_EN 0
-#endif
-
-/* NIC TX */
-#ifndef APP_DEFAULT_NIC_TX_RING_SIZE
-#define APP_DEFAULT_NIC_TX_RING_SIZE 1024
-#endif
-
-/*
- * These default values are optimized for use with the Intel(R) 82599 10 GbE
- * Controller and the DPDK ixgbe PMD. Consider using other values for other
- * network controllers and/or network drivers.
- */
-#ifndef APP_DEFAULT_NIC_TX_PTHRESH
-#define APP_DEFAULT_NIC_TX_PTHRESH  36
-#endif
-
-#ifndef APP_DEFAULT_NIC_TX_HTHRESH
-#define APP_DEFAULT_NIC_TX_HTHRESH  0
-#endif
-
-#ifndef APP_DEFAULT_NIC_TX_WTHRESH
-#define APP_DEFAULT_NIC_TX_WTHRESH  0
-#endif
-
-#ifndef APP_DEFAULT_NIC_TX_FREE_THRESH
-#define APP_DEFAULT_NIC_TX_FREE_THRESH  0
-#endif
-
-#ifndef APP_DEFAULT_NIC_TX_RS_THRESH
-#define APP_DEFAULT_NIC_TX_RS_THRESH  0
-#endif
-
-/* Software Rings */
-#ifndef APP_DEFAULT_RING_RX_SIZE
-#define APP_DEFAULT_RING_RX_SIZE 1024
-#endif
-
-#ifndef APP_DEFAULT_RING_TX_SIZE
-#define APP_DEFAULT_RING_TX_SIZE 1024
-#endif
-
-/* Bursts */
-#ifndef APP_MBUF_ARRAY_SIZE
-#define APP_MBUF_ARRAY_SIZE   512
-#endif
-
-#ifndef APP_DEFAULT_BURST_SIZE_IO_RX_READ
-#define APP_DEFAULT_BURST_SIZE_IO_RX_READ  144
-#endif
-#if (APP_DEFAULT_BURST_SIZE_IO_RX_READ > APP_MBUF_ARRAY_SIZE)
-#error "APP_DEFAULT_BURST_SIZE_IO_RX_READ is too big"
-#endif
-
-#ifndef APP_DEFAULT_BURST_SIZE_IO_RX_WRITE
-#define APP_DEFAULT_BURST_SIZE_IO_RX_WRITE  144
-#endif
-#if (APP_DEFAULT_BURST_SIZE_IO_RX_WRITE > APP_MBUF_ARRAY_SIZE)
-#error "APP_DEFAULT_BURST_SIZE_IO_RX_WRITE is too big"
-#endif
-
-#ifndef APP_DEFAULT_BURST_SIZE_IO_TX_READ
-#define APP_DEFAULT_BURST_SIZE_IO_TX_READ  144
-#endif
-#if (APP_DEFAULT_BURST_SIZE_IO_TX_READ > APP_MBUF_ARRAY_SIZE)
-#error "APP_DEFAULT_BURST_SIZE_IO_TX_READ is too big"
-#endif
-
-#ifndef APP_DEFAULT_BURST_SIZE_IO_TX_WRITE
-#define APP_DEFAULT_BURST_SIZE_IO_TX_WRITE  144
-#endif
-#if (APP_DEFAULT_BURST_SIZE_IO_TX_WRITE > APP_MBUF_ARRAY_SIZE)
-#error "APP_DEFAULT_BURST_SIZE_IO_TX_WRITE is too big"
-#endif
-
-#ifndef APP_DEFAULT_BURST_SIZE_WORKER_READ
-#define APP_DEFAULT_BURST_SIZE_WORKER_READ  144
-#endif
-#if ((2 * APP_DEFAULT_BURST_SIZE_WORKER_READ) > APP_MBUF_ARRAY_SIZE)
-#error "APP_DEFAULT_BURST_SIZE_WORKER_READ is too big"
-#endif
-
-#ifndef APP_DEFAULT_BURST_SIZE_WORKER_WRITE
-#define APP_DEFAULT_BURST_SIZE_WORKER_WRITE  144
-#endif
-#if (APP_DEFAULT_BURST_SIZE_WORKER_WRITE > APP_MBUF_ARRAY_SIZE)
-#error "APP_DEFAULT_BURST_SIZE_WORKER_WRITE is too big"
-#endif
-
-/* Load balancing logic */
-#ifndef APP_DEFAULT_IO_RX_LB_POS
-#define APP_DEFAULT_IO_RX_LB_POS 29
-#endif
-#if (APP_DEFAULT_IO_RX_LB_POS >= 64)
-#error "APP_DEFAULT_IO_RX_LB_POS is too big"
-#endif
-
-struct app_mbuf_array {
-	struct rte_mbuf *array[APP_MBUF_ARRAY_SIZE];
-	uint32_t n_mbufs;
-};
-
-enum app_lcore_type {
-	e_APP_LCORE_DISABLED = 0,
-	e_APP_LCORE_IO,
-	e_APP_LCORE_WORKER
-};
-
-struct app_lcore_params_io {
-	/* I/O RX */
-	struct {
-		/* NIC */
-		struct {
-			uint16_t port;
-			uint8_t queue;
-		} nic_queues[APP_MAX_NIC_RX_QUEUES_PER_IO_LCORE];
-		uint32_t n_nic_queues;
-
-		/* Rings */
-		struct rte_ring *rings[APP_MAX_WORKER_LCORES];
-		uint32_t n_rings;
-
-		/* Internal buffers */
-		struct app_mbuf_array mbuf_in;
-		struct app_mbuf_array mbuf_out[APP_MAX_WORKER_LCORES];
-		uint8_t mbuf_out_flush[APP_MAX_WORKER_LCORES];
-
-		/* Stats */
-		uint32_t nic_queues_count[APP_MAX_NIC_RX_QUEUES_PER_IO_LCORE];
-		uint32_t nic_queues_iters[APP_MAX_NIC_RX_QUEUES_PER_IO_LCORE];
-		uint32_t rings_count[APP_MAX_WORKER_LCORES];
-		uint32_t rings_iters[APP_MAX_WORKER_LCORES];
-	} rx;
-
-	/* I/O TX */
-	struct {
-		/* Rings */
-		struct rte_ring *rings[APP_MAX_NIC_PORTS][APP_MAX_WORKER_LCORES];
-
-		/* NIC */
-		uint16_t nic_ports[APP_MAX_NIC_TX_PORTS_PER_IO_LCORE];
-		uint32_t n_nic_ports;
-
-		/* Internal buffers */
-		struct app_mbuf_array mbuf_out[APP_MAX_NIC_TX_PORTS_PER_IO_LCORE];
-		uint8_t mbuf_out_flush[APP_MAX_NIC_TX_PORTS_PER_IO_LCORE];
-
-		/* Stats */
-		uint32_t rings_count[APP_MAX_NIC_PORTS][APP_MAX_WORKER_LCORES];
-		uint32_t rings_iters[APP_MAX_NIC_PORTS][APP_MAX_WORKER_LCORES];
-		uint32_t nic_ports_count[APP_MAX_NIC_TX_PORTS_PER_IO_LCORE];
-		uint32_t nic_ports_iters[APP_MAX_NIC_TX_PORTS_PER_IO_LCORE];
-	} tx;
-};
-
-struct app_lcore_params_worker {
-	/* Rings */
-	struct rte_ring *rings_in[APP_MAX_IO_LCORES];
-	uint32_t n_rings_in;
-	struct rte_ring *rings_out[APP_MAX_NIC_PORTS];
-
-	/* LPM table */
-	struct rte_lpm *lpm_table;
-	uint32_t worker_id;
-
-	/* Internal buffers */
-	struct app_mbuf_array mbuf_in;
-	struct app_mbuf_array mbuf_out[APP_MAX_NIC_PORTS];
-	uint8_t mbuf_out_flush[APP_MAX_NIC_PORTS];
-
-	/* Stats */
-	uint32_t rings_in_count[APP_MAX_IO_LCORES];
-	uint32_t rings_in_iters[APP_MAX_IO_LCORES];
-	uint32_t rings_out_count[APP_MAX_NIC_PORTS];
-	uint32_t rings_out_iters[APP_MAX_NIC_PORTS];
-};
-
-struct app_lcore_params {
-	union {
-		struct app_lcore_params_io io;
-		struct app_lcore_params_worker worker;
-	};
-	enum app_lcore_type type;
-	struct rte_mempool *pool;
-} __rte_cache_aligned;
-
-struct app_lpm_rule {
-	uint32_t ip;
-	uint8_t depth;
-	uint8_t if_out;
-};
-
-struct app_params {
-	/* lcore */
-	struct app_lcore_params lcore_params[APP_MAX_LCORES];
-
-	/* NIC */
-	uint8_t nic_rx_queue_mask[APP_MAX_NIC_PORTS][APP_MAX_RX_QUEUES_PER_NIC_PORT];
-	uint8_t nic_tx_port_mask[APP_MAX_NIC_PORTS];
-
-	/* mbuf pools */
-	struct rte_mempool *pools[APP_MAX_SOCKETS];
-
-	/* LPM tables */
-	struct rte_lpm *lpm_tables[APP_MAX_SOCKETS];
-	struct app_lpm_rule lpm_rules[APP_MAX_LPM_RULES];
-	uint32_t n_lpm_rules;
-
-	/* rings */
-	uint32_t nic_rx_ring_size;
-	uint32_t nic_tx_ring_size;
-	uint32_t ring_rx_size;
-	uint32_t ring_tx_size;
-
-	/* burst size */
-	uint32_t burst_size_io_rx_read;
-	uint32_t burst_size_io_rx_write;
-	uint32_t burst_size_io_tx_read;
-	uint32_t burst_size_io_tx_write;
-	uint32_t burst_size_worker_read;
-	uint32_t burst_size_worker_write;
-
-	/* load balancing */
-	uint8_t pos_lb;
-} __rte_cache_aligned;
-
-extern struct app_params app;
-
-int app_parse_args(int argc, char **argv);
-void app_print_usage(void);
-void app_init(void);
-int app_lcore_main_loop(void *arg);
-
-int app_get_nic_rx_queues_per_port(uint16_t port);
-int app_get_lcore_for_nic_rx(uint16_t port, uint8_t queue,
-			      uint32_t *lcore_out);
-int app_get_lcore_for_nic_tx(uint16_t port, uint32_t *lcore_out);
-int app_is_socket_used(uint32_t socket);
-uint32_t app_get_lcores_io_rx(void);
-uint32_t app_get_lcores_worker(void);
-void app_print_params(void);
-
-#endif /* _MAIN_H_ */
diff --git a/examples/load_balancer/meson.build b/examples/load_balancer/meson.build
deleted file mode 100644
index 4f7ac39..0000000
--- a/examples/load_balancer/meson.build
+++ /dev/null
@@ -1,12 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-deps += 'lpm'
-sources = files(
-	'config.c', 'init.c', 'main.c', 'runtime.c'
-)
diff --git a/examples/load_balancer/runtime.c b/examples/load_balancer/runtime.c
deleted file mode 100644
index 39a846a..0000000
--- a/examples/load_balancer/runtime.c
+++ /dev/null
@@ -1,642 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <sys/types.h>
-#include <string.h>
-#include <sys/queue.h>
-#include <stdarg.h>
-#include <errno.h>
-#include <getopt.h>
-
-#include <rte_common.h>
-#include <rte_byteorder.h>
-#include <rte_log.h>
-#include <rte_memory.h>
-#include <rte_memcpy.h>
-#include <rte_eal.h>
-#include <rte_launch.h>
-#include <rte_atomic.h>
-#include <rte_cycles.h>
-#include <rte_prefetch.h>
-#include <rte_lcore.h>
-#include <rte_per_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_interrupts.h>
-#include <rte_random.h>
-#include <rte_debug.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_ring.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-#include <rte_ip.h>
-#include <rte_tcp.h>
-#include <rte_lpm.h>
-
-#include "main.h"
-
-#ifndef APP_LCORE_IO_FLUSH
-#define APP_LCORE_IO_FLUSH           1000000
-#endif
-
-#ifndef APP_LCORE_WORKER_FLUSH
-#define APP_LCORE_WORKER_FLUSH       1000000
-#endif
-
-#ifndef APP_STATS
-#define APP_STATS                    1000000
-#endif
-
-#define APP_IO_RX_DROP_ALL_PACKETS   0
-#define APP_WORKER_DROP_ALL_PACKETS  0
-#define APP_IO_TX_DROP_ALL_PACKETS   0
-
-#ifndef APP_IO_RX_PREFETCH_ENABLE
-#define APP_IO_RX_PREFETCH_ENABLE    1
-#endif
-
-#ifndef APP_WORKER_PREFETCH_ENABLE
-#define APP_WORKER_PREFETCH_ENABLE   1
-#endif
-
-#ifndef APP_IO_TX_PREFETCH_ENABLE
-#define APP_IO_TX_PREFETCH_ENABLE    1
-#endif
-
-#if APP_IO_RX_PREFETCH_ENABLE
-#define APP_IO_RX_PREFETCH0(p)       rte_prefetch0(p)
-#define APP_IO_RX_PREFETCH1(p)       rte_prefetch1(p)
-#else
-#define APP_IO_RX_PREFETCH0(p)
-#define APP_IO_RX_PREFETCH1(p)
-#endif
-
-#if APP_WORKER_PREFETCH_ENABLE
-#define APP_WORKER_PREFETCH0(p)      rte_prefetch0(p)
-#define APP_WORKER_PREFETCH1(p)      rte_prefetch1(p)
-#else
-#define APP_WORKER_PREFETCH0(p)
-#define APP_WORKER_PREFETCH1(p)
-#endif
-
-#if APP_IO_TX_PREFETCH_ENABLE
-#define APP_IO_TX_PREFETCH0(p)       rte_prefetch0(p)
-#define APP_IO_TX_PREFETCH1(p)       rte_prefetch1(p)
-#else
-#define APP_IO_TX_PREFETCH0(p)
-#define APP_IO_TX_PREFETCH1(p)
-#endif
-
-static inline void
-app_lcore_io_rx_buffer_to_send (
-	struct app_lcore_params_io *lp,
-	uint32_t worker,
-	struct rte_mbuf *mbuf,
-	uint32_t bsz)
-{
-	uint32_t pos;
-	int ret;
-
-	pos = lp->rx.mbuf_out[worker].n_mbufs;
-	lp->rx.mbuf_out[worker].array[pos ++] = mbuf;
-	if (likely(pos < bsz)) {
-		lp->rx.mbuf_out[worker].n_mbufs = pos;
-		return;
-	}
-
-	ret = rte_ring_sp_enqueue_bulk(
-		lp->rx.rings[worker],
-		(void **) lp->rx.mbuf_out[worker].array,
-		bsz,
-		NULL);
-
-	if (unlikely(ret == 0)) {
-		uint32_t k;
-		for (k = 0; k < bsz; k ++) {
-			struct rte_mbuf *m = lp->rx.mbuf_out[worker].array[k];
-			rte_pktmbuf_free(m);
-		}
-	}
-
-	lp->rx.mbuf_out[worker].n_mbufs = 0;
-	lp->rx.mbuf_out_flush[worker] = 0;
-
-#if APP_STATS
-	lp->rx.rings_iters[worker] ++;
-	if (likely(ret == 0)) {
-		lp->rx.rings_count[worker] ++;
-	}
-	if (unlikely(lp->rx.rings_iters[worker] == APP_STATS)) {
-		unsigned lcore = rte_lcore_id();
-
-		printf("\tI/O RX %u out (worker %u): enq success rate = %.2f\n",
-			lcore,
-			(unsigned)worker,
-			((double) lp->rx.rings_count[worker]) / ((double) lp->rx.rings_iters[worker]));
-		lp->rx.rings_iters[worker] = 0;
-		lp->rx.rings_count[worker] = 0;
-	}
-#endif
-}
-
-static inline void
-app_lcore_io_rx(
-	struct app_lcore_params_io *lp,
-	uint32_t n_workers,
-	uint32_t bsz_rd,
-	uint32_t bsz_wr,
-	uint8_t pos_lb)
-{
-	struct rte_mbuf *mbuf_1_0, *mbuf_1_1, *mbuf_2_0, *mbuf_2_1;
-	uint8_t *data_1_0, *data_1_1 = NULL;
-	uint32_t i;
-
-	for (i = 0; i < lp->rx.n_nic_queues; i ++) {
-		uint16_t port = lp->rx.nic_queues[i].port;
-		uint8_t queue = lp->rx.nic_queues[i].queue;
-		uint32_t n_mbufs, j;
-
-		n_mbufs = rte_eth_rx_burst(
-			port,
-			queue,
-			lp->rx.mbuf_in.array,
-			(uint16_t) bsz_rd);
-
-		if (unlikely(n_mbufs == 0)) {
-			continue;
-		}
-
-#if APP_STATS
-		lp->rx.nic_queues_iters[i] ++;
-		lp->rx.nic_queues_count[i] += n_mbufs;
-		if (unlikely(lp->rx.nic_queues_iters[i] == APP_STATS)) {
-			struct rte_eth_stats stats;
-			unsigned lcore = rte_lcore_id();
-
-			rte_eth_stats_get(port, &stats);
-
-			printf("I/O RX %u in (NIC port %u): NIC drop ratio = %.2f avg burst size = %.2f\n",
-				lcore,
-				port,
-				(double) stats.imissed / (double) (stats.imissed + stats.ipackets),
-				((double) lp->rx.nic_queues_count[i]) / ((double) lp->rx.nic_queues_iters[i]));
-			lp->rx.nic_queues_iters[i] = 0;
-			lp->rx.nic_queues_count[i] = 0;
-		}
-#endif
-
-#if APP_IO_RX_DROP_ALL_PACKETS
-		for (j = 0; j < n_mbufs; j ++) {
-			struct rte_mbuf *pkt = lp->rx.mbuf_in.array[j];
-			rte_pktmbuf_free(pkt);
-		}
-
-		continue;
-#endif
-
-		mbuf_1_0 = lp->rx.mbuf_in.array[0];
-		mbuf_1_1 = lp->rx.mbuf_in.array[1];
-		data_1_0 = rte_pktmbuf_mtod(mbuf_1_0, uint8_t *);
-		if (likely(n_mbufs > 1)) {
-			data_1_1 = rte_pktmbuf_mtod(mbuf_1_1, uint8_t *);
-		}
-
-		mbuf_2_0 = lp->rx.mbuf_in.array[2];
-		mbuf_2_1 = lp->rx.mbuf_in.array[3];
-		APP_IO_RX_PREFETCH0(mbuf_2_0);
-		APP_IO_RX_PREFETCH0(mbuf_2_1);
-
-		for (j = 0; j + 3 < n_mbufs; j += 2) {
-			struct rte_mbuf *mbuf_0_0, *mbuf_0_1;
-			uint8_t *data_0_0, *data_0_1;
-			uint32_t worker_0, worker_1;
-
-			mbuf_0_0 = mbuf_1_0;
-			mbuf_0_1 = mbuf_1_1;
-			data_0_0 = data_1_0;
-			data_0_1 = data_1_1;
-
-			mbuf_1_0 = mbuf_2_0;
-			mbuf_1_1 = mbuf_2_1;
-			data_1_0 = rte_pktmbuf_mtod(mbuf_2_0, uint8_t *);
-			data_1_1 = rte_pktmbuf_mtod(mbuf_2_1, uint8_t *);
-			APP_IO_RX_PREFETCH0(data_1_0);
-			APP_IO_RX_PREFETCH0(data_1_1);
-
-			mbuf_2_0 = lp->rx.mbuf_in.array[j+4];
-			mbuf_2_1 = lp->rx.mbuf_in.array[j+5];
-			APP_IO_RX_PREFETCH0(mbuf_2_0);
-			APP_IO_RX_PREFETCH0(mbuf_2_1);
-
-			worker_0 = data_0_0[pos_lb] & (n_workers - 1);
-			worker_1 = data_0_1[pos_lb] & (n_workers - 1);
-
-			app_lcore_io_rx_buffer_to_send(lp, worker_0, mbuf_0_0, bsz_wr);
-			app_lcore_io_rx_buffer_to_send(lp, worker_1, mbuf_0_1, bsz_wr);
-		}
-
-		/* Handle the last 1, 2 (when n_mbufs is even) or 3 (when n_mbufs is odd) packets  */
-		for ( ; j < n_mbufs; j += 1) {
-			struct rte_mbuf *mbuf;
-			uint8_t *data;
-			uint32_t worker;
-
-			mbuf = mbuf_1_0;
-			mbuf_1_0 = mbuf_1_1;
-			mbuf_1_1 = mbuf_2_0;
-			mbuf_2_0 = mbuf_2_1;
-
-			data = rte_pktmbuf_mtod(mbuf, uint8_t *);
-
-			APP_IO_RX_PREFETCH0(mbuf_1_0);
-
-			worker = data[pos_lb] & (n_workers - 1);
-
-			app_lcore_io_rx_buffer_to_send(lp, worker, mbuf, bsz_wr);
-		}
-	}
-}
-
-static inline void
-app_lcore_io_rx_flush(struct app_lcore_params_io *lp, uint32_t n_workers)
-{
-	uint32_t worker;
-
-	for (worker = 0; worker < n_workers; worker ++) {
-		int ret;
-
-		if (likely((lp->rx.mbuf_out_flush[worker] == 0) ||
-		           (lp->rx.mbuf_out[worker].n_mbufs == 0))) {
-			lp->rx.mbuf_out_flush[worker] = 1;
-			continue;
-		}
-
-		ret = rte_ring_sp_enqueue_bulk(
-			lp->rx.rings[worker],
-			(void **) lp->rx.mbuf_out[worker].array,
-			lp->rx.mbuf_out[worker].n_mbufs,
-			NULL);
-
-		if (unlikely(ret == 0)) {
-			uint32_t k;
-			for (k = 0; k < lp->rx.mbuf_out[worker].n_mbufs; k ++) {
-				struct rte_mbuf *pkt_to_free = lp->rx.mbuf_out[worker].array[k];
-				rte_pktmbuf_free(pkt_to_free);
-			}
-		}
-
-		lp->rx.mbuf_out[worker].n_mbufs = 0;
-		lp->rx.mbuf_out_flush[worker] = 1;
-	}
-}
-
-static inline void
-app_lcore_io_tx(
-	struct app_lcore_params_io *lp,
-	uint32_t n_workers,
-	uint32_t bsz_rd,
-	uint32_t bsz_wr)
-{
-	uint32_t worker;
-
-	for (worker = 0; worker < n_workers; worker ++) {
-		uint32_t i;
-
-		for (i = 0; i < lp->tx.n_nic_ports; i ++) {
-			uint16_t port = lp->tx.nic_ports[i];
-			struct rte_ring *ring = lp->tx.rings[port][worker];
-			uint32_t n_mbufs, n_pkts;
-			int ret;
-
-			n_mbufs = lp->tx.mbuf_out[port].n_mbufs;
-			ret = rte_ring_sc_dequeue_bulk(
-				ring,
-				(void **) &lp->tx.mbuf_out[port].array[n_mbufs],
-				bsz_rd,
-				NULL);
-
-			if (unlikely(ret == 0))
-				continue;
-
-			n_mbufs += bsz_rd;
-
-#if APP_IO_TX_DROP_ALL_PACKETS
-			{
-				uint32_t j;
-				APP_IO_TX_PREFETCH0(lp->tx.mbuf_out[port].array[0]);
-				APP_IO_TX_PREFETCH0(lp->tx.mbuf_out[port].array[1]);
-
-				for (j = 0; j < n_mbufs; j ++) {
-					if (likely(j < n_mbufs - 2)) {
-						APP_IO_TX_PREFETCH0(lp->tx.mbuf_out[port].array[j + 2]);
-					}
-
-					rte_pktmbuf_free(lp->tx.mbuf_out[port].array[j]);
-				}
-
-				lp->tx.mbuf_out[port].n_mbufs = 0;
-
-				continue;
-			}
-#endif
-
-			if (unlikely(n_mbufs < bsz_wr)) {
-				lp->tx.mbuf_out[port].n_mbufs = n_mbufs;
-				continue;
-			}
-
-			n_pkts = rte_eth_tx_burst(
-				port,
-				0,
-				lp->tx.mbuf_out[port].array,
-				(uint16_t) n_mbufs);
-
-#if APP_STATS
-			lp->tx.nic_ports_iters[port] ++;
-			lp->tx.nic_ports_count[port] += n_pkts;
-			if (unlikely(lp->tx.nic_ports_iters[port] == APP_STATS)) {
-				unsigned lcore = rte_lcore_id();
-
-				printf("\t\t\tI/O TX %u out (port %u): avg burst size = %.2f\n",
-					lcore,
-					port,
-					((double) lp->tx.nic_ports_count[port]) / ((double) lp->tx.nic_ports_iters[port]));
-				lp->tx.nic_ports_iters[port] = 0;
-				lp->tx.nic_ports_count[port] = 0;
-			}
-#endif
-
-			if (unlikely(n_pkts < n_mbufs)) {
-				uint32_t k;
-				for (k = n_pkts; k < n_mbufs; k ++) {
-					struct rte_mbuf *pkt_to_free = lp->tx.mbuf_out[port].array[k];
-					rte_pktmbuf_free(pkt_to_free);
-				}
-			}
-			lp->tx.mbuf_out[port].n_mbufs = 0;
-			lp->tx.mbuf_out_flush[port] = 0;
-		}
-	}
-}
-
-static inline void
-app_lcore_io_tx_flush(struct app_lcore_params_io *lp)
-{
-	uint16_t port;
-	uint32_t i;
-
-	for (i = 0; i < lp->tx.n_nic_ports; i++) {
-		uint32_t n_pkts;
-
-		port = lp->tx.nic_ports[i];
-		if (likely((lp->tx.mbuf_out_flush[port] == 0) ||
-		           (lp->tx.mbuf_out[port].n_mbufs == 0))) {
-			lp->tx.mbuf_out_flush[port] = 1;
-			continue;
-		}
-
-		n_pkts = rte_eth_tx_burst(
-			port,
-			0,
-			lp->tx.mbuf_out[port].array,
-			(uint16_t) lp->tx.mbuf_out[port].n_mbufs);
-
-		if (unlikely(n_pkts < lp->tx.mbuf_out[port].n_mbufs)) {
-			uint32_t k;
-			for (k = n_pkts; k < lp->tx.mbuf_out[port].n_mbufs; k ++) {
-				struct rte_mbuf *pkt_to_free = lp->tx.mbuf_out[port].array[k];
-				rte_pktmbuf_free(pkt_to_free);
-			}
-		}
-
-		lp->tx.mbuf_out[port].n_mbufs = 0;
-		lp->tx.mbuf_out_flush[port] = 1;
-	}
-}
-
-static void
-app_lcore_main_loop_io(void)
-{
-	uint32_t lcore = rte_lcore_id();
-	struct app_lcore_params_io *lp = &app.lcore_params[lcore].io;
-	uint32_t n_workers = app_get_lcores_worker();
-	uint64_t i = 0;
-
-	uint32_t bsz_rx_rd = app.burst_size_io_rx_read;
-	uint32_t bsz_rx_wr = app.burst_size_io_rx_write;
-	uint32_t bsz_tx_rd = app.burst_size_io_tx_read;
-	uint32_t bsz_tx_wr = app.burst_size_io_tx_write;
-
-	uint8_t pos_lb = app.pos_lb;
-
-	for ( ; ; ) {
-		if (APP_LCORE_IO_FLUSH && (unlikely(i == APP_LCORE_IO_FLUSH))) {
-			if (likely(lp->rx.n_nic_queues > 0)) {
-				app_lcore_io_rx_flush(lp, n_workers);
-			}
-
-			if (likely(lp->tx.n_nic_ports > 0)) {
-				app_lcore_io_tx_flush(lp);
-			}
-
-			i = 0;
-		}
-
-		if (likely(lp->rx.n_nic_queues > 0)) {
-			app_lcore_io_rx(lp, n_workers, bsz_rx_rd, bsz_rx_wr, pos_lb);
-		}
-
-		if (likely(lp->tx.n_nic_ports > 0)) {
-			app_lcore_io_tx(lp, n_workers, bsz_tx_rd, bsz_tx_wr);
-		}
-
-		i ++;
-	}
-}
-
-static inline void
-app_lcore_worker(
-	struct app_lcore_params_worker *lp,
-	uint32_t bsz_rd,
-	uint32_t bsz_wr)
-{
-	uint32_t i;
-
-	for (i = 0; i < lp->n_rings_in; i ++) {
-		struct rte_ring *ring_in = lp->rings_in[i];
-		uint32_t j;
-		int ret;
-
-		ret = rte_ring_sc_dequeue_bulk(
-			ring_in,
-			(void **) lp->mbuf_in.array,
-			bsz_rd,
-			NULL);
-
-		if (unlikely(ret == 0))
-			continue;
-
-#if APP_WORKER_DROP_ALL_PACKETS
-		for (j = 0; j < bsz_rd; j ++) {
-			struct rte_mbuf *pkt = lp->mbuf_in.array[j];
-			rte_pktmbuf_free(pkt);
-		}
-
-		continue;
-#endif
-
-		APP_WORKER_PREFETCH1(rte_pktmbuf_mtod(lp->mbuf_in.array[0], unsigned char *));
-		APP_WORKER_PREFETCH0(lp->mbuf_in.array[1]);
-
-		for (j = 0; j < bsz_rd; j ++) {
-			struct rte_mbuf *pkt;
-			struct ipv4_hdr *ipv4_hdr;
-			uint32_t ipv4_dst, pos;
-			uint32_t port;
-
-			if (likely(j < bsz_rd - 1)) {
-				APP_WORKER_PREFETCH1(rte_pktmbuf_mtod(lp->mbuf_in.array[j+1], unsigned char *));
-			}
-			if (likely(j < bsz_rd - 2)) {
-				APP_WORKER_PREFETCH0(lp->mbuf_in.array[j+2]);
-			}
-
-			pkt = lp->mbuf_in.array[j];
-			ipv4_hdr = rte_pktmbuf_mtod_offset(pkt,
-							   struct ipv4_hdr *,
-							   sizeof(struct ether_hdr));
-			ipv4_dst = rte_be_to_cpu_32(ipv4_hdr->dst_addr);
-
-			if (unlikely(rte_lpm_lookup(lp->lpm_table, ipv4_dst, &port) != 0)) {
-				port = pkt->port;
-			}
-
-			pos = lp->mbuf_out[port].n_mbufs;
-
-			lp->mbuf_out[port].array[pos ++] = pkt;
-			if (likely(pos < bsz_wr)) {
-				lp->mbuf_out[port].n_mbufs = pos;
-				continue;
-			}
-
-			ret = rte_ring_sp_enqueue_bulk(
-				lp->rings_out[port],
-				(void **) lp->mbuf_out[port].array,
-				bsz_wr,
-				NULL);
-
-#if APP_STATS
-			lp->rings_out_iters[port] ++;
-			if (ret > 0) {
-				lp->rings_out_count[port] += 1;
-			}
-			if (lp->rings_out_iters[port] == APP_STATS){
-				printf("\t\tWorker %u out (NIC port %u): enq success rate = %.2f\n",
-					(unsigned) lp->worker_id,
-					port,
-					((double) lp->rings_out_count[port]) / ((double) lp->rings_out_iters[port]));
-				lp->rings_out_iters[port] = 0;
-				lp->rings_out_count[port] = 0;
-			}
-#endif
-
-			if (unlikely(ret == 0)) {
-				uint32_t k;
-				for (k = 0; k < bsz_wr; k ++) {
-					struct rte_mbuf *pkt_to_free = lp->mbuf_out[port].array[k];
-					rte_pktmbuf_free(pkt_to_free);
-				}
-			}
-
-			lp->mbuf_out[port].n_mbufs = 0;
-			lp->mbuf_out_flush[port] = 0;
-		}
-	}
-}
-
-static inline void
-app_lcore_worker_flush(struct app_lcore_params_worker *lp)
-{
-	uint32_t port;
-
-	for (port = 0; port < APP_MAX_NIC_PORTS; port ++) {
-		int ret;
-
-		if (unlikely(lp->rings_out[port] == NULL)) {
-			continue;
-		}
-
-		if (likely((lp->mbuf_out_flush[port] == 0) ||
-		           (lp->mbuf_out[port].n_mbufs == 0))) {
-			lp->mbuf_out_flush[port] = 1;
-			continue;
-		}
-
-		ret = rte_ring_sp_enqueue_bulk(
-			lp->rings_out[port],
-			(void **) lp->mbuf_out[port].array,
-			lp->mbuf_out[port].n_mbufs,
-			NULL);
-
-		if (unlikely(ret == 0)) {
-			uint32_t k;
-			for (k = 0; k < lp->mbuf_out[port].n_mbufs; k ++) {
-				struct rte_mbuf *pkt_to_free = lp->mbuf_out[port].array[k];
-				rte_pktmbuf_free(pkt_to_free);
-			}
-		}
-
-		lp->mbuf_out[port].n_mbufs = 0;
-		lp->mbuf_out_flush[port] = 1;
-	}
-}
-
-static void
-app_lcore_main_loop_worker(void) {
-	uint32_t lcore = rte_lcore_id();
-	struct app_lcore_params_worker *lp = &app.lcore_params[lcore].worker;
-	uint64_t i = 0;
-
-	uint32_t bsz_rd = app.burst_size_worker_read;
-	uint32_t bsz_wr = app.burst_size_worker_write;
-
-	for ( ; ; ) {
-		if (APP_LCORE_WORKER_FLUSH && (unlikely(i == APP_LCORE_WORKER_FLUSH))) {
-			app_lcore_worker_flush(lp);
-			i = 0;
-		}
-
-		app_lcore_worker(lp, bsz_rd, bsz_wr);
-
-		i ++;
-	}
-}
-
-int
-app_lcore_main_loop(__attribute__((unused)) void *arg)
-{
-	struct app_lcore_params *lp;
-	unsigned lcore;
-
-	lcore = rte_lcore_id();
-	lp = &app.lcore_params[lcore];
-
-	if (lp->type == e_APP_LCORE_IO) {
-		printf("Logical core %u (I/O) main loop.\n", lcore);
-		app_lcore_main_loop_io();
-	}
-
-	if (lp->type == e_APP_LCORE_WORKER) {
-		printf("Logical core %u (worker %u) main loop.\n",
-			lcore,
-			(unsigned) lp->worker.worker_id);
-		app_lcore_main_loop_worker();
-	}
-
-	return 0;
-}
diff --git a/examples/meson.build b/examples/meson.build
deleted file mode 100644
index 2c6b3f8..0000000
--- a/examples/meson.build
+++ /dev/null
@@ -1,33 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-driver_libs = []
-if get_option('default_library') == 'static'
-	driver_libs = dpdk_drivers
-endif
-
-execinfo = cc.find_library('execinfo', required: false)
-foreach example: get_option('examples').split(',')
-	name = example
-	sources = []
-	allow_experimental_apis = false
-	cflags = machine_args
-	ext_deps = [execinfo]
-	includes = [include_directories(example)]
-	deps = ['eal', 'mempool', 'net', 'mbuf', 'ethdev', 'cmdline']
-	subdir(example)
-
-	dep_objs = ext_deps
-	foreach d:deps
-		dep_objs += [get_variable(get_option('default_library') + '_rte_' + d)]
-	endforeach
-	if allow_experimental_apis
-		cflags += '-DALLOW_EXPERIMENTAL_API'
-	endif
-	executable('dpdk-' + name, sources,
-		include_directories: includes,
-		link_whole: driver_libs,
-		link_args: dpdk_extra_ldflags,
-		c_args: cflags,
-		dependencies: dep_objs)
-endforeach
diff --git a/examples/multi_process/Makefile b/examples/multi_process/Makefile
deleted file mode 100644
index a6708b7..0000000
--- a/examples/multi_process/Makefile
+++ /dev/null
@@ -1,17 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-DIRS-$(CONFIG_RTE_EXEC_ENV_LINUXAPP) += client_server_mp
-DIRS-$(CONFIG_RTE_EXEC_ENV_LINUXAPP) += simple_mp
-DIRS-$(CONFIG_RTE_EXEC_ENV_LINUXAPP) += symmetric_mp
-
-include $(RTE_SDK)/mk/rte.extsubdir.mk
diff --git a/examples/multi_process/client_server_mp/Makefile b/examples/multi_process/client_server_mp/Makefile
deleted file mode 100644
index 6f6c452..0000000
--- a/examples/multi_process/client_server_mp/Makefile
+++ /dev/null
@@ -1,16 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-DIRS-$(CONFIG_RTE_EXEC_ENV_LINUXAPP) += mp_client
-DIRS-$(CONFIG_RTE_EXEC_ENV_LINUXAPP) += mp_server
-
-include $(RTE_SDK)/mk/rte.extsubdir.mk
diff --git a/examples/multi_process/client_server_mp/mp_client/Makefile b/examples/multi_process/client_server_mp/mp_client/Makefile
deleted file mode 100644
index 298e1b0..0000000
--- a/examples/multi_process/client_server_mp/mp_client/Makefile
+++ /dev/null
@@ -1,20 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-include $(RTE_SDK)/mk/rte.vars.mk
-
-# binary name
-APP = mp_client
-
-# all source are stored in SRCS-y
-SRCS-y := client.c
-
-CFLAGS += $(WERROR_FLAGS) -O3
-CFLAGS += -I$(SRCDIR)/../shared
-
-include $(RTE_SDK)/mk/rte.extapp.mk
diff --git a/examples/multi_process/client_server_mp/mp_client/client.c b/examples/multi_process/client_server_mp/mp_client/client.c
deleted file mode 100644
index 92955e9..0000000
--- a/examples/multi_process/client_server_mp/mp_client/client.c
+++ /dev/null
@@ -1,271 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#include <stdint.h>
-#include <stdio.h>
-#include <inttypes.h>
-#include <stdarg.h>
-#include <errno.h>
-#include <sys/queue.h>
-#include <stdlib.h>
-#include <getopt.h>
-#include <string.h>
-
-#include <rte_common.h>
-#include <rte_malloc.h>
-#include <rte_memory.h>
-#include <rte_memzone.h>
-#include <rte_eal.h>
-#include <rte_atomic.h>
-#include <rte_branch_prediction.h>
-#include <rte_log.h>
-#include <rte_per_lcore.h>
-#include <rte_lcore.h>
-#include <rte_ring.h>
-#include <rte_launch.h>
-#include <rte_debug.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-#include <rte_interrupts.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_string_fns.h>
-
-#include "common.h"
-
-/* Number of packets to attempt to read from queue */
-#define PKT_READ_SIZE  ((uint16_t)32)
-
-/* our client id number - tells us which rx queue to read, and NIC TX
- * queue to write to. */
-static uint8_t client_id = 0;
-
-#define MBQ_CAPACITY 32
-
-/* maps input ports to output ports for packets */
-static uint16_t output_ports[RTE_MAX_ETHPORTS];
-
-/* buffers up a set of packet that are ready to send */
-struct rte_eth_dev_tx_buffer *tx_buffer[RTE_MAX_ETHPORTS];
-
-/* shared data from server. We update statistics here */
-static volatile struct tx_stats *tx_stats;
-
-
-/*
- * print a usage message
- */
-static void
-usage(const char *progname)
-{
-	printf("Usage: %s [EAL args] -- -n <client_id>\n\n", progname);
-}
-
-/*
- * Convert the client id number from a string to an int.
- */
-static int
-parse_client_num(const char *client)
-{
-	char *end = NULL;
-	unsigned long temp;
-
-	if (client == NULL || *client == '\0')
-		return -1;
-
-	temp = strtoul(client, &end, 10);
-	if (end == NULL || *end != '\0')
-		return -1;
-
-	client_id = (uint8_t)temp;
-	return 0;
-}
-
-/*
- * Parse the application arguments to the client app.
- */
-static int
-parse_app_args(int argc, char *argv[])
-{
-	int option_index, opt;
-	char **argvopt = argv;
-	const char *progname = NULL;
-	static struct option lgopts[] = { /* no long options */
-		{NULL, 0, 0, 0 }
-	};
-	progname = argv[0];
-
-	while ((opt = getopt_long(argc, argvopt, "n:", lgopts,
-		&option_index)) != EOF){
-		switch (opt){
-			case 'n':
-				if (parse_client_num(optarg) != 0){
-					usage(progname);
-					return -1;
-				}
-				break;
-			default:
-				usage(progname);
-				return -1;
-		}
-	}
-	return 0;
-}
-
-/*
- * Tx buffer error callback
- */
-static void
-flush_tx_error_callback(struct rte_mbuf **unsent, uint16_t count,
-		void *userdata) {
-	int i;
-	uint16_t port_id = (uintptr_t)userdata;
-
-	tx_stats->tx_drop[port_id] += count;
-
-	/* free the mbufs which failed from transmit */
-	for (i = 0; i < count; i++)
-		rte_pktmbuf_free(unsent[i]);
-
-}
-
-static void
-configure_tx_buffer(uint16_t port_id, uint16_t size)
-{
-	int ret;
-
-	/* Initialize TX buffers */
-	tx_buffer[port_id] = rte_zmalloc_socket("tx_buffer",
-			RTE_ETH_TX_BUFFER_SIZE(size), 0,
-			rte_eth_dev_socket_id(port_id));
-	if (tx_buffer[port_id] == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot allocate buffer for tx on port %u\n",
-			 port_id);
-
-	rte_eth_tx_buffer_init(tx_buffer[port_id], size);
-
-	ret = rte_eth_tx_buffer_set_err_callback(tx_buffer[port_id],
-			flush_tx_error_callback, (void *)(intptr_t)port_id);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE,
-		"Cannot set error callback for tx buffer on port %u\n",
-			 port_id);
-}
-
-/*
- * set up output ports so that all traffic on port gets sent out
- * its paired port. Index using actual port numbers since that is
- * what comes in the mbuf structure.
- */
-static void
-configure_output_ports(const struct port_info *ports)
-{
-	int i;
-	if (ports->num_ports > RTE_MAX_ETHPORTS)
-		rte_exit(EXIT_FAILURE, "Too many ethernet ports. RTE_MAX_ETHPORTS = %u\n",
-				(unsigned)RTE_MAX_ETHPORTS);
-	for (i = 0; i < ports->num_ports - 1; i+=2){
-		uint16_t p1 = ports->id[i];
-		uint16_t p2 = ports->id[i+1];
-		output_ports[p1] = p2;
-		output_ports[p2] = p1;
-
-		configure_tx_buffer(p1, MBQ_CAPACITY);
-		configure_tx_buffer(p2, MBQ_CAPACITY);
-
-	}
-}
-
-/*
- * This function performs routing of packets
- * Just sends each input packet out an output port based solely on the input
- * port it arrived on.
- */
-static void
-handle_packet(struct rte_mbuf *buf)
-{
-	int sent;
-	const uint16_t in_port = buf->port;
-	const uint16_t out_port = output_ports[in_port];
-	struct rte_eth_dev_tx_buffer *buffer = tx_buffer[out_port];
-
-	sent = rte_eth_tx_buffer(out_port, client_id, buffer, buf);
-	if (sent)
-		tx_stats->tx[out_port] += sent;
-
-}
-
-/*
- * Application main function - loops through
- * receiving and processing packets. Never returns
- */
-int
-main(int argc, char *argv[])
-{
-	const struct rte_memzone *mz;
-	struct rte_ring *rx_ring;
-	struct rte_mempool *mp;
-	struct port_info *ports;
-	int need_flush = 0; /* indicates whether we have unsent packets */
-	int retval;
-	void *pkts[PKT_READ_SIZE];
-	uint16_t sent;
-
-	if ((retval = rte_eal_init(argc, argv)) < 0)
-		return -1;
-	argc -= retval;
-	argv += retval;
-
-	if (parse_app_args(argc, argv) < 0)
-		rte_exit(EXIT_FAILURE, "Invalid command-line arguments\n");
-
-	if (rte_eth_dev_count() == 0)
-		rte_exit(EXIT_FAILURE, "No Ethernet ports - bye\n");
-
-	rx_ring = rte_ring_lookup(get_rx_queue_name(client_id));
-	if (rx_ring == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot get RX ring - is server process running?\n");
-
-	mp = rte_mempool_lookup(PKTMBUF_POOL_NAME);
-	if (mp == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot get mempool for mbufs\n");
-
-	mz = rte_memzone_lookup(MZ_PORT_INFO);
-	if (mz == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot get port info structure\n");
-	ports = mz->addr;
-	tx_stats = &(ports->tx_stats[client_id]);
-
-	configure_output_ports(ports);
-
-	RTE_LOG(INFO, APP, "Finished Process Init.\n");
-
-	printf("\nClient process %d handling packets\n", client_id);
-	printf("[Press Ctrl-C to quit ...]\n");
-
-	for (;;) {
-		uint16_t i, rx_pkts;
-		uint16_t port;
-
-		rx_pkts = rte_ring_dequeue_burst(rx_ring, pkts,
-				PKT_READ_SIZE, NULL);
-
-		if (unlikely(rx_pkts == 0)){
-			if (need_flush)
-				for (port = 0; port < ports->num_ports; port++) {
-					sent = rte_eth_tx_buffer_flush(ports->id[port], client_id,
-							tx_buffer[port]);
-					if (unlikely(sent))
-						tx_stats->tx[port] += sent;
-				}
-			need_flush = 0;
-			continue;
-		}
-
-		for (i = 0; i < rx_pkts; i++)
-			handle_packet(pkts[i]);
-
-		need_flush = 1;
-	}
-}
diff --git a/examples/multi_process/client_server_mp/mp_server/Makefile b/examples/multi_process/client_server_mp/mp_server/Makefile
deleted file mode 100644
index 3e244e2..0000000
--- a/examples/multi_process/client_server_mp/mp_server/Makefile
+++ /dev/null
@@ -1,33 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-ifneq ($(CONFIG_RTE_EXEC_ENV),"linuxapp")
-$(error This application can only operate in a linuxapp environment, \
-please change the definition of the RTE_TARGET environment variable)
-endif
-
-# binary name
-APP = mp_server
-
-# all source are stored in SRCS-y
-SRCS-y := main.c init.c args.c
-
-INC := $(sort $(wildcard *.h))
-
-CFLAGS += $(WERROR_FLAGS) -O3
-CFLAGS += -I$(SRCDIR)/../shared
-
-# for newer gcc, e.g. 4.4, no-strict-aliasing may not be necessary
-# and so the next line can be removed in those cases.
-EXTRA_CFLAGS += -fno-strict-aliasing
-
-include $(RTE_SDK)/mk/rte.extapp.mk
diff --git a/examples/multi_process/client_server_mp/mp_server/args.c b/examples/multi_process/client_server_mp/mp_server/args.c
deleted file mode 100644
index b0d8d76..0000000
--- a/examples/multi_process/client_server_mp/mp_server/args.c
+++ /dev/null
@@ -1,143 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <stdint.h>
-#include <getopt.h>
-#include <stdarg.h>
-#include <errno.h>
-
-#include <rte_memory.h>
-#include <rte_string_fns.h>
-
-#include "common.h"
-#include "args.h"
-#include "init.h"
-
-/* global var for number of clients - extern in header */
-uint8_t num_clients;
-
-static const char *progname;
-
-/**
- * Prints out usage information to stdout
- */
-static void
-usage(void)
-{
-	printf(
-	    "%s [EAL options] -- -p PORTMASK -n NUM_CLIENTS [-s NUM_SOCKETS]\n"
-	    " -p PORTMASK: hexadecimal bitmask of ports to use\n"
-	    " -n NUM_CLIENTS: number of client processes to use\n"
-	    , progname);
-}
-
-/**
- * The ports to be used by the application are passed in
- * the form of a bitmask. This function parses the bitmask
- * and places the port numbers to be used into the port[]
- * array variable
- */
-static int
-parse_portmask(uint8_t max_ports, const char *portmask)
-{
-	char *end = NULL;
-	unsigned long pm;
-	uint16_t count = 0;
-
-	if (portmask == NULL || *portmask == '\0')
-		return -1;
-
-	/* convert parameter to a number and verify */
-	pm = strtoul(portmask, &end, 16);
-	if (end == NULL || *end != '\0' || pm == 0)
-		return -1;
-
-	/* loop through bits of the mask and mark ports */
-	while (pm != 0){
-		if (pm & 0x01){ /* bit is set in mask, use port */
-			if (count >= max_ports)
-				printf("WARNING: requested port %u not present"
-				" - ignoring\n", (unsigned)count);
-			else
-			    ports->id[ports->num_ports++] = count;
-		}
-		pm = (pm >> 1);
-		count++;
-	}
-
-	return 0;
-}
-
-/**
- * Take the number of clients parameter passed to the app
- * and convert to a number to store in the num_clients variable
- */
-static int
-parse_num_clients(const char *clients)
-{
-	char *end = NULL;
-	unsigned long temp;
-
-	if (clients == NULL || *clients == '\0')
-		return -1;
-
-	temp = strtoul(clients, &end, 10);
-	if (end == NULL || *end != '\0' || temp == 0)
-		return -1;
-
-	num_clients = (uint8_t)temp;
-	return 0;
-}
-
-/**
- * The application specific arguments follow the DPDK-specific
- * arguments which are stripped by the DPDK init. This function
- * processes these application arguments, printing usage info
- * on error.
- */
-int
-parse_app_args(uint16_t max_ports, int argc, char *argv[])
-{
-	int option_index, opt;
-	char **argvopt = argv;
-	static struct option lgopts[] = { /* no long options */
-		{NULL, 0, 0, 0 }
-	};
-	progname = argv[0];
-
-	while ((opt = getopt_long(argc, argvopt, "n:p:", lgopts,
-		&option_index)) != EOF){
-		switch (opt){
-			case 'p':
-				if (parse_portmask(max_ports, optarg) != 0){
-					usage();
-					return -1;
-				}
-				break;
-			case 'n':
-				if (parse_num_clients(optarg) != 0){
-					usage();
-					return -1;
-				}
-				break;
-			default:
-				printf("ERROR: Unknown option '%c'\n", opt);
-				usage();
-				return -1;
-		}
-	}
-
-	if (ports->num_ports == 0 || num_clients == 0){
-		usage();
-		return -1;
-	}
-
-	if (ports->num_ports % 2 != 0){
-		printf("ERROR: application requires an even number of ports to use\n");
-		return -1;
-	}
-	return 0;
-}
diff --git a/examples/multi_process/client_server_mp/mp_server/args.h b/examples/multi_process/client_server_mp/mp_server/args.h
deleted file mode 100644
index 79c190a..0000000
--- a/examples/multi_process/client_server_mp/mp_server/args.h
+++ /dev/null
@@ -1,10 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#ifndef _ARGS_H_
-#define _ARGS_H_
-
-int parse_app_args(uint16_t max_ports, int argc, char *argv[]);
-
-#endif /* ifndef _ARGS_H_ */
diff --git a/examples/multi_process/client_server_mp/mp_server/init.c b/examples/multi_process/client_server_mp/mp_server/init.c
deleted file mode 100644
index 1c465cc..0000000
--- a/examples/multi_process/client_server_mp/mp_server/init.c
+++ /dev/null
@@ -1,280 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdint.h>
-#include <stdio.h>
-#include <string.h>
-#include <sys/queue.h>
-#include <errno.h>
-#include <stdarg.h>
-#include <inttypes.h>
-
-#include <rte_common.h>
-#include <rte_memory.h>
-#include <rte_memzone.h>
-#include <rte_eal.h>
-#include <rte_byteorder.h>
-#include <rte_atomic.h>
-#include <rte_launch.h>
-#include <rte_per_lcore.h>
-#include <rte_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_debug.h>
-#include <rte_ring.h>
-#include <rte_log.h>
-#include <rte_mempool.h>
-#include <rte_memcpy.h>
-#include <rte_mbuf.h>
-#include <rte_interrupts.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_malloc.h>
-#include <rte_string_fns.h>
-#include <rte_cycles.h>
-
-#include "common.h"
-#include "args.h"
-#include "init.h"
-
-#define MBUFS_PER_CLIENT 1536
-#define MBUFS_PER_PORT 1536
-#define MBUF_CACHE_SIZE 512
-
-#define RTE_MP_RX_DESC_DEFAULT 1024
-#define RTE_MP_TX_DESC_DEFAULT 1024
-#define CLIENT_QUEUE_RINGSIZE 128
-
-#define NO_FLAGS 0
-
-/* The mbuf pool for packet rx */
-struct rte_mempool *pktmbuf_pool;
-
-/* array of info/queues for clients */
-struct client *clients = NULL;
-
-/* the port details */
-struct port_info *ports;
-
-/**
- * Initialise the mbuf pool for packet reception for the NIC, and any other
- * buffer pools needed by the app - currently none.
- */
-static int
-init_mbuf_pools(void)
-{
-	const unsigned num_mbufs = (num_clients * MBUFS_PER_CLIENT) \
-			+ (ports->num_ports * MBUFS_PER_PORT);
-
-	/* don't pass single-producer/single-consumer flags to mbuf create as it
-	 * seems faster to use a cache instead */
-	printf("Creating mbuf pool '%s' [%u mbufs] ...\n",
-			PKTMBUF_POOL_NAME, num_mbufs);
-	pktmbuf_pool = rte_pktmbuf_pool_create(PKTMBUF_POOL_NAME, num_mbufs,
-		MBUF_CACHE_SIZE, 0, RTE_MBUF_DEFAULT_BUF_SIZE, rte_socket_id());
-
-	return pktmbuf_pool == NULL; /* 0  on success */
-}
-
-/**
- * Initialise an individual port:
- * - configure number of rx and tx rings
- * - set up each rx ring, to pull from the main mbuf pool
- * - set up each tx ring
- * - start the port and report its status to stdout
- */
-static int
-init_port(uint16_t port_num)
-{
-	/* for port configuration all features are off by default */
-	const struct rte_eth_conf port_conf = {
-		.rxmode = {
-			.mq_mode = ETH_MQ_RX_RSS
-		}
-	};
-	const uint16_t rx_rings = 1, tx_rings = num_clients;
-	uint16_t rx_ring_size = RTE_MP_RX_DESC_DEFAULT;
-	uint16_t tx_ring_size = RTE_MP_TX_DESC_DEFAULT;
-
-	uint16_t q;
-	int retval;
-
-	printf("Port %u init ... ", port_num);
-	fflush(stdout);
-
-	/* Standard DPDK port initialisation - config port, then set up
-	 * rx and tx rings */
-	if ((retval = rte_eth_dev_configure(port_num, rx_rings, tx_rings,
-		&port_conf)) != 0)
-		return retval;
-
-	retval = rte_eth_dev_adjust_nb_rx_tx_desc(port_num, &rx_ring_size,
-			&tx_ring_size);
-	if (retval != 0)
-		return retval;
-
-	for (q = 0; q < rx_rings; q++) {
-		retval = rte_eth_rx_queue_setup(port_num, q, rx_ring_size,
-				rte_eth_dev_socket_id(port_num),
-				NULL, pktmbuf_pool);
-		if (retval < 0) return retval;
-	}
-
-	for ( q = 0; q < tx_rings; q ++ ) {
-		retval = rte_eth_tx_queue_setup(port_num, q, tx_ring_size,
-				rte_eth_dev_socket_id(port_num),
-				NULL);
-		if (retval < 0) return retval;
-	}
-
-	rte_eth_promiscuous_enable(port_num);
-
-	retval  = rte_eth_dev_start(port_num);
-	if (retval < 0) return retval;
-
-	printf( "done: \n");
-
-	return 0;
-}
-
-/**
- * Set up the DPDK rings which will be used to pass packets, via
- * pointers, between the multi-process server and client processes.
- * Each client needs one RX queue.
- */
-static int
-init_shm_rings(void)
-{
-	unsigned i;
-	unsigned socket_id;
-	const char * q_name;
-	const unsigned ringsize = CLIENT_QUEUE_RINGSIZE;
-
-	clients = rte_malloc("client details",
-		sizeof(*clients) * num_clients, 0);
-	if (clients == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot allocate memory for client program details\n");
-
-	for (i = 0; i < num_clients; i++) {
-		/* Create an RX queue for each client */
-		socket_id = rte_socket_id();
-		q_name = get_rx_queue_name(i);
-		clients[i].rx_q = rte_ring_create(q_name,
-				ringsize, socket_id,
-				RING_F_SP_ENQ | RING_F_SC_DEQ ); /* single prod, single cons */
-		if (clients[i].rx_q == NULL)
-			rte_exit(EXIT_FAILURE, "Cannot create rx ring queue for client %u\n", i);
-	}
-	return 0;
-}
-
-/* Check the link status of all ports in up to 9s, and print them finally */
-static void
-check_all_ports_link_status(uint16_t port_num, uint32_t port_mask)
-{
-#define CHECK_INTERVAL 100 /* 100ms */
-#define MAX_CHECK_TIME 90 /* 9s (90 * 100ms) in total */
-	uint16_t portid;
-	uint8_t count, all_ports_up, print_flag = 0;
-	struct rte_eth_link link;
-
-	printf("\nChecking link status");
-	fflush(stdout);
-	for (count = 0; count <= MAX_CHECK_TIME; count++) {
-		all_ports_up = 1;
-		for (portid = 0; portid < port_num; portid++) {
-			if ((port_mask & (1 << ports->id[portid])) == 0)
-				continue;
-			memset(&link, 0, sizeof(link));
-			rte_eth_link_get_nowait(ports->id[portid], &link);
-			/* print link status if flag set */
-			if (print_flag == 1) {
-				if (link.link_status)
-					printf("Port %d Link Up - speed %u "
-						"Mbps - %s\n", ports->id[portid],
-						(unsigned)link.link_speed,
-				(link.link_duplex == ETH_LINK_FULL_DUPLEX) ?
-					("full-duplex") : ("half-duplex\n"));
-				else
-					printf("Port %d Link Down\n",
-						(uint8_t)ports->id[portid]);
-				continue;
-			}
-			/* clear all_ports_up flag if any link down */
-			if (link.link_status == ETH_LINK_DOWN) {
-				all_ports_up = 0;
-				break;
-			}
-		}
-		/* after finally printing all link status, get out */
-		if (print_flag == 1)
-			break;
-
-		if (all_ports_up == 0) {
-			printf(".");
-			fflush(stdout);
-			rte_delay_ms(CHECK_INTERVAL);
-		}
-
-		/* set the print_flag if all ports up or timeout */
-		if (all_ports_up == 1 || count == (MAX_CHECK_TIME - 1)) {
-			print_flag = 1;
-			printf("done\n");
-		}
-	}
-}
-
-/**
- * Main init function for the multi-process server app,
- * calls subfunctions to do each stage of the initialisation.
- */
-int
-init(int argc, char *argv[])
-{
-	int retval;
-	const struct rte_memzone *mz;
-	uint16_t i, total_ports;
-
-	/* init EAL, parsing EAL args */
-	retval = rte_eal_init(argc, argv);
-	if (retval < 0)
-		return -1;
-	argc -= retval;
-	argv += retval;
-
-	/* get total number of ports */
-	total_ports = rte_eth_dev_count();
-
-	/* set up array for port data */
-	mz = rte_memzone_reserve(MZ_PORT_INFO, sizeof(*ports),
-				rte_socket_id(), NO_FLAGS);
-	if (mz == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot reserve memory zone for port information\n");
-	memset(mz->addr, 0, sizeof(*ports));
-	ports = mz->addr;
-
-	/* parse additional, application arguments */
-	retval = parse_app_args(total_ports, argc, argv);
-	if (retval != 0)
-		return -1;
-
-	/* initialise mbuf pools */
-	retval = init_mbuf_pools();
-	if (retval != 0)
-		rte_exit(EXIT_FAILURE, "Cannot create needed mbuf pools\n");
-
-	/* now initialise the ports we will use */
-	for (i = 0; i < ports->num_ports; i++) {
-		retval = init_port(ports->id[i]);
-		if (retval != 0)
-			rte_exit(EXIT_FAILURE, "Cannot initialise port %u\n",
-					(unsigned)i);
-	}
-
-	check_all_ports_link_status(ports->num_ports, (~0x0));
-
-	/* initialise the client queues/rings for inter-eu comms */
-	init_shm_rings();
-
-	return 0;
-}
diff --git a/examples/multi_process/client_server_mp/mp_server/init.h b/examples/multi_process/client_server_mp/mp_server/init.h
deleted file mode 100644
index de5049c..0000000
--- a/examples/multi_process/client_server_mp/mp_server/init.h
+++ /dev/null
@@ -1,43 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#ifndef _INIT_H_
-#define _INIT_H_
-
-/*
- * #include <rte_ring.h>
- * #include "args.h"
- */
-
-/*
- * Define a client structure with all needed info, including
- * stats from the clients.
- */
-struct client {
-	struct rte_ring *rx_q;
-	unsigned client_id;
-	/* these stats hold how many packets the client will actually receive,
-	 * and how many packets were dropped because the client's queue was full.
-	 * The port-info stats, in contrast, record how many packets were received
-	 * or transmitted on an actual NIC port.
-	 */
-	struct {
-		volatile uint64_t rx;
-		volatile uint64_t rx_drop;
-	} stats;
-};
-
-extern struct client *clients;
-
-/* the shared port information: port numbers, rx and tx stats etc. */
-extern struct port_info *ports;
-
-extern struct rte_mempool *pktmbuf_pool;
-extern uint8_t num_clients;
-extern unsigned num_sockets;
-extern struct port_info *ports;
-
-int init(int argc, char *argv[]);
-
-#endif /* ifndef _INIT_H_ */
diff --git a/examples/multi_process/client_server_mp/mp_server/main.c b/examples/multi_process/client_server_mp/mp_server/main.c
deleted file mode 100644
index 93a9a08..0000000
--- a/examples/multi_process/client_server_mp/mp_server/main.c
+++ /dev/null
@@ -1,285 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <string.h>
-#include <unistd.h>
-#include <stdint.h>
-#include <stdarg.h>
-#include <inttypes.h>
-#include <sys/queue.h>
-#include <errno.h>
-#include <netinet/ip.h>
-
-#include <rte_common.h>
-#include <rte_memory.h>
-#include <rte_eal.h>
-#include <rte_launch.h>
-#include <rte_per_lcore.h>
-#include <rte_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_atomic.h>
-#include <rte_ring.h>
-#include <rte_log.h>
-#include <rte_debug.h>
-#include <rte_mempool.h>
-#include <rte_memcpy.h>
-#include <rte_mbuf.h>
-#include <rte_ether.h>
-#include <rte_interrupts.h>
-#include <rte_ethdev.h>
-#include <rte_byteorder.h>
-#include <rte_malloc.h>
-#include <rte_string_fns.h>
-
-#include "common.h"
-#include "args.h"
-#include "init.h"
-
-/*
- * When doing reads from the NIC or the client queues,
- * use this batch size
- */
-#define PACKET_READ_SIZE 32
-
-/*
- * Local buffers to put packets in, used to send packets in bursts to the
- * clients
- */
-struct client_rx_buf {
-	struct rte_mbuf *buffer[PACKET_READ_SIZE];
-	uint16_t count;
-};
-
-/* One buffer per client rx queue - dynamically allocate array */
-static struct client_rx_buf *cl_rx_buf;
-
-static const char *
-get_printable_mac_addr(uint16_t port)
-{
-	static const char err_address[] = "00:00:00:00:00:00";
-	static char addresses[RTE_MAX_ETHPORTS][sizeof(err_address)];
-
-	if (unlikely(port >= RTE_MAX_ETHPORTS))
-		return err_address;
-	if (unlikely(addresses[port][0]=='\0')){
-		struct ether_addr mac;
-		rte_eth_macaddr_get(port, &mac);
-		snprintf(addresses[port], sizeof(addresses[port]),
-				"%02x:%02x:%02x:%02x:%02x:%02x\n",
-				mac.addr_bytes[0], mac.addr_bytes[1], mac.addr_bytes[2],
-				mac.addr_bytes[3], mac.addr_bytes[4], mac.addr_bytes[5]);
-	}
-	return addresses[port];
-}
-
-/*
- * This function displays the recorded statistics for each port
- * and for each client. It uses ANSI terminal codes to clear
- * screen when called. It is called from a single non-master
- * thread in the server process, when the process is run with more
- * than one lcore enabled.
- */
-static void
-do_stats_display(void)
-{
-	unsigned i, j;
-	const char clr[] = { 27, '[', '2', 'J', '\0' };
-	const char topLeft[] = { 27, '[', '1', ';', '1', 'H','\0' };
-	uint64_t port_tx[RTE_MAX_ETHPORTS], port_tx_drop[RTE_MAX_ETHPORTS];
-	uint64_t client_tx[MAX_CLIENTS], client_tx_drop[MAX_CLIENTS];
-
-	/* to get TX stats, we need to do some summing calculations */
-	memset(port_tx, 0, sizeof(port_tx));
-	memset(port_tx_drop, 0, sizeof(port_tx_drop));
-	memset(client_tx, 0, sizeof(client_tx));
-	memset(client_tx_drop, 0, sizeof(client_tx_drop));
-
-	for (i = 0; i < num_clients; i++){
-		const volatile struct tx_stats *tx = &ports->tx_stats[i];
-		for (j = 0; j < ports->num_ports; j++){
-			/* assign to local variables here, save re-reading volatile vars */
-			const uint64_t tx_val = tx->tx[ports->id[j]];
-			const uint64_t drop_val = tx->tx_drop[ports->id[j]];
-			port_tx[j] += tx_val;
-			port_tx_drop[j] += drop_val;
-			client_tx[i] += tx_val;
-			client_tx_drop[i] += drop_val;
-		}
-	}
-
-	/* Clear screen and move to top left */
-	printf("%s%s", clr, topLeft);
-
-	printf("PORTS\n");
-	printf("-----\n");
-	for (i = 0; i < ports->num_ports; i++)
-		printf("Port %u: '%s'\t", (unsigned)ports->id[i],
-				get_printable_mac_addr(ports->id[i]));
-	printf("\n\n");
-	for (i = 0; i < ports->num_ports; i++){
-		printf("Port %u - rx: %9"PRIu64"\t"
-				"tx: %9"PRIu64"\n",
-				(unsigned)ports->id[i], ports->rx_stats.rx[i],
-				port_tx[i]);
-	}
-
-	printf("\nCLIENTS\n");
-	printf("-------\n");
-	for (i = 0; i < num_clients; i++){
-		const unsigned long long rx = clients[i].stats.rx;
-		const unsigned long long rx_drop = clients[i].stats.rx_drop;
-		printf("Client %2u - rx: %9llu, rx_drop: %9llu\n"
-				"            tx: %9"PRIu64", tx_drop: %9"PRIu64"\n",
-				i, rx, rx_drop, client_tx[i], client_tx_drop[i]);
-	}
-
-	printf("\n");
-}
-
-/*
- * The function called from each non-master lcore used by the process.
- * The test_and_set function is used to randomly pick a single lcore on which
- * the code to display the statistics will run. Otherwise, the code just
- * repeatedly sleeps.
- */
-static int
-sleep_lcore(__attribute__((unused)) void *dummy)
-{
-	/* Used to pick a display thread - static, so zero-initialised */
-	static rte_atomic32_t display_stats;
-
-	/* Only one core should display stats */
-	if (rte_atomic32_test_and_set(&display_stats)) {
-		const unsigned sleeptime = 1;
-		printf("Core %u displaying statistics\n", rte_lcore_id());
-
-		/* Longer initial pause so above printf is seen */
-		sleep(sleeptime * 3);
-
-		/* Loop forever: sleep always returns 0 or <= param */
-		while (sleep(sleeptime) <= sleeptime)
-			do_stats_display();
-	}
-	return 0;
-}
-
-/*
- * Function to set all the client statistic values to zero.
- * Called at program startup.
- */
-static void
-clear_stats(void)
-{
-	unsigned i;
-
-	for (i = 0; i < num_clients; i++)
-		clients[i].stats.rx = clients[i].stats.rx_drop = 0;
-}
-
-/*
- * send a burst of traffic to a client, assuming there are packets
- * available to be sent to this client
- */
-static void
-flush_rx_queue(uint16_t client)
-{
-	uint16_t j;
-	struct client *cl;
-
-	if (cl_rx_buf[client].count == 0)
-		return;
-
-	cl = &clients[client];
-	if (rte_ring_enqueue_bulk(cl->rx_q, (void **)cl_rx_buf[client].buffer,
-			cl_rx_buf[client].count, NULL) == 0){
-		for (j = 0; j < cl_rx_buf[client].count; j++)
-			rte_pktmbuf_free(cl_rx_buf[client].buffer[j]);
-		cl->stats.rx_drop += cl_rx_buf[client].count;
-	}
-	else
-		cl->stats.rx += cl_rx_buf[client].count;
-
-	cl_rx_buf[client].count = 0;
-}
-
-/*
- * marks a packet down to be sent to a particular client process
- */
-static inline void
-enqueue_rx_packet(uint8_t client, struct rte_mbuf *buf)
-{
-	cl_rx_buf[client].buffer[cl_rx_buf[client].count++] = buf;
-}
-
-/*
- * This function takes a group of packets and routes them
- * individually to the client process. Very simply round-robins the packets
- * without checking any of the packet contents.
- */
-static void
-process_packets(uint32_t port_num __rte_unused,
-		struct rte_mbuf *pkts[], uint16_t rx_count)
-{
-	uint16_t i;
-	uint8_t client = 0;
-
-	for (i = 0; i < rx_count; i++) {
-		enqueue_rx_packet(client, pkts[i]);
-
-		if (++client == num_clients)
-			client = 0;
-	}
-
-	for (i = 0; i < num_clients; i++)
-		flush_rx_queue(i);
-}
-
-/*
- * Function called by the master lcore of the DPDK process.
- */
-static void
-do_packet_forwarding(void)
-{
-	unsigned port_num = 0; /* indexes the port[] array */
-
-	for (;;) {
-		struct rte_mbuf *buf[PACKET_READ_SIZE];
-		uint16_t rx_count;
-
-		/* read a port */
-		rx_count = rte_eth_rx_burst(ports->id[port_num], 0, \
-				buf, PACKET_READ_SIZE);
-		ports->rx_stats.rx[port_num] += rx_count;
-
-		/* Now process the NIC packets read */
-		if (likely(rx_count > 0))
-			process_packets(port_num, buf, rx_count);
-
-		/* move to next port */
-		if (++port_num == ports->num_ports)
-			port_num = 0;
-	}
-}
-
-int
-main(int argc, char *argv[])
-{
-	/* initialise the system */
-	if (init(argc, argv) < 0 )
-		return -1;
-	RTE_LOG(INFO, APP, "Finished Process Init.\n");
-
-	cl_rx_buf = calloc(num_clients, sizeof(cl_rx_buf[0]));
-
-	/* clear statistics */
-	clear_stats();
-
-	/* put all other cores to sleep bar master */
-	rte_eal_mp_remote_launch(sleep_lcore, NULL, SKIP_MASTER);
-
-	do_packet_forwarding();
-	return 0;
-}
diff --git a/examples/multi_process/client_server_mp/shared/common.h b/examples/multi_process/client_server_mp/shared/common.h
deleted file mode 100644
index ac91755..0000000
--- a/examples/multi_process/client_server_mp/shared/common.h
+++ /dev/null
@@ -1,58 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#ifndef _COMMON_H_
-#define _COMMON_H_
-
-#define MAX_CLIENTS             16
-
-/*
- * Shared port info, including statistics information for display by server.
- * Structure will be put in a memzone.
- * - All port id values share one cache line as this data will be read-only
- * during operation.
- * - All rx statistic values share cache lines, as this data is written only
- * by the server process. (rare reads by stats display)
- * - The tx statistics have values for all ports per cache line, but the stats
- * themselves are written by the clients, so we have a distinct set, on different
- * cache lines for each client to use.
- */
-struct rx_stats{
-	uint64_t rx[RTE_MAX_ETHPORTS];
-} __rte_cache_aligned;
-
-struct tx_stats{
-	uint64_t tx[RTE_MAX_ETHPORTS];
-	uint64_t tx_drop[RTE_MAX_ETHPORTS];
-} __rte_cache_aligned;
-
-struct port_info {
-	uint16_t num_ports;
-	uint16_t id[RTE_MAX_ETHPORTS];
-	volatile struct rx_stats rx_stats;
-	volatile struct tx_stats tx_stats[MAX_CLIENTS];
-};
-
-/* define common names for structures shared between server and client */
-#define MP_CLIENT_RXQ_NAME "MProc_Client_%u_RX"
-#define PKTMBUF_POOL_NAME "MProc_pktmbuf_pool"
-#define MZ_PORT_INFO "MProc_port_info"
-
-/*
- * Given the rx queue name template above, get the queue name
- */
-static inline const char *
-get_rx_queue_name(unsigned id)
-{
-	/* buffer for return value. Size calculated by %u being replaced
-	 * by maximum 3 digits (plus an extra byte for safety) */
-	static char buffer[sizeof(MP_CLIENT_RXQ_NAME) + 2];
-
-	snprintf(buffer, sizeof(buffer) - 1, MP_CLIENT_RXQ_NAME, id);
-	return buffer;
-}
-
-#define RTE_LOGTYPE_APP RTE_LOGTYPE_USER1
-
-#endif
diff --git a/examples/multi_process/l2fwd_fork/Makefile b/examples/multi_process/l2fwd_fork/Makefile
deleted file mode 100644
index 79d5068..0000000
--- a/examples/multi_process/l2fwd_fork/Makefile
+++ /dev/null
@@ -1,23 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-# binary name
-APP = l2fwd-fork
-
-# all source are stored in SRCS-y
-SRCS-y := main.c flib.c
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-
-include $(RTE_SDK)/mk/rte.extapp.mk
diff --git a/examples/multi_process/l2fwd_fork/flib.c b/examples/multi_process/l2fwd_fork/flib.c
deleted file mode 100644
index 52c6152..0000000
--- a/examples/multi_process/l2fwd_fork/flib.c
+++ /dev/null
@@ -1,280 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-#include <unistd.h>
-#include <stdio.h>
-#include <stdlib.h>
-#include <string.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <sys/types.h>
-#include <sys/queue.h>
-#include <sys/wait.h>
-#include <sys/prctl.h>
-#include <netinet/in.h>
-#include <setjmp.h>
-#include <stdarg.h>
-#include <ctype.h>
-#include <errno.h>
-#include <getopt.h>
-#include <dirent.h>
-#include <signal.h>
-
-#include <rte_common.h>
-#include <rte_log.h>
-#include <rte_malloc.h>
-#include <rte_memory.h>
-#include <rte_memcpy.h>
-#include <rte_eal.h>
-#include <rte_launch.h>
-#include <rte_atomic.h>
-#include <rte_cycles.h>
-#include <rte_prefetch.h>
-#include <rte_lcore.h>
-#include <rte_per_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_interrupts.h>
-#include <rte_random.h>
-#include <rte_debug.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-#include <rte_string_fns.h>
-
-#include "flib.h"
-
-#define SIG_PARENT_EXIT SIGUSR1
-
-struct lcore_stat {
-	pid_t pid;           /**< pthread identifier */
-	lcore_function_t *f; /**< function to call */
-	void *arg;           /**< argument of function */
-	slave_exit_notify *cb_fn;
-} __rte_cache_aligned;
-
-
-static struct lcore_stat *core_cfg;
-static uint16_t *lcore_cfg = NULL;
-
-/* signal handler to be notified after parent leaves */
-static void
-sighand_parent_exit(int sig)
-{
-	printf("lcore = %u : Find parent leaves, sig=%d\n", rte_lcore_id(),
-			sig);
-	printf("Child leaving\n");
-	exit(0);
-
-	return;
-}
-
-/**
- * Real function entrance ran in slave process
- **/
-static int
-slave_proc_func(void)
-{
-	struct rte_config *config;
-	unsigned slave_id = rte_lcore_id();
-	struct lcore_stat *cfg = &core_cfg[slave_id];
-
-	if (prctl(PR_SET_PDEATHSIG, SIG_PARENT_EXIT, 0, 0, 0, 0) != 0)
-		printf("Warning: Slave can't register for being notified in"
-               "case master process exited\n");
-	else {
-		struct sigaction act;
-		memset(&act, 0 , sizeof(act));
-		act.sa_handler = sighand_parent_exit;
-		if (sigaction(SIG_PARENT_EXIT, &act, NULL) != 0)
-			printf("Fail to register signal handler:%d\n", SIG_PARENT_EXIT);
-	}
-
-	/* Set slave process to SECONDARY to avoid operation like dev_start/stop etc */
-	config = rte_eal_get_configuration();
-	if (NULL == config)
-		printf("Warning:Can't get rte_config\n");
-	else
-		config->process_type = RTE_PROC_SECONDARY;
-
-	printf("Core %u is ready (pid=%d)\n", slave_id, (int)cfg->pid);
-
-	exit(cfg->f(cfg->arg));
-}
-
-/**
- * function entrance ran in master thread, which will spawn slave process and wait until
- * specific slave exited.
- **/
-static int
-lcore_func(void *arg __attribute__((unused)))
-{
-	unsigned slave_id = rte_lcore_id();
-	struct lcore_stat *cfg = &core_cfg[slave_id];
-	int pid, stat;
-
-	if (rte_get_master_lcore() == slave_id)
-		return cfg->f(cfg->arg);
-
-	/* fork a slave process */
-	pid = fork();
-
-	if (pid == -1) {
-		printf("Failed to fork\n");
-		return -1;
-	} else if (pid == 0) /* child */
-		return slave_proc_func();
-	else { /* parent */
-		cfg->pid = pid;
-
-		waitpid(pid, &stat, 0);
-
-		cfg->pid = 0;
-		cfg->f = NULL;
-		cfg->arg = NULL;
-		/* Notify slave's exit if applicable */
-		if(cfg->cb_fn)
-			cfg->cb_fn(slave_id, stat);
-		return stat;
-	}
-}
-
-static int
-lcore_id_init(void)
-{
-	int i;
-	/* Setup lcore ID allocation map */
-	lcore_cfg = rte_zmalloc("LCORE_ID_MAP",
-						sizeof(uint16_t) * RTE_MAX_LCORE,
-						RTE_CACHE_LINE_SIZE);
-
-	if(lcore_cfg == NULL)
-		rte_panic("Failed to malloc\n");
-
-	for (i = 0; i < RTE_MAX_LCORE; i++) {
-		if (rte_lcore_is_enabled(i))
-			lcore_cfg[i] = 1;
-	}
-	return 0;
-}
-
-int
-flib_assign_lcore_id(void)
-{
-	unsigned i;
-	int ret;
-
-	/**
-	 * thread assigned a lcore id previously, or a  slave thread. But still have
-	 * a bug here: If the core mask includes core 0, and that core call this
-	 * function, it still can get a new lcore id.
-	 **/
-	if (rte_lcore_id() != 0)
-		return -1;
-
-	do {
-		/* Find a lcore id not used yet, avoid to use lcore ID 0 */
-		for (i = 1; i < RTE_MAX_LCORE; i++) {
-			if (lcore_cfg[i] == 0)
-				break;
-		}
-		if (i == RTE_MAX_LCORE)
-			return -1;
-
-		/* Assign new lcore id to this thread */
-
-		ret = rte_atomic16_cmpset(&lcore_cfg[i], 0, 1);
-	} while (unlikely(ret == 0));
-
-	RTE_PER_LCORE(_lcore_id) = i;
-	return i;
-}
-
-void
-flib_free_lcore_id(unsigned lcore_id)
-{
-	/* id is not valid or belongs to pinned core id */
-	if (lcore_id >= RTE_MAX_LCORE || lcore_id == 0 ||
-		rte_lcore_is_enabled(lcore_id))
-		return;
-
-	lcore_cfg[lcore_id] = 0;
-}
-
-int
-flib_register_slave_exit_notify(unsigned slave_id,
-	slave_exit_notify *cb)
-{
-	if (cb == NULL)
-		return -EFAULT;
-
-	if (!rte_lcore_is_enabled(slave_id))
-		return -ENOENT;
-
-	core_cfg[slave_id].cb_fn = cb;
-
-	return 0;
-}
-
-enum slave_stat
-flib_query_slave_status(unsigned slave_id)
-{
-	if (!rte_lcore_is_enabled(slave_id))
-		return ST_FREEZE;
-	/* pid only be set when slave process spawned */
-	if (core_cfg[slave_id].pid != 0)
-		return ST_RUN;
-	else
-		return ST_IDLE;
-}
-
-int
-flib_remote_launch(lcore_function_t *f,
-					void *arg, unsigned slave_id)
-{
-	if (f == NULL)
-		return -1;
-
-	if (!rte_lcore_is_enabled(slave_id))
-		return -1;
-
-	/* Wait until specific lcore state change to WAIT */
-	rte_eal_wait_lcore(slave_id);
-
-	core_cfg[slave_id].f = f;
-	core_cfg[slave_id].arg = arg;
-
-	return rte_eal_remote_launch(lcore_func, NULL, slave_id);
-}
-
-int
-flib_mp_remote_launch(lcore_function_t *f, void *arg,
-			enum rte_rmt_call_master_t call_master)
-{
-	int i;
-
-	RTE_LCORE_FOREACH_SLAVE(i) {
-		core_cfg[i].arg = arg;
-		core_cfg[i].f = f;
-	}
-
-	return rte_eal_mp_remote_launch(lcore_func, NULL, call_master);
-}
-
-int
-flib_init(void)
-{
-	if ((core_cfg = rte_zmalloc("core_cfg",
-		sizeof(struct lcore_stat) * RTE_MAX_LCORE,
-		RTE_CACHE_LINE_SIZE)) == NULL ) {
-		printf("rte_zmalloc failed\n");
-		return -1;
-	}
-
-	if (lcore_id_init() != 0) {
-		printf("lcore_id_init failed\n");
-		return -1;
-	}
-
-	return 0;
-}
diff --git a/examples/multi_process/l2fwd_fork/flib.h b/examples/multi_process/l2fwd_fork/flib.h
deleted file mode 100644
index 8bc13a1..0000000
--- a/examples/multi_process/l2fwd_fork/flib.h
+++ /dev/null
@@ -1,120 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#ifndef __FLIB_H
-#define __FLIB_H
-
-/* callback function pointer when specific slave leaves */
-typedef void (slave_exit_notify)(unsigned slaveid, int stat);
-
-enum slave_stat{
-	ST_FREEZE = 1,
-	ST_IDLE,
-	ST_RUN,
-	ST_ZOMBIE,	/* Not implemented yet */
-};
-
-/**
- * Initialize the fork lib.
- *
- * @return
- *    - 0 : fork lib initialized successfully
- *    - -1 : fork lib initialized failed
- */
-int flib_init(void);
-
-/**
- * Check that every SLAVE lcores are in WAIT state, then call
- * flib_remote_launch() for all of them. If call_master is true
- * (set to CALL_MASTER), also call the function on the master lcore.
- *
- * @param f:
- *	function pointer need to run
- * @param arg:
- *	argument for f to carry
- * @param call_master
- *	- SKIP_MASTER : only launch function on slave lcores
- *	- CALL_MASTER : launch function on master and slave lcores
- * @return
- *    - 0 : function  execute successfully
- *    - -1 :  function  execute  failed
- */
-int flib_mp_remote_launch(lcore_function_t *f,
-		void *arg, enum rte_rmt_call_master_t call_master);
-
-/**
- * Send a message to a slave lcore identified by slave_id to call a
- * function f with argument arg.
- *
- * @param f:
- *	function pointer need to run
- * @param arg:
- *	argument for f to carry
- * @param slave_id
- *	slave lcore id to run on
- * @return
- *    - 0 : function  execute successfully
- *    - -1 :  function  execute  failed
- */
-int flib_remote_launch(lcore_function_t *f,
-					void *arg, unsigned slave_id);
-
-/**
- * Query the running stat for specific slave, wont' work in with master id
- *
- * @param slave_id:
- *	lcore id which should not be master id
- * @return
- *    - ST_FREEZE : lcore is not in enabled core mask
- *	 - ST_IDLE     : lcore is idle
- *    -  ST_RUN     : lcore is running something
- */
-enum slave_stat
-flib_query_slave_status(unsigned slave_id);
-
-/**
- * Register a callback function to be notified in case specific slave exit.
- *
- * @param slave_id:
- *	lcore id which should not be master id
- * @param cb:
- *	callback pointer to register
- * @return
- *    - 0            :  function  execute successfully
- *    - -EFAULT  :  argument error
- *    - -ENOENT :  slave_id not correct
- */
-int flib_register_slave_exit_notify(unsigned slave_id,
-	slave_exit_notify *cb);
-
-/**
- * Assign a lcore ID to non-slave thread.  Non-slave thread refers to thread that
- * not created by function rte_eal_remote_launch or rte_eal_mp_remote_launch.
- * These threads can either bind lcore or float among different lcores.
- * This lcore ID will be unique in multi-thread or multi-process DPDK running
- * environment, then it can benefit from using the cache mechanism provided in
- * mempool library.
- * After calling successfully, use rte_lcore_id() to get the assigned lcore ID, but
- * other lcore funtions can't guarantee to work correctly.
- *
- * @return
- *   -    -1  : can't assign a lcore id with 3 possibilities.
- *                 - it's not non-slave thread.
- *                 - it had assign a lcore id previously
- *                 - the lcore id is running out.
- *   -  > 0 :  the assigned lcore id.
- */
-int flib_assign_lcore_id(void);
-
-/**
- * Free the lcore_id that assigned in flib_assign_lcore_id().
- * call it in case non-slave thread is leaving or left.
- *
- * @param lcore_id
- * The identifier of the lcore, which MUST be between 1 and
- *   RTE_MAX_LCORE-1.
- */
-void flib_free_lcore_id(unsigned lcore_id);
-
-#endif /* __FLIB_H  */
diff --git a/examples/multi_process/l2fwd_fork/main.c b/examples/multi_process/l2fwd_fork/main.c
deleted file mode 100644
index 6b130f2..0000000
--- a/examples/multi_process/l2fwd_fork/main.c
+++ /dev/null
@@ -1,1259 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-#define _GNU_SOURCE
-#include <stdio.h>
-#include <stdlib.h>
-#include <unistd.h>
-#include <string.h>
-#include <stdint.h>
-#include <sched.h>
-#include <inttypes.h>
-#include <sys/types.h>
-#include <sys/queue.h>
-#include <netinet/in.h>
-#include <setjmp.h>
-#include <stdarg.h>
-#include <ctype.h>
-#include <errno.h>
-#include <getopt.h>
-
-#include <rte_common.h>
-#include <rte_log.h>
-#include <rte_memory.h>
-#include <rte_memcpy.h>
-#include <rte_eal.h>
-#include <rte_launch.h>
-#include <rte_atomic.h>
-#include <rte_spinlock.h>
-#include <rte_cycles.h>
-#include <rte_prefetch.h>
-#include <rte_lcore.h>
-#include <rte_per_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_interrupts.h>
-#include <rte_random.h>
-#include <rte_debug.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_ring.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-#include <rte_malloc.h>
-
-#include "flib.h"
-
-#define RTE_LOGTYPE_L2FWD RTE_LOGTYPE_USER1
-#define MBUF_NAME	"mbuf_pool_%d"
-#define MBUF_DATA_SIZE	RTE_MBUF_DEFAULT_BUF_SIZE
-#define NB_MBUF   8192
-#define RING_MASTER_NAME	"l2fwd_ring_m2s_"
-#define RING_SLAVE_NAME		"l2fwd_ring_s2m_"
-#define MAX_NAME_LEN	32
-/* RECREATE flag indicate needs initialize resource and launch slave_core again */
-#define SLAVE_RECREATE_FLAG 0x1
-/* RESTART flag indicate needs restart port and send START command again */
-#define SLAVE_RESTART_FLAG 0x2
-#define INVALID_MAPPING_ID	((unsigned)LCORE_ID_ANY)
-/* Maximum message buffer per slave */
-#define NB_CORE_MSGBUF	32
-enum l2fwd_cmd{
-	CMD_START,
-	CMD_STOP,
-};
-
-#define MAX_PKT_BURST 32
-#define BURST_TX_DRAIN_US 100 /* TX drain every ~100us */
-
-/*
- * Configurable number of RX/TX ring descriptors
- */
-#define RTE_TEST_RX_DESC_DEFAULT 1024
-#define RTE_TEST_TX_DESC_DEFAULT 1024
-static uint16_t nb_rxd = RTE_TEST_RX_DESC_DEFAULT;
-static uint16_t nb_txd = RTE_TEST_TX_DESC_DEFAULT;
-
-/* ethernet addresses of ports */
-static struct ether_addr l2fwd_ports_eth_addr[RTE_MAX_ETHPORTS];
-
-/* mask of enabled ports */
-static uint32_t l2fwd_enabled_port_mask = 0;
-
-/* list of enabled ports */
-static uint32_t l2fwd_dst_ports[RTE_MAX_ETHPORTS];
-
-static unsigned int l2fwd_rx_queue_per_lcore = 1;
-
-struct mbuf_table {
-	unsigned len;
-	struct rte_mbuf *m_table[MAX_PKT_BURST];
-};
-
-#define MAX_RX_QUEUE_PER_LCORE 16
-#define MAX_TX_QUEUE_PER_PORT 16
-struct lcore_queue_conf {
-	unsigned n_rx_port;
-	unsigned rx_port_list[MAX_RX_QUEUE_PER_LCORE];
-} __rte_cache_aligned;
-struct lcore_queue_conf lcore_queue_conf[RTE_MAX_LCORE];
-
-struct rte_eth_dev_tx_buffer *tx_buffer[RTE_MAX_ETHPORTS];
-
-struct lcore_resource_struct {
-	int enabled;	/* Only set in case this lcore involved into packet forwarding */
-	int flags; 	    /* Set only slave need to restart or recreate */
-	unsigned lcore_id;  /*  lcore ID */
-	unsigned pair_id; 	/* dependency lcore ID on port */
-	char ring_name[2][MAX_NAME_LEN];
-	/* ring[0] for master send cmd, slave read */
-	/* ring[1] for slave send ack, master read */
-	struct rte_ring *ring[2];
-	int port_num;					/* Total port numbers */
-	/* Port id for that lcore to receive packets */
-	uint16_t port[RTE_MAX_ETHPORTS];
-}__attribute__((packed)) __rte_cache_aligned;
-
-static struct lcore_resource_struct lcore_resource[RTE_MAX_LCORE];
-static struct rte_mempool *message_pool;
-static rte_spinlock_t res_lock = RTE_SPINLOCK_INITIALIZER;
-/* use floating processes */
-static int float_proc = 0;
-/* Save original cpu affinity */
-struct cpu_aff_arg{
-	cpu_set_t set;
-	size_t size;
-}cpu_aff;
-
-static const struct rte_eth_conf port_conf = {
-	.rxmode = {
-		.split_hdr_size = 0,
-		.ignore_offload_bitfield = 1,
-		.offloads = DEV_RX_OFFLOAD_CRC_STRIP,
-	},
-	.txmode = {
-		.mq_mode = ETH_MQ_TX_NONE,
-	},
-};
-
-static struct rte_mempool * l2fwd_pktmbuf_pool[RTE_MAX_ETHPORTS];
-
-/* Per-port statistics struct */
-struct l2fwd_port_statistics {
-	uint64_t tx;
-	uint64_t rx;
-	uint64_t dropped;
-} __rte_cache_aligned;
-struct l2fwd_port_statistics *port_statistics;
-/**
- * pointer to lcore ID mapping array, used to return lcore id in case slave
- * process exited unexpectedly, use only floating process option applied
- **/
-unsigned *mapping_id;
-
-/* A tsc-based timer responsible for triggering statistics printout */
-#define TIMER_MILLISECOND 2000000ULL /* around 1ms at 2 Ghz */
-#define MAX_TIMER_PERIOD 86400 /* 1 day max */
-static int64_t timer_period = 10 * TIMER_MILLISECOND * 1000; /* default period is 10 seconds */
-
-static int l2fwd_launch_one_lcore(void *dummy);
-
-/* Print out statistics on packets dropped */
-static void
-print_stats(void)
-{
-	uint64_t total_packets_dropped, total_packets_tx, total_packets_rx;
-	unsigned portid;
-
-	total_packets_dropped = 0;
-	total_packets_tx = 0;
-	total_packets_rx = 0;
-
-	const char clr[] = { 27, '[', '2', 'J', '\0' };
-	const char topLeft[] = { 27, '[', '1', ';', '1', 'H','\0' };
-
-		/* Clear screen and move to top left */
-	printf("%s%s", clr, topLeft);
-
-	printf("\nPort statistics ====================================");
-
-	for (portid = 0; portid < RTE_MAX_ETHPORTS; portid++) {
-		/* skip disabled ports */
-		if ((l2fwd_enabled_port_mask & (1 << portid)) == 0)
-			continue;
-		printf("\nStatistics for port %u ------------------------------"
-			   "\nPackets sent: %24"PRIu64
-			   "\nPackets received: %20"PRIu64
-			   "\nPackets dropped: %21"PRIu64,
-			   portid,
-			   port_statistics[portid].tx,
-			   port_statistics[portid].rx,
-			   port_statistics[portid].dropped);
-
-		total_packets_dropped += port_statistics[portid].dropped;
-		total_packets_tx += port_statistics[portid].tx;
-		total_packets_rx += port_statistics[portid].rx;
-	}
-	printf("\nAggregate statistics ==============================="
-		   "\nTotal packets sent: %18"PRIu64
-		   "\nTotal packets received: %14"PRIu64
-		   "\nTotal packets dropped: %15"PRIu64,
-		   total_packets_tx,
-		   total_packets_rx,
-		   total_packets_dropped);
-	printf("\n====================================================\n");
-}
-
-static int
-clear_cpu_affinity(void)
-{
-	int s;
-
-	s = sched_setaffinity(0, cpu_aff.size, &cpu_aff.set);
-	if (s != 0) {
-		printf("sched_setaffinity failed:%s\n", strerror(errno));
-		return -1;
-	}
-
-	return 0;
-}
-
-static int
-get_cpu_affinity(void)
-{
-	int s;
-
-	cpu_aff.size = sizeof(cpu_set_t);
-	CPU_ZERO(&cpu_aff.set);
-
-	s = sched_getaffinity(0, cpu_aff.size, &cpu_aff.set);
-	if (s != 0) {
-		printf("sched_getaffinity failed:%s\n", strerror(errno));
-		return -1;
-	}
-
-	return 0;
-}
-
-/**
- * This fnciton demonstrates the approach to create ring in first instance
- * or re-attach an existed ring in later instance.
- **/
-static struct rte_ring *
-create_ring(const char *name, unsigned count,
-					int socket_id,unsigned flags)
-{
-	struct rte_ring *ring;
-
-	if (name == NULL)
-		return NULL;
-
-	/* If already create, just attached it */
-	if (likely((ring = rte_ring_lookup(name)) != NULL))
-		return ring;
-
-	/* First call it, create one */
-	return rte_ring_create(name, count, socket_id, flags);
-}
-
-/* Malloc with rte_malloc on structures that shared by master and slave */
-static int
-l2fwd_malloc_shared_struct(void)
-{
-	port_statistics = rte_zmalloc("port_stat",
-						sizeof(struct l2fwd_port_statistics) * RTE_MAX_ETHPORTS,
-						0);
-	if (port_statistics == NULL)
-		return -1;
-
-	/* allocate  mapping_id array */
-	if (float_proc) {
-		int i;
-		mapping_id = rte_malloc("mapping_id", sizeof(unsigned) * RTE_MAX_LCORE,
-								0);
-
-		if (mapping_id == NULL)
-			return -1;
-
-		for (i = 0 ;i < RTE_MAX_LCORE; i++)
-			mapping_id[i] = INVALID_MAPPING_ID;
-	}
-	return 0;
-}
-
-/* Create ring which used for communicate among master and slave */
-static int
-create_ms_ring(unsigned slaveid)
-{
-	unsigned flag = RING_F_SP_ENQ | RING_F_SC_DEQ;
-	struct lcore_resource_struct *res = &lcore_resource[slaveid];
-	unsigned socketid = rte_socket_id();
-
-	/* Always assume create ring on master socket_id */
-	/* Default only create a ring size 32 */
-	snprintf(res->ring_name[0], MAX_NAME_LEN, "%s%u",
-			RING_MASTER_NAME, slaveid);
-	if ((res->ring[0] = create_ring(res->ring_name[0], NB_CORE_MSGBUF,
-				socketid, flag)) == NULL) {
-		printf("Create m2s ring %s failed\n", res->ring_name[0]);
-		return -1;
-	}
-
-	snprintf(res->ring_name[1], MAX_NAME_LEN, "%s%u",
-			RING_SLAVE_NAME, slaveid);
-	if ((res->ring[1] = create_ring(res->ring_name[1], NB_CORE_MSGBUF,
-		socketid, flag)) == NULL) {
-		printf("Create s2m ring %s failed\n", res->ring_name[1]);
-		return -1;
-	}
-
-	return 0;
-}
-
-/* send command to pair in paired master and slave ring */
-static inline int
-sendcmd(unsigned slaveid, enum l2fwd_cmd cmd, int is_master)
-{
-	struct lcore_resource_struct *res = &lcore_resource[slaveid];
-	void *msg;
-	int fd = !is_master;
-
-	/* Only check master, it must be enabled and running if it is slave */
-	if (is_master && !res->enabled)
-		return -1;
-
-	if (res->ring[fd] == NULL)
-		return -1;
-
-	if (rte_mempool_get(message_pool, &msg) < 0) {
-		printf("Error to get message buffer\n");
-		return -1;
-	}
-
-	*(enum l2fwd_cmd *)msg = cmd;
-
-	if (rte_ring_enqueue(res->ring[fd], msg) != 0) {
-		printf("Enqueue error\n");
-		rte_mempool_put(message_pool, msg);
-		return -1;
-	}
-
-	return 0;
-}
-
-/* Get command from pair in paired master and slave ring */
-static inline int
-getcmd(unsigned slaveid, enum l2fwd_cmd *cmd, int is_master)
-{
-	struct lcore_resource_struct *res = &lcore_resource[slaveid];
-	void *msg;
-	int fd = !!is_master;
-	int ret;
-	/* Only check master, it must be enabled and running if it is slave */
-	if (is_master && (!res->enabled))
-		return -1;
-
-	if (res->ring[fd] == NULL)
-		return -1;
-
-	ret = rte_ring_dequeue(res->ring[fd], &msg);
-
-	if (ret == 0) {
-		*cmd = *(enum l2fwd_cmd *)msg;
-		rte_mempool_put(message_pool, msg);
-	}
-	return ret;
-}
-
-/* Master send command to slave and wait until ack received or error met */
-static int
-master_sendcmd_with_ack(unsigned slaveid, enum l2fwd_cmd cmd)
-{
-	enum l2fwd_cmd ack_cmd;
-	int ret = -1;
-
-	if (sendcmd(slaveid, cmd, 1) != 0)
-		rte_exit(EXIT_FAILURE, "Failed to send message\n");
-
-	/* Get ack */
-	while (1) {
-		ret = getcmd(slaveid, &ack_cmd, 1);
-		if (ret == 0 && cmd == ack_cmd)
-			break;
-
-		/* If slave not running yet, return an error */
-		if (flib_query_slave_status(slaveid) != ST_RUN) {
-			ret = -ENOENT;
-			break;
-		}
-	}
-
-	return ret;
-}
-
-/* restart all port that assigned to that slave lcore */
-static int
-reset_slave_all_ports(unsigned slaveid)
-{
-	struct lcore_resource_struct *slave = &lcore_resource[slaveid];
-	int i, ret = 0;
-
-	/* stop/start port */
-	for (i = 0; i < slave->port_num; i++) {
-		char buf_name[RTE_MEMPOOL_NAMESIZE];
-		struct rte_mempool *pool;
-		printf("Stop port :%d\n", slave->port[i]);
-		rte_eth_dev_stop(slave->port[i]);
-		snprintf(buf_name, RTE_MEMPOOL_NAMESIZE, MBUF_NAME, slave->port[i]);
-		pool = rte_mempool_lookup(buf_name);
-		if (pool)
-			printf("Port %d mempool free object is %u(%u)\n", slave->port[i],
-				rte_mempool_avail_count(pool),
-				(unsigned int)NB_MBUF);
-		else
-			printf("Can't find mempool %s\n", buf_name);
-
-		printf("Start port :%d\n", slave->port[i]);
-		ret = rte_eth_dev_start(slave->port[i]);
-		if (ret != 0)
-			break;
-	}
-	return ret;
-}
-
-static int
-reset_shared_structures(unsigned slaveid)
-{
-	int ret;
-	/* Only port are shared resource here */
-	ret = reset_slave_all_ports(slaveid);
-
-	return ret;
-}
-
-/**
- * Call this function to re-create resource that needed for slave process that
- * exited in last instance
- **/
-static int
-init_slave_res(unsigned slaveid)
-{
-	struct lcore_resource_struct *slave = &lcore_resource[slaveid];
-	enum l2fwd_cmd cmd;
-
-	if (!slave->enabled) {
-		printf("Something wrong with lcore=%u enabled=%d\n",slaveid,
-			slave->enabled);
-		return -1;
-	}
-
-	/* Initialize ring */
-	if (create_ms_ring(slaveid) != 0)
-		rte_exit(EXIT_FAILURE, "failed to create ring for slave %u\n",
-				slaveid);
-
-	/* drain un-read buffer if have */
-	while (getcmd(slaveid, &cmd, 1) == 0);
-	while (getcmd(slaveid, &cmd, 0) == 0);
-
-	return 0;
-}
-
-static int
-recreate_one_slave(unsigned slaveid)
-{
-	int ret = 0;
-	/* Re-initialize resource for stalled slave */
-	if ((ret = init_slave_res(slaveid)) != 0) {
-		printf("Init slave=%u failed\n", slaveid);
-		return ret;
-	}
-
-	if ((ret = flib_remote_launch(l2fwd_launch_one_lcore, NULL, slaveid))
-		!= 0)
-		printf("Launch slave %u failed\n", slaveid);
-
-	return ret;
-}
-
-/**
- * remapping resource belong to slave_id to new lcore that gets from flib_assign_lcore_id(),
- * used only floating process option applied.
- *
- * @param slaveid
- *   original lcore_id that apply for remapping
- */
-static void
-remapping_slave_resource(unsigned slaveid, unsigned map_id)
-{
-
-	/* remapping lcore_resource */
-	memcpy(&lcore_resource[map_id], &lcore_resource[slaveid],
-			sizeof(struct lcore_resource_struct));
-
-	/* remapping lcore_queue_conf */
-	memcpy(&lcore_queue_conf[map_id], &lcore_queue_conf[slaveid],
-			sizeof(struct lcore_queue_conf));
-}
-
-static int
-reset_pair(unsigned slaveid, unsigned pairid)
-{
-	int ret;
-	if ((ret = reset_shared_structures(slaveid)) != 0)
-		goto back;
-
-	if((ret = reset_shared_structures(pairid)) != 0)
-		goto back;
-
-	if (float_proc) {
-		unsigned map_id = mapping_id[slaveid];
-
-		if (map_id != INVALID_MAPPING_ID) {
-			printf("%u return mapping id %u\n", slaveid, map_id);
-			flib_free_lcore_id(map_id);
-			mapping_id[slaveid] = INVALID_MAPPING_ID;
-		}
-
-		map_id = mapping_id[pairid];
-		if (map_id != INVALID_MAPPING_ID) {
-			printf("%u return mapping id %u\n", pairid, map_id);
-			flib_free_lcore_id(map_id);
-			mapping_id[pairid] = INVALID_MAPPING_ID;
-		}
-	}
-
-	if((ret = recreate_one_slave(slaveid)) != 0)
-		goto back;
-
-	ret = recreate_one_slave(pairid);
-
-back:
-	return ret;
-}
-
-static void
-slave_exit_cb(unsigned slaveid, __attribute__((unused))int stat)
-{
-	struct lcore_resource_struct *slave = &lcore_resource[slaveid];
-
-	printf("Get slave %u leave info\n", slaveid);
-	if (!slave->enabled) {
-		printf("Lcore=%u not registered for it's exit\n", slaveid);
-		return;
-	}
-	rte_spinlock_lock(&res_lock);
-
-	/* Change the state and wait master to start them */
-	slave->flags = SLAVE_RECREATE_FLAG;
-
-	rte_spinlock_unlock(&res_lock);
-}
-
-static void
-l2fwd_simple_forward(struct rte_mbuf *m, unsigned portid)
-{
-	struct ether_hdr *eth;
-	void *tmp;
-	unsigned dst_port;
-	int sent;
-	struct rte_eth_dev_tx_buffer *buffer;
-
-	dst_port = l2fwd_dst_ports[portid];
-	eth = rte_pktmbuf_mtod(m, struct ether_hdr *);
-
-	/* 02:00:00:00:00:xx */
-	tmp = &eth->d_addr.addr_bytes[0];
-	*((uint64_t *)tmp) = 0x000000000002 + ((uint64_t)dst_port << 40);
-
-	/* src addr */
-	ether_addr_copy(&l2fwd_ports_eth_addr[dst_port], &eth->s_addr);
-
-	buffer = tx_buffer[dst_port];
-	sent = rte_eth_tx_buffer(dst_port, 0, buffer, m);
-	if (sent)
-		port_statistics[dst_port].tx += sent;
-}
-
-/* main processing loop */
-static void
-l2fwd_main_loop(void)
-{
-	struct rte_mbuf *pkts_burst[MAX_PKT_BURST];
-	struct rte_mbuf *m;
-	int sent;
-	unsigned lcore_id;
-	uint64_t prev_tsc, diff_tsc, cur_tsc;
-	unsigned i, j, portid, nb_rx;
-	struct lcore_queue_conf *qconf;
-	const uint64_t drain_tsc = (rte_get_tsc_hz() + US_PER_S - 1) / US_PER_S *
-			BURST_TX_DRAIN_US;
-	struct rte_eth_dev_tx_buffer *buffer;
-
-	prev_tsc = 0;
-
-	lcore_id = rte_lcore_id();
-
-	qconf = &lcore_queue_conf[lcore_id];
-
-	if (qconf->n_rx_port == 0) {
-		RTE_LOG(INFO, L2FWD, "lcore %u has nothing to do\n", lcore_id);
-		return;
-	}
-
-	RTE_LOG(INFO, L2FWD, "entering main loop on lcore %u\n", lcore_id);
-
-	for (i = 0; i < qconf->n_rx_port; i++) {
-		portid = qconf->rx_port_list[i];
-		RTE_LOG(INFO, L2FWD, " -- lcoreid=%u portid=%u\n", lcore_id,
-			portid);
-	}
-
-	while (1) {
-		enum l2fwd_cmd cmd;
-		cur_tsc = rte_rdtsc();
-
-		if (unlikely(getcmd(lcore_id, &cmd, 0) == 0)) {
-			sendcmd(lcore_id, cmd, 0);
-
-			/* If get stop command, stop forwarding and exit */
-			if (cmd == CMD_STOP) {
-				return;
-			}
-		}
-
-		/*
-		 * TX burst queue drain
-		 */
-		diff_tsc = cur_tsc - prev_tsc;
-		if (unlikely(diff_tsc > drain_tsc)) {
-
-			for (i = 0; i < qconf->n_rx_port; i++) {
-
-				portid = l2fwd_dst_ports[qconf->rx_port_list[i]];
-				buffer = tx_buffer[portid];
-
-				sent = rte_eth_tx_buffer_flush(portid, 0, buffer);
-				if (sent)
-					port_statistics[portid].tx += sent;
-
-			}
-
-			prev_tsc = cur_tsc;
-		}
-
-		/*
-		 * Read packet from RX queues
-		 */
-		for (i = 0; i < qconf->n_rx_port; i++) {
-
-			portid = qconf->rx_port_list[i];
-			nb_rx = rte_eth_rx_burst((uint8_t) portid, 0,
-						 pkts_burst, MAX_PKT_BURST);
-
-			port_statistics[portid].rx += nb_rx;
-
-			for (j = 0; j < nb_rx; j++) {
-				m = pkts_burst[j];
-				rte_prefetch0(rte_pktmbuf_mtod(m, void *));
-				l2fwd_simple_forward(m, portid);
-			}
-		}
-	}
-}
-
-static int
-l2fwd_launch_one_lcore(__attribute__((unused)) void *dummy)
-{
-	unsigned lcore_id = rte_lcore_id();
-
-	if (float_proc) {
-		unsigned flcore_id;
-
-		/* Change it to floating process, also change it's lcore_id */
-		clear_cpu_affinity();
-		RTE_PER_LCORE(_lcore_id) = 0;
-		/* Get a lcore_id */
-		if (flib_assign_lcore_id() < 0 ) {
-			printf("flib_assign_lcore_id failed\n");
-			return -1;
-		}
-		flcore_id = rte_lcore_id();
-		/* Set mapping id, so master can return it after slave exited */
-		mapping_id[lcore_id] = flcore_id;
-		printf("Org lcore_id = %u, cur lcore_id = %u\n",
-				lcore_id, flcore_id);
-		remapping_slave_resource(lcore_id, flcore_id);
-	}
-
-	l2fwd_main_loop();
-
-	/* return lcore_id before return */
-	if (float_proc) {
-		flib_free_lcore_id(rte_lcore_id());
-		mapping_id[lcore_id] = INVALID_MAPPING_ID;
-	}
-	return 0;
-}
-
-/* display usage */
-static void
-l2fwd_usage(const char *prgname)
-{
-	printf("%s [EAL options] -- -p PORTMASK -s COREMASK [-q NQ] -f\n"
-	       "  -p PORTMASK: hexadecimal bitmask of ports to configure\n"
-	       "  -q NQ: number of queue (=ports) per lcore (default is 1)\n"
-	       "  -f use floating process which won't bind to any core to run\n"
-		   "  -T PERIOD: statistics will be refreshed each PERIOD seconds (0 to disable, 10 default, 86400 maximum)\n",
-	       prgname);
-}
-
-static int
-l2fwd_parse_portmask(const char *portmask)
-{
-	char *end = NULL;
-	unsigned long pm;
-
-	/* parse hexadecimal string */
-	pm = strtoul(portmask, &end, 16);
-	if ((portmask[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (pm == 0)
-		return -1;
-
-	return pm;
-}
-
-static unsigned int
-l2fwd_parse_nqueue(const char *q_arg)
-{
-	char *end = NULL;
-	unsigned long n;
-
-	/* parse hexadecimal string */
-	n = strtoul(q_arg, &end, 10);
-	if ((q_arg[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return 0;
-	if (n == 0)
-		return 0;
-	if (n >= MAX_RX_QUEUE_PER_LCORE)
-		return 0;
-
-	return n;
-}
-
-static int
-l2fwd_parse_timer_period(const char *q_arg)
-{
-	char *end = NULL;
-	int n;
-
-	/* parse number string */
-	n = strtol(q_arg, &end, 10);
-	if ((q_arg[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-	if (n >= MAX_TIMER_PERIOD)
-		return -1;
-
-	return n;
-}
-
-/* Parse the argument given in the command line of the application */
-static int
-l2fwd_parse_args(int argc, char **argv)
-{
-	int opt, ret;
-	char **argvopt;
-	int option_index;
-	char *prgname = argv[0];
-	static struct option lgopts[] = {
-		{NULL, 0, 0, 0}
-	};
-	int has_pmask = 0;
-
-	argvopt = argv;
-
-	while ((opt = getopt_long(argc, argvopt, "p:q:T:f",
-				  lgopts, &option_index)) != EOF) {
-
-		switch (opt) {
-		/* portmask */
-		case 'p':
-			l2fwd_enabled_port_mask = l2fwd_parse_portmask(optarg);
-			if (l2fwd_enabled_port_mask == 0) {
-				printf("invalid portmask\n");
-				l2fwd_usage(prgname);
-				return -1;
-			}
-			has_pmask = 1;
-			break;
-
-		/* nqueue */
-		case 'q':
-			l2fwd_rx_queue_per_lcore = l2fwd_parse_nqueue(optarg);
-			if (l2fwd_rx_queue_per_lcore == 0) {
-				printf("invalid queue number\n");
-				l2fwd_usage(prgname);
-				return -1;
-			}
-			break;
-
-		/* timer period */
-		case 'T':
-			timer_period = l2fwd_parse_timer_period(optarg) * 1000 * TIMER_MILLISECOND;
-			if (timer_period < 0) {
-				printf("invalid timer period\n");
-				l2fwd_usage(prgname);
-				return -1;
-			}
-			break;
-
-		/* use floating process */
-		case 'f':
-			float_proc = 1;
-			break;
-
-		/* long options */
-		case 0:
-			l2fwd_usage(prgname);
-			return -1;
-
-		default:
-			l2fwd_usage(prgname);
-			return -1;
-		}
-	}
-
-	if (optind >= 0)
-		argv[optind-1] = prgname;
-
-	if (!has_pmask) {
-		l2fwd_usage(prgname);
-		return -1;
-	}
-	ret = optind-1;
-	optind = 1; /* reset getopt lib */
-	return ret;
-}
-
-/* Check the link status of all ports in up to 9s, and print them finally */
-static void
-check_all_ports_link_status(uint32_t port_mask)
-{
-#define CHECK_INTERVAL 100 /* 100ms */
-#define MAX_CHECK_TIME 90 /* 9s (90 * 100ms) in total */
-	uint16_t portid;
-	uint8_t count, all_ports_up, print_flag = 0;
-	struct rte_eth_link link;
-
-	printf("\nChecking link status");
-	fflush(stdout);
-	for (count = 0; count <= MAX_CHECK_TIME; count++) {
-		all_ports_up = 1;
-		RTE_ETH_FOREACH_DEV(portid) {
-			if ((port_mask & (1 << portid)) == 0)
-				continue;
-			memset(&link, 0, sizeof(link));
-			rte_eth_link_get_nowait(portid, &link);
-			/* print link status if flag set */
-			if (print_flag == 1) {
-				if (link.link_status)
-					printf(
-					"Port%d Link Up- speed %u Mbps- %s\n",
-					portid, link.link_speed,
-				(link.link_duplex == ETH_LINK_FULL_DUPLEX) ?
-					("full-duplex") : ("half-duplex\n"));
-				else
-					printf("Port %d Link Down\n", portid);
-				continue;
-			}
-			/* clear all_ports_up flag if any link down */
-			if (link.link_status == ETH_LINK_DOWN) {
-				all_ports_up = 0;
-				break;
-			}
-		}
-		/* after finally printing all link status, get out */
-		if (print_flag == 1)
-			break;
-
-		if (all_ports_up == 0) {
-			printf(".");
-			fflush(stdout);
-			rte_delay_ms(CHECK_INTERVAL);
-		}
-
-		/* set the print_flag if all ports up or timeout */
-		if (all_ports_up == 1 || count == (MAX_CHECK_TIME - 1)) {
-			print_flag = 1;
-			printf("done\n");
-		}
-	}
-}
-
-int
-main(int argc, char **argv)
-{
-	struct lcore_queue_conf *qconf;
-	int ret;
-	uint16_t nb_ports;
-	uint16_t nb_ports_available = 0;
-	uint16_t portid, last_port;
-	unsigned rx_lcore_id;
-	unsigned nb_ports_in_mask = 0;
-	unsigned i;
-	uint64_t prev_tsc, diff_tsc, cur_tsc, timer_tsc;
-
-	/* Save cpu_affinity first, restore it in case it's floating process option */
-	if (get_cpu_affinity() != 0)
-		rte_exit(EXIT_FAILURE, "get_cpu_affinity error\n");
-
-	/* Also tries to set cpu affinity to detect whether  it will fail in child process */
-	if(clear_cpu_affinity() != 0)
-		rte_exit(EXIT_FAILURE, "clear_cpu_affinity error\n");
-
-	/* init EAL */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid EAL arguments\n");
-	argc -= ret;
-	argv += ret;
-
-	/* parse application arguments (after the EAL ones) */
-	ret = l2fwd_parse_args(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid L2FWD arguments\n");
-
-	/*flib init */
-	if (flib_init() != 0)
-		rte_exit(EXIT_FAILURE, "flib init error");
-
-	/**
-	  * Allocated structures that slave lcore would change. For those that slaves are
-	  * read only, needn't use malloc to share and global or static variables is ok since
-	  * slave inherit all the knowledge that master initialized.
-	  **/
-	if (l2fwd_malloc_shared_struct() != 0)
-		rte_exit(EXIT_FAILURE, "malloc mem failed\n");
-
-	/* Initialize lcore_resource structures */
-	memset(lcore_resource, 0, sizeof(lcore_resource));
-	for (i = 0; i < RTE_MAX_LCORE; i++)
-		lcore_resource[i].lcore_id = i;
-
-	nb_ports = rte_eth_dev_count();
-	if (nb_ports == 0)
-		rte_exit(EXIT_FAILURE, "No Ethernet ports - bye\n");
-
-	/* create the mbuf pool */
-	RTE_ETH_FOREACH_DEV(portid) {
-		/* skip ports that are not enabled */
-		if ((l2fwd_enabled_port_mask & (1 << portid)) == 0)
-			continue;
-		char buf_name[RTE_MEMPOOL_NAMESIZE];
-		snprintf(buf_name, RTE_MEMPOOL_NAMESIZE, MBUF_NAME, portid);
-		l2fwd_pktmbuf_pool[portid] =
-			rte_pktmbuf_pool_create(buf_name, NB_MBUF, 32,
-				0, MBUF_DATA_SIZE, rte_socket_id());
-		if (l2fwd_pktmbuf_pool[portid] == NULL)
-			rte_exit(EXIT_FAILURE, "Cannot create mbuf pool\n");
-
-		printf("Create mbuf %s\n", buf_name);
-	}
-
-	/* reset l2fwd_dst_ports */
-	for (portid = 0; portid < RTE_MAX_ETHPORTS; portid++)
-		l2fwd_dst_ports[portid] = 0;
-	last_port = 0;
-
-	/*
-	 * Each logical core is assigned a dedicated TX queue on each port.
-	 */
-	RTE_ETH_FOREACH_DEV(portid) {
-		/* skip ports that are not enabled */
-		if ((l2fwd_enabled_port_mask & (1 << portid)) == 0)
-			continue;
-
-		if (nb_ports_in_mask % 2) {
-			l2fwd_dst_ports[portid] = last_port;
-			l2fwd_dst_ports[last_port] = portid;
-		}
-		else
-			last_port = portid;
-
-		nb_ports_in_mask++;
-	}
-	if (nb_ports_in_mask % 2) {
-		printf("Notice: odd number of ports in portmask.\n");
-		l2fwd_dst_ports[last_port] = last_port;
-	}
-
-	rx_lcore_id = 0;
-	qconf = NULL;
-
-	/* Initialize the port/queue configuration of each logical core */
-	RTE_ETH_FOREACH_DEV(portid) {
-		struct lcore_resource_struct *res;
-		/* skip ports that are not enabled */
-		if ((l2fwd_enabled_port_mask & (1 << portid)) == 0)
-			continue;
-
-		/* get the lcore_id for this port */
-		/* skip master lcore */
-		while (rte_lcore_is_enabled(rx_lcore_id) == 0 ||
-			   rte_get_master_lcore() == rx_lcore_id ||
-		       lcore_queue_conf[rx_lcore_id].n_rx_port ==
-		       l2fwd_rx_queue_per_lcore) {
-
-			rx_lcore_id++;
-			if (rx_lcore_id >= RTE_MAX_LCORE)
-				rte_exit(EXIT_FAILURE, "Not enough cores\n");
-		}
-
-		if (qconf != &lcore_queue_conf[rx_lcore_id])
-			/* Assigned a new logical core in the loop above. */
-			qconf = &lcore_queue_conf[rx_lcore_id];
-
-		qconf->rx_port_list[qconf->n_rx_port] = portid;
-		qconf->n_rx_port++;
-
-		/* Save the port resource info into lcore_resource strucutres */
-		res = &lcore_resource[rx_lcore_id];
-		res->enabled = 1;
-		res->port[res->port_num++] = portid;
-
-		printf("Lcore %u: RX port %u\n", rx_lcore_id, (unsigned) portid);
-	}
-
-	/* Initialise each port */
-	RTE_ETH_FOREACH_DEV(portid) {
-		struct rte_eth_rxconf rxq_conf;
-		struct rte_eth_txconf txq_conf;
-		struct rte_eth_conf local_port_conf = port_conf;
-
-		/* skip ports that are not enabled */
-		if ((l2fwd_enabled_port_mask & (1 << portid)) == 0) {
-			printf("Skipping disabled port %u\n", (unsigned) portid);
-			continue;
-		}
-		nb_ports_available++;
-		/* init port */
-		printf("Initializing port %u... ", (unsigned) portid);
-		fflush(stdout);
-		rte_eth_dev_info_get(portid, &dev_info);
-		if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-			local_port_conf.txmode.offloads |=
-				DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-		ret = rte_eth_dev_configure(portid, 1, 1, &local_port_conf);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "Cannot configure device: err=%d, port=%u\n",
-				  ret, (unsigned) portid);
-
-		ret = rte_eth_dev_adjust_nb_rx_tx_desc(portid, &nb_rxd,
-						       &nb_txd);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-				 "rte_eth_dev_adjust_nb_rx_tx_desc: err=%d, port=%u\n",
-				 ret, (unsigned) portid);
-
-		rte_eth_macaddr_get(portid,&l2fwd_ports_eth_addr[portid]);
-
-		/* init one RX queue */
-		fflush(stdout);
-		rxq_conf = dev_info.default_rxconf;
-		rxq_conf.offloads = local_port_conf.rxmode.offloads;
-		ret = rte_eth_rx_queue_setup(portid, 0, nb_rxd,
-					     rte_eth_dev_socket_id(portid),
-					     &rxq_conf,
-					     l2fwd_pktmbuf_pool[portid]);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "rte_eth_rx_queue_setup:err=%d, port=%u\n",
-				  ret, (unsigned) portid);
-
-		/* init one TX queue on each port */
-		fflush(stdout);
-		txq_conf = dev_info.default_txconf;
-		txq_conf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-		txq_conf.tx_offloads = local_port_conf.txmode.offloads;
-		ret = rte_eth_tx_queue_setup(portid, 0, nb_txd,
-				rte_eth_dev_socket_id(portid),
-				&txq_conf);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "rte_eth_tx_queue_setup:err=%d, port=%u\n",
-				ret, (unsigned) portid);
-
-		/* Initialize TX buffers */
-		tx_buffer[portid] = rte_zmalloc_socket("tx_buffer",
-				RTE_ETH_TX_BUFFER_SIZE(MAX_PKT_BURST), 0,
-				rte_eth_dev_socket_id(portid));
-		if (tx_buffer[portid] == NULL)
-			rte_exit(EXIT_FAILURE, "Cannot allocate buffer for tx on port %u\n",
-					(unsigned) portid);
-
-		rte_eth_tx_buffer_init(tx_buffer[portid], MAX_PKT_BURST);
-
-		ret = rte_eth_tx_buffer_set_err_callback(tx_buffer[portid],
-				rte_eth_tx_buffer_count_callback,
-				&port_statistics[portid].dropped);
-		if (ret < 0)
-				rte_exit(EXIT_FAILURE, "Cannot set error callback for "
-						"tx buffer on port %u\n", (unsigned) portid);
-
-		/* Start device */
-		ret = rte_eth_dev_start(portid);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "rte_eth_dev_start:err=%d, port=%u\n",
-				  ret, (unsigned) portid);
-
-		printf("done: \n");
-
-		rte_eth_promiscuous_enable(portid);
-
-		printf("Port %u, MAC address: %02X:%02X:%02X:%02X:%02X:%02X\n\n",
-				(unsigned) portid,
-				l2fwd_ports_eth_addr[portid].addr_bytes[0],
-				l2fwd_ports_eth_addr[portid].addr_bytes[1],
-				l2fwd_ports_eth_addr[portid].addr_bytes[2],
-				l2fwd_ports_eth_addr[portid].addr_bytes[3],
-				l2fwd_ports_eth_addr[portid].addr_bytes[4],
-				l2fwd_ports_eth_addr[portid].addr_bytes[5]);
-
-		/* initialize port stats */
-		//memset(&port_statistics, 0, sizeof(port_statistics));
-	}
-
-	if (!nb_ports_available) {
-		rte_exit(EXIT_FAILURE,
-			"All available ports are disabled. Please set portmask.\n");
-	}
-
-	check_all_ports_link_status(l2fwd_enabled_port_mask);
-
-	/* Record pair lcore */
-	/**
-	 * Since l2fwd example would create pair between different neighbour port, that's
-	 * port 0 receive and forward to port 1, the same to port 1, these 2 ports will have
-	 * dependency. If one port stopped working (killed, for example), the port need to
-	 * be stopped/started again. During the time, another port need to wait until stop/start
-	 * procedure completed. So, record the pair relationship for those lcores working
-	 * on ports.
-	 **/
-	RTE_ETH_FOREACH_DEV(portid) {
-		uint32_t pair_port;
-		unsigned lcore = 0, pair_lcore = 0;
-		unsigned j, find_lcore, find_pair_lcore;
-		/* skip ports that are not enabled */
-		if ((l2fwd_enabled_port_mask & (1 << portid)) == 0)
-			continue;
-
-		/* Find pair ports' lcores */
-		find_lcore = find_pair_lcore = 0;
-		pair_port = l2fwd_dst_ports[portid];
-		for (i = 0; i < RTE_MAX_LCORE; i++) {
-			if (!rte_lcore_is_enabled(i))
-				continue;
-			for (j = 0; j < lcore_queue_conf[i].n_rx_port;j++) {
-				if (lcore_queue_conf[i].rx_port_list[j] == portid) {
-					lcore = i;
-					find_lcore = 1;
-					break;
-				}
-				if (lcore_queue_conf[i].rx_port_list[j] == pair_port) {
-					pair_lcore = i;
-					find_pair_lcore = 1;
-					break;
-				}
-			}
-			if (find_lcore && find_pair_lcore)
-				break;
-		}
-		if (!find_lcore || !find_pair_lcore)
-			rte_exit(EXIT_FAILURE, "Not find port=%d pair\n", portid);
-
-		printf("lcore %u and %u paired\n", lcore, pair_lcore);
-		lcore_resource[lcore].pair_id = pair_lcore;
-		lcore_resource[pair_lcore].pair_id = lcore;
-	}
-
-	/* Create message buffer for all master and slave */
-	message_pool = rte_mempool_create("ms_msg_pool",
-			   NB_CORE_MSGBUF * RTE_MAX_LCORE,
-			   sizeof(enum l2fwd_cmd), NB_CORE_MSGBUF / 2,
-			   0, NULL, NULL, NULL, NULL, rte_socket_id(), 0);
-
-	if (message_pool == NULL)
-		rte_exit(EXIT_FAILURE, "Create msg mempool failed\n");
-
-	/* Create ring for each master and slave pair, also register cb when slave leaves */
-	for (i = 0; i < RTE_MAX_LCORE; i++) {
-		/**
-		 * Only create ring and register slave_exit cb in case that core involved into
-		 * packet forwarding
-		 **/
-		if (lcore_resource[i].enabled) {
-			/* Create ring for master and slave communication */
-			ret = create_ms_ring(i);
-			if (ret != 0)
-				rte_exit(EXIT_FAILURE, "Create ring for lcore=%u failed",
-				i);
-
-			if (flib_register_slave_exit_notify(i,
-				slave_exit_cb) != 0)
-				rte_exit(EXIT_FAILURE,
-						"Register master_trace_slave_exit failed");
-		}
-	}
-
-	/* launch per-lcore init on every lcore except master */
-	flib_mp_remote_launch(l2fwd_launch_one_lcore, NULL, SKIP_MASTER);
-
-	/* print statistics 10 second */
-	prev_tsc = cur_tsc = rte_rdtsc();
-	timer_tsc = 0;
-	while (1) {
-		sleep(1);
-		cur_tsc = rte_rdtsc();
-		diff_tsc = cur_tsc - prev_tsc;
-		/* if timer is enabled */
-		if (timer_period > 0) {
-
-			/* advance the timer */
-			timer_tsc += diff_tsc;
-
-			/* if timer has reached its timeout */
-			if (unlikely(timer_tsc >= (uint64_t) timer_period)) {
-
-				print_stats();
-				/* reset the timer */
-				timer_tsc = 0;
-			}
-		}
-
-		prev_tsc = cur_tsc;
-
-		/* Check any slave need restart or recreate */
-		rte_spinlock_lock(&res_lock);
-		for (i = 0; i < RTE_MAX_LCORE; i++) {
-			struct lcore_resource_struct *res  = &lcore_resource[i];
-			struct lcore_resource_struct *pair = &lcore_resource[res->pair_id];
-
-			/* If find slave exited, try to reset pair */
-			if (res->enabled && res->flags && pair->enabled) {
-				if (!pair->flags) {
-					master_sendcmd_with_ack(pair->lcore_id, CMD_STOP);
-					rte_spinlock_unlock(&res_lock);
-					sleep(1);
-					rte_spinlock_lock(&res_lock);
-					if (pair->flags)
-						continue;
-				}
-				if (reset_pair(res->lcore_id, pair->lcore_id) != 0)
-					rte_exit(EXIT_FAILURE, "failed to reset slave");
-				res->flags  = 0;
-				pair->flags = 0;
-			}
-		}
-		rte_spinlock_unlock(&res_lock);
-	}
-
-}
diff --git a/examples/multi_process/simple_mp/Makefile b/examples/multi_process/simple_mp/Makefile
deleted file mode 100644
index fba9c86..0000000
--- a/examples/multi_process/simple_mp/Makefile
+++ /dev/null
@@ -1,22 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-# binary name
-APP = simple_mp
-
-# all source are stored in SRCS-y
-SRCS-y := main.c mp_commands.c
-
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-
-include $(RTE_SDK)/mk/rte.extapp.mk
diff --git a/examples/multi_process/simple_mp/main.c b/examples/multi_process/simple_mp/main.c
deleted file mode 100644
index e6c69d6..0000000
--- a/examples/multi_process/simple_mp/main.c
+++ /dev/null
@@ -1,125 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-/*
- * This sample application is a simple multi-process application which
- * demostrates sharing of queues and memory pools between processes, and
- * using those queues/pools for communication between the processes.
- *
- * Application is designed to run with two processes, a primary and a
- * secondary, and each accepts commands on the commandline, the most
- * important of which is "send", which just sends a string to the other
- * process.
- */
-
-#include <stdio.h>
-#include <string.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <stdarg.h>
-#include <errno.h>
-#include <unistd.h>
-#include <termios.h>
-#include <sys/queue.h>
-
-#include <rte_common.h>
-#include <rte_memory.h>
-#include <rte_launch.h>
-#include <rte_eal.h>
-#include <rte_per_lcore.h>
-#include <rte_lcore.h>
-#include <rte_debug.h>
-#include <rte_atomic.h>
-#include <rte_branch_prediction.h>
-#include <rte_ring.h>
-#include <rte_log.h>
-#include <rte_mempool.h>
-#include <cmdline_rdline.h>
-#include <cmdline_parse.h>
-#include <cmdline_parse_string.h>
-#include <cmdline_socket.h>
-#include <cmdline.h>
-#include "mp_commands.h"
-
-#define RTE_LOGTYPE_APP RTE_LOGTYPE_USER1
-
-static const char *_MSG_POOL = "MSG_POOL";
-static const char *_SEC_2_PRI = "SEC_2_PRI";
-static const char *_PRI_2_SEC = "PRI_2_SEC";
-
-struct rte_ring *send_ring, *recv_ring;
-struct rte_mempool *message_pool;
-volatile int quit = 0;
-
-static int
-lcore_recv(__attribute__((unused)) void *arg)
-{
-	unsigned lcore_id = rte_lcore_id();
-
-	printf("Starting core %u\n", lcore_id);
-	while (!quit){
-		void *msg;
-		if (rte_ring_dequeue(recv_ring, &msg) < 0){
-			usleep(5);
-			continue;
-		}
-		printf("core %u: Received '%s'\n", lcore_id, (char *)msg);
-		rte_mempool_put(message_pool, msg);
-	}
-
-	return 0;
-}
-
-int
-main(int argc, char **argv)
-{
-	const unsigned flags = 0;
-	const unsigned ring_size = 64;
-	const unsigned pool_size = 1024;
-	const unsigned pool_cache = 32;
-	const unsigned priv_data_sz = 0;
-
-	int ret;
-	unsigned lcore_id;
-
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Cannot init EAL\n");
-
-	if (rte_eal_process_type() == RTE_PROC_PRIMARY){
-		send_ring = rte_ring_create(_PRI_2_SEC, ring_size, rte_socket_id(), flags);
-		recv_ring = rte_ring_create(_SEC_2_PRI, ring_size, rte_socket_id(), flags);
-		message_pool = rte_mempool_create(_MSG_POOL, pool_size,
-				STR_TOKEN_SIZE, pool_cache, priv_data_sz,
-				NULL, NULL, NULL, NULL,
-				rte_socket_id(), flags);
-	} else {
-		recv_ring = rte_ring_lookup(_PRI_2_SEC);
-		send_ring = rte_ring_lookup(_SEC_2_PRI);
-		message_pool = rte_mempool_lookup(_MSG_POOL);
-	}
-	if (send_ring == NULL)
-		rte_exit(EXIT_FAILURE, "Problem getting sending ring\n");
-	if (recv_ring == NULL)
-		rte_exit(EXIT_FAILURE, "Problem getting receiving ring\n");
-	if (message_pool == NULL)
-		rte_exit(EXIT_FAILURE, "Problem getting message pool\n");
-
-	RTE_LOG(INFO, APP, "Finished Process Init.\n");
-
-	/* call lcore_recv() on every slave lcore */
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		rte_eal_remote_launch(lcore_recv, NULL, lcore_id);
-	}
-
-	/* call cmd prompt on master lcore */
-	struct cmdline *cl = cmdline_stdin_new(simple_mp_ctx, "\nsimple_mp > ");
-	if (cl == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot create cmdline instance\n");
-	cmdline_interact(cl);
-	cmdline_stdin_exit(cl);
-
-	rte_eal_mp_wait_lcore();
-	return 0;
-}
diff --git a/examples/multi_process/simple_mp/mp_commands.c b/examples/multi_process/simple_mp/mp_commands.c
deleted file mode 100644
index e4df6ff..0000000
--- a/examples/multi_process/simple_mp/mp_commands.c
+++ /dev/null
@@ -1,136 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-#include <stdint.h>
-#include <string.h>
-#include <stdlib.h>
-#include <stdarg.h>
-#include <inttypes.h>
-#include <stdio.h>
-#include <termios.h>
-#include <errno.h>
-#include <sys/queue.h>
-
-#include <rte_common.h>
-#include <rte_memory.h>
-#include <rte_eal.h>
-#include <rte_atomic.h>
-#include <rte_branch_prediction.h>
-#include <rte_launch.h>
-#include <rte_log.h>
-#include <rte_per_lcore.h>
-#include <rte_lcore.h>
-#include <rte_ring.h>
-#include <rte_debug.h>
-#include <rte_mempool.h>
-#include <rte_string_fns.h>
-
-#include <cmdline_rdline.h>
-#include <cmdline_parse.h>
-#include <cmdline_parse_string.h>
-#include <cmdline_socket.h>
-#include <cmdline.h>
-#include "mp_commands.h"
-
-/**********************************************************/
-
-struct cmd_send_result {
-	cmdline_fixed_string_t action;
-	cmdline_fixed_string_t message;
-};
-
-static void cmd_send_parsed(void *parsed_result,
-		__attribute__((unused)) struct cmdline *cl,
-		__attribute__((unused)) void *data)
-{
-	void *msg = NULL;
-	struct cmd_send_result *res = parsed_result;
-
-	if (rte_mempool_get(message_pool, &msg) < 0)
-		rte_panic("Failed to get message buffer\n");
-	snprintf((char *)msg, STR_TOKEN_SIZE, "%s", res->message);
-	if (rte_ring_enqueue(send_ring, msg) < 0) {
-		printf("Failed to send message - message discarded\n");
-		rte_mempool_put(message_pool, msg);
-	}
-}
-
-cmdline_parse_token_string_t cmd_send_action =
-	TOKEN_STRING_INITIALIZER(struct cmd_send_result, action, "send");
-cmdline_parse_token_string_t cmd_send_message =
-	TOKEN_STRING_INITIALIZER(struct cmd_send_result, message, NULL);
-
-cmdline_parse_inst_t cmd_send = {
-	.f = cmd_send_parsed,  /* function to call */
-	.data = NULL,      /* 2nd arg of func */
-	.help_str = "send a string to another process",
-	.tokens = {        /* token list, NULL terminated */
-			(void *)&cmd_send_action,
-			(void *)&cmd_send_message,
-			NULL,
-	},
-};
-
-/**********************************************************/
-
-struct cmd_quit_result {
-	cmdline_fixed_string_t quit;
-};
-
-static void cmd_quit_parsed(__attribute__((unused)) void *parsed_result,
-			    struct cmdline *cl,
-			    __attribute__((unused)) void *data)
-{
-	quit = 1;
-	cmdline_quit(cl);
-}
-
-cmdline_parse_token_string_t cmd_quit_quit =
-	TOKEN_STRING_INITIALIZER(struct cmd_quit_result, quit, "quit");
-
-cmdline_parse_inst_t cmd_quit = {
-	.f = cmd_quit_parsed,  /* function to call */
-	.data = NULL,      /* 2nd arg of func */
-	.help_str = "close the application",
-	.tokens = {        /* token list, NULL terminated */
-		(void *)&cmd_quit_quit,
-		NULL,
-	},
-};
-
-/**********************************************************/
-
-struct cmd_help_result {
-	cmdline_fixed_string_t help;
-};
-
-static void cmd_help_parsed(__attribute__((unused)) void *parsed_result,
-			    struct cmdline *cl,
-			    __attribute__((unused)) void *data)
-{
-	cmdline_printf(cl, "Simple demo example of multi-process in RTE\n\n"
-			"This is a readline-like interface that can be used to\n"
-			"send commands to the simple app. Commands supported are:\n\n"
-			"- send [string]\n" "- help\n" "- quit\n\n");
-}
-
-cmdline_parse_token_string_t cmd_help_help =
-	TOKEN_STRING_INITIALIZER(struct cmd_help_result, help, "help");
-
-cmdline_parse_inst_t cmd_help = {
-	.f = cmd_help_parsed,  /* function to call */
-	.data = NULL,      /* 2nd arg of func */
-	.help_str = "show help",
-	.tokens = {        /* token list, NULL terminated */
-		(void *)&cmd_help_help,
-		NULL,
-	},
-};
-
-/****** CONTEXT (list of instruction) */
-cmdline_parse_ctx_t simple_mp_ctx[] = {
-		(cmdline_parse_inst_t *)&cmd_send,
-		(cmdline_parse_inst_t *)&cmd_quit,
-		(cmdline_parse_inst_t *)&cmd_help,
-	NULL,
-};
diff --git a/examples/multi_process/simple_mp/mp_commands.h b/examples/multi_process/simple_mp/mp_commands.h
deleted file mode 100644
index 5d67413..0000000
--- a/examples/multi_process/simple_mp/mp_commands.h
+++ /dev/null
@@ -1,14 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#ifndef _SIMPLE_MP_COMMANDS_H_
-#define _SIMPLE_MP_COMMANDS_H_
-
-extern struct rte_ring *send_ring;
-extern struct rte_mempool *message_pool;
-extern volatile int quit;
-
-extern cmdline_parse_ctx_t simple_mp_ctx[];
-
-#endif /* _SIMPLE_MP_COMMANDS_H_ */
diff --git a/examples/multi_process/symmetric_mp/Makefile b/examples/multi_process/symmetric_mp/Makefile
deleted file mode 100644
index 6c0fcb5..0000000
--- a/examples/multi_process/symmetric_mp/Makefile
+++ /dev/null
@@ -1,23 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-# binary name
-APP = symmetric_mp
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-
-include $(RTE_SDK)/mk/rte.extapp.mk
diff --git a/examples/multi_process/symmetric_mp/main.c b/examples/multi_process/symmetric_mp/main.c
deleted file mode 100644
index 75cad0c..0000000
--- a/examples/multi_process/symmetric_mp/main.c
+++ /dev/null
@@ -1,454 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-/*
- * Sample application demostrating how to do packet I/O in a multi-process
- * environment. The same code can be run as a primary process and as a
- * secondary process, just with a different proc-id parameter in each case
- * (apart from the EAL flag to indicate a secondary process).
- *
- * Each process will read from the same ports, given by the port-mask
- * parameter, which should be the same in each case, just using a different
- * queue per port as determined by the proc-id parameter.
- */
-
-#include <stdio.h>
-#include <string.h>
-#include <stdint.h>
-#include <stdlib.h>
-#include <stdarg.h>
-#include <errno.h>
-#include <sys/queue.h>
-#include <getopt.h>
-#include <signal.h>
-#include <inttypes.h>
-
-#include <rte_common.h>
-#include <rte_log.h>
-#include <rte_memory.h>
-#include <rte_launch.h>
-#include <rte_eal.h>
-#include <rte_per_lcore.h>
-#include <rte_lcore.h>
-#include <rte_atomic.h>
-#include <rte_branch_prediction.h>
-#include <rte_debug.h>
-#include <rte_interrupts.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_mempool.h>
-#include <rte_memcpy.h>
-#include <rte_mbuf.h>
-#include <rte_string_fns.h>
-#include <rte_cycles.h>
-
-#define RTE_LOGTYPE_APP RTE_LOGTYPE_USER1
-
-#define NB_MBUFS 64*1024 /* use 64k mbufs */
-#define MBUF_CACHE_SIZE 256
-#define PKT_BURST 32
-#define RX_RING_SIZE 1024
-#define TX_RING_SIZE 1024
-
-#define PARAM_PROC_ID "proc-id"
-#define PARAM_NUM_PROCS "num-procs"
-
-/* for each lcore, record the elements of the ports array to use */
-struct lcore_ports{
-	unsigned start_port;
-	unsigned num_ports;
-};
-
-/* structure to record the rx and tx packets. Put two per cache line as ports
- * used in pairs */
-struct port_stats{
-	unsigned rx;
-	unsigned tx;
-	unsigned drop;
-} __attribute__((aligned(RTE_CACHE_LINE_SIZE / 2)));
-
-static int proc_id = -1;
-static unsigned num_procs = 0;
-
-static uint16_t ports[RTE_MAX_ETHPORTS];
-static unsigned num_ports = 0;
-
-static struct lcore_ports lcore_ports[RTE_MAX_LCORE];
-static struct port_stats pstats[RTE_MAX_ETHPORTS];
-
-/* prints the usage statement and quits with an error message */
-static void
-smp_usage(const char *prgname, const char *errmsg)
-{
-	printf("\nError: %s\n",errmsg);
-	printf("\n%s [EAL options] -- -p <port mask> "
-			"--"PARAM_NUM_PROCS" <n>"
-			" --"PARAM_PROC_ID" <id>\n"
-			"-p         : a hex bitmask indicating what ports are to be used\n"
-			"--num-procs: the number of processes which will be used\n"
-			"--proc-id  : the id of the current process (id < num-procs)\n"
-			"\n",
-			prgname);
-	exit(1);
-}
-
-
-/* signal handler configured for SIGTERM and SIGINT to print stats on exit */
-static void
-print_stats(int signum)
-{
-	unsigned i;
-	printf("\nExiting on signal %d\n\n", signum);
-	for (i = 0; i < num_ports; i++){
-		const uint8_t p_num = ports[i];
-		printf("Port %u: RX - %u, TX - %u, Drop - %u\n", (unsigned)p_num,
-				pstats[p_num].rx, pstats[p_num].tx, pstats[p_num].drop);
-	}
-	exit(0);
-}
-
-/* Parse the argument given in the command line of the application */
-static int
-smp_parse_args(int argc, char **argv)
-{
-	int opt, ret;
-	char **argvopt;
-	int option_index;
-	uint16_t i, port_mask = 0;
-	char *prgname = argv[0];
-	static struct option lgopts[] = {
-			{PARAM_NUM_PROCS, 1, 0, 0},
-			{PARAM_PROC_ID, 1, 0, 0},
-			{NULL, 0, 0, 0}
-	};
-
-	argvopt = argv;
-
-	while ((opt = getopt_long(argc, argvopt, "p:", \
-			lgopts, &option_index)) != EOF) {
-
-		switch (opt) {
-		case 'p':
-			port_mask = strtoull(optarg, NULL, 16);
-			break;
-			/* long options */
-		case 0:
-			if (strncmp(lgopts[option_index].name, PARAM_NUM_PROCS, 8) == 0)
-				num_procs = atoi(optarg);
-			else if (strncmp(lgopts[option_index].name, PARAM_PROC_ID, 7) == 0)
-				proc_id = atoi(optarg);
-			break;
-
-		default:
-			smp_usage(prgname, "Cannot parse all command-line arguments\n");
-		}
-	}
-
-	if (optind >= 0)
-		argv[optind-1] = prgname;
-
-	if (proc_id < 0)
-		smp_usage(prgname, "Invalid or missing proc-id parameter\n");
-	if (rte_eal_process_type() == RTE_PROC_PRIMARY && num_procs == 0)
-		smp_usage(prgname, "Invalid or missing num-procs parameter\n");
-	if (port_mask == 0)
-		smp_usage(prgname, "Invalid or missing port mask\n");
-
-	/* get the port numbers from the port mask */
-	RTE_ETH_FOREACH_DEV(i)
-		if(port_mask & (1 << i))
-			ports[num_ports++] = (uint8_t)i;
-
-	ret = optind-1;
-	optind = 1; /* reset getopt lib */
-
-	return ret;
-}
-
-/*
- * Initialises a given port using global settings and with the rx buffers
- * coming from the mbuf_pool passed as parameter
- */
-static inline int
-smp_port_init(uint16_t port, struct rte_mempool *mbuf_pool,
-	       uint16_t num_queues)
-{
-	struct rte_eth_conf port_conf = {
-			.rxmode = {
-				.mq_mode	= ETH_MQ_RX_RSS,
-				.split_hdr_size = 0,
-				.ignore_offload_bitfield = 1,
-				.offloads = (DEV_RX_OFFLOAD_CHECKSUM |
-					     DEV_RX_OFFLOAD_CRC_STRIP),
-			},
-			.rx_adv_conf = {
-				.rss_conf = {
-					.rss_key = NULL,
-					.rss_hf = ETH_RSS_IP,
-				},
-			},
-			.txmode = {
-				.mq_mode = ETH_MQ_TX_NONE,
-			}
-	};
-	const uint16_t rx_rings = num_queues, tx_rings = num_queues;
-	struct rte_eth_dev_info info;
-	struct rte_eth_rxconf rxq_conf;
-	struct rte_eth_txconf txq_conf;
-	int retval;
-	uint16_t q;
-	uint16_t nb_rxd = RX_RING_SIZE;
-	uint16_t nb_txd = TX_RING_SIZE;
-
-	if (rte_eal_process_type() == RTE_PROC_SECONDARY)
-		return 0;
-
-	if (!rte_eth_dev_is_valid_port(port))
-		return -1;
-
-	printf("# Initialising port %u... ", port);
-	fflush(stdout);
-
-	rte_eth_dev_info_get(port, &info);
-	info.default_rxconf.rx_drop_en = 1;
-
-	if (info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-		port_conf.txmode.offloads |=
-			DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-	retval = rte_eth_dev_configure(port, rx_rings, tx_rings, &port_conf);
-	if (retval < 0)
-		return retval;
-
-	retval = rte_eth_dev_adjust_nb_rx_tx_desc(port, &nb_rxd, &nb_txd);
-	if (retval < 0)
-		return retval;
-
-	rxq_conf = info.default_rxconf;
-	rxq_conf.offloads = port_conf.rxmode.offloads;
-	for (q = 0; q < rx_rings; q ++) {
-		retval = rte_eth_rx_queue_setup(port, q, nb_rxd,
-				rte_eth_dev_socket_id(port),
-				&rxq_conf,
-				mbuf_pool);
-		if (retval < 0)
-			return retval;
-	}
-
-	txq_conf = info.default_txconf;
-	txq_conf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-	txq_conf.offloads = port_conf.txmode.offloads;
-	for (q = 0; q < tx_rings; q ++) {
-		retval = rte_eth_tx_queue_setup(port, q, nb_txd,
-				rte_eth_dev_socket_id(port),
-				&txq_conf);
-		if (retval < 0)
-			return retval;
-	}
-
-	rte_eth_promiscuous_enable(port);
-
-	retval  = rte_eth_dev_start(port);
-	if (retval < 0)
-		return retval;
-
-	return 0;
-}
-
-/* Goes through each of the lcores and calculates what ports should
- * be used by that core. Fills in the global lcore_ports[] array.
- */
-static void
-assign_ports_to_cores(void)
-{
-
-	const unsigned lcores = rte_eal_get_configuration()->lcore_count;
-	const unsigned port_pairs = num_ports / 2;
-	const unsigned pairs_per_lcore = port_pairs / lcores;
-	unsigned extra_pairs = port_pairs % lcores;
-	unsigned ports_assigned = 0;
-	unsigned i;
-
-	RTE_LCORE_FOREACH(i) {
-		lcore_ports[i].start_port = ports_assigned;
-		lcore_ports[i].num_ports = pairs_per_lcore * 2;
-		if (extra_pairs > 0) {
-			lcore_ports[i].num_ports += 2;
-			extra_pairs--;
-		}
-		ports_assigned += lcore_ports[i].num_ports;
-	}
-}
-
-/* Main function used by the processing threads.
- * Prints out some configuration details for the thread and then begins
- * performing packet RX and TX.
- */
-static int
-lcore_main(void *arg __rte_unused)
-{
-	const unsigned id = rte_lcore_id();
-	const unsigned start_port = lcore_ports[id].start_port;
-	const unsigned end_port = start_port + lcore_ports[id].num_ports;
-	const uint16_t q_id = (uint16_t)proc_id;
-	unsigned p, i;
-	char msgbuf[256];
-	int msgbufpos = 0;
-
-	if (start_port == end_port){
-		printf("Lcore %u has nothing to do\n", id);
-		return 0;
-	}
-
-	/* build up message in msgbuf before printing to decrease likelihood
-	 * of multi-core message interleaving.
-	 */
-	msgbufpos += snprintf(msgbuf, sizeof(msgbuf) - msgbufpos,
-			"Lcore %u using ports ", id);
-	for (p = start_port; p < end_port; p++){
-		msgbufpos += snprintf(msgbuf + msgbufpos, sizeof(msgbuf) - msgbufpos,
-				"%u ", (unsigned)ports[p]);
-	}
-	printf("%s\n", msgbuf);
-	printf("lcore %u using queue %u of each port\n", id, (unsigned)q_id);
-
-	/* handle packet I/O from the ports, reading and writing to the
-	 * queue number corresponding to our process number (not lcore id)
-	 */
-
-	for (;;) {
-		struct rte_mbuf *buf[PKT_BURST];
-
-		for (p = start_port; p < end_port; p++) {
-			const uint8_t src = ports[p];
-			const uint8_t dst = ports[p ^ 1]; /* 0 <-> 1, 2 <-> 3 etc */
-			const uint16_t rx_c = rte_eth_rx_burst(src, q_id, buf, PKT_BURST);
-			if (rx_c == 0)
-				continue;
-			pstats[src].rx += rx_c;
-
-			const uint16_t tx_c = rte_eth_tx_burst(dst, q_id, buf, rx_c);
-			pstats[dst].tx += tx_c;
-			if (tx_c != rx_c) {
-				pstats[dst].drop += (rx_c - tx_c);
-				for (i = tx_c; i < rx_c; i++)
-					rte_pktmbuf_free(buf[i]);
-			}
-		}
-	}
-}
-
-/* Check the link status of all ports in up to 9s, and print them finally */
-static void
-check_all_ports_link_status(uint16_t port_num, uint32_t port_mask)
-{
-#define CHECK_INTERVAL 100 /* 100ms */
-#define MAX_CHECK_TIME 90 /* 9s (90 * 100ms) in total */
-	uint16_t portid;
-	uint8_t count, all_ports_up, print_flag = 0;
-	struct rte_eth_link link;
-
-	printf("\nChecking link status");
-	fflush(stdout);
-	for (count = 0; count <= MAX_CHECK_TIME; count++) {
-		all_ports_up = 1;
-		for (portid = 0; portid < port_num; portid++) {
-			if ((port_mask & (1 << portid)) == 0)
-				continue;
-			memset(&link, 0, sizeof(link));
-			rte_eth_link_get_nowait(portid, &link);
-			/* print link status if flag set */
-			if (print_flag == 1) {
-				if (link.link_status)
-					printf(
-					"Port%d Link Up. Speed %u Mbps - %s\n",
-						portid, link.link_speed,
-				(link.link_duplex == ETH_LINK_FULL_DUPLEX) ?
-					("full-duplex") : ("half-duplex\n"));
-				else
-					printf("Port %d Link Down\n", portid);
-				continue;
-			}
-			/* clear all_ports_up flag if any link down */
-			if (link.link_status == ETH_LINK_DOWN) {
-				all_ports_up = 0;
-				break;
-			}
-		}
-		/* after finally printing all link status, get out */
-		if (print_flag == 1)
-			break;
-
-		if (all_ports_up == 0) {
-			printf(".");
-			fflush(stdout);
-			rte_delay_ms(CHECK_INTERVAL);
-		}
-
-		/* set the print_flag if all ports up or timeout */
-		if (all_ports_up == 1 || count == (MAX_CHECK_TIME - 1)) {
-			print_flag = 1;
-			printf("done\n");
-		}
-	}
-}
-
-/* Main function.
- * Performs initialisation and then calls the lcore_main on each core
- * to do the packet-processing work.
- */
-int
-main(int argc, char **argv)
-{
-	static const char *_SMP_MBUF_POOL = "SMP_MBUF_POOL";
-	int ret;
-	unsigned i;
-	enum rte_proc_type_t proc_type;
-	struct rte_mempool *mp;
-
-	/* set up signal handlers to print stats on exit */
-	signal(SIGINT, print_stats);
-	signal(SIGTERM, print_stats);
-
-	/* initialise the EAL for all */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Cannot init EAL\n");
-	argc -= ret;
-	argv += ret;
-
-	/* determine the NIC devices available */
-	if (rte_eth_dev_count() == 0)
-		rte_exit(EXIT_FAILURE, "No Ethernet ports - bye\n");
-
-	/* parse application arguments (those after the EAL ones) */
-	smp_parse_args(argc, argv);
-
-	proc_type = rte_eal_process_type();
-	mp = (proc_type == RTE_PROC_SECONDARY) ?
-			rte_mempool_lookup(_SMP_MBUF_POOL) :
-			rte_pktmbuf_pool_create(_SMP_MBUF_POOL, NB_MBUFS,
-				MBUF_CACHE_SIZE, 0, RTE_MBUF_DEFAULT_BUF_SIZE,
-				rte_socket_id());
-	if (mp == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot get memory pool for buffers\n");
-
-	if (num_ports & 1)
-		rte_exit(EXIT_FAILURE, "Application must use an even number of ports\n");
-	for(i = 0; i < num_ports; i++){
-		if(proc_type == RTE_PROC_PRIMARY)
-			if (smp_port_init(ports[i], mp, (uint16_t)num_procs) < 0)
-				rte_exit(EXIT_FAILURE, "Error initialising ports\n");
-	}
-
-	if (proc_type == RTE_PROC_PRIMARY)
-		check_all_ports_link_status((uint8_t)num_ports, (~0x0));
-
-	assign_ports_to_cores();
-
-	RTE_LOG(INFO, APP, "Finished Process Init.\n");
-
-	rte_eal_mp_remote_launch(lcore_main, NULL, CALL_MASTER);
-
-	return 0;
-}
diff --git a/examples/netmap_compat/Makefile b/examples/netmap_compat/Makefile
deleted file mode 100644
index dd87ac9..0000000
--- a/examples/netmap_compat/Makefile
+++ /dev/null
@@ -1,22 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-unexport RTE_SRCDIR RTE_OUTPUT RTE_EXTMK
-
-DIRS-y += bridge
-
-.PHONY: all clean $(DIRS-y)
-
-all: $(DIRS-y)
-clean: $(DIRS-y)
-
-$(DIRS-y):
-	$(MAKE) -C $@ $(MAKECMDGOALS) O=$(RTE_OUTPUT)
diff --git a/examples/netmap_compat/bridge/Makefile b/examples/netmap_compat/bridge/Makefile
deleted file mode 100644
index a7c9c14..0000000
--- a/examples/netmap_compat/bridge/Makefile
+++ /dev/null
@@ -1,35 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-ifeq ($(RTE_SDK),)
-$(error "Please define the RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-ifneq ($(CONFIG_RTE_EXEC_ENV),"linuxapp")
-$(info This application can only operate in a linuxapp environment, \
-please change the definition of the RTE_TARGET environment variable)
-all:
-clean:
-else
-
-# binary name
-APP = bridge
-
-# for compat_netmap.c
-VPATH := $(SRCDIR)/../lib
-
-# all source are stored in SRCS-y
-SRCS-y := bridge.c
-SRCS-y += compat_netmap.c
-
-CFLAGS += -O3 -I$(SRCDIR)/../lib -I$(SRCDIR)/../netmap
-CFLAGS += $(WERROR_FLAGS)
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-
-endif
diff --git a/examples/netmap_compat/bridge/bridge.c b/examples/netmap_compat/bridge/bridge.c
deleted file mode 100644
index 59c5e43..0000000
--- a/examples/netmap_compat/bridge/bridge.c
+++ /dev/null
@@ -1,345 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <fcntl.h>
-#include <getopt.h>
-#include <inttypes.h>
-#include <signal.h>
-#include <stdio.h>
-#include <stdlib.h>
-#include <sys/mman.h>
-
-#include <rte_eal.h>
-#include <rte_ethdev.h>
-#include <rte_mbuf.h>
-#include <rte_mempool.h>
-#include <rte_string_fns.h>
-#include "compat_netmap.h"
-
-
-#define BUF_SIZE	RTE_MBUF_DEFAULT_DATAROOM
-#define MBUF_DATA_SIZE	(BUF_SIZE + RTE_PKTMBUF_HEADROOM)
-
-#define MBUF_PER_POOL	8192
-
-struct rte_eth_conf eth_conf = {
-	.rxmode = {
-		.split_hdr_size = 0,
-		.ignore_offload_bitfield = 1,
-		.offloads = DEV_RX_OFFLOAD_CRC_STRIP,
-	},
-	.txmode = {
-		.mq_mode = ETH_MQ_TX_NONE,
-	},
-};
-
-#define	MAX_QUEUE_NUM	1
-#define	RX_QUEUE_NUM	1
-#define	TX_QUEUE_NUM	1
-
-#define	MAX_DESC_NUM	0x400
-#define	RX_DESC_NUM	0x100
-#define	TX_DESC_NUM	0x200
-
-#define	RX_SYNC_NUM	0x20
-#define	TX_SYNC_NUM	0x20
-
-struct rte_netmap_port_conf port_conf = {
-	.eth_conf = &eth_conf,
-	.socket_id = SOCKET_ID_ANY,
-	.nr_tx_rings = TX_QUEUE_NUM,
-	.nr_rx_rings = RX_QUEUE_NUM,
-	.nr_tx_slots = TX_DESC_NUM,
-	.nr_rx_slots = RX_DESC_NUM,
-	.tx_burst = TX_SYNC_NUM,
-	.rx_burst = RX_SYNC_NUM,
-};
-
-struct rte_netmap_conf netmap_conf = {
-	.socket_id = SOCKET_ID_ANY,
-	.max_bufsz = BUF_SIZE,
-	.max_rings = MAX_QUEUE_NUM,
-	.max_slots = MAX_DESC_NUM,
-};
-
-static int stop = 0;
-
-#define	MAX_PORT_NUM	2
-
-struct netmap_port {
-	int fd;
-	struct netmap_if *nmif;
-	struct netmap_ring *rx_ring;
-	struct netmap_ring *tx_ring;
-	const char *str;
-	uint8_t id;
-};
-
-static struct {
-	uint32_t num;
-	struct netmap_port p[MAX_PORT_NUM];
-	void *mem;
-} ports;
-
-static void
-usage(const char *prgname)
-{
-	fprintf(stderr, "Usage: %s [EAL args] -- [OPTION]...\n"
-		"-h, --help   \t Show this help message and exit\n"
-		"-i INTERFACE_A   \t Interface (DPDK port number) to use\n"
-		"[ -i INTERFACE_B   \t Interface (DPDK port number) to use ]\n",
-		prgname);
-}
-
-static uint8_t
-parse_portid(const char *portid_str)
-{
-	char *end;
-	unsigned id;
-
-	id = strtoul(portid_str, &end, 10);
-
-	if (end == portid_str || *end != '\0' || id > RTE_MAX_ETHPORTS)
-		rte_exit(EXIT_FAILURE, "Invalid port number\n");
-
-	return (uint8_t) id;
-}
-
-static int
-parse_args(int argc, char **argv)
-{
-	int opt;
-
-	while ((opt = getopt(argc, argv, "hi:")) != -1) {
-		switch (opt) {
-		case 'h':
-			usage(argv[0]);
-			rte_exit(EXIT_SUCCESS, "exiting...");
-			break;
-		case 'i':
-			if (ports.num >= RTE_DIM(ports.p)) {
-				usage(argv[0]);
-				rte_exit(EXIT_FAILURE, "configs with %u "
-					"ports are not supported\n",
-					ports.num + 1);
-
-			}
-
-			ports.p[ports.num].str = optarg;
-			ports.p[ports.num].id = parse_portid(optarg);
-			ports.num++;
-			break;
-		default:
-			usage(argv[0]);
-			rte_exit(EXIT_FAILURE, "invalid option: %c\n", opt);
-		}
-	}
-
-	return 0;
-}
-
-static void sigint_handler(__rte_unused int sig)
-{
-	stop = 1;
-	signal(SIGINT, SIG_DFL);
-}
-
-static void move(int n, struct netmap_ring *rx, struct netmap_ring *tx)
-{
-	uint32_t tmp;
-
-	while (n-- > 0) {
-		tmp = tx->slot[tx->cur].buf_idx;
-
-		tx->slot[tx->cur].buf_idx = rx->slot[rx->cur].buf_idx;
-		tx->slot[tx->cur].len     = rx->slot[rx->cur].len;
-		tx->slot[tx->cur].flags  |= NS_BUF_CHANGED;
-		tx->cur = NETMAP_RING_NEXT(tx, tx->cur);
-		tx->avail--;
-
-		rx->slot[rx->cur].buf_idx = tmp;
-		rx->slot[rx->cur].flags  |= NS_BUF_CHANGED;
-		rx->cur = NETMAP_RING_NEXT(rx, rx->cur);
-		rx->avail--;
-	}
-}
-
-static int
-netmap_port_open(uint32_t idx)
-{
-	int err;
-	struct netmap_port *port;
-	struct nmreq req;
-
-	port = ports.p + idx;
-
-	port->fd = rte_netmap_open("/dev/netmap", O_RDWR);
-
-	snprintf(req.nr_name, sizeof(req.nr_name), "%s", port->str);
-	req.nr_version = NETMAP_API;
-	req.nr_ringid = 0;
-
-	err = rte_netmap_ioctl(port->fd, NIOCGINFO, &req);
-	if (err) {
-		printf("[E] NIOCGINFO ioctl failed (error %d)\n", err);
-		return err;
-	}
-
-	snprintf(req.nr_name, sizeof(req.nr_name), "%s", port->str);
-	req.nr_version = NETMAP_API;
-	req.nr_ringid = 0;
-
-	err = rte_netmap_ioctl(port->fd, NIOCREGIF, &req);
-	if (err) {
-		printf("[E] NIOCREGIF ioctl failed (error %d)\n", err);
-		return err;
-	}
-
-	/* mmap only once. */
-	if (ports.mem == NULL)
-		ports.mem = rte_netmap_mmap(NULL, req.nr_memsize,
-			PROT_WRITE | PROT_READ, MAP_PRIVATE, port->fd, 0);
-
-	if (ports.mem == MAP_FAILED) {
-		printf("[E] NETMAP mmap failed for fd: %d)\n", port->fd);
-		return -ENOMEM;
-	}
-
-	port->nmif = NETMAP_IF(ports.mem, req.nr_offset);
-
-	port->tx_ring = NETMAP_TXRING(port->nmif, 0);
-	port->rx_ring = NETMAP_RXRING(port->nmif, 0);
-
-	return 0;
-}
-
-
-int main(int argc, char *argv[])
-{
-	int err, ret;
-	uint32_t i, pmsk;
-	struct nmreq req;
-	struct pollfd pollfd[MAX_PORT_NUM];
-	struct rte_mempool *pool;
-	struct netmap_ring *rx_ring, *tx_ring;
-
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Cannot initialize EAL\n");
-
-	argc -= ret;
-	argv += ret;
-
-	parse_args(argc, argv);
-
-	if (ports.num == 0)
-		rte_exit(EXIT_FAILURE, "no ports specified\n");
-
-	if (rte_eth_dev_count() < 1)
-		rte_exit(EXIT_FAILURE, "Not enough ethernet ports available\n");
-
-	pool = rte_pktmbuf_pool_create("mbuf_pool", MBUF_PER_POOL, 32, 0,
-		MBUF_DATA_SIZE, rte_socket_id());
-	if (pool == NULL)
-		rte_exit(EXIT_FAILURE, "Couldn't create mempool\n");
-
-	netmap_conf.socket_id = rte_socket_id();
-	err = rte_netmap_init(&netmap_conf);
-
-	if (err < 0)
-		rte_exit(EXIT_FAILURE,
-			"Couldn't initialize librte_compat_netmap\n");
-	else
-		printf("librte_compat_netmap initialized\n");
-
-	port_conf.pool = pool;
-	port_conf.socket_id = rte_socket_id();
-
-	for (i = 0; i != ports.num; i++) {
-
-		err = rte_netmap_init_port(ports.p[i].id, &port_conf);
-		if (err < 0)
-			rte_exit(EXIT_FAILURE, "Couldn't setup port %hhu\n",
-				ports.p[i].id);
-
-		rte_eth_promiscuous_enable(ports.p[i].id);
-	}
-
-	for (i = 0; i != ports.num; i++) {
-
-		err = netmap_port_open(i);
-		if (err) {
-			rte_exit(EXIT_FAILURE, "Couldn't set port %hhu "
-				"under NETMAP control\n",
-				ports.p[i].id);
-		}
-		else
-			printf("Port %hhu now in Netmap mode\n", ports.p[i].id);
-	}
-
-	memset(pollfd, 0, sizeof(pollfd));
-
-	for (i = 0; i != ports.num; i++) {
-		pollfd[i].fd = ports.p[i].fd;
-		pollfd[i].events = POLLIN | POLLOUT;
-	}
-
-	signal(SIGINT, sigint_handler);
-
-	pmsk = ports.num - 1;
-
-	printf("Bridge up and running!\n");
-
-	while (!stop) {
-		uint32_t n_pkts;
-
-		pollfd[0].revents = 0;
-		pollfd[1].revents = 0;
-
-		ret = rte_netmap_poll(pollfd, ports.num, 0);
-		if (ret < 0) {
-	   		stop = 1;
-	    		printf("[E] poll returned with error %d\n", ret);
-		}
-
-		if (((pollfd[0].revents | pollfd[1].revents) & POLLERR) != 0) {
-			printf("POLLERR!\n");
-		}
-
-		if ((pollfd[0].revents & POLLIN) != 0 &&
-				(pollfd[pmsk].revents & POLLOUT) != 0) {
-
-			rx_ring = ports.p[0].rx_ring;
-			tx_ring = ports.p[pmsk].tx_ring;
-
-			n_pkts = RTE_MIN(rx_ring->avail, tx_ring->avail);
-			move(n_pkts, rx_ring, tx_ring);
-		}
-
-		if (pmsk != 0 && (pollfd[pmsk].revents & POLLIN) != 0 &&
-				(pollfd[0].revents & POLLOUT) != 0) {
-
-			rx_ring = ports.p[pmsk].rx_ring;
-			tx_ring = ports.p[0].tx_ring;
-
-			n_pkts = RTE_MIN(rx_ring->avail, tx_ring->avail);
-			move(n_pkts, rx_ring, tx_ring);
-		}
-	}
-
-	printf("Bridge stopped!\n");
-
-	for (i = 0; i != ports.num; i++) {
-		err = rte_netmap_ioctl(ports.p[i].fd, NIOCUNREGIF, &req);
-		if (err) {
-			printf("[E] NIOCUNREGIF ioctl failed (error %d)\n",
-				err);
-		}
-		else
-			printf("Port %hhu unregistered from Netmap mode\n", ports.p[i].id);
-
-		rte_netmap_close(ports.p[i].fd);
-	}
-	return 0;
-}
diff --git a/examples/netmap_compat/lib/compat_netmap.c b/examples/netmap_compat/lib/compat_netmap.c
deleted file mode 100644
index af3dd22..0000000
--- a/examples/netmap_compat/lib/compat_netmap.c
+++ /dev/null
@@ -1,900 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <errno.h>
-#include <inttypes.h>
-#include <poll.h>
-#include <stdio.h>
-#include <stdlib.h>
-#include <net/if.h>
-#include <sys/types.h>
-#include <sys/resource.h>
-#include <sys/mman.h>
-
-#include <rte_common.h>
-#include <rte_errno.h>
-#include <rte_ethdev.h>
-#include <rte_log.h>
-#include <rte_malloc.h>
-#include <rte_mbuf.h>
-#include <rte_spinlock.h>
-#include <rte_string_fns.h>
-
-#include "compat_netmap.h"
-
-struct netmap_port {
-	struct rte_mempool   *pool;
-	struct netmap_if     *nmif;
-	struct rte_eth_conf   eth_conf;
-	struct rte_eth_txconf tx_conf;
-	struct rte_eth_rxconf rx_conf;
-	int32_t  socket_id;
-	uint16_t nr_tx_rings;
-	uint16_t nr_rx_rings;
-	uint32_t nr_tx_slots;
-	uint32_t nr_rx_slots;
-	uint16_t tx_burst;
-	uint16_t rx_burst;
-	uint32_t fd;
-};
-
-struct fd_port {
-	uint32_t port;
-};
-
-#ifndef POLLRDNORM
-#define POLLRDNORM	0x0040
-#endif
-
-#ifndef POLLWRNORM
-#define POLLWRNORM	0x0100
-#endif
-
-#define	FD_PORT_FREE	UINT32_MAX
-#define	FD_PORT_RSRV	(FD_PORT_FREE - 1)
-
-struct netmap_state {
-	struct rte_netmap_conf conf;
-	uintptr_t buf_start;
-	void     *mem;
-	uint32_t  mem_sz;
-	uint32_t  netif_memsz;
-};
-
-
-#define COMPAT_NETMAP_MAX_NOFILE	(2 * RTE_MAX_ETHPORTS)
-#define COMPAT_NETMAP_MAX_BURST		64
-#define COMPAT_NETMAP_MAX_PKT_PER_SYNC	(2 * COMPAT_NETMAP_MAX_BURST)
-
-static struct netmap_port ports[RTE_MAX_ETHPORTS];
-static struct netmap_state netmap;
-
-static struct fd_port fd_port[COMPAT_NETMAP_MAX_NOFILE];
-static const int next_fd_start = RLIMIT_NOFILE + 1;
-static rte_spinlock_t netmap_lock;
-
-#define	IDX_TO_FD(x)	((x) + next_fd_start)
-#define	FD_TO_IDX(x)	((x) - next_fd_start)
-#define	FD_VALID(x)	((x) >= next_fd_start && \
-	(x) < (typeof (x))(RTE_DIM(fd_port) + next_fd_start))
-
-#define	PORT_NUM_RINGS	(2 * netmap.conf.max_rings)
-#define	PORT_NUM_SLOTS	(PORT_NUM_RINGS * netmap.conf.max_slots)
-
-#define	BUF_IDX(port, ring, slot)            \
-	(((port) * PORT_NUM_RINGS + (ring)) * netmap.conf.max_slots + \
-	(slot))
-
-#define NETMAP_IF_RING_OFS(rid, rings, slots)   ({\
-	struct netmap_if *_if;                    \
-	struct netmap_ring *_rg;                  \
-	sizeof(*_if) +                            \
-	(rings) * sizeof(_if->ring_ofs[0]) +      \
-	(rid) * sizeof(*_rg) +                    \
-	(slots) * sizeof(_rg->slot[0]);           \
-	})
-
-static void netmap_unregif(uint32_t idx, uint32_t port);
-
-
-static int32_t
-ifname_to_portid(const char *ifname, uint16_t *port)
-{
-	char *endptr;
-	uint64_t portid;
-
-	errno = 0;
-	portid = strtoul(ifname, &endptr, 10);
-	if (endptr == ifname || *endptr != '\0' ||
-			portid >= RTE_DIM(ports) || errno != 0)
-		return -EINVAL;
-
-	*port = portid;
-	return 0;
-}
-
-/**
- * Given a dpdk mbuf, fill in the Netmap slot in ring r and its associated
- * buffer with the data held by the mbuf.
- * Note that mbuf chains are not supported.
- */
-static void
-mbuf_to_slot(struct rte_mbuf *mbuf, struct netmap_ring *r, uint32_t index)
-{
-	char *data;
-	uint16_t length;
-
-	data   = rte_pktmbuf_mtod(mbuf, char *);
-	length = rte_pktmbuf_data_len(mbuf);
-
-	if (length > r->nr_buf_size)
-		length = 0;
-
-	r->slot[index].len = length;
-	rte_memcpy(NETMAP_BUF(r, r->slot[index].buf_idx), data, length);
-}
-
-/**
- * Given a Netmap ring and a slot index for that ring, construct a dpdk mbuf
- * from the data held in the buffer associated with the slot.
- * Allocation/deallocation of the dpdk mbuf are the responsibility of the
- * caller.
- * Note that mbuf chains are not supported.
- */
-static void
-slot_to_mbuf(struct netmap_ring *r, uint32_t index, struct rte_mbuf *mbuf)
-{
-	char *data;
-	uint16_t length;
-
-	rte_pktmbuf_reset(mbuf);
-	length = r->slot[index].len;
-	data = rte_pktmbuf_append(mbuf, length);
-
-	if (data != NULL)
-	    rte_memcpy(data, NETMAP_BUF(r, r->slot[index].buf_idx), length);
-}
-
-static int32_t
-fd_reserve(void)
-{
-	uint32_t i;
-
-	for (i = 0; i != RTE_DIM(fd_port) && fd_port[i].port != FD_PORT_FREE;
-			i++)
-		;
-
-	if (i == RTE_DIM(fd_port))
-		return -ENOMEM;
-
-	fd_port[i].port = FD_PORT_RSRV;
-	return IDX_TO_FD(i);
-}
-
-static int32_t
-fd_release(int32_t fd)
-{
-	uint32_t idx, port;
-
-	idx = FD_TO_IDX(fd);
-
-	if (!FD_VALID(fd) || (port = fd_port[idx].port) == FD_PORT_FREE)
-		return -EINVAL;
-
-	/* if we still have a valid port attached, release the port */
-	if (port < RTE_DIM(ports) && ports[port].fd == idx) {
-		netmap_unregif(idx, port);
-	}
-
-	fd_port[idx].port = FD_PORT_FREE;
-	return 0;
-}
-
-static int
-check_nmreq(struct nmreq *req, uint16_t *port)
-{
-	int32_t rc;
-	uint16_t portid;
-
-	if (req == NULL)
-		return -EINVAL;
-
-	if (req->nr_version != NETMAP_API) {
-		req->nr_version = NETMAP_API;
-		return -EINVAL;
-	}
-
-	if ((rc = ifname_to_portid(req->nr_name, &portid)) != 0) {
-	    	RTE_LOG(ERR, USER1, "Invalid interface name:\"%s\" "
-			"in NIOCGINFO call\n", req->nr_name);
-		return rc;
-	}
-
-	if (ports[portid].pool == NULL) {
-		RTE_LOG(ERR, USER1, "Misconfigured portid %u\n", portid);
-		return -EINVAL;
-	}
-
-	*port = portid;
-	return 0;
-}
-
-/**
- * Simulate a Netmap NIOCGINFO ioctl: given a struct nmreq holding an interface
- * name (a port number in our case), fill the struct nmreq in with advisory
- * information about the interface: number of rings and their size, total memory
- * required in the map, ...
- * Those are preconfigured using rte_eth_{,tx,rx}conf and
- * rte_netmap_port_conf structures
- * and calls to rte_netmap_init_port() in the Netmap application.
- */
-static int
-ioctl_niocginfo(__rte_unused int fd, void * param)
-{
-	uint16_t portid;
-	struct nmreq *req;
-	int32_t rc;
-
-	req = (struct nmreq *)param;
-	if ((rc = check_nmreq(req, &portid)) != 0)
-		return rc;
-
-	req->nr_tx_rings = (uint16_t)(ports[portid].nr_tx_rings - 1);
-	req->nr_rx_rings = (uint16_t)(ports[portid].nr_rx_rings - 1);
-	req->nr_tx_slots = ports[portid].nr_tx_slots;
-	req->nr_rx_slots = ports[portid].nr_rx_slots;
-
-	/* in current implementation we have all NETIFs shared aone region. */
-	req->nr_memsize = netmap.mem_sz;
-	req->nr_offset = 0;
-
-	return 0;
-}
-
-static void
-netmap_ring_setup(struct netmap_ring *ring, uint16_t port, uint32_t ringid,
-	uint32_t num_slots)
-{
-	uint32_t j;
-
-	ring->buf_ofs = netmap.buf_start - (uintptr_t)ring;
-	ring->num_slots = num_slots;
-	ring->cur = 0;
-	ring->reserved = 0;
-	ring->nr_buf_size = netmap.conf.max_bufsz;
-	ring->flags = 0;
-	ring->ts.tv_sec = 0;
-	ring->ts.tv_usec = 0;
-
-	for (j = 0; j < ring->num_slots; j++) {
-		ring->slot[j].buf_idx = BUF_IDX(port, ringid, j);
-		ring->slot[j].len = 0;
-		ring->flags = 0;
-	}
-}
-
-static int
-netmap_regif(struct nmreq *req, uint32_t idx, uint16_t port)
-{
-	struct netmap_if *nmif;
-	struct netmap_ring *ring;
-	uint32_t i, slots, start_ring;
-	int32_t rc;
-
-	if (ports[port].fd < RTE_DIM(fd_port)) {
-		RTE_LOG(ERR, USER1, "port %u already in use by fd: %u\n",
-			port, IDX_TO_FD(ports[port].fd));
-		return -EBUSY;
-	}
-	if (fd_port[idx].port != FD_PORT_RSRV) {
-	    	RTE_LOG(ERR, USER1, "fd: %u is misconfigured\n",
-			IDX_TO_FD(idx));
-		return -EBUSY;
-	}
-
-	nmif = ports[port].nmif;
-
-	/* setup netmap_if fields. */
-	memset(nmif, 0, netmap.netif_memsz);
-
-	/* only ALL rings supported right now. */
-	if (req->nr_ringid != 0)
-		return -EINVAL;
-
-	snprintf(nmif->ni_name, sizeof(nmif->ni_name), "%s", req->nr_name);
-	nmif->ni_version  = req->nr_version;
-
-	/* Netmap uses ni_(r|t)x_rings + 1 */
-	nmif->ni_rx_rings = ports[port].nr_rx_rings - 1;
-	nmif->ni_tx_rings = ports[port].nr_tx_rings - 1;
-
-	/*
-	 * Setup TX rings and slots.
-	 * Refer to the comments in netmap.h for details
-	 */
-
-	slots = 0;
-	for (i = 0; i < nmif->ni_tx_rings + 1; i++) {
-
-		nmif->ring_ofs[i] = NETMAP_IF_RING_OFS(i,
-			PORT_NUM_RINGS, slots);
-
-		ring = NETMAP_TXRING(nmif, i);
-		netmap_ring_setup(ring, port, i, ports[port].nr_tx_slots);
-		ring->avail = ring->num_slots;
-
-		slots += ports[port].nr_tx_slots;
-	}
-
-	/*
-	 * Setup  RX rings and slots.
-	 * Refer to the comments in netmap.h for details
-	 */
-
-	start_ring = i;
-
-	for (; i < nmif->ni_rx_rings + 1 + start_ring; i++) {
-
-		nmif->ring_ofs[i] = NETMAP_IF_RING_OFS(i,
-			PORT_NUM_RINGS, slots);
-
-		ring = NETMAP_RXRING(nmif, (i - start_ring));
-		netmap_ring_setup(ring, port, i, ports[port].nr_rx_slots);
-		ring->avail = 0;
-
-		slots += ports[port].nr_rx_slots;
-	}
-
-	if ((rc = rte_eth_dev_start(port)) < 0) {
-		RTE_LOG(ERR, USER1,
-			"Couldn't start ethernet device %s (error %d)\n",
-			req->nr_name, rc);
-	    return rc;
-	}
-
-	/* setup fdi <--> port relationtip. */
-	ports[port].fd = idx;
-	fd_port[idx].port = port;
-
-	req->nr_memsize = netmap.mem_sz;
-	req->nr_offset = (uintptr_t)nmif - (uintptr_t)netmap.mem;
-
-	return 0;
-}
-
-/**
- * Simulate a Netmap NIOCREGIF ioctl:
- */
-static int
-ioctl_niocregif(int32_t fd, void * param)
-{
-	uint16_t portid;
-	int32_t rc;
-	uint32_t idx;
-	struct nmreq *req;
-
-	req = (struct nmreq *)param;
-	if ((rc = check_nmreq(req, &portid)) != 0)
-		return rc;
-
-	idx = FD_TO_IDX(fd);
-
-	rte_spinlock_lock(&netmap_lock);
-	rc = netmap_regif(req, idx, portid);
-	rte_spinlock_unlock(&netmap_lock);
-
-	return rc;
-}
-
-static void
-netmap_unregif(uint32_t idx, uint32_t port)
-{
-	fd_port[idx].port = FD_PORT_RSRV;
-	ports[port].fd = UINT32_MAX;
-	rte_eth_dev_stop(port);
-}
-
-/**
- * Simulate a Netmap NIOCUNREGIF ioctl: put an interface running in Netmap
- * mode back in "normal" mode. In our case, we just stop the port associated
- * with this file descriptor.
- */
-static int
-ioctl_niocunregif(int fd)
-{
-	uint32_t idx, port;
-	int32_t rc;
-
-	idx = FD_TO_IDX(fd);
-
-	rte_spinlock_lock(&netmap_lock);
-
-	port = fd_port[idx].port;
-	if (port < RTE_DIM(ports) && ports[port].fd == idx) {
-		netmap_unregif(idx, port);
-		rc = 0;
-	} else {
-		RTE_LOG(ERR, USER1,
-			"%s: %d is not associated with valid port\n",
-			__func__, fd);
-		rc = -EINVAL;
-	}
-
-	rte_spinlock_unlock(&netmap_lock);
-	return rc;
-}
-
-/**
- * A call to rx_sync_ring will try to fill a Netmap RX ring with as many
- * packets as it can hold coming from its dpdk port.
- */
-static inline int
-rx_sync_ring(struct netmap_ring *ring, uint16_t port, uint16_t ring_number,
-	uint16_t max_burst)
-{
-	int32_t i, n_rx;
-	uint16_t burst_size;
-	uint32_t cur_slot, n_free_slots;
-	struct rte_mbuf *rx_mbufs[COMPAT_NETMAP_MAX_BURST];
-
-	n_free_slots = ring->num_slots - (ring->avail + ring->reserved);
-	n_free_slots = RTE_MIN(n_free_slots, max_burst);
-	cur_slot = (ring->cur + ring->avail) & (ring->num_slots - 1);
-
-	while (n_free_slots) {
-		burst_size = (uint16_t)RTE_MIN(n_free_slots, RTE_DIM(rx_mbufs));
-
-		/* receive up to burst_size packets from the NIC's queue */
-		n_rx = rte_eth_rx_burst(port, ring_number, rx_mbufs,
-			burst_size);
-
-		if (n_rx == 0)
-			return 0;
-		if (unlikely(n_rx < 0))
-			return -1;
-
-		/* Put those n_rx packets in the Netmap structures */
-		for (i = 0; i < n_rx ; i++) {
-			mbuf_to_slot(rx_mbufs[i], ring, cur_slot);
-			rte_pktmbuf_free(rx_mbufs[i]);
-			cur_slot = NETMAP_RING_NEXT(ring, cur_slot);
-		}
-
-		/* Update the Netmap ring structure to reflect the change */
-		ring->avail += n_rx;
-		n_free_slots -= n_rx;
-	}
-
-	return 0;
-}
-
-static inline int
-rx_sync_if(uint32_t port)
-{
-	uint16_t burst;
-	uint32_t i, rc;
-	struct netmap_if *nifp;
-	struct netmap_ring *r;
-
-	nifp = ports[port].nmif;
-	burst = ports[port].rx_burst;
-	rc = 0;
-
-	for (i = 0; i < nifp->ni_rx_rings + 1; i++) {
-		r = NETMAP_RXRING(nifp, i);
-		rx_sync_ring(r, port, (uint16_t)i, burst);
-		rc += r->avail;
-	}
-
-	return rc;
-}
-
-/**
- * Simulate a Netmap NIOCRXSYNC ioctl:
- */
-static int
-ioctl_niocrxsync(int fd)
-{
-	uint32_t idx, port;
-
-	idx = FD_TO_IDX(fd);
-	if ((port = fd_port[idx].port) < RTE_DIM(ports) &&
-			ports[port].fd == idx) {
-		return rx_sync_if(fd_port[idx].port);
-	} else  {
-		return -EINVAL;
-	}
-}
-
-/**
- * A call to tx_sync_ring will try to empty a Netmap TX ring by converting its
- * buffers into rte_mbufs and sending them out on the rings's dpdk port.
- */
-static int
-tx_sync_ring(struct netmap_ring *ring, uint16_t port, uint16_t ring_number,
-	struct rte_mempool *pool, uint16_t max_burst)
-{
-	uint32_t i, n_tx;
-	uint16_t burst_size;
-	uint32_t cur_slot, n_used_slots;
-	struct rte_mbuf *tx_mbufs[COMPAT_NETMAP_MAX_BURST];
-
-	n_used_slots = ring->num_slots - ring->avail;
-	n_used_slots = RTE_MIN(n_used_slots, max_burst);
-	cur_slot = (ring->cur + ring->avail) & (ring->num_slots - 1);
-
-	while (n_used_slots) {
-		burst_size = (uint16_t)RTE_MIN(n_used_slots, RTE_DIM(tx_mbufs));
-
-		for (i = 0; i < burst_size; i++) {
-			tx_mbufs[i] = rte_pktmbuf_alloc(pool);
-			if (tx_mbufs[i] == NULL)
-				goto err;
-
-			slot_to_mbuf(ring, cur_slot, tx_mbufs[i]);
-			cur_slot = NETMAP_RING_NEXT(ring, cur_slot);
-		}
-
-		n_tx = rte_eth_tx_burst(port, ring_number, tx_mbufs,
-			burst_size);
-
-		/* Update the Netmap ring structure to reflect the change */
-		ring->avail += n_tx;
-		n_used_slots -= n_tx;
-
-		/* Return the mbufs that failed to transmit to their pool */
-		if (unlikely(n_tx != burst_size)) {
-			for (i = n_tx; i < burst_size; i++)
-				rte_pktmbuf_free(tx_mbufs[i]);
-	        	break;
-		}
-	}
-
-	return 0;
-
-err:
-	for (; i == 0; --i)
-		rte_pktmbuf_free(tx_mbufs[i]);
-
-	RTE_LOG(ERR, USER1,
-		"Couldn't get mbuf from mempool is the mempool too small?\n");
-	return -1;
-}
-
-static int
-tx_sync_if(uint32_t port)
-{
-	uint16_t burst;
-	uint32_t i, rc;
-	struct netmap_if *nifp;
-	struct netmap_ring *r;
-	struct rte_mempool *mp;
-
-	nifp = ports[port].nmif;
-	mp = ports[port].pool;
-	burst = ports[port].tx_burst;
-	rc = 0;
-
-	for (i = 0; i < nifp->ni_tx_rings + 1; i++) {
-		r = NETMAP_TXRING(nifp, i);
-		tx_sync_ring(r, port, (uint16_t)i, mp, burst);
-		rc += r->avail;
-	}
-
-	return rc;
-}
-
-/**
- * Simulate a Netmap NIOCTXSYNC ioctl:
- */
-static inline int
-ioctl_nioctxsync(int fd)
-{
-	uint32_t idx, port;
-
-	idx = FD_TO_IDX(fd);
-	if ((port = fd_port[idx].port) < RTE_DIM(ports) &&
-			ports[port].fd == idx) {
-		return tx_sync_if(fd_port[idx].port);
-	} else  {
-		return -EINVAL;
-	}
-}
-
-/**
- * Give the library a mempool of rte_mbufs with which it can do the
- * rte_mbuf <--> netmap slot conversions.
- */
-int
-rte_netmap_init(const struct rte_netmap_conf *conf)
-{
-	size_t buf_ofs, nmif_sz, sz;
-	size_t port_rings, port_slots, port_bufs;
-	uint32_t i, port_num;
-
-	port_num = RTE_MAX_ETHPORTS;
-	port_rings = 2 * conf->max_rings;
-	port_slots = port_rings * conf->max_slots;
-	port_bufs = port_slots;
-
-	nmif_sz = NETMAP_IF_RING_OFS(port_rings, port_rings, port_slots);
-	sz = nmif_sz * port_num;
-
-	buf_ofs = RTE_ALIGN_CEIL(sz, RTE_CACHE_LINE_SIZE);
-	sz = buf_ofs + port_bufs * conf->max_bufsz * port_num;
-
-	if (sz > UINT32_MAX ||
-			(netmap.mem = rte_zmalloc_socket(__func__, sz,
-			RTE_CACHE_LINE_SIZE, conf->socket_id)) == NULL) {
-		RTE_LOG(ERR, USER1, "%s: failed to allocate %zu bytes\n",
-			__func__, sz);
-		return -ENOMEM;
-	}
-
-	netmap.mem_sz = sz;
-	netmap.netif_memsz = nmif_sz;
-	netmap.buf_start = (uintptr_t)netmap.mem + buf_ofs;
-	netmap.conf = *conf;
-
-	rte_spinlock_init(&netmap_lock);
-
-	/* Mark all ports as unused and set NETIF pointer. */
-	for (i = 0; i != RTE_DIM(ports); i++) {
-		ports[i].fd = UINT32_MAX;
-		ports[i].nmif = (struct netmap_if *)
-			((uintptr_t)netmap.mem + nmif_sz * i);
-	}
-
-	/* Mark all fd_ports as unused. */
-	for (i = 0; i != RTE_DIM(fd_port); i++) {
-		fd_port[i].port = FD_PORT_FREE;
-	}
-
-	return 0;
-}
-
-
-int
-rte_netmap_init_port(uint16_t portid, const struct rte_netmap_port_conf *conf)
-{
-	int32_t ret;
-	uint16_t i;
-	uint16_t rx_slots, tx_slots;
-	struct rte_eth_rxconf rxq_conf;
-	struct rte_eth_txconf txq_conf;
-	struct rte_eth_dev_info dev_info;
-
-	if (conf == NULL ||
-			portid >= RTE_DIM(ports) ||
-			conf->nr_tx_rings > netmap.conf.max_rings ||
-			conf->nr_rx_rings > netmap.conf.max_rings) {
-		RTE_LOG(ERR, USER1, "%s(%u): invalid parameters\n",
-			__func__, portid);
-		return -EINVAL;
-	}
-
-	rx_slots = (uint16_t)rte_align32pow2(conf->nr_rx_slots);
-	tx_slots = (uint16_t)rte_align32pow2(conf->nr_tx_slots);
-
-	if (tx_slots > netmap.conf.max_slots ||
-			rx_slots > netmap.conf.max_slots) {
-		RTE_LOG(ERR, USER1, "%s(%u): invalid parameters\n",
-			__func__, portid);
-		return -EINVAL;
-	}
-
-	rte_eth_dev_info_get(portid, &dev_info);
-	if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-		conf->eth_conf->txmode.offloads |=
-			DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-	ret = rte_eth_dev_configure(portid, conf->nr_rx_rings,
-		conf->nr_tx_rings, conf->eth_conf);
-
-	if (ret < 0) {
-		RTE_LOG(ERR, USER1, "Couldn't configure port %u\n", portid);
-		return ret;
-	}
-
-	ret = rte_eth_dev_adjust_nb_rx_tx_desc(portid, &rx_slots, &tx_slots);
-
-	if (ret < 0) {
-		RTE_LOG(ERR, USER1,
-			"Couldn't ot adjust number of descriptors for port %u\n",
-			portid);
-		return ret;
-	}
-
-	rxq_conf = dev_info.default_rxconf;
-	rxq_conf.offloads = conf->eth_conf->rxmode.offloads;
-	txq_conf = dev_info.default_txconf;
-	txq_conf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-	txq_conf.offloads = conf->eth_conf->txmode.offloads;
-	for (i = 0; i < conf->nr_tx_rings; i++) {
-		ret = rte_eth_tx_queue_setup(portid, i, tx_slots,
-			conf->socket_id, &txq_conf);
-
-		if (ret < 0) {
-			RTE_LOG(ERR, USER1,
-				"fail to configure TX queue %u of port %u\n",
-				i, portid);
-			return ret;
-		}
-
-		ret = rte_eth_rx_queue_setup(portid, i, rx_slots,
-			conf->socket_id, &rxq_conf, conf->pool);
-
-		if (ret < 0) {
-			RTE_LOG(ERR, USER1,
-				"fail to configure RX queue %u of port %u\n",
-				i, portid);
-			return ret;
-		}
-	}
-
-	/* copy config to the private storage. */
-	ports[portid].eth_conf = conf->eth_conf[0];
-	ports[portid].pool = conf->pool;
-	ports[portid].socket_id = conf->socket_id;
-	ports[portid].nr_tx_rings = conf->nr_tx_rings;
-	ports[portid].nr_rx_rings = conf->nr_rx_rings;
-	ports[portid].nr_tx_slots = tx_slots;
-	ports[portid].nr_rx_slots = rx_slots;
-	ports[portid].tx_burst = conf->tx_burst;
-	ports[portid].rx_burst = conf->rx_burst;
-
-	return 0;
-}
-
-int
-rte_netmap_close(__rte_unused int fd)
-{
-	int32_t rc;
-
-	rte_spinlock_lock(&netmap_lock);
-	rc = fd_release(fd);
-	rte_spinlock_unlock(&netmap_lock);
-
-	if (rc < 0) {
-		errno =-rc;
-		rc = -1;
-	}
-	return rc;
-}
-
-int rte_netmap_ioctl(int fd, uint32_t op, void *param)
-{
-	int ret;
-
-	if (!FD_VALID(fd)) {
-	    errno = EBADF;
-	    return -1;
-	}
-
-	switch (op) {
-
-	    case NIOCGINFO:
-	        ret = ioctl_niocginfo(fd, param);
-	        break;
-
-	    case NIOCREGIF:
-	        ret = ioctl_niocregif(fd, param);
-	        break;
-
-	    case NIOCUNREGIF:
-	        ret = ioctl_niocunregif(fd);
-	        break;
-
-	    case NIOCRXSYNC:
-	        ret = ioctl_niocrxsync(fd);
-	        break;
-
-	    case NIOCTXSYNC:
-	        ret = ioctl_nioctxsync(fd);
-	        break;
-
-	    default:
-	        ret = -ENOTTY;
-	}
-
-	if (ret < 0) {
-		errno = -ret;
-		ret = -1;
-	} else {
-		ret = 0;
-	}
-
-	return ret;
-}
-
-void *
-rte_netmap_mmap(void *addr, size_t length,
-	int prot, int flags, int fd, off_t offset)
-{
-	static const int cprot = PROT_WRITE | PROT_READ;
-
-	if (!FD_VALID(fd) || length + offset > netmap.mem_sz ||
-			(prot & cprot) != cprot ||
-			((flags & MAP_FIXED) != 0 && addr != NULL)) {
-
-		errno = EINVAL;
-		return MAP_FAILED;
-	}
-
-	return (void *)((uintptr_t)netmap.mem + (uintptr_t)offset);
-}
-
-/**
- * Return a "fake" file descriptor with a value above RLIMIT_NOFILE so that
- * any attempt to use that file descriptor with the usual API will fail.
- */
-int
-rte_netmap_open(__rte_unused const char *pathname, __rte_unused int flags)
-{
-	int fd;
-
-	rte_spinlock_lock(&netmap_lock);
-	fd = fd_reserve();
-	rte_spinlock_unlock(&netmap_lock);
-
-	if (fd < 0) {
-		errno = -fd;
-		fd = -1;
-	}
-	return fd;
-}
-
-/**
- * Doesn't support timeout other than 0 or infinite (negative) timeout
- */
-int
-rte_netmap_poll(struct pollfd *fds, nfds_t nfds, int timeout)
-{
-	int32_t count_it, ret;
-	uint32_t i, idx, port;
-	uint32_t want_rx, want_tx;
-
-	if (timeout > 0)
-		return -1;
-
-	ret = 0;
-	do {
-		for (i = 0; i < nfds; i++) {
-
-			count_it = 0;
-
-			if (!FD_VALID(fds[i].fd) || fds[i].events == 0) {
-				fds[i].revents = 0;
-				continue;
-			}
-
-			idx = FD_TO_IDX(fds[i].fd);
-			if ((port = fd_port[idx].port) >= RTE_DIM(ports) ||
-		ports[port].fd != idx) {
-
-				fds[i].revents |= POLLERR;
-				ret++;
-				continue;
-			}
-
-			want_rx = fds[i].events & (POLLIN  | POLLRDNORM);
-			want_tx = fds[i].events & (POLLOUT | POLLWRNORM);
-
-			if (want_rx && rx_sync_if(port) > 0) {
-				fds[i].revents = (uint16_t)
-					(fds[i].revents | want_rx);
-				count_it = 1;
-			}
-			if (want_tx && tx_sync_if(port) > 0) {
-				fds[i].revents = (uint16_t)
-					(fds[i].revents | want_tx);
-				count_it = 1;
-			}
-
-			ret += count_it;
-		}
-	}
-	while ((ret == 0 && timeout < 0) || timeout);
-
-	return ret;
-}
diff --git a/examples/netmap_compat/lib/compat_netmap.h b/examples/netmap_compat/lib/compat_netmap.h
deleted file mode 100644
index 12b618b..0000000
--- a/examples/netmap_compat/lib/compat_netmap.h
+++ /dev/null
@@ -1,51 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#ifndef _RTE_COMPAT_NETMAP_H_
-
-#include <poll.h>
-#include <linux/ioctl.h>
-#include <net/if.h>
-
-#include <rte_ethdev.h>
-#include <rte_mempool.h>
-
-#include "netmap.h"
-#include "netmap_user.h"
-
-/**
- * One can overwrite Netmap macros here as needed
- */
-
-struct rte_netmap_conf {
-	int32_t  socket_id;
-	uint32_t max_rings; /* number of rings(queues) per netmap_if(port) */
-	uint32_t max_slots; /* number of slots(descriptors) per netmap ring. */
-	uint16_t max_bufsz; /* size of each netmap buffer. */
-};
-
-struct rte_netmap_port_conf {
-	struct rte_eth_conf   *eth_conf;
-	struct rte_mempool    *pool;
-	int32_t socket_id;
-	uint16_t nr_tx_rings;
-	uint16_t nr_rx_rings;
-	uint32_t nr_tx_slots;
-	uint32_t nr_rx_slots;
-	uint16_t tx_burst;
-	uint16_t rx_burst;
-};
-
-int rte_netmap_init(const struct rte_netmap_conf *conf);
-int rte_netmap_init_port(uint16_t portid,
-	const struct rte_netmap_port_conf *conf);
-
-int rte_netmap_close(int fd);
-int rte_netmap_ioctl(int fd, uint32_t op, void *param);
-int rte_netmap_open(const char *pathname, int flags);
-int rte_netmap_poll(struct pollfd *fds, nfds_t nfds, int timeout);
-void *rte_netmap_mmap(void *addr, size_t length, int prot, int flags, int fd,
-	                  off_t offset);
-
-#endif /* _RTE_COMPAT_NETMAP_H_ */
diff --git a/examples/netmap_compat/netmap/netmap.h b/examples/netmap_compat/netmap/netmap.h
deleted file mode 100644
index 677c8a9..0000000
--- a/examples/netmap_compat/netmap/netmap.h
+++ /dev/null
@@ -1,289 +0,0 @@
-/*
- * Copyright (C) 2011 Matteo Landi, Luigi Rizzo. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions are
- * met:
- *
- *   1. Redistributions of source code must retain the above copyright
- *      notice, this list of conditions and the following disclaimer.
- *
- *   2. Redistributions in binary form must reproduce the above copyright
- *      notice, this list of conditions and the following disclaimer in the
- *      documentation and/or other materials provided with the
- *      distribution.
- *
- *   3. Neither the name of the authors nor the names of their contributors
- *      may be used to endorse or promote products derived from this
- *      software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY MATTEO LANDI AND CONTRIBUTORS "AS IS" AND
- * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL MATTEO LANDI OR CONTRIBUTORS
- * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
- * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
- * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
- * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
- * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
- * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
- * THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * $FreeBSD: head/sys/net/netmap.h 231198 2012-02-08 11:43:29Z luigi $
- * $Id: netmap.h 10879 2012-04-12 22:48:59Z luigi $
- *
- * Definitions of constants and the structures used by the netmap
- * framework, for the part visible to both kernel and userspace.
- * Detailed info on netmap is available with "man netmap" or at
- *
- *	http://info.iet.unipi.it/~luigi/netmap/
- */
-
-#ifndef _NET_NETMAP_H_
-#define _NET_NETMAP_H_
-
-/*
- * --- Netmap data structures ---
- *
- * The data structures used by netmap are shown below. Those in
- * capital letters are in an mmapp()ed area shared with userspace,
- * while others are private to the kernel.
- * Shared structures do not contain pointers but only memory
- * offsets, so that addressing is portable between kernel and userspace.
-
-
- softc
-+----------------+
-| standard fields|
-| if_pspare[0] ----------+
-+----------------+       |
-                         |
-+----------------+<------+
-|(netmap_adapter)|
-|                |                             netmap_kring
-| tx_rings *--------------------------------->+---------------+
-|                |       netmap_kring         | ring    *---------.
-| rx_rings *--------->+---------------+       | nr_hwcur      |   |
-+----------------+    | ring    *--------.    | nr_hwavail    |   V
-                      | nr_hwcur      |  |    | selinfo       |   |
-                      | nr_hwavail    |  |    +---------------+   .
-                      | selinfo       |  |    |     ...       |   .
-                      +---------------+  |    |(ntx+1 entries)|
-                      |    ....       |  |    |               |
-                      |(nrx+1 entries)|  |    +---------------+
-                      |               |  |
-   KERNEL             +---------------+  |
-                                         |
-  ====================================================================
-                                         |
-   USERSPACE                             |      NETMAP_RING
-                                         +---->+-------------+
-                                             / | cur         |
-   NETMAP_IF  (nifp, one per file desc.)    /  | avail       |
-    +---------------+                      /   | buf_ofs     |
-    | ni_tx_rings   |                     /    +=============+
-    | ni_rx_rings   |                    /     | buf_idx     | slot[0]
-    |               |                   /      | len, flags  |
-    |               |                  /       +-------------+
-    +===============+                 /        | buf_idx     | slot[1]
-    | txring_ofs[0] | (rel.to nifp)--'         | len, flags  |
-    | txring_ofs[1] |                          +-------------+
-  (num_rings+1 entries)                     (nr_num_slots entries)
-    | txring_ofs[n] |                          | buf_idx     | slot[n-1]
-    +---------------+                          | len, flags  |
-    | rxring_ofs[0] |                          +-------------+
-    | rxring_ofs[1] |
-  (num_rings+1 entries)
-    | txring_ofs[n] |
-    +---------------+
-
- * The private descriptor ('softc' or 'adapter') of each interface
- * is extended with a "struct netmap_adapter" containing netmap-related
- * info (see description in dev/netmap/netmap_kernel.h.
- * Among other things, tx_rings and rx_rings point to the arrays of
- * "struct netmap_kring" which in turn reache the various
- * "struct netmap_ring", shared with userspace.
-
- * The NETMAP_RING is the userspace-visible replica of the NIC ring.
- * Each slot has the index of a buffer, its length and some flags.
- * In user space, the buffer address is computed as
- *	(char *)ring + buf_ofs + index*NETMAP_BUF_SIZE
- * In the kernel, buffers do not necessarily need to be contiguous,
- * and the virtual and physical addresses are derived through
- * a lookup table.
- * To associate a different buffer to a slot, applications must
- * write the new index in buf_idx, and set NS_BUF_CHANGED flag to
- * make sure that the kernel updates the hardware ring as needed.
- *
- * Normally the driver is not requested to report the result of
- * transmissions (this can dramatically speed up operation).
- * However the user may request to report completion by setting
- * NS_REPORT.
- */
-struct netmap_slot {
-	uint32_t buf_idx; /* buffer index */
-	uint16_t len;	/* packet length, to be copied to/from the hw ring */
-	uint16_t flags;	/* buf changed, etc. */
-#define	NS_BUF_CHANGED	0x0001	/* must resync the map, buffer changed */
-#define	NS_REPORT	0x0002	/* ask the hardware to report results
-				 * e.g. by generating an interrupt
-				 */
-};
-
-/*
- * Netmap representation of a TX or RX ring (also known as "queue").
- * This is a queue implemented as a fixed-size circular array.
- * At the software level, two fields are important: avail and cur.
- *
- * In TX rings:
- *	avail	indicates the number of slots available for transmission.
- *		It is updated by the kernel after every netmap system call.
- *		It MUST BE decremented by the application when it appends a
- *		packet.
- *	cur	indicates the slot to use for the next packet
- *		to send (i.e. the "tail" of the queue).
- *		It MUST BE incremented by the application before
- *		netmap system calls to reflect the number of newly
- *		sent packets.
- *		It is checked by the kernel on netmap system calls
- *		(normally unmodified by the kernel unless invalid).
- *
- *   The kernel side of netmap uses two additional fields in its own
- *   private ring structure, netmap_kring:
- *	nr_hwcur is a copy of nr_cur on an NIOCTXSYNC.
- *	nr_hwavail is the number of slots known as available by the
- *		hardware. It is updated on an INTR (inc by the
- *		number of packets sent) and on a NIOCTXSYNC
- *		(decrease by nr_cur - nr_hwcur)
- *		A special case, nr_hwavail is -1 if the transmit
- *		side is idle (no pending transmits).
- *
- * In RX rings:
- *	avail	is the number of packets available (possibly 0).
- *		It MUST BE decremented by the application when it consumes
- *		a packet, and it is updated to nr_hwavail on a NIOCRXSYNC
- *	cur	indicates the first slot that contains a packet not
- *		processed yet (the "head" of the queue).
- *		It MUST BE incremented by the software when it consumes
- *		a packet.
- *	reserved	indicates the number of buffers before 'cur'
- *		that the application has still in use. Normally 0,
- *		it MUST BE incremented by the application when it
- *		does not return the buffer immediately, and decremented
- *		when the buffer is finally freed.
- *
- *   The kernel side of netmap uses two additional fields in the kring:
- *	nr_hwcur is a copy of nr_cur on an NIOCRXSYNC
- *	nr_hwavail is the number of packets available. It is updated
- *		on INTR (inc by the number of new packets arrived)
- *		and on NIOCRXSYNC (decreased by nr_cur - nr_hwcur).
- *
- * DATA OWNERSHIP/LOCKING:
- *	The netmap_ring is owned by the user program and it is only
- *	accessed or modified in the upper half of the kernel during
- *	a system call.
- *
- *	The netmap_kring is only modified by the upper half of the kernel.
- */
-struct netmap_ring {
-	/*
-	 * nr_buf_base_ofs is meant to be used through macros.
-	 * It contains the offset of the buffer region from this
-	 * descriptor.
-	 */
-	ssize_t	buf_ofs;
-	uint32_t	num_slots;	/* number of slots in the ring. */
-	uint32_t	avail;		/* number of usable slots */
-	uint32_t        cur;		/* 'current' r/w position */
-	uint32_t	reserved;	/* not refilled before current */
-
-	uint16_t	nr_buf_size;
-	uint16_t	flags;
-#define	NR_TIMESTAMP	0x0002		/* set timestamp on *sync() */
-
-	struct timeval	ts;		/* time of last *sync() */
-
-	/* the slots follow. This struct has variable size */
-	struct netmap_slot slot[0];	/* array of slots. */
-};
-
-
-/*
- * Netmap representation of an interface and its queue(s).
- * There is one netmap_if for each file descriptor on which we want
- * to select/poll.  We assume that on each interface has the same number
- * of receive and transmit queues.
- * select/poll operates on one or all pairs depending on the value of
- * nmr_queueid passed on the ioctl.
- */
-struct netmap_if {
-	char		ni_name[IFNAMSIZ]; /* name of the interface. */
-	u_int	ni_version;	/* API version, currently unused */
-	u_int	ni_rx_rings;	/* number of rx rings */
-	u_int	ni_tx_rings;	/* if zero, same as ni_rx_rings */
-	/*
-	 * The following array contains the offset of each netmap ring
-	 * from this structure. The first ni_tx_queues+1 entries refer
-	 * to the tx rings, the next ni_rx_queues+1 refer to the rx rings
-	 * (the last entry in each block refers to the host stack rings).
-	 * The area is filled up by the kernel on NIOCREG,
-	 * and then only read by userspace code.
-	 */
-	ssize_t	ring_ofs[0];
-};
-
-#ifndef NIOCREGIF
-/*
- * ioctl names and related fields
- *
- * NIOCGINFO takes a struct ifreq, the interface name is the input,
- *	the outputs are number of queues and number of descriptor
- *	for each queue (useful to set number of threads etc.).
- *
- * NIOCREGIF takes an interface name within a struct ifreq,
- *	and activates netmap mode on the interface (if possible).
- *
- * NIOCUNREGIF unregisters the interface associated to the fd.
- *
- * NIOCTXSYNC, NIOCRXSYNC synchronize tx or rx queues,
- *	whose identity is set in NIOCREGIF through nr_ringid
- */
-
-/*
- * struct nmreq overlays a struct ifreq
- */
-struct nmreq {
-	char		nr_name[IFNAMSIZ];
-	uint32_t	nr_version;	/* API version */
-#define	NETMAP_API	3		/* current version */
-	uint32_t	nr_offset;	/* nifp offset in the shared region */
-	uint32_t	nr_memsize;	/* size of the shared region */
-	uint32_t	nr_tx_slots;	/* slots in tx rings */
-	uint32_t	nr_rx_slots;	/* slots in rx rings */
-	uint16_t	nr_tx_rings;	/* number of tx rings */
-	uint16_t	nr_rx_rings;	/* number of rx rings */
-	uint16_t	nr_ringid;	/* ring(s) we care about */
-#define NETMAP_HW_RING	0x4000		/* low bits indicate one hw ring */
-#define NETMAP_SW_RING	0x2000		/* process the sw ring */
-#define NETMAP_NO_TX_POLL	0x1000	/* no automatic txsync on poll */
-#define NETMAP_RING_MASK 0xfff		/* the ring number */
-	uint16_t	spare1;
-	uint32_t	spare2[4];
-};
-
-/*
- * FreeBSD uses the size value embedded in the _IOWR to determine
- * how much to copy in/out. So we need it to match the actual
- * data structure we pass. We put some spares in the structure
- * to ease compatibility with other versions
- */
-#define NIOCGINFO	_IOWR('i', 145, struct nmreq) /* return IF info */
-#define NIOCREGIF	_IOWR('i', 146, struct nmreq) /* interface register */
-#define NIOCUNREGIF	_IO('i', 147) /* interface unregister */
-#define NIOCTXSYNC	_IO('i', 148) /* sync tx queues */
-#define NIOCRXSYNC	_IO('i', 149) /* sync rx queues */
-#endif /* !NIOCREGIF */
-
-#endif /* _NET_NETMAP_H_ */
diff --git a/examples/netmap_compat/netmap/netmap_user.h b/examples/netmap_compat/netmap/netmap_user.h
deleted file mode 100644
index f369592..0000000
--- a/examples/netmap_compat/netmap/netmap_user.h
+++ /dev/null
@@ -1,95 +0,0 @@
-/*
- * Copyright (C) 2011 Matteo Landi, Luigi Rizzo. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions are
- * met:
- *
- *   1. Redistributions of source code must retain the above copyright
- *      notice, this list of conditions and the following disclaimer.
- *
- *   2. Redistributions in binary form must reproduce the above copyright
- *      notice, this list of conditions and the following disclaimer in the
- *      documentation and/or other materials provided with the
- *      distribution.
- *
- *   3. Neither the name of the authors nor the names of their contributors
- *      may be used to endorse or promote products derived from this
- *      software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY MATTEO LANDI AND CONTRIBUTORS "AS IS" AND
- * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL MATTEO LANDI OR CONTRIBUTORS
- * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
- * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
- * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
- * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
- * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
- * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
- * THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * $FreeBSD: head/sys/net/netmap_user.h 231198 2012-02-08 11:43:29Z luigi $
- * $Id: netmap_user.h 10879 2012-04-12 22:48:59Z luigi $
- *
- * This header contains the macros used to manipulate netmap structures
- * and packets in userspace. See netmap(4) for more information.
- *
- * The address of the struct netmap_if, say nifp, is computed from the
- * value returned from ioctl(.., NIOCREG, ...) and the mmap region:
- *	ioctl(fd, NIOCREG, &req);
- *	mem = mmap(0, ... );
- *	nifp = NETMAP_IF(mem, req.nr_nifp);
- *		(so simple, we could just do it manually)
- *
- * From there:
- *	struct netmap_ring *NETMAP_TXRING(nifp, index)
- *	struct netmap_ring *NETMAP_RXRING(nifp, index)
- *		we can access ring->nr_cur, ring->nr_avail, ring->nr_flags
- *
- *	ring->slot[i] gives us the i-th slot (we can access
- *		directly plen, flags, bufindex)
- *
- *	char *buf = NETMAP_BUF(ring, index) returns a pointer to
- *		the i-th buffer
- *
- * Since rings are circular, we have macros to compute the next index
- *	i = NETMAP_RING_NEXT(ring, i);
- */
-
-#ifndef _NET_NETMAP_USER_H_
-#define _NET_NETMAP_USER_H_
-
-#define NETMAP_IF(b, o)	(struct netmap_if *)((char *)(b) + (o))
-
-#define NETMAP_TXRING(nifp, index)			\
-	((struct netmap_ring *)((char *)(nifp) +	\
-		(nifp)->ring_ofs[index] ) )
-
-#define NETMAP_RXRING(nifp, index)			\
-	((struct netmap_ring *)((char *)(nifp) +	\
-	    (nifp)->ring_ofs[index + (nifp)->ni_tx_rings + 1] ) )
-
-#define NETMAP_BUF(ring, index)				\
-	((char *)(ring) + (ring)->buf_ofs + ((index)*(ring)->nr_buf_size))
-
-#define NETMAP_BUF_IDX(ring, buf)			\
-	( ((char *)(buf) - ((char *)(ring) + (ring)->buf_ofs) ) / \
-		(ring)->nr_buf_size )
-
-#define	NETMAP_RING_NEXT(r, i)				\
-	((i)+1 == (r)->num_slots ? 0 : (i) + 1 )
-
-#define	NETMAP_RING_FIRST_RESERVED(r)			\
-	( (r)->cur < (r)->reserved ?			\
-	  (r)->cur + (r)->num_slots - (r)->reserved :	\
-	  (r)->cur - (r)->reserved )
-
-/*
- * Return 1 if the given tx ring is empty.
- */
-#define NETMAP_TX_RING_EMPTY(r)	((r)->avail >= (r)->num_slots - 1)
-
-#endif /* _NET_NETMAP_USER_H_ */
diff --git a/examples/packet_ordering/Makefile b/examples/packet_ordering/Makefile
deleted file mode 100644
index 5eb503c..0000000
--- a/examples/packet_ordering/Makefile
+++ /dev/null
@@ -1,58 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-# binary name
-APP = packet_ordering
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else # Build using legacy build system
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-endif
diff --git a/examples/packet_ordering/main.c b/examples/packet_ordering/main.c
deleted file mode 100644
index 676cb6f..0000000
--- a/examples/packet_ordering/main.c
+++ /dev/null
@@ -1,734 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#include <signal.h>
-#include <getopt.h>
-
-#include <rte_eal.h>
-#include <rte_common.h>
-#include <rte_errno.h>
-#include <rte_ethdev.h>
-#include <rte_lcore.h>
-#include <rte_malloc.h>
-#include <rte_mbuf.h>
-#include <rte_mempool.h>
-#include <rte_ring.h>
-#include <rte_reorder.h>
-
-#define RX_DESC_PER_QUEUE 1024
-#define TX_DESC_PER_QUEUE 1024
-
-#define MAX_PKTS_BURST 32
-#define REORDER_BUFFER_SIZE 8192
-#define MBUF_PER_POOL 65535
-#define MBUF_POOL_CACHE_SIZE 250
-
-#define RING_SIZE 16384
-
-/* Macros for printing using RTE_LOG */
-#define RTE_LOGTYPE_REORDERAPP          RTE_LOGTYPE_USER1
-
-unsigned int portmask;
-unsigned int disable_reorder;
-volatile uint8_t quit_signal;
-
-static struct rte_mempool *mbuf_pool;
-
-static struct rte_eth_conf port_conf_default = {
-	.rxmode = {
-		.ignore_offload_bitfield = 1,
-	},
-};
-
-struct worker_thread_args {
-	struct rte_ring *ring_in;
-	struct rte_ring *ring_out;
-};
-
-struct send_thread_args {
-	struct rte_ring *ring_in;
-	struct rte_reorder_buffer *buffer;
-};
-
-volatile struct app_stats {
-	struct {
-		uint64_t rx_pkts;
-		uint64_t enqueue_pkts;
-		uint64_t enqueue_failed_pkts;
-	} rx __rte_cache_aligned;
-
-	struct {
-		uint64_t dequeue_pkts;
-		uint64_t enqueue_pkts;
-		uint64_t enqueue_failed_pkts;
-	} wkr __rte_cache_aligned;
-
-	struct {
-		uint64_t dequeue_pkts;
-		/* Too early pkts transmitted directly w/o reordering */
-		uint64_t early_pkts_txtd_woro;
-		/* Too early pkts failed from direct transmit */
-		uint64_t early_pkts_tx_failed_woro;
-		uint64_t ro_tx_pkts;
-		uint64_t ro_tx_failed_pkts;
-	} tx __rte_cache_aligned;
-} app_stats;
-
-/**
- * Get the last enabled lcore ID
- *
- * @return
- *   The last enabled lcore ID.
- */
-static unsigned int
-get_last_lcore_id(void)
-{
-	int i;
-
-	for (i = RTE_MAX_LCORE - 1; i >= 0; i--)
-		if (rte_lcore_is_enabled(i))
-			return i;
-	return 0;
-}
-
-/**
- * Get the previous enabled lcore ID
- * @param id
- *  The current lcore ID
- * @return
- *   The previous enabled lcore ID or the current lcore
- *   ID if it is the first available core.
- */
-static unsigned int
-get_previous_lcore_id(unsigned int id)
-{
-	int i;
-
-	for (i = id - 1; i >= 0; i--)
-		if (rte_lcore_is_enabled(i))
-			return i;
-	return id;
-}
-
-static inline void
-pktmbuf_free_bulk(struct rte_mbuf *mbuf_table[], unsigned n)
-{
-	unsigned int i;
-
-	for (i = 0; i < n; i++)
-		rte_pktmbuf_free(mbuf_table[i]);
-}
-
-/* display usage */
-static void
-print_usage(const char *prgname)
-{
-	printf("%s [EAL options] -- -p PORTMASK\n"
-			"  -p PORTMASK: hexadecimal bitmask of ports to configure\n",
-			prgname);
-}
-
-static int
-parse_portmask(const char *portmask)
-{
-	unsigned long pm;
-	char *end = NULL;
-
-	/* parse hexadecimal string */
-	pm = strtoul(portmask, &end, 16);
-	if ((portmask[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (pm == 0)
-		return -1;
-
-	return pm;
-}
-
-/* Parse the argument given in the command line of the application */
-static int
-parse_args(int argc, char **argv)
-{
-	int opt;
-	int option_index;
-	char **argvopt;
-	char *prgname = argv[0];
-	static struct option lgopts[] = {
-		{"disable-reorder", 0, 0, 0},
-		{NULL, 0, 0, 0}
-	};
-
-	argvopt = argv;
-
-	while ((opt = getopt_long(argc, argvopt, "p:",
-					lgopts, &option_index)) != EOF) {
-		switch (opt) {
-		/* portmask */
-		case 'p':
-			portmask = parse_portmask(optarg);
-			if (portmask == 0) {
-				printf("invalid portmask\n");
-				print_usage(prgname);
-				return -1;
-			}
-			break;
-		/* long options */
-		case 0:
-			if (!strcmp(lgopts[option_index].name, "disable-reorder")) {
-				printf("reorder disabled\n");
-				disable_reorder = 1;
-			}
-			break;
-		default:
-			print_usage(prgname);
-			return -1;
-		}
-	}
-	if (optind <= 1) {
-		print_usage(prgname);
-		return -1;
-	}
-
-	argv[optind-1] = prgname;
-	optind = 1; /* reset getopt lib */
-	return 0;
-}
-
-/*
- * Tx buffer error callback
- */
-static void
-flush_tx_error_callback(struct rte_mbuf **unsent, uint16_t count,
-		void *userdata __rte_unused) {
-
-	/* free the mbufs which failed from transmit */
-	app_stats.tx.ro_tx_failed_pkts += count;
-	RTE_LOG_DP(DEBUG, REORDERAPP, "%s:Packet loss with tx_burst\n", __func__);
-	pktmbuf_free_bulk(unsent, count);
-
-}
-
-static inline int
-free_tx_buffers(struct rte_eth_dev_tx_buffer *tx_buffer[]) {
-	uint16_t port_id;
-
-	/* initialize buffers for all ports */
-	RTE_ETH_FOREACH_DEV(port_id) {
-		/* skip ports that are not enabled */
-		if ((portmask & (1 << port_id)) == 0)
-			continue;
-
-		rte_free(tx_buffer[port_id]);
-	}
-	return 0;
-}
-
-static inline int
-configure_tx_buffers(struct rte_eth_dev_tx_buffer *tx_buffer[])
-{
-	uint16_t port_id;
-	int ret;
-
-	/* initialize buffers for all ports */
-	RTE_ETH_FOREACH_DEV(port_id) {
-		/* skip ports that are not enabled */
-		if ((portmask & (1 << port_id)) == 0)
-			continue;
-
-		/* Initialize TX buffers */
-		tx_buffer[port_id] = rte_zmalloc_socket("tx_buffer",
-				RTE_ETH_TX_BUFFER_SIZE(MAX_PKTS_BURST), 0,
-				rte_eth_dev_socket_id(port_id));
-		if (tx_buffer[port_id] == NULL)
-			rte_exit(EXIT_FAILURE, "Cannot allocate buffer for tx on port %u\n",
-				 port_id);
-
-		rte_eth_tx_buffer_init(tx_buffer[port_id], MAX_PKTS_BURST);
-
-		ret = rte_eth_tx_buffer_set_err_callback(tx_buffer[port_id],
-				flush_tx_error_callback, NULL);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-			"Cannot set error callback for tx buffer on port %u\n",
-				 port_id);
-	}
-	return 0;
-}
-
-static inline int
-configure_eth_port(uint16_t port_id)
-{
-	struct ether_addr addr;
-	const uint16_t rxRings = 1, txRings = 1;
-	int ret;
-	uint16_t q;
-	uint16_t nb_rxd = RX_DESC_PER_QUEUE;
-	uint16_t nb_txd = TX_DESC_PER_QUEUE;
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_txconf txconf;
-	struct rte_eth_conf port_conf = port_conf_default;
-
-	if (!rte_eth_dev_is_valid_port(port_id))
-		return -1;
-
-	rte_eth_dev_info_get(port_id, &dev_info);
-	if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-		port_conf.txmode.offloads |=
-			DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-	ret = rte_eth_dev_configure(port_id, rxRings, txRings, &port_conf_default);
-	if (ret != 0)
-		return ret;
-
-	ret = rte_eth_dev_adjust_nb_rx_tx_desc(port_id, &nb_rxd, &nb_txd);
-	if (ret != 0)
-		return ret;
-
-	for (q = 0; q < rxRings; q++) {
-		ret = rte_eth_rx_queue_setup(port_id, q, nb_rxd,
-				rte_eth_dev_socket_id(port_id), NULL,
-				mbuf_pool);
-		if (ret < 0)
-			return ret;
-	}
-
-	txconf = dev_info.default_txconf;
-	txconf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-	txconf.offloads = port_conf.txmode.offloads;
-	for (q = 0; q < txRings; q++) {
-		ret = rte_eth_tx_queue_setup(port_id, q, nb_txd,
-				rte_eth_dev_socket_id(port_id), &txconf);
-		if (ret < 0)
-			return ret;
-	}
-
-	ret = rte_eth_dev_start(port_id);
-	if (ret < 0)
-		return ret;
-
-	rte_eth_macaddr_get(port_id, &addr);
-	printf("Port %u MAC: %02"PRIx8" %02"PRIx8" %02"PRIx8
-			" %02"PRIx8" %02"PRIx8" %02"PRIx8"\n",
-			port_id,
-			addr.addr_bytes[0], addr.addr_bytes[1],
-			addr.addr_bytes[2], addr.addr_bytes[3],
-			addr.addr_bytes[4], addr.addr_bytes[5]);
-
-	rte_eth_promiscuous_enable(port_id);
-
-	return 0;
-}
-
-static void
-print_stats(void)
-{
-	uint16_t i;
-	struct rte_eth_stats eth_stats;
-
-	printf("\nRX thread stats:\n");
-	printf(" - Pkts rxd:				%"PRIu64"\n",
-						app_stats.rx.rx_pkts);
-	printf(" - Pkts enqd to workers ring:		%"PRIu64"\n",
-						app_stats.rx.enqueue_pkts);
-
-	printf("\nWorker thread stats:\n");
-	printf(" - Pkts deqd from workers ring:		%"PRIu64"\n",
-						app_stats.wkr.dequeue_pkts);
-	printf(" - Pkts enqd to tx ring:		%"PRIu64"\n",
-						app_stats.wkr.enqueue_pkts);
-	printf(" - Pkts enq to tx failed:		%"PRIu64"\n",
-						app_stats.wkr.enqueue_failed_pkts);
-
-	printf("\nTX stats:\n");
-	printf(" - Pkts deqd from tx ring:		%"PRIu64"\n",
-						app_stats.tx.dequeue_pkts);
-	printf(" - Ro Pkts transmitted:			%"PRIu64"\n",
-						app_stats.tx.ro_tx_pkts);
-	printf(" - Ro Pkts tx failed:			%"PRIu64"\n",
-						app_stats.tx.ro_tx_failed_pkts);
-	printf(" - Pkts transmitted w/o reorder:	%"PRIu64"\n",
-						app_stats.tx.early_pkts_txtd_woro);
-	printf(" - Pkts tx failed w/o reorder:		%"PRIu64"\n",
-						app_stats.tx.early_pkts_tx_failed_woro);
-
-	RTE_ETH_FOREACH_DEV(i) {
-		rte_eth_stats_get(i, &eth_stats);
-		printf("\nPort %u stats:\n", i);
-		printf(" - Pkts in:   %"PRIu64"\n", eth_stats.ipackets);
-		printf(" - Pkts out:  %"PRIu64"\n", eth_stats.opackets);
-		printf(" - In Errs:   %"PRIu64"\n", eth_stats.ierrors);
-		printf(" - Out Errs:  %"PRIu64"\n", eth_stats.oerrors);
-		printf(" - Mbuf Errs: %"PRIu64"\n", eth_stats.rx_nombuf);
-	}
-}
-
-static void
-int_handler(int sig_num)
-{
-	printf("Exiting on signal %d\n", sig_num);
-	quit_signal = 1;
-}
-
-/**
- * This thread receives mbufs from the port and affects them an internal
- * sequence number to keep track of their order of arrival through an
- * mbuf structure.
- * The mbufs are then passed to the worker threads via the rx_to_workers
- * ring.
- */
-static int
-rx_thread(struct rte_ring *ring_out)
-{
-	uint32_t seqn = 0;
-	uint16_t i, ret = 0;
-	uint16_t nb_rx_pkts;
-	uint16_t port_id;
-	struct rte_mbuf *pkts[MAX_PKTS_BURST];
-
-	RTE_LOG(INFO, REORDERAPP, "%s() started on lcore %u\n", __func__,
-							rte_lcore_id());
-
-	while (!quit_signal) {
-
-		RTE_ETH_FOREACH_DEV(port_id) {
-			if ((portmask & (1 << port_id)) != 0) {
-
-				/* receive packets */
-				nb_rx_pkts = rte_eth_rx_burst(port_id, 0,
-								pkts, MAX_PKTS_BURST);
-				if (nb_rx_pkts == 0) {
-					RTE_LOG_DP(DEBUG, REORDERAPP,
-					"%s():Received zero packets\n",	__func__);
-					continue;
-				}
-				app_stats.rx.rx_pkts += nb_rx_pkts;
-
-				/* mark sequence number */
-				for (i = 0; i < nb_rx_pkts; )
-					pkts[i++]->seqn = seqn++;
-
-				/* enqueue to rx_to_workers ring */
-				ret = rte_ring_enqueue_burst(ring_out,
-						(void *)pkts, nb_rx_pkts, NULL);
-				app_stats.rx.enqueue_pkts += ret;
-				if (unlikely(ret < nb_rx_pkts)) {
-					app_stats.rx.enqueue_failed_pkts +=
-									(nb_rx_pkts-ret);
-					pktmbuf_free_bulk(&pkts[ret], nb_rx_pkts - ret);
-				}
-			}
-		}
-	}
-	return 0;
-}
-
-/**
- * This thread takes bursts of packets from the rx_to_workers ring and
- * Changes the input port value to output port value. And feds it to
- * workers_to_tx
- */
-static int
-worker_thread(void *args_ptr)
-{
-	const uint8_t nb_ports = rte_eth_dev_count();
-	uint16_t i, ret = 0;
-	uint16_t burst_size = 0;
-	struct worker_thread_args *args;
-	struct rte_mbuf *burst_buffer[MAX_PKTS_BURST] = { NULL };
-	struct rte_ring *ring_in, *ring_out;
-	const unsigned xor_val = (nb_ports > 1);
-
-	args = (struct worker_thread_args *) args_ptr;
-	ring_in  = args->ring_in;
-	ring_out = args->ring_out;
-
-	RTE_LOG(INFO, REORDERAPP, "%s() started on lcore %u\n", __func__,
-							rte_lcore_id());
-
-	while (!quit_signal) {
-
-		/* dequeue the mbufs from rx_to_workers ring */
-		burst_size = rte_ring_dequeue_burst(ring_in,
-				(void *)burst_buffer, MAX_PKTS_BURST, NULL);
-		if (unlikely(burst_size == 0))
-			continue;
-
-		__sync_fetch_and_add(&app_stats.wkr.dequeue_pkts, burst_size);
-
-		/* just do some operation on mbuf */
-		for (i = 0; i < burst_size;)
-			burst_buffer[i++]->port ^= xor_val;
-
-		/* enqueue the modified mbufs to workers_to_tx ring */
-		ret = rte_ring_enqueue_burst(ring_out, (void *)burst_buffer,
-				burst_size, NULL);
-		__sync_fetch_and_add(&app_stats.wkr.enqueue_pkts, ret);
-		if (unlikely(ret < burst_size)) {
-			/* Return the mbufs to their respective pool, dropping packets */
-			__sync_fetch_and_add(&app_stats.wkr.enqueue_failed_pkts,
-					(int)burst_size - ret);
-			pktmbuf_free_bulk(&burst_buffer[ret], burst_size - ret);
-		}
-	}
-	return 0;
-}
-
-/**
- * Dequeue mbufs from the workers_to_tx ring and reorder them before
- * transmitting.
- */
-static int
-send_thread(struct send_thread_args *args)
-{
-	int ret;
-	unsigned int i, dret;
-	uint16_t nb_dq_mbufs;
-	uint8_t outp;
-	unsigned sent;
-	struct rte_mbuf *mbufs[MAX_PKTS_BURST];
-	struct rte_mbuf *rombufs[MAX_PKTS_BURST] = {NULL};
-	static struct rte_eth_dev_tx_buffer *tx_buffer[RTE_MAX_ETHPORTS];
-
-	RTE_LOG(INFO, REORDERAPP, "%s() started on lcore %u\n", __func__, rte_lcore_id());
-
-	configure_tx_buffers(tx_buffer);
-
-	while (!quit_signal) {
-
-		/* deque the mbufs from workers_to_tx ring */
-		nb_dq_mbufs = rte_ring_dequeue_burst(args->ring_in,
-				(void *)mbufs, MAX_PKTS_BURST, NULL);
-
-		if (unlikely(nb_dq_mbufs == 0))
-			continue;
-
-		app_stats.tx.dequeue_pkts += nb_dq_mbufs;
-
-		for (i = 0; i < nb_dq_mbufs; i++) {
-			/* send dequeued mbufs for reordering */
-			ret = rte_reorder_insert(args->buffer, mbufs[i]);
-
-			if (ret == -1 && rte_errno == ERANGE) {
-				/* Too early pkts should be transmitted out directly */
-				RTE_LOG_DP(DEBUG, REORDERAPP,
-						"%s():Cannot reorder early packet "
-						"direct enqueuing to TX\n", __func__);
-				outp = mbufs[i]->port;
-				if ((portmask & (1 << outp)) == 0) {
-					rte_pktmbuf_free(mbufs[i]);
-					continue;
-				}
-				if (rte_eth_tx_burst(outp, 0, (void *)mbufs[i], 1) != 1) {
-					rte_pktmbuf_free(mbufs[i]);
-					app_stats.tx.early_pkts_tx_failed_woro++;
-				} else
-					app_stats.tx.early_pkts_txtd_woro++;
-			} else if (ret == -1 && rte_errno == ENOSPC) {
-				/**
-				 * Early pkts just outside of window should be dropped
-				 */
-				rte_pktmbuf_free(mbufs[i]);
-			}
-		}
-
-		/*
-		 * drain MAX_PKTS_BURST of reordered
-		 * mbufs for transmit
-		 */
-		dret = rte_reorder_drain(args->buffer, rombufs, MAX_PKTS_BURST);
-		for (i = 0; i < dret; i++) {
-
-			struct rte_eth_dev_tx_buffer *outbuf;
-			uint8_t outp1;
-
-			outp1 = rombufs[i]->port;
-			/* skip ports that are not enabled */
-			if ((portmask & (1 << outp1)) == 0) {
-				rte_pktmbuf_free(rombufs[i]);
-				continue;
-			}
-
-			outbuf = tx_buffer[outp1];
-			sent = rte_eth_tx_buffer(outp1, 0, outbuf, rombufs[i]);
-			if (sent)
-				app_stats.tx.ro_tx_pkts += sent;
-		}
-	}
-
-	free_tx_buffers(tx_buffer);
-
-	return 0;
-}
-
-/**
- * Dequeue mbufs from the workers_to_tx ring and transmit them
- */
-static int
-tx_thread(struct rte_ring *ring_in)
-{
-	uint32_t i, dqnum;
-	uint8_t outp;
-	unsigned sent;
-	struct rte_mbuf *mbufs[MAX_PKTS_BURST];
-	struct rte_eth_dev_tx_buffer *outbuf;
-	static struct rte_eth_dev_tx_buffer *tx_buffer[RTE_MAX_ETHPORTS];
-
-	RTE_LOG(INFO, REORDERAPP, "%s() started on lcore %u\n", __func__,
-							rte_lcore_id());
-
-	configure_tx_buffers(tx_buffer);
-
-	while (!quit_signal) {
-
-		/* deque the mbufs from workers_to_tx ring */
-		dqnum = rte_ring_dequeue_burst(ring_in,
-				(void *)mbufs, MAX_PKTS_BURST, NULL);
-
-		if (unlikely(dqnum == 0))
-			continue;
-
-		app_stats.tx.dequeue_pkts += dqnum;
-
-		for (i = 0; i < dqnum; i++) {
-			outp = mbufs[i]->port;
-			/* skip ports that are not enabled */
-			if ((portmask & (1 << outp)) == 0) {
-				rte_pktmbuf_free(mbufs[i]);
-				continue;
-			}
-
-			outbuf = tx_buffer[outp];
-			sent = rte_eth_tx_buffer(outp, 0, outbuf, mbufs[i]);
-			if (sent)
-				app_stats.tx.ro_tx_pkts += sent;
-		}
-	}
-
-	return 0;
-}
-
-int
-main(int argc, char **argv)
-{
-	int ret;
-	unsigned nb_ports;
-	unsigned int lcore_id, last_lcore_id, master_lcore_id;
-	uint16_t port_id;
-	uint16_t nb_ports_available;
-	struct worker_thread_args worker_args = {NULL, NULL};
-	struct send_thread_args send_args = {NULL, NULL};
-	struct rte_ring *rx_to_workers;
-	struct rte_ring *workers_to_tx;
-
-	/* catch ctrl-c so we can print on exit */
-	signal(SIGINT, int_handler);
-
-	/* Initialize EAL */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		return -1;
-
-	argc -= ret;
-	argv += ret;
-
-	/* Parse the application specific arguments */
-	ret = parse_args(argc, argv);
-	if (ret < 0)
-		return -1;
-
-	/* Check if we have enought cores */
-	if (rte_lcore_count() < 3)
-		rte_exit(EXIT_FAILURE, "Error, This application needs at "
-				"least 3 logical cores to run:\n"
-				"1 lcore for packet RX\n"
-				"1 lcore for packet TX\n"
-				"and at least 1 lcore for worker threads\n");
-
-	nb_ports = rte_eth_dev_count();
-	if (nb_ports == 0)
-		rte_exit(EXIT_FAILURE, "Error: no ethernet ports detected\n");
-	if (nb_ports != 1 && (nb_ports & 1))
-		rte_exit(EXIT_FAILURE, "Error: number of ports must be even, except "
-				"when using a single port\n");
-
-	mbuf_pool = rte_pktmbuf_pool_create("mbuf_pool", MBUF_PER_POOL,
-			MBUF_POOL_CACHE_SIZE, 0, RTE_MBUF_DEFAULT_BUF_SIZE,
-			rte_socket_id());
-	if (mbuf_pool == NULL)
-		rte_exit(EXIT_FAILURE, "%s\n", rte_strerror(rte_errno));
-
-	nb_ports_available = nb_ports;
-
-	/* initialize all ports */
-	RTE_ETH_FOREACH_DEV(port_id) {
-		/* skip ports that are not enabled */
-		if ((portmask & (1 << port_id)) == 0) {
-			printf("\nSkipping disabled port %d\n", port_id);
-			nb_ports_available--;
-			continue;
-		}
-		/* init port */
-		printf("Initializing port %u... done\n", port_id);
-
-		if (configure_eth_port(port_id) != 0)
-			rte_exit(EXIT_FAILURE, "Cannot initialize port %"PRIu8"\n",
-					port_id);
-	}
-
-	if (!nb_ports_available) {
-		rte_exit(EXIT_FAILURE,
-			"All available ports are disabled. Please set portmask.\n");
-	}
-
-	/* Create rings for inter core communication */
-	rx_to_workers = rte_ring_create("rx_to_workers", RING_SIZE, rte_socket_id(),
-			RING_F_SP_ENQ);
-	if (rx_to_workers == NULL)
-		rte_exit(EXIT_FAILURE, "%s\n", rte_strerror(rte_errno));
-
-	workers_to_tx = rte_ring_create("workers_to_tx", RING_SIZE, rte_socket_id(),
-			RING_F_SC_DEQ);
-	if (workers_to_tx == NULL)
-		rte_exit(EXIT_FAILURE, "%s\n", rte_strerror(rte_errno));
-
-	if (!disable_reorder) {
-		send_args.buffer = rte_reorder_create("PKT_RO", rte_socket_id(),
-				REORDER_BUFFER_SIZE);
-		if (send_args.buffer == NULL)
-			rte_exit(EXIT_FAILURE, "%s\n", rte_strerror(rte_errno));
-	}
-
-	last_lcore_id   = get_last_lcore_id();
-	master_lcore_id = rte_get_master_lcore();
-
-	worker_args.ring_in  = rx_to_workers;
-	worker_args.ring_out = workers_to_tx;
-
-	/* Start worker_thread() on all the available slave cores but the last 1 */
-	for (lcore_id = 0; lcore_id <= get_previous_lcore_id(last_lcore_id); lcore_id++)
-		if (rte_lcore_is_enabled(lcore_id) && lcore_id != master_lcore_id)
-			rte_eal_remote_launch(worker_thread, (void *)&worker_args,
-					lcore_id);
-
-	if (disable_reorder) {
-		/* Start tx_thread() on the last slave core */
-		rte_eal_remote_launch((lcore_function_t *)tx_thread, workers_to_tx,
-				last_lcore_id);
-	} else {
-		send_args.ring_in = workers_to_tx;
-		/* Start send_thread() on the last slave core */
-		rte_eal_remote_launch((lcore_function_t *)send_thread,
-				(void *)&send_args, last_lcore_id);
-	}
-
-	/* Start rx_thread() on the master core */
-	rx_thread(rx_to_workers);
-
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		if (rte_eal_wait_lcore(lcore_id) < 0)
-			return -1;
-	}
-
-	print_stats();
-	return 0;
-}
diff --git a/examples/packet_ordering/meson.build b/examples/packet_ordering/meson.build
deleted file mode 100644
index a377694..0000000
--- a/examples/packet_ordering/meson.build
+++ /dev/null
@@ -1,13 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-deps += 'reorder'
-allow_experimental_apis = true
-sources = files(
-	'main.c'
-)
diff --git a/examples/performance-thread/Makefile b/examples/performance-thread/Makefile
deleted file mode 100644
index 792ac66..0000000
--- a/examples/performance-thread/Makefile
+++ /dev/null
@@ -1,21 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2015 Intel Corporation
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-ifeq ($(filter y,$(CONFIG_RTE_ARCH_X86_64) $(CONFIG_RTE_ARCH_ARM64)),)
-$(error This application is only supported for x86_64 and arm64 targets)
-endif
-
-DIRS-y += l3fwd-thread
-DIRS-y += pthread_shim
-
-
-include $(RTE_SDK)/mk/rte.extsubdir.mk
diff --git a/examples/performance-thread/common/arch/arm64/ctx.c b/examples/performance-thread/common/arch/arm64/ctx.c
deleted file mode 100644
index 7c5c916..0000000
--- a/examples/performance-thread/common/arch/arm64/ctx.c
+++ /dev/null
@@ -1,62 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2017 Cavium, Inc
- */
-
-#include <rte_common.h>
-#include <ctx.h>
-
-void
-ctx_switch(struct ctx *new_ctx __rte_unused, struct ctx *curr_ctx __rte_unused)
-{
-	/* SAVE CURRENT CONTEXT */
-	asm volatile (
-		/* Save SP */
-		"mov x3, sp\n"
-		"str x3, [x1, #0]\n"
-
-		/* Save FP and LR */
-		"stp x29, x30, [x1, #8]\n"
-
-		/* Save Callee Saved Regs x19 - x28 */
-		"stp x19, x20, [x1, #24]\n"
-		"stp x21, x22, [x1, #40]\n"
-		"stp x23, x24, [x1, #56]\n"
-		"stp x25, x26, [x1, #72]\n"
-		"stp x27, x28, [x1, #88]\n"
-
-		/*
-		 * Save bottom 64-bits of Callee Saved
-		 * SIMD Regs v8 - v15
-		 */
-		"stp d8, d9, [x1, #104]\n"
-		"stp d10, d11, [x1, #120]\n"
-		"stp d12, d13, [x1, #136]\n"
-		"stp d14, d15, [x1, #152]\n"
-	);
-
-	/* RESTORE NEW CONTEXT */
-	asm volatile (
-		/* Restore SP */
-		"ldr x3, [x0, #0]\n"
-		"mov sp, x3\n"
-
-		/* Restore FP and LR */
-		"ldp x29, x30, [x0, #8]\n"
-
-		/* Restore Callee Saved Regs x19 - x28 */
-		"ldp x19, x20, [x0, #24]\n"
-		"ldp x21, x22, [x0, #40]\n"
-		"ldp x23, x24, [x0, #56]\n"
-		"ldp x25, x26, [x0, #72]\n"
-		"ldp x27, x28, [x0, #88]\n"
-
-		/*
-		 * Restore bottom 64-bits of Callee Saved
-		 * SIMD Regs v8 - v15
-		 */
-		"ldp d8, d9, [x0, #104]\n"
-		"ldp d10, d11, [x0, #120]\n"
-		"ldp d12, d13, [x0, #136]\n"
-		"ldp d14, d15, [x0, #152]\n"
-	);
-}
diff --git a/examples/performance-thread/common/arch/arm64/ctx.h b/examples/performance-thread/common/arch/arm64/ctx.h
deleted file mode 100644
index 74c2e7a..0000000
--- a/examples/performance-thread/common/arch/arm64/ctx.h
+++ /dev/null
@@ -1,55 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2017 Cavium, Inc
- */
-
-#ifndef CTX_H
-#define CTX_H
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-/*
- * CPU context registers
- */
-struct ctx {
-	void	*sp;		/* 0  */
-	void	*fp;		/* 8 */
-	void	*lr;		/* 16  */
-
-	/* Callee Saved Generic Registers */
-	void	*r19;		/* 24 */
-	void	*r20;		/* 32 */
-	void	*r21;		/* 40 */
-	void	*r22;		/* 48 */
-	void	*r23;		/* 56 */
-	void	*r24;		/* 64 */
-	void	*r25;		/* 72 */
-	void	*r26;		/* 80 */
-	void	*r27;		/* 88 */
-	void	*r28;		/* 96 */
-
-	/*
-	 * Callee Saved SIMD Registers. Only the bottom 64-bits
-	 * of these registers needs to be saved.
-	 */
-	void	*v8;		/* 104 */
-	void	*v9;		/* 112 */
-	void	*v10;		/* 120 */
-	void	*v11;		/* 128 */
-	void	*v12;		/* 136 */
-	void	*v13;		/* 144 */
-	void	*v14;		/* 152 */
-	void	*v15;		/* 160 */
-};
-
-
-void
-ctx_switch(struct ctx *new_ctx, struct ctx *curr_ctx);
-
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif /* RTE_CTX_H_ */
diff --git a/examples/performance-thread/common/arch/arm64/stack.h b/examples/performance-thread/common/arch/arm64/stack.h
deleted file mode 100644
index 722c473..0000000
--- a/examples/performance-thread/common/arch/arm64/stack.h
+++ /dev/null
@@ -1,56 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2017 Cavium, Inc
- */
-
-#ifndef STACK_H
-#define STACK_H
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-#include "lthread_int.h"
-
-/*
- * Sets up the initial stack for the lthread.
- */
-static inline void
-arch_set_stack(struct lthread *lt, void *func)
-{
-	void **stack_top = (void *)((char *)(lt->stack) + lt->stack_size);
-
-	/*
-	 * Align stack_top to 16 bytes. Arm64 has the constraint that the
-	 * stack pointer must always be quad-word aligned.
-	 */
-	stack_top = (void **)(((unsigned long)(stack_top)) & ~0xfUL);
-
-	/*
-	 * First Stack Frame
-	 */
-	stack_top[0] = NULL;
-	stack_top[-1] = NULL;
-
-	/*
-	 * Initialize the context
-	 */
-	lt->ctx.fp = &stack_top[-1];
-	lt->ctx.sp = &stack_top[-2];
-
-	/*
-	 * Here only the address of _lthread_exec is saved as the link
-	 * register value. The argument to _lthread_exec i.e the address of
-	 * the lthread struct is not saved. This is because the first
-	 * argument to ctx_switch is the address of the new context,
-	 * which also happens to be the address of required lthread struct.
-	 * So while returning from ctx_switch into _thread_exec, parameter
-	 * register x0 will always contain the required value.
-	 */
-	lt->ctx.lr = func;
-}
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif /* STACK_H_ */
diff --git a/examples/performance-thread/common/arch/x86/ctx.c b/examples/performance-thread/common/arch/x86/ctx.c
deleted file mode 100644
index 1e8e271..0000000
--- a/examples/performance-thread/common/arch/x86/ctx.c
+++ /dev/null
@@ -1,93 +0,0 @@
-/*-
- *   BSD LICENSE
- *
- *   Copyright(c) 2015  Intel Corporation. All rights reserved.
- *   All rights reserved.
- *
- *   Redistribution and use in source and binary forms, with or without
- *   modification, are permitted provided that the following conditions
- *   are met:
- *
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above copyright
- *       notice, this list of conditions and the following disclaimer in
- *       the documentation and/or other materials provided with the
- *       distribution.
- *     * Neither the name of Intel Corporation nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * https://github.com/halayli/lthread which carries the following license.
- *
- * Copyright (C) 2012, Hasan Alayli <halayli@gmail.com>
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- * 1. Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- * 2. Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *
- * THIS SOFTWARE IS PROVIDED BY AUTHOR AND CONTRIBUTORS ``AS IS'' AND
- * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
- * ARE DISCLAIMED.  IN NO EVENT SHALL AUTHOR OR CONTRIBUTORS BE LIABLE
- * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
- * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
- * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
- * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
- * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
- * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
- * SUCH DAMAGE.
- */
-
-
-
-#if defined(__x86_64__)
-__asm__ (
-".text\n"
-".p2align 4,,15\n"
-".globl ctx_switch\n"
-".globl _ctx_switch\n"
-"ctx_switch:\n"
-"_ctx_switch:\n"
-"	movq %rsp, 0(%rsi)	# save stack_pointer\n"
-"	movq %rbp, 8(%rsi)	# save frame_pointer\n"
-"	movq (%rsp), %rax	# save insn_pointer\n"
-"	movq %rax, 16(%rsi)\n"
-"	movq %rbx, 24(%rsi)\n	# save rbx,r12-r15\n"
-"	movq 24(%rdi), %rbx\n"
-"	movq %r15, 56(%rsi)\n"
-"	movq %r14, 48(%rsi)\n"
-"	movq 48(%rdi), %r14\n"
-"	movq 56(%rdi), %r15\n"
-"	movq %r13, 40(%rsi)\n"
-"	movq %r12, 32(%rsi)\n"
-"	movq 32(%rdi), %r12\n"
-"	movq 40(%rdi), %r13\n"
-"	movq 0(%rdi), %rsp	# restore stack_pointer\n"
-"	movq 16(%rdi), %rax	# restore insn_pointer\n"
-"	movq 8(%rdi), %rbp	# restore frame_pointer\n"
-"	movq %rax, (%rsp)\n"
-"	ret\n"
-	);
-#else
-#pragma GCC error "__x86_64__ is not defined"
-#endif
diff --git a/examples/performance-thread/common/arch/x86/ctx.h b/examples/performance-thread/common/arch/x86/ctx.h
deleted file mode 100644
index c6a46c5..0000000
--- a/examples/performance-thread/common/arch/x86/ctx.h
+++ /dev/null
@@ -1,36 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2015 Intel Corporation
- */
-
-
-#ifndef CTX_H
-#define CTX_H
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-/*
- * CPU context registers
- */
-struct ctx {
-	void	*rsp;		/* 0  */
-	void	*rbp;		/* 8  */
-	void	*rip;		/* 16 */
-	void	*rbx;		/* 24 */
-	void	*r12;		/* 32 */
-	void	*r13;		/* 40 */
-	void	*r14;		/* 48 */
-	void	*r15;		/* 56 */
-};
-
-
-void
-ctx_switch(struct ctx *new_ctx, struct ctx *curr_ctx);
-
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif /* RTE_CTX_H_ */
diff --git a/examples/performance-thread/common/arch/x86/stack.h b/examples/performance-thread/common/arch/x86/stack.h
deleted file mode 100644
index 7cdd5c7..0000000
--- a/examples/performance-thread/common/arch/x86/stack.h
+++ /dev/null
@@ -1,40 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2015 Intel Corporation.
- * Copyright(c) Cavium, Inc. 2017.
- * All rights reserved
- * Copyright (C) 2012, Hasan Alayli <halayli@gmail.com>
- * Portions derived from: https://github.com/halayli/lthread
- * With permissions from Hasan Alayli to use them as BSD-3-Clause
- */
-
-#ifndef STACK_H
-#define STACK_H
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-#include "lthread_int.h"
-
-/*
- * Sets up the initial stack for the lthread.
- */
-static inline void
-arch_set_stack(struct lthread *lt, void *func)
-{
-	char *stack_top = (char *)(lt->stack) + lt->stack_size;
-	void **s = (void **)stack_top;
-
-	/* set initial context */
-	s[-3] = NULL;
-	s[-2] = (void *)lt;
-	lt->ctx.rsp = (void *)(stack_top - (4 * sizeof(void *)));
-	lt->ctx.rbp = (void *)(stack_top - (3 * sizeof(void *)));
-	lt->ctx.rip = func;
-}
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif /* STACK_H_ */
diff --git a/examples/performance-thread/common/common.mk b/examples/performance-thread/common/common.mk
deleted file mode 100644
index 5e2b18a..0000000
--- a/examples/performance-thread/common/common.mk
+++ /dev/null
@@ -1,21 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2015 Intel Corporation
-
-# list the C files belonging to the lthread subsystem, these are common to all
-# lthread apps. Any makefile including this should set VPATH to include this
-# directory path
-#
-
-MKFILE_PATH=$(abspath $(dir $(lastword $(MAKEFILE_LIST))))
-
-ifeq ($(CONFIG_RTE_ARCH_X86_64),y)
-ARCH_PATH += $(MKFILE_PATH)/arch/x86
-else ifeq ($(CONFIG_RTE_ARCH_ARM64),y)
-ARCH_PATH += $(MKFILE_PATH)/arch/arm64
-endif
-
-VPATH := $(MKFILE_PATH) $(ARCH_PATH)
-
-SRCS-y += lthread.c lthread_sched.c lthread_cond.c lthread_tls.c lthread_mutex.c lthread_diag.c ctx.c
-
-INCLUDES += -I$(MKFILE_PATH) -I$(ARCH_PATH)
diff --git a/examples/performance-thread/common/lthread.c b/examples/performance-thread/common/lthread.c
deleted file mode 100644
index 0b60a42..0000000
--- a/examples/performance-thread/common/lthread.c
+++ /dev/null
@@ -1,523 +0,0 @@
-/*-
- *   BSD LICENSE
- *
- *   Copyright(c) 2015 Intel Corporation. All rights reserved.
- *   All rights reserved.
- *
- *   Redistribution and use in source and binary forms, with or without
- *   modification, are permitted provided that the following conditions
- *   are met:
- *
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above copyright
- *       notice, this list of conditions and the following disclaimer in
- *       the documentation and/or other materials provided with the
- *       distribution.
- *     * Neither the name of Intel Corporation nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * Some portions of this software is derived from the
- * https://github.com/halayli/lthread which carrys the following license.
- *
- * Copyright (C) 2012, Hasan Alayli <halayli@gmail.com>
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- * 1. Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- * 2. Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *
- * THIS SOFTWARE IS PROVIDED BY AUTHOR AND CONTRIBUTORS ``AS IS'' AND
- * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
- * ARE DISCLAIMED.  IN NO EVENT SHALL AUTHOR OR CONTRIBUTORS BE LIABLE
- * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
- * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
- * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
- * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
- * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
- * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
- * SUCH DAMAGE.
- */
-
-#define RTE_MEM 1
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <string.h>
-#include <stdint.h>
-#include <stddef.h>
-#include <limits.h>
-#include <inttypes.h>
-#include <unistd.h>
-#include <pthread.h>
-#include <fcntl.h>
-#include <sys/time.h>
-#include <sys/mman.h>
-
-#include <rte_log.h>
-#include <ctx.h>
-#include <stack.h>
-
-#include "lthread_api.h"
-#include "lthread.h"
-#include "lthread_timer.h"
-#include "lthread_tls.h"
-#include "lthread_objcache.h"
-#include "lthread_diag.h"
-
-
-/*
- * This function gets called after an lthread function has returned.
- */
-void _lthread_exit_handler(struct lthread *lt)
-{
-
-	lt->state |= BIT(ST_LT_EXITED);
-
-	if (!(lt->state & BIT(ST_LT_DETACH))) {
-		/* thread is this not explicitly detached
-		 * it must be joinable, so we call lthread_exit().
-		 */
-		lthread_exit(NULL);
-	}
-
-	/* if we get here the thread is detached so we can reschedule it,
-	 * allowing the scheduler to free it
-	 */
-	_reschedule();
-}
-
-
-/*
- * Free resources allocated to an lthread
- */
-void _lthread_free(struct lthread *lt)
-{
-
-	DIAG_EVENT(lt, LT_DIAG_LTHREAD_FREE, lt, 0);
-
-	/* invoke any user TLS destructor functions */
-	_lthread_tls_destroy(lt);
-
-	/* free memory allocated for TLS defined using RTE_PER_LTHREAD macros */
-	if (sizeof(void *) < (uint64_t)RTE_PER_LTHREAD_SECTION_SIZE)
-		_lthread_objcache_free(lt->tls->root_sched->per_lthread_cache,
-					lt->per_lthread_data);
-
-	/* free pthread style TLS memory */
-	_lthread_objcache_free(lt->tls->root_sched->tls_cache, lt->tls);
-
-	/* free the stack */
-	_lthread_objcache_free(lt->stack_container->root_sched->stack_cache,
-				lt->stack_container);
-
-	/* now free the thread */
-	_lthread_objcache_free(lt->root_sched->lthread_cache, lt);
-
-}
-
-/*
- * Allocate a stack and maintain a cache of stacks
- */
-struct lthread_stack *_stack_alloc(void)
-{
-	struct lthread_stack *s;
-
-	s = _lthread_objcache_alloc((THIS_SCHED)->stack_cache);
-	RTE_ASSERT(s != NULL);
-
-	s->root_sched = THIS_SCHED;
-	s->stack_size = LTHREAD_MAX_STACK_SIZE;
-	return s;
-}
-
-/*
- * Execute a ctx by invoking the start function
- * On return call an exit handler if the user has provided one
- */
-static void _lthread_exec(void *arg)
-{
-	struct lthread *lt = (struct lthread *)arg;
-
-	/* invoke the contexts function */
-	lt->fun(lt->arg);
-	/* do exit handling */
-	if (lt->exit_handler != NULL)
-		lt->exit_handler(lt);
-}
-
-/*
- *	Initialize an lthread
- *	Set its function, args, and exit handler
- */
-void
-_lthread_init(struct lthread *lt,
-	lthread_func_t fun, void *arg, lthread_exit_func exit_handler)
-{
-
-	/* set ctx func and args */
-	lt->fun = fun;
-	lt->arg = arg;
-	lt->exit_handler = exit_handler;
-
-	/* set initial state */
-	lt->birth = _sched_now();
-	lt->state = BIT(ST_LT_INIT);
-	lt->join = LT_JOIN_INITIAL;
-}
-
-/*
- *	set the lthread stack
- */
-void _lthread_set_stack(struct lthread *lt, void *stack, size_t stack_size)
-{
-	/* set stack */
-	lt->stack = stack;
-	lt->stack_size = stack_size;
-
-	arch_set_stack(lt, _lthread_exec);
-}
-
-/*
- * Create an lthread on the current scheduler
- * If there is no current scheduler on this pthread then first create one
- */
-int
-lthread_create(struct lthread **new_lt, int lcore_id,
-		lthread_func_t fun, void *arg)
-{
-	if ((new_lt == NULL) || (fun == NULL))
-		return POSIX_ERRNO(EINVAL);
-
-	if (lcore_id < 0)
-		lcore_id = rte_lcore_id();
-	else if (lcore_id > LTHREAD_MAX_LCORES)
-		return POSIX_ERRNO(EINVAL);
-
-	struct lthread *lt = NULL;
-
-	if (THIS_SCHED == NULL) {
-		THIS_SCHED = _lthread_sched_create(0);
-		if (THIS_SCHED == NULL) {
-			perror("Failed to create scheduler");
-			return POSIX_ERRNO(EAGAIN);
-		}
-	}
-
-	/* allocate a thread structure */
-	lt = _lthread_objcache_alloc((THIS_SCHED)->lthread_cache);
-	if (lt == NULL)
-		return POSIX_ERRNO(EAGAIN);
-
-	bzero(lt, sizeof(struct lthread));
-	lt->root_sched = THIS_SCHED;
-
-	/* set the function args and exit handlder */
-	_lthread_init(lt, fun, arg, _lthread_exit_handler);
-
-	/* put it in the ready queue */
-	*new_lt = lt;
-
-	if (lcore_id < 0)
-		lcore_id = rte_lcore_id();
-
-	DIAG_CREATE_EVENT(lt, LT_DIAG_LTHREAD_CREATE);
-
-	rte_wmb();
-	_ready_queue_insert(_lthread_sched_get(lcore_id), lt);
-	return 0;
-}
-
-/*
- * Schedules lthread to sleep for `nsecs`
- * setting the lthread state to LT_ST_SLEEPING.
- * lthread state is cleared upon resumption or expiry.
- */
-static inline void _lthread_sched_sleep(struct lthread *lt, uint64_t nsecs)
-{
-	uint64_t state = lt->state;
-	uint64_t clks = _ns_to_clks(nsecs);
-
-	if (clks) {
-		_timer_start(lt, clks);
-		lt->state = state | BIT(ST_LT_SLEEPING);
-	}
-	DIAG_EVENT(lt, LT_DIAG_LTHREAD_SLEEP, clks, 0);
-	_suspend();
-}
-
-
-
-/*
- * Cancels any running timer.
- * This can be called multiple times on the same lthread regardless if it was
- * sleeping or not.
- */
-int _lthread_desched_sleep(struct lthread *lt)
-{
-	uint64_t state = lt->state;
-
-	if (state & BIT(ST_LT_SLEEPING)) {
-		_timer_stop(lt);
-		state &= (CLEARBIT(ST_LT_SLEEPING) & CLEARBIT(ST_LT_EXPIRED));
-		lt->state = state | BIT(ST_LT_READY);
-		return 1;
-	}
-	return 0;
-}
-
-/*
- * set user data pointer in an lthread
- */
-void lthread_set_data(void *data)
-{
-	if (sizeof(void *) == RTE_PER_LTHREAD_SECTION_SIZE)
-		THIS_LTHREAD->per_lthread_data = data;
-}
-
-/*
- * Retrieve user data pointer from an lthread
- */
-void *lthread_get_data(void)
-{
-	return THIS_LTHREAD->per_lthread_data;
-}
-
-/*
- * Return the current lthread handle
- */
-struct lthread *lthread_current(void)
-{
-	struct lthread_sched *sched = THIS_SCHED;
-
-	if (sched)
-		return sched->current_lthread;
-	return NULL;
-}
-
-
-
-/*
- * Tasklet to cancel a thread
- */
-static void *
-_cancel(void *arg)
-{
-	struct lthread *lt = (struct lthread *) arg;
-
-	lt->state |= BIT(ST_LT_CANCELLED);
-	lthread_detach();
-	return NULL;
-}
-
-
-/*
- * Mark the specified as canceled
- */
-int lthread_cancel(struct lthread *cancel_lt)
-{
-	struct lthread *lt;
-
-	if ((cancel_lt == NULL) || (cancel_lt == THIS_LTHREAD))
-		return POSIX_ERRNO(EINVAL);
-
-	DIAG_EVENT(cancel_lt, LT_DIAG_LTHREAD_CANCEL, cancel_lt, 0);
-
-	if (cancel_lt->sched != THIS_SCHED) {
-
-		/* spawn task-let to cancel the thread */
-		lthread_create(&lt,
-				cancel_lt->sched->lcore_id,
-				_cancel,
-				cancel_lt);
-		return 0;
-	}
-	cancel_lt->state |= BIT(ST_LT_CANCELLED);
-	return 0;
-}
-
-/*
- * Suspend the current lthread for specified time
- */
-void lthread_sleep(uint64_t nsecs)
-{
-	struct lthread *lt = THIS_LTHREAD;
-
-	_lthread_sched_sleep(lt, nsecs);
-
-}
-
-/*
- * Suspend the current lthread for specified time
- */
-void lthread_sleep_clks(uint64_t clks)
-{
-	struct lthread *lt = THIS_LTHREAD;
-	uint64_t state = lt->state;
-
-	if (clks) {
-		_timer_start(lt, clks);
-		lt->state = state | BIT(ST_LT_SLEEPING);
-	}
-	DIAG_EVENT(lt, LT_DIAG_LTHREAD_SLEEP, clks, 0);
-	_suspend();
-}
-
-/*
- * Requeue the current thread to the back of the ready queue
- */
-void lthread_yield(void)
-{
-	struct lthread *lt = THIS_LTHREAD;
-
-	DIAG_EVENT(lt, LT_DIAG_LTHREAD_YIELD, 0, 0);
-
-	_ready_queue_insert(THIS_SCHED, lt);
-	ctx_switch(&(THIS_SCHED)->ctx, &lt->ctx);
-}
-
-/*
- * Exit the current lthread
- * If a thread is joining pass the user pointer to it
- */
-void lthread_exit(void *ptr)
-{
-	struct lthread *lt = THIS_LTHREAD;
-
-	/* if thread is detached (this is not valid) just exit */
-	if (lt->state & BIT(ST_LT_DETACH))
-		return;
-
-	/* There is a race between lthread_join() and lthread_exit()
-	 *  - if exit before join then we suspend and resume on join
-	 *  - if join before exit then we resume the joining thread
-	 */
-	if ((lt->join == LT_JOIN_INITIAL)
-	    && rte_atomic64_cmpset(&lt->join, LT_JOIN_INITIAL,
-				   LT_JOIN_EXITING)) {
-
-		DIAG_EVENT(lt, LT_DIAG_LTHREAD_EXIT, 1, 0);
-		_suspend();
-		/* set the exit value */
-		if ((ptr != NULL) && (lt->lt_join->lt_exit_ptr != NULL))
-			*(lt->lt_join->lt_exit_ptr) = ptr;
-
-		/* let the joining thread know we have set the exit value */
-		lt->join = LT_JOIN_EXIT_VAL_SET;
-	} else {
-
-		DIAG_EVENT(lt, LT_DIAG_LTHREAD_EXIT, 0, 0);
-		/* set the exit value */
-		if ((ptr != NULL) && (lt->lt_join->lt_exit_ptr != NULL))
-			*(lt->lt_join->lt_exit_ptr) = ptr;
-		/* let the joining thread know we have set the exit value */
-		lt->join = LT_JOIN_EXIT_VAL_SET;
-		_ready_queue_insert(lt->lt_join->sched,
-				    (struct lthread *)lt->lt_join);
-	}
-
-
-	/* wait until the joinging thread has collected the exit value */
-	while (lt->join != LT_JOIN_EXIT_VAL_READ)
-		_reschedule();
-
-	/* reset join state */
-	lt->join = LT_JOIN_INITIAL;
-
-	/* detach it so its resources can be released */
-	lt->state |= (BIT(ST_LT_DETACH) | BIT(ST_LT_EXITED));
-}
-
-/*
- * Join an lthread
- * Suspend until the joined thread returns
- */
-int lthread_join(struct lthread *lt, void **ptr)
-{
-	if (lt == NULL)
-		return POSIX_ERRNO(EINVAL);
-
-	struct lthread *current = THIS_LTHREAD;
-	uint64_t lt_state = lt->state;
-
-	/* invalid to join a detached thread, or a thread that is joined */
-	if ((lt_state & BIT(ST_LT_DETACH)) || (lt->join == LT_JOIN_THREAD_SET))
-		return POSIX_ERRNO(EINVAL);
-	/* pointer to the joining thread and a poingter to return a value */
-	lt->lt_join = current;
-	current->lt_exit_ptr = ptr;
-	/* There is a race between lthread_join() and lthread_exit()
-	 *  - if join before exit we suspend and will resume when exit is called
-	 *  - if exit before join we resume the exiting thread
-	 */
-	if ((lt->join == LT_JOIN_INITIAL)
-	    && rte_atomic64_cmpset(&lt->join, LT_JOIN_INITIAL,
-				   LT_JOIN_THREAD_SET)) {
-
-		DIAG_EVENT(current, LT_DIAG_LTHREAD_JOIN, lt, 1);
-		_suspend();
-	} else {
-		DIAG_EVENT(current, LT_DIAG_LTHREAD_JOIN, lt, 0);
-		_ready_queue_insert(lt->sched, lt);
-	}
-
-	/* wait for exiting thread to set return value */
-	while (lt->join != LT_JOIN_EXIT_VAL_SET)
-		_reschedule();
-
-	/* collect the return value */
-	if (ptr != NULL)
-		*ptr = *current->lt_exit_ptr;
-
-	/* let the exiting thread proceed to exit */
-	lt->join = LT_JOIN_EXIT_VAL_READ;
-	return 0;
-}
-
-
-/*
- * Detach current lthread
- * A detached thread cannot be joined
- */
-void lthread_detach(void)
-{
-	struct lthread *lt = THIS_LTHREAD;
-
-	DIAG_EVENT(lt, LT_DIAG_LTHREAD_DETACH, 0, 0);
-
-	uint64_t state = lt->state;
-
-	lt->state = state | BIT(ST_LT_DETACH);
-}
-
-/*
- * Set function name of an lthread
- * this is a debug aid
- */
-void lthread_set_funcname(const char *f)
-{
-	struct lthread *lt = THIS_LTHREAD;
-
-	strncpy(lt->funcname, f, sizeof(lt->funcname));
-	lt->funcname[sizeof(lt->funcname)-1] = 0;
-}
diff --git a/examples/performance-thread/common/lthread.h b/examples/performance-thread/common/lthread.h
deleted file mode 100644
index 0cde591..0000000
--- a/examples/performance-thread/common/lthread.h
+++ /dev/null
@@ -1,107 +0,0 @@
-/*-
- *   BSD LICENSE
- *
- *   Copyright(c) 2015 Intel Corporation. All rights reserved.
- *   All rights reserved.
- *
- *   Redistribution and use in source and binary forms, with or without
- *   modification, are permitted provided that the following conditions
- *   are met:
- *
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above copyright
- *       notice, this list of conditions and the following disclaimer in
- *       the documentation and/or other materials provided with the
- *       distribution.
- *     * Neither the name of Intel Corporation nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * Some portions of this software is derived from the
- * https://github.com/halayli/lthread which carrys the following license.
- *
- * Copyright (C) 2012, Hasan Alayli <halayli@gmail.com>
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- * 1. Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- * 2. Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *
- * THIS SOFTWARE IS PROVIDED BY AUTHOR AND CONTRIBUTORS ``AS IS'' AND
- * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
- * ARE DISCLAIMED.  IN NO EVENT SHALL AUTHOR OR CONTRIBUTORS BE LIABLE
- * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
- * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
- * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
- * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
- * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
- * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
- * SUCH DAMAGE.
- */
-
-#ifndef LTHREAD_H_
-#define LTHREAD_H_
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-#include <rte_per_lcore.h>
-
-#include "lthread_api.h"
-#include "lthread_diag.h"
-
-struct lthread;
-struct lthread_sched;
-
-/* function to be called when a context function returns */
-typedef void (*lthread_exit_func) (struct lthread *);
-
-void _lthread_exit_handler(struct lthread *lt);
-
-void lthread_set_funcname(const char *f);
-
-void _lthread_sched_busy_sleep(struct lthread *lt, uint64_t nsecs);
-
-int _lthread_desched_sleep(struct lthread *lt);
-
-void _lthread_free(struct lthread *lt);
-
-struct lthread_sched *_lthread_sched_get(unsigned int lcore_id);
-
-struct lthread_stack *_stack_alloc(void);
-
-struct
-lthread_sched *_lthread_sched_create(size_t stack_size);
-
-void
-_lthread_init(struct lthread *lt,
-	      lthread_func_t fun, void *arg, lthread_exit_func exit_handler);
-
-void _lthread_set_stack(struct lthread *lt, void *stack, size_t stack_size);
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif				/* LTHREAD_H_ */
diff --git a/examples/performance-thread/common/lthread_api.h b/examples/performance-thread/common/lthread_api.h
deleted file mode 100644
index a74680b..0000000
--- a/examples/performance-thread/common/lthread_api.h
+++ /dev/null
@@ -1,840 +0,0 @@
-/*-
- *   BSD LICENSE
- *
- *   Copyright(c) 2015 Intel Corporation. All rights reserved.
- *   All rights reserved.
- *
- *   Redistribution and use in source and binary forms, with or without
- *   modification, are permitted provided that the following conditions
- *   are met:
- *
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above copyright
- *       notice, this list of conditions and the following disclaimer in
- *       the documentation and/or other materials provided with the
- *       distribution.
- *     * Neither the name of Intel Corporation nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * Some portions of this software may have been derived from the
- * https://github.com/halayli/lthread which carrys the following license.
- *
- * Copyright (C) 2012, Hasan Alayli <halayli@gmail.com>
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- * 1. Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- * 2. Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *
- * THIS SOFTWARE IS PROVIDED BY AUTHOR AND CONTRIBUTORS ``AS IS'' AND
- * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
- * ARE DISCLAIMED.  IN NO EVENT SHALL AUTHOR OR CONTRIBUTORS BE LIABLE
- * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
- * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
- * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
- * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
- * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
- * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
- * SUCH DAMAGE.
- */
-
-/**
- *  @file lthread_api.h
- *
- *  @warning
- *  @b EXPERIMENTAL: this API may change without prior notice
- *
- *  This file contains the public API for the L-thread subsystem
- *
- *  The L_thread subsystem provides a simple cooperative scheduler to
- *  enable arbitrary functions to run as cooperative threads within a
- * single P-thread.
- *
- * The subsystem provides a P-thread like API that is intended to assist in
- * reuse of legacy code written for POSIX p_threads.
- *
- * The L-thread subsystem relies on cooperative multitasking, as such
- * an L-thread must possess frequent rescheduling points. Often these
- * rescheduling points are provided transparently when the application
- * invokes an L-thread API.
- *
- * In some applications it is possible that the program may enter a loop the
- * exit condition for which depends on the action of another thread or a
- * response from hardware. In such a case it is necessary to yield the thread
- * periodically in the loop body, to allow other threads an opportunity to
- * run. This can be done by inserting a call to lthread_yield() or
- * lthread_sleep(n) in the body of the loop.
- *
- * If the application makes expensive / blocking system calls or does other
- * work that would take an inordinate amount of time to complete, this will
- * stall the cooperative scheduler resulting in very poor performance.
- *
- * In such cases an L-thread can be migrated temporarily to another scheduler
- * running in a different P-thread on another core. When the expensive or
- * blocking operation is completed it can be migrated back to the original
- * scheduler.  In this way other threads can continue to run on the original
- * scheduler and will be completely unaffected by the blocking behaviour.
- * To migrate an L-thread to another scheduler the API lthread_set_affinity()
- * is provided.
- *
- * If L-threads that share data are running on the same core it is possible
- * to design programs where mutual exclusion mechanisms to protect shared data
- * can be avoided. This is due to the fact that the cooperative threads cannot
- * preempt each other.
- *
- * There are two cases where mutual exclusion mechanisms are necessary.
- *
- *  a) Where the L-threads sharing data are running on different cores.
- *  b) Where code must yield while updating data shared with another thread.
- *
- * The L-thread subsystem provides a set of mutex APIs to help with such
- * scenarios, however excessive reliance on on these will impact performance
- * and is best avoided if possible.
- *
- * L-threads can synchronise using a fast condition variable implementation
- * that supports signal and broadcast. An L-thread running on any core can
- * wait on a condition.
- *
- * L-threads can have L-thread local storage with an API modelled on either the
- * P-thread get/set specific API or using PER_LTHREAD macros modelled on the
- * RTE_PER_LCORE macros. Alternatively a simple user data pointer may be set
- * and retrieved from a thread.
- */
-#ifndef LTHREAD_H
-#define LTHREAD_H
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-#include <stdint.h>
-#include <sys/socket.h>
-#include <fcntl.h>
-#include <netinet/in.h>
-
-#include <rte_cycles.h>
-
-
-struct lthread;
-struct lthread_cond;
-struct lthread_mutex;
-
-struct lthread_condattr;
-struct lthread_mutexattr;
-
-typedef void *(*lthread_func_t) (void *);
-
-/*
- * Define the size of stack for an lthread
- * Then this is the size that will be allocated on lthread creation
- * This is a fixed size and will not grow.
- */
-#define LTHREAD_MAX_STACK_SIZE (1024*64)
-
-/**
- * Define the maximum number of TLS keys that can be created
- *
- */
-#define LTHREAD_MAX_KEYS 1024
-
-/**
- * Define the maximum number of attempts to destroy an lthread's
- * TLS data on thread exit
- */
-#define LTHREAD_DESTRUCTOR_ITERATIONS 4
-
-
-/**
- * Define the maximum number of lcores that will support lthreads
- */
-#define LTHREAD_MAX_LCORES RTE_MAX_LCORE
-
-/**
- * How many lthread objects to pre-allocate as the system grows
- * applies to lthreads + stacks, TLS, mutexs, cond vars.
- *
- * @see _lthread_alloc()
- * @see _cond_alloc()
- * @see _mutex_alloc()
- *
- */
-#define LTHREAD_PREALLOC 100
-
-/**
- * Set the number of schedulers in the system.
- *
- * This function may optionally be called before starting schedulers.
- *
- * If the number of schedulers is not set, or set to 0 then each scheduler
- * will begin scheduling lthreads immediately it is started.
-
- * If the number of schedulers is set to greater than 0, then each scheduler
- * will wait until all schedulers have started before beginning to schedule
- * lthreads.
- *
- * If an application wishes to have threads migrate between cores using
- * lthread_set_affinity(), or join threads running on other cores using
- * lthread_join(), then it is prudent to set the number of schedulers to ensure
- * that all schedulers are initialised beforehand.
- *
- * @param num
- *  the number of schedulers in the system
- * @return
- * the number of schedulers in the system
- */
-int lthread_num_schedulers_set(int num);
-
-/**
- * Return the number of schedulers currently running
- * @return
- *  the number of schedulers in the system
- */
-int lthread_active_schedulers(void);
-
-/**
-  * Shutdown the specified scheduler
-  *
-  *  This function tells the specified scheduler to
-  *  exit if/when there is no more work to do.
-  *
-  *  Note that although the scheduler will stop
-  *  resources are not freed.
-  *
-  * @param lcore
-  *	The lcore of the scheduler to shutdown
-  *
-  * @return
-  *  none
-  */
-void lthread_scheduler_shutdown(unsigned lcore);
-
-/**
-  * Shutdown all schedulers
-  *
-  *  This function tells all schedulers  including the current scheduler to
-  *  exit if/when there is no more work to do.
-  *
-  *  Note that although the schedulers will stop
-  *  resources are not freed.
-  *
-  * @return
-  *  none
-  */
-void lthread_scheduler_shutdown_all(void);
-
-/**
-  * Run the lthread scheduler
-  *
-  *  Runs the lthread scheduler.
-  *  This function returns only if/when all lthreads have exited.
-  *  This function must be the main loop of an EAL thread.
-  *
-  * @return
-  *	 none
-  */
-
-void lthread_run(void);
-
-/**
-  * Create an lthread
-  *
-  *  Creates an lthread and places it in the ready queue on a particular
-  *  lcore.
-  *
-  *  If no scheduler exists yet on the curret lcore then one is created.
-  *
-  * @param new_lt
-  *  Pointer to an lthread pointer that will be initialized
-  * @param lcore
-  *  the lcore the thread should be started on or the current clore
-  *    -1 the current lcore
-  *    0 - LTHREAD_MAX_LCORES any other lcore
-  * @param lthread_func
-  *  Pointer to the function the for the thread to run
-  * @param arg
-  *  Pointer to args that will be passed to the thread
-  *
-  * @return
-  *	 0    success
-  *	 EAGAIN  no resources available
-  *	 EINVAL  NULL thread or function pointer, or lcore_id out of range
-  */
-int
-lthread_create(struct lthread **new_lt,
-		int lcore, lthread_func_t func, void *arg);
-
-/**
-  * Cancel an lthread
-  *
-  *  Cancels an lthread and causes it to be terminated
-  *  If the lthread is detached it will be freed immediately
-  *  otherwise its resources will not be released until it is joined.
-  *
-  * @param new_lt
-  *  Pointer to an lthread that will be cancelled
-  *
-  * @return
-  *	 0    success
-  *	 EINVAL  thread was NULL
-  */
-int lthread_cancel(struct lthread *lt);
-
-/**
-  * Join an lthread
-  *
-  *  Joins the current thread with the specified lthread, and waits for that
-  *  thread to exit.
-  *  Passes an optional pointer to collect returned data.
-  *
-  * @param lt
-  *  Pointer to the lthread to be joined
-  * @param ptr
-  *  Pointer to pointer to collect returned data
-  *
-0  * @return
-  *  0    success
-  *  EINVAL lthread could not be joined.
-  */
-int lthread_join(struct lthread *lt, void **ptr);
-
-/**
-  * Detach an lthread
-  *
-  * Detaches the current thread
-  * On exit a detached lthread will be freed immediately and will not wait
-  * to be joined. The default state for a thread is not detached.
-  *
-  * @return
-  *  none
-  */
-void lthread_detach(void);
-
-/**
-  *  Exit an lthread
-  *
-  * Terminate the current thread, optionally return data.
-  * The data may be collected by lthread_join()
-  *
-  * After calling this function the lthread will be suspended until it is
-  * joined. After it is joined then its resources will be freed.
-  *
-  * @param ptr
-  *  Pointer to pointer to data to be returned
-  *
-  * @return
-  *  none
-  */
-void lthread_exit(void *val);
-
-/**
-  * Cause the current lthread to sleep for n nanoseconds
-  *
-  * The current thread will be suspended until the specified time has elapsed
-  * or has been exceeded.
-  *
-  * Execution will switch to the next lthread that is ready to run
-  *
-  * @param nsecs
-  *  Number of nanoseconds to sleep
-  *
-  * @return
-  *  none
-  */
-void lthread_sleep(uint64_t nsecs);
-
-/**
-  * Cause the current lthread to sleep for n cpu clock ticks
-  *
-  *  The current thread will be suspended until the specified time has elapsed
-  *  or has been exceeded.
-  *
-  *	 Execution will switch to the next lthread that is ready to run
-  *
-  * @param clks
-  *  Number of clock ticks to sleep
-  *
-  * @return
-  *  none
-  */
-void lthread_sleep_clks(uint64_t clks);
-
-/**
-  * Yield the current lthread
-  *
-  *  The current thread will yield and execution will switch to the
-  *  next lthread that is ready to run
-  *
-  * @return
-  *  none
-  */
-void lthread_yield(void);
-
-/**
-  * Migrate the current thread to another scheduler
-  *
-  *  This function migrates the current thread to another scheduler.
-  *  Execution will switch to the next lthread that is ready to run on the
-  *  current scheduler. The current thread will be resumed on the new scheduler.
-  *
-  * @param lcore
-  *	The lcore to migrate to
-  *
-  * @return
-  *  0   success we are now running on the specified core
-  *  EINVAL the destination lcore was not valid
-  */
-int lthread_set_affinity(unsigned lcore);
-
-/**
-  * Return the current lthread
-  *
-  *  Returns the current lthread
-  *
-  * @return
-  *  pointer to the current lthread
-  */
-struct lthread
-*lthread_current(void);
-
-/**
-  * Associate user data with an lthread
-  *
-  *  This function sets a user data pointer in the current lthread
-  *  The pointer can be retrieved with lthread_get_data()
-  *  It is the users responsibility to allocate and free any data referenced
-  *  by the user pointer.
-  *
-  * @param data
-  *  pointer to user data
-  *
-  * @return
-  *  none
-  */
-void lthread_set_data(void *data);
-
-/**
-  * Get user data for the current lthread
-  *
-  *  This function returns a user data pointer for the current lthread
-  *  The pointer must first be set with lthread_set_data()
-  *  It is the users responsibility to allocate and free any data referenced
-  *  by the user pointer.
-  *
-  * @return
-  *  pointer to user data
-  */
-void
-*lthread_get_data(void);
-
-struct lthread_key;
-typedef void (*tls_destructor_func) (void *);
-
-/**
-  * Create a key for lthread TLS
-  *
-  *  This function is modelled on pthread_key_create
-  *  It creates a thread-specific data key visible to all lthreads on the
-  *  current scheduler.
-  *
-  *  Key values may be used to locate thread-specific data.
-  *  The same key value	may be used by different threads, the values bound
-  *  to the key by	lthread_setspecific() are maintained on	a per-thread
-  *  basis and persist for the life of the calling thread.
-  *
-  *  An	optional destructor function may be associated with each key value.
-  *  At	thread exit, if	a key value has	a non-NULL destructor pointer, and the
-  *  thread has	a non-NULL value associated with the key, the function pointed
-  *  to	is called with the current associated value as its sole	argument.
-  *
-  * @param key
-  *   Pointer to the key to be created
-  * @param destructor
-  *   Pointer to destructor function
-  *
-  * @return
-  *  0 success
-  *  EINVAL the key ptr was NULL
-  *  EAGAIN no resources available
-  */
-int lthread_key_create(unsigned int *key, tls_destructor_func destructor);
-
-/**
-  * Delete key for lthread TLS
-  *
-  *  This function is modelled on pthread_key_delete().
-  *  It deletes a thread-specific data key previously returned by
-  *  lthread_key_create().
-  *  The thread-specific data values associated with the key need not be NULL
-  *  at the time that lthread_key_delete is called.
-  *  It is the responsibility of the application to free any application
-  *  storage or perform any cleanup actions for data structures related to the
-  *  deleted key. This cleanup can be done either before or after
-  * lthread_key_delete is called.
-  *
-  * @param key
-  *  The key to be deleted
-  *
-  * @return
-  *  0 Success
-  *  EINVAL the key was invalid
-  */
-int lthread_key_delete(unsigned int key);
-
-/**
-  * Get lthread TLS
-  *
-  *  This function is modelled on pthread_get_specific().
-  *  It returns the value currently bound to the specified key on behalf of the
-  *  calling thread. Calling lthread_getspecific() with a key value not
-  *  obtained from lthread_key_create() or after key has been deleted with
-  *  lthread_key_delete() will result in undefined behaviour.
-  *  lthread_getspecific() may be called from a thread-specific data destructor
-  *  function.
-  *
-  * @param key
-  *  The key for which data is requested
-  *
-  * @return
-  *  Pointer to the thread specific data associated with that key
-  *  or NULL if no data has been set.
-  */
-void
-*lthread_getspecific(unsigned int key);
-
-/**
-  * Set lthread TLS
-  *
-  *  This function is modelled on pthread_set_sepcific()
-  *  It associates a thread-specific value with a key obtained via a previous
-  *  call to lthread_key_create().
-  *  Different threads may bind different values to the same key. These values
-  *  are typically pointers to dynamically allocated memory that have been
-  *  reserved by the calling thread. Calling lthread_setspecific with a key
-  *  value not obtained from lthread_key_create or after the key has been
-  *  deleted with lthread_key_delete will result in undefined behaviour.
-  *
-  * @param key
-  *  The key for which data is to be set
-  * @param key
-  *  Pointer to the user data
-  *
-  * @return
-  *  0 success
-  *  EINVAL the key was invalid
-  */
-
-int lthread_setspecific(unsigned int key, const void *value);
-
-/**
- * The macros below provide an alternative mechanism to access lthread local
- *  storage.
- *
- * The macros can be used to declare define and access per lthread local
- * storage in a similar way to the RTE_PER_LCORE macros which control storage
- * local to an lcore.
- *
- * Memory for per lthread variables declared in this way is allocated when the
- * lthread is created and a pointer to this memory is stored in the lthread.
- * The per lthread variables are accessed via the pointer + the offset of the
- * particular variable.
- *
- * The total size of per lthread storage, and the variable offsets are found by
- * defining the variables in a unique global memory section, the start and end
- * of which is known. This global memory section is used only in the
- * computation of the addresses of the lthread variables, and is never actually
- * used to store any data.
- *
- * Due to the fact that variables declared this way may be scattered across
- * many files, the start and end of the section and variable offsets are only
- * known after linking, thus the computation of section size and variable
- * addresses is performed at run time.
- *
- * These macros are primarily provided to aid porting of code that makes use
- * of the existing RTE_PER_LCORE macros. In principle it would be more efficient
- * to gather all lthread local variables into a single structure and
- * set/retrieve a pointer to that struct using the alternative
- * lthread_data_set/get APIs.
- *
- * These macros are mutually exclusive with the lthread_data_set/get APIs.
- * If you define storage using these macros then the lthread_data_set/get APIs
- * will not perform as expected, the lthread_data_set API does nothing, and the
- * lthread_data_get API returns the start of global section.
- *
- */
-/* start and end of per lthread section */
-extern char __start_per_lt;
-extern char __stop_per_lt;
-
-
-#define RTE_DEFINE_PER_LTHREAD(type, name)                      \
-__typeof__(type)__attribute((section("per_lt"))) per_lt_##name
-
-/**
- * Macro to declare an extern per lthread variable "var" of type "type"
- */
-#define RTE_DECLARE_PER_LTHREAD(type, name)                     \
-extern __typeof__(type)__attribute((section("per_lt"))) per_lt_##name
-
-/**
- * Read/write the per-lcore variable value
- */
-#define RTE_PER_LTHREAD(name) ((typeof(per_lt_##name) *)\
-((char *)lthread_get_data() +\
-((char *) &per_lt_##name - &__start_per_lt)))
-
-/**
-  * Initialize a mutex
-  *
-  *  This function provides a mutual exclusion device, the need for which
-  *  can normally be avoided in a cooperative multitasking environment.
-  *  It is provided to aid porting of legacy code originally written for
-  *   preemptive multitasking environments such as pthreads.
-  *
-  *  A mutex may be unlocked (not owned by any thread), or locked (owned by
-  *  one thread).
-  *
-  *  A mutex can never be owned  by more than one thread simultaneously.
-  *  A thread attempting to lock a mutex that is already locked by another
-  *  thread is suspended until the owning thread unlocks the mutex.
-  *
-  *  lthread_mutex_init() initializes the mutex object pointed to by mutex
-  *  Optional mutex attributes specified in mutexattr, are reserved for future
-  *  use and are currently ignored.
-  *
-  *  If a thread calls lthread_mutex_lock() on the mutex, then if the mutex
-  *  is currently unlocked,  it  becomes  locked  and  owned  by  the calling
-  *  thread, and lthread_mutex_lock returns immediately. If the mutex is
-  *  already locked by another thread, lthread_mutex_lock suspends the calling
-  *  thread until the mutex is unlocked.
-  *
-  *  lthread_mutex_trylock behaves identically to rte_thread_mutex_lock, except
-  *  that it does not block the calling  thread  if the mutex is already locked
-  *  by another thread.
-  *
-  *  lthread_mutex_unlock() unlocks the specified mutex. The mutex is assumed
-  *  to be locked and owned by the calling thread.
-  *
-  *  lthread_mutex_destroy() destroys a	mutex object, freeing its resources.
-  *  The mutex must be unlocked with nothing blocked on it before calling
-  *  lthread_mutex_destroy.
-  *
-  * @param name
-  *  Optional pointer to string describing the mutex
-  * @param mutex
-  *  Pointer to pointer to the mutex to be initialized
-  * @param attribute
-  *  Pointer to attribute - unused reserved
-  *
-  * @return
-  *  0 success
-  *  EINVAL mutex was not a valid pointer
-  *  EAGAIN insufficient resources
-  */
-
-int
-lthread_mutex_init(char *name, struct lthread_mutex **mutex,
-		   const struct lthread_mutexattr *attr);
-
-/**
-  * Destroy a mutex
-  *
-  *  This function destroys the specified mutex freeing its resources.
-  *  The mutex must be unlocked before calling lthread_mutex_destroy.
-  *
-  * @see lthread_mutex_init()
-  *
-  * @param mutex
-  *  Pointer to pointer to the mutex to be initialized
-  *
-  * @return
-  *  0 success
-  *  EINVAL mutex was not an initialized mutex
-  *  EBUSY mutex was still in use
-  */
-int lthread_mutex_destroy(struct lthread_mutex *mutex);
-
-/**
-  * Lock a mutex
-  *
-  *  This function attempts to lock a mutex.
-  *  If a thread calls lthread_mutex_lock() on the mutex, then if the mutex
-  *  is currently unlocked,  it  becomes  locked  and  owned  by  the calling
-  *  thread, and lthread_mutex_lock returns immediately. If the mutex is
-  *  already locked by another thread, lthread_mutex_lock suspends the calling
-  *  thread until the mutex is unlocked.
-  *
-  * @see lthread_mutex_init()
-  *
-  * @param mutex
-  *  Pointer to pointer to the mutex to be initialized
-  *
-  * @return
-  *  0 success
-  *  EINVAL mutex was not an initialized mutex
-  *  EDEADLOCK the mutex was already owned by the calling thread
-  */
-
-int lthread_mutex_lock(struct lthread_mutex *mutex);
-
-/**
-  * Try to lock a mutex
-  *
-  *  This function attempts to lock a mutex.
-  *  lthread_mutex_trylock behaves identically to rte_thread_mutex_lock, except
-  *  that it does not block the calling  thread  if the mutex is already locked
-  *  by another thread.
-  *
-  *
-  * @see lthread_mutex_init()
-  *
-  * @param mutex
-  *  Pointer to pointer to the mutex to be initialized
-  *
-  * @return
-  * 0 success
-  * EINVAL mutex was not an initialized mutex
-  * EBUSY the mutex was already locked by another thread
-  */
-int lthread_mutex_trylock(struct lthread_mutex *mutex);
-
-/**
-  * Unlock a mutex
-  *
-  * This function attempts to unlock the specified mutex. The mutex is assumed
-  * to be locked and owned by the calling thread.
-  *
-  * The oldest of any threads blocked on the mutex is made ready and may
-  * compete with any other running thread to gain the mutex, it fails it will
-  *  be blocked again.
-  *
-  * @param mutex
-  * Pointer to pointer to the mutex to be initialized
-  *
-  * @return
-  *  0 mutex was unlocked
-  *  EINVAL mutex was not an initialized mutex
-  *  EPERM the mutex was not owned by the calling thread
-  */
-
-int lthread_mutex_unlock(struct lthread_mutex *mutex);
-
-/**
-  * Initialize a condition variable
-  *
-  *  This function initializes a condition variable.
-  *
-  *  Condition variables can be used to communicate changes in the state of data
-  *  shared between threads.
-  *
-  * @see lthread_cond_wait()
-  *
-  * @param name
-  *  Pointer to optional string describing the condition variable
-  * @param c
-  *  Pointer to pointer to the condition variable to be initialized
-  * @param attr
-  *  Pointer to optional attribute reserved for future use, currently ignored
-  *
-  * @return
-  *  0 success
-  *  EINVAL cond was not a valid pointer
-  *  EAGAIN insufficient resources
-  */
-int
-lthread_cond_init(char *name, struct lthread_cond **c,
-		  const struct lthread_condattr *attr);
-
-/**
-  * Destroy a condition variable
-  *
-  *  This function destroys a condition variable that was created with
-  *  lthread_cond_init() and releases its resources.
-  *
-  * @param cond
-  *  Pointer to pointer to the condition variable to be destroyed
-  *
-  * @return
-  *  0 Success
-  *  EBUSY condition variable was still in use
-  *  EINVAL was not an initialised condition variable
-  */
-int lthread_cond_destroy(struct lthread_cond *cond);
-
-/**
-  * Wait on a condition variable
-  *
-  *  The function blocks the current thread waiting on the condition variable
-  *  specified by cond. The waiting thread unblocks only after another thread
-  *  calls lthread_cond_signal, or lthread_cond_broadcast, specifying the
-  *  same condition variable.
-  *
-  * @param cond
-  *  Pointer to pointer to the condition variable to be waited on
-  *
-  * @param reserved
-  *  reserved for future use
-  *
-  * @return
-  *  0 The condition was signalled ( Success )
-  *  EINVAL was not a an initialised condition variable
-  */
-int lthread_cond_wait(struct lthread_cond *c, uint64_t reserved);
-
-/**
-  * Signal a condition variable
-  *
-  *  The function unblocks one thread waiting for the condition variable cond.
-  *  If no threads are waiting on cond, the rte_lthead_cond_signal() function
-  *  has no effect.
-  *
-  * @param cond
-  *  Pointer to pointer to the condition variable to be signalled
-  *
-  * @return
-  *  0 The condition was signalled ( Success )
-  *  EINVAL was not a an initialised condition variable
-  */
-int lthread_cond_signal(struct lthread_cond *c);
-
-/**
-  * Broadcast a condition variable
-  *
-  *  The function unblocks all threads waiting for the condition variable cond.
-  *  If no threads are waiting on cond, the rte_lthead_cond_broadcast()
-  *  function has no effect.
-  *
-  * @param cond
-  *  Pointer to pointer to the condition variable to be signalled
-  *
-  * @return
-  *  0 The condition was signalled ( Success )
-  *  EINVAL was not a an initialised condition variable
-  */
-int lthread_cond_broadcast(struct lthread_cond *c);
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif				/* LTHREAD_H */
diff --git a/examples/performance-thread/common/lthread_cond.c b/examples/performance-thread/common/lthread_cond.c
deleted file mode 100644
index 96fcce0..0000000
--- a/examples/performance-thread/common/lthread_cond.c
+++ /dev/null
@@ -1,239 +0,0 @@
-/*-
- *   BSD LICENSE
- *
- *   Copyright(c) 2015 Intel Corporation. All rights reserved.
- *   All rights reserved.
- *
- *   Redistribution and use in source and binary forms, with or without
- *   modification, are permitted provided that the following conditions
- *   are met:
- *
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above copyright
- *       notice, this list of conditions and the following disclaimer in
- *       the documentation and/or other materials provided with the
- *       distribution.
- *     * Neither the name of Intel Corporation nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * Some portions of this software may have been derived from the
- * https://github.com/halayli/lthread which carrys the following license.
- *
- * Copyright (C) 2012, Hasan Alayli <halayli@gmail.com>
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- * 1. Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- * 2. Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *
- * THIS SOFTWARE IS PROVIDED BY AUTHOR AND CONTRIBUTORS ``AS IS'' AND
- * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
- * ARE DISCLAIMED.  IN NO EVENT SHALL AUTHOR OR CONTRIBUTORS BE LIABLE
- * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
- * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
- * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
- * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
- * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
- * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
- * SUCH DAMAGE.
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <string.h>
-#include <stdint.h>
-#include <stddef.h>
-#include <limits.h>
-#include <inttypes.h>
-#include <unistd.h>
-#include <pthread.h>
-#include <fcntl.h>
-#include <sys/time.h>
-#include <sys/mman.h>
-#include <errno.h>
-
-#include <rte_log.h>
-#include <rte_common.h>
-
-#include "lthread_api.h"
-#include "lthread_diag_api.h"
-#include "lthread_diag.h"
-#include "lthread_int.h"
-#include "lthread_sched.h"
-#include "lthread_queue.h"
-#include "lthread_objcache.h"
-#include "lthread_timer.h"
-#include "lthread_mutex.h"
-#include "lthread_cond.h"
-
-/*
- * Create a condition variable
- */
-int
-lthread_cond_init(char *name, struct lthread_cond **cond,
-		  __rte_unused const struct lthread_condattr *attr)
-{
-	struct lthread_cond *c;
-
-	if (cond == NULL)
-		return POSIX_ERRNO(EINVAL);
-
-	/* allocate a condition variable from cache */
-	c = _lthread_objcache_alloc((THIS_SCHED)->cond_cache);
-
-	if (c == NULL)
-		return POSIX_ERRNO(EAGAIN);
-
-	c->blocked = _lthread_queue_create("blocked");
-	if (c->blocked == NULL) {
-		_lthread_objcache_free((THIS_SCHED)->cond_cache, (void *)c);
-		return POSIX_ERRNO(EAGAIN);
-	}
-
-	if (name == NULL)
-		strncpy(c->name, "no name", sizeof(c->name));
-	else
-		strncpy(c->name, name, sizeof(c->name));
-	c->name[sizeof(c->name)-1] = 0;
-
-	c->root_sched = THIS_SCHED;
-
-	(*cond) = c;
-	DIAG_CREATE_EVENT((*cond), LT_DIAG_COND_CREATE);
-	return 0;
-}
-
-/*
- * Destroy a condition variable
- */
-int lthread_cond_destroy(struct lthread_cond *c)
-{
-	if (c == NULL) {
-		DIAG_EVENT(c, LT_DIAG_COND_DESTROY, c, POSIX_ERRNO(EINVAL));
-		return POSIX_ERRNO(EINVAL);
-	}
-
-	/* try to free it */
-	if (_lthread_queue_destroy(c->blocked) < 0) {
-		/* queue in use */
-		DIAG_EVENT(c, LT_DIAG_COND_DESTROY, c, POSIX_ERRNO(EBUSY));
-		return POSIX_ERRNO(EBUSY);
-	}
-
-	/* okay free it */
-	_lthread_objcache_free(c->root_sched->cond_cache, c);
-	DIAG_EVENT(c, LT_DIAG_COND_DESTROY, c, 0);
-	return 0;
-}
-
-/*
- * Wait on a condition variable
- */
-int lthread_cond_wait(struct lthread_cond *c, __rte_unused uint64_t reserved)
-{
-	struct lthread *lt = THIS_LTHREAD;
-
-	if (c == NULL) {
-		DIAG_EVENT(c, LT_DIAG_COND_WAIT, c, POSIX_ERRNO(EINVAL));
-		return POSIX_ERRNO(EINVAL);
-	}
-
-
-	DIAG_EVENT(c, LT_DIAG_COND_WAIT, c, 0);
-
-	/* queue the current thread in the blocked queue
-	 * this will be written when we return to the scheduler
-	 * to ensure that the current thread context is saved
-	 * before any signal could result in it being dequeued and
-	 * resumed
-	 */
-	lt->pending_wr_queue = c->blocked;
-	_suspend();
-
-	/* the condition happened */
-	return 0;
-}
-
-/*
- * Signal a condition variable
- * attempt to resume any blocked thread
- */
-int lthread_cond_signal(struct lthread_cond *c)
-{
-	struct lthread *lt;
-
-	if (c == NULL) {
-		DIAG_EVENT(c, LT_DIAG_COND_SIGNAL, c, POSIX_ERRNO(EINVAL));
-		return POSIX_ERRNO(EINVAL);
-	}
-
-	lt = _lthread_queue_remove(c->blocked);
-
-	if (lt != NULL) {
-		/* okay wake up this thread */
-		DIAG_EVENT(c, LT_DIAG_COND_SIGNAL, c, lt);
-		_ready_queue_insert((struct lthread_sched *)lt->sched, lt);
-	}
-	return 0;
-}
-
-/*
- * Broadcast a condition variable
- */
-int lthread_cond_broadcast(struct lthread_cond *c)
-{
-	struct lthread *lt;
-
-	if (c == NULL) {
-		DIAG_EVENT(c, LT_DIAG_COND_BROADCAST, c, POSIX_ERRNO(EINVAL));
-		return POSIX_ERRNO(EINVAL);
-	}
-
-	DIAG_EVENT(c, LT_DIAG_COND_BROADCAST, c, 0);
-	do {
-		/* drain the queue waking everybody */
-		lt = _lthread_queue_remove(c->blocked);
-
-		if (lt != NULL) {
-			DIAG_EVENT(c, LT_DIAG_COND_BROADCAST, c, lt);
-			/* wake up */
-			_ready_queue_insert((struct lthread_sched *)lt->sched,
-					    lt);
-		}
-	} while (!_lthread_queue_empty(c->blocked));
-	_reschedule();
-	DIAG_EVENT(c, LT_DIAG_COND_BROADCAST, c, 0);
-	return 0;
-}
-
-/*
- * return the diagnostic ref val stored in a condition var
- */
-uint64_t
-lthread_cond_diag_ref(struct lthread_cond *c)
-{
-	if (c == NULL)
-		return 0;
-	return c->diag_ref;
-}
diff --git a/examples/performance-thread/common/lthread_cond.h b/examples/performance-thread/common/lthread_cond.h
deleted file mode 100644
index 5e5f14b..0000000
--- a/examples/performance-thread/common/lthread_cond.h
+++ /dev/null
@@ -1,85 +0,0 @@
-/*-
- *   BSD LICENSE
- *
- *   Copyright(c) 2015 Intel Corporation. All rights reserved.
- *   All rights reserved.
- *
- *   Redistribution and use in source and binary forms, with or without
- *   modification, are permitted provided that the following conditions
- *   are met:
- *
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above copyright
- *       notice, this list of conditions and the following disclaimer in
- *       the documentation and/or other materials provided with the
- *       distribution.
- *     * Neither the name of Intel Corporation nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * Some portions of this software may have been derived from the
- * https://github.com/halayli/lthread which carrys the following license.
- *
- * Copyright (C) 2012, Hasan Alayli <halayli@gmail.com>
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- * 1. Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- * 2. Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *
- * THIS SOFTWARE IS PROVIDED BY AUTHOR AND CONTRIBUTORS ``AS IS'' AND
- * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
- * ARE DISCLAIMED.  IN NO EVENT SHALL AUTHOR OR CONTRIBUTORS BE LIABLE
- * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
- * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
- * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
- * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
- * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
- * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
- * SUCH DAMAGE.
- */
-
-#ifndef LTHREAD_COND_H_
-#define LTHREAD_COND_H_
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-#include "lthread_queue.h"
-
-#define MAX_COND_NAME_SIZE 64
-
-struct lthread_cond {
-	struct lthread_queue *blocked;
-	struct lthread_sched *root_sched;
-	int count;
-	char name[MAX_COND_NAME_SIZE];
-	uint64_t diag_ref;	/* optional ref to user diag data */
-} __rte_cache_aligned;
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif				/* LTHREAD_COND_H_ */
diff --git a/examples/performance-thread/common/lthread_diag.c b/examples/performance-thread/common/lthread_diag.c
deleted file mode 100644
index 57760a1..0000000
--- a/examples/performance-thread/common/lthread_diag.c
+++ /dev/null
@@ -1,293 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2015 Intel Corporation
- */
-
-#include <rte_log.h>
-#include <rte_common.h>
-
-#include "lthread_diag.h"
-#include "lthread_queue.h"
-#include "lthread_pool.h"
-#include "lthread_objcache.h"
-#include "lthread_sched.h"
-#include "lthread_diag_api.h"
-
-
-/* dummy ref value of default diagnostic callback */
-static uint64_t dummy_ref;
-
-#define DIAG_SCHED_STATS_FORMAT \
-"core %d\n%33s %12s %12s %12s %12s\n"
-
-#define DIAG_CACHE_STATS_FORMAT \
-"%20s %12lu %12lu %12lu %12lu %12lu\n"
-
-#define DIAG_QUEUE_STATS_FORMAT \
-"%20s %12lu %12lu %12lu\n"
-
-
-/*
- * texts used in diagnostic events,
- * corresponding diagnostic mask bit positions are given as comment
- */
-const char *diag_event_text[] = {
-	"LTHREAD_CREATE     ",	/* 00 */
-	"LTHREAD_EXIT       ",	/* 01 */
-	"LTHREAD_JOIN       ",	/* 02 */
-	"LTHREAD_CANCEL     ",	/* 03 */
-	"LTHREAD_DETACH     ",	/* 04 */
-	"LTHREAD_FREE       ",	/* 05 */
-	"LTHREAD_SUSPENDED  ",	/* 06 */
-	"LTHREAD_YIELD      ",	/* 07 */
-	"LTHREAD_RESCHEDULED",	/* 08 */
-	"LTHREAD_SLEEP      ",	/* 09 */
-	"LTHREAD_RESUMED    ",	/* 10 */
-	"LTHREAD_AFFINITY   ",	/* 11 */
-	"LTHREAD_TMR_START  ",	/* 12 */
-	"LTHREAD_TMR_DELETE ",	/* 13 */
-	"LTHREAD_TMR_EXPIRED",	/* 14 */
-	"COND_CREATE        ",	/* 15 */
-	"COND_DESTROY       ",	/* 16 */
-	"COND_WAIT          ",	/* 17 */
-	"COND_SIGNAL        ",	/* 18 */
-	"COND_BROADCAST     ",	/* 19 */
-	"MUTEX_CREATE       ",	/* 20 */
-	"MUTEX_DESTROY      ",	/* 21 */
-	"MUTEX_LOCK         ",	/* 22 */
-	"MUTEX_TRYLOCK      ",	/* 23 */
-	"MUTEX_BLOCKED      ",	/* 24 */
-	"MUTEX_UNLOCKED     ",	/* 25 */
-	"SCHED_CREATE       ",	/* 26 */
-	"SCHED_SHUTDOWN     "	/* 27 */
-};
-
-
-/*
- * set diagnostic ,ask
- */
-void lthread_diagnostic_set_mask(DIAG_USED uint64_t mask)
-{
-#if LTHREAD_DIAG
-	diag_mask = mask;
-#else
-	RTE_LOG(INFO, LTHREAD,
-		"LTHREAD_DIAG is not set, see lthread_diag_api.h\n");
-#endif
-}
-
-
-/*
- * Check consistency of the scheduler stats
- * Only sensible run after the schedulers are stopped
- * Count the number of objects lying in caches and queues
- * and available in the qnode pool.
- * This should be equal to the total capacity of all
- * qnode pools.
- */
-void
-_sched_stats_consistency_check(void);
-void
-_sched_stats_consistency_check(void)
-{
-#if LTHREAD_DIAG
-	int i;
-	struct lthread_sched *sched;
-	uint64_t count = 0;
-	uint64_t capacity = 0;
-
-	for (i = 0; i < LTHREAD_MAX_LCORES; i++) {
-		sched = schedcore[i];
-		if (sched == NULL)
-			continue;
-
-		/* each of these queues consumes a stub node */
-		count += 8;
-		count += DIAG_COUNT(sched->ready, size);
-		count += DIAG_COUNT(sched->pready, size);
-		count += DIAG_COUNT(sched->lthread_cache, available);
-		count += DIAG_COUNT(sched->stack_cache, available);
-		count += DIAG_COUNT(sched->tls_cache, available);
-		count += DIAG_COUNT(sched->per_lthread_cache, available);
-		count += DIAG_COUNT(sched->cond_cache, available);
-		count += DIAG_COUNT(sched->mutex_cache, available);
-
-		/* the node pool does not consume a stub node */
-		if (sched->qnode_pool->fast_alloc != NULL)
-			count++;
-		count += DIAG_COUNT(sched->qnode_pool, available);
-
-		capacity += DIAG_COUNT(sched->qnode_pool, capacity);
-	}
-	if (count != capacity) {
-		RTE_LOG(CRIT, LTHREAD,
-			"Scheduler caches are inconsistent\n");
-	} else {
-		RTE_LOG(INFO, LTHREAD,
-			"Scheduler caches are ok\n");
-	}
-#endif
-}
-
-
-#if LTHREAD_DIAG
-/*
- * Display node pool stats
- */
-static inline void
-_qnode_pool_display(DIAG_USED struct qnode_pool *p)
-{
-
-	printf(DIAG_CACHE_STATS_FORMAT,
-			p->name,
-			DIAG_COUNT(p, rd),
-			DIAG_COUNT(p, wr),
-			DIAG_COUNT(p, available),
-			DIAG_COUNT(p, prealloc),
-			DIAG_COUNT(p, capacity));
-	fflush(stdout);
-}
-#endif
-
-
-#if LTHREAD_DIAG
-/*
- * Display queue stats
- */
-static inline void
-_lthread_queue_display(DIAG_USED struct lthread_queue *q)
-{
-#if DISPLAY_OBJCACHE_QUEUES
-	printf(DIAG_QUEUE_STATS_FORMAT,
-			q->name,
-			DIAG_COUNT(q, rd),
-			DIAG_COUNT(q, wr),
-			DIAG_COUNT(q, size));
-	fflush(stdout);
-#else
-	printf("%s: queue stats disabled\n",
-			q->name);
-
-#endif
-}
-#endif
-
-#if LTHREAD_DIAG
-/*
- * Display objcache stats
- */
-static inline void
-_objcache_display(DIAG_USED struct lthread_objcache *c)
-{
-
-	printf(DIAG_CACHE_STATS_FORMAT,
-			c->name,
-			DIAG_COUNT(c, rd),
-			DIAG_COUNT(c, wr),
-			DIAG_COUNT(c, available),
-			DIAG_COUNT(c, prealloc),
-			DIAG_COUNT(c, capacity));
-	_lthread_queue_display(c->q);
-	fflush(stdout);
-}
-#endif
-
-/*
- * Display sched stats
- */
-void
-lthread_sched_stats_display(void)
-{
-#if LTHREAD_DIAG
-	int i;
-	struct lthread_sched *sched;
-
-	for (i = 0; i < LTHREAD_MAX_LCORES; i++) {
-		sched = schedcore[i];
-		if (sched != NULL) {
-			printf(DIAG_SCHED_STATS_FORMAT,
-					sched->lcore_id,
-					"rd",
-					"wr",
-					"present",
-					"nb preallocs",
-					"capacity");
-			_lthread_queue_display(sched->ready);
-			_lthread_queue_display(sched->pready);
-			_qnode_pool_display(sched->qnode_pool);
-			_objcache_display(sched->lthread_cache);
-			_objcache_display(sched->stack_cache);
-			_objcache_display(sched->tls_cache);
-			_objcache_display(sched->per_lthread_cache);
-			_objcache_display(sched->cond_cache);
-			_objcache_display(sched->mutex_cache);
-		fflush(stdout);
-		}
-	}
-	_sched_stats_consistency_check();
-#else
-	RTE_LOG(INFO, LTHREAD,
-		"lthread diagnostics disabled\n"
-		"hint - set LTHREAD_DIAG in lthread_diag_api.h\n");
-#endif
-}
-
-/*
- * Defafult diagnostic callback
- */
-static uint64_t
-_lthread_diag_default_cb(uint64_t time, struct lthread *lt, int diag_event,
-		uint64_t diag_ref, const char *text, uint64_t p1, uint64_t p2)
-{
-	uint64_t _p2;
-	int lcore = (int) rte_lcore_id();
-
-	switch (diag_event) {
-	case LT_DIAG_LTHREAD_CREATE:
-	case LT_DIAG_MUTEX_CREATE:
-	case LT_DIAG_COND_CREATE:
-		_p2 = dummy_ref;
-		break;
-	default:
-		_p2 = p2;
-		break;
-	}
-
-	printf("%"PRIu64" %d %8.8lx %8.8lx %s %8.8lx %8.8lx\n",
-		time,
-		lcore,
-		(uint64_t) lt,
-		diag_ref,
-		text,
-		p1,
-		_p2);
-
-	return dummy_ref++;
-}
-
-/*
- * plug in default diag callback with mask off
- */
-RTE_INIT(_lthread_diag_ctor)
-{
-	diag_cb = _lthread_diag_default_cb;
-	diag_mask = 0;
-}
-
-
-/*
- * enable diagnostics
- */
-void lthread_diagnostic_enable(DIAG_USED diag_callback cb,
-				DIAG_USED uint64_t mask)
-{
-#if LTHREAD_DIAG
-	if (cb == NULL)
-		diag_cb = _lthread_diag_default_cb;
-	else
-		diag_cb = cb;
-	diag_mask = mask;
-#else
-	RTE_LOG(INFO, LTHREAD,
-		"LTHREAD_DIAG is not set, see lthread_diag_api.h\n");
-#endif
-}
diff --git a/examples/performance-thread/common/lthread_diag.h b/examples/performance-thread/common/lthread_diag.h
deleted file mode 100644
index e876dda..0000000
--- a/examples/performance-thread/common/lthread_diag.h
+++ /dev/null
@@ -1,112 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2015 Intel Corporation
- */
-
-#ifndef LTHREAD_DIAG_H_
-#define LTHREAD_DIAG_H_
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-#include <stdint.h>
-#include <inttypes.h>
-
-#include <rte_log.h>
-#include <rte_common.h>
-
-#include "lthread_api.h"
-#include "lthread_diag_api.h"
-
-extern diag_callback diag_cb;
-
-extern const char *diag_event_text[];
-extern uint64_t diag_mask;
-
-/* max size of name strings */
-#define LT_MAX_NAME_SIZE 64
-
-#if LTHREAD_DIAG
-#define DISPLAY_OBJCACHE_QUEUES 1
-
-/*
- * Generate a diagnostic trace or event in the case where an object is created.
- *
- * The value returned by the callback is stored in the object.
- *
- * @ param obj
- *  pointer to the object that was created
- * @ param ev
- *  the event code
- *
- */
-#define DIAG_CREATE_EVENT(obj, ev) do {					\
-	struct lthread *ct = RTE_PER_LCORE(this_sched)->current_lthread;\
-	if ((BIT(ev) & diag_mask) && (ev < LT_DIAG_EVENT_MAX)) {	\
-		(obj)->diag_ref = (diag_cb)(rte_rdtsc(),		\
-					ct,				\
-					(ev),				\
-					0,				\
-					diag_event_text[(ev)],		\
-					(uint64_t)obj,			\
-					0);				\
-	}								\
-} while (0)
-
-/*
- * Generate a diagnostic trace event.
- *
- * @ param obj
- *  pointer to the lthread, cond or mutex object
- * @ param ev
- *  the event code
- * @ param p1
- *  object specific value ( see lthread_diag_api.h )
- * @ param p2
- *  object specific value ( see lthread_diag_api.h )
- */
-#define DIAG_EVENT(obj, ev, p1, p2) do {				\
-	struct lthread *ct = RTE_PER_LCORE(this_sched)->current_lthread;\
-	if ((BIT(ev) & diag_mask) && (ev < LT_DIAG_EVENT_MAX)) {	\
-		(diag_cb)(rte_rdtsc(),					\
-				ct,					\
-				ev,					\
-				(obj)->diag_ref,			\
-				diag_event_text[(ev)],			\
-				(uint64_t)(p1),				\
-				(uint64_t)(p2));			\
-	}								\
-} while (0)
-
-#define DIAG_COUNT_DEFINE(x) rte_atomic64_t count_##x
-#define DIAG_COUNT_INIT(o, x) rte_atomic64_init(&((o)->count_##x))
-#define DIAG_COUNT_INC(o, x) rte_atomic64_inc(&((o)->count_##x))
-#define DIAG_COUNT_DEC(o, x) rte_atomic64_dec(&((o)->count_##x))
-#define DIAG_COUNT(o, x) rte_atomic64_read(&((o)->count_##x))
-
-#define DIAG_USED
-
-#else
-
-/* no diagnostics configured */
-
-#define DISPLAY_OBJCACHE_QUEUES 0
-
-#define DIAG_CREATE_EVENT(obj, ev)
-#define DIAG_EVENT(obj, ev, p1, p)
-
-#define DIAG_COUNT_DEFINE(x)
-#define DIAG_COUNT_INIT(o, x) do {} while (0)
-#define DIAG_COUNT_INC(o, x) do {} while (0)
-#define DIAG_COUNT_DEC(o, x) do {} while (0)
-#define DIAG_COUNT(o, x) 0
-
-#define DIAG_USED __rte_unused
-
-#endif				/* LTHREAD_DIAG */
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif				/* LTHREAD_DIAG_H_ */
diff --git a/examples/performance-thread/common/lthread_diag_api.h b/examples/performance-thread/common/lthread_diag_api.h
deleted file mode 100644
index d65f486..0000000
--- a/examples/performance-thread/common/lthread_diag_api.h
+++ /dev/null
@@ -1,304 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2015 Intel Corporation
- */
-#ifndef LTHREAD_DIAG_API_H_
-#define LTHREAD_DIAG_API_H_
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-#include <stdint.h>
-#include <inttypes.h>
-
-/*
- * Enable diagnostics
- * 0 = conditionally compiled out
- * 1 = compiled in and maskable at run time, see below for details
- */
-#define LTHREAD_DIAG 0
-
-/**
- *
- * @file lthread_diag_api.h
- *
- * @warning
- * @b EXPERIMENTAL: this API may change without prior notice
- *
- * lthread diagnostic interface
- *
- * If enabled via configuration file option ( tbd ) the lthread subsystem
- * can generate selected trace information, either RTE_LOG  (INFO) messages,
- * or else invoke a user supplied callback function when any of the events
- * listed below occur.
- *
- * Reporting of events can be selectively masked, the bit position in the
- * mask is determined by the corresponding event identifier listed below.
- *
- * Diagnostics are enabled by registering the callback function and mask
- * using the API lthread_diagnostic_enable().
- *
- * Various interesting parameters are passed to the callback, including the
- * time in cpu clks, the lthread id, the diagnostic event id, a user ref value,
- * event text string, object being traced, and two context dependent parameters
- * (p1 and p2). The meaning of the two parameters p1 and p2 depends on
- * the specific event.
- *
- * The events LT_DIAG_LTHREAD_CREATE, LT_DIAG_MUTEX_CREATE and
- * LT_DIAG_COND_CREATE are implicitly enabled if the event mask includes any of
- * the LT_DIAG_LTHREAD_XXX, LT_DIAG_MUTEX_XXX or LT_DIAG_COND_XXX events
- * respectively.
- *
- * These create events may also be included in the mask discreetly if it is
- * desired to monitor only create events.
- *
- * @param  time
- *  The time in cpu clks at which the event occurred
- *
- * @param  lthread
- *  The current lthread
- *
- * @param diag_event
- *  The diagnostic event id (bit position in the mask)
- *
- * @param  diag_ref
- *
- * For LT_DIAG_LTHREAD_CREATE, LT_DIAG_MUTEX_CREATE or LT_DIAG_COND_CREATE
- * this parameter is not used and set to 0.
- * All other events diag_ref contains the user ref value returned by the
- * callback function when lthread is created.
- *
- * The diag_ref values assigned to mutex and cond var can be retrieved
- * using the APIs lthread_mutex_diag_ref(), and lthread_cond_diag_ref()
- * respectively.
- *
- * @param p1
- *  see below
- *
- * @param p1
- *  see below
- *
- * @returns
- * For LT_DIAG_LTHREAD_CREATE, LT_DIAG_MUTEX_CREATE or LT_DIAG_COND_CREATE
- * expects a user diagnostic ref value that will be saved in the lthread, mutex
- * or cond var.
- *
- * For all other events return value is ignored.
- *
- *	LT_DIAG_SCHED_CREATE - Invoked when a scheduler is created
- *		p1 = the scheduler that was created
- *		p2 = not used
- *		return value will be ignored
- *
- *	LT_DIAG_SCHED_SHUTDOWN - Invoked when a shutdown request is received
- *		p1 = the scheduler to be shutdown
- *		p2 = not used
- *		return value will be ignored
- *
- *	LT_DIAG_LTHREAD_CREATE - Invoked when a thread is created
- *		p1 = the lthread that was created
- *		p2 = not used
- *		return value will be stored in the lthread
- *
- *	LT_DIAG_LTHREAD_EXIT - Invoked when a lthread exits
- *		p2 = 0 if the thread was already joined
- *		p2 = 1 if the thread was not already joined
- *		return val ignored
- *
- *	LT_DIAG_LTHREAD_JOIN - Invoked when a lthread exits
- *		p1 = the lthread that is being joined
- *		p2 = 0 if the thread was already exited
- *		p2 = 1 if the thread was not already exited
- *		return val ignored
- *
- *	LT_DIAG_LTHREAD_CANCELLED - Invoked when an lthread is cancelled
- *		p1 = not used
- *		p2 = not used
- *		return val ignored
- *
- *	LT_DIAG_LTHREAD_DETACH - Invoked when an lthread is detached
- *		p1 = not used
- *		p2 = not used
- *		return val ignored
- *
- *	LT_DIAG_LTHREAD_FREE - Invoked when an lthread is freed
- *		p1 = not used
- *		p2 = not used
- *		return val ignored
- *
- *	LT_DIAG_LTHREAD_SUSPENDED - Invoked when an lthread is suspended
- *		p1 = not used
- *		p2 = not used
- *		return val ignored
- *
- *	LT_DIAG_LTHREAD_YIELD - Invoked when an lthread explicitly yields
- *		p1 = not used
- *		p2 = not used
- *		return val ignored
- *
- *	LT_DIAG_LTHREAD_RESCHEDULED - Invoked when an lthread is rescheduled
- *		p1 = not used
- *		p2 = not used
- *		return val ignored
- *
- *	LT_DIAG_LTHREAD_RESUMED - Invoked when an lthread is resumed
- *		p1 = not used
- *		p2 = not used
- *		return val ignored
- *
- *	LT_DIAG_LTHREAD_AFFINITY - Invoked when an lthread is affinitised
- *		p1 = the destination lcore_id
- *		p2 = not used
- *		return val ignored
- *
- *	LT_DIAG_LTHREAD_TMR_START - Invoked when an lthread starts a timer
- *		p1 = address of timer node
- *		p2 = the timeout value
- *		return val ignored
- *
- *	LT_DIAG_LTHREAD_TMR_DELETE - Invoked when an lthread deletes a timer
- *		p1 = address of the timer node
- *		p2 = 0 the timer and the was successfully deleted
- *		p2 = not usee
- *		return val ignored
- *
- *	LT_DIAG_LTHREAD_TMR_EXPIRED - Invoked when an lthread timer expires
- *		p1 = address of scheduler the timer expired on
- *		p2 = the thread associated with the timer
- *		return val ignored
- *
- *	LT_DIAG_COND_CREATE - Invoked when a condition variable is created
- *		p1 = address of cond var that was created
- *		p2 = not used
- *		return diag ref value will be stored in the condition variable
- *
- *	LT_DIAG_COND_DESTROY - Invoked when a condition variable is destroyed
- *		p1 = not used
- *		p2 = not used
- *		return val ignored
- *
- *	LT_DIAG_COND_WAIT - Invoked when an lthread waits on a cond var
- *		p1 = the address of the condition variable
- *		p2 = not used
- *		return val ignored
- *
- *	LT_DIAG_COND_SIGNAL - Invoked when an lthread signals a cond var
- *		p1 = the address of the cond var
- *		p2 = the lthread that was signalled, or error code
- *		return val ignored
- *
- *	LT_DIAG_COND_BROADCAST - Invoked when an lthread broadcasts a cond var
- *		p1 = the address of the condition variable
- *		p2 = the lthread(s) that are signalled, or error code
- *
- *	LT_DIAG_MUTEX_CREATE - Invoked when a mutex is created
- *		p1 = address of muex
- *		p2 = not used
- *		return diag ref value will be stored in the mutex variable
- *
- *	LT_DIAG_MUTEX_DESTROY - Invoked when a mutex is destroyed
- *		p1 = address of mutex
- *		p2 = not used
- *		return val ignored
- *
- *	LT_DIAG_MUTEX_LOCK - Invoked when a mutex lock is obtained
- *		p1 = address of mutex
- *		p2 = function return value
- *		return val ignored
- *
- *	LT_DIAG_MUTEX_BLOCKED  - Invoked when an lthread blocks on a mutex
- *		p1 = address of mutex
- *		p2 = function return value
- *		return val ignored
- *
- *	LT_DIAG_MUTEX_TRYLOCK - Invoked when a mutex try lock is attempted
- *		p1 = address of mutex
- *		p2 = the function return value
- *		return val ignored
- *
- *	LT_DIAG_MUTEX_UNLOCKED - Invoked when a mutex is unlocked
- *		p1 = address of mutex
- *		p2 = the thread that was unlocked, or error code
- *		return val ignored
- */
-typedef uint64_t (*diag_callback) (uint64_t time, struct lthread *lt,
-				  int diag_event, uint64_t diag_ref,
-				const char *text, uint64_t p1, uint64_t p2);
-
-/*
- * Set user diagnostic callback and mask
- * If the callback function pointer is NULL the default
- * callback handler will be restored.
- */
-void lthread_diagnostic_enable(diag_callback cb, uint64_t diag_mask);
-
-/*
- * Set diagnostic mask
- */
-void lthread_diagnostic_set_mask(uint64_t mask);
-
-/*
- * lthread diagnostic callback
- */
-enum lthread_diag_ev {
-	/* bits 0 - 14 lthread flag group */
-	LT_DIAG_LTHREAD_CREATE,		/* 00 mask 0x00000001 */
-	LT_DIAG_LTHREAD_EXIT,		/* 01 mask 0x00000002 */
-	LT_DIAG_LTHREAD_JOIN,		/* 02 mask 0x00000004 */
-	LT_DIAG_LTHREAD_CANCEL,		/* 03 mask 0x00000008 */
-	LT_DIAG_LTHREAD_DETACH,		/* 04 mask 0x00000010 */
-	LT_DIAG_LTHREAD_FREE,		/* 05 mask 0x00000020 */
-	LT_DIAG_LTHREAD_SUSPENDED,	/* 06 mask 0x00000040 */
-	LT_DIAG_LTHREAD_YIELD,		/* 07 mask 0x00000080 */
-	LT_DIAG_LTHREAD_RESCHEDULED,	/* 08 mask 0x00000100 */
-	LT_DIAG_LTHREAD_SLEEP,		/* 09 mask 0x00000200 */
-	LT_DIAG_LTHREAD_RESUMED,	/* 10 mask 0x00000400 */
-	LT_DIAG_LTHREAD_AFFINITY,	/* 11 mask 0x00000800 */
-	LT_DIAG_LTHREAD_TMR_START,	/* 12 mask 0x00001000 */
-	LT_DIAG_LTHREAD_TMR_DELETE,	/* 13 mask 0x00002000 */
-	LT_DIAG_LTHREAD_TMR_EXPIRED,	/* 14 mask 0x00004000 */
-	/* bits 15 - 19 conditional variable flag group */
-	LT_DIAG_COND_CREATE,		/* 15 mask 0x00008000 */
-	LT_DIAG_COND_DESTROY,		/* 16 mask 0x00010000 */
-	LT_DIAG_COND_WAIT,		/* 17 mask 0x00020000 */
-	LT_DIAG_COND_SIGNAL,		/* 18 mask 0x00040000 */
-	LT_DIAG_COND_BROADCAST,		/* 19 mask 0x00080000 */
-	/* bits 20 - 25 mutex flag group */
-	LT_DIAG_MUTEX_CREATE,		/* 20 mask 0x00100000 */
-	LT_DIAG_MUTEX_DESTROY,		/* 21 mask 0x00200000 */
-	LT_DIAG_MUTEX_LOCK,		/* 22 mask 0x00400000 */
-	LT_DIAG_MUTEX_TRYLOCK,		/* 23 mask 0x00800000 */
-	LT_DIAG_MUTEX_BLOCKED,		/* 24 mask 0x01000000 */
-	LT_DIAG_MUTEX_UNLOCKED,		/* 25 mask 0x02000000 */
-	/* bits 26 - 27 scheduler flag group - 8 bits */
-	LT_DIAG_SCHED_CREATE,		/* 26 mask 0x04000000 */
-	LT_DIAG_SCHED_SHUTDOWN,		/* 27 mask 0x08000000 */
-	LT_DIAG_EVENT_MAX
-};
-
-#define LT_DIAG_ALL 0xffffffffffffffff
-
-
-/*
- * Display scheduler stats
- */
-void
-lthread_sched_stats_display(void);
-
-/*
- * return the diagnostic ref val stored in a condition var
- */
-uint64_t
-lthread_cond_diag_ref(struct lthread_cond *c);
-
-/*
- * return the diagnostic ref val stored in a mutex
- */
-uint64_t
-lthread_mutex_diag_ref(struct lthread_mutex *m);
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif				/* LTHREAD_DIAG_API_H_ */
diff --git a/examples/performance-thread/common/lthread_int.h b/examples/performance-thread/common/lthread_int.h
deleted file mode 100644
index e1da246..0000000
--- a/examples/performance-thread/common/lthread_int.h
+++ /dev/null
@@ -1,207 +0,0 @@
-/*-
- *   BSD LICENSE
- *
- *   Copyright(c) 2015 Intel Corporation. All rights reserved.
- *   All rights reserved.
- *
- *   Redistribution and use in source and binary forms, with or without
- *   modification, are permitted provided that the following conditions
- *   are met:
- *
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above copyright
- *       notice, this list of conditions and the following disclaimer in
- *       the documentation and/or other materials provided with the
- *       distribution.
- *     * Neither the name of Intel Corporation nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * Some portions of this software may have been derived from the
- * https://github.com/halayli/lthread which carrys the following license.
- *
- * Copyright (C) 2012, Hasan Alayli <halayli@gmail.com>
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- * 1. Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- * 2. Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *
- * THIS SOFTWARE IS PROVIDED BY AUTHOR AND CONTRIBUTORS ``AS IS'' AND
- * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
- * ARE DISCLAIMED.  IN NO EVENT SHALL AUTHOR OR CONTRIBUTORS BE LIABLE
- * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
- * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
- * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
- * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
- * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
- * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
- * SUCH DAMAGE.
- */
-#ifndef LTHREAD_INT_H
-#define LTHREAD_INT_H
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-#include <stdint.h>
-#include <sys/time.h>
-#include <sys/types.h>
-#include <errno.h>
-#include <pthread.h>
-#include <time.h>
-
-#include <rte_memory.h>
-#include <rte_cycles.h>
-#include <rte_per_lcore.h>
-#include <rte_timer.h>
-#include <rte_atomic_64.h>
-#include <rte_spinlock.h>
-#include <ctx.h>
-
-#include <lthread_api.h>
-#include "lthread.h"
-#include "lthread_diag.h"
-#include "lthread_tls.h"
-
-struct lthread;
-struct lthread_sched;
-struct lthread_cond;
-struct lthread_mutex;
-struct lthread_key;
-
-struct key_pool;
-struct qnode;
-struct qnode_pool;
-struct lthread_sched;
-struct lthread_tls;
-
-
-#define BIT(x) (1 << (x))
-#define CLEARBIT(x) ~(1 << (x))
-
-#define POSIX_ERRNO(x)  (x)
-
-#define MAX_LTHREAD_NAME_SIZE 64
-
-#define RTE_LOGTYPE_LTHREAD RTE_LOGTYPE_USER1
-
-
-/* define some shorthand for current scheduler and current thread */
-#define THIS_SCHED RTE_PER_LCORE(this_sched)
-#define THIS_LTHREAD RTE_PER_LCORE(this_sched)->current_lthread
-
-/*
- * Definition of an scheduler struct
- */
-struct lthread_sched {
-	struct ctx ctx;					/* cpu context */
-	uint64_t birth;					/* time created */
-	struct lthread *current_lthread;		/* running thread */
-	unsigned lcore_id;				/* this sched lcore */
-	int run_flag;					/* sched shutdown */
-	uint64_t nb_blocked_threads;	/* blocked threads */
-	struct lthread_queue *ready;			/* local ready queue */
-	struct lthread_queue *pready;			/* peer ready queue */
-	struct lthread_objcache *lthread_cache;		/* free lthreads */
-	struct lthread_objcache *stack_cache;		/* free stacks */
-	struct lthread_objcache *per_lthread_cache;	/* free per lthread */
-	struct lthread_objcache *tls_cache;		/* free TLS */
-	struct lthread_objcache *cond_cache;		/* free cond vars */
-	struct lthread_objcache *mutex_cache;		/* free mutexes */
-	struct qnode_pool *qnode_pool;		/* pool of queue nodes */
-	struct key_pool *key_pool;		/* pool of free TLS keys */
-	size_t stack_size;
-	uint64_t diag_ref;				/* diag ref */
-} __rte_cache_aligned;
-
-RTE_DECLARE_PER_LCORE(struct lthread_sched *, this_sched);
-
-
-/*
- * State for an lthread
- */
-enum lthread_st {
-	ST_LT_INIT,		/* initial state */
-	ST_LT_READY,		/* lthread is ready to run */
-	ST_LT_SLEEPING,		/* lthread is sleeping */
-	ST_LT_EXPIRED,		/* lthread timeout has expired  */
-	ST_LT_EXITED,		/* lthread has exited and needs cleanup */
-	ST_LT_DETACH,		/* lthread frees on exit*/
-	ST_LT_CANCELLED,	/* lthread has been cancelled */
-};
-
-/*
- * lthread sub states for exit/join
- */
-enum join_st {
-	LT_JOIN_INITIAL,	/* initial state */
-	LT_JOIN_EXITING,	/* thread is exiting */
-	LT_JOIN_THREAD_SET,	/* joining thread has been set */
-	LT_JOIN_EXIT_VAL_SET,	/* exiting thread has set ret val */
-	LT_JOIN_EXIT_VAL_READ,	/* joining thread has collected ret val */
-};
-
-/* defnition of an lthread stack object */
-struct lthread_stack {
-	uint8_t stack[LTHREAD_MAX_STACK_SIZE];
-	size_t stack_size;
-	struct lthread_sched *root_sched;
-} __rte_cache_aligned;
-
-/*
- * Definition of an lthread
- */
-struct lthread {
-	struct ctx ctx;				/* cpu context */
-
-	uint64_t state;				/* current lthread state */
-
-	struct lthread_sched *sched;		/* current scheduler */
-	void *stack;				/* ptr to actual stack */
-	size_t stack_size;			/* current stack_size */
-	size_t last_stack_size;			/* last yield  stack_size */
-	lthread_func_t fun;			/* func ctx is running */
-	void *arg;				/* func args passed to func */
-	void *per_lthread_data;			/* per lthread user data */
-	lthread_exit_func exit_handler;		/* called when thread exits */
-	uint64_t birth;				/* time lthread was born */
-	struct lthread_queue *pending_wr_queue;	/* deferred  queue to write */
-	struct lthread *lt_join;		/* lthread to join on */
-	uint64_t join;				/* state for joining */
-	void **lt_exit_ptr;			/* exit ptr for lthread_join */
-	struct lthread_sched *root_sched;	/* thread was created here*/
-	struct queue_node *qnode;		/* node when in a queue */
-	struct rte_timer tim;			/* sleep timer */
-	struct lthread_tls *tls;		/* keys in use by the thread */
-	struct lthread_stack *stack_container;	/* stack */
-	char funcname[MAX_LTHREAD_NAME_SIZE];	/* thread func name */
-	uint64_t diag_ref;			/* ref to user diag data */
-} __rte_cache_aligned;
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif				/* LTHREAD_INT_H */
diff --git a/examples/performance-thread/common/lthread_mutex.c b/examples/performance-thread/common/lthread_mutex.c
deleted file mode 100644
index 01da6ca..0000000
--- a/examples/performance-thread/common/lthread_mutex.c
+++ /dev/null
@@ -1,224 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2015 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <string.h>
-#include <stdint.h>
-#include <stddef.h>
-#include <limits.h>
-#include <inttypes.h>
-#include <unistd.h>
-#include <pthread.h>
-#include <fcntl.h>
-#include <sys/time.h>
-#include <sys/mman.h>
-
-#include <rte_per_lcore.h>
-#include <rte_log.h>
-#include <rte_spinlock.h>
-#include <rte_common.h>
-
-#include "lthread_api.h"
-#include "lthread_int.h"
-#include "lthread_mutex.h"
-#include "lthread_sched.h"
-#include "lthread_queue.h"
-#include "lthread_objcache.h"
-#include "lthread_diag.h"
-
-/*
- * Create a mutex
- */
-int
-lthread_mutex_init(char *name, struct lthread_mutex **mutex,
-		   __rte_unused const struct lthread_mutexattr *attr)
-{
-	struct lthread_mutex *m;
-
-	if (mutex == NULL)
-		return POSIX_ERRNO(EINVAL);
-
-
-	m = _lthread_objcache_alloc((THIS_SCHED)->mutex_cache);
-	if (m == NULL)
-		return POSIX_ERRNO(EAGAIN);
-
-	m->blocked = _lthread_queue_create("blocked queue");
-	if (m->blocked == NULL) {
-		_lthread_objcache_free((THIS_SCHED)->mutex_cache, m);
-		return POSIX_ERRNO(EAGAIN);
-	}
-
-	if (name == NULL)
-		strncpy(m->name, "no name", sizeof(m->name));
-	else
-		strncpy(m->name, name, sizeof(m->name));
-	m->name[sizeof(m->name)-1] = 0;
-
-	m->root_sched = THIS_SCHED;
-	m->owner = NULL;
-
-	rte_atomic64_init(&m->count);
-
-	DIAG_CREATE_EVENT(m, LT_DIAG_MUTEX_CREATE);
-	/* success */
-	(*mutex) = m;
-	return 0;
-}
-
-/*
- * Destroy a mutex
- */
-int lthread_mutex_destroy(struct lthread_mutex *m)
-{
-	if ((m == NULL) || (m->blocked == NULL)) {
-		DIAG_EVENT(m, LT_DIAG_MUTEX_DESTROY, m, POSIX_ERRNO(EINVAL));
-		return POSIX_ERRNO(EINVAL);
-	}
-
-	if (m->owner == NULL) {
-		/* try to delete the blocked queue */
-		if (_lthread_queue_destroy(m->blocked) < 0) {
-			DIAG_EVENT(m, LT_DIAG_MUTEX_DESTROY,
-					m, POSIX_ERRNO(EBUSY));
-			return POSIX_ERRNO(EBUSY);
-		}
-
-		/* free the mutex to cache */
-		_lthread_objcache_free(m->root_sched->mutex_cache, m);
-		DIAG_EVENT(m, LT_DIAG_MUTEX_DESTROY, m, 0);
-		return 0;
-	}
-	/* can't do its still in use */
-	DIAG_EVENT(m, LT_DIAG_MUTEX_DESTROY, m, POSIX_ERRNO(EBUSY));
-	return POSIX_ERRNO(EBUSY);
-}
-
-/*
- * Try to obtain a mutex
- */
-int lthread_mutex_lock(struct lthread_mutex *m)
-{
-	struct lthread *lt = THIS_LTHREAD;
-
-	if ((m == NULL) || (m->blocked == NULL)) {
-		DIAG_EVENT(m, LT_DIAG_MUTEX_LOCK, m, POSIX_ERRNO(EINVAL));
-		return POSIX_ERRNO(EINVAL);
-	}
-
-	/* allow no recursion */
-	if (m->owner == lt) {
-		DIAG_EVENT(m, LT_DIAG_MUTEX_LOCK, m, POSIX_ERRNO(EDEADLK));
-		return POSIX_ERRNO(EDEADLK);
-	}
-
-	for (;;) {
-		rte_atomic64_inc(&m->count);
-		do {
-			if (rte_atomic64_cmpset
-			    ((uint64_t *) &m->owner, 0, (uint64_t) lt)) {
-				/* happy days, we got the lock */
-				DIAG_EVENT(m, LT_DIAG_MUTEX_LOCK, m, 0);
-				return 0;
-			}
-			/* spin due to race with unlock when
-			* nothing was blocked
-			*/
-		} while ((rte_atomic64_read(&m->count) == 1) &&
-				(m->owner == NULL));
-
-		/* queue the current thread in the blocked queue
-		 * we defer this to after we return to the scheduler
-		 * to ensure that the current thread context is saved
-		 * before unlock could result in it being dequeued and
-		 * resumed
-		 */
-		DIAG_EVENT(m, LT_DIAG_MUTEX_BLOCKED, m, lt);
-		lt->pending_wr_queue = m->blocked;
-		/* now relinquish cpu */
-		_suspend();
-		/* resumed, must loop and compete for the lock again */
-	}
-	return 0;
-}
-
-/* try to lock a mutex but don't block */
-int lthread_mutex_trylock(struct lthread_mutex *m)
-{
-	struct lthread *lt = THIS_LTHREAD;
-
-	if ((m == NULL) || (m->blocked == NULL)) {
-		DIAG_EVENT(m, LT_DIAG_MUTEX_TRYLOCK, m, POSIX_ERRNO(EINVAL));
-		return POSIX_ERRNO(EINVAL);
-	}
-
-	if (m->owner == lt) {
-		/* no recursion */
-		DIAG_EVENT(m, LT_DIAG_MUTEX_TRYLOCK, m, POSIX_ERRNO(EDEADLK));
-		return POSIX_ERRNO(EDEADLK);
-	}
-
-	rte_atomic64_inc(&m->count);
-	if (rte_atomic64_cmpset
-	    ((uint64_t *) &m->owner, (uint64_t) NULL, (uint64_t) lt)) {
-		/* got the lock */
-		DIAG_EVENT(m, LT_DIAG_MUTEX_TRYLOCK, m, 0);
-		return 0;
-	}
-
-	/* failed so return busy */
-	rte_atomic64_dec(&m->count);
-	DIAG_EVENT(m, LT_DIAG_MUTEX_TRYLOCK, m, POSIX_ERRNO(EBUSY));
-	return POSIX_ERRNO(EBUSY);
-}
-
-/*
- * Unlock a mutex
- */
-int lthread_mutex_unlock(struct lthread_mutex *m)
-{
-	struct lthread *lt = THIS_LTHREAD;
-	struct lthread *unblocked;
-
-	if ((m == NULL) || (m->blocked == NULL)) {
-		DIAG_EVENT(m, LT_DIAG_MUTEX_UNLOCKED, m, POSIX_ERRNO(EINVAL));
-		return POSIX_ERRNO(EINVAL);
-	}
-
-	/* fail if its owned */
-	if (m->owner != lt || m->owner == NULL) {
-		DIAG_EVENT(m, LT_DIAG_MUTEX_UNLOCKED, m, POSIX_ERRNO(EPERM));
-		return POSIX_ERRNO(EPERM);
-	}
-
-	rte_atomic64_dec(&m->count);
-	/* if there are blocked threads then make one ready */
-	while (rte_atomic64_read(&m->count) > 0) {
-		unblocked = _lthread_queue_remove(m->blocked);
-
-		if (unblocked != NULL) {
-			rte_atomic64_dec(&m->count);
-			DIAG_EVENT(m, LT_DIAG_MUTEX_UNLOCKED, m, unblocked);
-			RTE_ASSERT(unblocked->sched != NULL);
-			_ready_queue_insert((struct lthread_sched *)
-					    unblocked->sched, unblocked);
-			break;
-		}
-	}
-	/* release the lock */
-	m->owner = NULL;
-	return 0;
-}
-
-/*
- * return the diagnostic ref val stored in a mutex
- */
-uint64_t
-lthread_mutex_diag_ref(struct lthread_mutex *m)
-{
-	if (m == NULL)
-		return 0;
-	return m->diag_ref;
-}
diff --git a/examples/performance-thread/common/lthread_mutex.h b/examples/performance-thread/common/lthread_mutex.h
deleted file mode 100644
index cd866f8..0000000
--- a/examples/performance-thread/common/lthread_mutex.h
+++ /dev/null
@@ -1,31 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2015 Intel Corporation
- */
-
-
-#ifndef LTHREAD_MUTEX_H_
-#define LTHREAD_MUTEX_H_
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-#include "lthread_queue.h"
-
-
-#define MAX_MUTEX_NAME_SIZE 64
-
-struct lthread_mutex {
-	struct lthread *owner;
-	rte_atomic64_t	count;
-	struct lthread_queue *blocked __rte_cache_aligned;
-	struct lthread_sched *root_sched;
-	char			name[MAX_MUTEX_NAME_SIZE];
-	uint64_t		diag_ref; /* optional ref to user diag data */
-} __rte_cache_aligned;
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif /* LTHREAD_MUTEX_H_ */
diff --git a/examples/performance-thread/common/lthread_objcache.h b/examples/performance-thread/common/lthread_objcache.h
deleted file mode 100644
index 777a194..0000000
--- a/examples/performance-thread/common/lthread_objcache.h
+++ /dev/null
@@ -1,136 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2015 Intel Corporation
- */
-#ifndef LTHREAD_OBJCACHE_H_
-#define LTHREAD_OBJCACHE_H_
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-#include <string.h>
-
-#include <rte_per_lcore.h>
-#include <rte_malloc.h>
-#include <rte_memory.h>
-
-#include "lthread_int.h"
-#include "lthread_diag.h"
-#include "lthread_queue.h"
-
-
-RTE_DECLARE_PER_LCORE(struct lthread_sched *, this_sched);
-
-struct lthread_objcache {
-	struct lthread_queue *q;
-	size_t obj_size;
-	int prealloc_size;
-	char name[LT_MAX_NAME_SIZE];
-
-	DIAG_COUNT_DEFINE(rd);
-	DIAG_COUNT_DEFINE(wr);
-	DIAG_COUNT_DEFINE(prealloc);
-	DIAG_COUNT_DEFINE(capacity);
-	DIAG_COUNT_DEFINE(available);
-};
-
-/*
- * Create a cache
- */
-static inline struct
-lthread_objcache *_lthread_objcache_create(const char *name,
-					size_t obj_size,
-					int prealloc_size)
-{
-	struct lthread_objcache *c =
-	    rte_malloc_socket(NULL, sizeof(struct lthread_objcache),
-				RTE_CACHE_LINE_SIZE,
-				rte_socket_id());
-	if (c == NULL)
-		return NULL;
-
-	c->q = _lthread_queue_create("cache queue");
-	if (c->q == NULL) {
-		rte_free(c);
-		return NULL;
-	}
-	c->obj_size = obj_size;
-	c->prealloc_size = prealloc_size;
-
-	if (name != NULL)
-		strncpy(c->name, name, LT_MAX_NAME_SIZE);
-	c->name[sizeof(c->name)-1] = 0;
-
-	DIAG_COUNT_INIT(c, rd);
-	DIAG_COUNT_INIT(c, wr);
-	DIAG_COUNT_INIT(c, prealloc);
-	DIAG_COUNT_INIT(c, capacity);
-	DIAG_COUNT_INIT(c, available);
-	return c;
-}
-
-/*
- * Destroy an objcache
- */
-static inline int
-_lthread_objcache_destroy(struct lthread_objcache *c)
-{
-	if (_lthread_queue_destroy(c->q) == 0) {
-		rte_free(c);
-		return 0;
-	}
-	return -1;
-}
-
-/*
- * Allocate an object from an object cache
- */
-static inline void *
-_lthread_objcache_alloc(struct lthread_objcache *c)
-{
-	int i;
-	void *data;
-	struct lthread_queue *q = c->q;
-	size_t obj_size = c->obj_size;
-	int prealloc_size = c->prealloc_size;
-
-	data = _lthread_queue_remove(q);
-
-	if (data == NULL) {
-		DIAG_COUNT_INC(c, prealloc);
-		for (i = 0; i < prealloc_size; i++) {
-			data =
-			    rte_zmalloc_socket(NULL, obj_size,
-					RTE_CACHE_LINE_SIZE,
-					rte_socket_id());
-			if (data == NULL)
-				return NULL;
-
-			DIAG_COUNT_INC(c, available);
-			DIAG_COUNT_INC(c, capacity);
-			_lthread_queue_insert_mp(q, data);
-		}
-		data = _lthread_queue_remove(q);
-	}
-	DIAG_COUNT_INC(c, rd);
-	DIAG_COUNT_DEC(c, available);
-	return data;
-}
-
-/*
- * free an object to a cache
- */
-static inline void
-_lthread_objcache_free(struct lthread_objcache *c, void *obj)
-{
-	DIAG_COUNT_INC(c, wr);
-	DIAG_COUNT_INC(c, available);
-	_lthread_queue_insert_mp(c->q, obj);
-}
-
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif				/* LTHREAD_OBJCACHE_H_ */
diff --git a/examples/performance-thread/common/lthread_pool.h b/examples/performance-thread/common/lthread_pool.h
deleted file mode 100644
index 315a2e2..0000000
--- a/examples/performance-thread/common/lthread_pool.h
+++ /dev/null
@@ -1,339 +0,0 @@
-/*
- *-
- *   BSD LICENSE
- *
- *   Copyright(c) 2015 Intel Corporation. All rights reserved.
- *   All rights reserved.
- *
- *   Redistribution and use in source and binary forms, with or without
- *   modification, are permitted provided that the following conditions
- *   are met:
- *
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above copyright
- *       notice, this list of conditions and the following disclaimer in
- *       the documentation and/or other materials provided with the
- *       distribution.
- *     * Neither the name of Intel Corporation nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * Some portions of this software is derived from the producer
- * consumer queues described by Dmitry Vyukov and published  here
- * http://www.1024cores.net
- *
- * Copyright (c) 2010-2011 Dmitry Vyukov. All rights reserved.
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met
- *
- * 1. Redistributions of source code must retain the above copyright notice,
- * this list of conditions and the following disclaimer.
- *
- * 2. Redistributions in binary form must reproduce the above copyright notice,
- * this list of conditions and the following disclaimer in the documentation
- * and/or other materials provided with the distribution.
- *
- * THIS SOFTWARE IS PROVIDED BY DMITRY VYUKOV "AS IS"
- * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
- * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL DMITRY VYUKOV OR CONTRIBUTORS
- * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
- * OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
- * OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
- * OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
- * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
- * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
- * EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- *
- * The views and conclusions contained in the software and documentation are
- * those of the authors and should not be interpreted as representing official
- * policies, either expressed or implied, of Dmitry Vyukov.
- */
-
-#ifndef LTHREAD_POOL_H_
-#define LTHREAD_POOL_H_
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-#include <rte_malloc.h>
-#include <rte_per_lcore.h>
-#include <rte_log.h>
-
-#include "lthread_int.h"
-#include "lthread_diag.h"
-
-/*
- * This file implements pool of queue nodes used by the queue implemented
- * in lthread_queue.h.
- *
- * The pool is an intrusive lock free MPSC queue.
- *
- * The pool is created empty and populated lazily, i.e. on first attempt to
- * allocate a the pool.
- *
- * Whenever the pool is empty more nodes are added to the pool
- * The number of nodes preallocated in this way is a parameter of
- * _qnode_pool_create. Freeing an object returns it to the pool.
- *
- * Each lthread scheduler maintains its own pool of nodes. L-threads must always
- * allocate from this local pool ( because it is a single consumer queue ).
- * L-threads can free nodes to any pool (because it is a multi producer queue)
- * This enables threads that have affined to a different scheduler to free
- * nodes safely.
- */
-
-struct qnode;
-struct qnode_cache;
-
-/*
- * define intermediate node
- */
-struct qnode {
-	struct qnode *next;
-	void *data;
-	struct qnode_pool *pool;
-} __rte_cache_aligned;
-
-/*
- * a pool structure
- */
-struct qnode_pool {
-	struct qnode *head;
-	struct qnode *stub;
-	struct qnode *fast_alloc;
-	struct qnode *tail __rte_cache_aligned;
-	int pre_alloc;
-	char name[LT_MAX_NAME_SIZE];
-
-	DIAG_COUNT_DEFINE(rd);
-	DIAG_COUNT_DEFINE(wr);
-	DIAG_COUNT_DEFINE(available);
-	DIAG_COUNT_DEFINE(prealloc);
-	DIAG_COUNT_DEFINE(capacity);
-} __rte_cache_aligned;
-
-/*
- * Create a pool of qnodes
- */
-
-static inline struct qnode_pool *
-_qnode_pool_create(const char *name, int prealloc_size) {
-
-	struct qnode_pool *p = rte_malloc_socket(NULL,
-					sizeof(struct qnode_pool),
-					RTE_CACHE_LINE_SIZE,
-					rte_socket_id());
-
-	RTE_ASSERT(p);
-
-	p->stub = rte_malloc_socket(NULL,
-				sizeof(struct qnode),
-				RTE_CACHE_LINE_SIZE,
-				rte_socket_id());
-
-	RTE_ASSERT(p->stub);
-
-	if (name != NULL)
-		strncpy(p->name, name, LT_MAX_NAME_SIZE);
-	p->name[sizeof(p->name)-1] = 0;
-
-	p->stub->pool = p;
-	p->stub->next = NULL;
-	p->tail = p->stub;
-	p->head = p->stub;
-	p->pre_alloc = prealloc_size;
-
-	DIAG_COUNT_INIT(p, rd);
-	DIAG_COUNT_INIT(p, wr);
-	DIAG_COUNT_INIT(p, available);
-	DIAG_COUNT_INIT(p, prealloc);
-	DIAG_COUNT_INIT(p, capacity);
-
-	return p;
-}
-
-
-/*
- * Insert a node into the pool
- */
-static __rte_always_inline void
-_qnode_pool_insert(struct qnode_pool *p, struct qnode *n)
-{
-	n->next = NULL;
-	struct qnode *prev = n;
-	/* We insert at the head */
-	prev = (struct qnode *) __sync_lock_test_and_set((uint64_t *)&p->head,
-						(uint64_t) prev);
-	/* there is a window of inconsistency until prev next is set */
-	/* which is why remove must retry */
-	prev->next = (n);
-}
-
-/*
- * Remove a node from the pool
- *
- * There is a race with _qnode_pool_insert() whereby the queue could appear
- * empty during a concurrent insert, this is handled by retrying
- *
- * The queue uses a stub node, which must be swung as the queue becomes
- * empty, this requires an insert of the stub, which means that removing the
- * last item from the queue incurs the penalty of an atomic exchange. Since the
- * pool is maintained with a bulk pre-allocation the cost of this is amortised.
- */
-static __rte_always_inline struct qnode *
-_pool_remove(struct qnode_pool *p)
-{
-	struct qnode *head;
-	struct qnode *tail = p->tail;
-	struct qnode *next = tail->next;
-
-	/* we remove from the tail */
-	if (tail == p->stub) {
-		if (next == NULL)
-			return NULL;
-		/* advance the tail */
-		p->tail = next;
-		tail = next;
-		next = next->next;
-	}
-	if (likely(next != NULL)) {
-		p->tail = next;
-		return tail;
-	}
-
-	head = p->head;
-	if (tail == head)
-		return NULL;
-
-	/* swing stub node */
-	_qnode_pool_insert(p, p->stub);
-
-	next = tail->next;
-	if (next) {
-		p->tail = next;
-		return tail;
-	}
-	return NULL;
-}
-
-
-/*
- * This adds a retry to the _pool_remove function
- * defined above
- */
-static __rte_always_inline struct qnode *
-_qnode_pool_remove(struct qnode_pool *p)
-{
-	struct qnode *n;
-
-	do {
-		n = _pool_remove(p);
-		if (likely(n != NULL))
-			return n;
-
-		rte_compiler_barrier();
-	}  while ((p->head != p->tail) &&
-			(p->tail != p->stub));
-	return NULL;
-}
-
-/*
- * Allocate a node from the pool
- * If the pool is empty add mode nodes
- */
-static __rte_always_inline struct qnode *
-_qnode_alloc(void)
-{
-	struct qnode_pool *p = (THIS_SCHED)->qnode_pool;
-	int prealloc_size = p->pre_alloc;
-	struct qnode *n;
-	int i;
-
-	if (likely(p->fast_alloc != NULL)) {
-		n = p->fast_alloc;
-		p->fast_alloc = NULL;
-		return n;
-	}
-
-	n = _qnode_pool_remove(p);
-
-	if (unlikely(n == NULL)) {
-		DIAG_COUNT_INC(p, prealloc);
-		for (i = 0; i < prealloc_size; i++) {
-			n = rte_malloc_socket(NULL,
-					sizeof(struct qnode),
-					RTE_CACHE_LINE_SIZE,
-					rte_socket_id());
-			if (n == NULL)
-				return NULL;
-
-			DIAG_COUNT_INC(p, available);
-			DIAG_COUNT_INC(p, capacity);
-
-			n->pool = p;
-			_qnode_pool_insert(p, n);
-		}
-		n = _qnode_pool_remove(p);
-	}
-	n->pool = p;
-	DIAG_COUNT_INC(p, rd);
-	DIAG_COUNT_DEC(p, available);
-	return n;
-}
-
-
-
-/*
-* free a queue node to the per scheduler pool from which it came
-*/
-static __rte_always_inline void
-_qnode_free(struct qnode *n)
-{
-	struct qnode_pool *p = n->pool;
-
-
-	if (unlikely(p->fast_alloc != NULL) ||
-			unlikely(n->pool != (THIS_SCHED)->qnode_pool)) {
-		DIAG_COUNT_INC(p, wr);
-		DIAG_COUNT_INC(p, available);
-		_qnode_pool_insert(p, n);
-		return;
-	}
-	p->fast_alloc = n;
-}
-
-/*
- * Destroy an qnode pool
- * queue must be empty when this is called
- */
-static inline int
-_qnode_pool_destroy(struct qnode_pool *p)
-{
-	rte_free(p->stub);
-	rte_free(p);
-	return 0;
-}
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif				/* LTHREAD_POOL_H_ */
diff --git a/examples/performance-thread/common/lthread_queue.h b/examples/performance-thread/common/lthread_queue.h
deleted file mode 100644
index 833ed92..0000000
--- a/examples/performance-thread/common/lthread_queue.h
+++ /dev/null
@@ -1,309 +0,0 @@
-/*
- *-
- *   BSD LICENSE
- *
- *   Copyright(c) 2015 Intel Corporation. All rights reserved.
- *   All rights reserved.
- *
- *   Redistribution and use in source and binary forms, with or without
- *   modification, are permitted provided that the following conditions
- *   are met:
- *
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above copyright
- *       notice, this list of conditions and the following disclaimer in
- *       the documentation and/or other materials provided with the
- *       distribution.
- *     * Neither the name of Intel Corporation nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * Some portions of this software is derived from the producer
- * consumer queues described by Dmitry Vyukov and published  here
- * http://www.1024cores.net
- *
- * Copyright (c) 2010-2011 Dmitry Vyukov. All rights reserved.
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *
- * 1. Redistributions of source code must retain the above copyright notice,
- * this list of conditions and the following disclaimer.
- *
- * 2. Redistributions in binary form must reproduce the above copyright notice,
- * this list of conditions and the following disclaimer in the documentation
- * and/or other materials provided with the distribution.
- *
- * THIS SOFTWARE IS PROVIDED BY DMITRY VYUKOV "AS IS"
- * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
- * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL DMITRY VYUKOV OR CONTRIBUTORS
- * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
- * OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
- * OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
- * OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
- * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
- * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
- * EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- *
- * The views and conclusions contained in the software and documentation are
- * those of the authors and should not be interpreted as representing official
- * policies, either expressed or implied, of Dmitry Vyukov.
- */
-
-#ifndef LTHREAD_QUEUE_H_
-#define LTHREAD_QUEUE_H_
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-#include <string.h>
-
-#include <rte_prefetch.h>
-#include <rte_per_lcore.h>
-
-#include "lthread_int.h"
-#include "lthread.h"
-#include "lthread_diag.h"
-#include "lthread_pool.h"
-
-struct lthread_queue;
-
-/*
- * This file implements an unbounded FIFO queue based on a lock free
- * linked list.
- *
- * The queue is non-intrusive in that it uses intermediate nodes, and does
- * not require these nodes to be inserted into the object being placed
- * in the queue.
- *
- * This is slightly more efficient than the very similar queue in lthread_pool
- * in that it does not have to swing a stub node as the queue becomes empty.
- *
- * The queue access functions allocate and free intermediate node
- * transparently from/to a per scheduler pool ( see lthread_pool.h ).
- *
- * The queue provides both MPSC and SPSC insert methods
- */
-
-/*
- * define a queue of lthread nodes
- */
-struct lthread_queue {
-	struct qnode *head;
-	struct qnode *tail __rte_cache_aligned;
-	struct lthread_queue *p;
-	char name[LT_MAX_NAME_SIZE];
-
-	DIAG_COUNT_DEFINE(rd);
-	DIAG_COUNT_DEFINE(wr);
-	DIAG_COUNT_DEFINE(size);
-
-} __rte_cache_aligned;
-
-
-
-static inline struct lthread_queue *
-_lthread_queue_create(const char *name)
-{
-	struct qnode *stub;
-	struct lthread_queue *new_queue;
-
-	new_queue = rte_malloc_socket(NULL, sizeof(struct lthread_queue),
-					RTE_CACHE_LINE_SIZE,
-					rte_socket_id());
-	if (new_queue == NULL)
-		return NULL;
-
-	/* allocated stub node */
-	stub = _qnode_alloc();
-	RTE_ASSERT(stub);
-
-	if (name != NULL)
-		strncpy(new_queue->name, name, sizeof(new_queue->name));
-	new_queue->name[sizeof(new_queue->name)-1] = 0;
-
-	/* initialize queue as empty */
-	stub->next = NULL;
-	new_queue->head = stub;
-	new_queue->tail = stub;
-
-	DIAG_COUNT_INIT(new_queue, rd);
-	DIAG_COUNT_INIT(new_queue, wr);
-	DIAG_COUNT_INIT(new_queue, size);
-
-	return new_queue;
-}
-
-/**
- * Return true if the queue is empty
- */
-static __rte_always_inline int
-_lthread_queue_empty(struct lthread_queue *q)
-{
-	return q->tail == q->head;
-}
-
-
-
-/**
- * Destroy a queue
- * fail if queue is not empty
- */
-static inline int _lthread_queue_destroy(struct lthread_queue *q)
-{
-	if (q == NULL)
-		return -1;
-
-	if (!_lthread_queue_empty(q))
-		return -1;
-
-	_qnode_free(q->head);
-	rte_free(q);
-	return 0;
-}
-
-RTE_DECLARE_PER_LCORE(struct lthread_sched *, this_sched);
-
-/*
- * Insert a node into a queue
- * this implementation is multi producer safe
- */
-static __rte_always_inline struct qnode *
-_lthread_queue_insert_mp(struct lthread_queue
-							  *q, void *data)
-{
-	struct qnode *prev;
-	struct qnode *n = _qnode_alloc();
-
-	if (n == NULL)
-		return NULL;
-
-	/* set object in node */
-	n->data = data;
-	n->next = NULL;
-
-	/* this is an MPSC method, perform a locked update */
-	prev = n;
-	prev =
-	    (struct qnode *)__sync_lock_test_and_set((uint64_t *) &(q)->head,
-					       (uint64_t) prev);
-	/* there is a window of inconsistency until prev next is set,
-	 * which is why remove must retry
-	 */
-	prev->next = n;
-
-	DIAG_COUNT_INC(q, wr);
-	DIAG_COUNT_INC(q, size);
-
-	return n;
-}
-
-/*
- * Insert an node into a queue in single producer mode
- * this implementation is NOT mult producer safe
- */
-static __rte_always_inline struct qnode *
-_lthread_queue_insert_sp(struct lthread_queue
-							  *q, void *data)
-{
-	/* allocate a queue node */
-	struct qnode *prev;
-	struct qnode *n = _qnode_alloc();
-
-	if (n == NULL)
-		return NULL;
-
-	/* set data in node */
-	n->data = data;
-	n->next = NULL;
-
-	/* this is an SPSC method, no need for locked exchange operation */
-	prev = q->head;
-	prev->next = q->head = n;
-
-	DIAG_COUNT_INC(q, wr);
-	DIAG_COUNT_INC(q, size);
-
-	return n;
-}
-
-/*
- * Remove a node from a queue
- */
-static __rte_always_inline void *
-_lthread_queue_poll(struct lthread_queue *q)
-{
-	void *data = NULL;
-	struct qnode *tail = q->tail;
-	struct qnode *next = (struct qnode *)tail->next;
-	/*
-	 * There is a small window of inconsistency between producer and
-	 * consumer whereby the queue may appear empty if consumer and
-	 * producer access it at the same time.
-	 * The consumer must handle this by retrying
-	 */
-
-	if (likely(next != NULL)) {
-		q->tail = next;
-		tail->data = next->data;
-		data = tail->data;
-
-		/* free the node */
-		_qnode_free(tail);
-
-		DIAG_COUNT_INC(q, rd);
-		DIAG_COUNT_DEC(q, size);
-		return data;
-	}
-	return NULL;
-}
-
-/*
- * Remove a node from a queue
- */
-static __rte_always_inline void *
-_lthread_queue_remove(struct lthread_queue *q)
-{
-	void *data = NULL;
-
-	/*
-	 * There is a small window of inconsistency between producer and
-	 * consumer whereby the queue may appear empty if consumer and
-	 * producer access it at the same time. We handle this by retrying
-	 */
-	do {
-		data = _lthread_queue_poll(q);
-
-		if (likely(data != NULL)) {
-
-			DIAG_COUNT_INC(q, rd);
-			DIAG_COUNT_DEC(q, size);
-			return data;
-		}
-		rte_compiler_barrier();
-	} while (unlikely(!_lthread_queue_empty(q)));
-	return NULL;
-}
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif				/* LTHREAD_QUEUE_H_ */
diff --git a/examples/performance-thread/common/lthread_sched.c b/examples/performance-thread/common/lthread_sched.c
deleted file mode 100644
index 779aeb1..0000000
--- a/examples/performance-thread/common/lthread_sched.c
+++ /dev/null
@@ -1,600 +0,0 @@
-/*-
- *   BSD LICENSE
- *
- *   Copyright(c) 2015 Intel Corporation. All rights reserved.
- *   All rights reserved.
- *
- *   Redistribution and use in source and binary forms, with or without
- *   modification, are permitted provided that the following conditions
- *   are met:
- *
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above copyright
- *       notice, this list of conditions and the following disclaimer in
- *       the documentation and/or other materials provided with the
- *       distribution.
- *     * Neither the name of Intel Corporation nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * Some portions of this software is derived from the
- * https://github.com/halayli/lthread which carrys the following license.
- *
- * Copyright (C) 2012, Hasan Alayli <halayli@gmail.com>
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- * 1. Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- * 2. Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *
- * THIS SOFTWARE IS PROVIDED BY AUTHOR AND CONTRIBUTORS ``AS IS'' AND
- * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
- * ARE DISCLAIMED.  IN NO EVENT SHALL AUTHOR OR CONTRIBUTORS BE LIABLE
- * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
- * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
- * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
- * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
- * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
- * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
- * SUCH DAMAGE.
- */
-
-
-#define RTE_MEM 1
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <string.h>
-#include <stdint.h>
-#include <stddef.h>
-#include <limits.h>
-#include <inttypes.h>
-#include <unistd.h>
-#include <pthread.h>
-#include <fcntl.h>
-#include <sys/time.h>
-#include <sys/mman.h>
-#include <sched.h>
-
-#include <rte_prefetch.h>
-#include <rte_per_lcore.h>
-#include <rte_atomic.h>
-#include <rte_atomic_64.h>
-#include <rte_log.h>
-#include <rte_common.h>
-#include <rte_branch_prediction.h>
-
-#include "lthread_api.h"
-#include "lthread_int.h"
-#include "lthread_sched.h"
-#include "lthread_objcache.h"
-#include "lthread_timer.h"
-#include "lthread_mutex.h"
-#include "lthread_cond.h"
-#include "lthread_tls.h"
-#include "lthread_diag.h"
-
-/*
- * This file implements the lthread scheduler
- * The scheduler is the function lthread_run()
- * This must be run as the main loop of an EAL thread.
- *
- * Currently once a scheduler is created it cannot be destroyed
- * When a scheduler shuts down it is assumed that the application is terminating
- */
-
-static rte_atomic16_t num_schedulers;
-static rte_atomic16_t active_schedulers;
-
-/* one scheduler per lcore */
-RTE_DEFINE_PER_LCORE(struct lthread_sched *, this_sched) = NULL;
-
-struct lthread_sched *schedcore[LTHREAD_MAX_LCORES];
-
-diag_callback diag_cb;
-
-uint64_t diag_mask;
-
-
-/* constructor */
-RTE_INIT(lthread_sched_ctor)
-{
-	memset(schedcore, 0, sizeof(schedcore));
-	rte_atomic16_init(&num_schedulers);
-	rte_atomic16_set(&num_schedulers, 1);
-	rte_atomic16_init(&active_schedulers);
-	rte_atomic16_set(&active_schedulers, 0);
-	diag_cb = NULL;
-}
-
-
-enum sched_alloc_phase {
-	SCHED_ALLOC_OK,
-	SCHED_ALLOC_QNODE_POOL,
-	SCHED_ALLOC_READY_QUEUE,
-	SCHED_ALLOC_PREADY_QUEUE,
-	SCHED_ALLOC_LTHREAD_CACHE,
-	SCHED_ALLOC_STACK_CACHE,
-	SCHED_ALLOC_PERLT_CACHE,
-	SCHED_ALLOC_TLS_CACHE,
-	SCHED_ALLOC_COND_CACHE,
-	SCHED_ALLOC_MUTEX_CACHE,
-};
-
-static int
-_lthread_sched_alloc_resources(struct lthread_sched *new_sched)
-{
-	int alloc_status;
-
-	do {
-		/* Initialize per scheduler queue node pool */
-		alloc_status = SCHED_ALLOC_QNODE_POOL;
-		new_sched->qnode_pool =
-			_qnode_pool_create("qnode pool", LTHREAD_PREALLOC);
-		if (new_sched->qnode_pool == NULL)
-			break;
-
-		/* Initialize per scheduler local ready queue */
-		alloc_status = SCHED_ALLOC_READY_QUEUE;
-		new_sched->ready = _lthread_queue_create("ready queue");
-		if (new_sched->ready == NULL)
-			break;
-
-		/* Initialize per scheduler local peer ready queue */
-		alloc_status = SCHED_ALLOC_PREADY_QUEUE;
-		new_sched->pready = _lthread_queue_create("pready queue");
-		if (new_sched->pready == NULL)
-			break;
-
-		/* Initialize per scheduler local free lthread cache */
-		alloc_status = SCHED_ALLOC_LTHREAD_CACHE;
-		new_sched->lthread_cache =
-			_lthread_objcache_create("lthread cache",
-						sizeof(struct lthread),
-						LTHREAD_PREALLOC);
-		if (new_sched->lthread_cache == NULL)
-			break;
-
-		/* Initialize per scheduler local free stack cache */
-		alloc_status = SCHED_ALLOC_STACK_CACHE;
-		new_sched->stack_cache =
-			_lthread_objcache_create("stack_cache",
-						sizeof(struct lthread_stack),
-						LTHREAD_PREALLOC);
-		if (new_sched->stack_cache == NULL)
-			break;
-
-		/* Initialize per scheduler local free per lthread data cache */
-		alloc_status = SCHED_ALLOC_PERLT_CACHE;
-		new_sched->per_lthread_cache =
-			_lthread_objcache_create("per_lt cache",
-						RTE_PER_LTHREAD_SECTION_SIZE,
-						LTHREAD_PREALLOC);
-		if (new_sched->per_lthread_cache == NULL)
-			break;
-
-		/* Initialize per scheduler local free tls cache */
-		alloc_status = SCHED_ALLOC_TLS_CACHE;
-		new_sched->tls_cache =
-			_lthread_objcache_create("TLS cache",
-						sizeof(struct lthread_tls),
-						LTHREAD_PREALLOC);
-		if (new_sched->tls_cache == NULL)
-			break;
-
-		/* Initialize per scheduler local free cond var cache */
-		alloc_status = SCHED_ALLOC_COND_CACHE;
-		new_sched->cond_cache =
-			_lthread_objcache_create("cond cache",
-						sizeof(struct lthread_cond),
-						LTHREAD_PREALLOC);
-		if (new_sched->cond_cache == NULL)
-			break;
-
-		/* Initialize per scheduler local free mutex cache */
-		alloc_status = SCHED_ALLOC_MUTEX_CACHE;
-		new_sched->mutex_cache =
-			_lthread_objcache_create("mutex cache",
-						sizeof(struct lthread_mutex),
-						LTHREAD_PREALLOC);
-		if (new_sched->mutex_cache == NULL)
-			break;
-
-		alloc_status = SCHED_ALLOC_OK;
-	} while (0);
-
-	/* roll back on any failure */
-	switch (alloc_status) {
-	case SCHED_ALLOC_MUTEX_CACHE:
-		_lthread_objcache_destroy(new_sched->cond_cache);
-		/* fall through */
-	case SCHED_ALLOC_COND_CACHE:
-		_lthread_objcache_destroy(new_sched->tls_cache);
-		/* fall through */
-	case SCHED_ALLOC_TLS_CACHE:
-		_lthread_objcache_destroy(new_sched->per_lthread_cache);
-		/* fall through */
-	case SCHED_ALLOC_PERLT_CACHE:
-		_lthread_objcache_destroy(new_sched->stack_cache);
-		/* fall through */
-	case SCHED_ALLOC_STACK_CACHE:
-		_lthread_objcache_destroy(new_sched->lthread_cache);
-		/* fall through */
-	case SCHED_ALLOC_LTHREAD_CACHE:
-		_lthread_queue_destroy(new_sched->pready);
-		/* fall through */
-	case SCHED_ALLOC_PREADY_QUEUE:
-		_lthread_queue_destroy(new_sched->ready);
-		/* fall through */
-	case SCHED_ALLOC_READY_QUEUE:
-		_qnode_pool_destroy(new_sched->qnode_pool);
-		/* fall through */
-	case SCHED_ALLOC_QNODE_POOL:
-		/* fall through */
-	case SCHED_ALLOC_OK:
-		break;
-	}
-	return alloc_status;
-}
-
-
-/*
- * Create a scheduler on the current lcore
- */
-struct lthread_sched *_lthread_sched_create(size_t stack_size)
-{
-	int status;
-	struct lthread_sched *new_sched;
-	unsigned lcoreid = rte_lcore_id();
-
-	RTE_ASSERT(stack_size <= LTHREAD_MAX_STACK_SIZE);
-
-	if (stack_size == 0)
-		stack_size = LTHREAD_MAX_STACK_SIZE;
-
-	new_sched =
-	     rte_calloc_socket(NULL, 1, sizeof(struct lthread_sched),
-				RTE_CACHE_LINE_SIZE,
-				rte_socket_id());
-	if (new_sched == NULL) {
-		RTE_LOG(CRIT, LTHREAD,
-			"Failed to allocate memory for scheduler\n");
-		return NULL;
-	}
-
-	_lthread_key_pool_init();
-
-	new_sched->stack_size = stack_size;
-	new_sched->birth = rte_rdtsc();
-	THIS_SCHED = new_sched;
-
-	status = _lthread_sched_alloc_resources(new_sched);
-	if (status != SCHED_ALLOC_OK) {
-		RTE_LOG(CRIT, LTHREAD,
-			"Failed to allocate resources for scheduler code = %d\n",
-			status);
-		rte_free(new_sched);
-		return NULL;
-	}
-
-	bzero(&new_sched->ctx, sizeof(struct ctx));
-
-	new_sched->lcore_id = lcoreid;
-
-	schedcore[lcoreid] = new_sched;
-
-	new_sched->run_flag = 1;
-
-	DIAG_EVENT(new_sched, LT_DIAG_SCHED_CREATE, rte_lcore_id(), 0);
-
-	rte_wmb();
-	return new_sched;
-}
-
-/*
- * Set the number of schedulers in the system
- */
-int lthread_num_schedulers_set(int num)
-{
-	rte_atomic16_set(&num_schedulers, num);
-	return (int)rte_atomic16_read(&num_schedulers);
-}
-
-/*
- * Return the number of schedulers active
- */
-int lthread_active_schedulers(void)
-{
-	return (int)rte_atomic16_read(&active_schedulers);
-}
-
-
-/**
- * shutdown the scheduler running on the specified lcore
- */
-void lthread_scheduler_shutdown(unsigned lcoreid)
-{
-	uint64_t coreid = (uint64_t) lcoreid;
-
-	if (coreid < LTHREAD_MAX_LCORES) {
-		if (schedcore[coreid] != NULL)
-			schedcore[coreid]->run_flag = 0;
-	}
-}
-
-/**
- * shutdown all schedulers
- */
-void lthread_scheduler_shutdown_all(void)
-{
-	uint64_t i;
-
-	/*
-	 * give time for all schedulers to have started
-	 * Note we use sched_yield() rather than pthread_yield() to allow
-	 * for the possibility of a pthread wrapper on lthread_yield(),
-	 * something that is not possible unless the scheduler is running.
-	 */
-	while (rte_atomic16_read(&active_schedulers) <
-	       rte_atomic16_read(&num_schedulers))
-		sched_yield();
-
-	for (i = 0; i < LTHREAD_MAX_LCORES; i++) {
-		if (schedcore[i] != NULL)
-			schedcore[i]->run_flag = 0;
-	}
-}
-
-/*
- * Resume a suspended lthread
- */
-static __rte_always_inline void
-_lthread_resume(struct lthread *lt);
-static inline void _lthread_resume(struct lthread *lt)
-{
-	struct lthread_sched *sched = THIS_SCHED;
-	struct lthread_stack *s;
-	uint64_t state = lt->state;
-#if LTHREAD_DIAG
-	int init = 0;
-#endif
-
-	sched->current_lthread = lt;
-
-	if (state & (BIT(ST_LT_CANCELLED) | BIT(ST_LT_EXITED))) {
-		/* if detached we can free the thread now */
-		if (state & BIT(ST_LT_DETACH)) {
-			_lthread_free(lt);
-			sched->current_lthread = NULL;
-			return;
-		}
-	}
-
-	if (state & BIT(ST_LT_INIT)) {
-		/* first time this thread has been run */
-		/* assign thread to this scheduler */
-		lt->sched = THIS_SCHED;
-
-		/* allocate stack */
-		s = _stack_alloc();
-
-		lt->stack_container = s;
-		_lthread_set_stack(lt, s->stack, s->stack_size);
-
-		/* allocate memory for TLS used by this thread */
-		_lthread_tls_alloc(lt);
-
-		lt->state = BIT(ST_LT_READY);
-#if LTHREAD_DIAG
-		init = 1;
-#endif
-	}
-
-	DIAG_EVENT(lt, LT_DIAG_LTHREAD_RESUMED, init, lt);
-
-	/* switch to the new thread */
-	ctx_switch(&lt->ctx, &sched->ctx);
-
-	/* If posting to a queue that could be read by another lcore
-	 * we defer the queue write till now to ensure the context has been
-	 * saved before the other core tries to resume it
-	 * This applies to blocking on mutex, cond, and to set_affinity
-	 */
-	if (lt->pending_wr_queue != NULL) {
-		struct lthread_queue *dest = lt->pending_wr_queue;
-
-		lt->pending_wr_queue = NULL;
-
-		/* queue the current thread to the specified queue */
-		_lthread_queue_insert_mp(dest, lt);
-	}
-
-	sched->current_lthread = NULL;
-}
-
-/*
- * Handle sleep timer expiry
-*/
-void
-_sched_timer_cb(struct rte_timer *tim, void *arg)
-{
-	struct lthread *lt = (struct lthread *) arg;
-	uint64_t state = lt->state;
-
-	DIAG_EVENT(lt, LT_DIAG_LTHREAD_TMR_EXPIRED, &lt->tim, 0);
-
-	rte_timer_stop(tim);
-
-	if (lt->state & BIT(ST_LT_CANCELLED))
-		(THIS_SCHED)->nb_blocked_threads--;
-
-	lt->state = state | BIT(ST_LT_EXPIRED);
-	_lthread_resume(lt);
-	lt->state = state & CLEARBIT(ST_LT_EXPIRED);
-}
-
-
-
-/*
- * Returns 0 if there is a pending job in scheduler or 1 if done and can exit.
- */
-static inline int _lthread_sched_isdone(struct lthread_sched *sched)
-{
-	return (sched->run_flag == 0) &&
-			(_lthread_queue_empty(sched->ready)) &&
-			(_lthread_queue_empty(sched->pready)) &&
-			(sched->nb_blocked_threads == 0);
-}
-
-/*
- * Wait for all schedulers to start
- */
-static inline void _lthread_schedulers_sync_start(void)
-{
-	rte_atomic16_inc(&active_schedulers);
-
-	/* wait for lthread schedulers
-	 * Note we use sched_yield() rather than pthread_yield() to allow
-	 * for the possibility of a pthread wrapper on lthread_yield(),
-	 * something that is not possible unless the scheduler is running.
-	 */
-	while (rte_atomic16_read(&active_schedulers) <
-	       rte_atomic16_read(&num_schedulers))
-		sched_yield();
-
-}
-
-/*
- * Wait for all schedulers to stop
- */
-static inline void _lthread_schedulers_sync_stop(void)
-{
-	rte_atomic16_dec(&active_schedulers);
-	rte_atomic16_dec(&num_schedulers);
-
-	/* wait for schedulers
-	 * Note we use sched_yield() rather than pthread_yield() to allow
-	 * for the possibility of a pthread wrapper on lthread_yield(),
-	 * something that is not possible unless the scheduler is running.
-	 */
-	while (rte_atomic16_read(&active_schedulers) > 0)
-		sched_yield();
-
-}
-
-
-/*
- * Run the lthread scheduler
- * This loop is the heart of the system
- */
-void lthread_run(void)
-{
-
-	struct lthread_sched *sched = THIS_SCHED;
-	struct lthread *lt = NULL;
-
-	RTE_LOG(INFO, LTHREAD,
-		"starting scheduler %p on lcore %u phys core %u\n",
-		sched, rte_lcore_id(),
-		rte_lcore_index(rte_lcore_id()));
-
-	/* if more than one, wait for all schedulers to start */
-	_lthread_schedulers_sync_start();
-
-
-	/*
-	 * This is the main scheduling loop
-	 * So long as there are tasks in existence we run this loop.
-	 * We check for:-
-	 *   expired timers,
-	 *   the local ready queue,
-	 *   and the peer ready queue,
-	 *
-	 * and resume lthreads ad infinitum.
-	 */
-	while (!_lthread_sched_isdone(sched)) {
-
-		rte_timer_manage();
-
-		lt = _lthread_queue_poll(sched->ready);
-		if (lt != NULL)
-			_lthread_resume(lt);
-		lt = _lthread_queue_poll(sched->pready);
-		if (lt != NULL)
-			_lthread_resume(lt);
-	}
-
-
-	/* if more than one wait for all schedulers to stop */
-	_lthread_schedulers_sync_stop();
-
-	(THIS_SCHED) = NULL;
-
-	RTE_LOG(INFO, LTHREAD,
-		"stopping scheduler %p on lcore %u phys core %u\n",
-		sched, rte_lcore_id(),
-		rte_lcore_index(rte_lcore_id()));
-	fflush(stdout);
-}
-
-/*
- * Return the scheduler for this lcore
- *
- */
-struct lthread_sched *_lthread_sched_get(unsigned int lcore_id)
-{
-	struct lthread_sched *res = NULL;
-
-	if (lcore_id < LTHREAD_MAX_LCORES)
-		res = schedcore[lcore_id];
-
-	return res;
-}
-
-/*
- * migrate the current thread to another scheduler running
- * on the specified lcore.
- */
-int lthread_set_affinity(unsigned lcoreid)
-{
-	struct lthread *lt = THIS_LTHREAD;
-	struct lthread_sched *dest_sched;
-
-	if (unlikely(lcoreid >= LTHREAD_MAX_LCORES))
-		return POSIX_ERRNO(EINVAL);
-
-	DIAG_EVENT(lt, LT_DIAG_LTHREAD_AFFINITY, lcoreid, 0);
-
-	dest_sched = schedcore[lcoreid];
-
-	if (unlikely(dest_sched == NULL))
-		return POSIX_ERRNO(EINVAL);
-
-	if (likely(dest_sched != THIS_SCHED)) {
-		lt->sched = dest_sched;
-		lt->pending_wr_queue = dest_sched->pready;
-		_affinitize();
-		return 0;
-	}
-	return 0;
-}
diff --git a/examples/performance-thread/common/lthread_sched.h b/examples/performance-thread/common/lthread_sched.h
deleted file mode 100644
index aa2f0c4..0000000
--- a/examples/performance-thread/common/lthread_sched.h
+++ /dev/null
@@ -1,159 +0,0 @@
-/*-
- *   BSD LICENSE
- *
- *   Copyright(c) 2015  Intel Corporation. All rights reserved.
- *   All rights reserved.
- *
- *   Redistribution and use in source and binary forms, with or without
- *   modification, are permitted provided that the following conditions
- *   are met:
- *
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above copyright
- *       notice, this list of conditions and the following disclaimer in
- *       the documentation and/or other materials provided with the
- *       distribution.
- *     * Neither the name of Intel Corporation nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * Some portions of this software is derived from the
- * https://github.com/halayli/lthread which carrys the following license.
- *
- * Copyright (C) 2012, Hasan Alayli <halayli@gmail.com>
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- * 1. Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- * 2. Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *
- * THIS SOFTWARE IS PROVIDED BY AUTHOR AND CONTRIBUTORS ``AS IS'' AND
- * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
- * ARE DISCLAIMED.  IN NO EVENT SHALL AUTHOR OR CONTRIBUTORS BE LIABLE
- * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
- * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
- * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
- * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
- * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
- * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
- * SUCH DAMAGE.
- */
-
-#ifndef LTHREAD_SCHED_H_
-#define LTHREAD_SCHED_H_
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-#include "lthread_int.h"
-#include "lthread_queue.h"
-#include "lthread_objcache.h"
-#include "lthread_diag.h"
-#include "ctx.h"
-
-/*
- * insert an lthread into a queue
- */
-static inline void
-_ready_queue_insert(struct lthread_sched *sched, struct lthread *lt)
-{
-	if (sched == THIS_SCHED)
-		_lthread_queue_insert_sp((THIS_SCHED)->ready, lt);
-	else
-		_lthread_queue_insert_mp(sched->pready, lt);
-}
-
-/*
- * remove an lthread from a queue
- */
-static inline struct lthread *_ready_queue_remove(struct lthread_queue *q)
-{
-	return _lthread_queue_remove(q);
-}
-
-/**
- * Return true if the ready queue is empty
- */
-static inline int _ready_queue_empty(struct lthread_queue *q)
-{
-	return _lthread_queue_empty(q);
-}
-
-static inline uint64_t _sched_now(void)
-{
-	uint64_t now = rte_rdtsc();
-
-	if (now > (THIS_SCHED)->birth)
-		return now - (THIS_SCHED)->birth;
-	if (now < (THIS_SCHED)->birth)
-		return (THIS_SCHED)->birth - now;
-	/* never return 0 because this means sleep forever */
-	return 1;
-}
-
-static __rte_always_inline void
-_affinitize(void);
-static inline void
-_affinitize(void)
-{
-	struct lthread *lt = THIS_LTHREAD;
-
-	DIAG_EVENT(lt, LT_DIAG_LTHREAD_SUSPENDED, 0, 0);
-	ctx_switch(&(THIS_SCHED)->ctx, &lt->ctx);
-}
-
-static __rte_always_inline void
-_suspend(void);
-static inline void
-_suspend(void)
-{
-	struct lthread *lt = THIS_LTHREAD;
-
-	(THIS_SCHED)->nb_blocked_threads++;
-	DIAG_EVENT(lt, LT_DIAG_LTHREAD_SUSPENDED, 0, 0);
-	ctx_switch(&(THIS_SCHED)->ctx, &lt->ctx);
-	(THIS_SCHED)->nb_blocked_threads--;
-}
-
-static __rte_always_inline void
-_reschedule(void);
-static inline void
-_reschedule(void)
-{
-	struct lthread *lt = THIS_LTHREAD;
-
-	DIAG_EVENT(lt, LT_DIAG_LTHREAD_RESCHEDULED, 0, 0);
-	_ready_queue_insert(THIS_SCHED, lt);
-	ctx_switch(&(THIS_SCHED)->ctx, &lt->ctx);
-}
-
-extern struct lthread_sched *schedcore[];
-void _sched_timer_cb(struct rte_timer *tim, void *arg);
-void _sched_shutdown(__rte_unused void *arg);
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif				/* LTHREAD_SCHED_H_ */
diff --git a/examples/performance-thread/common/lthread_timer.h b/examples/performance-thread/common/lthread_timer.h
deleted file mode 100644
index f2d8671..0000000
--- a/examples/performance-thread/common/lthread_timer.h
+++ /dev/null
@@ -1,68 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2015 Intel Corporation
- */
-
-
-#ifndef LTHREAD_TIMER_H_
-#define LTHREAD_TIMER_H_
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-#include "lthread_int.h"
-#include "lthread_sched.h"
-
-
-static inline uint64_t
-_ns_to_clks(uint64_t ns)
-{
-	/*
-	 * clkns needs to be divided by 1E9 to get ns clocks. However,
-	 * dividing by this first would lose a lot of accuracy.
-	 * Dividing after a multiply by ns, could cause overflow of
-	 * uint64_t if ns is about 5 seconds [if we assume a max tsc
-	 * rate of 4GHz]. Therefore we first divide by 1E4, then
-	 * multiply and finally divide by 1E5. This allows ns to be
-	 * values many hours long, without overflow, while still keeping
-	 * reasonable accuracy.
-	 */
-	uint64_t clkns = rte_get_tsc_hz() / 1e4;
-
-	clkns *= ns;
-	clkns /= 1e5;
-
-	return clkns;
-}
-
-
-static inline void
-_timer_start(struct lthread *lt, uint64_t clks)
-{
-	if (clks > 0) {
-		DIAG_EVENT(lt, LT_DIAG_LTHREAD_TMR_START, &lt->tim, clks);
-		rte_timer_init(&lt->tim);
-		rte_timer_reset(&lt->tim,
-				clks,
-				SINGLE,
-				rte_lcore_id(),
-				_sched_timer_cb,
-				(void *)lt);
-	}
-}
-
-
-static inline void
-_timer_stop(struct lthread *lt)
-{
-	if (lt != NULL) {
-		DIAG_EVENT(lt, LT_DIAG_LTHREAD_TMR_DELETE, &lt->tim, 0);
-		rte_timer_stop(&lt->tim);
-	}
-}
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif /* LTHREAD_TIMER_H_ */
diff --git a/examples/performance-thread/common/lthread_tls.c b/examples/performance-thread/common/lthread_tls.c
deleted file mode 100644
index 07de6ca..0000000
--- a/examples/performance-thread/common/lthread_tls.c
+++ /dev/null
@@ -1,222 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2015 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <string.h>
-#include <stdint.h>
-#include <limits.h>
-#include <inttypes.h>
-#include <unistd.h>
-#include <pthread.h>
-#include <fcntl.h>
-#include <sys/time.h>
-#include <sys/mman.h>
-#include <sched.h>
-
-#include <rte_malloc.h>
-#include <rte_log.h>
-#include <rte_ring.h>
-#include <rte_atomic_64.h>
-
-#include "lthread_tls.h"
-#include "lthread_queue.h"
-#include "lthread_objcache.h"
-#include "lthread_sched.h"
-
-static struct rte_ring *key_pool;
-static uint64_t key_pool_init;
-
-/* needed to cause section start and end to be defined */
-RTE_DEFINE_PER_LTHREAD(void *, dummy);
-
-static struct lthread_key key_table[LTHREAD_MAX_KEYS];
-
-RTE_INIT(thread_tls_ctor)
-{
-	key_pool = NULL;
-	key_pool_init = 0;
-}
-
-/*
- * Initialize a pool of keys
- * These are unique tokens that can be obtained by threads
- * calling lthread_key_create()
- */
-void _lthread_key_pool_init(void)
-{
-	static struct rte_ring *pool;
-	struct lthread_key *new_key;
-	char name[MAX_LTHREAD_NAME_SIZE];
-
-	bzero(key_table, sizeof(key_table));
-
-	/* only one lcore should do this */
-	if (rte_atomic64_cmpset(&key_pool_init, 0, 1)) {
-
-		snprintf(name,
-			MAX_LTHREAD_NAME_SIZE,
-			"lthread_key_pool_%d",
-			getpid());
-
-		pool = rte_ring_create(name,
-					LTHREAD_MAX_KEYS, 0, 0);
-		RTE_ASSERT(pool);
-
-		int i;
-
-		for (i = 1; i < LTHREAD_MAX_KEYS; i++) {
-			new_key = &key_table[i];
-			rte_ring_mp_enqueue((struct rte_ring *)pool,
-						(void *)new_key);
-		}
-		key_pool = pool;
-	}
-	/* other lcores wait here till done */
-	while (key_pool == NULL) {
-		rte_compiler_barrier();
-		sched_yield();
-	};
-}
-
-/*
- * Create a key
- * this means getting a key from the pool
- */
-int lthread_key_create(unsigned int *key, tls_destructor_func destructor)
-{
-	if (key == NULL)
-		return POSIX_ERRNO(EINVAL);
-
-	struct lthread_key *new_key;
-
-	if (rte_ring_mc_dequeue((struct rte_ring *)key_pool, (void **)&new_key)
-	    == 0) {
-		new_key->destructor = destructor;
-		*key = (new_key - key_table);
-
-		return 0;
-	}
-	return POSIX_ERRNO(EAGAIN);
-}
-
-
-/*
- * Delete a key
- */
-int lthread_key_delete(unsigned int k)
-{
-	struct lthread_key *key;
-
-	key = (struct lthread_key *) &key_table[k];
-
-	if (k > LTHREAD_MAX_KEYS)
-		return POSIX_ERRNO(EINVAL);
-
-	key->destructor = NULL;
-	rte_ring_mp_enqueue((struct rte_ring *)key_pool,
-					(void *)key);
-	return 0;
-}
-
-
-
-/*
- * Break association for all keys in use by this thread
- * invoke the destructor if available.
- * Since a destructor can create keys we could enter an infinite loop
- * therefore we give up after LTHREAD_DESTRUCTOR_ITERATIONS
- * the behavior is modelled on pthread
- */
-void _lthread_tls_destroy(struct lthread *lt)
-{
-	int i, k;
-	int nb_keys;
-	void *data;
-
-	for (i = 0; i < LTHREAD_DESTRUCTOR_ITERATIONS; i++) {
-
-		for (k = 1; k < LTHREAD_MAX_KEYS; k++) {
-
-			/* no keys in use ? */
-			nb_keys = lt->tls->nb_keys_inuse;
-			if (nb_keys == 0)
-				return;
-
-			/* this key not in use ? */
-			if (lt->tls->data[k] == NULL)
-				continue;
-
-			/* remove this key */
-			data = lt->tls->data[k];
-			lt->tls->data[k] = NULL;
-			lt->tls->nb_keys_inuse = nb_keys-1;
-
-			/* invoke destructor */
-			if (key_table[k].destructor != NULL)
-				key_table[k].destructor(data);
-		}
-	}
-}
-
-/*
- * Return the pointer associated with a key
- * If the key is no longer valid return NULL
- */
-void
-*lthread_getspecific(unsigned int k)
-{
-	void *res = NULL;
-
-	if (k < LTHREAD_MAX_KEYS)
-		res = THIS_LTHREAD->tls->data[k];
-
-	return res;
-}
-
-/*
- * Set a value against a key
- * If the key is no longer valid return an error
- * when storing value
- */
-int lthread_setspecific(unsigned int k, const void *data)
-{
-	if (k >= LTHREAD_MAX_KEYS)
-		return POSIX_ERRNO(EINVAL);
-
-	int n = THIS_LTHREAD->tls->nb_keys_inuse;
-
-	/* discard const qualifier */
-	char *p = (char *) (uintptr_t) data;
-
-
-	if (data != NULL) {
-		if (THIS_LTHREAD->tls->data[k] == NULL)
-			THIS_LTHREAD->tls->nb_keys_inuse = n+1;
-	}
-
-	THIS_LTHREAD->tls->data[k] = (void *) p;
-	return 0;
-}
-
-/*
- * Allocate data for TLS cache
-*/
-void _lthread_tls_alloc(struct lthread *lt)
-{
-	struct lthread_tls *tls;
-
-	tls = _lthread_objcache_alloc((THIS_SCHED)->tls_cache);
-
-	RTE_ASSERT(tls != NULL);
-
-	tls->root_sched = (THIS_SCHED);
-	lt->tls = tls;
-
-	/* allocate data for TLS varaiables using RTE_PER_LTHREAD macros */
-	if (sizeof(void *) < (uint64_t)RTE_PER_LTHREAD_SECTION_SIZE) {
-		lt->per_lthread_data =
-		    _lthread_objcache_alloc((THIS_SCHED)->per_lthread_cache);
-	}
-}
diff --git a/examples/performance-thread/common/lthread_tls.h b/examples/performance-thread/common/lthread_tls.h
deleted file mode 100644
index 4c262e9..0000000
--- a/examples/performance-thread/common/lthread_tls.h
+++ /dev/null
@@ -1,35 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2015 Intel Corporation
- */
-
-#ifndef LTHREAD_TLS_H_
-#define LTHREAD_TLS_H_
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-#include "lthread_api.h"
-
-#define RTE_PER_LTHREAD_SECTION_SIZE \
-(&__stop_per_lt - &__start_per_lt)
-
-struct lthread_key {
-	tls_destructor_func destructor;
-};
-
-struct lthread_tls {
-	void *data[LTHREAD_MAX_KEYS];
-	int  nb_keys_inuse;
-	struct lthread_sched *root_sched;
-};
-
-void _lthread_tls_destroy(struct lthread *lt);
-void _lthread_key_pool_init(void);
-void _lthread_tls_alloc(struct lthread *lt);
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif				/* LTHREAD_TLS_H_ */
diff --git a/examples/performance-thread/l3fwd-thread/Makefile b/examples/performance-thread/l3fwd-thread/Makefile
deleted file mode 100644
index 5ac5436..0000000
--- a/examples/performance-thread/l3fwd-thread/Makefile
+++ /dev/null
@@ -1,30 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2015 Intel Corporation
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-# binary name
-APP = l3fwd-thread
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-
-include $(RTE_SDK)/examples/performance-thread/common/common.mk
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -O3 -g $(USER_FLAGS) $(INCLUDES) $(WERROR_FLAGS)
-
-# workaround for a gcc bug with noreturn attribute
-# http://gcc.gnu.org/bugzilla/show_bug.cgi?id=12603
-#ifeq ($(CONFIG_RTE_TOOLCHAIN_GCC),y)
-CFLAGS_main.o += -Wno-return-type
-#endif
-
-include $(RTE_SDK)/mk/rte.extapp.mk
diff --git a/examples/performance-thread/l3fwd-thread/main.c b/examples/performance-thread/l3fwd-thread/main.c
deleted file mode 100644
index c5a173e..0000000
--- a/examples/performance-thread/l3fwd-thread/main.c
+++ /dev/null
@@ -1,3734 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#define _GNU_SOURCE
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <sys/types.h>
-#include <string.h>
-#include <sys/queue.h>
-#include <stdarg.h>
-#include <errno.h>
-#include <getopt.h>
-
-#include <rte_common.h>
-#include <rte_vect.h>
-#include <rte_byteorder.h>
-#include <rte_log.h>
-#include <rte_memory.h>
-#include <rte_memcpy.h>
-#include <rte_eal.h>
-#include <rte_launch.h>
-#include <rte_atomic.h>
-#include <rte_cycles.h>
-#include <rte_prefetch.h>
-#include <rte_lcore.h>
-#include <rte_per_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_interrupts.h>
-#include <rte_random.h>
-#include <rte_debug.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_ring.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-#include <rte_ip.h>
-#include <rte_tcp.h>
-#include <rte_udp.h>
-#include <rte_string_fns.h>
-#include <rte_pause.h>
-
-#include <cmdline_parse.h>
-#include <cmdline_parse_etheraddr.h>
-
-#include <lthread_api.h>
-
-#define APP_LOOKUP_EXACT_MATCH          0
-#define APP_LOOKUP_LPM                  1
-#define DO_RFC_1812_CHECKS
-
-/* Enable cpu-load stats 0-off, 1-on */
-#define APP_CPU_LOAD                 1
-
-#ifndef APP_LOOKUP_METHOD
-#define APP_LOOKUP_METHOD             APP_LOOKUP_LPM
-#endif
-
-#ifndef __GLIBC__ /* sched_getcpu() is glibc specific */
-#define sched_getcpu() rte_lcore_id()
-#endif
-
-static int
-check_ptype(int portid)
-{
-	int i, ret;
-	int ipv4 = 0, ipv6 = 0;
-
-	ret = rte_eth_dev_get_supported_ptypes(portid, RTE_PTYPE_L3_MASK, NULL,
-			0);
-	if (ret <= 0)
-		return 0;
-
-	uint32_t ptypes[ret];
-
-	ret = rte_eth_dev_get_supported_ptypes(portid, RTE_PTYPE_L3_MASK,
-			ptypes, ret);
-	for (i = 0; i < ret; ++i) {
-		if (ptypes[i] & RTE_PTYPE_L3_IPV4)
-			ipv4 = 1;
-		if (ptypes[i] & RTE_PTYPE_L3_IPV6)
-			ipv6 = 1;
-	}
-
-	if (ipv4 && ipv6)
-		return 1;
-
-	return 0;
-}
-
-static inline void
-parse_ptype(struct rte_mbuf *m)
-{
-	struct ether_hdr *eth_hdr;
-	uint32_t packet_type = RTE_PTYPE_UNKNOWN;
-	uint16_t ether_type;
-
-	eth_hdr = rte_pktmbuf_mtod(m, struct ether_hdr *);
-	ether_type = eth_hdr->ether_type;
-	if (ether_type == rte_cpu_to_be_16(ETHER_TYPE_IPv4))
-		packet_type |= RTE_PTYPE_L3_IPV4_EXT_UNKNOWN;
-	else if (ether_type == rte_cpu_to_be_16(ETHER_TYPE_IPv6))
-		packet_type |= RTE_PTYPE_L3_IPV6_EXT_UNKNOWN;
-
-	m->packet_type = packet_type;
-}
-
-static uint16_t
-cb_parse_ptype(__rte_unused uint16_t port, __rte_unused uint16_t queue,
-		struct rte_mbuf *pkts[], uint16_t nb_pkts,
-		__rte_unused uint16_t max_pkts, __rte_unused void *user_param)
-{
-	unsigned int i;
-
-	for (i = 0; i < nb_pkts; i++)
-		parse_ptype(pkts[i]);
-
-	return nb_pkts;
-}
-
-/*
- *  When set to zero, simple forwaring path is eanbled.
- *  When set to one, optimized forwarding path is enabled.
- *  Note that LPM optimisation path uses SSE4.1 instructions.
- */
-#define ENABLE_MULTI_BUFFER_OPTIMIZE	1
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_EXACT_MATCH)
-#include <rte_hash.h>
-#elif (APP_LOOKUP_METHOD == APP_LOOKUP_LPM)
-#include <rte_lpm.h>
-#include <rte_lpm6.h>
-#else
-#error "APP_LOOKUP_METHOD set to incorrect value"
-#endif
-
-#define RTE_LOGTYPE_L3FWD RTE_LOGTYPE_USER1
-
-#define MAX_JUMBO_PKT_LEN  9600
-
-#define IPV6_ADDR_LEN 16
-
-#define MEMPOOL_CACHE_SIZE 256
-
-/*
- * This expression is used to calculate the number of mbufs needed depending on
- * user input, taking into account memory for rx and tx hardware rings, cache
- * per lcore and mtable per port per lcore. RTE_MAX is used to ensure that
- * NB_MBUF never goes below a minimum value of 8192
- */
-
-#define NB_MBUF RTE_MAX(\
-		(nb_ports*nb_rx_queue*nb_rxd +      \
-		nb_ports*nb_lcores*MAX_PKT_BURST +  \
-		nb_ports*n_tx_queue*nb_txd +        \
-		nb_lcores*MEMPOOL_CACHE_SIZE),      \
-		(unsigned)8192)
-
-#define MAX_PKT_BURST     32
-#define BURST_TX_DRAIN_US 100 /* TX drain every ~100us */
-
-/*
- * Try to avoid TX buffering if we have at least MAX_TX_BURST packets to send.
- */
-#define	MAX_TX_BURST  (MAX_PKT_BURST / 2)
-#define BURST_SIZE    MAX_TX_BURST
-
-#define NB_SOCKETS 8
-
-/* Configure how many packets ahead to prefetch, when reading packets */
-#define PREFETCH_OFFSET	3
-
-/* Used to mark destination port as 'invalid'. */
-#define	BAD_PORT	((uint16_t)-1)
-
-#define FWDSTEP	4
-
-/*
- * Configurable number of RX/TX ring descriptors
- */
-#define RTE_TEST_RX_DESC_DEFAULT 1024
-#define RTE_TEST_TX_DESC_DEFAULT 1024
-static uint16_t nb_rxd = RTE_TEST_RX_DESC_DEFAULT;
-static uint16_t nb_txd = RTE_TEST_TX_DESC_DEFAULT;
-
-/* ethernet addresses of ports */
-static uint64_t dest_eth_addr[RTE_MAX_ETHPORTS];
-static struct ether_addr ports_eth_addr[RTE_MAX_ETHPORTS];
-
-static xmm_t val_eth[RTE_MAX_ETHPORTS];
-
-/* replace first 12B of the ethernet header. */
-#define	MASK_ETH 0x3f
-
-/* mask of enabled ports */
-static uint32_t enabled_port_mask;
-static int promiscuous_on; /**< Set in promiscuous mode off by default. */
-static int numa_on = 1;    /**< NUMA is enabled by default. */
-static int parse_ptype_on;
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_EXACT_MATCH)
-static int ipv6;           /**< ipv6 is false by default. */
-#endif
-
-#if (APP_CPU_LOAD == 1)
-
-#define MAX_CPU RTE_MAX_LCORE
-#define CPU_LOAD_TIMEOUT_US (5 * 1000 * 1000)  /**< Timeout for collecting 5s */
-
-#define CPU_PROCESS     0
-#define CPU_POLL        1
-#define MAX_CPU_COUNTER 2
-
-struct cpu_load {
-	uint16_t       n_cpu;
-	uint64_t       counter;
-	uint64_t       hits[MAX_CPU_COUNTER][MAX_CPU];
-} __rte_cache_aligned;
-
-static struct cpu_load cpu_load;
-static int cpu_load_lcore_id = -1;
-
-#define SET_CPU_BUSY(thread, counter) \
-		thread->conf.busy[counter] = 1
-
-#define SET_CPU_IDLE(thread, counter) \
-		thread->conf.busy[counter] = 0
-
-#define IS_CPU_BUSY(thread, counter) \
-		(thread->conf.busy[counter] > 0)
-
-#else
-
-#define SET_CPU_BUSY(thread, counter)
-#define SET_CPU_IDLE(thread, counter)
-#define IS_CPU_BUSY(thread, counter) 0
-
-#endif
-
-struct mbuf_table {
-	uint16_t len;
-	struct rte_mbuf *m_table[MAX_PKT_BURST];
-};
-
-struct lcore_rx_queue {
-	uint16_t port_id;
-	uint8_t queue_id;
-} __rte_cache_aligned;
-
-#define MAX_RX_QUEUE_PER_LCORE 16
-#define MAX_TX_QUEUE_PER_PORT  RTE_MAX_ETHPORTS
-#define MAX_RX_QUEUE_PER_PORT  128
-
-#define MAX_LCORE_PARAMS       1024
-struct rx_thread_params {
-	uint16_t port_id;
-	uint8_t queue_id;
-	uint8_t lcore_id;
-	uint8_t thread_id;
-} __rte_cache_aligned;
-
-static struct rx_thread_params rx_thread_params_array[MAX_LCORE_PARAMS];
-static struct rx_thread_params rx_thread_params_array_default[] = {
-	{0, 0, 2, 0},
-	{0, 1, 2, 1},
-	{0, 2, 2, 2},
-	{1, 0, 2, 3},
-	{1, 1, 2, 4},
-	{1, 2, 2, 5},
-	{2, 0, 2, 6},
-	{3, 0, 3, 7},
-	{3, 1, 3, 8},
-};
-
-static struct rx_thread_params *rx_thread_params =
-		rx_thread_params_array_default;
-static uint16_t nb_rx_thread_params = RTE_DIM(rx_thread_params_array_default);
-
-struct tx_thread_params {
-	uint8_t lcore_id;
-	uint8_t thread_id;
-} __rte_cache_aligned;
-
-static struct tx_thread_params tx_thread_params_array[MAX_LCORE_PARAMS];
-static struct tx_thread_params tx_thread_params_array_default[] = {
-	{4, 0},
-	{5, 1},
-	{6, 2},
-	{7, 3},
-	{8, 4},
-	{9, 5},
-	{10, 6},
-	{11, 7},
-	{12, 8},
-};
-
-static struct tx_thread_params *tx_thread_params =
-		tx_thread_params_array_default;
-static uint16_t nb_tx_thread_params = RTE_DIM(tx_thread_params_array_default);
-
-static struct rte_eth_conf port_conf = {
-	.rxmode = {
-		.mq_mode = ETH_MQ_RX_RSS,
-		.max_rx_pkt_len = ETHER_MAX_LEN,
-		.split_hdr_size = 0,
-		.ignore_offload_bitfield = 1,
-		.offloads = (DEV_RX_OFFLOAD_CHECKSUM |
-			     DEV_RX_OFFLOAD_CRC_STRIP),
-	},
-	.rx_adv_conf = {
-		.rss_conf = {
-			.rss_key = NULL,
-			.rss_hf = ETH_RSS_TCP,
-		},
-	},
-	.txmode = {
-		.mq_mode = ETH_MQ_TX_NONE,
-	},
-};
-
-static struct rte_mempool *pktmbuf_pool[NB_SOCKETS];
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_EXACT_MATCH)
-
-#include <rte_hash_crc.h>
-#define DEFAULT_HASH_FUNC       rte_hash_crc
-
-struct ipv4_5tuple {
-	uint32_t ip_dst;
-	uint32_t ip_src;
-	uint16_t port_dst;
-	uint16_t port_src;
-	uint8_t  proto;
-} __attribute__((__packed__));
-
-union ipv4_5tuple_host {
-	struct {
-		uint8_t  pad0;
-		uint8_t  proto;
-		uint16_t pad1;
-		uint32_t ip_src;
-		uint32_t ip_dst;
-		uint16_t port_src;
-		uint16_t port_dst;
-	};
-	__m128i xmm;
-};
-
-#define XMM_NUM_IN_IPV6_5TUPLE 3
-
-struct ipv6_5tuple {
-	uint8_t  ip_dst[IPV6_ADDR_LEN];
-	uint8_t  ip_src[IPV6_ADDR_LEN];
-	uint16_t port_dst;
-	uint16_t port_src;
-	uint8_t  proto;
-} __attribute__((__packed__));
-
-union ipv6_5tuple_host {
-	struct {
-		uint16_t pad0;
-		uint8_t  proto;
-		uint8_t  pad1;
-		uint8_t  ip_src[IPV6_ADDR_LEN];
-		uint8_t  ip_dst[IPV6_ADDR_LEN];
-		uint16_t port_src;
-		uint16_t port_dst;
-		uint64_t reserve;
-	};
-	__m128i xmm[XMM_NUM_IN_IPV6_5TUPLE];
-};
-
-struct ipv4_l3fwd_route {
-	struct ipv4_5tuple key;
-	uint8_t if_out;
-};
-
-struct ipv6_l3fwd_route {
-	struct ipv6_5tuple key;
-	uint8_t if_out;
-};
-
-static struct ipv4_l3fwd_route ipv4_l3fwd_route_array[] = {
-	{{IPv4(101, 0, 0, 0), IPv4(100, 10, 0, 1),  101, 11, IPPROTO_TCP}, 0},
-	{{IPv4(201, 0, 0, 0), IPv4(200, 20, 0, 1),  102, 12, IPPROTO_TCP}, 1},
-	{{IPv4(111, 0, 0, 0), IPv4(100, 30, 0, 1),  101, 11, IPPROTO_TCP}, 2},
-	{{IPv4(211, 0, 0, 0), IPv4(200, 40, 0, 1),  102, 12, IPPROTO_TCP}, 3},
-};
-
-static struct ipv6_l3fwd_route ipv6_l3fwd_route_array[] = {
-	{{
-	{0xfe, 0x80, 0, 0, 0, 0, 0, 0, 0x02, 0x1e, 0x67, 0xff, 0xfe, 0, 0, 0},
-	{0xfe, 0x80, 0, 0, 0, 0, 0, 0, 0x02, 0x1b, 0x21, 0xff, 0xfe, 0x91, 0x38,
-			0x05},
-	101, 11, IPPROTO_TCP}, 0},
-
-	{{
-	{0xfe, 0x90, 0, 0, 0, 0, 0, 0, 0x02, 0x1e, 0x67, 0xff, 0xfe, 0, 0, 0},
-	{0xfe, 0x90, 0, 0, 0, 0, 0, 0, 0x02, 0x1b, 0x21, 0xff, 0xfe, 0x91, 0x38,
-			0x05},
-	102, 12, IPPROTO_TCP}, 1},
-
-	{{
-	{0xfe, 0xa0, 0, 0, 0, 0, 0, 0, 0x02, 0x1e, 0x67, 0xff, 0xfe, 0, 0, 0},
-	{0xfe, 0xa0, 0, 0, 0, 0, 0, 0, 0x02, 0x1b, 0x21, 0xff, 0xfe, 0x91, 0x38,
-			0x05},
-	101, 11, IPPROTO_TCP}, 2},
-
-	{{
-	{0xfe, 0xb0, 0, 0, 0, 0, 0, 0, 0x02, 0x1e, 0x67, 0xff, 0xfe, 0, 0, 0},
-	{0xfe, 0xb0, 0, 0, 0, 0, 0, 0, 0x02, 0x1b, 0x21, 0xff, 0xfe, 0x91, 0x38,
-			0x05},
-	102, 12, IPPROTO_TCP}, 3},
-};
-
-typedef struct rte_hash lookup_struct_t;
-static lookup_struct_t *ipv4_l3fwd_lookup_struct[NB_SOCKETS];
-static lookup_struct_t *ipv6_l3fwd_lookup_struct[NB_SOCKETS];
-
-#ifdef RTE_ARCH_X86_64
-/* default to 4 million hash entries (approx) */
-#define L3FWD_HASH_ENTRIES (1024*1024*4)
-#else
-/* 32-bit has less address-space for hugepage memory, limit to 1M entries */
-#define L3FWD_HASH_ENTRIES (1024*1024*1)
-#endif
-#define HASH_ENTRY_NUMBER_DEFAULT 4
-
-static uint32_t hash_entry_number = HASH_ENTRY_NUMBER_DEFAULT;
-
-static inline uint32_t
-ipv4_hash_crc(const void *data, __rte_unused uint32_t data_len,
-		uint32_t init_val)
-{
-	const union ipv4_5tuple_host *k;
-	uint32_t t;
-	const uint32_t *p;
-
-	k = data;
-	t = k->proto;
-	p = (const uint32_t *)&k->port_src;
-
-	init_val = rte_hash_crc_4byte(t, init_val);
-	init_val = rte_hash_crc_4byte(k->ip_src, init_val);
-	init_val = rte_hash_crc_4byte(k->ip_dst, init_val);
-	init_val = rte_hash_crc_4byte(*p, init_val);
-	return init_val;
-}
-
-static inline uint32_t
-ipv6_hash_crc(const void *data, __rte_unused uint32_t data_len,
-		uint32_t init_val)
-{
-	const union ipv6_5tuple_host *k;
-	uint32_t t;
-	const uint32_t *p;
-	const uint32_t *ip_src0, *ip_src1, *ip_src2, *ip_src3;
-	const uint32_t *ip_dst0, *ip_dst1, *ip_dst2, *ip_dst3;
-
-	k = data;
-	t = k->proto;
-	p = (const uint32_t *)&k->port_src;
-
-	ip_src0 = (const uint32_t *) k->ip_src;
-	ip_src1 = (const uint32_t *)(k->ip_src + 4);
-	ip_src2 = (const uint32_t *)(k->ip_src + 8);
-	ip_src3 = (const uint32_t *)(k->ip_src + 12);
-	ip_dst0 = (const uint32_t *) k->ip_dst;
-	ip_dst1 = (const uint32_t *)(k->ip_dst + 4);
-	ip_dst2 = (const uint32_t *)(k->ip_dst + 8);
-	ip_dst3 = (const uint32_t *)(k->ip_dst + 12);
-	init_val = rte_hash_crc_4byte(t, init_val);
-	init_val = rte_hash_crc_4byte(*ip_src0, init_val);
-	init_val = rte_hash_crc_4byte(*ip_src1, init_val);
-	init_val = rte_hash_crc_4byte(*ip_src2, init_val);
-	init_val = rte_hash_crc_4byte(*ip_src3, init_val);
-	init_val = rte_hash_crc_4byte(*ip_dst0, init_val);
-	init_val = rte_hash_crc_4byte(*ip_dst1, init_val);
-	init_val = rte_hash_crc_4byte(*ip_dst2, init_val);
-	init_val = rte_hash_crc_4byte(*ip_dst3, init_val);
-	init_val = rte_hash_crc_4byte(*p, init_val);
-	return init_val;
-}
-
-#define IPV4_L3FWD_NUM_ROUTES RTE_DIM(ipv4_l3fwd_route_array)
-#define IPV6_L3FWD_NUM_ROUTES RTE_DIM(ipv6_l3fwd_route_array)
-
-static uint8_t ipv4_l3fwd_out_if[L3FWD_HASH_ENTRIES] __rte_cache_aligned;
-static uint8_t ipv6_l3fwd_out_if[L3FWD_HASH_ENTRIES] __rte_cache_aligned;
-
-#endif
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_LPM)
-struct ipv4_l3fwd_route {
-	uint32_t ip;
-	uint8_t  depth;
-	uint8_t  if_out;
-};
-
-struct ipv6_l3fwd_route {
-	uint8_t ip[16];
-	uint8_t depth;
-	uint8_t if_out;
-};
-
-static struct ipv4_l3fwd_route ipv4_l3fwd_route_array[] = {
-	{IPv4(1, 1, 1, 0), 24, 0},
-	{IPv4(2, 1, 1, 0), 24, 1},
-	{IPv4(3, 1, 1, 0), 24, 2},
-	{IPv4(4, 1, 1, 0), 24, 3},
-	{IPv4(5, 1, 1, 0), 24, 4},
-	{IPv4(6, 1, 1, 0), 24, 5},
-	{IPv4(7, 1, 1, 0), 24, 6},
-	{IPv4(8, 1, 1, 0), 24, 7},
-};
-
-static struct ipv6_l3fwd_route ipv6_l3fwd_route_array[] = {
-	{{1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1}, 48, 0},
-	{{2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1}, 48, 1},
-	{{3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1}, 48, 2},
-	{{4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1}, 48, 3},
-	{{5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1}, 48, 4},
-	{{6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1}, 48, 5},
-	{{7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1}, 48, 6},
-	{{8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1}, 48, 7},
-};
-
-#define IPV4_L3FWD_NUM_ROUTES RTE_DIM(ipv4_l3fwd_route_array)
-#define IPV6_L3FWD_NUM_ROUTES RTE_DIM(ipv6_l3fwd_route_array)
-
-#define IPV4_L3FWD_LPM_MAX_RULES         1024
-#define IPV6_L3FWD_LPM_MAX_RULES         1024
-#define IPV6_L3FWD_LPM_NUMBER_TBL8S (1 << 16)
-
-typedef struct rte_lpm lookup_struct_t;
-typedef struct rte_lpm6 lookup6_struct_t;
-static lookup_struct_t *ipv4_l3fwd_lookup_struct[NB_SOCKETS];
-static lookup6_struct_t *ipv6_l3fwd_lookup_struct[NB_SOCKETS];
-#endif
-
-struct lcore_conf {
-	lookup_struct_t *ipv4_lookup_struct;
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_LPM)
-	lookup6_struct_t *ipv6_lookup_struct;
-#else
-	lookup_struct_t *ipv6_lookup_struct;
-#endif
-	void *data;
-} __rte_cache_aligned;
-
-static struct lcore_conf lcore_conf[RTE_MAX_LCORE];
-RTE_DEFINE_PER_LCORE(struct lcore_conf *, lcore_conf);
-
-#define MAX_RX_QUEUE_PER_THREAD 16
-#define MAX_TX_PORT_PER_THREAD  RTE_MAX_ETHPORTS
-#define MAX_TX_QUEUE_PER_PORT   RTE_MAX_ETHPORTS
-#define MAX_RX_QUEUE_PER_PORT   128
-
-#define MAX_RX_THREAD 1024
-#define MAX_TX_THREAD 1024
-#define MAX_THREAD    (MAX_RX_THREAD + MAX_TX_THREAD)
-
-/**
- * Producers and consumers threads configuration
- */
-static int lthreads_on = 1; /**< Use lthreads for processing*/
-
-rte_atomic16_t rx_counter;  /**< Number of spawned rx threads */
-rte_atomic16_t tx_counter;  /**< Number of spawned tx threads */
-
-struct thread_conf {
-	uint16_t lcore_id;      /**< Initial lcore for rx thread */
-	uint16_t cpu_id;        /**< Cpu id for cpu load stats counter */
-	uint16_t thread_id;     /**< Thread ID */
-
-#if (APP_CPU_LOAD > 0)
-	int busy[MAX_CPU_COUNTER];
-#endif
-};
-
-struct thread_rx_conf {
-	struct thread_conf conf;
-
-	uint16_t n_rx_queue;
-	struct lcore_rx_queue rx_queue_list[MAX_RX_QUEUE_PER_LCORE];
-
-	uint16_t n_ring;        /**< Number of output rings */
-	struct rte_ring *ring[RTE_MAX_LCORE];
-	struct lthread_cond *ready[RTE_MAX_LCORE];
-
-#if (APP_CPU_LOAD > 0)
-	int busy[MAX_CPU_COUNTER];
-#endif
-} __rte_cache_aligned;
-
-uint16_t n_rx_thread;
-struct thread_rx_conf rx_thread[MAX_RX_THREAD];
-
-struct thread_tx_conf {
-	struct thread_conf conf;
-
-	uint16_t tx_queue_id[RTE_MAX_LCORE];
-	struct mbuf_table tx_mbufs[RTE_MAX_LCORE];
-
-	struct rte_ring *ring;
-	struct lthread_cond **ready;
-
-} __rte_cache_aligned;
-
-uint16_t n_tx_thread;
-struct thread_tx_conf tx_thread[MAX_TX_THREAD];
-
-/* Send burst of packets on an output interface */
-static inline int
-send_burst(struct thread_tx_conf *qconf, uint16_t n, uint16_t port)
-{
-	struct rte_mbuf **m_table;
-	int ret;
-	uint16_t queueid;
-
-	queueid = qconf->tx_queue_id[port];
-	m_table = (struct rte_mbuf **)qconf->tx_mbufs[port].m_table;
-
-	ret = rte_eth_tx_burst(port, queueid, m_table, n);
-	if (unlikely(ret < n)) {
-		do {
-			rte_pktmbuf_free(m_table[ret]);
-		} while (++ret < n);
-	}
-
-	return 0;
-}
-
-/* Enqueue a single packet, and send burst if queue is filled */
-static inline int
-send_single_packet(struct rte_mbuf *m, uint16_t port)
-{
-	uint16_t len;
-	struct thread_tx_conf *qconf;
-
-	if (lthreads_on)
-		qconf = (struct thread_tx_conf *)lthread_get_data();
-	else
-		qconf = (struct thread_tx_conf *)RTE_PER_LCORE(lcore_conf)->data;
-
-	len = qconf->tx_mbufs[port].len;
-	qconf->tx_mbufs[port].m_table[len] = m;
-	len++;
-
-	/* enough pkts to be sent */
-	if (unlikely(len == MAX_PKT_BURST)) {
-		send_burst(qconf, MAX_PKT_BURST, port);
-		len = 0;
-	}
-
-	qconf->tx_mbufs[port].len = len;
-	return 0;
-}
-
-#if ((APP_LOOKUP_METHOD == APP_LOOKUP_LPM) && \
-	(ENABLE_MULTI_BUFFER_OPTIMIZE == 1))
-static __rte_always_inline void
-send_packetsx4(uint16_t port,
-	struct rte_mbuf *m[], uint32_t num)
-{
-	uint32_t len, j, n;
-	struct thread_tx_conf *qconf;
-
-	if (lthreads_on)
-		qconf = (struct thread_tx_conf *)lthread_get_data();
-	else
-		qconf = (struct thread_tx_conf *)RTE_PER_LCORE(lcore_conf)->data;
-
-	len = qconf->tx_mbufs[port].len;
-
-	/*
-	 * If TX buffer for that queue is empty, and we have enough packets,
-	 * then send them straightway.
-	 */
-	if (num >= MAX_TX_BURST && len == 0) {
-		n = rte_eth_tx_burst(port, qconf->tx_queue_id[port], m, num);
-		if (unlikely(n < num)) {
-			do {
-				rte_pktmbuf_free(m[n]);
-			} while (++n < num);
-		}
-		return;
-	}
-
-	/*
-	 * Put packets into TX buffer for that queue.
-	 */
-
-	n = len + num;
-	n = (n > MAX_PKT_BURST) ? MAX_PKT_BURST - len : num;
-
-	j = 0;
-	switch (n % FWDSTEP) {
-	while (j < n) {
-	case 0:
-		qconf->tx_mbufs[port].m_table[len + j] = m[j];
-		j++;
-		/* fall-through */
-	case 3:
-		qconf->tx_mbufs[port].m_table[len + j] = m[j];
-		j++;
-		/* fall-through */
-	case 2:
-		qconf->tx_mbufs[port].m_table[len + j] = m[j];
-		j++;
-		/* fall-through */
-	case 1:
-		qconf->tx_mbufs[port].m_table[len + j] = m[j];
-		j++;
-	}
-	}
-
-	len += n;
-
-	/* enough pkts to be sent */
-	if (unlikely(len == MAX_PKT_BURST)) {
-
-		send_burst(qconf, MAX_PKT_BURST, port);
-
-		/* copy rest of the packets into the TX buffer. */
-		len = num - n;
-		j = 0;
-		switch (len % FWDSTEP) {
-		while (j < len) {
-		case 0:
-			qconf->tx_mbufs[port].m_table[j] = m[n + j];
-			j++;
-			/* fall-through */
-		case 3:
-			qconf->tx_mbufs[port].m_table[j] = m[n + j];
-			j++;
-			/* fall-through */
-		case 2:
-			qconf->tx_mbufs[port].m_table[j] = m[n + j];
-			j++;
-			/* fall-through */
-		case 1:
-			qconf->tx_mbufs[port].m_table[j] = m[n + j];
-			j++;
-		}
-		}
-	}
-
-	qconf->tx_mbufs[port].len = len;
-}
-#endif /* APP_LOOKUP_LPM */
-
-#ifdef DO_RFC_1812_CHECKS
-static inline int
-is_valid_ipv4_pkt(struct ipv4_hdr *pkt, uint32_t link_len)
-{
-	/* From http://www.rfc-editor.org/rfc/rfc1812.txt section 5.2.2 */
-	/*
-	 * 1. The packet length reported by the Link Layer must be large
-	 * enough to hold the minimum length legal IP datagram (20 bytes).
-	 */
-	if (link_len < sizeof(struct ipv4_hdr))
-		return -1;
-
-	/* 2. The IP checksum must be correct. */
-	/* this is checked in H/W */
-
-	/*
-	 * 3. The IP version number must be 4. If the version number is not 4
-	 * then the packet may be another version of IP, such as IPng or
-	 * ST-II.
-	 */
-	if (((pkt->version_ihl) >> 4) != 4)
-		return -3;
-	/*
-	 * 4. The IP header length field must be large enough to hold the
-	 * minimum length legal IP datagram (20 bytes = 5 words).
-	 */
-	if ((pkt->version_ihl & 0xf) < 5)
-		return -4;
-
-	/*
-	 * 5. The IP total length field must be large enough to hold the IP
-	 * datagram header, whose length is specified in the IP header length
-	 * field.
-	 */
-	if (rte_cpu_to_be_16(pkt->total_length) < sizeof(struct ipv4_hdr))
-		return -5;
-
-	return 0;
-}
-#endif
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_EXACT_MATCH)
-
-static __m128i mask0;
-static __m128i mask1;
-static __m128i mask2;
-static inline uint16_t
-get_ipv4_dst_port(void *ipv4_hdr, uint16_t portid,
-		lookup_struct_t *ipv4_l3fwd_lookup_struct)
-{
-	int ret = 0;
-	union ipv4_5tuple_host key;
-
-	ipv4_hdr = (uint8_t *)ipv4_hdr + offsetof(struct ipv4_hdr, time_to_live);
-	__m128i data = _mm_loadu_si128((__m128i *)(ipv4_hdr));
-	/* Get 5 tuple: dst port, src port, dst IP address, src IP address and
-	   protocol */
-	key.xmm = _mm_and_si128(data, mask0);
-	/* Find destination port */
-	ret = rte_hash_lookup(ipv4_l3fwd_lookup_struct, (const void *)&key);
-	return ((ret < 0) ? portid : ipv4_l3fwd_out_if[ret]);
-}
-
-static inline uint16_t
-get_ipv6_dst_port(void *ipv6_hdr, uint16_t portid,
-		lookup_struct_t *ipv6_l3fwd_lookup_struct)
-{
-	int ret = 0;
-	union ipv6_5tuple_host key;
-
-	ipv6_hdr = (uint8_t *)ipv6_hdr + offsetof(struct ipv6_hdr, payload_len);
-	__m128i data0 = _mm_loadu_si128((__m128i *)(ipv6_hdr));
-	__m128i data1 = _mm_loadu_si128((__m128i *)(((uint8_t *)ipv6_hdr) +
-			sizeof(__m128i)));
-	__m128i data2 = _mm_loadu_si128((__m128i *)(((uint8_t *)ipv6_hdr) +
-			sizeof(__m128i) + sizeof(__m128i)));
-	/* Get part of 5 tuple: src IP address lower 96 bits and protocol */
-	key.xmm[0] = _mm_and_si128(data0, mask1);
-	/* Get part of 5 tuple: dst IP address lower 96 bits and src IP address
-	   higher 32 bits */
-	key.xmm[1] = data1;
-	/* Get part of 5 tuple: dst port and src port and dst IP address higher
-	   32 bits */
-	key.xmm[2] = _mm_and_si128(data2, mask2);
-
-	/* Find destination port */
-	ret = rte_hash_lookup(ipv6_l3fwd_lookup_struct, (const void *)&key);
-	return ((ret < 0) ? portid : ipv6_l3fwd_out_if[ret]);
-}
-#endif
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_LPM)
-
-static inline uint16_t
-get_ipv4_dst_port(void *ipv4_hdr, uint16_t portid,
-		lookup_struct_t *ipv4_l3fwd_lookup_struct)
-{
-	uint32_t next_hop;
-
-	return ((rte_lpm_lookup(ipv4_l3fwd_lookup_struct,
-		rte_be_to_cpu_32(((struct ipv4_hdr *)ipv4_hdr)->dst_addr),
-		&next_hop) == 0) ? next_hop : portid);
-}
-
-static inline uint16_t
-get_ipv6_dst_port(void *ipv6_hdr,  uint16_t portid,
-		lookup6_struct_t *ipv6_l3fwd_lookup_struct)
-{
-	uint32_t next_hop;
-
-	return ((rte_lpm6_lookup(ipv6_l3fwd_lookup_struct,
-			((struct ipv6_hdr *)ipv6_hdr)->dst_addr, &next_hop) == 0) ?
-			next_hop : portid);
-}
-#endif
-
-static inline void l3fwd_simple_forward(struct rte_mbuf *m, uint16_t portid)
-		__attribute__((unused));
-
-#if ((APP_LOOKUP_METHOD == APP_LOOKUP_EXACT_MATCH) && \
-	(ENABLE_MULTI_BUFFER_OPTIMIZE == 1))
-
-#define MASK_ALL_PKTS   0xff
-#define EXCLUDE_1ST_PKT 0xfe
-#define EXCLUDE_2ND_PKT 0xfd
-#define EXCLUDE_3RD_PKT 0xfb
-#define EXCLUDE_4TH_PKT 0xf7
-#define EXCLUDE_5TH_PKT 0xef
-#define EXCLUDE_6TH_PKT 0xdf
-#define EXCLUDE_7TH_PKT 0xbf
-#define EXCLUDE_8TH_PKT 0x7f
-
-static inline void
-simple_ipv4_fwd_8pkts(struct rte_mbuf *m[8], uint16_t portid)
-{
-	struct ether_hdr *eth_hdr[8];
-	struct ipv4_hdr *ipv4_hdr[8];
-	uint16_t dst_port[8];
-	int32_t ret[8];
-	union ipv4_5tuple_host key[8];
-	__m128i data[8];
-
-	eth_hdr[0] = rte_pktmbuf_mtod(m[0], struct ether_hdr *);
-	eth_hdr[1] = rte_pktmbuf_mtod(m[1], struct ether_hdr *);
-	eth_hdr[2] = rte_pktmbuf_mtod(m[2], struct ether_hdr *);
-	eth_hdr[3] = rte_pktmbuf_mtod(m[3], struct ether_hdr *);
-	eth_hdr[4] = rte_pktmbuf_mtod(m[4], struct ether_hdr *);
-	eth_hdr[5] = rte_pktmbuf_mtod(m[5], struct ether_hdr *);
-	eth_hdr[6] = rte_pktmbuf_mtod(m[6], struct ether_hdr *);
-	eth_hdr[7] = rte_pktmbuf_mtod(m[7], struct ether_hdr *);
-
-	/* Handle IPv4 headers.*/
-	ipv4_hdr[0] = rte_pktmbuf_mtod_offset(m[0], struct ipv4_hdr *,
-			sizeof(struct ether_hdr));
-	ipv4_hdr[1] = rte_pktmbuf_mtod_offset(m[1], struct ipv4_hdr *,
-			sizeof(struct ether_hdr));
-	ipv4_hdr[2] = rte_pktmbuf_mtod_offset(m[2], struct ipv4_hdr *,
-			sizeof(struct ether_hdr));
-	ipv4_hdr[3] = rte_pktmbuf_mtod_offset(m[3], struct ipv4_hdr *,
-			sizeof(struct ether_hdr));
-	ipv4_hdr[4] = rte_pktmbuf_mtod_offset(m[4], struct ipv4_hdr *,
-			sizeof(struct ether_hdr));
-	ipv4_hdr[5] = rte_pktmbuf_mtod_offset(m[5], struct ipv4_hdr *,
-			sizeof(struct ether_hdr));
-	ipv4_hdr[6] = rte_pktmbuf_mtod_offset(m[6], struct ipv4_hdr *,
-			sizeof(struct ether_hdr));
-	ipv4_hdr[7] = rte_pktmbuf_mtod_offset(m[7], struct ipv4_hdr *,
-			sizeof(struct ether_hdr));
-
-#ifdef DO_RFC_1812_CHECKS
-	/* Check to make sure the packet is valid (RFC1812) */
-	uint8_t valid_mask = MASK_ALL_PKTS;
-
-	if (is_valid_ipv4_pkt(ipv4_hdr[0], m[0]->pkt_len) < 0) {
-		rte_pktmbuf_free(m[0]);
-		valid_mask &= EXCLUDE_1ST_PKT;
-	}
-	if (is_valid_ipv4_pkt(ipv4_hdr[1], m[1]->pkt_len) < 0) {
-		rte_pktmbuf_free(m[1]);
-		valid_mask &= EXCLUDE_2ND_PKT;
-	}
-	if (is_valid_ipv4_pkt(ipv4_hdr[2], m[2]->pkt_len) < 0) {
-		rte_pktmbuf_free(m[2]);
-		valid_mask &= EXCLUDE_3RD_PKT;
-	}
-	if (is_valid_ipv4_pkt(ipv4_hdr[3], m[3]->pkt_len) < 0) {
-		rte_pktmbuf_free(m[3]);
-		valid_mask &= EXCLUDE_4TH_PKT;
-	}
-	if (is_valid_ipv4_pkt(ipv4_hdr[4], m[4]->pkt_len) < 0) {
-		rte_pktmbuf_free(m[4]);
-		valid_mask &= EXCLUDE_5TH_PKT;
-	}
-	if (is_valid_ipv4_pkt(ipv4_hdr[5], m[5]->pkt_len) < 0) {
-		rte_pktmbuf_free(m[5]);
-		valid_mask &= EXCLUDE_6TH_PKT;
-	}
-	if (is_valid_ipv4_pkt(ipv4_hdr[6], m[6]->pkt_len) < 0) {
-		rte_pktmbuf_free(m[6]);
-		valid_mask &= EXCLUDE_7TH_PKT;
-	}
-	if (is_valid_ipv4_pkt(ipv4_hdr[7], m[7]->pkt_len) < 0) {
-		rte_pktmbuf_free(m[7]);
-		valid_mask &= EXCLUDE_8TH_PKT;
-	}
-	if (unlikely(valid_mask != MASK_ALL_PKTS)) {
-		if (valid_mask == 0)
-			return;
-
-		uint8_t i = 0;
-
-		for (i = 0; i < 8; i++)
-			if ((0x1 << i) & valid_mask)
-				l3fwd_simple_forward(m[i], portid);
-	}
-#endif /* End of #ifdef DO_RFC_1812_CHECKS */
-
-	data[0] = _mm_loadu_si128(rte_pktmbuf_mtod_offset(m[0], __m128i *,
-			sizeof(struct ether_hdr) +
-			offsetof(struct ipv4_hdr, time_to_live)));
-	data[1] = _mm_loadu_si128(rte_pktmbuf_mtod_offset(m[1], __m128i *,
-			sizeof(struct ether_hdr) +
-			offsetof(struct ipv4_hdr, time_to_live)));
-	data[2] = _mm_loadu_si128(rte_pktmbuf_mtod_offset(m[2], __m128i *,
-			sizeof(struct ether_hdr) +
-			offsetof(struct ipv4_hdr, time_to_live)));
-	data[3] = _mm_loadu_si128(rte_pktmbuf_mtod_offset(m[3], __m128i *,
-			sizeof(struct ether_hdr) +
-			offsetof(struct ipv4_hdr, time_to_live)));
-	data[4] = _mm_loadu_si128(rte_pktmbuf_mtod_offset(m[4], __m128i *,
-			sizeof(struct ether_hdr) +
-			offsetof(struct ipv4_hdr, time_to_live)));
-	data[5] = _mm_loadu_si128(rte_pktmbuf_mtod_offset(m[5], __m128i *,
-			sizeof(struct ether_hdr) +
-			offsetof(struct ipv4_hdr, time_to_live)));
-	data[6] = _mm_loadu_si128(rte_pktmbuf_mtod_offset(m[6], __m128i *,
-			sizeof(struct ether_hdr) +
-			offsetof(struct ipv4_hdr, time_to_live)));
-	data[7] = _mm_loadu_si128(rte_pktmbuf_mtod_offset(m[7], __m128i *,
-			sizeof(struct ether_hdr) +
-			offsetof(struct ipv4_hdr, time_to_live)));
-
-	key[0].xmm = _mm_and_si128(data[0], mask0);
-	key[1].xmm = _mm_and_si128(data[1], mask0);
-	key[2].xmm = _mm_and_si128(data[2], mask0);
-	key[3].xmm = _mm_and_si128(data[3], mask0);
-	key[4].xmm = _mm_and_si128(data[4], mask0);
-	key[5].xmm = _mm_and_si128(data[5], mask0);
-	key[6].xmm = _mm_and_si128(data[6], mask0);
-	key[7].xmm = _mm_and_si128(data[7], mask0);
-
-	const void *key_array[8] = {&key[0], &key[1], &key[2], &key[3],
-			&key[4], &key[5], &key[6], &key[7]};
-
-	rte_hash_lookup_bulk(RTE_PER_LCORE(lcore_conf)->ipv4_lookup_struct,
-			&key_array[0], 8, ret);
-	dst_port[0] = ((ret[0] < 0) ? portid : ipv4_l3fwd_out_if[ret[0]]);
-	dst_port[1] = ((ret[1] < 0) ? portid : ipv4_l3fwd_out_if[ret[1]]);
-	dst_port[2] = ((ret[2] < 0) ? portid : ipv4_l3fwd_out_if[ret[2]]);
-	dst_port[3] = ((ret[3] < 0) ? portid : ipv4_l3fwd_out_if[ret[3]]);
-	dst_port[4] = ((ret[4] < 0) ? portid : ipv4_l3fwd_out_if[ret[4]]);
-	dst_port[5] = ((ret[5] < 0) ? portid : ipv4_l3fwd_out_if[ret[5]]);
-	dst_port[6] = ((ret[6] < 0) ? portid : ipv4_l3fwd_out_if[ret[6]]);
-	dst_port[7] = ((ret[7] < 0) ? portid : ipv4_l3fwd_out_if[ret[7]]);
-
-	if (dst_port[0] >= RTE_MAX_ETHPORTS ||
-			(enabled_port_mask & 1 << dst_port[0]) == 0)
-		dst_port[0] = portid;
-	if (dst_port[1] >= RTE_MAX_ETHPORTS ||
-			(enabled_port_mask & 1 << dst_port[1]) == 0)
-		dst_port[1] = portid;
-	if (dst_port[2] >= RTE_MAX_ETHPORTS ||
-			(enabled_port_mask & 1 << dst_port[2]) == 0)
-		dst_port[2] = portid;
-	if (dst_port[3] >= RTE_MAX_ETHPORTS ||
-			(enabled_port_mask & 1 << dst_port[3]) == 0)
-		dst_port[3] = portid;
-	if (dst_port[4] >= RTE_MAX_ETHPORTS ||
-			(enabled_port_mask & 1 << dst_port[4]) == 0)
-		dst_port[4] = portid;
-	if (dst_port[5] >= RTE_MAX_ETHPORTS ||
-			(enabled_port_mask & 1 << dst_port[5]) == 0)
-		dst_port[5] = portid;
-	if (dst_port[6] >= RTE_MAX_ETHPORTS ||
-			(enabled_port_mask & 1 << dst_port[6]) == 0)
-		dst_port[6] = portid;
-	if (dst_port[7] >= RTE_MAX_ETHPORTS ||
-			(enabled_port_mask & 1 << dst_port[7]) == 0)
-		dst_port[7] = portid;
-
-#ifdef DO_RFC_1812_CHECKS
-	/* Update time to live and header checksum */
-	--(ipv4_hdr[0]->time_to_live);
-	--(ipv4_hdr[1]->time_to_live);
-	--(ipv4_hdr[2]->time_to_live);
-	--(ipv4_hdr[3]->time_to_live);
-	++(ipv4_hdr[0]->hdr_checksum);
-	++(ipv4_hdr[1]->hdr_checksum);
-	++(ipv4_hdr[2]->hdr_checksum);
-	++(ipv4_hdr[3]->hdr_checksum);
-	--(ipv4_hdr[4]->time_to_live);
-	--(ipv4_hdr[5]->time_to_live);
-	--(ipv4_hdr[6]->time_to_live);
-	--(ipv4_hdr[7]->time_to_live);
-	++(ipv4_hdr[4]->hdr_checksum);
-	++(ipv4_hdr[5]->hdr_checksum);
-	++(ipv4_hdr[6]->hdr_checksum);
-	++(ipv4_hdr[7]->hdr_checksum);
-#endif
-
-	/* dst addr */
-	*(uint64_t *)&eth_hdr[0]->d_addr = dest_eth_addr[dst_port[0]];
-	*(uint64_t *)&eth_hdr[1]->d_addr = dest_eth_addr[dst_port[1]];
-	*(uint64_t *)&eth_hdr[2]->d_addr = dest_eth_addr[dst_port[2]];
-	*(uint64_t *)&eth_hdr[3]->d_addr = dest_eth_addr[dst_port[3]];
-	*(uint64_t *)&eth_hdr[4]->d_addr = dest_eth_addr[dst_port[4]];
-	*(uint64_t *)&eth_hdr[5]->d_addr = dest_eth_addr[dst_port[5]];
-	*(uint64_t *)&eth_hdr[6]->d_addr = dest_eth_addr[dst_port[6]];
-	*(uint64_t *)&eth_hdr[7]->d_addr = dest_eth_addr[dst_port[7]];
-
-	/* src addr */
-	ether_addr_copy(&ports_eth_addr[dst_port[0]], &eth_hdr[0]->s_addr);
-	ether_addr_copy(&ports_eth_addr[dst_port[1]], &eth_hdr[1]->s_addr);
-	ether_addr_copy(&ports_eth_addr[dst_port[2]], &eth_hdr[2]->s_addr);
-	ether_addr_copy(&ports_eth_addr[dst_port[3]], &eth_hdr[3]->s_addr);
-	ether_addr_copy(&ports_eth_addr[dst_port[4]], &eth_hdr[4]->s_addr);
-	ether_addr_copy(&ports_eth_addr[dst_port[5]], &eth_hdr[5]->s_addr);
-	ether_addr_copy(&ports_eth_addr[dst_port[6]], &eth_hdr[6]->s_addr);
-	ether_addr_copy(&ports_eth_addr[dst_port[7]], &eth_hdr[7]->s_addr);
-
-	send_single_packet(m[0], (uint8_t)dst_port[0]);
-	send_single_packet(m[1], (uint8_t)dst_port[1]);
-	send_single_packet(m[2], (uint8_t)dst_port[2]);
-	send_single_packet(m[3], (uint8_t)dst_port[3]);
-	send_single_packet(m[4], (uint8_t)dst_port[4]);
-	send_single_packet(m[5], (uint8_t)dst_port[5]);
-	send_single_packet(m[6], (uint8_t)dst_port[6]);
-	send_single_packet(m[7], (uint8_t)dst_port[7]);
-
-}
-
-static inline void get_ipv6_5tuple(struct rte_mbuf *m0, __m128i mask0,
-		__m128i mask1, union ipv6_5tuple_host *key)
-{
-	__m128i tmpdata0 = _mm_loadu_si128(rte_pktmbuf_mtod_offset(m0,
-			__m128i *, sizeof(struct ether_hdr) +
-			offsetof(struct ipv6_hdr, payload_len)));
-	__m128i tmpdata1 = _mm_loadu_si128(rte_pktmbuf_mtod_offset(m0,
-			__m128i *, sizeof(struct ether_hdr) +
-			offsetof(struct ipv6_hdr, payload_len) + sizeof(__m128i)));
-	__m128i tmpdata2 = _mm_loadu_si128(rte_pktmbuf_mtod_offset(m0,
-			__m128i *, sizeof(struct ether_hdr) +
-			offsetof(struct ipv6_hdr, payload_len) + sizeof(__m128i) +
-			sizeof(__m128i)));
-	key->xmm[0] = _mm_and_si128(tmpdata0, mask0);
-	key->xmm[1] = tmpdata1;
-	key->xmm[2] = _mm_and_si128(tmpdata2, mask1);
-}
-
-static inline void
-simple_ipv6_fwd_8pkts(struct rte_mbuf *m[8], uint16_t portid)
-{
-	int32_t ret[8];
-	uint16_t dst_port[8];
-	struct ether_hdr *eth_hdr[8];
-	union ipv6_5tuple_host key[8];
-
-	__attribute__((unused)) struct ipv6_hdr *ipv6_hdr[8];
-
-	eth_hdr[0] = rte_pktmbuf_mtod(m[0], struct ether_hdr *);
-	eth_hdr[1] = rte_pktmbuf_mtod(m[1], struct ether_hdr *);
-	eth_hdr[2] = rte_pktmbuf_mtod(m[2], struct ether_hdr *);
-	eth_hdr[3] = rte_pktmbuf_mtod(m[3], struct ether_hdr *);
-	eth_hdr[4] = rte_pktmbuf_mtod(m[4], struct ether_hdr *);
-	eth_hdr[5] = rte_pktmbuf_mtod(m[5], struct ether_hdr *);
-	eth_hdr[6] = rte_pktmbuf_mtod(m[6], struct ether_hdr *);
-	eth_hdr[7] = rte_pktmbuf_mtod(m[7], struct ether_hdr *);
-
-	/* Handle IPv6 headers.*/
-	ipv6_hdr[0] = rte_pktmbuf_mtod_offset(m[0], struct ipv6_hdr *,
-			sizeof(struct ether_hdr));
-	ipv6_hdr[1] = rte_pktmbuf_mtod_offset(m[1], struct ipv6_hdr *,
-			sizeof(struct ether_hdr));
-	ipv6_hdr[2] = rte_pktmbuf_mtod_offset(m[2], struct ipv6_hdr *,
-			sizeof(struct ether_hdr));
-	ipv6_hdr[3] = rte_pktmbuf_mtod_offset(m[3], struct ipv6_hdr *,
-			sizeof(struct ether_hdr));
-	ipv6_hdr[4] = rte_pktmbuf_mtod_offset(m[4], struct ipv6_hdr *,
-			sizeof(struct ether_hdr));
-	ipv6_hdr[5] = rte_pktmbuf_mtod_offset(m[5], struct ipv6_hdr *,
-			sizeof(struct ether_hdr));
-	ipv6_hdr[6] = rte_pktmbuf_mtod_offset(m[6], struct ipv6_hdr *,
-			sizeof(struct ether_hdr));
-	ipv6_hdr[7] = rte_pktmbuf_mtod_offset(m[7], struct ipv6_hdr *,
-			sizeof(struct ether_hdr));
-
-	get_ipv6_5tuple(m[0], mask1, mask2, &key[0]);
-	get_ipv6_5tuple(m[1], mask1, mask2, &key[1]);
-	get_ipv6_5tuple(m[2], mask1, mask2, &key[2]);
-	get_ipv6_5tuple(m[3], mask1, mask2, &key[3]);
-	get_ipv6_5tuple(m[4], mask1, mask2, &key[4]);
-	get_ipv6_5tuple(m[5], mask1, mask2, &key[5]);
-	get_ipv6_5tuple(m[6], mask1, mask2, &key[6]);
-	get_ipv6_5tuple(m[7], mask1, mask2, &key[7]);
-
-	const void *key_array[8] = {&key[0], &key[1], &key[2], &key[3],
-			&key[4], &key[5], &key[6], &key[7]};
-
-	rte_hash_lookup_bulk(RTE_PER_LCORE(lcore_conf)->ipv6_lookup_struct,
-			&key_array[0], 4, ret);
-	dst_port[0] = ((ret[0] < 0) ? portid : ipv6_l3fwd_out_if[ret[0]]);
-	dst_port[1] = ((ret[1] < 0) ? portid : ipv6_l3fwd_out_if[ret[1]]);
-	dst_port[2] = ((ret[2] < 0) ? portid : ipv6_l3fwd_out_if[ret[2]]);
-	dst_port[3] = ((ret[3] < 0) ? portid : ipv6_l3fwd_out_if[ret[3]]);
-	dst_port[4] = ((ret[4] < 0) ? portid : ipv6_l3fwd_out_if[ret[4]]);
-	dst_port[5] = ((ret[5] < 0) ? portid : ipv6_l3fwd_out_if[ret[5]]);
-	dst_port[6] = ((ret[6] < 0) ? portid : ipv6_l3fwd_out_if[ret[6]]);
-	dst_port[7] = ((ret[7] < 0) ? portid : ipv6_l3fwd_out_if[ret[7]]);
-
-	if (dst_port[0] >= RTE_MAX_ETHPORTS ||
-			(enabled_port_mask & 1 << dst_port[0]) == 0)
-		dst_port[0] = portid;
-	if (dst_port[1] >= RTE_MAX_ETHPORTS ||
-			(enabled_port_mask & 1 << dst_port[1]) == 0)
-		dst_port[1] = portid;
-	if (dst_port[2] >= RTE_MAX_ETHPORTS ||
-			(enabled_port_mask & 1 << dst_port[2]) == 0)
-		dst_port[2] = portid;
-	if (dst_port[3] >= RTE_MAX_ETHPORTS ||
-			(enabled_port_mask & 1 << dst_port[3]) == 0)
-		dst_port[3] = portid;
-	if (dst_port[4] >= RTE_MAX_ETHPORTS ||
-			(enabled_port_mask & 1 << dst_port[4]) == 0)
-		dst_port[4] = portid;
-	if (dst_port[5] >= RTE_MAX_ETHPORTS ||
-			(enabled_port_mask & 1 << dst_port[5]) == 0)
-		dst_port[5] = portid;
-	if (dst_port[6] >= RTE_MAX_ETHPORTS ||
-			(enabled_port_mask & 1 << dst_port[6]) == 0)
-		dst_port[6] = portid;
-	if (dst_port[7] >= RTE_MAX_ETHPORTS ||
-			(enabled_port_mask & 1 << dst_port[7]) == 0)
-		dst_port[7] = portid;
-
-	/* dst addr */
-	*(uint64_t *)&eth_hdr[0]->d_addr = dest_eth_addr[dst_port[0]];
-	*(uint64_t *)&eth_hdr[1]->d_addr = dest_eth_addr[dst_port[1]];
-	*(uint64_t *)&eth_hdr[2]->d_addr = dest_eth_addr[dst_port[2]];
-	*(uint64_t *)&eth_hdr[3]->d_addr = dest_eth_addr[dst_port[3]];
-	*(uint64_t *)&eth_hdr[4]->d_addr = dest_eth_addr[dst_port[4]];
-	*(uint64_t *)&eth_hdr[5]->d_addr = dest_eth_addr[dst_port[5]];
-	*(uint64_t *)&eth_hdr[6]->d_addr = dest_eth_addr[dst_port[6]];
-	*(uint64_t *)&eth_hdr[7]->d_addr = dest_eth_addr[dst_port[7]];
-
-	/* src addr */
-	ether_addr_copy(&ports_eth_addr[dst_port[0]], &eth_hdr[0]->s_addr);
-	ether_addr_copy(&ports_eth_addr[dst_port[1]], &eth_hdr[1]->s_addr);
-	ether_addr_copy(&ports_eth_addr[dst_port[2]], &eth_hdr[2]->s_addr);
-	ether_addr_copy(&ports_eth_addr[dst_port[3]], &eth_hdr[3]->s_addr);
-	ether_addr_copy(&ports_eth_addr[dst_port[4]], &eth_hdr[4]->s_addr);
-	ether_addr_copy(&ports_eth_addr[dst_port[5]], &eth_hdr[5]->s_addr);
-	ether_addr_copy(&ports_eth_addr[dst_port[6]], &eth_hdr[6]->s_addr);
-	ether_addr_copy(&ports_eth_addr[dst_port[7]], &eth_hdr[7]->s_addr);
-
-	send_single_packet(m[0], dst_port[0]);
-	send_single_packet(m[1], dst_port[1]);
-	send_single_packet(m[2], dst_port[2]);
-	send_single_packet(m[3], dst_port[3]);
-	send_single_packet(m[4], dst_port[4]);
-	send_single_packet(m[5], dst_port[5]);
-	send_single_packet(m[6], dst_port[6]);
-	send_single_packet(m[7], dst_port[7]);
-
-}
-#endif /* APP_LOOKUP_METHOD */
-
-static __rte_always_inline void
-l3fwd_simple_forward(struct rte_mbuf *m, uint16_t portid)
-{
-	struct ether_hdr *eth_hdr;
-	struct ipv4_hdr *ipv4_hdr;
-	uint16_t dst_port;
-
-	eth_hdr = rte_pktmbuf_mtod(m, struct ether_hdr *);
-
-	if (RTE_ETH_IS_IPV4_HDR(m->packet_type)) {
-		/* Handle IPv4 headers.*/
-		ipv4_hdr = rte_pktmbuf_mtod_offset(m, struct ipv4_hdr *,
-				sizeof(struct ether_hdr));
-
-#ifdef DO_RFC_1812_CHECKS
-		/* Check to make sure the packet is valid (RFC1812) */
-		if (is_valid_ipv4_pkt(ipv4_hdr, m->pkt_len) < 0) {
-			rte_pktmbuf_free(m);
-			return;
-		}
-#endif
-
-		 dst_port = get_ipv4_dst_port(ipv4_hdr, portid,
-			RTE_PER_LCORE(lcore_conf)->ipv4_lookup_struct);
-		if (dst_port >= RTE_MAX_ETHPORTS ||
-				(enabled_port_mask & 1 << dst_port) == 0)
-			dst_port = portid;
-
-#ifdef DO_RFC_1812_CHECKS
-		/* Update time to live and header checksum */
-		--(ipv4_hdr->time_to_live);
-		++(ipv4_hdr->hdr_checksum);
-#endif
-		/* dst addr */
-		*(uint64_t *)&eth_hdr->d_addr = dest_eth_addr[dst_port];
-
-		/* src addr */
-		ether_addr_copy(&ports_eth_addr[dst_port], &eth_hdr->s_addr);
-
-		send_single_packet(m, dst_port);
-	} else if (RTE_ETH_IS_IPV6_HDR(m->packet_type)) {
-		/* Handle IPv6 headers.*/
-		struct ipv6_hdr *ipv6_hdr;
-
-		ipv6_hdr = rte_pktmbuf_mtod_offset(m, struct ipv6_hdr *,
-				sizeof(struct ether_hdr));
-
-		dst_port = get_ipv6_dst_port(ipv6_hdr, portid,
-				RTE_PER_LCORE(lcore_conf)->ipv6_lookup_struct);
-
-		if (dst_port >= RTE_MAX_ETHPORTS ||
-				(enabled_port_mask & 1 << dst_port) == 0)
-			dst_port = portid;
-
-		/* dst addr */
-		*(uint64_t *)&eth_hdr->d_addr = dest_eth_addr[dst_port];
-
-		/* src addr */
-		ether_addr_copy(&ports_eth_addr[dst_port], &eth_hdr->s_addr);
-
-		send_single_packet(m, dst_port);
-	} else
-		/* Free the mbuf that contains non-IPV4/IPV6 packet */
-		rte_pktmbuf_free(m);
-}
-
-#if ((APP_LOOKUP_METHOD == APP_LOOKUP_LPM) && \
-	(ENABLE_MULTI_BUFFER_OPTIMIZE == 1))
-#ifdef DO_RFC_1812_CHECKS
-
-#define	IPV4_MIN_VER_IHL	0x45
-#define	IPV4_MAX_VER_IHL	0x4f
-#define	IPV4_MAX_VER_IHL_DIFF	(IPV4_MAX_VER_IHL - IPV4_MIN_VER_IHL)
-
-/* Minimum value of IPV4 total length (20B) in network byte order. */
-#define	IPV4_MIN_LEN_BE	(sizeof(struct ipv4_hdr) << 8)
-
-/*
- * From http://www.rfc-editor.org/rfc/rfc1812.txt section 5.2.2:
- * - The IP version number must be 4.
- * - The IP header length field must be large enough to hold the
- *    minimum length legal IP datagram (20 bytes = 5 words).
- * - The IP total length field must be large enough to hold the IP
- *   datagram header, whose length is specified in the IP header length
- *   field.
- * If we encounter invalid IPV4 packet, then set destination port for it
- * to BAD_PORT value.
- */
-static __rte_always_inline void
-rfc1812_process(struct ipv4_hdr *ipv4_hdr, uint16_t *dp, uint32_t ptype)
-{
-	uint8_t ihl;
-
-	if (RTE_ETH_IS_IPV4_HDR(ptype)) {
-		ihl = ipv4_hdr->version_ihl - IPV4_MIN_VER_IHL;
-
-		ipv4_hdr->time_to_live--;
-		ipv4_hdr->hdr_checksum++;
-
-		if (ihl > IPV4_MAX_VER_IHL_DIFF ||
-				((uint8_t)ipv4_hdr->total_length == 0 &&
-				ipv4_hdr->total_length < IPV4_MIN_LEN_BE)) {
-			dp[0] = BAD_PORT;
-		}
-	}
-}
-
-#else
-#define	rfc1812_process(mb, dp, ptype)	do { } while (0)
-#endif /* DO_RFC_1812_CHECKS */
-#endif /* APP_LOOKUP_LPM && ENABLE_MULTI_BUFFER_OPTIMIZE */
-
-
-#if ((APP_LOOKUP_METHOD == APP_LOOKUP_LPM) && \
-	(ENABLE_MULTI_BUFFER_OPTIMIZE == 1))
-
-static __rte_always_inline uint16_t
-get_dst_port(struct rte_mbuf *pkt, uint32_t dst_ipv4, uint16_t portid)
-{
-	uint32_t next_hop;
-	struct ipv6_hdr *ipv6_hdr;
-	struct ether_hdr *eth_hdr;
-
-	if (RTE_ETH_IS_IPV4_HDR(pkt->packet_type)) {
-		return (uint16_t) ((rte_lpm_lookup(
-				RTE_PER_LCORE(lcore_conf)->ipv4_lookup_struct, dst_ipv4,
-				&next_hop) == 0) ? next_hop : portid);
-
-	} else if (RTE_ETH_IS_IPV6_HDR(pkt->packet_type)) {
-
-		eth_hdr = rte_pktmbuf_mtod(pkt, struct ether_hdr *);
-		ipv6_hdr = (struct ipv6_hdr *)(eth_hdr + 1);
-
-		return (uint16_t) ((rte_lpm6_lookup(
-				RTE_PER_LCORE(lcore_conf)->ipv6_lookup_struct,
-				ipv6_hdr->dst_addr, &next_hop) == 0) ?
-				next_hop : portid);
-
-	}
-
-	return portid;
-}
-
-static inline void
-process_packet(struct rte_mbuf *pkt, uint16_t *dst_port, uint16_t portid)
-{
-	struct ether_hdr *eth_hdr;
-	struct ipv4_hdr *ipv4_hdr;
-	uint32_t dst_ipv4;
-	uint16_t dp;
-	__m128i te, ve;
-
-	eth_hdr = rte_pktmbuf_mtod(pkt, struct ether_hdr *);
-	ipv4_hdr = (struct ipv4_hdr *)(eth_hdr + 1);
-
-	dst_ipv4 = ipv4_hdr->dst_addr;
-	dst_ipv4 = rte_be_to_cpu_32(dst_ipv4);
-	dp = get_dst_port(pkt, dst_ipv4, portid);
-
-	te = _mm_load_si128((__m128i *)eth_hdr);
-	ve = val_eth[dp];
-
-	dst_port[0] = dp;
-	rfc1812_process(ipv4_hdr, dst_port, pkt->packet_type);
-
-	te =  _mm_blend_epi16(te, ve, MASK_ETH);
-	_mm_store_si128((__m128i *)eth_hdr, te);
-}
-
-/*
- * Read packet_type and destination IPV4 addresses from 4 mbufs.
- */
-static inline void
-processx4_step1(struct rte_mbuf *pkt[FWDSTEP],
-		__m128i *dip,
-		uint32_t *ipv4_flag)
-{
-	struct ipv4_hdr *ipv4_hdr;
-	struct ether_hdr *eth_hdr;
-	uint32_t x0, x1, x2, x3;
-
-	eth_hdr = rte_pktmbuf_mtod(pkt[0], struct ether_hdr *);
-	ipv4_hdr = (struct ipv4_hdr *)(eth_hdr + 1);
-	x0 = ipv4_hdr->dst_addr;
-	ipv4_flag[0] = pkt[0]->packet_type & RTE_PTYPE_L3_IPV4;
-
-	eth_hdr = rte_pktmbuf_mtod(pkt[1], struct ether_hdr *);
-	ipv4_hdr = (struct ipv4_hdr *)(eth_hdr + 1);
-	x1 = ipv4_hdr->dst_addr;
-	ipv4_flag[0] &= pkt[1]->packet_type;
-
-	eth_hdr = rte_pktmbuf_mtod(pkt[2], struct ether_hdr *);
-	ipv4_hdr = (struct ipv4_hdr *)(eth_hdr + 1);
-	x2 = ipv4_hdr->dst_addr;
-	ipv4_flag[0] &= pkt[2]->packet_type;
-
-	eth_hdr = rte_pktmbuf_mtod(pkt[3], struct ether_hdr *);
-	ipv4_hdr = (struct ipv4_hdr *)(eth_hdr + 1);
-	x3 = ipv4_hdr->dst_addr;
-	ipv4_flag[0] &= pkt[3]->packet_type;
-
-	dip[0] = _mm_set_epi32(x3, x2, x1, x0);
-}
-
-/*
- * Lookup into LPM for destination port.
- * If lookup fails, use incoming port (portid) as destination port.
- */
-static inline void
-processx4_step2(__m128i dip,
-		uint32_t ipv4_flag,
-		uint16_t portid,
-		struct rte_mbuf *pkt[FWDSTEP],
-		uint16_t dprt[FWDSTEP])
-{
-	rte_xmm_t dst;
-	const __m128i bswap_mask = _mm_set_epi8(12, 13, 14, 15, 8, 9, 10, 11,
-			4, 5, 6, 7, 0, 1, 2, 3);
-
-	/* Byte swap 4 IPV4 addresses. */
-	dip = _mm_shuffle_epi8(dip, bswap_mask);
-
-	/* if all 4 packets are IPV4. */
-	if (likely(ipv4_flag)) {
-		rte_lpm_lookupx4(RTE_PER_LCORE(lcore_conf)->ipv4_lookup_struct, dip,
-				dst.u32, portid);
-
-		/* get rid of unused upper 16 bit for each dport. */
-		dst.x = _mm_packs_epi32(dst.x, dst.x);
-		*(uint64_t *)dprt = dst.u64[0];
-	} else {
-		dst.x = dip;
-		dprt[0] = get_dst_port(pkt[0], dst.u32[0], portid);
-		dprt[1] = get_dst_port(pkt[1], dst.u32[1], portid);
-		dprt[2] = get_dst_port(pkt[2], dst.u32[2], portid);
-		dprt[3] = get_dst_port(pkt[3], dst.u32[3], portid);
-	}
-}
-
-/*
- * Update source and destination MAC addresses in the ethernet header.
- * Perform RFC1812 checks and updates for IPV4 packets.
- */
-static inline void
-processx4_step3(struct rte_mbuf *pkt[FWDSTEP], uint16_t dst_port[FWDSTEP])
-{
-	__m128i te[FWDSTEP];
-	__m128i ve[FWDSTEP];
-	__m128i *p[FWDSTEP];
-
-	p[0] = rte_pktmbuf_mtod(pkt[0], __m128i *);
-	p[1] = rte_pktmbuf_mtod(pkt[1], __m128i *);
-	p[2] = rte_pktmbuf_mtod(pkt[2], __m128i *);
-	p[3] = rte_pktmbuf_mtod(pkt[3], __m128i *);
-
-	ve[0] = val_eth[dst_port[0]];
-	te[0] = _mm_load_si128(p[0]);
-
-	ve[1] = val_eth[dst_port[1]];
-	te[1] = _mm_load_si128(p[1]);
-
-	ve[2] = val_eth[dst_port[2]];
-	te[2] = _mm_load_si128(p[2]);
-
-	ve[3] = val_eth[dst_port[3]];
-	te[3] = _mm_load_si128(p[3]);
-
-	/* Update first 12 bytes, keep rest bytes intact. */
-	te[0] =  _mm_blend_epi16(te[0], ve[0], MASK_ETH);
-	te[1] =  _mm_blend_epi16(te[1], ve[1], MASK_ETH);
-	te[2] =  _mm_blend_epi16(te[2], ve[2], MASK_ETH);
-	te[3] =  _mm_blend_epi16(te[3], ve[3], MASK_ETH);
-
-	_mm_store_si128(p[0], te[0]);
-	_mm_store_si128(p[1], te[1]);
-	_mm_store_si128(p[2], te[2]);
-	_mm_store_si128(p[3], te[3]);
-
-	rfc1812_process((struct ipv4_hdr *)((struct ether_hdr *)p[0] + 1),
-			&dst_port[0], pkt[0]->packet_type);
-	rfc1812_process((struct ipv4_hdr *)((struct ether_hdr *)p[1] + 1),
-			&dst_port[1], pkt[1]->packet_type);
-	rfc1812_process((struct ipv4_hdr *)((struct ether_hdr *)p[2] + 1),
-			&dst_port[2], pkt[2]->packet_type);
-	rfc1812_process((struct ipv4_hdr *)((struct ether_hdr *)p[3] + 1),
-			&dst_port[3], pkt[3]->packet_type);
-}
-
-/*
- * We group consecutive packets with the same destionation port into one burst.
- * To avoid extra latency this is done together with some other packet
- * processing, but after we made a final decision about packet's destination.
- * To do this we maintain:
- * pnum - array of number of consecutive packets with the same dest port for
- * each packet in the input burst.
- * lp - pointer to the last updated element in the pnum.
- * dlp - dest port value lp corresponds to.
- */
-
-#define	GRPSZ	(1 << FWDSTEP)
-#define	GRPMSK	(GRPSZ - 1)
-
-#define GROUP_PORT_STEP(dlp, dcp, lp, pn, idx)	do { \
-	if (likely((dlp) == (dcp)[(idx)])) {         \
-		(lp)[0]++;                           \
-	} else {                                     \
-		(dlp) = (dcp)[idx];                  \
-		(lp) = (pn) + (idx);                 \
-		(lp)[0] = 1;                         \
-	}                                            \
-} while (0)
-
-/*
- * Group consecutive packets with the same destination port in bursts of 4.
- * Suppose we have array of destionation ports:
- * dst_port[] = {a, b, c, d,, e, ... }
- * dp1 should contain: <a, b, c, d>, dp2: <b, c, d, e>.
- * We doing 4 comparisons at once and the result is 4 bit mask.
- * This mask is used as an index into prebuild array of pnum values.
- */
-static inline uint16_t *
-port_groupx4(uint16_t pn[FWDSTEP + 1], uint16_t *lp, __m128i dp1, __m128i dp2)
-{
-	static const struct {
-		uint64_t pnum; /* prebuild 4 values for pnum[]. */
-		int32_t  idx;  /* index for new last updated elemnet. */
-		uint16_t lpv;  /* add value to the last updated element. */
-	} gptbl[GRPSZ] = {
-	{
-		/* 0: a != b, b != c, c != d, d != e */
-		.pnum = UINT64_C(0x0001000100010001),
-		.idx = 4,
-		.lpv = 0,
-	},
-	{
-		/* 1: a == b, b != c, c != d, d != e */
-		.pnum = UINT64_C(0x0001000100010002),
-		.idx = 4,
-		.lpv = 1,
-	},
-	{
-		/* 2: a != b, b == c, c != d, d != e */
-		.pnum = UINT64_C(0x0001000100020001),
-		.idx = 4,
-		.lpv = 0,
-	},
-	{
-		/* 3: a == b, b == c, c != d, d != e */
-		.pnum = UINT64_C(0x0001000100020003),
-		.idx = 4,
-		.lpv = 2,
-	},
-	{
-		/* 4: a != b, b != c, c == d, d != e */
-		.pnum = UINT64_C(0x0001000200010001),
-		.idx = 4,
-		.lpv = 0,
-	},
-	{
-		/* 5: a == b, b != c, c == d, d != e */
-		.pnum = UINT64_C(0x0001000200010002),
-		.idx = 4,
-		.lpv = 1,
-	},
-	{
-		/* 6: a != b, b == c, c == d, d != e */
-		.pnum = UINT64_C(0x0001000200030001),
-		.idx = 4,
-		.lpv = 0,
-	},
-	{
-		/* 7: a == b, b == c, c == d, d != e */
-		.pnum = UINT64_C(0x0001000200030004),
-		.idx = 4,
-		.lpv = 3,
-	},
-	{
-		/* 8: a != b, b != c, c != d, d == e */
-		.pnum = UINT64_C(0x0002000100010001),
-		.idx = 3,
-		.lpv = 0,
-	},
-	{
-		/* 9: a == b, b != c, c != d, d == e */
-		.pnum = UINT64_C(0x0002000100010002),
-		.idx = 3,
-		.lpv = 1,
-	},
-	{
-		/* 0xa: a != b, b == c, c != d, d == e */
-		.pnum = UINT64_C(0x0002000100020001),
-		.idx = 3,
-		.lpv = 0,
-	},
-	{
-		/* 0xb: a == b, b == c, c != d, d == e */
-		.pnum = UINT64_C(0x0002000100020003),
-		.idx = 3,
-		.lpv = 2,
-	},
-	{
-		/* 0xc: a != b, b != c, c == d, d == e */
-		.pnum = UINT64_C(0x0002000300010001),
-		.idx = 2,
-		.lpv = 0,
-	},
-	{
-		/* 0xd: a == b, b != c, c == d, d == e */
-		.pnum = UINT64_C(0x0002000300010002),
-		.idx = 2,
-		.lpv = 1,
-	},
-	{
-		/* 0xe: a != b, b == c, c == d, d == e */
-		.pnum = UINT64_C(0x0002000300040001),
-		.idx = 1,
-		.lpv = 0,
-	},
-	{
-		/* 0xf: a == b, b == c, c == d, d == e */
-		.pnum = UINT64_C(0x0002000300040005),
-		.idx = 0,
-		.lpv = 4,
-	},
-	};
-
-	union {
-		uint16_t u16[FWDSTEP + 1];
-		uint64_t u64;
-	} *pnum = (void *)pn;
-
-	int32_t v;
-
-	dp1 = _mm_cmpeq_epi16(dp1, dp2);
-	dp1 = _mm_unpacklo_epi16(dp1, dp1);
-	v = _mm_movemask_ps((__m128)dp1);
-
-	/* update last port counter. */
-	lp[0] += gptbl[v].lpv;
-
-	/* if dest port value has changed. */
-	if (v != GRPMSK) {
-		pnum->u64 = gptbl[v].pnum;
-		pnum->u16[FWDSTEP] = 1;
-		lp = pnum->u16 + gptbl[v].idx;
-	}
-
-	return lp;
-}
-
-#endif /* APP_LOOKUP_METHOD */
-
-static void
-process_burst(struct rte_mbuf *pkts_burst[MAX_PKT_BURST], int nb_rx,
-		uint16_t portid)
-{
-
-	int j;
-
-#if ((APP_LOOKUP_METHOD == APP_LOOKUP_LPM) && \
-	(ENABLE_MULTI_BUFFER_OPTIMIZE == 1))
-	int32_t k;
-	uint16_t dlp;
-	uint16_t *lp;
-	uint16_t dst_port[MAX_PKT_BURST];
-	__m128i dip[MAX_PKT_BURST / FWDSTEP];
-	uint32_t ipv4_flag[MAX_PKT_BURST / FWDSTEP];
-	uint16_t pnum[MAX_PKT_BURST + 1];
-#endif
-
-
-#if (ENABLE_MULTI_BUFFER_OPTIMIZE == 1)
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_EXACT_MATCH)
-	{
-		/*
-		 * Send nb_rx - nb_rx%8 packets
-		 * in groups of 8.
-		 */
-		int32_t n = RTE_ALIGN_FLOOR(nb_rx, 8);
-
-		for (j = 0; j < n; j += 8) {
-			uint32_t pkt_type =
-				pkts_burst[j]->packet_type &
-				pkts_burst[j+1]->packet_type &
-				pkts_burst[j+2]->packet_type &
-				pkts_burst[j+3]->packet_type &
-				pkts_burst[j+4]->packet_type &
-				pkts_burst[j+5]->packet_type &
-				pkts_burst[j+6]->packet_type &
-				pkts_burst[j+7]->packet_type;
-			if (pkt_type & RTE_PTYPE_L3_IPV4) {
-				simple_ipv4_fwd_8pkts(&pkts_burst[j], portid);
-			} else if (pkt_type &
-				RTE_PTYPE_L3_IPV6) {
-				simple_ipv6_fwd_8pkts(&pkts_burst[j], portid);
-			} else {
-				l3fwd_simple_forward(pkts_burst[j], portid);
-				l3fwd_simple_forward(pkts_burst[j+1], portid);
-				l3fwd_simple_forward(pkts_burst[j+2], portid);
-				l3fwd_simple_forward(pkts_burst[j+3], portid);
-				l3fwd_simple_forward(pkts_burst[j+4], portid);
-				l3fwd_simple_forward(pkts_burst[j+5], portid);
-				l3fwd_simple_forward(pkts_burst[j+6], portid);
-				l3fwd_simple_forward(pkts_burst[j+7], portid);
-			}
-		}
-		for (; j < nb_rx ; j++)
-			l3fwd_simple_forward(pkts_burst[j], portid);
-	}
-#elif (APP_LOOKUP_METHOD == APP_LOOKUP_LPM)
-
-	k = RTE_ALIGN_FLOOR(nb_rx, FWDSTEP);
-	for (j = 0; j != k; j += FWDSTEP)
-		processx4_step1(&pkts_burst[j], &dip[j / FWDSTEP],
-				&ipv4_flag[j / FWDSTEP]);
-
-	k = RTE_ALIGN_FLOOR(nb_rx, FWDSTEP);
-	for (j = 0; j != k; j += FWDSTEP)
-		processx4_step2(dip[j / FWDSTEP], ipv4_flag[j / FWDSTEP],
-				portid, &pkts_burst[j], &dst_port[j]);
-
-	/*
-	 * Finish packet processing and group consecutive
-	 * packets with the same destination port.
-	 */
-	k = RTE_ALIGN_FLOOR(nb_rx, FWDSTEP);
-	if (k != 0) {
-		__m128i dp1, dp2;
-
-		lp = pnum;
-		lp[0] = 1;
-
-		processx4_step3(pkts_burst, dst_port);
-
-		/* dp1: <d[0], d[1], d[2], d[3], ... > */
-		dp1 = _mm_loadu_si128((__m128i *)dst_port);
-
-		for (j = FWDSTEP; j != k; j += FWDSTEP) {
-			processx4_step3(&pkts_burst[j], &dst_port[j]);
-
-			/*
-			 * dp2:
-			 * <d[j-3], d[j-2], d[j-1], d[j], ... >
-			 */
-			dp2 = _mm_loadu_si128(
-					(__m128i *)&dst_port[j - FWDSTEP + 1]);
-			lp  = port_groupx4(&pnum[j - FWDSTEP], lp, dp1, dp2);
-
-			/*
-			 * dp1:
-			 * <d[j], d[j+1], d[j+2], d[j+3], ... >
-			 */
-			dp1 = _mm_srli_si128(dp2, (FWDSTEP - 1) *
-					sizeof(dst_port[0]));
-		}
-
-		/*
-		 * dp2: <d[j-3], d[j-2], d[j-1], d[j-1], ... >
-		 */
-		dp2 = _mm_shufflelo_epi16(dp1, 0xf9);
-		lp  = port_groupx4(&pnum[j - FWDSTEP], lp, dp1, dp2);
-
-		/*
-		 * remove values added by the last repeated
-		 * dst port.
-		 */
-		lp[0]--;
-		dlp = dst_port[j - 1];
-	} else {
-		/* set dlp and lp to the never used values. */
-		dlp = BAD_PORT - 1;
-		lp = pnum + MAX_PKT_BURST;
-	}
-
-	/* Process up to last 3 packets one by one. */
-	switch (nb_rx % FWDSTEP) {
-	case 3:
-		process_packet(pkts_burst[j], dst_port + j, portid);
-		GROUP_PORT_STEP(dlp, dst_port, lp, pnum, j);
-		j++;
-		/* fall-through */
-	case 2:
-		process_packet(pkts_burst[j], dst_port + j, portid);
-		GROUP_PORT_STEP(dlp, dst_port, lp, pnum, j);
-		j++;
-		/* fall-through */
-	case 1:
-		process_packet(pkts_burst[j], dst_port + j, portid);
-		GROUP_PORT_STEP(dlp, dst_port, lp, pnum, j);
-		j++;
-	}
-
-	/*
-	 * Send packets out, through destination port.
-	 * Consecuteve pacekts with the same destination port
-	 * are already grouped together.
-	 * If destination port for the packet equals BAD_PORT,
-	 * then free the packet without sending it out.
-	 */
-	for (j = 0; j < nb_rx; j += k) {
-
-		int32_t m;
-		uint16_t pn;
-
-		pn = dst_port[j];
-		k = pnum[j];
-
-		if (likely(pn != BAD_PORT))
-			send_packetsx4(pn, pkts_burst + j, k);
-		else
-			for (m = j; m != j + k; m++)
-				rte_pktmbuf_free(pkts_burst[m]);
-
-	}
-
-#endif /* APP_LOOKUP_METHOD */
-#else /* ENABLE_MULTI_BUFFER_OPTIMIZE == 0 */
-
-	/* Prefetch first packets */
-	for (j = 0; j < PREFETCH_OFFSET && j < nb_rx; j++)
-		rte_prefetch0(rte_pktmbuf_mtod(pkts_burst[j], void *));
-
-	/* Prefetch and forward already prefetched packets */
-	for (j = 0; j < (nb_rx - PREFETCH_OFFSET); j++) {
-		rte_prefetch0(rte_pktmbuf_mtod(pkts_burst[
-				j + PREFETCH_OFFSET], void *));
-		l3fwd_simple_forward(pkts_burst[j], portid);
-	}
-
-	/* Forward remaining prefetched packets */
-	for (; j < nb_rx; j++)
-		l3fwd_simple_forward(pkts_burst[j], portid);
-
-#endif /* ENABLE_MULTI_BUFFER_OPTIMIZE */
-
-}
-
-#if (APP_CPU_LOAD > 0)
-
-/*
- * CPU-load stats collector
- */
-static int
-cpu_load_collector(__rte_unused void *arg) {
-	unsigned i, j, k;
-	uint64_t hits;
-	uint64_t prev_tsc, diff_tsc, cur_tsc;
-	uint64_t total[MAX_CPU] = { 0 };
-	unsigned min_cpu = MAX_CPU;
-	unsigned max_cpu = 0;
-	unsigned cpu_id;
-	int busy_total = 0;
-	int busy_flag = 0;
-
-	unsigned int n_thread_per_cpu[MAX_CPU] = { 0 };
-	struct thread_conf *thread_per_cpu[MAX_CPU][MAX_THREAD];
-
-	struct thread_conf *thread_conf;
-
-	const uint64_t interval_tsc = (rte_get_tsc_hz() + US_PER_S - 1) /
-		US_PER_S * CPU_LOAD_TIMEOUT_US;
-
-	prev_tsc = 0;
-	/*
-	 * Wait for all threads
-	 */
-
-	printf("Waiting for %d rx threads and %d tx threads\n", n_rx_thread,
-			n_tx_thread);
-
-	while (rte_atomic16_read(&rx_counter) < n_rx_thread)
-		rte_pause();
-
-	while (rte_atomic16_read(&tx_counter) < n_tx_thread)
-		rte_pause();
-
-	for (i = 0; i < n_rx_thread; i++) {
-
-		thread_conf = &rx_thread[i].conf;
-		cpu_id = thread_conf->cpu_id;
-		thread_per_cpu[cpu_id][n_thread_per_cpu[cpu_id]++] = thread_conf;
-
-		if (cpu_id > max_cpu)
-			max_cpu = cpu_id;
-		if (cpu_id < min_cpu)
-			min_cpu = cpu_id;
-	}
-	for (i = 0; i < n_tx_thread; i++) {
-
-		thread_conf = &tx_thread[i].conf;
-		cpu_id = thread_conf->cpu_id;
-		thread_per_cpu[cpu_id][n_thread_per_cpu[cpu_id]++] = thread_conf;
-
-		if (thread_conf->cpu_id > max_cpu)
-			max_cpu = thread_conf->cpu_id;
-		if (thread_conf->cpu_id < min_cpu)
-			min_cpu = thread_conf->cpu_id;
-	}
-
-	while (1) {
-
-		cpu_load.counter++;
-		for (i = min_cpu; i <= max_cpu; i++) {
-			for (j = 0; j < MAX_CPU_COUNTER; j++) {
-				for (k = 0; k < n_thread_per_cpu[i]; k++)
-					if (thread_per_cpu[i][k]->busy[j]) {
-						busy_flag = 1;
-						break;
-					}
-				if (busy_flag) {
-					cpu_load.hits[j][i]++;
-					busy_total = 1;
-					busy_flag = 0;
-				}
-			}
-
-			if (busy_total) {
-				total[i]++;
-				busy_total = 0;
-			}
-		}
-
-		cur_tsc = rte_rdtsc();
-
-		diff_tsc = cur_tsc - prev_tsc;
-		if (unlikely(diff_tsc > interval_tsc)) {
-
-			printf("\033c");
-
-			printf("Cpu usage for %d rx threads and %d tx threads:\n\n",
-					n_rx_thread, n_tx_thread);
-
-			printf("cpu#     proc%%  poll%%  overhead%%\n\n");
-
-			for (i = min_cpu; i <= max_cpu; i++) {
-				hits = 0;
-				printf("CPU %d:", i);
-				for (j = 0; j < MAX_CPU_COUNTER; j++) {
-					printf("%7" PRIu64 "",
-							cpu_load.hits[j][i] * 100 / cpu_load.counter);
-					hits += cpu_load.hits[j][i];
-					cpu_load.hits[j][i] = 0;
-				}
-				printf("%7" PRIu64 "\n",
-						100 - total[i] * 100 / cpu_load.counter);
-				total[i] = 0;
-			}
-			cpu_load.counter = 0;
-
-			prev_tsc = cur_tsc;
-		}
-
-	}
-}
-#endif /* APP_CPU_LOAD */
-
-/*
- * Null processing lthread loop
- *
- * This loop is used to start empty scheduler on lcore.
- */
-static void *
-lthread_null(__rte_unused void *args)
-{
-	int lcore_id = rte_lcore_id();
-
-	RTE_LOG(INFO, L3FWD, "Starting scheduler on lcore %d.\n", lcore_id);
-	lthread_exit(NULL);
-	return NULL;
-}
-
-/* main processing loop */
-static void *
-lthread_tx_per_ring(void *dummy)
-{
-	int nb_rx;
-	uint16_t portid;
-	struct rte_ring *ring;
-	struct thread_tx_conf *tx_conf;
-	struct rte_mbuf *pkts_burst[MAX_PKT_BURST];
-	struct lthread_cond *ready;
-
-	tx_conf = (struct thread_tx_conf *)dummy;
-	ring = tx_conf->ring;
-	ready = *tx_conf->ready;
-
-	lthread_set_data((void *)tx_conf);
-
-	/*
-	 * Move this lthread to lcore
-	 */
-	lthread_set_affinity(tx_conf->conf.lcore_id);
-
-	RTE_LOG(INFO, L3FWD, "entering main tx loop on lcore %u\n", rte_lcore_id());
-
-	nb_rx = 0;
-	rte_atomic16_inc(&tx_counter);
-	while (1) {
-
-		/*
-		 * Read packet from ring
-		 */
-		SET_CPU_BUSY(tx_conf, CPU_POLL);
-		nb_rx = rte_ring_sc_dequeue_burst(ring, (void **)pkts_burst,
-				MAX_PKT_BURST, NULL);
-		SET_CPU_IDLE(tx_conf, CPU_POLL);
-
-		if (nb_rx > 0) {
-			SET_CPU_BUSY(tx_conf, CPU_PROCESS);
-			portid = pkts_burst[0]->port;
-			process_burst(pkts_burst, nb_rx, portid);
-			SET_CPU_IDLE(tx_conf, CPU_PROCESS);
-			lthread_yield();
-		} else
-			lthread_cond_wait(ready, 0);
-
-	}
-	return NULL;
-}
-
-/*
- * Main tx-lthreads spawner lthread.
- *
- * This lthread is used to spawn one new lthread per ring from producers.
- *
- */
-static void *
-lthread_tx(void *args)
-{
-	struct lthread *lt;
-
-	unsigned lcore_id;
-	uint16_t portid;
-	struct thread_tx_conf *tx_conf;
-
-	tx_conf = (struct thread_tx_conf *)args;
-	lthread_set_data((void *)tx_conf);
-
-	/*
-	 * Move this lthread to the selected lcore
-	 */
-	lthread_set_affinity(tx_conf->conf.lcore_id);
-
-	/*
-	 * Spawn tx readers (one per input ring)
-	 */
-	lthread_create(&lt, tx_conf->conf.lcore_id, lthread_tx_per_ring,
-			(void *)tx_conf);
-
-	lcore_id = rte_lcore_id();
-
-	RTE_LOG(INFO, L3FWD, "Entering Tx main loop on lcore %u\n", lcore_id);
-
-	tx_conf->conf.cpu_id = sched_getcpu();
-	while (1) {
-
-		lthread_sleep(BURST_TX_DRAIN_US * 1000);
-
-		/*
-		 * TX burst queue drain
-		 */
-		for (portid = 0; portid < RTE_MAX_ETHPORTS; portid++) {
-			if (tx_conf->tx_mbufs[portid].len == 0)
-				continue;
-			SET_CPU_BUSY(tx_conf, CPU_PROCESS);
-			send_burst(tx_conf, tx_conf->tx_mbufs[portid].len, portid);
-			SET_CPU_IDLE(tx_conf, CPU_PROCESS);
-			tx_conf->tx_mbufs[portid].len = 0;
-		}
-
-	}
-	return NULL;
-}
-
-static void *
-lthread_rx(void *dummy)
-{
-	int ret;
-	uint16_t nb_rx;
-	int i;
-	uint16_t portid;
-	uint8_t queueid;
-	int worker_id;
-	int len[RTE_MAX_LCORE] = { 0 };
-	int old_len, new_len;
-	struct rte_mbuf *pkts_burst[MAX_PKT_BURST];
-	struct thread_rx_conf *rx_conf;
-
-	rx_conf = (struct thread_rx_conf *)dummy;
-	lthread_set_data((void *)rx_conf);
-
-	/*
-	 * Move this lthread to lcore
-	 */
-	lthread_set_affinity(rx_conf->conf.lcore_id);
-
-	if (rx_conf->n_rx_queue == 0) {
-		RTE_LOG(INFO, L3FWD, "lcore %u has nothing to do\n", rte_lcore_id());
-		return NULL;
-	}
-
-	RTE_LOG(INFO, L3FWD, "Entering main Rx loop on lcore %u\n", rte_lcore_id());
-
-	for (i = 0; i < rx_conf->n_rx_queue; i++) {
-
-		portid = rx_conf->rx_queue_list[i].port_id;
-		queueid = rx_conf->rx_queue_list[i].queue_id;
-		RTE_LOG(INFO, L3FWD,
-			" -- lcoreid=%u portid=%u rxqueueid=%hhu\n",
-				rte_lcore_id(), portid, queueid);
-	}
-
-	/*
-	 * Init all condition variables (one per rx thread)
-	 */
-	for (i = 0; i < rx_conf->n_rx_queue; i++)
-		lthread_cond_init(NULL, &rx_conf->ready[i], NULL);
-
-	worker_id = 0;
-
-	rx_conf->conf.cpu_id = sched_getcpu();
-	rte_atomic16_inc(&rx_counter);
-	while (1) {
-
-		/*
-		 * Read packet from RX queues
-		 */
-		for (i = 0; i < rx_conf->n_rx_queue; ++i) {
-			portid = rx_conf->rx_queue_list[i].port_id;
-			queueid = rx_conf->rx_queue_list[i].queue_id;
-
-			SET_CPU_BUSY(rx_conf, CPU_POLL);
-			nb_rx = rte_eth_rx_burst(portid, queueid, pkts_burst,
-				MAX_PKT_BURST);
-			SET_CPU_IDLE(rx_conf, CPU_POLL);
-
-			if (nb_rx != 0) {
-				worker_id = (worker_id + 1) % rx_conf->n_ring;
-				old_len = len[worker_id];
-
-				SET_CPU_BUSY(rx_conf, CPU_PROCESS);
-				ret = rte_ring_sp_enqueue_burst(
-						rx_conf->ring[worker_id],
-						(void **) pkts_burst,
-						nb_rx, NULL);
-
-				new_len = old_len + ret;
-
-				if (new_len >= BURST_SIZE) {
-					lthread_cond_signal(rx_conf->ready[worker_id]);
-					new_len = 0;
-				}
-
-				len[worker_id] = new_len;
-
-				if (unlikely(ret < nb_rx)) {
-					uint32_t k;
-
-					for (k = ret; k < nb_rx; k++) {
-						struct rte_mbuf *m = pkts_burst[k];
-
-						rte_pktmbuf_free(m);
-					}
-				}
-				SET_CPU_IDLE(rx_conf, CPU_PROCESS);
-			}
-
-			lthread_yield();
-		}
-	}
-	return NULL;
-}
-
-/*
- * Start scheduler with initial lthread on lcore
- *
- * This lthread loop spawns all rx and tx lthreads on master lcore
- */
-
-static void *
-lthread_spawner(__rte_unused void *arg)
-{
-	struct lthread *lt[MAX_THREAD];
-	int i;
-	int n_thread = 0;
-
-	printf("Entering lthread_spawner\n");
-
-	/*
-	 * Create producers (rx threads) on default lcore
-	 */
-	for (i = 0; i < n_rx_thread; i++) {
-		rx_thread[i].conf.thread_id = i;
-		lthread_create(&lt[n_thread], -1, lthread_rx,
-				(void *)&rx_thread[i]);
-		n_thread++;
-	}
-
-	/*
-	 * Wait for all producers. Until some producers can be started on the same
-	 * scheduler as this lthread, yielding is required to let them to run and
-	 * prevent deadlock here.
-	 */
-	while (rte_atomic16_read(&rx_counter) < n_rx_thread)
-		lthread_sleep(100000);
-
-	/*
-	 * Create consumers (tx threads) on default lcore_id
-	 */
-	for (i = 0; i < n_tx_thread; i++) {
-		tx_thread[i].conf.thread_id = i;
-		lthread_create(&lt[n_thread], -1, lthread_tx,
-				(void *)&tx_thread[i]);
-		n_thread++;
-	}
-
-	/*
-	 * Wait for all threads finished
-	 */
-	for (i = 0; i < n_thread; i++)
-		lthread_join(lt[i], NULL);
-
-	return NULL;
-}
-
-/*
- * Start master scheduler with initial lthread spawning rx and tx lthreads
- * (main_lthread_master).
- */
-static int
-lthread_master_spawner(__rte_unused void *arg) {
-	struct lthread *lt;
-	int lcore_id = rte_lcore_id();
-
-	RTE_PER_LCORE(lcore_conf) = &lcore_conf[lcore_id];
-	lthread_create(&lt, -1, lthread_spawner, NULL);
-	lthread_run();
-
-	return 0;
-}
-
-/*
- * Start scheduler on lcore.
- */
-static int
-sched_spawner(__rte_unused void *arg) {
-	struct lthread *lt;
-	int lcore_id = rte_lcore_id();
-
-#if (APP_CPU_LOAD)
-	if (lcore_id == cpu_load_lcore_id) {
-		cpu_load_collector(arg);
-		return 0;
-	}
-#endif /* APP_CPU_LOAD */
-
-	RTE_PER_LCORE(lcore_conf) = &lcore_conf[lcore_id];
-	lthread_create(&lt, -1, lthread_null, NULL);
-	lthread_run();
-
-	return 0;
-}
-
-/* main processing loop */
-static int
-pthread_tx(void *dummy)
-{
-	struct rte_mbuf *pkts_burst[MAX_PKT_BURST];
-	uint64_t prev_tsc, diff_tsc, cur_tsc;
-	int nb_rx;
-	uint16_t portid;
-	struct thread_tx_conf *tx_conf;
-
-	const uint64_t drain_tsc = (rte_get_tsc_hz() + US_PER_S - 1) /
-		US_PER_S * BURST_TX_DRAIN_US;
-
-	prev_tsc = 0;
-
-	tx_conf = (struct thread_tx_conf *)dummy;
-
-	RTE_LOG(INFO, L3FWD, "Entering main Tx loop on lcore %u\n", rte_lcore_id());
-
-	tx_conf->conf.cpu_id = sched_getcpu();
-	rte_atomic16_inc(&tx_counter);
-	while (1) {
-
-		cur_tsc = rte_rdtsc();
-
-		/*
-		 * TX burst queue drain
-		 */
-		diff_tsc = cur_tsc - prev_tsc;
-		if (unlikely(diff_tsc > drain_tsc)) {
-
-			/*
-			 * This could be optimized (use queueid instead of
-			 * portid), but it is not called so often
-			 */
-			SET_CPU_BUSY(tx_conf, CPU_PROCESS);
-			for (portid = 0; portid < RTE_MAX_ETHPORTS; portid++) {
-				if (tx_conf->tx_mbufs[portid].len == 0)
-					continue;
-				send_burst(tx_conf, tx_conf->tx_mbufs[portid].len, portid);
-				tx_conf->tx_mbufs[portid].len = 0;
-			}
-			SET_CPU_IDLE(tx_conf, CPU_PROCESS);
-
-			prev_tsc = cur_tsc;
-		}
-
-		/*
-		 * Read packet from ring
-		 */
-		SET_CPU_BUSY(tx_conf, CPU_POLL);
-		nb_rx = rte_ring_sc_dequeue_burst(tx_conf->ring,
-				(void **)pkts_burst, MAX_PKT_BURST, NULL);
-		SET_CPU_IDLE(tx_conf, CPU_POLL);
-
-		if (unlikely(nb_rx == 0)) {
-			sched_yield();
-			continue;
-		}
-
-		SET_CPU_BUSY(tx_conf, CPU_PROCESS);
-		portid = pkts_burst[0]->port;
-		process_burst(pkts_burst, nb_rx, portid);
-		SET_CPU_IDLE(tx_conf, CPU_PROCESS);
-
-	}
-}
-
-static int
-pthread_rx(void *dummy)
-{
-	int i;
-	int worker_id;
-	uint32_t n;
-	uint32_t nb_rx;
-	unsigned lcore_id;
-	uint8_t queueid;
-	uint16_t portid;
-	struct rte_mbuf *pkts_burst[MAX_PKT_BURST];
-
-	struct thread_rx_conf *rx_conf;
-
-	lcore_id = rte_lcore_id();
-	rx_conf = (struct thread_rx_conf *)dummy;
-
-	if (rx_conf->n_rx_queue == 0) {
-		RTE_LOG(INFO, L3FWD, "lcore %u has nothing to do\n", lcore_id);
-		return 0;
-	}
-
-	RTE_LOG(INFO, L3FWD, "entering main rx loop on lcore %u\n", lcore_id);
-
-	for (i = 0; i < rx_conf->n_rx_queue; i++) {
-
-		portid = rx_conf->rx_queue_list[i].port_id;
-		queueid = rx_conf->rx_queue_list[i].queue_id;
-		RTE_LOG(INFO, L3FWD,
-			" -- lcoreid=%u portid=%u rxqueueid=%hhu\n",
-				lcore_id, portid, queueid);
-	}
-
-	worker_id = 0;
-	rx_conf->conf.cpu_id = sched_getcpu();
-	rte_atomic16_inc(&rx_counter);
-	while (1) {
-
-		/*
-		 * Read packet from RX queues
-		 */
-		for (i = 0; i < rx_conf->n_rx_queue; ++i) {
-			portid = rx_conf->rx_queue_list[i].port_id;
-			queueid = rx_conf->rx_queue_list[i].queue_id;
-
-			SET_CPU_BUSY(rx_conf, CPU_POLL);
-			nb_rx = rte_eth_rx_burst(portid, queueid, pkts_burst,
-				MAX_PKT_BURST);
-			SET_CPU_IDLE(rx_conf, CPU_POLL);
-
-			if (nb_rx == 0) {
-				sched_yield();
-				continue;
-			}
-
-			SET_CPU_BUSY(rx_conf, CPU_PROCESS);
-			worker_id = (worker_id + 1) % rx_conf->n_ring;
-			n = rte_ring_sp_enqueue_burst(rx_conf->ring[worker_id],
-					(void **)pkts_burst, nb_rx, NULL);
-
-			if (unlikely(n != nb_rx)) {
-				uint32_t k;
-
-				for (k = n; k < nb_rx; k++) {
-					struct rte_mbuf *m = pkts_burst[k];
-
-					rte_pktmbuf_free(m);
-				}
-			}
-
-			SET_CPU_IDLE(rx_conf, CPU_PROCESS);
-
-		}
-	}
-}
-
-/*
- * P-Thread spawner.
- */
-static int
-pthread_run(__rte_unused void *arg) {
-	int lcore_id = rte_lcore_id();
-	int i;
-
-	for (i = 0; i < n_rx_thread; i++)
-		if (rx_thread[i].conf.lcore_id == lcore_id) {
-			printf("Start rx thread on %d...\n", lcore_id);
-			RTE_PER_LCORE(lcore_conf) = &lcore_conf[lcore_id];
-			RTE_PER_LCORE(lcore_conf)->data = (void *)&rx_thread[i];
-			pthread_rx((void *)&rx_thread[i]);
-			return 0;
-		}
-
-	for (i = 0; i < n_tx_thread; i++)
-		if (tx_thread[i].conf.lcore_id == lcore_id) {
-			printf("Start tx thread on %d...\n", lcore_id);
-			RTE_PER_LCORE(lcore_conf) = &lcore_conf[lcore_id];
-			RTE_PER_LCORE(lcore_conf)->data = (void *)&tx_thread[i];
-			pthread_tx((void *)&tx_thread[i]);
-			return 0;
-		}
-
-#if (APP_CPU_LOAD)
-	if (lcore_id == cpu_load_lcore_id)
-		cpu_load_collector(arg);
-#endif /* APP_CPU_LOAD */
-
-	return 0;
-}
-
-static int
-check_lcore_params(void)
-{
-	uint8_t queue, lcore;
-	uint16_t i;
-	int socketid;
-
-	for (i = 0; i < nb_rx_thread_params; ++i) {
-		queue = rx_thread_params[i].queue_id;
-		if (queue >= MAX_RX_QUEUE_PER_PORT) {
-			printf("invalid queue number: %hhu\n", queue);
-			return -1;
-		}
-		lcore = rx_thread_params[i].lcore_id;
-		if (!rte_lcore_is_enabled(lcore)) {
-			printf("error: lcore %hhu is not enabled in lcore mask\n", lcore);
-			return -1;
-		}
-		socketid = rte_lcore_to_socket_id(lcore);
-		if ((socketid != 0) && (numa_on == 0))
-			printf("warning: lcore %hhu is on socket %d with numa off\n",
-				lcore, socketid);
-	}
-	return 0;
-}
-
-static int
-check_port_config(void)
-{
-	unsigned portid;
-	uint16_t i;
-
-	for (i = 0; i < nb_rx_thread_params; ++i) {
-		portid = rx_thread_params[i].port_id;
-		if ((enabled_port_mask & (1 << portid)) == 0) {
-			printf("port %u is not enabled in port mask\n", portid);
-			return -1;
-		}
-		if (!rte_eth_dev_is_valid_port(portid)) {
-			printf("port %u is not present on the board\n", portid);
-			return -1;
-		}
-	}
-	return 0;
-}
-
-static uint8_t
-get_port_n_rx_queues(const uint16_t port)
-{
-	int queue = -1;
-	uint16_t i;
-
-	for (i = 0; i < nb_rx_thread_params; ++i)
-		if (rx_thread_params[i].port_id == port &&
-				rx_thread_params[i].queue_id > queue)
-			queue = rx_thread_params[i].queue_id;
-
-	return (uint8_t)(++queue);
-}
-
-static int
-init_rx_rings(void)
-{
-	unsigned socket_io;
-	struct thread_rx_conf *rx_conf;
-	struct thread_tx_conf *tx_conf;
-	unsigned rx_thread_id, tx_thread_id;
-	char name[256];
-	struct rte_ring *ring = NULL;
-
-	for (tx_thread_id = 0; tx_thread_id < n_tx_thread; tx_thread_id++) {
-
-		tx_conf = &tx_thread[tx_thread_id];
-
-		printf("Connecting tx-thread %d with rx-thread %d\n", tx_thread_id,
-				tx_conf->conf.thread_id);
-
-		rx_thread_id = tx_conf->conf.thread_id;
-		if (rx_thread_id > n_tx_thread) {
-			printf("connection from tx-thread %u to rx-thread %u fails "
-					"(rx-thread not defined)\n", tx_thread_id, rx_thread_id);
-			return -1;
-		}
-
-		rx_conf = &rx_thread[rx_thread_id];
-		socket_io = rte_lcore_to_socket_id(rx_conf->conf.lcore_id);
-
-		snprintf(name, sizeof(name), "app_ring_s%u_rx%u_tx%u",
-				socket_io, rx_thread_id, tx_thread_id);
-
-		ring = rte_ring_create(name, 1024 * 4, socket_io,
-				RING_F_SP_ENQ | RING_F_SC_DEQ);
-
-		if (ring == NULL) {
-			rte_panic("Cannot create ring to connect rx-thread %u "
-					"with tx-thread %u\n", rx_thread_id, tx_thread_id);
-		}
-
-		rx_conf->ring[rx_conf->n_ring] = ring;
-
-		tx_conf->ring = ring;
-		tx_conf->ready = &rx_conf->ready[rx_conf->n_ring];
-
-		rx_conf->n_ring++;
-	}
-	return 0;
-}
-
-static int
-init_rx_queues(void)
-{
-	uint16_t i, nb_rx_queue;
-	uint8_t thread;
-
-	n_rx_thread = 0;
-
-	for (i = 0; i < nb_rx_thread_params; ++i) {
-		thread = rx_thread_params[i].thread_id;
-		nb_rx_queue = rx_thread[thread].n_rx_queue;
-
-		if (nb_rx_queue >= MAX_RX_QUEUE_PER_LCORE) {
-			printf("error: too many queues (%u) for thread: %u\n",
-				(unsigned)nb_rx_queue + 1, (unsigned)thread);
-			return -1;
-		}
-
-		rx_thread[thread].conf.thread_id = thread;
-		rx_thread[thread].conf.lcore_id = rx_thread_params[i].lcore_id;
-		rx_thread[thread].rx_queue_list[nb_rx_queue].port_id =
-			rx_thread_params[i].port_id;
-		rx_thread[thread].rx_queue_list[nb_rx_queue].queue_id =
-			rx_thread_params[i].queue_id;
-		rx_thread[thread].n_rx_queue++;
-
-		if (thread >= n_rx_thread)
-			n_rx_thread = thread + 1;
-
-	}
-	return 0;
-}
-
-static int
-init_tx_threads(void)
-{
-	int i;
-
-	n_tx_thread = 0;
-	for (i = 0; i < nb_tx_thread_params; ++i) {
-		tx_thread[n_tx_thread].conf.thread_id = tx_thread_params[i].thread_id;
-		tx_thread[n_tx_thread].conf.lcore_id = tx_thread_params[i].lcore_id;
-		n_tx_thread++;
-	}
-	return 0;
-}
-
-/* display usage */
-static void
-print_usage(const char *prgname)
-{
-	printf("%s [EAL options] -- -p PORTMASK -P"
-		"  [--rx (port,queue,lcore,thread)[,(port,queue,lcore,thread]]"
-		"  [--tx (lcore,thread)[,(lcore,thread]]"
-		"  [--enable-jumbo [--max-pkt-len PKTLEN]]\n"
-		"  [--parse-ptype]\n\n"
-		"  -p PORTMASK: hexadecimal bitmask of ports to configure\n"
-		"  -P : enable promiscuous mode\n"
-		"  --rx (port,queue,lcore,thread): rx queues configuration\n"
-		"  --tx (lcore,thread): tx threads configuration\n"
-		"  --stat-lcore LCORE: use lcore for stat collector\n"
-		"  --eth-dest=X,MM:MM:MM:MM:MM:MM: optional, ethernet destination for port X\n"
-		"  --no-numa: optional, disable numa awareness\n"
-		"  --ipv6: optional, specify it if running ipv6 packets\n"
-		"  --enable-jumbo: enable jumbo frame"
-		" which max packet len is PKTLEN in decimal (64-9600)\n"
-		"  --hash-entry-num: specify the hash entry number in hexadecimal to be setup\n"
-		"  --no-lthreads: turn off lthread model\n"
-		"  --parse-ptype: set to use software to analyze packet type\n\n",
-		prgname);
-}
-
-static int parse_max_pkt_len(const char *pktlen)
-{
-	char *end = NULL;
-	unsigned long len;
-
-	/* parse decimal string */
-	len = strtoul(pktlen, &end, 10);
-	if ((pktlen[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (len == 0)
-		return -1;
-
-	return len;
-}
-
-static int
-parse_portmask(const char *portmask)
-{
-	char *end = NULL;
-	unsigned long pm;
-
-	/* parse hexadecimal string */
-	pm = strtoul(portmask, &end, 16);
-	if ((portmask[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (pm == 0)
-		return -1;
-
-	return pm;
-}
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_EXACT_MATCH)
-static int
-parse_hash_entry_number(const char *hash_entry_num)
-{
-	char *end = NULL;
-	unsigned long hash_en;
-
-	/* parse hexadecimal string */
-	hash_en = strtoul(hash_entry_num, &end, 16);
-	if ((hash_entry_num[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (hash_en == 0)
-		return -1;
-
-	return hash_en;
-}
-#endif
-
-static int
-parse_rx_config(const char *q_arg)
-{
-	char s[256];
-	const char *p, *p0 = q_arg;
-	char *end;
-	enum fieldnames {
-		FLD_PORT = 0,
-		FLD_QUEUE,
-		FLD_LCORE,
-		FLD_THREAD,
-		_NUM_FLD
-	};
-	unsigned long int_fld[_NUM_FLD];
-	char *str_fld[_NUM_FLD];
-	int i;
-	unsigned size;
-
-	nb_rx_thread_params = 0;
-
-	while ((p = strchr(p0, '(')) != NULL) {
-		++p;
-		p0 = strchr(p, ')');
-		if (p0 == NULL)
-			return -1;
-
-		size = p0 - p;
-		if (size >= sizeof(s))
-			return -1;
-
-		snprintf(s, sizeof(s), "%.*s", size, p);
-		if (rte_strsplit(s, sizeof(s), str_fld, _NUM_FLD, ',') != _NUM_FLD)
-			return -1;
-		for (i = 0; i < _NUM_FLD; i++) {
-			errno = 0;
-			int_fld[i] = strtoul(str_fld[i], &end, 0);
-			if (errno != 0 || end == str_fld[i] || int_fld[i] > 255)
-				return -1;
-		}
-		if (nb_rx_thread_params >= MAX_LCORE_PARAMS) {
-			printf("exceeded max number of rx params: %hu\n",
-					nb_rx_thread_params);
-			return -1;
-		}
-		rx_thread_params_array[nb_rx_thread_params].port_id =
-				int_fld[FLD_PORT];
-		rx_thread_params_array[nb_rx_thread_params].queue_id =
-				(uint8_t)int_fld[FLD_QUEUE];
-		rx_thread_params_array[nb_rx_thread_params].lcore_id =
-				(uint8_t)int_fld[FLD_LCORE];
-		rx_thread_params_array[nb_rx_thread_params].thread_id =
-				(uint8_t)int_fld[FLD_THREAD];
-		++nb_rx_thread_params;
-	}
-	rx_thread_params = rx_thread_params_array;
-	return 0;
-}
-
-static int
-parse_tx_config(const char *q_arg)
-{
-	char s[256];
-	const char *p, *p0 = q_arg;
-	char *end;
-	enum fieldnames {
-		FLD_LCORE = 0,
-		FLD_THREAD,
-		_NUM_FLD
-	};
-	unsigned long int_fld[_NUM_FLD];
-	char *str_fld[_NUM_FLD];
-	int i;
-	unsigned size;
-
-	nb_tx_thread_params = 0;
-
-	while ((p = strchr(p0, '(')) != NULL) {
-		++p;
-		p0 = strchr(p, ')');
-		if (p0 == NULL)
-			return -1;
-
-		size = p0 - p;
-		if (size >= sizeof(s))
-			return -1;
-
-		snprintf(s, sizeof(s), "%.*s", size, p);
-		if (rte_strsplit(s, sizeof(s), str_fld, _NUM_FLD, ',') != _NUM_FLD)
-			return -1;
-		for (i = 0; i < _NUM_FLD; i++) {
-			errno = 0;
-			int_fld[i] = strtoul(str_fld[i], &end, 0);
-			if (errno != 0 || end == str_fld[i] || int_fld[i] > 255)
-				return -1;
-		}
-		if (nb_tx_thread_params >= MAX_LCORE_PARAMS) {
-			printf("exceeded max number of tx params: %hu\n",
-				nb_tx_thread_params);
-			return -1;
-		}
-		tx_thread_params_array[nb_tx_thread_params].lcore_id =
-				(uint8_t)int_fld[FLD_LCORE];
-		tx_thread_params_array[nb_tx_thread_params].thread_id =
-				(uint8_t)int_fld[FLD_THREAD];
-		++nb_tx_thread_params;
-	}
-	tx_thread_params = tx_thread_params_array;
-
-	return 0;
-}
-
-#if (APP_CPU_LOAD > 0)
-static int
-parse_stat_lcore(const char *stat_lcore)
-{
-	char *end = NULL;
-	unsigned long lcore_id;
-
-	lcore_id = strtoul(stat_lcore, &end, 10);
-	if ((stat_lcore[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	return lcore_id;
-}
-#endif
-
-static void
-parse_eth_dest(const char *optarg)
-{
-	uint16_t portid;
-	char *port_end;
-	uint8_t c, *dest, peer_addr[6];
-
-	errno = 0;
-	portid = strtoul(optarg, &port_end, 10);
-	if (errno != 0 || port_end == optarg || *port_end++ != ',')
-		rte_exit(EXIT_FAILURE,
-		"Invalid eth-dest: %s", optarg);
-	if (portid >= RTE_MAX_ETHPORTS)
-		rte_exit(EXIT_FAILURE,
-		"eth-dest: port %d >= RTE_MAX_ETHPORTS(%d)\n",
-		portid, RTE_MAX_ETHPORTS);
-
-	if (cmdline_parse_etheraddr(NULL, port_end,
-		&peer_addr, sizeof(peer_addr)) < 0)
-		rte_exit(EXIT_FAILURE,
-		"Invalid ethernet address: %s\n",
-		port_end);
-	dest = (uint8_t *)&dest_eth_addr[portid];
-	for (c = 0; c < 6; c++)
-		dest[c] = peer_addr[c];
-	*(uint64_t *)(val_eth + portid) = dest_eth_addr[portid];
-}
-
-#define CMD_LINE_OPT_RX_CONFIG "rx"
-#define CMD_LINE_OPT_TX_CONFIG "tx"
-#define CMD_LINE_OPT_STAT_LCORE "stat-lcore"
-#define CMD_LINE_OPT_ETH_DEST "eth-dest"
-#define CMD_LINE_OPT_NO_NUMA "no-numa"
-#define CMD_LINE_OPT_IPV6 "ipv6"
-#define CMD_LINE_OPT_ENABLE_JUMBO "enable-jumbo"
-#define CMD_LINE_OPT_HASH_ENTRY_NUM "hash-entry-num"
-#define CMD_LINE_OPT_NO_LTHREADS "no-lthreads"
-#define CMD_LINE_OPT_PARSE_PTYPE "parse-ptype"
-
-/* Parse the argument given in the command line of the application */
-static int
-parse_args(int argc, char **argv)
-{
-	int opt, ret;
-	char **argvopt;
-	int option_index;
-	char *prgname = argv[0];
-	static struct option lgopts[] = {
-		{CMD_LINE_OPT_RX_CONFIG, 1, 0, 0},
-		{CMD_LINE_OPT_TX_CONFIG, 1, 0, 0},
-		{CMD_LINE_OPT_STAT_LCORE, 1, 0, 0},
-		{CMD_LINE_OPT_ETH_DEST, 1, 0, 0},
-		{CMD_LINE_OPT_NO_NUMA, 0, 0, 0},
-		{CMD_LINE_OPT_IPV6, 0, 0, 0},
-		{CMD_LINE_OPT_ENABLE_JUMBO, 0, 0, 0},
-		{CMD_LINE_OPT_HASH_ENTRY_NUM, 1, 0, 0},
-		{CMD_LINE_OPT_NO_LTHREADS, 0, 0, 0},
-		{CMD_LINE_OPT_PARSE_PTYPE, 0, 0, 0},
-		{NULL, 0, 0, 0}
-	};
-
-	argvopt = argv;
-
-	while ((opt = getopt_long(argc, argvopt, "p:P",
-				lgopts, &option_index)) != EOF) {
-
-		switch (opt) {
-		/* portmask */
-		case 'p':
-			enabled_port_mask = parse_portmask(optarg);
-			if (enabled_port_mask == 0) {
-				printf("invalid portmask\n");
-				print_usage(prgname);
-				return -1;
-			}
-			break;
-		case 'P':
-			printf("Promiscuous mode selected\n");
-			promiscuous_on = 1;
-			break;
-
-		/* long options */
-		case 0:
-			if (!strncmp(lgopts[option_index].name, CMD_LINE_OPT_RX_CONFIG,
-				sizeof(CMD_LINE_OPT_RX_CONFIG))) {
-				ret = parse_rx_config(optarg);
-				if (ret) {
-					printf("invalid rx-config\n");
-					print_usage(prgname);
-					return -1;
-				}
-			}
-
-			if (!strncmp(lgopts[option_index].name, CMD_LINE_OPT_TX_CONFIG,
-				sizeof(CMD_LINE_OPT_TX_CONFIG))) {
-				ret = parse_tx_config(optarg);
-				if (ret) {
-					printf("invalid tx-config\n");
-					print_usage(prgname);
-					return -1;
-				}
-			}
-
-#if (APP_CPU_LOAD > 0)
-			if (!strncmp(lgopts[option_index].name, CMD_LINE_OPT_STAT_LCORE,
-					sizeof(CMD_LINE_OPT_STAT_LCORE))) {
-				cpu_load_lcore_id = parse_stat_lcore(optarg);
-			}
-#endif
-
-			if (!strncmp(lgopts[option_index].name, CMD_LINE_OPT_ETH_DEST,
-				sizeof(CMD_LINE_OPT_ETH_DEST)))
-					parse_eth_dest(optarg);
-
-			if (!strncmp(lgopts[option_index].name, CMD_LINE_OPT_NO_NUMA,
-				sizeof(CMD_LINE_OPT_NO_NUMA))) {
-				printf("numa is disabled\n");
-				numa_on = 0;
-			}
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_EXACT_MATCH)
-			if (!strncmp(lgopts[option_index].name, CMD_LINE_OPT_IPV6,
-				sizeof(CMD_LINE_OPT_IPV6))) {
-				printf("ipv6 is specified\n");
-				ipv6 = 1;
-			}
-#endif
-
-			if (!strncmp(lgopts[option_index].name, CMD_LINE_OPT_NO_LTHREADS,
-					sizeof(CMD_LINE_OPT_NO_LTHREADS))) {
-				printf("l-threads model is disabled\n");
-				lthreads_on = 0;
-			}
-
-			if (!strncmp(lgopts[option_index].name, CMD_LINE_OPT_PARSE_PTYPE,
-					sizeof(CMD_LINE_OPT_PARSE_PTYPE))) {
-				printf("software packet type parsing enabled\n");
-				parse_ptype_on = 1;
-			}
-
-			if (!strncmp(lgopts[option_index].name, CMD_LINE_OPT_ENABLE_JUMBO,
-				sizeof(CMD_LINE_OPT_ENABLE_JUMBO))) {
-				struct option lenopts = {"max-pkt-len", required_argument, 0,
-						0};
-
-				printf("jumbo frame is enabled - disabling simple TX path\n");
-				port_conf.rxmode.offloads |=
-						DEV_RX_OFFLOAD_JUMBO_FRAME;
-				port_conf.txmode.offloads |=
-						DEV_TX_OFFLOAD_MULTI_SEGS;
-
-				/* if no max-pkt-len set, use the default value ETHER_MAX_LEN */
-				if (0 == getopt_long(argc, argvopt, "", &lenopts,
-						&option_index)) {
-
-					ret = parse_max_pkt_len(optarg);
-					if ((ret < 64) || (ret > MAX_JUMBO_PKT_LEN)) {
-						printf("invalid packet length\n");
-						print_usage(prgname);
-						return -1;
-					}
-					port_conf.rxmode.max_rx_pkt_len = ret;
-				}
-				printf("set jumbo frame max packet length to %u\n",
-						(unsigned int)port_conf.rxmode.max_rx_pkt_len);
-			}
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_EXACT_MATCH)
-			if (!strncmp(lgopts[option_index].name, CMD_LINE_OPT_HASH_ENTRY_NUM,
-				sizeof(CMD_LINE_OPT_HASH_ENTRY_NUM))) {
-				ret = parse_hash_entry_number(optarg);
-				if ((ret > 0) && (ret <= L3FWD_HASH_ENTRIES)) {
-					hash_entry_number = ret;
-				} else {
-					printf("invalid hash entry number\n");
-					print_usage(prgname);
-					return -1;
-				}
-			}
-#endif
-			break;
-
-		default:
-			print_usage(prgname);
-			return -1;
-		}
-	}
-
-	if (optind >= 0)
-		argv[optind-1] = prgname;
-
-	ret = optind-1;
-	optind = 1; /* reset getopt lib */
-	return ret;
-}
-
-static void
-print_ethaddr(const char *name, const struct ether_addr *eth_addr)
-{
-	char buf[ETHER_ADDR_FMT_SIZE];
-
-	ether_format_addr(buf, ETHER_ADDR_FMT_SIZE, eth_addr);
-	printf("%s%s", name, buf);
-}
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_EXACT_MATCH)
-
-static void convert_ipv4_5tuple(struct ipv4_5tuple *key1,
-		union ipv4_5tuple_host *key2)
-{
-	key2->ip_dst = rte_cpu_to_be_32(key1->ip_dst);
-	key2->ip_src = rte_cpu_to_be_32(key1->ip_src);
-	key2->port_dst = rte_cpu_to_be_16(key1->port_dst);
-	key2->port_src = rte_cpu_to_be_16(key1->port_src);
-	key2->proto = key1->proto;
-	key2->pad0 = 0;
-	key2->pad1 = 0;
-}
-
-static void convert_ipv6_5tuple(struct ipv6_5tuple *key1,
-		union ipv6_5tuple_host *key2)
-{
-	uint32_t i;
-
-	for (i = 0; i < 16; i++) {
-		key2->ip_dst[i] = key1->ip_dst[i];
-		key2->ip_src[i] = key1->ip_src[i];
-	}
-	key2->port_dst = rte_cpu_to_be_16(key1->port_dst);
-	key2->port_src = rte_cpu_to_be_16(key1->port_src);
-	key2->proto = key1->proto;
-	key2->pad0 = 0;
-	key2->pad1 = 0;
-	key2->reserve = 0;
-}
-
-#define BYTE_VALUE_MAX 256
-#define ALL_32_BITS 0xffffffff
-#define BIT_8_TO_15 0x0000ff00
-static inline void
-populate_ipv4_few_flow_into_table(const struct rte_hash *h)
-{
-	uint32_t i;
-	int32_t ret;
-	uint32_t array_len = RTE_DIM(ipv4_l3fwd_route_array);
-
-	mask0 = _mm_set_epi32(ALL_32_BITS, ALL_32_BITS, ALL_32_BITS, BIT_8_TO_15);
-	for (i = 0; i < array_len; i++) {
-		struct ipv4_l3fwd_route  entry;
-		union ipv4_5tuple_host newkey;
-
-		entry = ipv4_l3fwd_route_array[i];
-		convert_ipv4_5tuple(&entry.key, &newkey);
-		ret = rte_hash_add_key(h, (void *)&newkey);
-		if (ret < 0) {
-			rte_exit(EXIT_FAILURE, "Unable to add entry %" PRIu32
-				" to the l3fwd hash.\n", i);
-		}
-		ipv4_l3fwd_out_if[ret] = entry.if_out;
-	}
-	printf("Hash: Adding 0x%" PRIx32 " keys\n", array_len);
-}
-
-#define BIT_16_TO_23 0x00ff0000
-static inline void
-populate_ipv6_few_flow_into_table(const struct rte_hash *h)
-{
-	uint32_t i;
-	int32_t ret;
-	uint32_t array_len = RTE_DIM(ipv6_l3fwd_route_array);
-
-	mask1 = _mm_set_epi32(ALL_32_BITS, ALL_32_BITS, ALL_32_BITS, BIT_16_TO_23);
-	mask2 = _mm_set_epi32(0, 0, ALL_32_BITS, ALL_32_BITS);
-	for (i = 0; i < array_len; i++) {
-		struct ipv6_l3fwd_route entry;
-		union ipv6_5tuple_host newkey;
-
-		entry = ipv6_l3fwd_route_array[i];
-		convert_ipv6_5tuple(&entry.key, &newkey);
-		ret = rte_hash_add_key(h, (void *)&newkey);
-		if (ret < 0) {
-			rte_exit(EXIT_FAILURE, "Unable to add entry %" PRIu32
-				" to the l3fwd hash.\n", i);
-		}
-		ipv6_l3fwd_out_if[ret] = entry.if_out;
-	}
-	printf("Hash: Adding 0x%" PRIx32 "keys\n", array_len);
-}
-
-#define NUMBER_PORT_USED 4
-static inline void
-populate_ipv4_many_flow_into_table(const struct rte_hash *h,
-		unsigned int nr_flow)
-{
-	unsigned i;
-
-	mask0 = _mm_set_epi32(ALL_32_BITS, ALL_32_BITS, ALL_32_BITS, BIT_8_TO_15);
-
-	for (i = 0; i < nr_flow; i++) {
-		struct ipv4_l3fwd_route entry;
-		union ipv4_5tuple_host newkey;
-		uint8_t a = (uint8_t)((i / NUMBER_PORT_USED) % BYTE_VALUE_MAX);
-		uint8_t b = (uint8_t)(((i / NUMBER_PORT_USED) / BYTE_VALUE_MAX) %
-				BYTE_VALUE_MAX);
-		uint8_t c = (uint8_t)((i / NUMBER_PORT_USED) / (BYTE_VALUE_MAX *
-				BYTE_VALUE_MAX));
-		/* Create the ipv4 exact match flow */
-		memset(&entry, 0, sizeof(entry));
-		switch (i & (NUMBER_PORT_USED - 1)) {
-		case 0:
-			entry = ipv4_l3fwd_route_array[0];
-			entry.key.ip_dst = IPv4(101, c, b, a);
-			break;
-		case 1:
-			entry = ipv4_l3fwd_route_array[1];
-			entry.key.ip_dst = IPv4(201, c, b, a);
-			break;
-		case 2:
-			entry = ipv4_l3fwd_route_array[2];
-			entry.key.ip_dst = IPv4(111, c, b, a);
-			break;
-		case 3:
-			entry = ipv4_l3fwd_route_array[3];
-			entry.key.ip_dst = IPv4(211, c, b, a);
-			break;
-		};
-		convert_ipv4_5tuple(&entry.key, &newkey);
-		int32_t ret = rte_hash_add_key(h, (void *)&newkey);
-
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "Unable to add entry %u\n", i);
-
-		ipv4_l3fwd_out_if[ret] = (uint8_t)entry.if_out;
-
-	}
-	printf("Hash: Adding 0x%x keys\n", nr_flow);
-}
-
-static inline void
-populate_ipv6_many_flow_into_table(const struct rte_hash *h,
-		unsigned int nr_flow)
-{
-	unsigned i;
-
-	mask1 = _mm_set_epi32(ALL_32_BITS, ALL_32_BITS, ALL_32_BITS, BIT_16_TO_23);
-	mask2 = _mm_set_epi32(0, 0, ALL_32_BITS, ALL_32_BITS);
-	for (i = 0; i < nr_flow; i++) {
-		struct ipv6_l3fwd_route entry;
-		union ipv6_5tuple_host newkey;
-
-		uint8_t a = (uint8_t) ((i / NUMBER_PORT_USED) % BYTE_VALUE_MAX);
-		uint8_t b = (uint8_t) (((i / NUMBER_PORT_USED) / BYTE_VALUE_MAX) %
-				BYTE_VALUE_MAX);
-		uint8_t c = (uint8_t) ((i / NUMBER_PORT_USED) / (BYTE_VALUE_MAX *
-				BYTE_VALUE_MAX));
-
-		/* Create the ipv6 exact match flow */
-		memset(&entry, 0, sizeof(entry));
-		switch (i & (NUMBER_PORT_USED - 1)) {
-		case 0:
-			entry = ipv6_l3fwd_route_array[0];
-			break;
-		case 1:
-			entry = ipv6_l3fwd_route_array[1];
-			break;
-		case 2:
-			entry = ipv6_l3fwd_route_array[2];
-			break;
-		case 3:
-			entry = ipv6_l3fwd_route_array[3];
-			break;
-		};
-		entry.key.ip_dst[13] = c;
-		entry.key.ip_dst[14] = b;
-		entry.key.ip_dst[15] = a;
-		convert_ipv6_5tuple(&entry.key, &newkey);
-		int32_t ret = rte_hash_add_key(h, (void *)&newkey);
-
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "Unable to add entry %u\n", i);
-
-		ipv6_l3fwd_out_if[ret] = (uint8_t) entry.if_out;
-
-	}
-	printf("Hash: Adding 0x%x keys\n", nr_flow);
-}
-
-static void
-setup_hash(int socketid)
-{
-	struct rte_hash_parameters ipv4_l3fwd_hash_params = {
-		.name = NULL,
-		.entries = L3FWD_HASH_ENTRIES,
-		.key_len = sizeof(union ipv4_5tuple_host),
-		.hash_func = ipv4_hash_crc,
-		.hash_func_init_val = 0,
-	};
-
-	struct rte_hash_parameters ipv6_l3fwd_hash_params = {
-		.name = NULL,
-		.entries = L3FWD_HASH_ENTRIES,
-		.key_len = sizeof(union ipv6_5tuple_host),
-		.hash_func = ipv6_hash_crc,
-		.hash_func_init_val = 0,
-	};
-
-	char s[64];
-
-	/* create ipv4 hash */
-	snprintf(s, sizeof(s), "ipv4_l3fwd_hash_%d", socketid);
-	ipv4_l3fwd_hash_params.name = s;
-	ipv4_l3fwd_hash_params.socket_id = socketid;
-	ipv4_l3fwd_lookup_struct[socketid] =
-			rte_hash_create(&ipv4_l3fwd_hash_params);
-	if (ipv4_l3fwd_lookup_struct[socketid] == NULL)
-		rte_exit(EXIT_FAILURE, "Unable to create the l3fwd hash on "
-				"socket %d\n", socketid);
-
-	/* create ipv6 hash */
-	snprintf(s, sizeof(s), "ipv6_l3fwd_hash_%d", socketid);
-	ipv6_l3fwd_hash_params.name = s;
-	ipv6_l3fwd_hash_params.socket_id = socketid;
-	ipv6_l3fwd_lookup_struct[socketid] =
-			rte_hash_create(&ipv6_l3fwd_hash_params);
-	if (ipv6_l3fwd_lookup_struct[socketid] == NULL)
-		rte_exit(EXIT_FAILURE, "Unable to create the l3fwd hash on "
-				"socket %d\n", socketid);
-
-	if (hash_entry_number != HASH_ENTRY_NUMBER_DEFAULT) {
-		/* For testing hash matching with a large number of flows we
-		 * generate millions of IP 5-tuples with an incremented dst
-		 * address to initialize the hash table. */
-		if (ipv6 == 0) {
-			/* populate the ipv4 hash */
-			populate_ipv4_many_flow_into_table(
-				ipv4_l3fwd_lookup_struct[socketid], hash_entry_number);
-		} else {
-			/* populate the ipv6 hash */
-			populate_ipv6_many_flow_into_table(
-				ipv6_l3fwd_lookup_struct[socketid], hash_entry_number);
-		}
-	} else {
-		/* Use data in ipv4/ipv6 l3fwd lookup table directly to initialize
-		 * the hash table */
-		if (ipv6 == 0) {
-			/* populate the ipv4 hash */
-			populate_ipv4_few_flow_into_table(
-					ipv4_l3fwd_lookup_struct[socketid]);
-		} else {
-			/* populate the ipv6 hash */
-			populate_ipv6_few_flow_into_table(
-					ipv6_l3fwd_lookup_struct[socketid]);
-		}
-	}
-}
-#endif
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_LPM)
-static void
-setup_lpm(int socketid)
-{
-	struct rte_lpm6_config config;
-	struct rte_lpm_config lpm_ipv4_config;
-	unsigned i;
-	int ret;
-	char s[64];
-
-	/* create the LPM table */
-	snprintf(s, sizeof(s), "IPV4_L3FWD_LPM_%d", socketid);
-	lpm_ipv4_config.max_rules = IPV4_L3FWD_LPM_MAX_RULES;
-	lpm_ipv4_config.number_tbl8s = 256;
-	lpm_ipv4_config.flags = 0;
-	ipv4_l3fwd_lookup_struct[socketid] =
-			rte_lpm_create(s, socketid, &lpm_ipv4_config);
-	if (ipv4_l3fwd_lookup_struct[socketid] == NULL)
-		rte_exit(EXIT_FAILURE, "Unable to create the l3fwd LPM table"
-				" on socket %d\n", socketid);
-
-	/* populate the LPM table */
-	for (i = 0; i < IPV4_L3FWD_NUM_ROUTES; i++) {
-
-		/* skip unused ports */
-		if ((1 << ipv4_l3fwd_route_array[i].if_out &
-				enabled_port_mask) == 0)
-			continue;
-
-		ret = rte_lpm_add(ipv4_l3fwd_lookup_struct[socketid],
-			ipv4_l3fwd_route_array[i].ip,
-			ipv4_l3fwd_route_array[i].depth,
-			ipv4_l3fwd_route_array[i].if_out);
-
-		if (ret < 0) {
-			rte_exit(EXIT_FAILURE, "Unable to add entry %u to the "
-				"l3fwd LPM table on socket %d\n",
-				i, socketid);
-		}
-
-		printf("LPM: Adding route 0x%08x / %d (%d)\n",
-			(unsigned)ipv4_l3fwd_route_array[i].ip,
-			ipv4_l3fwd_route_array[i].depth,
-			ipv4_l3fwd_route_array[i].if_out);
-	}
-
-	/* create the LPM6 table */
-	snprintf(s, sizeof(s), "IPV6_L3FWD_LPM_%d", socketid);
-
-	config.max_rules = IPV6_L3FWD_LPM_MAX_RULES;
-	config.number_tbl8s = IPV6_L3FWD_LPM_NUMBER_TBL8S;
-	config.flags = 0;
-	ipv6_l3fwd_lookup_struct[socketid] = rte_lpm6_create(s, socketid,
-				&config);
-	if (ipv6_l3fwd_lookup_struct[socketid] == NULL)
-		rte_exit(EXIT_FAILURE, "Unable to create the l3fwd LPM table"
-				" on socket %d\n", socketid);
-
-	/* populate the LPM table */
-	for (i = 0; i < IPV6_L3FWD_NUM_ROUTES; i++) {
-
-		/* skip unused ports */
-		if ((1 << ipv6_l3fwd_route_array[i].if_out &
-				enabled_port_mask) == 0)
-			continue;
-
-		ret = rte_lpm6_add(ipv6_l3fwd_lookup_struct[socketid],
-			ipv6_l3fwd_route_array[i].ip,
-			ipv6_l3fwd_route_array[i].depth,
-			ipv6_l3fwd_route_array[i].if_out);
-
-		if (ret < 0) {
-			rte_exit(EXIT_FAILURE, "Unable to add entry %u to the "
-				"l3fwd LPM table on socket %d\n",
-				i, socketid);
-		}
-
-		printf("LPM: Adding route %s / %d (%d)\n",
-			"IPV6",
-			ipv6_l3fwd_route_array[i].depth,
-			ipv6_l3fwd_route_array[i].if_out);
-	}
-}
-#endif
-
-static int
-init_mem(unsigned nb_mbuf)
-{
-	struct lcore_conf *qconf;
-	int socketid;
-	unsigned lcore_id;
-	char s[64];
-
-	for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-		if (rte_lcore_is_enabled(lcore_id) == 0)
-			continue;
-
-		if (numa_on)
-			socketid = rte_lcore_to_socket_id(lcore_id);
-		else
-			socketid = 0;
-
-		if (socketid >= NB_SOCKETS) {
-			rte_exit(EXIT_FAILURE, "Socket %d of lcore %u is out of range %d\n",
-				socketid, lcore_id, NB_SOCKETS);
-		}
-		if (pktmbuf_pool[socketid] == NULL) {
-			snprintf(s, sizeof(s), "mbuf_pool_%d", socketid);
-			pktmbuf_pool[socketid] =
-				rte_pktmbuf_pool_create(s, nb_mbuf,
-					MEMPOOL_CACHE_SIZE, 0,
-					RTE_MBUF_DEFAULT_BUF_SIZE, socketid);
-			if (pktmbuf_pool[socketid] == NULL)
-				rte_exit(EXIT_FAILURE,
-						"Cannot init mbuf pool on socket %d\n", socketid);
-			else
-				printf("Allocated mbuf pool on socket %d\n", socketid);
-
-#if (APP_LOOKUP_METHOD == APP_LOOKUP_LPM)
-			setup_lpm(socketid);
-#else
-			setup_hash(socketid);
-#endif
-		}
-		qconf = &lcore_conf[lcore_id];
-		qconf->ipv4_lookup_struct = ipv4_l3fwd_lookup_struct[socketid];
-		qconf->ipv6_lookup_struct = ipv6_l3fwd_lookup_struct[socketid];
-	}
-	return 0;
-}
-
-/* Check the link status of all ports in up to 9s, and print them finally */
-static void
-check_all_ports_link_status(uint32_t port_mask)
-{
-#define CHECK_INTERVAL 100 /* 100ms */
-#define MAX_CHECK_TIME 90 /* 9s (90 * 100ms) in total */
-	uint16_t portid;
-	uint8_t count, all_ports_up, print_flag = 0;
-	struct rte_eth_link link;
-
-	printf("\nChecking link status");
-	fflush(stdout);
-	for (count = 0; count <= MAX_CHECK_TIME; count++) {
-		all_ports_up = 1;
-		RTE_ETH_FOREACH_DEV(portid) {
-			if ((port_mask & (1 << portid)) == 0)
-				continue;
-			memset(&link, 0, sizeof(link));
-			rte_eth_link_get_nowait(portid, &link);
-			/* print link status if flag set */
-			if (print_flag == 1) {
-				if (link.link_status)
-					printf(
-					"Port%d Link Up. Speed %u Mbps - %s\n",
-						portid, link.link_speed,
-				(link.link_duplex == ETH_LINK_FULL_DUPLEX) ?
-					("full-duplex") : ("half-duplex\n"));
-				else
-					printf("Port %d Link Down\n", portid);
-				continue;
-			}
-			/* clear all_ports_up flag if any link down */
-			if (link.link_status == ETH_LINK_DOWN) {
-				all_ports_up = 0;
-				break;
-			}
-		}
-		/* after finally printing all link status, get out */
-		if (print_flag == 1)
-			break;
-
-		if (all_ports_up == 0) {
-			printf(".");
-			fflush(stdout);
-			rte_delay_ms(CHECK_INTERVAL);
-		}
-
-		/* set the print_flag if all ports up or timeout */
-		if (all_ports_up == 1 || count == (MAX_CHECK_TIME - 1)) {
-			print_flag = 1;
-			printf("done\n");
-		}
-	}
-}
-
-int
-main(int argc, char **argv)
-{
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_txconf *txconf;
-	int ret;
-	int i;
-	unsigned nb_ports;
-	uint16_t queueid, portid;
-	unsigned lcore_id;
-	uint32_t n_tx_queue, nb_lcores;
-	uint8_t nb_rx_queue, queue, socketid;
-
-	/* init EAL */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid EAL parameters\n");
-	argc -= ret;
-	argv += ret;
-
-	/* pre-init dst MACs for all ports to 02:00:00:00:00:xx */
-	for (portid = 0; portid < RTE_MAX_ETHPORTS; portid++) {
-		dest_eth_addr[portid] = ETHER_LOCAL_ADMIN_ADDR +
-				((uint64_t)portid << 40);
-		*(uint64_t *)(val_eth + portid) = dest_eth_addr[portid];
-	}
-
-	/* parse application arguments (after the EAL ones) */
-	ret = parse_args(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid L3FWD parameters\n");
-
-	if (check_lcore_params() < 0)
-		rte_exit(EXIT_FAILURE, "check_lcore_params failed\n");
-
-	printf("Initializing rx-queues...\n");
-	ret = init_rx_queues();
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "init_rx_queues failed\n");
-
-	printf("Initializing tx-threads...\n");
-	ret = init_tx_threads();
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "init_tx_threads failed\n");
-
-	printf("Initializing rings...\n");
-	ret = init_rx_rings();
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "init_rx_rings failed\n");
-
-	nb_ports = rte_eth_dev_count();
-
-	if (check_port_config() < 0)
-		rte_exit(EXIT_FAILURE, "check_port_config failed\n");
-
-	nb_lcores = rte_lcore_count();
-
-	/* initialize all ports */
-	RTE_ETH_FOREACH_DEV(portid) {
-		struct rte_eth_conf local_port_conf = port_conf;
-
-		/* skip ports that are not enabled */
-		if ((enabled_port_mask & (1 << portid)) == 0) {
-			printf("\nSkipping disabled port %d\n", portid);
-			continue;
-		}
-
-		/* init port */
-		printf("Initializing port %d ... ", portid);
-		fflush(stdout);
-
-		nb_rx_queue = get_port_n_rx_queues(portid);
-		n_tx_queue = nb_lcores;
-		if (n_tx_queue > MAX_TX_QUEUE_PER_PORT)
-			n_tx_queue = MAX_TX_QUEUE_PER_PORT;
-		printf("Creating queues: nb_rxq=%d nb_txq=%u... ",
-			nb_rx_queue, (unsigned)n_tx_queue);
-		rte_eth_dev_info_get(portid, &dev_info);
-		if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-			local_port_conf.txmode.offloads |=
-				DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-		ret = rte_eth_dev_configure(portid, nb_rx_queue,
-					(uint16_t)n_tx_queue, &local_port_conf);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "Cannot configure device: err=%d, port=%d\n",
-				ret, portid);
-
-		ret = rte_eth_dev_adjust_nb_rx_tx_desc(portid, &nb_rxd,
-						       &nb_txd);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE,
-				 "rte_eth_dev_adjust_nb_rx_tx_desc: err=%d, port=%d\n",
-				 ret, portid);
-
-		rte_eth_macaddr_get(portid, &ports_eth_addr[portid]);
-		print_ethaddr(" Address:", &ports_eth_addr[portid]);
-		printf(", ");
-		print_ethaddr("Destination:",
-			(const struct ether_addr *)&dest_eth_addr[portid]);
-		printf(", ");
-
-		/*
-		 * prepare src MACs for each port.
-		 */
-		ether_addr_copy(&ports_eth_addr[portid],
-			(struct ether_addr *)(val_eth + portid) + 1);
-
-		/* init memory */
-		ret = init_mem(NB_MBUF);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "init_mem failed\n");
-
-		/* init one TX queue per couple (lcore,port) */
-		queueid = 0;
-		for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-			if (rte_lcore_is_enabled(lcore_id) == 0)
-				continue;
-
-			if (numa_on)
-				socketid = (uint8_t)rte_lcore_to_socket_id(lcore_id);
-			else
-				socketid = 0;
-
-			printf("txq=%u,%d,%d ", lcore_id, queueid, socketid);
-			fflush(stdout);
-
-			txconf = &dev_info.default_txconf;
-			txconf->txq_flags = ETH_TXQ_FLAGS_IGNORE;
-			txconf->offloads = local_port_conf.txmode.offloads;
-			ret = rte_eth_tx_queue_setup(portid, queueid, nb_txd,
-						     socketid, txconf);
-			if (ret < 0)
-				rte_exit(EXIT_FAILURE, "rte_eth_tx_queue_setup: err=%d, "
-					"port=%d\n", ret, portid);
-
-			tx_thread[lcore_id].tx_queue_id[portid] = queueid;
-			queueid++;
-		}
-		printf("\n");
-	}
-
-	for (i = 0; i < n_rx_thread; i++) {
-		lcore_id = rx_thread[i].conf.lcore_id;
-
-		if (rte_lcore_is_enabled(lcore_id) == 0) {
-			rte_exit(EXIT_FAILURE,
-					"Cannot start Rx thread on lcore %u: lcore disabled\n",
-					lcore_id
-				);
-		}
-
-		printf("\nInitializing rx queues for Rx thread %d on lcore %u ... ",
-				i, lcore_id);
-		fflush(stdout);
-
-		/* init RX queues */
-		for (queue = 0; queue < rx_thread[i].n_rx_queue; ++queue) {
-			struct rte_eth_dev *dev;
-			struct rte_eth_conf *conf;
-			struct rte_eth_rxconf rxq_conf;
-
-			portid = rx_thread[i].rx_queue_list[queue].port_id;
-			queueid = rx_thread[i].rx_queue_list[queue].queue_id;
-			dev = &rte_eth_devices[portid];
-			conf = &dev->data->dev_conf;
-
-			if (numa_on)
-				socketid = (uint8_t)rte_lcore_to_socket_id(lcore_id);
-			else
-				socketid = 0;
-
-			printf("rxq=%d,%d,%d ", portid, queueid, socketid);
-			fflush(stdout);
-
-			rte_eth_dev_info_get(portid, &dev_info);
-			rxq_conf = dev_info.default_rxconf;
-			rxq_conf.offloads = conf->rxmode.offloads;
-			ret = rte_eth_rx_queue_setup(portid, queueid, nb_rxd,
-					socketid,
-					&rxq_conf,
-					pktmbuf_pool[socketid]);
-			if (ret < 0)
-				rte_exit(EXIT_FAILURE, "rte_eth_rx_queue_setup: err=%d, "
-						"port=%d\n", ret, portid);
-		}
-	}
-
-	printf("\n");
-
-	/* start ports */
-	RTE_ETH_FOREACH_DEV(portid) {
-		if ((enabled_port_mask & (1 << portid)) == 0)
-			continue;
-
-		/* Start device */
-		ret = rte_eth_dev_start(portid);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "rte_eth_dev_start: err=%d, port=%d\n",
-				ret, portid);
-
-		/*
-		 * If enabled, put device in promiscuous mode.
-		 * This allows IO forwarding mode to forward packets
-		 * to itself through 2 cross-connected  ports of the
-		 * target machine.
-		 */
-		if (promiscuous_on)
-			rte_eth_promiscuous_enable(portid);
-	}
-
-	for (i = 0; i < n_rx_thread; i++) {
-		lcore_id = rx_thread[i].conf.lcore_id;
-		if (rte_lcore_is_enabled(lcore_id) == 0)
-			continue;
-
-		/* check if hw packet type is supported */
-		for (queue = 0; queue < rx_thread[i].n_rx_queue; ++queue) {
-			portid = rx_thread[i].rx_queue_list[queue].port_id;
-			queueid = rx_thread[i].rx_queue_list[queue].queue_id;
-
-			if (parse_ptype_on) {
-				if (!rte_eth_add_rx_callback(portid, queueid,
-						cb_parse_ptype, NULL))
-					rte_exit(EXIT_FAILURE,
-						"Failed to add rx callback: "
-						"port=%d\n", portid);
-			} else if (!check_ptype(portid))
-				rte_exit(EXIT_FAILURE,
-					"Port %d cannot parse packet type.\n\n"
-					"Please add --parse-ptype to use sw "
-					"packet type analyzer.\n\n",
-					portid);
-		}
-	}
-
-	check_all_ports_link_status(enabled_port_mask);
-
-	if (lthreads_on) {
-		printf("Starting L-Threading Model\n");
-
-#if (APP_CPU_LOAD > 0)
-		if (cpu_load_lcore_id > 0)
-			/* Use one lcore for cpu load collector */
-			nb_lcores--;
-#endif
-
-		lthread_num_schedulers_set(nb_lcores);
-		rte_eal_mp_remote_launch(sched_spawner, NULL, SKIP_MASTER);
-		lthread_master_spawner(NULL);
-
-	} else {
-		printf("Starting P-Threading Model\n");
-		/* launch per-lcore init on every lcore */
-		rte_eal_mp_remote_launch(pthread_run, NULL, CALL_MASTER);
-		RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-			if (rte_eal_wait_lcore(lcore_id) < 0)
-				return -1;
-		}
-	}
-
-	return 0;
-}
diff --git a/examples/performance-thread/l3fwd-thread/test.sh b/examples/performance-thread/l3fwd-thread/test.sh
deleted file mode 100755
index b7718b6..0000000
--- a/examples/performance-thread/l3fwd-thread/test.sh
+++ /dev/null
@@ -1,149 +0,0 @@
-#!/bin/bash
-
-case "$1" in
-
-	######################
-	# 1 L-core per pcore #
-	######################
-
-	"1.1")
-		echo "1.1 1 L-core per pcore (N=2)"
-
-		./build/l3fwd-thread -c ff -n 2 -- -P -p 3 \
-				--enable-jumbo --max-pkt-len 1500  \
-				--rx="(0,0,0,0)(1,0,0,0)"          \
-				--tx="(1,0)"                       \
-				--stat-lcore 2                     \
-				--no-lthread
-
-		;;
-
-	"1.2")
-		echo "1.2 1 L-core per pcore (N=4)"
-
-		./build/l3fwd-thread -c ff -n 2 -- -P -p 3 \
-				--enable-jumbo --max-pkt-len 1500  \
-				--rx="(0,0,0,0)(1,0,1,1)"          \
-				--tx="(2,0)(3,1)"                  \
-				--stat-lcore 4                     \
-				--no-lthread
-		;;
-
-	"1.3")
-		echo "1.3 1 L-core per pcore (N=8)"
-
-		./build/l3fwd-thread -c 1ff -n 2 -- -P -p 3                          \
-				--enable-jumbo --max-pkt-len 1500                            \
-				--rx="(0,0,0,0)(0,1,1,1)(1,0,2,2)(1,1,3,3)"                  \
-				--tx="(4,0)(5,1)(6,2)(7,3)"                                  \
-				--stat-lcore 8                                               \
-				--no-lthread
-		;;
-
-	"1.4")
-		echo "1.3 1 L-core per pcore (N=16)"
-
-		./build/l3fwd-thread -c 3ffff -n 2 -- -P -p 3                          \
-				--enable-jumbo --max-pkt-len 1500                              \
-				--rx="(0,0,0,0)(0,1,1,1)(0,2,2,2)(0,3,3,3)(1,0,4,4)(1,1,5,5)(1,2,6,6)(1,3,7,7)" \
-				--tx="(8,0)(9,1)(10,2)(11,3)(12,4)(13,5)(14,6)(15,7)"          \
-				--stat-lcore 16                                                \
-				--no-lthread
-		;;
-
-
-	######################
-	# N L-core per pcore #
-	######################
-
-	"2.1")
-		echo "2.1 N L-core per pcore (N=2)"
-
-		./build/l3fwd-thread -c ff -n 2 --lcores="2,(0-1)@0" -- -P -p 3 \
-				--enable-jumbo --max-pkt-len 1500                       \
-				--rx="(0,0,0,0)(1,0,0,0)"                               \
-				--tx="(1,0)"                                            \
-				--stat-lcore 2                                          \
-				--no-lthread
-
-		;;
-
-	"2.2")
-		echo "2.2 N L-core per pcore (N=4)"
-
-		./build/l3fwd-thread -c ff -n 2 --lcores="(0-3)@0,4" -- -P -p 3 \
-				--enable-jumbo --max-pkt-len 1500  \
-				--rx="(0,0,0,0)(1,0,1,1)"          \
-				--tx="(2,0)(3,1)"                  \
-				--stat-lcore 4                     \
-				--no-lthread
-		;;
-
-	"2.3")
-		echo "2.3 N L-core per pcore (N=8)"
-
-		./build/l3fwd-thread -c 3ffff -n 2 --lcores="(0-7)@0,8" -- -P -p 3     \
-				--enable-jumbo --max-pkt-len 1500                              \
-				--rx="(0,0,0,0)(0,1,1,1)(1,0,2,2)(1,1,3,3)"                    \
-				--tx="(4,0)(5,1)(6,2)(7,3)"                                    \
-				--stat-lcore 8                                                 \
-				--no-lthread
-		;;
-
-	"2.4")
-		echo "2.3 N L-core per pcore (N=16)"
-
-		./build/l3fwd-thread -c 3ffff -n 2 --lcores="(0-15)@0,16" -- -P -p 3   \
-				--enable-jumbo --max-pkt-len 1500                              \
-				--rx="(0,0,0,0)(0,1,1,1)(0,2,2,2)(0,3,3,3)(1,0,4,4)(1,1,5,5)(1,2,6,6)(1,3,7,7)" \
-				--tx="(8,0)(9,1)(10,2)(11,3)(12,4)(13,5)(14,6)(15,7)"          \
-				--stat-lcore 16                                                \
-				--no-lthread
-		;;
-
-
-	#########################
-	# N L-threads per pcore #
-	#########################
-
-	"3.1")
-		echo "3.1 N L-threads per pcore (N=2)"
-
-		./build/l3fwd-thread -c ff -n 2 -- -P -p 3  \
-				--enable-jumbo --max-pkt-len 1500   \
-				--rx="(0,0,0,0)(1,0,0,0)"           \
-				--tx="(0,0)"                        \
-				--stat-lcore 1
-		;;
-
-	"3.2")
-		echo "3.2 N L-threads per pcore (N=4)"
-
-		./build/l3fwd-thread -c ff -n 2 -- -P -p 3  \
-				--enable-jumbo --max-pkt-len 1500   \
-				--rx="(0,0,0,0)(1,0,0,1)"           \
-				--tx="(0,0)(0,1)"                   \
-				--stat-lcore 1
-		;;
-
-	"3.3")
-		echo "3.2 N L-threads per pcore (N=8)"
-
-		./build/l3fwd-thread -c ff -n 2 -- -P -p 3                             \
-				--enable-jumbo --max-pkt-len 1500                              \
-				--rx="(0,0,0,0)(0,1,0,1)(1,0,0,2)(1,1,0,3)"                    \
-				--tx="(0,0)(0,1)(0,2)(0,3)"                                    \
-				--stat-lcore 1
-		;;
-
-	"3.4")
-		echo "3.2 N L-threads per pcore (N=16)"
-
-		./build/l3fwd-thread -c ff -n 2 -- -P -p 3                             \
-				--enable-jumbo --max-pkt-len 1500                              \
-				--rx="(0,0,0,0)(0,1,0,1)(0,2,0,2)(0,0,0,3)(1,0,0,4)(1,1,0,5)(1,2,0,6)(1,3,0,7)" \
-				--tx="(0,0)(0,1)(0,2)(0,3)(0,4)(0,5)(0,6)(0,7)"                \
-				--stat-lcore 1
-		;;
-
-esac
diff --git a/examples/performance-thread/pthread_shim/Makefile b/examples/performance-thread/pthread_shim/Makefile
deleted file mode 100644
index a6d276a..0000000
--- a/examples/performance-thread/pthread_shim/Makefile
+++ /dev/null
@@ -1,32 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2015 Intel Corporation
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-# binary name
-APP = lthread_pthread_shim
-
-# all source are stored in SRCS-y
-SRCS-y := main.c  pthread_shim.c
-INCLUDES := -I$(RTE_SDK)/$(RTE_TARGET)/include -I$(SRCDIR)
-include $(RTE_SDK)/examples/performance-thread/common/common.mk
-
-CFLAGS += -g -O3 $(USER_FLAGS) $(INCLUDES)
-CFLAGS += $(WERROR_FLAGS)
-
-LDFLAGS += -lpthread
-
-# workaround for a gcc bug with noreturn attribute
-# http://gcc.gnu.org/bugzilla/show_bug.cgi?id=12603
-ifeq ($(CONFIG_RTE_TOOLCHAIN_GCC),y)
-CFLAGS_main.o += -Wno-return-type
-endif
-
-include $(RTE_SDK)/mk/rte.extapp.mk
diff --git a/examples/performance-thread/pthread_shim/main.c b/examples/performance-thread/pthread_shim/main.c
deleted file mode 100644
index 7d0d581..0000000
--- a/examples/performance-thread/pthread_shim/main.c
+++ /dev/null
@@ -1,263 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2015 Intel Corporation
- */
-
-#define _GNU_SOURCE
-#include <stdio.h>
-#include <stdlib.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <sys/types.h>
-#include <string.h>
-#include <sys/queue.h>
-#include <stdarg.h>
-#include <errno.h>
-#include <getopt.h>
-#include <unistd.h>
-#include <sched.h>
-#include <pthread.h>
-
-#include <rte_common.h>
-#include <rte_lcore.h>
-#include <rte_per_lcore.h>
-#include <rte_timer.h>
-
-#include "lthread_api.h"
-#include "lthread_diag_api.h"
-#include "pthread_shim.h"
-
-#define DEBUG_APP 0
-#define HELLOW_WORLD_MAX_LTHREADS 10
-
-#ifndef __GLIBC__ /* sched_getcpu() is glibc-specific */
-#define sched_getcpu() rte_lcore_id()
-#endif
-
-__thread int print_count;
-__thread pthread_mutex_t print_lock;
-
-__thread pthread_mutex_t exit_lock;
-__thread pthread_cond_t exit_cond;
-
-/*
- * A simple thread that demonstrates use of a mutex, a condition
- * variable, thread local storage, explicit yield, and thread exit.
- *
- * The thread uses a mutex to protect a shared counter which is incremented
- * and then it waits on condition variable before exiting.
- *
- * The thread argument is stored in and retrieved from TLS, using
- * the pthread key create, get and set specific APIs.
- *
- * The thread yields while holding the mutex, to provide opportunity
- * for other threads to contend.
- *
- * All of the pthread API functions used by this thread are actually
- * resolved to corresponding lthread functions by the pthread shim
- * implemented in pthread_shim.c
- */
-void *helloworld_pthread(void *arg);
-void *helloworld_pthread(void *arg)
-{
-	pthread_key_t key;
-
-	/* create a key for TLS */
-	pthread_key_create(&key, NULL);
-
-	/* store the arg in TLS */
-	pthread_setspecific(key, arg);
-
-	/* grab lock and increment shared counter */
-	pthread_mutex_lock(&print_lock);
-	print_count++;
-
-	/* yield thread to give opportunity for lock contention */
-	pthread_yield();
-
-	/* retrieve arg from TLS */
-	uint64_t thread_no = (uint64_t) pthread_getspecific(key);
-
-	printf("Hello - lcore = %d count = %d thread_no = %d thread_id = %p\n",
-			sched_getcpu(),
-			print_count,
-			(int) thread_no,
-			(void *)pthread_self());
-
-	/* release the lock */
-	pthread_mutex_unlock(&print_lock);
-
-	/*
-	 * wait on condition variable
-	 * before exiting
-	 */
-	pthread_mutex_lock(&exit_lock);
-	pthread_cond_wait(&exit_cond, &exit_lock);
-	pthread_mutex_unlock(&exit_lock);
-
-	/* exit */
-	pthread_exit((void *) thread_no);
-}
-
-
-/*
- * This is the initial thread
- *
- * It demonstrates pthread, mutex and condition variable creation,
- * broadcast and pthread join APIs.
- *
- * This initial thread must always start life as an lthread.
- *
- * This thread creates many more threads then waits a short time
- * before signalling them to exit using a broadcast.
- *
- * All of the pthread API functions used by this thread are actually
- * resolved to corresponding lthread functions by the pthread shim
- * implemented in pthread_shim.c
- *
- * After all threads have finished the lthread scheduler is shutdown
- * and normal pthread operation is restored
- */
-__thread pthread_t tid[HELLOW_WORLD_MAX_LTHREADS];
-
-static void *initial_lthread(void *args __attribute__((unused)))
-{
-	int lcore = (int) rte_lcore_id();
-	/*
-	 *
-	 * We can now enable pthread API override
-	 * and start to use the pthread APIs
-	 */
-	pthread_override_set(1);
-
-	uint64_t i;
-	int ret;
-
-	/* initialize mutex for shared counter */
-	print_count = 0;
-	pthread_mutex_init(&print_lock, NULL);
-
-	/* initialize mutex and condition variable controlling thread exit */
-	pthread_mutex_init(&exit_lock, NULL);
-	pthread_cond_init(&exit_cond, NULL);
-
-	/* spawn a number of threads */
-	for (i = 0; i < HELLOW_WORLD_MAX_LTHREADS; i++) {
-
-		/*
-		 * Not strictly necessary but
-		 * for the sake of this example
-		 * use an attribute to pass the desired lcore
-		 */
-		pthread_attr_t attr;
-		rte_cpuset_t cpuset;
-
-		CPU_ZERO(&cpuset);
-		CPU_SET(lcore, &cpuset);
-		pthread_attr_init(&attr);
-		pthread_attr_setaffinity_np(&attr, sizeof(rte_cpuset_t), &cpuset);
-
-		/* create the thread */
-		ret = pthread_create(&tid[i], &attr,
-				helloworld_pthread, (void *) i);
-		if (ret != 0)
-			rte_exit(EXIT_FAILURE, "Cannot create helloworld thread\n");
-	}
-
-	/* wait for 1s to allow threads
-	 * to block on the condition variable
-	 * N.B. nanosleep() is resolved to lthread_sleep()
-	 * by the shim.
-	 */
-	struct timespec time;
-
-	time.tv_sec = 1;
-	time.tv_nsec = 0;
-	nanosleep(&time, NULL);
-
-	/* wake up all the threads */
-	pthread_cond_broadcast(&exit_cond);
-
-	/* wait for them to finish */
-	for (i = 0; i < HELLOW_WORLD_MAX_LTHREADS; i++) {
-
-		uint64_t thread_no;
-
-		pthread_join(tid[i], (void *) &thread_no);
-		if (thread_no != i)
-			printf("error on thread exit\n");
-	}
-
-	pthread_cond_destroy(&exit_cond);
-	pthread_mutex_destroy(&print_lock);
-	pthread_mutex_destroy(&exit_lock);
-
-	/* shutdown the lthread scheduler */
-	lthread_scheduler_shutdown(rte_lcore_id());
-	lthread_detach();
-	return NULL;
-}
-
-
-
-/* This thread creates a single initial lthread
- * and then runs the scheduler
- * An instance of this thread is created on each thread
- * in the core mask
- */
-static int
-lthread_scheduler(void *args __attribute__((unused)))
-{
-	/* create initial thread  */
-	struct lthread *lt;
-
-	lthread_create(&lt, -1, initial_lthread, (void *) NULL);
-
-	/* run the lthread scheduler */
-	lthread_run();
-
-	/* restore genuine pthread operation */
-	pthread_override_set(0);
-	return 0;
-}
-
-int main(int argc, char **argv)
-{
-	int num_sched = 0;
-
-	/* basic DPDK initialization is all that is necessary to run lthreads*/
-	int ret = rte_eal_init(argc, argv);
-
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid EAL parameters\n");
-
-	/* enable timer subsystem */
-	rte_timer_subsystem_init();
-
-#if DEBUG_APP
-	lthread_diagnostic_set_mask(LT_DIAG_ALL);
-#endif
-
-	/* create a scheduler on every core in the core mask
-	 * and launch an initial lthread that will spawn many more.
-	 */
-	unsigned lcore_id;
-
-	for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-		if (rte_lcore_is_enabled(lcore_id))
-			num_sched++;
-	}
-
-	/* set the number of schedulers, this forces all schedulers synchronize
-	 * before entering their main loop
-	 */
-	lthread_num_schedulers_set(num_sched);
-
-	/* launch all threads */
-	rte_eal_mp_remote_launch(lthread_scheduler, (void *)NULL, CALL_MASTER);
-
-	/* wait for threads to stop */
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		rte_eal_wait_lcore(lcore_id);
-	}
-	return 0;
-}
diff --git a/examples/performance-thread/pthread_shim/pthread_shim.c b/examples/performance-thread/pthread_shim/pthread_shim.c
deleted file mode 100644
index 53f1243..0000000
--- a/examples/performance-thread/pthread_shim/pthread_shim.c
+++ /dev/null
@@ -1,714 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2015 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <sys/types.h>
-#include <errno.h>
-#define __USE_GNU
-#include <sched.h>
-#include <dlfcn.h>
-
-#include <rte_log.h>
-
-#include "lthread_api.h"
-#include "pthread_shim.h"
-
-#define RTE_LOGTYPE_PTHREAD_SHIM RTE_LOGTYPE_USER3
-
-#define POSIX_ERRNO(x)  (x)
-
-/* some releases of FreeBSD 10, e.g. 10.0, don't have CPU_COUNT macro */
-#ifndef CPU_COUNT
-#define CPU_COUNT(x) __cpu_count(x)
-
-static inline unsigned int
-__cpu_count(const rte_cpuset_t *cpuset)
-{
-	unsigned int i, count = 0;
-	for (i = 0; i < RTE_MAX_LCORE; i++)
-		if (CPU_ISSET(i, cpuset))
-			count++;
-	return count;
-}
-#endif
-
-/*
- * this flag determines at run time if we override pthread
- * calls and map then to equivalent lthread calls
- * or of we call the standard pthread function
- */
-static __thread int override;
-
-
-/*
- * this structures contains function pointers that will be
- * initialised to the loaded address of the real
- * pthread library API functions
- */
-struct pthread_lib_funcs {
-int (*f_pthread_barrier_destroy)
-	(pthread_barrier_t *);
-int (*f_pthread_barrier_init)
-	(pthread_barrier_t *, const pthread_barrierattr_t *, unsigned);
-int (*f_pthread_barrier_wait)
-	(pthread_barrier_t *);
-int (*f_pthread_cond_broadcast)
-	(pthread_cond_t *);
-int (*f_pthread_cond_destroy)
-	(pthread_cond_t *);
-int (*f_pthread_cond_init)
-	(pthread_cond_t *, const pthread_condattr_t *);
-int (*f_pthread_cond_signal)
-	(pthread_cond_t *);
-int (*f_pthread_cond_timedwait)
-	(pthread_cond_t *, pthread_mutex_t *, const struct timespec *);
-int (*f_pthread_cond_wait)
-	(pthread_cond_t *, pthread_mutex_t *);
-int (*f_pthread_create)
-	(pthread_t *, const pthread_attr_t *, void *(*)(void *), void *);
-int (*f_pthread_detach)
-	(pthread_t);
-int (*f_pthread_equal)
-	(pthread_t, pthread_t);
-void (*f_pthread_exit)
-	(void *);
-void * (*f_pthread_getspecific)
-	(pthread_key_t);
-int (*f_pthread_getcpuclockid)
-	(pthread_t, clockid_t *);
-int (*f_pthread_join)
-	(pthread_t, void **);
-int (*f_pthread_key_create)
-	(pthread_key_t *, void (*) (void *));
-int (*f_pthread_key_delete)
-	(pthread_key_t);
-int (*f_pthread_mutex_destroy)
-	(pthread_mutex_t *__mutex);
-int (*f_pthread_mutex_init)
-	(pthread_mutex_t *__mutex, const pthread_mutexattr_t *);
-int (*f_pthread_mutex_lock)
-	(pthread_mutex_t *__mutex);
-int (*f_pthread_mutex_trylock)
-	(pthread_mutex_t *__mutex);
-int (*f_pthread_mutex_timedlock)
-	(pthread_mutex_t *__mutex, const struct timespec *);
-int (*f_pthread_mutex_unlock)
-	(pthread_mutex_t *__mutex);
-int (*f_pthread_once)
-	(pthread_once_t *, void (*) (void));
-int (*f_pthread_rwlock_destroy)
-	(pthread_rwlock_t *__rwlock);
-int (*f_pthread_rwlock_init)
-	(pthread_rwlock_t *__rwlock, const pthread_rwlockattr_t *);
-int (*f_pthread_rwlock_rdlock)
-	(pthread_rwlock_t *__rwlock);
-int (*f_pthread_rwlock_timedrdlock)
-	(pthread_rwlock_t *__rwlock, const struct timespec *);
-int (*f_pthread_rwlock_timedwrlock)
-	(pthread_rwlock_t *__rwlock, const struct timespec *);
-int (*f_pthread_rwlock_tryrdlock)
-	(pthread_rwlock_t *__rwlock);
-int (*f_pthread_rwlock_trywrlock)
-	(pthread_rwlock_t *__rwlock);
-int (*f_pthread_rwlock_unlock)
-	(pthread_rwlock_t *__rwlock);
-int (*f_pthread_rwlock_wrlock)
-	(pthread_rwlock_t *__rwlock);
-pthread_t (*f_pthread_self)
-	(void);
-int (*f_pthread_setspecific)
-	(pthread_key_t, const void *);
-int (*f_pthread_spin_init)
-	(pthread_spinlock_t *__spin, int);
-int (*f_pthread_spin_destroy)
-	(pthread_spinlock_t *__spin);
-int (*f_pthread_spin_lock)
-	(pthread_spinlock_t *__spin);
-int (*f_pthread_spin_trylock)
-	(pthread_spinlock_t *__spin);
-int (*f_pthread_spin_unlock)
-	(pthread_spinlock_t *__spin);
-int (*f_pthread_cancel)
-	(pthread_t);
-int (*f_pthread_setcancelstate)
-	(int, int *);
-int (*f_pthread_setcanceltype)
-	(int, int *);
-void (*f_pthread_testcancel)
-	(void);
-int (*f_pthread_getschedparam)
-	(pthread_t pthread, int *, struct sched_param *);
-int (*f_pthread_setschedparam)
-	(pthread_t, int, const struct sched_param *);
-int (*f_pthread_yield)
-	(void);
-int (*f_pthread_setaffinity_np)
-	(pthread_t thread, size_t cpusetsize, const rte_cpuset_t *cpuset);
-int (*f_nanosleep)
-	(const struct timespec *req, struct timespec *rem);
-} _sys_pthread_funcs = {
-	.f_pthread_barrier_destroy = NULL,
-};
-
-
-/*
- * this macro obtains the loaded address of a library function
- * and saves it.
- */
-static void *__libc_dl_handle = RTLD_NEXT;
-
-#define get_addr_of_loaded_symbol(name) do {				\
-	char *error_str;						\
-	_sys_pthread_funcs.f_##name = dlsym(__libc_dl_handle, (#name));	\
-	error_str = dlerror();						\
-	if (error_str != NULL) {					\
-		fprintf(stderr, "%s\n", error_str);			\
-	}								\
-} while (0)
-
-
-/*
- * The constructor function initialises the
- * function pointers for pthread library functions
- */
-RTE_INIT(pthread_intercept_ctor)
-{
-	override = 0;
-	/*
-	 * Get the original functions
-	 */
-	get_addr_of_loaded_symbol(pthread_barrier_destroy);
-	get_addr_of_loaded_symbol(pthread_barrier_init);
-	get_addr_of_loaded_symbol(pthread_barrier_wait);
-	get_addr_of_loaded_symbol(pthread_cond_broadcast);
-	get_addr_of_loaded_symbol(pthread_cond_destroy);
-	get_addr_of_loaded_symbol(pthread_cond_init);
-	get_addr_of_loaded_symbol(pthread_cond_signal);
-	get_addr_of_loaded_symbol(pthread_cond_timedwait);
-	get_addr_of_loaded_symbol(pthread_cond_wait);
-	get_addr_of_loaded_symbol(pthread_create);
-	get_addr_of_loaded_symbol(pthread_detach);
-	get_addr_of_loaded_symbol(pthread_equal);
-	get_addr_of_loaded_symbol(pthread_exit);
-	get_addr_of_loaded_symbol(pthread_getspecific);
-	get_addr_of_loaded_symbol(pthread_getcpuclockid);
-	get_addr_of_loaded_symbol(pthread_join);
-	get_addr_of_loaded_symbol(pthread_key_create);
-	get_addr_of_loaded_symbol(pthread_key_delete);
-	get_addr_of_loaded_symbol(pthread_mutex_destroy);
-	get_addr_of_loaded_symbol(pthread_mutex_init);
-	get_addr_of_loaded_symbol(pthread_mutex_lock);
-	get_addr_of_loaded_symbol(pthread_mutex_trylock);
-	get_addr_of_loaded_symbol(pthread_mutex_timedlock);
-	get_addr_of_loaded_symbol(pthread_mutex_unlock);
-	get_addr_of_loaded_symbol(pthread_once);
-	get_addr_of_loaded_symbol(pthread_rwlock_destroy);
-	get_addr_of_loaded_symbol(pthread_rwlock_init);
-	get_addr_of_loaded_symbol(pthread_rwlock_rdlock);
-	get_addr_of_loaded_symbol(pthread_rwlock_timedrdlock);
-	get_addr_of_loaded_symbol(pthread_rwlock_timedwrlock);
-	get_addr_of_loaded_symbol(pthread_rwlock_tryrdlock);
-	get_addr_of_loaded_symbol(pthread_rwlock_trywrlock);
-	get_addr_of_loaded_symbol(pthread_rwlock_unlock);
-	get_addr_of_loaded_symbol(pthread_rwlock_wrlock);
-	get_addr_of_loaded_symbol(pthread_self);
-	get_addr_of_loaded_symbol(pthread_setspecific);
-	get_addr_of_loaded_symbol(pthread_spin_init);
-	get_addr_of_loaded_symbol(pthread_spin_destroy);
-	get_addr_of_loaded_symbol(pthread_spin_lock);
-	get_addr_of_loaded_symbol(pthread_spin_trylock);
-	get_addr_of_loaded_symbol(pthread_spin_unlock);
-	get_addr_of_loaded_symbol(pthread_cancel);
-	get_addr_of_loaded_symbol(pthread_setcancelstate);
-	get_addr_of_loaded_symbol(pthread_setcanceltype);
-	get_addr_of_loaded_symbol(pthread_testcancel);
-	get_addr_of_loaded_symbol(pthread_getschedparam);
-	get_addr_of_loaded_symbol(pthread_setschedparam);
-	get_addr_of_loaded_symbol(pthread_yield);
-	get_addr_of_loaded_symbol(pthread_setaffinity_np);
-	get_addr_of_loaded_symbol(nanosleep);
-}
-
-
-/*
- * Enable/Disable pthread override
- * state
- *  0 disable
- *  1 enable
- */
-void pthread_override_set(int state)
-{
-	override = state;
-}
-
-
-/*
- * Return pthread override state
- * return
- *  0 disable
- *  1 enable
- */
-int pthread_override_get(void)
-{
-	return override;
-}
-
-/*
- * This macro is used to catch and log
- * invocation of stubs for unimplemented pthread
- * API functions.
- */
-#define NOT_IMPLEMENTED do {				\
-	if (override) {					\
-		RTE_LOG(WARNING,			\
-			PTHREAD_SHIM,			\
-			"WARNING %s NOT IMPLEMENTED\n",	\
-			__func__);			\
-	}						\
-} while (0)
-
-/*
- * pthread API override functions follow
- * Note in this example code only a subset of functions are
- * implemented.
- *
- * The stub functions provided will issue a warning log
- * message if an unimplemented function is invoked
- *
- */
-
-int pthread_barrier_destroy(pthread_barrier_t *a)
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_barrier_destroy(a);
-}
-
-int
-pthread_barrier_init(pthread_barrier_t *a,
-		     const pthread_barrierattr_t *b, unsigned c)
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_barrier_init(a, b, c);
-}
-
-int pthread_barrier_wait(pthread_barrier_t *a)
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_barrier_wait(a);
-}
-
-int pthread_cond_broadcast(pthread_cond_t *cond)
-{
-	if (override) {
-
-		lthread_cond_broadcast(*(struct lthread_cond **)cond);
-		return 0;
-	}
-	return _sys_pthread_funcs.f_pthread_cond_broadcast(cond);
-}
-
-int pthread_mutex_destroy(pthread_mutex_t *mutex)
-{
-	if (override)
-		return lthread_mutex_destroy(*(struct lthread_mutex **)mutex);
-	return _sys_pthread_funcs.f_pthread_mutex_destroy(mutex);
-}
-
-int pthread_cond_destroy(pthread_cond_t *cond)
-{
-	if (override)
-		return lthread_cond_destroy(*(struct lthread_cond **)cond);
-	return _sys_pthread_funcs.f_pthread_cond_destroy(cond);
-}
-
-int pthread_cond_init(pthread_cond_t *cond, const pthread_condattr_t *attr)
-{
-	if (override)
-		return lthread_cond_init(NULL,
-				(struct lthread_cond **)cond,
-				(const struct lthread_condattr *) attr);
-	return _sys_pthread_funcs.f_pthread_cond_init(cond, attr);
-}
-
-int pthread_cond_signal(pthread_cond_t *cond)
-{
-	if (override) {
-		lthread_cond_signal(*(struct lthread_cond **)cond);
-		return 0;
-	}
-	return _sys_pthread_funcs.f_pthread_cond_signal(cond);
-}
-
-int
-pthread_cond_timedwait(pthread_cond_t *__restrict cond,
-		       pthread_mutex_t *__restrict mutex,
-		       const struct timespec *__restrict time)
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_cond_timedwait(cond, mutex, time);
-}
-
-int pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex)
-{
-	if (override) {
-		pthread_mutex_unlock(mutex);
-		int rv = lthread_cond_wait(*(struct lthread_cond **)cond, 0);
-
-		pthread_mutex_lock(mutex);
-		return rv;
-	}
-	return _sys_pthread_funcs.f_pthread_cond_wait(cond, mutex);
-}
-
-int
-pthread_create(pthread_t *__restrict tid,
-		const pthread_attr_t *__restrict attr,
-		lthread_func_t func,
-	       void *__restrict arg)
-{
-	if (override) {
-		int lcore = -1;
-
-		if (attr != NULL) {
-			/* determine CPU being requested */
-			rte_cpuset_t cpuset;
-
-			CPU_ZERO(&cpuset);
-			pthread_attr_getaffinity_np(attr,
-						sizeof(rte_cpuset_t),
-						&cpuset);
-
-			if (CPU_COUNT(&cpuset) != 1)
-				return POSIX_ERRNO(EINVAL);
-
-			for (lcore = 0; lcore < LTHREAD_MAX_LCORES; lcore++) {
-				if (!CPU_ISSET(lcore, &cpuset))
-					continue;
-				break;
-			}
-		}
-		return lthread_create((struct lthread **)tid, lcore,
-				      func, arg);
-	}
-	return _sys_pthread_funcs.f_pthread_create(tid, attr, func, arg);
-}
-
-int pthread_detach(pthread_t tid)
-{
-	if (override) {
-		struct lthread *lt = (struct lthread *)tid;
-
-		if (lt == lthread_current()) {
-			lthread_detach();
-			return 0;
-		}
-		NOT_IMPLEMENTED;
-	}
-	return _sys_pthread_funcs.f_pthread_detach(tid);
-}
-
-int pthread_equal(pthread_t a, pthread_t b)
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_equal(a, b);
-}
-
-void pthread_exit_override(void *v)
-{
-	if (override) {
-		lthread_exit(v);
-		return;
-	}
-	_sys_pthread_funcs.f_pthread_exit(v);
-}
-
-void
-*pthread_getspecific(pthread_key_t key)
-{
-	if (override)
-		return lthread_getspecific((unsigned int) key);
-	return _sys_pthread_funcs.f_pthread_getspecific(key);
-}
-
-int pthread_getcpuclockid(pthread_t a, clockid_t *b)
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_getcpuclockid(a, b);
-}
-
-int pthread_join(pthread_t tid, void **val)
-{
-	if (override)
-		return lthread_join((struct lthread *)tid, val);
-	return _sys_pthread_funcs.f_pthread_join(tid, val);
-}
-
-int pthread_key_create(pthread_key_t *keyptr, void (*dtor) (void *))
-{
-	if (override)
-		return lthread_key_create((unsigned int *)keyptr, dtor);
-	return _sys_pthread_funcs.f_pthread_key_create(keyptr, dtor);
-}
-
-int pthread_key_delete(pthread_key_t key)
-{
-	if (override) {
-		lthread_key_delete((unsigned int) key);
-		return 0;
-	}
-	return _sys_pthread_funcs.f_pthread_key_delete(key);
-}
-
-
-int
-pthread_mutex_init(pthread_mutex_t *mutex, const pthread_mutexattr_t *attr)
-{
-	if (override)
-		return lthread_mutex_init(NULL,
-				(struct lthread_mutex **)mutex,
-				(const struct lthread_mutexattr *)attr);
-	return _sys_pthread_funcs.f_pthread_mutex_init(mutex, attr);
-}
-
-int pthread_mutex_lock(pthread_mutex_t *mutex)
-{
-	if (override)
-		return lthread_mutex_lock(*(struct lthread_mutex **)mutex);
-	return _sys_pthread_funcs.f_pthread_mutex_lock(mutex);
-}
-
-int pthread_mutex_trylock(pthread_mutex_t *mutex)
-{
-	if (override)
-		return lthread_mutex_trylock(*(struct lthread_mutex **)mutex);
-	return _sys_pthread_funcs.f_pthread_mutex_trylock(mutex);
-}
-
-int pthread_mutex_timedlock(pthread_mutex_t *mutex, const struct timespec *b)
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_mutex_timedlock(mutex, b);
-}
-
-int pthread_mutex_unlock(pthread_mutex_t *mutex)
-{
-	if (override)
-		return lthread_mutex_unlock(*(struct lthread_mutex **)mutex);
-	return _sys_pthread_funcs.f_pthread_mutex_unlock(mutex);
-}
-
-int pthread_once(pthread_once_t *a, void (b) (void))
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_once(a, b);
-}
-
-int pthread_rwlock_destroy(pthread_rwlock_t *a)
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_rwlock_destroy(a);
-}
-
-int pthread_rwlock_init(pthread_rwlock_t *a, const pthread_rwlockattr_t *b)
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_rwlock_init(a, b);
-}
-
-int pthread_rwlock_rdlock(pthread_rwlock_t *a)
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_rwlock_rdlock(a);
-}
-
-int pthread_rwlock_timedrdlock(pthread_rwlock_t *a, const struct timespec *b)
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_rwlock_timedrdlock(a, b);
-}
-
-int pthread_rwlock_timedwrlock(pthread_rwlock_t *a, const struct timespec *b)
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_rwlock_timedwrlock(a, b);
-}
-
-int pthread_rwlock_tryrdlock(pthread_rwlock_t *a)
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_rwlock_tryrdlock(a);
-}
-
-int pthread_rwlock_trywrlock(pthread_rwlock_t *a)
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_rwlock_trywrlock(a);
-}
-
-int pthread_rwlock_unlock(pthread_rwlock_t *a)
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_rwlock_unlock(a);
-}
-
-int pthread_rwlock_wrlock(pthread_rwlock_t *a)
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_rwlock_wrlock(a);
-}
-
-#ifdef RTE_EXEC_ENV_LINUXAPP
-int
-pthread_yield(void)
-{
-	if (override) {
-		lthread_yield();
-		return 0;
-	}
-	return _sys_pthread_funcs.f_pthread_yield();
-}
-#else
-void
-pthread_yield(void)
-{
-	if (override)
-		lthread_yield();
-	else
-		_sys_pthread_funcs.f_pthread_yield();
-}
-#endif
-
-pthread_t pthread_self(void)
-{
-	if (override)
-		return (pthread_t) lthread_current();
-	return _sys_pthread_funcs.f_pthread_self();
-}
-
-int pthread_setspecific(pthread_key_t key, const void *data)
-{
-	if (override) {
-		int rv =  lthread_setspecific((unsigned int)key, data);
-		return rv;
-	}
-	return _sys_pthread_funcs.f_pthread_setspecific(key, data);
-}
-
-int pthread_spin_init(pthread_spinlock_t *a, int b)
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_spin_init(a, b);
-}
-
-int pthread_spin_destroy(pthread_spinlock_t *a)
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_spin_destroy(a);
-}
-
-int pthread_spin_lock(pthread_spinlock_t *a)
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_spin_lock(a);
-}
-
-int pthread_spin_trylock(pthread_spinlock_t *a)
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_spin_trylock(a);
-}
-
-int pthread_spin_unlock(pthread_spinlock_t *a)
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_spin_unlock(a);
-}
-
-int pthread_cancel(pthread_t tid)
-{
-	if (override) {
-		lthread_cancel(*(struct lthread **)tid);
-		return 0;
-	}
-	return _sys_pthread_funcs.f_pthread_cancel(tid);
-}
-
-int pthread_setcancelstate(int a, int *b)
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_setcancelstate(a, b);
-}
-
-int pthread_setcanceltype(int a, int *b)
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_setcanceltype(a, b);
-}
-
-void pthread_testcancel(void)
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_testcancel();
-}
-
-
-int pthread_getschedparam(pthread_t tid, int *a, struct sched_param *b)
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_getschedparam(tid, a, b);
-}
-
-int pthread_setschedparam(pthread_t a, int b, const struct sched_param *c)
-{
-	NOT_IMPLEMENTED;
-	return _sys_pthread_funcs.f_pthread_setschedparam(a, b, c);
-}
-
-
-int nanosleep(const struct timespec *req, struct timespec *rem)
-{
-	if (override) {
-		uint64_t ns = req->tv_sec * 1000000000 + req->tv_nsec;
-
-		lthread_sleep(ns);
-		return 0;
-	}
-	return _sys_pthread_funcs.f_nanosleep(req, rem);
-}
-
-int
-pthread_setaffinity_np(pthread_t thread, size_t cpusetsize,
-		       const rte_cpuset_t *cpuset)
-{
-	if (override) {
-		/* we only allow affinity with a single CPU */
-		if (CPU_COUNT(cpuset) != 1)
-			return POSIX_ERRNO(EINVAL);
-
-		/* we only allow the current thread to sets its own affinity */
-		struct lthread *lt = (struct lthread *)thread;
-
-		if (lthread_current() != lt)
-			return POSIX_ERRNO(EINVAL);
-
-		/* determine the CPU being requested */
-		int i;
-
-		for (i = 0; i < LTHREAD_MAX_LCORES; i++) {
-			if (!CPU_ISSET(i, cpuset))
-				continue;
-			break;
-		}
-		/* check requested core is allowed */
-		if (i == LTHREAD_MAX_LCORES)
-			return POSIX_ERRNO(EINVAL);
-
-		/* finally we can set affinity to the requested lcore */
-		lthread_set_affinity(i);
-		return 0;
-	}
-	return _sys_pthread_funcs.f_pthread_setaffinity_np(thread, cpusetsize,
-							   cpuset);
-}
diff --git a/examples/performance-thread/pthread_shim/pthread_shim.h b/examples/performance-thread/pthread_shim/pthread_shim.h
deleted file mode 100644
index bba8ed0..0000000
--- a/examples/performance-thread/pthread_shim/pthread_shim.h
+++ /dev/null
@@ -1,85 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2015 Intel Corporation
- */
-
-#ifndef _PTHREAD_SHIM_H_
-#define _PTHREAD_SHIM_H_
-
-#include <rte_lcore.h>
-
-/*
- * This pthread shim is an example that demonstrates how legacy code
- * that makes use of POSIX pthread services can make use of lthreads
- * with reduced porting effort.
- *
- * N.B. The example is not a complete implementation, only a subset of
- * pthread APIs sufficient to demonstrate the principle of operation
- * are implemented.
- *
- * In general pthread attribute objects do not have equivalent functions
- * in lthreads, and are ignored.
- *
- * There is one exception and that is the use of attr to specify a
- * core affinity in calls to pthread_create.
- *
- * The shim operates as follows:-
- *
- * On initialisation a constructor function uses dlsym to obtain and
- * save the loaded address of the full set of pthread APIs that will
- * be overridden.
- *
- * For each function there is a stub provided that will invoke either
- * the genuine pthread library function saved saved by the constructor,
- * or else the corresponding equivalent lthread function.
- *
- * The stub functions are implemented in pthread_shim.c
- *
- * The stub will take care of adapting parameters, and any police
- * any constraints where lthread functionality differs.
- *
- * The initial thread must always be a pure lthread.
- *
- * The decision whether to invoke the real library function or the lthread
- * function is controlled by a per pthread flag that can be switched
- * on of off by the pthread_override_set() API described below. Typcially
- * this should be done as the first action of the initial lthread.
- *
- * N.B In general it would be poor practice to revert to invoke a real
- * pthread function when running as an lthread, since these may block and
- * effectively stall the lthread scheduler.
- *
- */
-
-
-/*
- * An exiting lthread must not terminate the pthread it is running in
- * since this would mean terminating the lthread scheduler.
- * We override pthread_exit() with a macro because it is typically declared with
- * __attribute__((noreturn))
- */
-void pthread_exit_override(void *v);
-
-#define pthread_exit(v) do { \
-	pthread_exit_override((v));	\
-	return NULL;	\
-} while (0)
-
-/*
- * Enable/Disable pthread override
- * state
- * 0 disable
- * 1 enable
- */
-void pthread_override_set(int state);
-
-
-/*
- * Return pthread override state
- * return
- * 0 disable
- * 1 enable
- */
-int pthread_override_get(void);
-
-
-#endif /* _PTHREAD_SHIM_H_ */
diff --git a/examples/ptpclient/Makefile b/examples/ptpclient/Makefile
deleted file mode 100644
index 1c1d9cd..0000000
--- a/examples/ptpclient/Makefile
+++ /dev/null
@@ -1,64 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2015 Intel Corporation
-
-# binary name
-APP = ptpclient
-
-# all source are stored in SRCS-y
-SRCS-y := ptpclient.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else # Build using legacy build system
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overriddegitn by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-
-# workaround for a gcc bug with noreturn attribute
-# http://gcc.gnu.org/bugzilla/show_bug.cgi?id=12603
-ifeq ($(CONFIG_RTE_TOOLCHAIN_GCC),y)
-CFLAGS_main.o += -Wno-return-type
-endif
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-endif
diff --git a/examples/ptpclient/meson.build b/examples/ptpclient/meson.build
deleted file mode 100644
index d4171a2..0000000
--- a/examples/ptpclient/meson.build
+++ /dev/null
@@ -1,12 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-allow_experimental_apis = true
-sources = files(
-	'ptpclient.c'
-)
diff --git a/examples/ptpclient/ptpclient.c b/examples/ptpclient/ptpclient.c
deleted file mode 100644
index 55be3f7..0000000
--- a/examples/ptpclient/ptpclient.c
+++ /dev/null
@@ -1,767 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2015 Intel Corporation
- */
-
-/*
- * This application is a simple Layer 2 PTP v2 client. It shows delta values
- * which are used to synchronize the PHC clock. if the "-T 1" parameter is
- * passed to the application the Linux kernel clock is also synchronized.
- */
-
-#include <stdint.h>
-#include <inttypes.h>
-#include <rte_eal.h>
-#include <rte_ethdev.h>
-#include <rte_cycles.h>
-#include <rte_lcore.h>
-#include <rte_mbuf.h>
-#include <rte_ip.h>
-#include <limits.h>
-#include <sys/time.h>
-#include <getopt.h>
-
-#define RX_RING_SIZE 1024
-#define TX_RING_SIZE 1024
-
-#define NUM_MBUFS            8191
-#define MBUF_CACHE_SIZE       250
-
-/* Values for the PTP messageType field. */
-#define SYNC                  0x0
-#define DELAY_REQ             0x1
-#define PDELAY_REQ            0x2
-#define PDELAY_RESP           0x3
-#define FOLLOW_UP             0x8
-#define DELAY_RESP            0x9
-#define PDELAY_RESP_FOLLOW_UP 0xA
-#define ANNOUNCE              0xB
-#define SIGNALING             0xC
-#define MANAGEMENT            0xD
-
-#define NSEC_PER_SEC        1000000000L
-#define KERNEL_TIME_ADJUST_LIMIT  20000
-#define PTP_PROTOCOL             0x88F7
-
-struct rte_mempool *mbuf_pool;
-uint32_t ptp_enabled_port_mask;
-uint8_t ptp_enabled_port_nb;
-static uint8_t ptp_enabled_ports[RTE_MAX_ETHPORTS];
-
-static const struct rte_eth_conf port_conf_default = {
-	.rxmode = {
-		.max_rx_pkt_len = ETHER_MAX_LEN,
-		.ignore_offload_bitfield = 1,
-	},
-};
-
-static const struct ether_addr ether_multicast = {
-	.addr_bytes = {0x01, 0x1b, 0x19, 0x0, 0x0, 0x0}
-};
-
-/* Structs used for PTP handling. */
-struct tstamp {
-	uint16_t   sec_msb;
-	uint32_t   sec_lsb;
-	uint32_t   ns;
-}  __attribute__((packed));
-
-struct clock_id {
-	uint8_t id[8];
-};
-
-struct port_id {
-	struct clock_id        clock_id;
-	uint16_t               port_number;
-}  __attribute__((packed));
-
-struct ptp_header {
-	uint8_t              msg_type;
-	uint8_t              ver;
-	uint16_t             message_length;
-	uint8_t              domain_number;
-	uint8_t              reserved1;
-	uint8_t              flag_field[2];
-	int64_t              correction;
-	uint32_t             reserved2;
-	struct port_id       source_port_id;
-	uint16_t             seq_id;
-	uint8_t              control;
-	int8_t               log_message_interval;
-} __attribute__((packed));
-
-struct sync_msg {
-	struct ptp_header   hdr;
-	struct tstamp       origin_tstamp;
-} __attribute__((packed));
-
-struct follow_up_msg {
-	struct ptp_header   hdr;
-	struct tstamp       precise_origin_tstamp;
-	uint8_t             suffix[0];
-} __attribute__((packed));
-
-struct delay_req_msg {
-	struct ptp_header   hdr;
-	struct tstamp       origin_tstamp;
-} __attribute__((packed));
-
-struct delay_resp_msg {
-	struct ptp_header    hdr;
-	struct tstamp        rx_tstamp;
-	struct port_id       req_port_id;
-	uint8_t              suffix[0];
-} __attribute__((packed));
-
-struct ptp_message {
-	union {
-		struct ptp_header          header;
-		struct sync_msg            sync;
-		struct delay_req_msg       delay_req;
-		struct follow_up_msg       follow_up;
-		struct delay_resp_msg      delay_resp;
-	} __attribute__((packed));
-};
-
-struct ptpv2_data_slave_ordinary {
-	struct rte_mbuf *m;
-	struct timespec tstamp1;
-	struct timespec tstamp2;
-	struct timespec tstamp3;
-	struct timespec tstamp4;
-	struct clock_id client_clock_id;
-	struct clock_id master_clock_id;
-	struct timeval new_adj;
-	int64_t delta;
-	uint16_t portid;
-	uint16_t seqID_SYNC;
-	uint16_t seqID_FOLLOWUP;
-	uint8_t ptpset;
-	uint8_t kernel_time_set;
-	uint16_t current_ptp_port;
-};
-
-static struct ptpv2_data_slave_ordinary ptp_data;
-
-static inline uint64_t timespec64_to_ns(const struct timespec *ts)
-{
-	return ((uint64_t) ts->tv_sec * NSEC_PER_SEC) + ts->tv_nsec;
-}
-
-static struct timeval
-ns_to_timeval(int64_t nsec)
-{
-	struct timespec t_spec = {0, 0};
-	struct timeval t_eval = {0, 0};
-	int32_t rem;
-
-	if (nsec == 0)
-		return t_eval;
-	rem = nsec % NSEC_PER_SEC;
-	t_spec.tv_sec = nsec / NSEC_PER_SEC;
-
-	if (rem < 0) {
-		t_spec.tv_sec--;
-		rem += NSEC_PER_SEC;
-	}
-
-	t_spec.tv_nsec = rem;
-	t_eval.tv_sec = t_spec.tv_sec;
-	t_eval.tv_usec = t_spec.tv_nsec / 1000;
-
-	return t_eval;
-}
-
-/*
- * Initializes a given port using global settings and with the RX buffers
- * coming from the mbuf_pool passed as a parameter.
- */
-static inline int
-port_init(uint16_t port, struct rte_mempool *mbuf_pool)
-{
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_conf port_conf = port_conf_default;
-	const uint16_t rx_rings = 1;
-	const uint16_t tx_rings = 1;
-	int retval;
-	uint16_t q;
-	uint16_t nb_rxd = RX_RING_SIZE;
-	uint16_t nb_txd = TX_RING_SIZE;
-
-	if (!rte_eth_dev_is_valid_port(port))
-		return -1;
-
-	rte_eth_dev_info_get(port, &dev_info);
-	if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-		port_conf.txmode.offloads |=
-			DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-	/* Force full Tx path in the driver, required for IEEE1588 */
-	port_conf.txmode.offloads |= DEV_TX_OFFLOAD_MULTI_SEGS;
-
-	/* Configure the Ethernet device. */
-	retval = rte_eth_dev_configure(port, rx_rings, tx_rings, &port_conf);
-	if (retval != 0)
-		return retval;
-
-	retval = rte_eth_dev_adjust_nb_rx_tx_desc(port, &nb_rxd, &nb_txd);
-	if (retval != 0)
-		return retval;
-
-	/* Allocate and set up 1 RX queue per Ethernet port. */
-	for (q = 0; q < rx_rings; q++) {
-		retval = rte_eth_rx_queue_setup(port, q, nb_rxd,
-				rte_eth_dev_socket_id(port), NULL, mbuf_pool);
-
-		if (retval < 0)
-			return retval;
-	}
-
-	/* Allocate and set up 1 TX queue per Ethernet port. */
-	for (q = 0; q < tx_rings; q++) {
-		/* Setup txq_flags */
-		struct rte_eth_txconf *txconf;
-
-		txconf = &dev_info.default_txconf;
-		txconf->txq_flags = ETH_TXQ_FLAGS_IGNORE;
-		txconf->offloads = port_conf.txmode.offloads;
-
-		retval = rte_eth_tx_queue_setup(port, q, nb_txd,
-				rte_eth_dev_socket_id(port), txconf);
-		if (retval < 0)
-			return retval;
-	}
-
-	/* Start the Ethernet port. */
-	retval = rte_eth_dev_start(port);
-	if (retval < 0)
-		return retval;
-
-	/* Enable timesync timestamping for the Ethernet device */
-	rte_eth_timesync_enable(port);
-
-	/* Enable RX in promiscuous mode for the Ethernet device. */
-	rte_eth_promiscuous_enable(port);
-
-	return 0;
-}
-
-static void
-print_clock_info(struct ptpv2_data_slave_ordinary *ptp_data)
-{
-	int64_t nsec;
-	struct timespec net_time, sys_time;
-
-	printf("Master Clock id: %02x:%02x:%02x:%02x:%02x:%02x:%02x:%02x",
-		ptp_data->master_clock_id.id[0],
-		ptp_data->master_clock_id.id[1],
-		ptp_data->master_clock_id.id[2],
-		ptp_data->master_clock_id.id[3],
-		ptp_data->master_clock_id.id[4],
-		ptp_data->master_clock_id.id[5],
-		ptp_data->master_clock_id.id[6],
-		ptp_data->master_clock_id.id[7]);
-
-	printf("\nT2 - Slave  Clock.  %lds %ldns",
-			(ptp_data->tstamp2.tv_sec),
-			(ptp_data->tstamp2.tv_nsec));
-
-	printf("\nT1 - Master Clock.  %lds %ldns ",
-			ptp_data->tstamp1.tv_sec,
-			(ptp_data->tstamp1.tv_nsec));
-
-	printf("\nT3 - Slave  Clock.  %lds %ldns",
-			ptp_data->tstamp3.tv_sec,
-			(ptp_data->tstamp3.tv_nsec));
-
-	printf("\nT4 - Master Clock.  %lds %ldns ",
-			ptp_data->tstamp4.tv_sec,
-			(ptp_data->tstamp4.tv_nsec));
-
-	printf("\nDelta between master and slave clocks:%"PRId64"ns\n",
-			ptp_data->delta);
-
-	clock_gettime(CLOCK_REALTIME, &sys_time);
-	rte_eth_timesync_read_time(ptp_data->current_ptp_port, &net_time);
-
-	time_t ts = net_time.tv_sec;
-
-	printf("\n\nComparison between Linux kernel Time and PTP:");
-
-	printf("\nCurrent PTP Time: %.24s %.9ld ns",
-			ctime(&ts), net_time.tv_nsec);
-
-	nsec = (int64_t)timespec64_to_ns(&net_time) -
-			(int64_t)timespec64_to_ns(&sys_time);
-	ptp_data->new_adj = ns_to_timeval(nsec);
-
-	gettimeofday(&ptp_data->new_adj, NULL);
-
-	time_t tp = ptp_data->new_adj.tv_sec;
-
-	printf("\nCurrent SYS Time: %.24s %.6ld ns",
-				ctime(&tp), ptp_data->new_adj.tv_usec);
-
-	printf("\nDelta between PTP and Linux Kernel time:%"PRId64"ns\n",
-				nsec);
-
-	printf("[Ctrl+C to quit]\n");
-
-	/* Clear screen and put cursor in column 1, row 1 */
-	printf("\033[2J\033[1;1H");
-}
-
-static int64_t
-delta_eval(struct ptpv2_data_slave_ordinary *ptp_data)
-{
-	int64_t delta;
-	uint64_t t1 = 0;
-	uint64_t t2 = 0;
-	uint64_t t3 = 0;
-	uint64_t t4 = 0;
-
-	t1 = timespec64_to_ns(&ptp_data->tstamp1);
-	t2 = timespec64_to_ns(&ptp_data->tstamp2);
-	t3 = timespec64_to_ns(&ptp_data->tstamp3);
-	t4 = timespec64_to_ns(&ptp_data->tstamp4);
-
-	delta = -((int64_t)((t2 - t1) - (t4 - t3))) / 2;
-
-	return delta;
-}
-
-/*
- * Parse the PTP SYNC message.
- */
-static void
-parse_sync(struct ptpv2_data_slave_ordinary *ptp_data, uint16_t rx_tstamp_idx)
-{
-	struct ptp_header *ptp_hdr;
-
-	ptp_hdr = (struct ptp_header *)(rte_pktmbuf_mtod(ptp_data->m, char *)
-			+ sizeof(struct ether_hdr));
-	ptp_data->seqID_SYNC = rte_be_to_cpu_16(ptp_hdr->seq_id);
-
-	if (ptp_data->ptpset == 0) {
-		rte_memcpy(&ptp_data->master_clock_id,
-				&ptp_hdr->source_port_id.clock_id,
-				sizeof(struct clock_id));
-		ptp_data->ptpset = 1;
-	}
-
-	if (memcmp(&ptp_hdr->source_port_id.clock_id,
-			&ptp_hdr->source_port_id.clock_id,
-			sizeof(struct clock_id)) == 0) {
-
-		if (ptp_data->ptpset == 1)
-			rte_eth_timesync_read_rx_timestamp(ptp_data->portid,
-					&ptp_data->tstamp2, rx_tstamp_idx);
-	}
-
-}
-
-/*
- * Parse the PTP FOLLOWUP message and send DELAY_REQ to the master clock.
- */
-static void
-parse_fup(struct ptpv2_data_slave_ordinary *ptp_data)
-{
-	struct ether_hdr *eth_hdr;
-	struct ptp_header *ptp_hdr;
-	struct clock_id *client_clkid;
-	struct ptp_message *ptp_msg;
-	struct rte_mbuf *created_pkt;
-	struct tstamp *origin_tstamp;
-	struct ether_addr eth_multicast = ether_multicast;
-	size_t pkt_size;
-	int wait_us;
-	struct rte_mbuf *m = ptp_data->m;
-
-	eth_hdr = rte_pktmbuf_mtod(m, struct ether_hdr *);
-	ptp_hdr = (struct ptp_header *)(rte_pktmbuf_mtod(m, char *)
-			+ sizeof(struct ether_hdr));
-	if (memcmp(&ptp_data->master_clock_id,
-			&ptp_hdr->source_port_id.clock_id,
-			sizeof(struct clock_id)) != 0)
-		return;
-
-	ptp_data->seqID_FOLLOWUP = rte_be_to_cpu_16(ptp_hdr->seq_id);
-	ptp_msg = (struct ptp_message *) (rte_pktmbuf_mtod(m, char *) +
-					  sizeof(struct ether_hdr));
-
-	origin_tstamp = &ptp_msg->follow_up.precise_origin_tstamp;
-	ptp_data->tstamp1.tv_nsec = ntohl(origin_tstamp->ns);
-	ptp_data->tstamp1.tv_sec =
-		((uint64_t)ntohl(origin_tstamp->sec_lsb)) |
-		(((uint64_t)ntohs(origin_tstamp->sec_msb)) << 32);
-
-	if (ptp_data->seqID_FOLLOWUP == ptp_data->seqID_SYNC) {
-
-		created_pkt = rte_pktmbuf_alloc(mbuf_pool);
-		pkt_size = sizeof(struct ether_hdr) +
-			sizeof(struct ptp_message);
-		created_pkt->data_len = pkt_size;
-		created_pkt->pkt_len = pkt_size;
-		eth_hdr = rte_pktmbuf_mtod(created_pkt, struct ether_hdr *);
-		rte_eth_macaddr_get(ptp_data->portid, &eth_hdr->s_addr);
-
-		/* Set multicast address 01-1B-19-00-00-00. */
-		ether_addr_copy(&eth_multicast, &eth_hdr->d_addr);
-
-		eth_hdr->ether_type = htons(PTP_PROTOCOL);
-		ptp_msg = (struct ptp_message *)
-			(rte_pktmbuf_mtod(created_pkt, char *) +
-			sizeof(struct ether_hdr));
-
-		ptp_msg->delay_req.hdr.seq_id = htons(ptp_data->seqID_SYNC);
-		ptp_msg->delay_req.hdr.msg_type = DELAY_REQ;
-		ptp_msg->delay_req.hdr.ver = 2;
-		ptp_msg->delay_req.hdr.control = 1;
-		ptp_msg->delay_req.hdr.log_message_interval = 127;
-
-		/* Set up clock id. */
-		client_clkid =
-			&ptp_msg->delay_req.hdr.source_port_id.clock_id;
-
-		client_clkid->id[0] = eth_hdr->s_addr.addr_bytes[0];
-		client_clkid->id[1] = eth_hdr->s_addr.addr_bytes[1];
-		client_clkid->id[2] = eth_hdr->s_addr.addr_bytes[2];
-		client_clkid->id[3] = 0xFF;
-		client_clkid->id[4] = 0xFE;
-		client_clkid->id[5] = eth_hdr->s_addr.addr_bytes[3];
-		client_clkid->id[6] = eth_hdr->s_addr.addr_bytes[4];
-		client_clkid->id[7] = eth_hdr->s_addr.addr_bytes[5];
-
-		rte_memcpy(&ptp_data->client_clock_id,
-			   client_clkid,
-			   sizeof(struct clock_id));
-
-		/* Enable flag for hardware timestamping. */
-		created_pkt->ol_flags |= PKT_TX_IEEE1588_TMST;
-
-		/*Read value from NIC to prevent latching with old value. */
-		rte_eth_timesync_read_tx_timestamp(ptp_data->portid,
-				&ptp_data->tstamp3);
-
-		/* Transmit the packet. */
-		rte_eth_tx_burst(ptp_data->portid, 0, &created_pkt, 1);
-
-		wait_us = 0;
-		ptp_data->tstamp3.tv_nsec = 0;
-		ptp_data->tstamp3.tv_sec = 0;
-
-		/* Wait at least 1 us to read TX timestamp. */
-		while ((rte_eth_timesync_read_tx_timestamp(ptp_data->portid,
-				&ptp_data->tstamp3) < 0) && (wait_us < 1000)) {
-			rte_delay_us(1);
-			wait_us++;
-		}
-	}
-}
-
-/*
- * Update the kernel time with the difference between it and the current NIC
- * time.
- */
-static inline void
-update_kernel_time(void)
-{
-	int64_t nsec;
-	struct timespec net_time, sys_time;
-
-	clock_gettime(CLOCK_REALTIME, &sys_time);
-	rte_eth_timesync_read_time(ptp_data.current_ptp_port, &net_time);
-
-	nsec = (int64_t)timespec64_to_ns(&net_time) -
-	       (int64_t)timespec64_to_ns(&sys_time);
-
-	ptp_data.new_adj = ns_to_timeval(nsec);
-
-	/*
-	 * If difference between kernel time and system time in NIC is too big
-	 * (more than +/- 20 microseconds), use clock_settime to set directly
-	 * the kernel time, as adjtime is better for small adjustments (takes
-	 * longer to adjust the time).
-	 */
-
-	if (nsec > KERNEL_TIME_ADJUST_LIMIT || nsec < -KERNEL_TIME_ADJUST_LIMIT)
-		clock_settime(CLOCK_REALTIME, &net_time);
-	else
-		adjtime(&ptp_data.new_adj, 0);
-
-
-}
-
-/*
- * Parse the DELAY_RESP message.
- */
-static void
-parse_drsp(struct ptpv2_data_slave_ordinary *ptp_data)
-{
-	struct rte_mbuf *m = ptp_data->m;
-	struct ptp_message *ptp_msg;
-	struct tstamp *rx_tstamp;
-	uint16_t seq_id;
-
-	ptp_msg = (struct ptp_message *) (rte_pktmbuf_mtod(m, char *) +
-					sizeof(struct ether_hdr));
-	seq_id = rte_be_to_cpu_16(ptp_msg->delay_resp.hdr.seq_id);
-	if (memcmp(&ptp_data->client_clock_id,
-		   &ptp_msg->delay_resp.req_port_id.clock_id,
-		   sizeof(struct clock_id)) == 0) {
-		if (seq_id == ptp_data->seqID_FOLLOWUP) {
-			rx_tstamp = &ptp_msg->delay_resp.rx_tstamp;
-			ptp_data->tstamp4.tv_nsec = ntohl(rx_tstamp->ns);
-			ptp_data->tstamp4.tv_sec =
-				((uint64_t)ntohl(rx_tstamp->sec_lsb)) |
-				(((uint64_t)ntohs(rx_tstamp->sec_msb)) << 32);
-
-			/* Evaluate the delta for adjustment. */
-			ptp_data->delta = delta_eval(ptp_data);
-
-			rte_eth_timesync_adjust_time(ptp_data->portid,
-						     ptp_data->delta);
-
-			ptp_data->current_ptp_port = ptp_data->portid;
-
-			/* Update kernel time if enabled in app parameters. */
-			if (ptp_data->kernel_time_set == 1)
-				update_kernel_time();
-
-
-
-		}
-	}
-}
-
-/* This function processes PTP packets, implementing slave PTP IEEE1588 L2
- * functionality.
- */
-static void
-parse_ptp_frames(uint16_t portid, struct rte_mbuf *m) {
-	struct ptp_header *ptp_hdr;
-	struct ether_hdr *eth_hdr;
-	uint16_t eth_type;
-
-	eth_hdr = rte_pktmbuf_mtod(m, struct ether_hdr *);
-	eth_type = rte_be_to_cpu_16(eth_hdr->ether_type);
-
-	if (eth_type == PTP_PROTOCOL) {
-		ptp_data.m = m;
-		ptp_data.portid = portid;
-		ptp_hdr = (struct ptp_header *)(rte_pktmbuf_mtod(m, char *)
-					+ sizeof(struct ether_hdr));
-
-		switch (ptp_hdr->msg_type) {
-		case SYNC:
-			parse_sync(&ptp_data, m->timesync);
-			break;
-		case FOLLOW_UP:
-			parse_fup(&ptp_data);
-			break;
-		case DELAY_RESP:
-			parse_drsp(&ptp_data);
-			print_clock_info(&ptp_data);
-			break;
-		default:
-			break;
-		}
-	}
-}
-
-/*
- * The lcore main. This is the main thread that does the work, reading from an
- * input port and writing to an output port.
- */
-static __attribute__((noreturn)) void
-lcore_main(void)
-{
-	uint16_t portid;
-	unsigned nb_rx;
-	struct rte_mbuf *m;
-
-	/*
-	 * Check that the port is on the same NUMA node as the polling thread
-	 * for best performance.
-	 */
-	printf("\nCore %u Waiting for SYNC packets. [Ctrl+C to quit]\n",
-			rte_lcore_id());
-
-	/* Run until the application is quit or killed. */
-
-	while (1) {
-		/* Read packet from RX queues. */
-		for (portid = 0; portid < ptp_enabled_port_nb; portid++) {
-
-			portid = ptp_enabled_ports[portid];
-			nb_rx = rte_eth_rx_burst(portid, 0, &m, 1);
-
-			if (likely(nb_rx == 0))
-				continue;
-
-			if (m->ol_flags & PKT_RX_IEEE1588_PTP)
-				parse_ptp_frames(portid, m);
-
-			rte_pktmbuf_free(m);
-		}
-	}
-}
-
-static void
-print_usage(const char *prgname)
-{
-	printf("%s [EAL options] -- -p PORTMASK -T VALUE\n"
-		" -T VALUE: 0 - Disable, 1 - Enable Linux Clock"
-		" Synchronization (0 default)\n"
-		" -p PORTMASK: hexadecimal bitmask of ports to configure\n",
-		prgname);
-}
-
-static int
-ptp_parse_portmask(const char *portmask)
-{
-	char *end = NULL;
-	unsigned long pm;
-
-	/* Parse the hexadecimal string. */
-	pm = strtoul(portmask, &end, 16);
-
-	if ((portmask[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (pm == 0)
-		return -1;
-
-	return pm;
-}
-
-static int
-parse_ptp_kernel(const char *param)
-{
-	char *end = NULL;
-	unsigned long pm;
-
-	/* Parse the hexadecimal string. */
-	pm = strtoul(param, &end, 16);
-
-	if ((param[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-	if (pm == 0)
-		return 0;
-
-	return 1;
-}
-
-/* Parse the commandline arguments. */
-static int
-ptp_parse_args(int argc, char **argv)
-{
-	int opt, ret;
-	char **argvopt;
-	int option_index;
-	char *prgname = argv[0];
-	static struct option lgopts[] = { {NULL, 0, 0, 0} };
-
-	argvopt = argv;
-
-	while ((opt = getopt_long(argc, argvopt, "p:T:",
-				  lgopts, &option_index)) != EOF) {
-
-		switch (opt) {
-
-		/* Portmask. */
-		case 'p':
-			ptp_enabled_port_mask = ptp_parse_portmask(optarg);
-			if (ptp_enabled_port_mask == 0) {
-				printf("invalid portmask\n");
-				print_usage(prgname);
-				return -1;
-			}
-			break;
-		/* Time synchronization. */
-		case 'T':
-			ret = parse_ptp_kernel(optarg);
-			if (ret < 0) {
-				print_usage(prgname);
-				return -1;
-			}
-
-			ptp_data.kernel_time_set = ret;
-			break;
-
-		default:
-			print_usage(prgname);
-			return -1;
-		}
-	}
-
-	argv[optind-1] = prgname;
-
-	optind = 1; /* Reset getopt lib. */
-
-	return 0;
-}
-
-/*
- * The main function, which does initialization and calls the per-lcore
- * functions.
- */
-int
-main(int argc, char *argv[])
-{
-	unsigned nb_ports;
-
-	uint16_t portid;
-
-	/* Initialize the Environment Abstraction Layer (EAL). */
-	int ret = rte_eal_init(argc, argv);
-
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Error with EAL initialization\n");
-
-	memset(&ptp_data, '\0', sizeof(struct ptpv2_data_slave_ordinary));
-
-	argc -= ret;
-	argv += ret;
-
-	ret = ptp_parse_args(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Error with PTP initialization\n");
-
-	/* Check that there is an even number of ports to send/receive on. */
-	nb_ports = rte_eth_dev_count();
-
-	/* Creates a new mempool in memory to hold the mbufs. */
-	mbuf_pool = rte_pktmbuf_pool_create("MBUF_POOL", NUM_MBUFS * nb_ports,
-		MBUF_CACHE_SIZE, 0, RTE_MBUF_DEFAULT_BUF_SIZE, rte_socket_id());
-
-	if (mbuf_pool == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot create mbuf pool\n");
-
-	/* Initialize all ports. */
-	RTE_ETH_FOREACH_DEV(portid) {
-		if ((ptp_enabled_port_mask & (1 << portid)) != 0) {
-			if (port_init(portid, mbuf_pool) == 0) {
-				ptp_enabled_ports[ptp_enabled_port_nb] = portid;
-				ptp_enabled_port_nb++;
-			} else {
-				rte_exit(EXIT_FAILURE,
-					 "Cannot init port %"PRIu8 "\n",
-					 portid);
-			}
-		} else
-			printf("Skipping disabled port %u\n", portid);
-	}
-
-	if (ptp_enabled_port_nb == 0) {
-		rte_exit(EXIT_FAILURE,
-			"All available ports are disabled."
-			" Please set portmask.\n");
-	}
-
-	if (rte_lcore_count() > 1)
-		printf("\nWARNING: Too many lcores enabled. Only 1 used.\n");
-
-	/* Call lcore_main on the master core only. */
-	lcore_main();
-
-	return 0;
-}
diff --git a/examples/qos_meter/Makefile b/examples/qos_meter/Makefile
deleted file mode 100644
index 69ac661..0000000
--- a/examples/qos_meter/Makefile
+++ /dev/null
@@ -1,61 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-# binary name
-APP = qos_meter
-
-# all source are stored in SRCS-y
-SRCS-y := main.c rte_policer.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else # Build using legacy build system
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-
-# workaround for a gcc bug with noreturn attribute
-# http://gcc.gnu.org/bugzilla/show_bug.cgi?id=12603
-ifeq ($(CONFIG_RTE_TOOLCHAIN_GCC),y)
-CFLAGS_main.o += -Wno-return-type
-endif
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-endif
diff --git a/examples/qos_meter/main.c b/examples/qos_meter/main.c
deleted file mode 100644
index f0f9bca..0000000
--- a/examples/qos_meter/main.c
+++ /dev/null
@@ -1,407 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2016 Intel Corporation
- */
-
-#include <stdio.h>
-#include <getopt.h>
-
-#include <rte_common.h>
-#include <rte_eal.h>
-#include <rte_malloc.h>
-#include <rte_mempool.h>
-#include <rte_ethdev.h>
-#include <rte_cycles.h>
-#include <rte_mbuf.h>
-#include <rte_meter.h>
-
-/*
- * Traffic metering configuration
- *
- */
-#define APP_MODE_FWD                    0
-#define APP_MODE_SRTCM_COLOR_BLIND      1
-#define APP_MODE_SRTCM_COLOR_AWARE      2
-#define APP_MODE_TRTCM_COLOR_BLIND      3
-#define APP_MODE_TRTCM_COLOR_AWARE      4
-
-#define APP_MODE	APP_MODE_SRTCM_COLOR_BLIND
-
-
-#include "main.h"
-
-
-#define APP_PKT_FLOW_POS                33
-#define APP_PKT_COLOR_POS               5
-
-
-#if APP_PKT_FLOW_POS > 64 || APP_PKT_COLOR_POS > 64
-#error Byte offset needs to be less than 64
-#endif
-
-/*
- * Buffer pool configuration
- *
- ***/
-#define NB_MBUF             8192
-#define MEMPOOL_CACHE_SIZE  256
-
-static struct rte_mempool *pool = NULL;
-
-/*
- * NIC configuration
- *
- ***/
-static struct rte_eth_conf port_conf = {
-	.rxmode = {
-		.mq_mode	= ETH_MQ_RX_RSS,
-		.max_rx_pkt_len = ETHER_MAX_LEN,
-		.split_hdr_size = 0,
-		.ignore_offload_bitfield = 1,
-		.offloads = (DEV_RX_OFFLOAD_CHECKSUM |
-			     DEV_RX_OFFLOAD_CRC_STRIP),
-	},
-	.rx_adv_conf = {
-		.rss_conf = {
-			.rss_key = NULL,
-			.rss_hf = ETH_RSS_IP,
-		},
-	},
-	.txmode = {
-		.mq_mode = ETH_DCB_NONE,
-	},
-};
-
-#define NIC_RX_QUEUE_DESC               1024
-#define NIC_TX_QUEUE_DESC               1024
-
-#define NIC_RX_QUEUE                    0
-#define NIC_TX_QUEUE                    0
-
-/*
- * Packet RX/TX
- *
- ***/
-#define PKT_RX_BURST_MAX                32
-#define PKT_TX_BURST_MAX                32
-#define TIME_TX_DRAIN                   200000ULL
-
-static uint16_t port_rx;
-static uint16_t port_tx;
-static struct rte_mbuf *pkts_rx[PKT_RX_BURST_MAX];
-struct rte_eth_dev_tx_buffer *tx_buffer;
-
-struct rte_meter_srtcm_params app_srtcm_params[] = {
-	{.cir = 1000000 * 46,  .cbs = 2048, .ebs = 2048},
-};
-
-struct rte_meter_trtcm_params app_trtcm_params[] = {
-	{.cir = 1000000 * 46,  .pir = 1500000 * 46,  .cbs = 2048, .pbs = 2048},
-};
-
-#define APP_FLOWS_MAX  256
-
-FLOW_METER app_flows[APP_FLOWS_MAX];
-
-static int
-app_configure_flow_table(void)
-{
-	uint32_t i, j;
-	int ret;
-
-	for (i = 0, j = 0; i < APP_FLOWS_MAX;
-			i ++, j = (j + 1) % RTE_DIM(PARAMS)) {
-		ret = FUNC_CONFIG(&app_flows[i], &PARAMS[j]);
-		if (ret)
-			return ret;
-	}
-
-	return 0;
-}
-
-static inline void
-app_set_pkt_color(uint8_t *pkt_data, enum policer_action color)
-{
-	pkt_data[APP_PKT_COLOR_POS] = (uint8_t)color;
-}
-
-static inline int
-app_pkt_handle(struct rte_mbuf *pkt, uint64_t time)
-{
-	uint8_t input_color, output_color;
-	uint8_t *pkt_data = rte_pktmbuf_mtod(pkt, uint8_t *);
-	uint32_t pkt_len = rte_pktmbuf_pkt_len(pkt) - sizeof(struct ether_hdr);
-	uint8_t flow_id = (uint8_t)(pkt_data[APP_PKT_FLOW_POS] & (APP_FLOWS_MAX - 1));
-	input_color = pkt_data[APP_PKT_COLOR_POS];
-	enum policer_action action;
-
-	/* color input is not used for blind modes */
-	output_color = (uint8_t) FUNC_METER(&app_flows[flow_id], time, pkt_len,
-		(enum rte_meter_color) input_color);
-
-	/* Apply policing and set the output color */
-	action = policer_table[input_color][output_color];
-	app_set_pkt_color(pkt_data, action);
-
-	return action;
-}
-
-
-static __attribute__((noreturn)) int
-main_loop(__attribute__((unused)) void *dummy)
-{
-	uint64_t current_time, last_time = rte_rdtsc();
-	uint32_t lcore_id = rte_lcore_id();
-
-	printf("Core %u: port RX = %d, port TX = %d\n", lcore_id, port_rx, port_tx);
-
-	while (1) {
-		uint64_t time_diff;
-		int i, nb_rx;
-
-		/* Mechanism to avoid stale packets in the output buffer */
-		current_time = rte_rdtsc();
-		time_diff = current_time - last_time;
-		if (unlikely(time_diff > TIME_TX_DRAIN)) {
-			/* Flush tx buffer */
-			rte_eth_tx_buffer_flush(port_tx, NIC_TX_QUEUE, tx_buffer);
-			last_time = current_time;
-		}
-
-		/* Read packet burst from NIC RX */
-		nb_rx = rte_eth_rx_burst(port_rx, NIC_RX_QUEUE, pkts_rx, PKT_RX_BURST_MAX);
-
-		/* Handle packets */
-		for (i = 0; i < nb_rx; i ++) {
-			struct rte_mbuf *pkt = pkts_rx[i];
-
-			/* Handle current packet */
-			if (app_pkt_handle(pkt, current_time) == DROP)
-				rte_pktmbuf_free(pkt);
-			else
-				rte_eth_tx_buffer(port_tx, NIC_TX_QUEUE, tx_buffer, pkt);
-		}
-	}
-}
-
-static void
-print_usage(const char *prgname)
-{
-	printf ("%s [EAL options] -- -p PORTMASK\n"
-		"  -p PORTMASK: hexadecimal bitmask of ports to configure\n",
-		prgname);
-}
-
-static int
-parse_portmask(const char *portmask)
-{
-	char *end = NULL;
-	unsigned long pm;
-
-	/* parse hexadecimal string */
-	pm = strtoul(portmask, &end, 16);
-	if ((portmask[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (pm == 0)
-		return -1;
-
-	return pm;
-}
-
-/* Parse the argument given in the command line of the application */
-static int
-parse_args(int argc, char **argv)
-{
-	int opt;
-	char **argvopt;
-	int option_index;
-	char *prgname = argv[0];
-	static struct option lgopts[] = {
-		{NULL, 0, 0, 0}
-	};
-	uint64_t port_mask, i, mask;
-
-	argvopt = argv;
-
-	while ((opt = getopt_long(argc, argvopt, "p:", lgopts, &option_index)) != EOF) {
-		switch (opt) {
-		case 'p':
-			port_mask = parse_portmask(optarg);
-			if (port_mask == 0) {
-				printf("invalid port mask (null port mask)\n");
-				print_usage(prgname);
-				return -1;
-			}
-
-			for (i = 0, mask = 1; i < 64; i ++, mask <<= 1){
-				if (mask & port_mask){
-					port_rx = i;
-					port_mask &= ~ mask;
-					break;
-				}
-			}
-
-			for (i = 0, mask = 1; i < 64; i ++, mask <<= 1){
-				if (mask & port_mask){
-					port_tx = i;
-					port_mask &= ~ mask;
-					break;
-				}
-			}
-
-			if (port_mask != 0) {
-				printf("invalid port mask (more than 2 ports)\n");
-				print_usage(prgname);
-				return -1;
-			}
-			break;
-
-		default:
-			print_usage(prgname);
-			return -1;
-		}
-	}
-
-	if (optind <= 1) {
-		print_usage(prgname);
-		return -1;
-	}
-
-	argv[optind-1] = prgname;
-
-	optind = 1; /* reset getopt lib */
-	return 0;
-}
-
-int
-main(int argc, char **argv)
-{
-	uint32_t lcore_id;
-	uint16_t nb_rxd = NIC_RX_QUEUE_DESC;
-	uint16_t nb_txd = NIC_TX_QUEUE_DESC;
-	struct rte_eth_conf conf;
-	struct rte_eth_rxconf rxq_conf;
-	struct rte_eth_txconf txq_conf;
-	struct rte_eth_dev_info dev_info;
-	int ret;
-
-	/* EAL init */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid EAL parameters\n");
-	argc -= ret;
-	argv += ret;
-	if (rte_lcore_count() != 1) {
-		rte_exit(EXIT_FAILURE, "This application does not accept more than one core. "
-		"Please adjust the \"-c COREMASK\" parameter accordingly.\n");
-	}
-
-	/* Application non-EAL arguments parse */
-	ret = parse_args(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid input arguments\n");
-
-	/* Buffer pool init */
-	pool = rte_pktmbuf_pool_create("pool", NB_MBUF, MEMPOOL_CACHE_SIZE,
-		0, RTE_MBUF_DEFAULT_BUF_SIZE, rte_socket_id());
-	if (pool == NULL)
-		rte_exit(EXIT_FAILURE, "Buffer pool creation error\n");
-
-	/* NIC init */
-	conf = port_conf;
-	rte_eth_dev_info_get(port_rx, &dev_info);
-	if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-		conf.txmode.offloads |= DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-	ret = rte_eth_dev_configure(port_rx, 1, 1, &conf);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Port %d configuration error (%d)\n", port_rx, ret);
-
-	ret = rte_eth_dev_adjust_nb_rx_tx_desc(port_rx, &nb_rxd, &nb_txd);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Port %d adjust number of descriptors error (%d)\n",
-				port_rx, ret);
-
-	rxq_conf = dev_info.default_rxconf;
-	rxq_conf.offloads = conf.rxmode.offloads;
-	ret = rte_eth_rx_queue_setup(port_rx, NIC_RX_QUEUE, nb_rxd,
-				rte_eth_dev_socket_id(port_rx),
-				&rxq_conf, pool);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Port %d RX queue setup error (%d)\n", port_rx, ret);
-
-	txq_conf = dev_info.default_txconf;
-	txq_conf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-	txq_conf.offloads = conf.txmode.offloads;
-	ret = rte_eth_tx_queue_setup(port_rx, NIC_TX_QUEUE, nb_txd,
-				rte_eth_dev_socket_id(port_rx),
-				&txq_conf);
-	if (ret < 0)
-	rte_exit(EXIT_FAILURE, "Port %d TX queue setup error (%d)\n", port_rx, ret);
-
-	conf = port_conf;
-	rte_eth_dev_info_get(port_tx, &dev_info);
-	if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-		conf.txmode.offloads |= DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-	ret = rte_eth_dev_configure(port_tx, 1, 1, &conf);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Port %d configuration error (%d)\n", port_tx, ret);
-
-	nb_rxd = NIC_RX_QUEUE_DESC;
-	nb_txd = NIC_TX_QUEUE_DESC;
-	ret = rte_eth_dev_adjust_nb_rx_tx_desc(port_tx, &nb_rxd, &nb_txd);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Port %d adjust number of descriptors error (%d)\n",
-				port_tx, ret);
-
-	rxq_conf = dev_info.default_rxconf;
-	rxq_conf.offloads = conf.rxmode.offloads;
-	ret = rte_eth_rx_queue_setup(port_tx, NIC_RX_QUEUE, nb_rxd,
-				rte_eth_dev_socket_id(port_tx),
-				NULL, pool);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Port %d RX queue setup error (%d)\n", port_tx, ret);
-
-	txq_conf = dev_info.default_txconf;
-	txq_conf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-	txq_conf.offloads = conf.txmode.offloads;
-	ret = rte_eth_tx_queue_setup(port_tx, NIC_TX_QUEUE, nb_txd,
-				rte_eth_dev_socket_id(port_tx),
-				NULL);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Port %d TX queue setup error (%d)\n", port_tx, ret);
-
-	tx_buffer = rte_zmalloc_socket("tx_buffer",
-			RTE_ETH_TX_BUFFER_SIZE(PKT_TX_BURST_MAX), 0,
-			rte_eth_dev_socket_id(port_tx));
-	if (tx_buffer == NULL)
-		rte_exit(EXIT_FAILURE, "Port %d TX buffer allocation error\n",
-				port_tx);
-
-	rte_eth_tx_buffer_init(tx_buffer, PKT_TX_BURST_MAX);
-
-	ret = rte_eth_dev_start(port_rx);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Port %d start error (%d)\n", port_rx, ret);
-
-	ret = rte_eth_dev_start(port_tx);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Port %d start error (%d)\n", port_tx, ret);
-
-	rte_eth_promiscuous_enable(port_rx);
-
-	rte_eth_promiscuous_enable(port_tx);
-
-	/* App configuration */
-	ret = app_configure_flow_table();
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid configure flow table\n");
-
-	/* Launch per-lcore init on every lcore */
-	rte_eal_mp_remote_launch(main_loop, NULL, CALL_MASTER);
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		if (rte_eal_wait_lcore(lcore_id) < 0)
-			return -1;
-	}
-
-	return 0;
-}
diff --git a/examples/qos_meter/main.h b/examples/qos_meter/main.h
deleted file mode 100644
index b27e8eb..0000000
--- a/examples/qos_meter/main.h
+++ /dev/null
@@ -1,64 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#ifndef _MAIN_H_
-#define _MAIN_H_
-
-enum policer_action {
-        GREEN = e_RTE_METER_GREEN,
-        YELLOW = e_RTE_METER_YELLOW,
-        RED = e_RTE_METER_RED,
-        DROP = 3,
-};
-
-enum policer_action policer_table[e_RTE_METER_COLORS][e_RTE_METER_COLORS] =
-{
-	{ GREEN, RED, RED},
-	{ DROP, YELLOW, RED},
-	{ DROP, DROP, RED}
-};
-
-#if APP_MODE == APP_MODE_FWD
-
-#define FUNC_METER(a,b,c,d) color, flow_id=flow_id, pkt_len=pkt_len, time=time
-#define FUNC_CONFIG(a, b) 0
-#define PARAMS	app_srtcm_params
-#define FLOW_METER int
-
-#elif APP_MODE == APP_MODE_SRTCM_COLOR_BLIND
-
-#define FUNC_METER(a,b,c,d) rte_meter_srtcm_color_blind_check(a,b,c)
-#define FUNC_CONFIG   rte_meter_srtcm_config
-#define PARAMS        app_srtcm_params
-#define FLOW_METER    struct rte_meter_srtcm
-
-#elif (APP_MODE == APP_MODE_SRTCM_COLOR_AWARE)
-
-#define FUNC_METER    rte_meter_srtcm_color_aware_check
-#define FUNC_CONFIG   rte_meter_srtcm_config
-#define PARAMS        app_srtcm_params
-#define FLOW_METER    struct rte_meter_srtcm
-
-#elif (APP_MODE == APP_MODE_TRTCM_COLOR_BLIND)
-
-#define FUNC_METER(a,b,c,d) rte_meter_trtcm_color_blind_check(a,b,c)
-#define FUNC_CONFIG  rte_meter_trtcm_config
-#define PARAMS       app_trtcm_params
-#define FLOW_METER   struct rte_meter_trtcm
-
-#elif (APP_MODE == APP_MODE_TRTCM_COLOR_AWARE)
-
-#define FUNC_METER   rte_meter_trtcm_color_aware_check
-#define FUNC_CONFIG  rte_meter_trtcm_config
-#define PARAMS       app_trtcm_params
-#define FLOW_METER   struct rte_meter_trtcm
-
-#else
-#error Invalid value for APP_MODE
-#endif
-
-
-
-
-#endif /* _MAIN_H_ */
diff --git a/examples/qos_meter/meson.build b/examples/qos_meter/meson.build
deleted file mode 100644
index ef7779f..0000000
--- a/examples/qos_meter/meson.build
+++ /dev/null
@@ -1,12 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-deps += 'meter'
-sources = files(
-	'main.c', 'rte_policer.c'
-)
diff --git a/examples/qos_meter/rte_policer.c b/examples/qos_meter/rte_policer.c
deleted file mode 100644
index 58c13ec..0000000
--- a/examples/qos_meter/rte_policer.c
+++ /dev/null
@@ -1,29 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdlib.h>
-#include "rte_policer.h"
-
-int
-rte_phb_config(struct rte_phb *phb_table, uint32_t phb_table_index,
-	enum rte_meter_color pre_meter, enum rte_meter_color post_meter, enum rte_phb_action action)
-{
-	struct rte_phb *phb = NULL;
-
-	/* User argument checking */
-	if (phb_table == NULL) {
-		return -1;
-	}
-
-	if ((pre_meter > e_RTE_METER_RED) || (post_meter > e_RTE_METER_RED) || (pre_meter > post_meter)) {
-		return -2;
-	}
-
-	/* Set action in PHB table entry */
-	phb = &phb_table[phb_table_index];
-	phb->actions[pre_meter][post_meter] = action;
-
-
-	return 0;
-}
diff --git a/examples/qos_meter/rte_policer.h b/examples/qos_meter/rte_policer.h
deleted file mode 100644
index 532a853..0000000
--- a/examples/qos_meter/rte_policer.h
+++ /dev/null
@@ -1,35 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#ifndef __INCLUDE_RTE_POLICER_H__
-#define __INCLUDE_RTE_POLICER_H__
-
-#include <stdint.h>
-#include <rte_meter.h>
-
-enum rte_phb_action {
-	e_RTE_PHB_ACTION_GREEN = e_RTE_METER_GREEN,
-	e_RTE_PHB_ACTION_YELLOW = e_RTE_METER_YELLOW,
-	e_RTE_PHB_ACTION_RED = e_RTE_METER_RED,
-	e_RTE_PHB_ACTION_DROP = 3,
-};
-
-struct rte_phb {
-	enum rte_phb_action actions[e_RTE_METER_COLORS][e_RTE_METER_COLORS];
-};
-
-int
-rte_phb_config(struct rte_phb *phb_table, uint32_t phb_table_index,
-	enum rte_meter_color pre_meter, enum rte_meter_color post_meter, enum rte_phb_action action);
-
-static inline enum rte_phb_action
-policer_run(struct rte_phb *phb_table, uint32_t phb_table_index, enum rte_meter_color pre_meter, enum rte_meter_color post_meter)
-{
-	struct rte_phb *phb = &phb_table[phb_table_index];
-	enum rte_phb_action action = phb->actions[pre_meter][post_meter];
-
-	return action;
-}
-
-#endif
diff --git a/examples/qos_sched/Makefile b/examples/qos_sched/Makefile
deleted file mode 100644
index 0f0a31f..0000000
--- a/examples/qos_sched/Makefile
+++ /dev/null
@@ -1,66 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-# binary name
-APP = qos_sched
-
-# all source are stored in SRCS-y
-SRCS-y := main.c args.c init.c app_thread.c cfg_file.c cmdline.c stats.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else # Build using legacy build system
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-ifneq ($(CONFIG_RTE_EXEC_ENV),"linuxapp")
-$(info This application can only operate in a linuxapp environment, \
-please change the definition of the RTE_TARGET environment variable)
-all:
-clean:
-else
-
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-CFLAGS_args.o := -D_GNU_SOURCE
-CFLAGS_cfg_file.o := -D_GNU_SOURCE
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-
-endif
-endif
diff --git a/examples/qos_sched/app_thread.c b/examples/qos_sched/app_thread.c
deleted file mode 100644
index a592742..0000000
--- a/examples/qos_sched/app_thread.c
+++ /dev/null
@@ -1,264 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdint.h>
-
-#include <rte_log.h>
-#include <rte_mbuf.h>
-#include <rte_malloc.h>
-#include <rte_cycles.h>
-#include <rte_ethdev.h>
-#include <rte_memcpy.h>
-#include <rte_byteorder.h>
-#include <rte_branch_prediction.h>
-#include <rte_sched.h>
-
-#include "main.h"
-
-/*
- * QoS parameters are encoded as follows:
- *		Outer VLAN ID defines subport
- *		Inner VLAN ID defines pipe
- *		Destination IP 0.0.XXX.0 defines traffic class
- *		Destination IP host (0.0.0.XXX) defines queue
- * Values below define offset to each field from start of frame
- */
-#define SUBPORT_OFFSET	7
-#define PIPE_OFFSET		9
-#define TC_OFFSET		20
-#define QUEUE_OFFSET	20
-#define COLOR_OFFSET	19
-
-static inline int
-get_pkt_sched(struct rte_mbuf *m, uint32_t *subport, uint32_t *pipe,
-			uint32_t *traffic_class, uint32_t *queue, uint32_t *color)
-{
-	uint16_t *pdata = rte_pktmbuf_mtod(m, uint16_t *);
-
-	*subport = (rte_be_to_cpu_16(pdata[SUBPORT_OFFSET]) & 0x0FFF) &
-			(port_params.n_subports_per_port - 1); /* Outer VLAN ID*/
-	*pipe = (rte_be_to_cpu_16(pdata[PIPE_OFFSET]) & 0x0FFF) &
-			(port_params.n_pipes_per_subport - 1); /* Inner VLAN ID */
-	*traffic_class = (pdata[QUEUE_OFFSET] & 0x0F) &
-			(RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE - 1); /* Destination IP */
-	*queue = ((pdata[QUEUE_OFFSET] >> 8) & 0x0F) &
-			(RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS - 1) ; /* Destination IP */
-	*color = pdata[COLOR_OFFSET] & 0x03; 	/* Destination IP */
-
-	return 0;
-}
-
-void
-app_rx_thread(struct thread_conf **confs)
-{
-	uint32_t i, nb_rx;
-	struct rte_mbuf *rx_mbufs[burst_conf.rx_burst] __rte_cache_aligned;
-	struct thread_conf *conf;
-	int conf_idx = 0;
-
-	uint32_t subport;
-	uint32_t pipe;
-	uint32_t traffic_class;
-	uint32_t queue;
-	uint32_t color;
-
-	while ((conf = confs[conf_idx])) {
-		nb_rx = rte_eth_rx_burst(conf->rx_port, conf->rx_queue, rx_mbufs,
-				burst_conf.rx_burst);
-
-		if (likely(nb_rx != 0)) {
-			APP_STATS_ADD(conf->stat.nb_rx, nb_rx);
-
-			for(i = 0; i < nb_rx; i++) {
-				get_pkt_sched(rx_mbufs[i],
-						&subport, &pipe, &traffic_class, &queue, &color);
-				rte_sched_port_pkt_write(rx_mbufs[i], subport, pipe,
-						traffic_class, queue, (enum rte_meter_color) color);
-			}
-
-			if (unlikely(rte_ring_sp_enqueue_bulk(conf->rx_ring,
-					(void **)rx_mbufs, nb_rx, NULL) == 0)) {
-				for(i = 0; i < nb_rx; i++) {
-					rte_pktmbuf_free(rx_mbufs[i]);
-
-					APP_STATS_ADD(conf->stat.nb_drop, 1);
-				}
-			}
-		}
-		conf_idx++;
-		if (confs[conf_idx] == NULL)
-			conf_idx = 0;
-	}
-}
-
-
-
-/* Send the packet to an output interface
- * For performance reason function returns number of packets dropped, not sent,
- * so 0 means that all packets were sent successfully
- */
-
-static inline void
-app_send_burst(struct thread_conf *qconf)
-{
-	struct rte_mbuf **mbufs;
-	uint32_t n, ret;
-
-	mbufs = (struct rte_mbuf **)qconf->m_table;
-	n = qconf->n_mbufs;
-
-	do {
-		ret = rte_eth_tx_burst(qconf->tx_port, qconf->tx_queue, mbufs, (uint16_t)n);
-		/* we cannot drop the packets, so re-send */
-		/* update number of packets to be sent */
-		n -= ret;
-		mbufs = (struct rte_mbuf **)&mbufs[ret];
-	} while (n);
-}
-
-
-/* Send the packet to an output interface */
-static void
-app_send_packets(struct thread_conf *qconf, struct rte_mbuf **mbufs, uint32_t nb_pkt)
-{
-	uint32_t i, len;
-
-	len = qconf->n_mbufs;
-	for(i = 0; i < nb_pkt; i++) {
-		qconf->m_table[len] = mbufs[i];
-		len++;
-		/* enough pkts to be sent */
-		if (unlikely(len == burst_conf.tx_burst)) {
-			qconf->n_mbufs = len;
-			app_send_burst(qconf);
-			len = 0;
-		}
-	}
-
-	qconf->n_mbufs = len;
-}
-
-void
-app_tx_thread(struct thread_conf **confs)
-{
-	struct rte_mbuf *mbufs[burst_conf.qos_dequeue];
-	struct thread_conf *conf;
-	int conf_idx = 0;
-	int retval;
-	const uint64_t drain_tsc = (rte_get_tsc_hz() + US_PER_S - 1) / US_PER_S * BURST_TX_DRAIN_US;
-
-	while ((conf = confs[conf_idx])) {
-		retval = rte_ring_sc_dequeue_bulk(conf->tx_ring, (void **)mbufs,
-					burst_conf.qos_dequeue, NULL);
-		if (likely(retval != 0)) {
-			app_send_packets(conf, mbufs, burst_conf.qos_dequeue);
-
-			conf->counter = 0; /* reset empty read loop counter */
-		}
-
-		conf->counter++;
-
-		/* drain ring and TX queues */
-		if (unlikely(conf->counter > drain_tsc)) {
-			/* now check is there any packets left to be transmitted */
-			if (conf->n_mbufs != 0) {
-				app_send_burst(conf);
-
-				conf->n_mbufs = 0;
-			}
-			conf->counter = 0;
-		}
-
-		conf_idx++;
-		if (confs[conf_idx] == NULL)
-			conf_idx = 0;
-	}
-}
-
-
-void
-app_worker_thread(struct thread_conf **confs)
-{
-	struct rte_mbuf *mbufs[burst_conf.ring_burst];
-	struct thread_conf *conf;
-	int conf_idx = 0;
-
-	while ((conf = confs[conf_idx])) {
-		uint32_t nb_pkt;
-
-		/* Read packet from the ring */
-		nb_pkt = rte_ring_sc_dequeue_burst(conf->rx_ring, (void **)mbufs,
-					burst_conf.ring_burst, NULL);
-		if (likely(nb_pkt)) {
-			int nb_sent = rte_sched_port_enqueue(conf->sched_port, mbufs,
-					nb_pkt);
-
-			APP_STATS_ADD(conf->stat.nb_drop, nb_pkt - nb_sent);
-			APP_STATS_ADD(conf->stat.nb_rx, nb_pkt);
-		}
-
-		nb_pkt = rte_sched_port_dequeue(conf->sched_port, mbufs,
-					burst_conf.qos_dequeue);
-		if (likely(nb_pkt > 0))
-			while (rte_ring_sp_enqueue_bulk(conf->tx_ring,
-					(void **)mbufs, nb_pkt, NULL) == 0)
-				; /* empty body */
-
-		conf_idx++;
-		if (confs[conf_idx] == NULL)
-			conf_idx = 0;
-	}
-}
-
-
-void
-app_mixed_thread(struct thread_conf **confs)
-{
-	struct rte_mbuf *mbufs[burst_conf.ring_burst];
-	struct thread_conf *conf;
-	int conf_idx = 0;
-	const uint64_t drain_tsc = (rte_get_tsc_hz() + US_PER_S - 1) / US_PER_S * BURST_TX_DRAIN_US;
-
-	while ((conf = confs[conf_idx])) {
-		uint32_t nb_pkt;
-
-		/* Read packet from the ring */
-		nb_pkt = rte_ring_sc_dequeue_burst(conf->rx_ring, (void **)mbufs,
-					burst_conf.ring_burst, NULL);
-		if (likely(nb_pkt)) {
-			int nb_sent = rte_sched_port_enqueue(conf->sched_port, mbufs,
-					nb_pkt);
-
-			APP_STATS_ADD(conf->stat.nb_drop, nb_pkt - nb_sent);
-			APP_STATS_ADD(conf->stat.nb_rx, nb_pkt);
-		}
-
-
-		nb_pkt = rte_sched_port_dequeue(conf->sched_port, mbufs,
-					burst_conf.qos_dequeue);
-		if (likely(nb_pkt > 0)) {
-			app_send_packets(conf, mbufs, nb_pkt);
-
-			conf->counter = 0; /* reset empty read loop counter */
-		}
-
-		conf->counter++;
-
-		/* drain ring and TX queues */
-		if (unlikely(conf->counter > drain_tsc)) {
-
-			/* now check is there any packets left to be transmitted */
-			if (conf->n_mbufs != 0) {
-				app_send_burst(conf);
-
-				conf->n_mbufs = 0;
-			}
-			conf->counter = 0;
-		}
-
-		conf_idx++;
-		if (confs[conf_idx] == NULL)
-			conf_idx = 0;
-	}
-}
diff --git a/examples/qos_sched/args.c b/examples/qos_sched/args.c
deleted file mode 100644
index 83eee95..0000000
--- a/examples/qos_sched/args.c
+++ /dev/null
@@ -1,459 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdio.h>
-#include <string.h>
-#include <stdlib.h>
-#include <stdint.h>
-#include <locale.h>
-#include <unistd.h>
-#include <limits.h>
-#include <getopt.h>
-
-#include <rte_log.h>
-#include <rte_eal.h>
-#include <rte_lcore.h>
-#include <rte_string_fns.h>
-
-#include "main.h"
-
-#define APP_NAME "qos_sched"
-#define MAX_OPT_VALUES 8
-#define SYS_CPU_DIR "/sys/devices/system/cpu/cpu%u/topology/"
-
-static uint32_t app_master_core = 1;
-static uint32_t app_numa_mask;
-static uint64_t app_used_core_mask = 0;
-static uint64_t app_used_port_mask = 0;
-static uint64_t app_used_rx_port_mask = 0;
-static uint64_t app_used_tx_port_mask = 0;
-
-
-static const char usage[] =
-	"                                                                               \n"
-	"    %s <APP PARAMS>                                                            \n"
-	"                                                                               \n"
-	"Application mandatory parameters:                                              \n"
-	"    --pfc \"RX PORT, TX PORT, RX LCORE, WT LCORE\" : Packet flow configuration \n"
-	"           multiple pfc can be configured in command line                      \n"
-	"                                                                               \n"
-	"Application optional parameters:                                               \n"
-        "    --i     : run in interactive mode (default value is %u)                    \n"
-	"    --mst I : master core index (default value is %u)                          \n"
-	"    --rsz \"A, B, C\" :   Ring sizes                                           \n"
-	"           A = Size (in number of buffer descriptors) of each of the NIC RX    \n"
-	"               rings read by the I/O RX lcores (default value is %u)           \n"
-	"           B = Size (in number of elements) of each of the SW rings used by the\n"
-	"               I/O RX lcores to send packets to worker lcores (default value is\n"
-	"               %u)                                                             \n"
-	"           C = Size (in number of buffer descriptors) of each of the NIC TX    \n"
-	"               rings written by worker lcores (default value is %u)            \n"
-	"    --bsz \"A, B, C, D\": Burst sizes                                          \n"
-	"           A = I/O RX lcore read burst size from NIC RX (default value is %u)  \n"
-	"           B = I/O RX lcore write burst size to output SW rings,               \n"
-	"               Worker lcore read burst size from input SW rings,               \n"
-	"               QoS enqueue size (default value is %u)                          \n"
-	"           C = QoS dequeue size (default value is %u)                          \n"
-	"           D = Worker lcore write burst size to NIC TX (default value is %u)   \n"
-	"    --msz M : Mempool size (in number of mbufs) for each pfc (default %u)      \n"
-	"    --rth \"A, B, C\" :   RX queue threshold parameters                        \n"
-	"           A = RX prefetch threshold (default value is %u)                     \n"
-	"           B = RX host threshold (default value is %u)                         \n"
-	"           C = RX write-back threshold (default value is %u)                   \n"
-	"    --tth \"A, B, C\" :   TX queue threshold parameters                        \n"
-	"           A = TX prefetch threshold (default value is %u)                     \n"
-	"           B = TX host threshold (default value is %u)                         \n"
-	"           C = TX write-back threshold (default value is %u)                   \n"
-	"    --cfg FILE : profile configuration to load                                 \n"
-;
-
-/* display usage */
-static void
-app_usage(const char *prgname)
-{
-	printf(usage, prgname, APP_INTERACTIVE_DEFAULT, app_master_core,
-		APP_RX_DESC_DEFAULT, APP_RING_SIZE, APP_TX_DESC_DEFAULT,
-		MAX_PKT_RX_BURST, PKT_ENQUEUE, PKT_DEQUEUE,
-		MAX_PKT_TX_BURST, NB_MBUF,
-		RX_PTHRESH, RX_HTHRESH, RX_WTHRESH,
-		TX_PTHRESH, TX_HTHRESH, TX_WTHRESH
-		);
-}
-
-static inline int str_is(const char *str, const char *is)
-{
-	return strcmp(str, is) == 0;
-}
-
-/* returns core mask used by DPDK */
-static uint64_t
-app_eal_core_mask(void)
-{
-	uint32_t i;
-	uint64_t cm = 0;
-	struct rte_config *cfg = rte_eal_get_configuration();
-
-	for (i = 0; i < APP_MAX_LCORE; i++) {
-		if (cfg->lcore_role[i] == ROLE_RTE)
-			cm |= (1ULL << i);
-	}
-
-	cm |= (1ULL << cfg->master_lcore);
-
-	return cm;
-}
-
-
-/* returns total number of cores presented in a system */
-static uint32_t
-app_cpu_core_count(void)
-{
-	int i, len;
-	char path[PATH_MAX];
-	uint32_t ncores = 0;
-
-	for (i = 0; i < APP_MAX_LCORE; i++) {
-		len = snprintf(path, sizeof(path), SYS_CPU_DIR, i);
-		if (len <= 0 || (unsigned)len >= sizeof(path))
-			continue;
-
-		if (access(path, F_OK) == 0)
-			ncores++;
-	}
-
-	return ncores;
-}
-
-/* returns:
-	 number of values parsed
-	-1 in case of error
-*/
-static int
-app_parse_opt_vals(const char *conf_str, char separator, uint32_t n_vals, uint32_t *opt_vals)
-{
-	char *string;
-	int i, n_tokens;
-	char *tokens[MAX_OPT_VALUES];
-
-	if (conf_str == NULL || opt_vals == NULL || n_vals == 0 || n_vals > MAX_OPT_VALUES)
-		return -1;
-
-	/* duplicate configuration string before splitting it to tokens */
-	string = strdup(conf_str);
-	if (string == NULL)
-		return -1;
-
-	n_tokens = rte_strsplit(string, strnlen(string, 32), tokens, n_vals, separator);
-
-	if (n_tokens > MAX_OPT_VALUES)
-		return -1;
-
-	for (i = 0; i < n_tokens; i++)
-		opt_vals[i] = (uint32_t)atol(tokens[i]);
-
-	free(string);
-
-	return n_tokens;
-}
-
-static int
-app_parse_ring_conf(const char *conf_str)
-{
-	int ret;
-	uint32_t vals[3];
-
-	ret = app_parse_opt_vals(conf_str, ',', 3, vals);
-	if (ret != 3)
-		return ret;
-
-	ring_conf.rx_size = vals[0];
-	ring_conf.ring_size = vals[1];
-	ring_conf.tx_size = vals[2];
-
-	return 0;
-}
-
-static int
-app_parse_rth_conf(const char *conf_str)
-{
-	int ret;
-	uint32_t vals[3];
-
-	ret = app_parse_opt_vals(conf_str, ',', 3, vals);
-	if (ret != 3)
-		return ret;
-
-	rx_thresh.pthresh = (uint8_t)vals[0];
-	rx_thresh.hthresh = (uint8_t)vals[1];
-	rx_thresh.wthresh = (uint8_t)vals[2];
-
-	return 0;
-}
-
-static int
-app_parse_tth_conf(const char *conf_str)
-{
-	int ret;
-	uint32_t vals[3];
-
-	ret = app_parse_opt_vals(conf_str, ',', 3, vals);
-	if (ret != 3)
-		return ret;
-
-	tx_thresh.pthresh = (uint8_t)vals[0];
-	tx_thresh.hthresh = (uint8_t)vals[1];
-	tx_thresh.wthresh = (uint8_t)vals[2];
-
-	return 0;
-}
-
-static int
-app_parse_flow_conf(const char *conf_str)
-{
-	int ret;
-	uint32_t vals[5];
-	struct flow_conf *pconf;
-	uint64_t mask;
-
-	memset(vals, 0, sizeof(vals));
-	ret = app_parse_opt_vals(conf_str, ',', 6, vals);
-	if (ret < 4 || ret > 5)
-		return ret;
-
-	pconf = &qos_conf[nb_pfc];
-
-	pconf->rx_port = vals[0];
-	pconf->tx_port = vals[1];
-	pconf->rx_core = (uint8_t)vals[2];
-	pconf->wt_core = (uint8_t)vals[3];
-	if (ret == 5)
-		pconf->tx_core = (uint8_t)vals[4];
-	else
-		pconf->tx_core = pconf->wt_core;
-
-	if (pconf->rx_core == pconf->wt_core) {
-		RTE_LOG(ERR, APP, "pfc %u: rx thread and worker thread cannot share same core\n", nb_pfc);
-		return -1;
-	}
-
-	if (pconf->rx_port >= RTE_MAX_ETHPORTS) {
-		RTE_LOG(ERR, APP, "pfc %u: invalid rx port %"PRIu16" index\n",
-				nb_pfc, pconf->rx_port);
-		return -1;
-	}
-	if (pconf->tx_port >= RTE_MAX_ETHPORTS) {
-		RTE_LOG(ERR, APP, "pfc %u: invalid tx port %"PRIu16" index\n",
-				nb_pfc, pconf->tx_port);
-		return -1;
-	}
-
-	mask = 1lu << pconf->rx_port;
-	if (app_used_rx_port_mask & mask) {
-		RTE_LOG(ERR, APP, "pfc %u: rx port %"PRIu16" is used already\n",
-				nb_pfc, pconf->rx_port);
-		return -1;
-	}
-	app_used_rx_port_mask |= mask;
-	app_used_port_mask |= mask;
-
-	mask = 1lu << pconf->tx_port;
-	if (app_used_tx_port_mask & mask) {
-		RTE_LOG(ERR, APP, "pfc %u: port %"PRIu16" is used already\n",
-				nb_pfc, pconf->tx_port);
-		return -1;
-	}
-	app_used_tx_port_mask |= mask;
-	app_used_port_mask |= mask;
-
-	mask = 1lu << pconf->rx_core;
-	app_used_core_mask |= mask;
-
-	mask = 1lu << pconf->wt_core;
-	app_used_core_mask |= mask;
-
-	mask = 1lu << pconf->tx_core;
-	app_used_core_mask |= mask;
-
-	nb_pfc++;
-
-	return 0;
-}
-
-static int
-app_parse_burst_conf(const char *conf_str)
-{
-	int ret;
-	uint32_t vals[4];
-
-	ret = app_parse_opt_vals(conf_str, ',', 4, vals);
-	if (ret != 4)
-		return ret;
-
-	burst_conf.rx_burst    = (uint16_t)vals[0];
-	burst_conf.ring_burst  = (uint16_t)vals[1];
-	burst_conf.qos_dequeue = (uint16_t)vals[2];
-	burst_conf.tx_burst    = (uint16_t)vals[3];
-
-	return 0;
-}
-
-/*
- * Parses the argument given in the command line of the application,
- * calculates mask for used cores and initializes EAL with calculated core mask
- */
-int
-app_parse_args(int argc, char **argv)
-{
-	int opt, ret;
-	int option_index;
-	const char *optname;
-	char *prgname = argv[0];
-	uint32_t i, nb_lcores;
-
-	static struct option lgopts[] = {
-		{ "pfc", 1, 0, 0 },
-		{ "mst", 1, 0, 0 },
-		{ "rsz", 1, 0, 0 },
-		{ "bsz", 1, 0, 0 },
-		{ "msz", 1, 0, 0 },
-		{ "rth", 1, 0, 0 },
-		{ "tth", 1, 0, 0 },
-		{ "cfg", 1, 0, 0 },
-		{ NULL,  0, 0, 0 }
-	};
-
-	/* initialize EAL first */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		return -1;
-
-	argc -= ret;
-	argv += ret;
-
-	/* set en_US locale to print big numbers with ',' */
-	setlocale(LC_NUMERIC, "en_US.utf-8");
-
-	while ((opt = getopt_long(argc, argv, "i",
-		lgopts, &option_index)) != EOF) {
-
-			switch (opt) {
-			case 'i':
-				printf("Interactive-mode selected\n");
-				interactive = 1;
-				break;
-			/* long options */
-			case 0:
-				optname = lgopts[option_index].name;
-				if (str_is(optname, "pfc")) {
-					ret = app_parse_flow_conf(optarg);
-					if (ret) {
-						RTE_LOG(ERR, APP, "Invalid pipe configuration %s\n", optarg);
-						return -1;
-					}
-					break;
-				}
-				if (str_is(optname, "mst")) {
-					app_master_core = (uint32_t)atoi(optarg);
-					break;
-				}
-				if (str_is(optname, "rsz")) {
-					ret = app_parse_ring_conf(optarg);
-					if (ret) {
-						RTE_LOG(ERR, APP, "Invalid ring configuration %s\n", optarg);
-						return -1;
-					}
-					break;
-				}
-				if (str_is(optname, "bsz")) {
-					ret = app_parse_burst_conf(optarg);
-					if (ret) {
-						RTE_LOG(ERR, APP, "Invalid burst configuration %s\n", optarg);
-						return -1;
-					}
-					break;
-				}
-				if (str_is(optname, "msz")) {
-					mp_size = atoi(optarg);
-					if (mp_size <= 0) {
-						RTE_LOG(ERR, APP, "Invalid mempool size %s\n", optarg);
-						return -1;
-					}
-					break;
-				}
-				if (str_is(optname, "rth")) {
-					ret = app_parse_rth_conf(optarg);
-					if (ret) {
-						RTE_LOG(ERR, APP, "Invalid RX threshold configuration %s\n", optarg);
-						return -1;
-					}
-					break;
-				}
-				if (str_is(optname, "tth")) {
-					ret = app_parse_tth_conf(optarg);
-					if (ret) {
-						RTE_LOG(ERR, APP, "Invalid TX threshold configuration %s\n", optarg);
-						return -1;
-					}
-					break;
-				}
-				if (str_is(optname, "cfg")) {
-					cfg_profile = optarg;
-					break;
-				}
-				break;
-
-			default:
-				app_usage(prgname);
-				return -1;
-			}
-	}
-
-	/* check master core index validity */
-	for(i = 0; i <= app_master_core; i++) {
-		if (app_used_core_mask & (1u << app_master_core)) {
-			RTE_LOG(ERR, APP, "Master core index is not configured properly\n");
-			app_usage(prgname);
-			return -1;
-		}
-	}
-	app_used_core_mask |= 1u << app_master_core;
-
-	if ((app_used_core_mask != app_eal_core_mask()) ||
-			(app_master_core != rte_get_master_lcore())) {
-		RTE_LOG(ERR, APP, "EAL core mask not configured properly, must be %" PRIx64
-				" instead of %" PRIx64 "\n" , app_used_core_mask, app_eal_core_mask());
-		return -1;
-	}
-
-	if (nb_pfc == 0) {
-		RTE_LOG(ERR, APP, "Packet flow not configured!\n");
-		app_usage(prgname);
-		return -1;
-	}
-
-	/* sanity check for cores assignment */
-	nb_lcores = app_cpu_core_count();
-
-	for(i = 0; i < nb_pfc; i++) {
-		if (qos_conf[i].rx_core >= nb_lcores) {
-			RTE_LOG(ERR, APP, "pfc %u: invalid RX lcore index %u\n", i + 1,
-					qos_conf[i].rx_core);
-			return -1;
-		}
-		if (qos_conf[i].wt_core >= nb_lcores) {
-			RTE_LOG(ERR, APP, "pfc %u: invalid WT lcore index %u\n", i + 1,
-					qos_conf[i].wt_core);
-			return -1;
-		}
-		uint32_t rx_sock = rte_lcore_to_socket_id(qos_conf[i].rx_core);
-		uint32_t wt_sock = rte_lcore_to_socket_id(qos_conf[i].wt_core);
-		if (rx_sock != wt_sock) {
-			RTE_LOG(ERR, APP, "pfc %u: RX and WT must be on the same socket\n", i + 1);
-			return -1;
-		}
-		app_numa_mask |= 1 << rte_lcore_to_socket_id(qos_conf[i].rx_core);
-	}
-
-	return 0;
-}
diff --git a/examples/qos_sched/cfg_file.c b/examples/qos_sched/cfg_file.c
deleted file mode 100644
index d198de6..0000000
--- a/examples/qos_sched/cfg_file.c
+++ /dev/null
@@ -1,313 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <string.h>
-#include <ctype.h>
-#include <rte_string_fns.h>
-#include <rte_sched.h>
-
-#include "cfg_file.h"
-#include "main.h"
-
-
-/** when we resize a file structure, how many extra entries
- * for new sections do we add in */
-#define CFG_ALLOC_SECTION_BATCH 8
-/** when we resize a section structure, how many extra entries
- * for new entries do we add in */
-#define CFG_ALLOC_ENTRY_BATCH 16
-
-int
-cfg_load_port(struct rte_cfgfile *cfg, struct rte_sched_port_params *port_params)
-{
-	const char *entry;
-	int j;
-
-	if (!cfg || !port_params)
-		return -1;
-
-	entry = rte_cfgfile_get_entry(cfg, "port", "frame overhead");
-	if (entry)
-		port_params->frame_overhead = (uint32_t)atoi(entry);
-
-	entry = rte_cfgfile_get_entry(cfg, "port", "number of subports per port");
-	if (entry)
-		port_params->n_subports_per_port = (uint32_t)atoi(entry);
-
-	entry = rte_cfgfile_get_entry(cfg, "port", "number of pipes per subport");
-	if (entry)
-		port_params->n_pipes_per_subport = (uint32_t)atoi(entry);
-
-	entry = rte_cfgfile_get_entry(cfg, "port", "queue sizes");
-	if (entry) {
-		char *next;
-
-		for(j = 0; j < RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE; j++) {
-			port_params->qsize[j] = (uint16_t)strtol(entry, &next, 10);
-			if (next == NULL)
-				break;
-			entry = next;
-		}
-	}
-
-#ifdef RTE_SCHED_RED
-	for (j = 0; j < RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE; j++) {
-		char str[32];
-
-		/* Parse WRED min thresholds */
-		snprintf(str, sizeof(str), "tc %d wred min", j);
-		entry = rte_cfgfile_get_entry(cfg, "red", str);
-		if (entry) {
-			char *next;
-			int k;
-			/* for each packet colour (green, yellow, red) */
-			for (k = 0; k < e_RTE_METER_COLORS; k++) {
-				port_params->red_params[j][k].min_th
-					= (uint16_t)strtol(entry, &next, 10);
-				if (next == NULL)
-					break;
-				entry = next;
-			}
-		}
-
-		/* Parse WRED max thresholds */
-		snprintf(str, sizeof(str), "tc %d wred max", j);
-		entry = rte_cfgfile_get_entry(cfg, "red", str);
-		if (entry) {
-			char *next;
-			int k;
-			/* for each packet colour (green, yellow, red) */
-			for (k = 0; k < e_RTE_METER_COLORS; k++) {
-				port_params->red_params[j][k].max_th
-					= (uint16_t)strtol(entry, &next, 10);
-				if (next == NULL)
-					break;
-				entry = next;
-			}
-		}
-
-		/* Parse WRED inverse mark probabilities */
-		snprintf(str, sizeof(str), "tc %d wred inv prob", j);
-		entry = rte_cfgfile_get_entry(cfg, "red", str);
-		if (entry) {
-			char *next;
-			int k;
-			/* for each packet colour (green, yellow, red) */
-			for (k = 0; k < e_RTE_METER_COLORS; k++) {
-				port_params->red_params[j][k].maxp_inv
-					= (uint8_t)strtol(entry, &next, 10);
-
-				if (next == NULL)
-					break;
-				entry = next;
-			}
-		}
-
-		/* Parse WRED EWMA filter weights */
-		snprintf(str, sizeof(str), "tc %d wred weight", j);
-		entry = rte_cfgfile_get_entry(cfg, "red", str);
-		if (entry) {
-			char *next;
-			int k;
-			/* for each packet colour (green, yellow, red) */
-			for (k = 0; k < e_RTE_METER_COLORS; k++) {
-				port_params->red_params[j][k].wq_log2
-					= (uint8_t)strtol(entry, &next, 10);
-				if (next == NULL)
-					break;
-				entry = next;
-			}
-		}
-	}
-#endif /* RTE_SCHED_RED */
-
-	return 0;
-}
-
-int
-cfg_load_pipe(struct rte_cfgfile *cfg, struct rte_sched_pipe_params *pipe_params)
-{
-	int i, j;
-	char *next;
-	const char *entry;
-	int profiles;
-
-	if (!cfg || !pipe_params)
-		return -1;
-
-	profiles = rte_cfgfile_num_sections(cfg, "pipe profile", sizeof("pipe profile") - 1);
-	port_params.n_pipe_profiles = profiles;
-
-	for (j = 0; j < profiles; j++) {
-		char pipe_name[32];
-		snprintf(pipe_name, sizeof(pipe_name), "pipe profile %d", j);
-
-		entry = rte_cfgfile_get_entry(cfg, pipe_name, "tb rate");
-		if (entry)
-			pipe_params[j].tb_rate = (uint32_t)atoi(entry);
-
-		entry = rte_cfgfile_get_entry(cfg, pipe_name, "tb size");
-		if (entry)
-			pipe_params[j].tb_size = (uint32_t)atoi(entry);
-
-		entry = rte_cfgfile_get_entry(cfg, pipe_name, "tc period");
-		if (entry)
-			pipe_params[j].tc_period = (uint32_t)atoi(entry);
-
-		entry = rte_cfgfile_get_entry(cfg, pipe_name, "tc 0 rate");
-		if (entry)
-			pipe_params[j].tc_rate[0] = (uint32_t)atoi(entry);
-
-		entry = rte_cfgfile_get_entry(cfg, pipe_name, "tc 1 rate");
-		if (entry)
-			pipe_params[j].tc_rate[1] = (uint32_t)atoi(entry);
-
-		entry = rte_cfgfile_get_entry(cfg, pipe_name, "tc 2 rate");
-		if (entry)
-			pipe_params[j].tc_rate[2] = (uint32_t)atoi(entry);
-
-		entry = rte_cfgfile_get_entry(cfg, pipe_name, "tc 3 rate");
-		if (entry)
-			pipe_params[j].tc_rate[3] = (uint32_t)atoi(entry);
-
-#ifdef RTE_SCHED_SUBPORT_TC_OV
-		entry = rte_cfgfile_get_entry(cfg, pipe_name, "tc 3 oversubscription weight");
-		if (entry)
-			pipe_params[j].tc_ov_weight = (uint8_t)atoi(entry);
-#endif
-
-		entry = rte_cfgfile_get_entry(cfg, pipe_name, "tc 0 wrr weights");
-		if (entry) {
-			for(i = 0; i < RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS; i++) {
-				pipe_params[j].wrr_weights[RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE*0 + i] =
-					(uint8_t)strtol(entry, &next, 10);
-				if (next == NULL)
-					break;
-				entry = next;
-			}
-		}
-		entry = rte_cfgfile_get_entry(cfg, pipe_name, "tc 1 wrr weights");
-		if (entry) {
-			for(i = 0; i < RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS; i++) {
-				pipe_params[j].wrr_weights[RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE*1 + i] =
-					(uint8_t)strtol(entry, &next, 10);
-				if (next == NULL)
-					break;
-				entry = next;
-			}
-		}
-		entry = rte_cfgfile_get_entry(cfg, pipe_name, "tc 2 wrr weights");
-		if (entry) {
-			for(i = 0; i < RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS; i++) {
-				pipe_params[j].wrr_weights[RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE*2 + i] =
-					(uint8_t)strtol(entry, &next, 10);
-				if (next == NULL)
-					break;
-				entry = next;
-			}
-		}
-		entry = rte_cfgfile_get_entry(cfg, pipe_name, "tc 3 wrr weights");
-		if (entry) {
-			for(i = 0; i < RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS; i++) {
-				pipe_params[j].wrr_weights[RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE*3 + i] =
-					(uint8_t)strtol(entry, &next, 10);
-				if (next == NULL)
-					break;
-				entry = next;
-			}
-		}
-	}
-	return 0;
-}
-
-int
-cfg_load_subport(struct rte_cfgfile *cfg, struct rte_sched_subport_params *subport_params)
-{
-	const char *entry;
-	int i, j, k;
-
-	if (!cfg || !subport_params)
-		return -1;
-
-	memset(app_pipe_to_profile, -1, sizeof(app_pipe_to_profile));
-
-	for (i = 0; i < MAX_SCHED_SUBPORTS; i++) {
-		char sec_name[CFG_NAME_LEN];
-		snprintf(sec_name, sizeof(sec_name), "subport %d", i);
-
-		if (rte_cfgfile_has_section(cfg, sec_name)) {
-			entry = rte_cfgfile_get_entry(cfg, sec_name, "tb rate");
-			if (entry)
-				subport_params[i].tb_rate = (uint32_t)atoi(entry);
-
-			entry = rte_cfgfile_get_entry(cfg, sec_name, "tb size");
-			if (entry)
-				subport_params[i].tb_size = (uint32_t)atoi(entry);
-
-			entry = rte_cfgfile_get_entry(cfg, sec_name, "tc period");
-			if (entry)
-				subport_params[i].tc_period = (uint32_t)atoi(entry);
-
-			entry = rte_cfgfile_get_entry(cfg, sec_name, "tc 0 rate");
-			if (entry)
-				subport_params[i].tc_rate[0] = (uint32_t)atoi(entry);
-
-			entry = rte_cfgfile_get_entry(cfg, sec_name, "tc 1 rate");
-			if (entry)
-				subport_params[i].tc_rate[1] = (uint32_t)atoi(entry);
-
-			entry = rte_cfgfile_get_entry(cfg, sec_name, "tc 2 rate");
-			if (entry)
-				subport_params[i].tc_rate[2] = (uint32_t)atoi(entry);
-
-			entry = rte_cfgfile_get_entry(cfg, sec_name, "tc 3 rate");
-			if (entry)
-				subport_params[i].tc_rate[3] = (uint32_t)atoi(entry);
-
-			int n_entries = rte_cfgfile_section_num_entries(cfg, sec_name);
-			struct rte_cfgfile_entry entries[n_entries];
-
-			rte_cfgfile_section_entries(cfg, sec_name, entries, n_entries);
-
-			for (j = 0; j < n_entries; j++) {
-				if (strncmp("pipe", entries[j].name, sizeof("pipe") - 1) == 0) {
-					int profile;
-					char *tokens[2] = {NULL, NULL};
-					int n_tokens;
-					int begin, end;
-
-					profile = atoi(entries[j].value);
-					n_tokens = rte_strsplit(&entries[j].name[sizeof("pipe")],
-							strnlen(entries[j].name, CFG_NAME_LEN), tokens, 2, '-');
-
-					begin =  atoi(tokens[0]);
-					if (n_tokens == 2)
-						end = atoi(tokens[1]);
-					else
-						end = begin;
-
-					if (end >= MAX_SCHED_PIPES || begin > end)
-						return -1;
-
-					for (k = begin; k <= end; k++) {
-						char profile_name[CFG_NAME_LEN];
-
-						snprintf(profile_name, sizeof(profile_name),
-								"pipe profile %d", profile);
-						if (rte_cfgfile_has_section(cfg, profile_name))
-							app_pipe_to_profile[i][k] = profile;
-						else
-							rte_exit(EXIT_FAILURE, "Wrong pipe profile %s\n",
-									entries[j].value);
-
-					}
-				}
-			}
-		}
-	}
-
-	return 0;
-}
diff --git a/examples/qos_sched/cfg_file.h b/examples/qos_sched/cfg_file.h
deleted file mode 100644
index 2eccf1c..0000000
--- a/examples/qos_sched/cfg_file.h
+++ /dev/null
@@ -1,17 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#ifndef __CFG_FILE_H__
-#define __CFG_FILE_H__
-
-#include <rte_sched.h>
-#include <rte_cfgfile.h>
-
-int cfg_load_port(struct rte_cfgfile *cfg, struct rte_sched_port_params *port);
-
-int cfg_load_pipe(struct rte_cfgfile *cfg, struct rte_sched_pipe_params *pipe);
-
-int cfg_load_subport(struct rte_cfgfile *cfg, struct rte_sched_subport_params *subport);
-
-#endif
diff --git a/examples/qos_sched/cmdline.c b/examples/qos_sched/cmdline.c
deleted file mode 100644
index 15f5183..0000000
--- a/examples/qos_sched/cmdline.c
+++ /dev/null
@@ -1,614 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdio.h>
-#include <termios.h>
-#include <inttypes.h>
-#include <string.h>
-
-#include <cmdline_rdline.h>
-#include <cmdline_parse.h>
-#include <cmdline_parse_num.h>
-#include <cmdline_parse_string.h>
-#include <cmdline_socket.h>
-#include <cmdline.h>
-
-#include "main.h"
-
-/* *** Help command with introduction. *** */
-struct cmd_help_result {
-	cmdline_fixed_string_t help;
-};
-
-static void cmd_help_parsed(__attribute__((unused)) void *parsed_result,
-                                  struct cmdline *cl,
-                                  __attribute__((unused)) void *data)
-{
-	cmdline_printf(
-		cl,
-		"\n"
-		"The following commands are currently available:\n\n"
-		"Control:\n"
-		"    quit                                      : Quit the application.\n"
-		"\nStatistics:\n"
-		"    stats app                                 : Show app statistics.\n"
-		"    stats port X subport Y                    : Show stats of a specific subport.\n"
-		"    stats port X subport Y pipe Z             : Show stats of a specific pipe.\n"
-		"\nAverage queue size:\n"
-		"    qavg port X subport Y                     : Show average queue size per subport.\n"
-		"    qavg port X subport Y tc Z                : Show average queue size per subport and TC.\n"
-		"    qavg port X subport Y pipe Z              : Show average queue size per pipe.\n"
-		"    qavg port X subport Y pipe Z tc A         : Show average queue size per pipe and TC.\n"
-		"    qavg port X subport Y pipe Z tc A q B     : Show average queue size of a specific queue.\n"
-		"    qavg [n|period] X                     : Set number of times and peiod (us).\n\n"
-	);
-
-}
-
-cmdline_parse_token_string_t cmd_help_help =
-	TOKEN_STRING_INITIALIZER(struct cmd_help_result, help, "help");
-
-cmdline_parse_inst_t cmd_help = {
-	.f = cmd_help_parsed,
-	.data = NULL,
-	.help_str = "show help",
-	.tokens = {
-		(void *)&cmd_help_help,
-		NULL,
-	},
-};
-
-/* *** QUIT *** */
-struct cmd_quit_result {
-	cmdline_fixed_string_t quit;
-};
-
-static void cmd_quit_parsed(__attribute__((unused)) void *parsed_result,
-		struct cmdline *cl,
-		__attribute__((unused)) void *data)
-{
-	cmdline_quit(cl);
-}
-
-cmdline_parse_token_string_t cmd_quit_quit =
-		TOKEN_STRING_INITIALIZER(struct cmd_quit_result, quit, "quit");
-
-cmdline_parse_inst_t cmd_quit = {
-	.f = cmd_quit_parsed,
-	.data = NULL,
-	.help_str = "exit application",
-	.tokens = {
-		(void *)&cmd_quit_quit,
-		NULL,
-		},
-};
-
-/* *** SET QAVG PARAMETERS *** */
-struct cmd_setqavg_result {
-        cmdline_fixed_string_t qavg_string;
-        cmdline_fixed_string_t param_string;
-        uint32_t number;
-};
-
-static void cmd_setqavg_parsed(void *parsed_result,
-                                __attribute__((unused)) struct cmdline *cl,
-                                __attribute__((unused)) void *data)
-{
-        struct cmd_setqavg_result *res = parsed_result;
-
-	if (!strcmp(res->param_string, "period"))
-		qavg_period = res->number;
-	else if (!strcmp(res->param_string, "n"))
-		qavg_ntimes = res->number;
-	else
-		printf("\nUnknown parameter.\n\n");
-}
-
-cmdline_parse_token_string_t cmd_setqavg_qavg_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_setqavg_result, qavg_string,
-                                "qavg");
-cmdline_parse_token_string_t cmd_setqavg_param_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_setqavg_result, param_string,
-                                "period#n");
-cmdline_parse_token_num_t cmd_setqavg_number =
-        TOKEN_NUM_INITIALIZER(struct cmd_setqavg_result, number,
-                                UINT32);
-
-cmdline_parse_inst_t cmd_setqavg = {
-        .f = cmd_setqavg_parsed,
-        .data = NULL,
-        .help_str = "Show subport stats.",
-        .tokens = {
-                (void *)&cmd_setqavg_qavg_string,
-                (void *)&cmd_setqavg_param_string,
-                (void *)&cmd_setqavg_number,
-                NULL,
-        },
-};
-
-/* *** SHOW APP STATS *** */
-struct cmd_appstats_result {
-	cmdline_fixed_string_t stats_string;
-	cmdline_fixed_string_t app_string;
-};
-
-static void cmd_appstats_parsed(__attribute__((unused)) void *parsed_result,
-				__attribute__((unused)) struct cmdline *cl,
-				__attribute__((unused)) void *data)
-{
-	app_stat();
-}
-
-cmdline_parse_token_string_t cmd_appstats_stats_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_appstats_result, stats_string,
-				"stats");
-cmdline_parse_token_string_t cmd_appstats_app_string =
-	TOKEN_STRING_INITIALIZER(struct cmd_appstats_result, app_string,
-				"app");
-
-cmdline_parse_inst_t cmd_appstats = {
-	.f = cmd_appstats_parsed,
-	.data = NULL,
-	.help_str = "Show app stats.",
-	.tokens = {
-		(void *)&cmd_appstats_stats_string,
-		(void *)&cmd_appstats_app_string,
-		NULL,
-	},
-};
-
-/* *** SHOW SUBPORT STATS *** */
-struct cmd_subportstats_result {
-        cmdline_fixed_string_t stats_string;
-        cmdline_fixed_string_t port_string;
-	uint16_t port_number;
-        cmdline_fixed_string_t subport_string;
-        uint32_t subport_number;
-};
-
-static void cmd_subportstats_parsed(void *parsed_result,
-                                __attribute__((unused)) struct cmdline *cl,
-                                __attribute__((unused)) void *data)
-{
-	struct cmd_subportstats_result *res = parsed_result;
-
-	if (subport_stat(res->port_number, res->subport_number) < 0)
-		printf ("\nStats not available for these parameters. Check that both the port and subport are correct.\n\n");
-}
-
-cmdline_parse_token_string_t cmd_subportstats_stats_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_subportstats_result, stats_string,
-                                "stats");
-cmdline_parse_token_string_t cmd_subportstats_port_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_subportstats_result, port_string,
-                                "port");
-cmdline_parse_token_string_t cmd_subportstats_subport_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_subportstats_result, subport_string,
-                                "subport");
-cmdline_parse_token_num_t cmd_subportstats_subport_number =
-        TOKEN_NUM_INITIALIZER(struct cmd_subportstats_result, subport_number,
-                                UINT32);
-cmdline_parse_token_num_t cmd_subportstats_port_number =
-        TOKEN_NUM_INITIALIZER(struct cmd_subportstats_result, port_number,
-			       UINT16);
-
-cmdline_parse_inst_t cmd_subportstats = {
-        .f = cmd_subportstats_parsed,
-        .data = NULL,
-        .help_str = "Show subport stats.",
-        .tokens = {
-                (void *)&cmd_subportstats_stats_string,
-                (void *)&cmd_subportstats_port_string,
-                (void *)&cmd_subportstats_port_number,
-                (void *)&cmd_subportstats_subport_string,
-                (void *)&cmd_subportstats_subport_number,
-                NULL,
-        },
-};
-
-/* *** SHOW PIPE STATS *** */
-struct cmd_pipestats_result {
-        cmdline_fixed_string_t stats_string;
-        cmdline_fixed_string_t port_string;
-	uint16_t port_number;
-        cmdline_fixed_string_t subport_string;
-        uint32_t subport_number;
-        cmdline_fixed_string_t pipe_string;
-        uint32_t pipe_number;
-};
-
-static void cmd_pipestats_parsed(void *parsed_result,
-                                __attribute__((unused)) struct cmdline *cl,
-                                __attribute__((unused)) void *data)
-{
-        struct cmd_pipestats_result *res = parsed_result;
-
-        if (pipe_stat(res->port_number, res->subport_number, res->pipe_number) < 0)
-                printf ("\nStats not available for these parameters. Check that both the port and subport are correct.\n\n");
-}
-
-cmdline_parse_token_string_t cmd_pipestats_stats_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_pipestats_result, stats_string,
-                                "stats");
-cmdline_parse_token_string_t cmd_pipestats_port_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_pipestats_result, port_string,
-                                "port");
-cmdline_parse_token_num_t cmd_pipestats_port_number =
-        TOKEN_NUM_INITIALIZER(struct cmd_pipestats_result, port_number,
-			       UINT16);
-cmdline_parse_token_string_t cmd_pipestats_subport_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_pipestats_result, subport_string,
-                                "subport");
-cmdline_parse_token_num_t cmd_pipestats_subport_number =
-        TOKEN_NUM_INITIALIZER(struct cmd_pipestats_result, subport_number,
-                                UINT32);
-cmdline_parse_token_string_t cmd_pipestats_pipe_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_pipestats_result, pipe_string,
-                                "pipe");
-cmdline_parse_token_num_t cmd_pipestats_pipe_number =
-        TOKEN_NUM_INITIALIZER(struct cmd_pipestats_result, pipe_number,
-                                UINT32);
-
-cmdline_parse_inst_t cmd_pipestats = {
-        .f = cmd_pipestats_parsed,
-        .data = NULL,
-        .help_str = "Show pipe stats.",
-        .tokens = {
-                (void *)&cmd_pipestats_stats_string,
-                (void *)&cmd_pipestats_port_string,
-                (void *)&cmd_pipestats_port_number,
-                (void *)&cmd_pipestats_subport_string,
-                (void *)&cmd_pipestats_subport_number,
-                (void *)&cmd_pipestats_pipe_string,
-                (void *)&cmd_pipestats_pipe_number,
-                NULL,
-        },
-};
-
-/* *** SHOW AVERAGE QUEUE SIZE (QUEUE) *** */
-struct cmd_avg_q_result {
-        cmdline_fixed_string_t qavg_string;
-        cmdline_fixed_string_t port_string;
-	uint16_t port_number;
-        cmdline_fixed_string_t subport_string;
-        uint32_t subport_number;
-        cmdline_fixed_string_t pipe_string;
-        uint32_t pipe_number;
-        cmdline_fixed_string_t tc_string;
-        uint8_t tc_number;
-        cmdline_fixed_string_t q_string;
-        uint8_t q_number;
-};
-
-static void cmd_avg_q_parsed(void *parsed_result,
-                                __attribute__((unused)) struct cmdline *cl,
-                                __attribute__((unused)) void *data)
-{
-        struct cmd_avg_q_result *res = parsed_result;
-
-        if (qavg_q(res->port_number, res->subport_number, res->pipe_number, res->tc_number, res->q_number) < 0)
-                printf ("\nStats not available for these parameters. Check that both the port and subport are correct.\n\n");
-}
-
-cmdline_parse_token_string_t cmd_avg_q_qavg_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_avg_q_result, qavg_string,
-                                "qavg");
-cmdline_parse_token_string_t cmd_avg_q_port_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_avg_q_result, port_string,
-                                "port");
-cmdline_parse_token_num_t cmd_avg_q_port_number =
-	TOKEN_NUM_INITIALIZER(struct cmd_avg_q_result, port_number,
-			       UINT16);
-cmdline_parse_token_string_t cmd_avg_q_subport_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_avg_q_result, subport_string,
-                                "subport");
-cmdline_parse_token_num_t cmd_avg_q_subport_number =
-        TOKEN_NUM_INITIALIZER(struct cmd_avg_q_result, subport_number,
-                                UINT32);
-cmdline_parse_token_string_t cmd_avg_q_pipe_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_avg_q_result, pipe_string,
-                                "pipe");
-cmdline_parse_token_num_t cmd_avg_q_pipe_number =
-        TOKEN_NUM_INITIALIZER(struct cmd_avg_q_result, pipe_number,
-                                UINT32);
-cmdline_parse_token_string_t cmd_avg_q_tc_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_avg_q_result, tc_string,
-                                "tc");
-cmdline_parse_token_num_t cmd_avg_q_tc_number =
-        TOKEN_NUM_INITIALIZER(struct cmd_avg_q_result, tc_number,
-                                UINT8);
-cmdline_parse_token_string_t cmd_avg_q_q_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_avg_q_result, q_string,
-                                "q");
-cmdline_parse_token_num_t cmd_avg_q_q_number =
-        TOKEN_NUM_INITIALIZER(struct cmd_avg_q_result, q_number,
-                                UINT8);
-
-cmdline_parse_inst_t cmd_avg_q = {
-        .f = cmd_avg_q_parsed,
-        .data = NULL,
-        .help_str = "Show pipe stats.",
-        .tokens = {
-                (void *)&cmd_avg_q_qavg_string,
-                (void *)&cmd_avg_q_port_string,
-                (void *)&cmd_avg_q_port_number,
-                (void *)&cmd_avg_q_subport_string,
-                (void *)&cmd_avg_q_subport_number,
-                (void *)&cmd_avg_q_pipe_string,
-                (void *)&cmd_avg_q_pipe_number,
-                (void *)&cmd_avg_q_tc_string,
-                (void *)&cmd_avg_q_tc_number,
-                (void *)&cmd_avg_q_q_string,
-                (void *)&cmd_avg_q_q_number,
-                NULL,
-        },
-};
-
-/* *** SHOW AVERAGE QUEUE SIZE (tc/pipe) *** */
-struct cmd_avg_tcpipe_result {
-        cmdline_fixed_string_t qavg_string;
-        cmdline_fixed_string_t port_string;
-	uint16_t port_number;
-        cmdline_fixed_string_t subport_string;
-        uint32_t subport_number;
-        cmdline_fixed_string_t pipe_string;
-        uint32_t pipe_number;
-        cmdline_fixed_string_t tc_string;
-        uint8_t tc_number;
-};
-
-static void cmd_avg_tcpipe_parsed(void *parsed_result,
-                                __attribute__((unused)) struct cmdline *cl,
-                                __attribute__((unused)) void *data)
-{
-        struct cmd_avg_tcpipe_result *res = parsed_result;
-
-        if (qavg_tcpipe(res->port_number, res->subport_number, res->pipe_number, res->tc_number) < 0)
-                printf ("\nStats not available for these parameters. Check that both the port and subport are correct.\n\n");
-}
-
-cmdline_parse_token_string_t cmd_avg_tcpipe_qavg_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_avg_tcpipe_result, qavg_string,
-                                "qavg");
-cmdline_parse_token_string_t cmd_avg_tcpipe_port_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_avg_tcpipe_result, port_string,
-                                "port");
-cmdline_parse_token_num_t cmd_avg_tcpipe_port_number =
-        TOKEN_NUM_INITIALIZER(struct cmd_avg_tcpipe_result, port_number,
-			       UINT16);
-cmdline_parse_token_string_t cmd_avg_tcpipe_subport_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_avg_tcpipe_result, subport_string,
-                                "subport");
-cmdline_parse_token_num_t cmd_avg_tcpipe_subport_number =
-        TOKEN_NUM_INITIALIZER(struct cmd_avg_tcpipe_result, subport_number,
-                                UINT32);
-cmdline_parse_token_string_t cmd_avg_tcpipe_pipe_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_avg_tcpipe_result, pipe_string,
-                                "pipe");
-cmdline_parse_token_num_t cmd_avg_tcpipe_pipe_number =
-        TOKEN_NUM_INITIALIZER(struct cmd_avg_tcpipe_result, pipe_number,
-                                UINT32);
-cmdline_parse_token_string_t cmd_avg_tcpipe_tc_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_avg_tcpipe_result, tc_string,
-                                "tc");
-cmdline_parse_token_num_t cmd_avg_tcpipe_tc_number =
-        TOKEN_NUM_INITIALIZER(struct cmd_avg_tcpipe_result, tc_number,
-                                UINT8);
-
-cmdline_parse_inst_t cmd_avg_tcpipe = {
-        .f = cmd_avg_tcpipe_parsed,
-        .data = NULL,
-        .help_str = "Show pipe stats.",
-        .tokens = {
-                (void *)&cmd_avg_tcpipe_qavg_string,
-                (void *)&cmd_avg_tcpipe_port_string,
-                (void *)&cmd_avg_tcpipe_port_number,
-                (void *)&cmd_avg_tcpipe_subport_string,
-                (void *)&cmd_avg_tcpipe_subport_number,
-                (void *)&cmd_avg_tcpipe_pipe_string,
-                (void *)&cmd_avg_tcpipe_pipe_number,
-                (void *)&cmd_avg_tcpipe_tc_string,
-                (void *)&cmd_avg_tcpipe_tc_number,
-                NULL,
-        },
-};
-
-/* *** SHOW AVERAGE QUEUE SIZE (pipe) *** */
-struct cmd_avg_pipe_result {
-        cmdline_fixed_string_t qavg_string;
-        cmdline_fixed_string_t port_string;
-	uint16_t port_number;
-        cmdline_fixed_string_t subport_string;
-        uint32_t subport_number;
-        cmdline_fixed_string_t pipe_string;
-        uint32_t pipe_number;
-};
-
-static void cmd_avg_pipe_parsed(void *parsed_result,
-                                __attribute__((unused)) struct cmdline *cl,
-                                __attribute__((unused)) void *data)
-{
-        struct cmd_avg_pipe_result *res = parsed_result;
-
-        if (qavg_pipe(res->port_number, res->subport_number, res->pipe_number) < 0)
-                printf ("\nStats not available for these parameters. Check that both the port and subport are correct.\n\n");
-}
-
-cmdline_parse_token_string_t cmd_avg_pipe_qavg_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_avg_pipe_result, qavg_string,
-                                "qavg");
-cmdline_parse_token_string_t cmd_avg_pipe_port_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_avg_pipe_result, port_string,
-                                "port");
-cmdline_parse_token_num_t cmd_avg_pipe_port_number =
-        TOKEN_NUM_INITIALIZER(struct cmd_avg_pipe_result, port_number,
-			       UINT16);
-cmdline_parse_token_string_t cmd_avg_pipe_subport_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_avg_pipe_result, subport_string,
-                                "subport");
-cmdline_parse_token_num_t cmd_avg_pipe_subport_number =
-        TOKEN_NUM_INITIALIZER(struct cmd_avg_pipe_result, subport_number,
-                                UINT32);
-cmdline_parse_token_string_t cmd_avg_pipe_pipe_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_avg_pipe_result, pipe_string,
-                                "pipe");
-cmdline_parse_token_num_t cmd_avg_pipe_pipe_number =
-        TOKEN_NUM_INITIALIZER(struct cmd_avg_pipe_result, pipe_number,
-                                UINT32);
-
-cmdline_parse_inst_t cmd_avg_pipe = {
-        .f = cmd_avg_pipe_parsed,
-        .data = NULL,
-        .help_str = "Show pipe stats.",
-        .tokens = {
-                (void *)&cmd_avg_pipe_qavg_string,
-                (void *)&cmd_avg_pipe_port_string,
-                (void *)&cmd_avg_pipe_port_number,
-                (void *)&cmd_avg_pipe_subport_string,
-                (void *)&cmd_avg_pipe_subport_number,
-                (void *)&cmd_avg_pipe_pipe_string,
-                (void *)&cmd_avg_pipe_pipe_number,
-                NULL,
-        },
-};
-
-/* *** SHOW AVERAGE QUEUE SIZE (tc/subport) *** */
-struct cmd_avg_tcsubport_result {
-        cmdline_fixed_string_t qavg_string;
-        cmdline_fixed_string_t port_string;
-	uint16_t port_number;
-        cmdline_fixed_string_t subport_string;
-        uint32_t subport_number;
-        cmdline_fixed_string_t tc_string;
-        uint8_t tc_number;
-};
-
-static void cmd_avg_tcsubport_parsed(void *parsed_result,
-                                __attribute__((unused)) struct cmdline *cl,
-                                __attribute__((unused)) void *data)
-{
-        struct cmd_avg_tcsubport_result *res = parsed_result;
-
-        if (qavg_tcsubport(res->port_number, res->subport_number, res->tc_number) < 0)
-                printf ("\nStats not available for these parameters. Check that both the port and subport are correct.\n\n");
-}
-
-cmdline_parse_token_string_t cmd_avg_tcsubport_qavg_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_avg_tcsubport_result, qavg_string,
-                                "qavg");
-cmdline_parse_token_string_t cmd_avg_tcsubport_port_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_avg_tcsubport_result, port_string,
-                                "port");
-cmdline_parse_token_num_t cmd_avg_tcsubport_port_number =
-        TOKEN_NUM_INITIALIZER(struct cmd_avg_tcsubport_result, port_number,
-			       UINT16);
-cmdline_parse_token_string_t cmd_avg_tcsubport_subport_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_avg_tcsubport_result, subport_string,
-                                "subport");
-cmdline_parse_token_num_t cmd_avg_tcsubport_subport_number =
-        TOKEN_NUM_INITIALIZER(struct cmd_avg_tcsubport_result, subport_number,
-                                UINT32);
-cmdline_parse_token_string_t cmd_avg_tcsubport_tc_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_avg_tcsubport_result, tc_string,
-                                "tc");
-cmdline_parse_token_num_t cmd_avg_tcsubport_tc_number =
-        TOKEN_NUM_INITIALIZER(struct cmd_avg_tcsubport_result, tc_number,
-                                UINT8);
-
-cmdline_parse_inst_t cmd_avg_tcsubport = {
-        .f = cmd_avg_tcsubport_parsed,
-        .data = NULL,
-        .help_str = "Show pipe stats.",
-        .tokens = {
-                (void *)&cmd_avg_tcsubport_qavg_string,
-                (void *)&cmd_avg_tcsubport_port_string,
-                (void *)&cmd_avg_tcsubport_port_number,
-                (void *)&cmd_avg_tcsubport_subport_string,
-                (void *)&cmd_avg_tcsubport_subport_number,
-                (void *)&cmd_avg_tcsubport_tc_string,
-                (void *)&cmd_avg_tcsubport_tc_number,
-                NULL,
-        },
-};
-
-/* *** SHOW AVERAGE QUEUE SIZE (subport) *** */
-struct cmd_avg_subport_result {
-        cmdline_fixed_string_t qavg_string;
-        cmdline_fixed_string_t port_string;
-	uint16_t port_number;
-        cmdline_fixed_string_t subport_string;
-        uint32_t subport_number;
-};
-
-static void cmd_avg_subport_parsed(void *parsed_result,
-                                __attribute__((unused)) struct cmdline *cl,
-                                __attribute__((unused)) void *data)
-{
-        struct cmd_avg_subport_result *res = parsed_result;
-
-        if (qavg_subport(res->port_number, res->subport_number) < 0)
-                printf ("\nStats not available for these parameters. Check that both the port and subport are correct.\n\n");
-}
-
-cmdline_parse_token_string_t cmd_avg_subport_qavg_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_avg_subport_result, qavg_string,
-                                "qavg");
-cmdline_parse_token_string_t cmd_avg_subport_port_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_avg_subport_result, port_string,
-                                "port");
-cmdline_parse_token_num_t cmd_avg_subport_port_number =
-        TOKEN_NUM_INITIALIZER(struct cmd_avg_subport_result, port_number,
-			       UINT16);
-cmdline_parse_token_string_t cmd_avg_subport_subport_string =
-        TOKEN_STRING_INITIALIZER(struct cmd_avg_subport_result, subport_string,
-                                "subport");
-cmdline_parse_token_num_t cmd_avg_subport_subport_number =
-        TOKEN_NUM_INITIALIZER(struct cmd_avg_subport_result, subport_number,
-                                UINT32);
-
-cmdline_parse_inst_t cmd_avg_subport = {
-        .f = cmd_avg_subport_parsed,
-        .data = NULL,
-        .help_str = "Show pipe stats.",
-        .tokens = {
-                (void *)&cmd_avg_subport_qavg_string,
-                (void *)&cmd_avg_subport_port_string,
-                (void *)&cmd_avg_subport_port_number,
-                (void *)&cmd_avg_subport_subport_string,
-                (void *)&cmd_avg_subport_subport_number,
-                NULL,
-        },
-};
-
-/* ******************************************************************************** */
-
-/* list of instructions */
-cmdline_parse_ctx_t main_ctx[] = {
-	(cmdline_parse_inst_t *)&cmd_help,
-	(cmdline_parse_inst_t *)&cmd_setqavg,
-	(cmdline_parse_inst_t *)&cmd_appstats,
-	(cmdline_parse_inst_t *)&cmd_subportstats,
-        (cmdline_parse_inst_t *)&cmd_pipestats,
-	(cmdline_parse_inst_t *)&cmd_avg_q,
-	(cmdline_parse_inst_t *)&cmd_avg_tcpipe,
-	(cmdline_parse_inst_t *)&cmd_avg_pipe,
-	(cmdline_parse_inst_t *)&cmd_avg_tcsubport,
-	(cmdline_parse_inst_t *)&cmd_avg_subport,
-	(cmdline_parse_inst_t *)&cmd_quit,
-	NULL,
-};
-
-/* prompt function, called from main on MASTER lcore */
-void
-prompt(void)
-{
-	struct cmdline *cl;
-
-	cl = cmdline_stdin_new(main_ctx, "qos_sched> ");
-	if (cl == NULL) {
-		return;
-	}
-	cmdline_interact(cl);
-	cmdline_stdin_exit(cl);
-}
diff --git a/examples/qos_sched/init.c b/examples/qos_sched/init.c
deleted file mode 100644
index 8914f76..0000000
--- a/examples/qos_sched/init.c
+++ /dev/null
@@ -1,364 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdint.h>
-#include <memory.h>
-
-#include <rte_log.h>
-#include <rte_mbuf.h>
-#include <rte_debug.h>
-#include <rte_ethdev.h>
-#include <rte_mempool.h>
-#include <rte_sched.h>
-#include <rte_cycles.h>
-#include <rte_string_fns.h>
-#include <rte_cfgfile.h>
-
-#include "main.h"
-#include "cfg_file.h"
-
-uint32_t app_numa_mask = 0;
-static uint32_t app_inited_port_mask = 0;
-
-int app_pipe_to_profile[MAX_SCHED_SUBPORTS][MAX_SCHED_PIPES];
-
-#define MAX_NAME_LEN 32
-
-struct ring_conf ring_conf = {
-	.rx_size   = APP_RX_DESC_DEFAULT,
-	.ring_size = APP_RING_SIZE,
-	.tx_size   = APP_TX_DESC_DEFAULT,
-};
-
-struct burst_conf burst_conf = {
-	.rx_burst    = MAX_PKT_RX_BURST,
-	.ring_burst  = PKT_ENQUEUE,
-	.qos_dequeue = PKT_DEQUEUE,
-	.tx_burst    = MAX_PKT_TX_BURST,
-};
-
-struct ring_thresh rx_thresh = {
-	.pthresh = RX_PTHRESH,
-	.hthresh = RX_HTHRESH,
-	.wthresh = RX_WTHRESH,
-};
-
-struct ring_thresh tx_thresh = {
-	.pthresh = TX_PTHRESH,
-	.hthresh = TX_HTHRESH,
-	.wthresh = TX_WTHRESH,
-};
-
-uint32_t nb_pfc;
-const char *cfg_profile = NULL;
-int mp_size = NB_MBUF;
-struct flow_conf qos_conf[MAX_DATA_STREAMS];
-
-static struct rte_eth_conf port_conf = {
-	.rxmode = {
-		.max_rx_pkt_len = ETHER_MAX_LEN,
-		.split_hdr_size = 0,
-		.ignore_offload_bitfield = 1,
-		.offloads = DEV_RX_OFFLOAD_CRC_STRIP,
-	},
-	.txmode = {
-		.mq_mode = ETH_DCB_NONE,
-	},
-};
-
-static int
-app_init_port(uint16_t portid, struct rte_mempool *mp)
-{
-	int ret;
-	struct rte_eth_link link;
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_rxconf rx_conf;
-	struct rte_eth_txconf tx_conf;
-	uint16_t rx_size;
-	uint16_t tx_size;
-	struct rte_eth_conf local_port_conf = port_conf;
-
-	/* check if port already initialized (multistream configuration) */
-	if (app_inited_port_mask & (1u << portid))
-		return 0;
-
-	rx_conf.rx_thresh.pthresh = rx_thresh.pthresh;
-	rx_conf.rx_thresh.hthresh = rx_thresh.hthresh;
-	rx_conf.rx_thresh.wthresh = rx_thresh.wthresh;
-	rx_conf.rx_free_thresh = 32;
-	rx_conf.rx_drop_en = 0;
-	rx_conf.rx_deferred_start = 0;
-
-	tx_conf.tx_thresh.pthresh = tx_thresh.pthresh;
-	tx_conf.tx_thresh.hthresh = tx_thresh.hthresh;
-	tx_conf.tx_thresh.wthresh = tx_thresh.wthresh;
-	tx_conf.tx_free_thresh = 0;
-	tx_conf.tx_rs_thresh = 0;
-	tx_conf.tx_deferred_start = 0;
-	tx_conf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-
-	/* init port */
-	RTE_LOG(INFO, APP, "Initializing port %"PRIu16"... ", portid);
-	fflush(stdout);
-	rte_eth_dev_info_get(portid, &dev_info);
-	if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-		local_port_conf.txmode.offloads |=
-			DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-	ret = rte_eth_dev_configure(portid, 1, 1, &local_port_conf);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE,
-			 "Cannot configure device: err=%d, port=%u\n",
-			 ret, portid);
-
-	rx_size = ring_conf.rx_size;
-	tx_size = ring_conf.tx_size;
-	ret = rte_eth_dev_adjust_nb_rx_tx_desc(portid, &rx_size, &tx_size);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE,
-			 "rte_eth_dev_adjust_nb_rx_tx_desc: err=%d,port=%u\n",
-			 ret, portid);
-	ring_conf.rx_size = rx_size;
-	ring_conf.tx_size = tx_size;
-
-	/* init one RX queue */
-	fflush(stdout);
-	rx_conf.offloads = local_port_conf.rxmode.offloads;
-	ret = rte_eth_rx_queue_setup(portid, 0, (uint16_t)ring_conf.rx_size,
-		rte_eth_dev_socket_id(portid), &rx_conf, mp);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE,
-			 "rte_eth_tx_queue_setup: err=%d, port=%u\n",
-			 ret, portid);
-
-	/* init one TX queue */
-	fflush(stdout);
-	tx_conf.offloads = local_port_conf.txmode.offloads;
-	ret = rte_eth_tx_queue_setup(portid, 0,
-		(uint16_t)ring_conf.tx_size, rte_eth_dev_socket_id(portid), &tx_conf);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE,
-			 "rte_eth_tx_queue_setup: err=%d, port=%u queue=%d\n",
-			 ret, portid, 0);
-
-	/* Start device */
-	ret = rte_eth_dev_start(portid);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE,
-			 "rte_pmd_port_start: err=%d, port=%u\n",
-			 ret, portid);
-
-	printf("done: ");
-
-	/* get link status */
-	rte_eth_link_get(portid, &link);
-	if (link.link_status) {
-		printf(" Link Up - speed %u Mbps - %s\n",
-			(uint32_t) link.link_speed,
-			(link.link_duplex == ETH_LINK_FULL_DUPLEX) ?
-			("full-duplex") : ("half-duplex\n"));
-	} else {
-		printf(" Link Down\n");
-	}
-	rte_eth_promiscuous_enable(portid);
-
-	/* mark port as initialized */
-	app_inited_port_mask |= 1u << portid;
-
-	return 0;
-}
-
-static struct rte_sched_subport_params subport_params[MAX_SCHED_SUBPORTS] = {
-	{
-		.tb_rate = 1250000000,
-		.tb_size = 1000000,
-
-		.tc_rate = {1250000000, 1250000000, 1250000000, 1250000000},
-		.tc_period = 10,
-	},
-};
-
-static struct rte_sched_pipe_params pipe_profiles[RTE_SCHED_PIPE_PROFILES_PER_PORT] = {
-	{ /* Profile #0 */
-		.tb_rate = 305175,
-		.tb_size = 1000000,
-
-		.tc_rate = {305175, 305175, 305175, 305175},
-		.tc_period = 40,
-#ifdef RTE_SCHED_SUBPORT_TC_OV
-		.tc_ov_weight = 1,
-#endif
-
-		.wrr_weights = {1, 1, 1, 1,  1, 1, 1, 1,  1, 1, 1, 1,  1, 1, 1, 1},
-	},
-};
-
-struct rte_sched_port_params port_params = {
-	.name = "port_scheduler_0",
-	.socket = 0, /* computed */
-	.rate = 0, /* computed */
-	.mtu = 6 + 6 + 4 + 4 + 2 + 1500,
-	.frame_overhead = RTE_SCHED_FRAME_OVERHEAD_DEFAULT,
-	.n_subports_per_port = 1,
-	.n_pipes_per_subport = 4096,
-	.qsize = {64, 64, 64, 64},
-	.pipe_profiles = pipe_profiles,
-	.n_pipe_profiles = sizeof(pipe_profiles) / sizeof(struct rte_sched_pipe_params),
-
-#ifdef RTE_SCHED_RED
-	.red_params = {
-		/* Traffic Class 0 Colors Green / Yellow / Red */
-		[0][0] = {.min_th = 48, .max_th = 64, .maxp_inv = 10, .wq_log2 = 9},
-		[0][1] = {.min_th = 40, .max_th = 64, .maxp_inv = 10, .wq_log2 = 9},
-		[0][2] = {.min_th = 32, .max_th = 64, .maxp_inv = 10, .wq_log2 = 9},
-
-		/* Traffic Class 1 - Colors Green / Yellow / Red */
-		[1][0] = {.min_th = 48, .max_th = 64, .maxp_inv = 10, .wq_log2 = 9},
-		[1][1] = {.min_th = 40, .max_th = 64, .maxp_inv = 10, .wq_log2 = 9},
-		[1][2] = {.min_th = 32, .max_th = 64, .maxp_inv = 10, .wq_log2 = 9},
-
-		/* Traffic Class 2 - Colors Green / Yellow / Red */
-		[2][0] = {.min_th = 48, .max_th = 64, .maxp_inv = 10, .wq_log2 = 9},
-		[2][1] = {.min_th = 40, .max_th = 64, .maxp_inv = 10, .wq_log2 = 9},
-		[2][2] = {.min_th = 32, .max_th = 64, .maxp_inv = 10, .wq_log2 = 9},
-
-		/* Traffic Class 3 - Colors Green / Yellow / Red */
-		[3][0] = {.min_th = 48, .max_th = 64, .maxp_inv = 10, .wq_log2 = 9},
-		[3][1] = {.min_th = 40, .max_th = 64, .maxp_inv = 10, .wq_log2 = 9},
-		[3][2] = {.min_th = 32, .max_th = 64, .maxp_inv = 10, .wq_log2 = 9}
-	}
-#endif /* RTE_SCHED_RED */
-};
-
-static struct rte_sched_port *
-app_init_sched_port(uint32_t portid, uint32_t socketid)
-{
-	static char port_name[32]; /* static as referenced from global port_params*/
-	struct rte_eth_link link;
-	struct rte_sched_port *port = NULL;
-	uint32_t pipe, subport;
-	int err;
-
-	rte_eth_link_get(portid, &link);
-
-	port_params.socket = socketid;
-	port_params.rate = (uint64_t) link.link_speed * 1000 * 1000 / 8;
-	snprintf(port_name, sizeof(port_name), "port_%d", portid);
-	port_params.name = port_name;
-
-	port = rte_sched_port_config(&port_params);
-	if (port == NULL){
-		rte_exit(EXIT_FAILURE, "Unable to config sched port\n");
-	}
-
-	for (subport = 0; subport < port_params.n_subports_per_port; subport ++) {
-		err = rte_sched_subport_config(port, subport, &subport_params[subport]);
-		if (err) {
-			rte_exit(EXIT_FAILURE, "Unable to config sched subport %u, err=%d\n",
-					subport, err);
-		}
-
-		for (pipe = 0; pipe < port_params.n_pipes_per_subport; pipe ++) {
-			if (app_pipe_to_profile[subport][pipe] != -1) {
-				err = rte_sched_pipe_config(port, subport, pipe,
-						app_pipe_to_profile[subport][pipe]);
-				if (err) {
-					rte_exit(EXIT_FAILURE, "Unable to config sched pipe %u "
-							"for profile %d, err=%d\n", pipe,
-							app_pipe_to_profile[subport][pipe], err);
-				}
-			}
-		}
-	}
-
-	return port;
-}
-
-static int
-app_load_cfg_profile(const char *profile)
-{
-	if (profile == NULL)
-		return 0;
-	struct rte_cfgfile *file = rte_cfgfile_load(profile, 0);
-	if (file == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot load configuration profile %s\n", profile);
-
-	cfg_load_port(file, &port_params);
-	cfg_load_subport(file, subport_params);
-	cfg_load_pipe(file, pipe_profiles);
-
-	rte_cfgfile_close(file);
-
-	return 0;
-}
-
-int app_init(void)
-{
-	uint32_t i;
-	char ring_name[MAX_NAME_LEN];
-	char pool_name[MAX_NAME_LEN];
-
-	if (rte_eth_dev_count() == 0)
-		rte_exit(EXIT_FAILURE, "No Ethernet port - bye\n");
-
-	/* load configuration profile */
-	if (app_load_cfg_profile(cfg_profile) != 0)
-		rte_exit(EXIT_FAILURE, "Invalid configuration profile\n");
-
-	/* Initialize each active flow */
-	for(i = 0; i < nb_pfc; i++) {
-		uint32_t socket = rte_lcore_to_socket_id(qos_conf[i].rx_core);
-		struct rte_ring *ring;
-
-		snprintf(ring_name, MAX_NAME_LEN, "ring-%u-%u", i, qos_conf[i].rx_core);
-		ring = rte_ring_lookup(ring_name);
-		if (ring == NULL)
-			qos_conf[i].rx_ring = rte_ring_create(ring_name, ring_conf.ring_size,
-			 	socket, RING_F_SP_ENQ | RING_F_SC_DEQ);
-		else
-			qos_conf[i].rx_ring = ring;
-
-		snprintf(ring_name, MAX_NAME_LEN, "ring-%u-%u", i, qos_conf[i].tx_core);
-		ring = rte_ring_lookup(ring_name);
-		if (ring == NULL)
-			qos_conf[i].tx_ring = rte_ring_create(ring_name, ring_conf.ring_size,
-				socket, RING_F_SP_ENQ | RING_F_SC_DEQ);
-		else
-			qos_conf[i].tx_ring = ring;
-
-
-		/* create the mbuf pools for each RX Port */
-		snprintf(pool_name, MAX_NAME_LEN, "mbuf_pool%u", i);
-		qos_conf[i].mbuf_pool = rte_pktmbuf_pool_create(pool_name,
-			mp_size, burst_conf.rx_burst * 4, 0,
-			RTE_MBUF_DEFAULT_BUF_SIZE,
-			rte_eth_dev_socket_id(qos_conf[i].rx_port));
-		if (qos_conf[i].mbuf_pool == NULL)
-			rte_exit(EXIT_FAILURE, "Cannot init mbuf pool for socket %u\n", i);
-
-		app_init_port(qos_conf[i].rx_port, qos_conf[i].mbuf_pool);
-		app_init_port(qos_conf[i].tx_port, qos_conf[i].mbuf_pool);
-
-		qos_conf[i].sched_port = app_init_sched_port(qos_conf[i].tx_port, socket);
-	}
-
-	RTE_LOG(INFO, APP, "time stamp clock running at %" PRIu64 " Hz\n",
-			 rte_get_timer_hz());
-
-	RTE_LOG(INFO, APP, "Ring sizes: NIC RX = %u, Mempool = %d SW queue = %u,"
-			 "NIC TX = %u\n", ring_conf.rx_size, mp_size, ring_conf.ring_size,
-			 ring_conf.tx_size);
-
-	RTE_LOG(INFO, APP, "Burst sizes: RX read = %hu, RX write = %hu,\n"
-						  "             Worker read/QoS enqueue = %hu,\n"
-						  "             QoS dequeue = %hu, Worker write = %hu\n",
-		burst_conf.rx_burst, burst_conf.ring_burst, burst_conf.ring_burst,
-		burst_conf.qos_dequeue, burst_conf.tx_burst);
-
-	RTE_LOG(INFO, APP, "NIC thresholds RX (p = %hhu, h = %hhu, w = %hhu),"
-				 "TX (p = %hhu, h = %hhu, w = %hhu)\n",
-		rx_thresh.pthresh, rx_thresh.hthresh, rx_thresh.wthresh,
-		tx_thresh.pthresh, tx_thresh.hthresh, tx_thresh.wthresh);
-
-	return 0;
-}
diff --git a/examples/qos_sched/main.c b/examples/qos_sched/main.c
deleted file mode 100644
index e7c97bd..0000000
--- a/examples/qos_sched/main.c
+++ /dev/null
@@ -1,221 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <unistd.h>
-#include <stdint.h>
-
-#include <rte_log.h>
-#include <rte_mbuf.h>
-#include <rte_malloc.h>
-#include <rte_cycles.h>
-#include <rte_ethdev.h>
-#include <rte_memcpy.h>
-#include <rte_byteorder.h>
-#include <rte_branch_prediction.h>
-
-#include <rte_sched.h>
-
-#include "main.h"
-
-#define APP_MODE_NONE 0
-#define APP_RX_MODE   1
-#define APP_WT_MODE   2
-#define APP_TX_MODE   4
-
-uint8_t interactive = APP_INTERACTIVE_DEFAULT;
-uint32_t qavg_period = APP_QAVG_PERIOD;
-uint32_t qavg_ntimes = APP_QAVG_NTIMES;
-
-/* main processing loop */
-static int
-app_main_loop(__attribute__((unused))void *dummy)
-{
-	uint32_t lcore_id;
-	uint32_t i, mode;
-	uint32_t rx_idx = 0;
-	uint32_t wt_idx = 0;
-	uint32_t tx_idx = 0;
-	struct thread_conf *rx_confs[MAX_DATA_STREAMS];
-	struct thread_conf *wt_confs[MAX_DATA_STREAMS];
-	struct thread_conf *tx_confs[MAX_DATA_STREAMS];
-
-	memset(rx_confs, 0, sizeof(rx_confs));
-	memset(wt_confs, 0, sizeof(wt_confs));
-	memset(tx_confs, 0, sizeof(tx_confs));
-
-
-	mode = APP_MODE_NONE;
-	lcore_id = rte_lcore_id();
-
-	for (i = 0; i < nb_pfc; i++) {
-		struct flow_conf *flow = &qos_conf[i];
-
-		if (flow->rx_core == lcore_id) {
-			flow->rx_thread.rx_port = flow->rx_port;
-			flow->rx_thread.rx_ring =  flow->rx_ring;
-			flow->rx_thread.rx_queue = flow->rx_queue;
-
-			rx_confs[rx_idx++] = &flow->rx_thread;
-
-			mode |= APP_RX_MODE;
-		}
-		if (flow->tx_core == lcore_id) {
-			flow->tx_thread.tx_port = flow->tx_port;
-			flow->tx_thread.tx_ring =  flow->tx_ring;
-			flow->tx_thread.tx_queue = flow->tx_queue;
-
-			tx_confs[tx_idx++] = &flow->tx_thread;
-
-			mode |= APP_TX_MODE;
-		}
-		if (flow->wt_core == lcore_id) {
-			flow->wt_thread.rx_ring =  flow->rx_ring;
-			flow->wt_thread.tx_ring =  flow->tx_ring;
-			flow->wt_thread.tx_port =  flow->tx_port;
-			flow->wt_thread.sched_port =  flow->sched_port;
-
-			wt_confs[wt_idx++] = &flow->wt_thread;
-
-			mode |= APP_WT_MODE;
-		}
-	}
-
-	if (mode == APP_MODE_NONE) {
-		RTE_LOG(INFO, APP, "lcore %u has nothing to do\n", lcore_id);
-		return -1;
-	}
-
-	if (mode == (APP_RX_MODE | APP_WT_MODE)) {
-		RTE_LOG(INFO, APP, "lcore %u was configured for both RX and WT !!!\n",
-				 lcore_id);
-		return -1;
-	}
-
-	RTE_LOG(INFO, APP, "entering main loop on lcore %u\n", lcore_id);
-	/* initialize mbuf memory */
-	if (mode == APP_RX_MODE) {
-		for (i = 0; i < rx_idx; i++) {
-			RTE_LOG(INFO, APP, "flow%u lcoreid%u reading port%u\n",
-					i, lcore_id, rx_confs[i]->rx_port);
-		}
-
-		app_rx_thread(rx_confs);
-	}
-	else if (mode == (APP_TX_MODE | APP_WT_MODE)) {
-		for (i = 0; i < wt_idx; i++) {
-			wt_confs[i]->m_table = rte_malloc("table_wt", sizeof(struct rte_mbuf *)
-					* burst_conf.tx_burst, RTE_CACHE_LINE_SIZE);
-
-			if (wt_confs[i]->m_table == NULL)
-				rte_panic("flow %u unable to allocate memory buffer\n", i);
-
-			RTE_LOG(INFO, APP,
-				"flow %u lcoreid %u sched+write port %u\n",
-					i, lcore_id, wt_confs[i]->tx_port);
-		}
-
-		app_mixed_thread(wt_confs);
-	}
-	else if (mode == APP_TX_MODE) {
-		for (i = 0; i < tx_idx; i++) {
-			tx_confs[i]->m_table = rte_malloc("table_tx", sizeof(struct rte_mbuf *)
-					* burst_conf.tx_burst, RTE_CACHE_LINE_SIZE);
-
-			if (tx_confs[i]->m_table == NULL)
-				rte_panic("flow %u unable to allocate memory buffer\n", i);
-
-			RTE_LOG(INFO, APP, "flow%u lcoreid%u write port%u\n",
-					i, lcore_id, tx_confs[i]->tx_port);
-		}
-
-		app_tx_thread(tx_confs);
-	}
-	else if (mode == APP_WT_MODE){
-		for (i = 0; i < wt_idx; i++) {
-			RTE_LOG(INFO, APP, "flow %u lcoreid %u scheduling \n", i, lcore_id);
-		}
-
-		app_worker_thread(wt_confs);
-	}
-
-	return 0;
-}
-
-void
-app_stat(void)
-{
-	uint32_t i;
-	struct rte_eth_stats stats;
-	static struct rte_eth_stats rx_stats[MAX_DATA_STREAMS];
-	static struct rte_eth_stats tx_stats[MAX_DATA_STREAMS];
-
-	/* print statistics */
-	for(i = 0; i < nb_pfc; i++) {
-		struct flow_conf *flow = &qos_conf[i];
-
-		rte_eth_stats_get(flow->rx_port, &stats);
-		printf("\nRX port %"PRIu16": rx: %"PRIu64 " err: %"PRIu64
-				" no_mbuf: %"PRIu64 "\n",
-				flow->rx_port,
-				stats.ipackets - rx_stats[i].ipackets,
-				stats.ierrors - rx_stats[i].ierrors,
-				stats.rx_nombuf - rx_stats[i].rx_nombuf);
-		memcpy(&rx_stats[i], &stats, sizeof(stats));
-
-		rte_eth_stats_get(flow->tx_port, &stats);
-		printf("TX port %"PRIu16": tx: %" PRIu64 " err: %" PRIu64 "\n",
-				flow->tx_port,
-				stats.opackets - tx_stats[i].opackets,
-				stats.oerrors - tx_stats[i].oerrors);
-		memcpy(&tx_stats[i], &stats, sizeof(stats));
-
-#if APP_COLLECT_STAT
-		printf("-------+------------+------------+\n");
-		printf("       |  received  |   dropped  |\n");
-		printf("-------+------------+------------+\n");
-		printf("  RX   | %10" PRIu64 " | %10" PRIu64 " |\n",
-			flow->rx_thread.stat.nb_rx,
-			flow->rx_thread.stat.nb_drop);
-		printf("QOS+TX | %10" PRIu64 " | %10" PRIu64 " |   pps: %"PRIu64 " \n",
-			flow->wt_thread.stat.nb_rx,
-			flow->wt_thread.stat.nb_drop,
-			flow->wt_thread.stat.nb_rx - flow->wt_thread.stat.nb_drop);
-		printf("-------+------------+------------+\n");
-
-		memset(&flow->rx_thread.stat, 0, sizeof(struct thread_stat));
-		memset(&flow->wt_thread.stat, 0, sizeof(struct thread_stat));
-#endif
-	}
-}
-
-int
-main(int argc, char **argv)
-{
-	int ret;
-
-	ret = app_parse_args(argc, argv);
-	if (ret < 0)
-		return -1;
-
-	ret = app_init();
-	if (ret < 0)
-		return -1;
-
-	/* launch per-lcore init on every lcore */
-	rte_eal_mp_remote_launch(app_main_loop, NULL, SKIP_MASTER);
-
-	if (interactive) {
-		sleep(1);
-		prompt();
-	}
-	else {
-		/* print statistics every second */
-		while(1) {
-			sleep(1);
-			app_stat();
-		}
-	}
-
-	return 0;
-}
diff --git a/examples/qos_sched/main.h b/examples/qos_sched/main.h
deleted file mode 100644
index 8a2741c..0000000
--- a/examples/qos_sched/main.h
+++ /dev/null
@@ -1,176 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#ifndef _MAIN_H_
-#define _MAIN_H_
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-#include <rte_sched.h>
-
-#define RTE_LOGTYPE_APP RTE_LOGTYPE_USER1
-
-/*
- * Configurable number of RX/TX ring descriptors
- */
-#define APP_INTERACTIVE_DEFAULT 0
-
-#define APP_RX_DESC_DEFAULT 1024
-#define APP_TX_DESC_DEFAULT 1024
-
-#define APP_RING_SIZE (8*1024)
-#define NB_MBUF   (2*1024*1024)
-
-#define MAX_PKT_RX_BURST 64
-#define PKT_ENQUEUE 64
-#define PKT_DEQUEUE 32
-#define MAX_PKT_TX_BURST 64
-
-#define RX_PTHRESH 8 /**< Default values of RX prefetch threshold reg. */
-#define RX_HTHRESH 8 /**< Default values of RX host threshold reg. */
-#define RX_WTHRESH 4 /**< Default values of RX write-back threshold reg. */
-
-#define TX_PTHRESH 36 /**< Default values of TX prefetch threshold reg. */
-#define TX_HTHRESH 0  /**< Default values of TX host threshold reg. */
-#define TX_WTHRESH 0  /**< Default values of TX write-back threshold reg. */
-
-#define BURST_TX_DRAIN_US 100
-
-#ifndef APP_MAX_LCORE
-#if (RTE_MAX_LCORE > 64)
-#define APP_MAX_LCORE 64
-#else
-#define APP_MAX_LCORE RTE_MAX_LCORE
-#endif
-#endif
-
-#define MAX_DATA_STREAMS (APP_MAX_LCORE/2)
-#define MAX_SCHED_SUBPORTS		8
-#define MAX_SCHED_PIPES		4096
-
-#ifndef APP_COLLECT_STAT
-#define APP_COLLECT_STAT		1
-#endif
-
-#if APP_COLLECT_STAT
-#define APP_STATS_ADD(stat,val) (stat) += (val)
-#else
-#define APP_STATS_ADD(stat,val) do {(void) (val);} while (0)
-#endif
-
-#define APP_QAVG_NTIMES 10
-#define APP_QAVG_PERIOD 100
-
-struct thread_stat
-{
-	uint64_t nb_rx;
-	uint64_t nb_drop;
-};
-
-
-struct thread_conf
-{
-	uint32_t counter;
-	uint32_t n_mbufs;
-	struct rte_mbuf **m_table;
-
-	uint16_t rx_port;
-	uint16_t tx_port;
-	uint16_t rx_queue;
-	uint16_t tx_queue;
-	struct rte_ring *rx_ring;
-	struct rte_ring *tx_ring;
-	struct rte_sched_port *sched_port;
-
-#if APP_COLLECT_STAT
-	struct thread_stat stat;
-#endif
-} __rte_cache_aligned;
-
-
-struct flow_conf
-{
-	uint32_t rx_core;
-	uint32_t wt_core;
-	uint32_t tx_core;
-	uint16_t rx_port;
-	uint16_t tx_port;
-	uint16_t rx_queue;
-	uint16_t tx_queue;
-	struct rte_ring *rx_ring;
-	struct rte_ring *tx_ring;
-	struct rte_sched_port *sched_port;
-	struct rte_mempool *mbuf_pool;
-
-	struct thread_conf rx_thread;
-	struct thread_conf wt_thread;
-	struct thread_conf tx_thread;
-};
-
-
-struct ring_conf
-{
-	uint32_t rx_size;
-	uint32_t ring_size;
-	uint32_t tx_size;
-};
-
-struct burst_conf
-{
-	uint16_t rx_burst;
-	uint16_t ring_burst;
-	uint16_t qos_dequeue;
-	uint16_t tx_burst;
-};
-
-struct ring_thresh
-{
-	uint8_t pthresh; /**< Ring prefetch threshold. */
-	uint8_t hthresh; /**< Ring host threshold. */
-	uint8_t wthresh; /**< Ring writeback threshold. */
-};
-
-extern uint8_t interactive;
-extern uint32_t qavg_period;
-extern uint32_t qavg_ntimes;
-extern uint32_t nb_pfc;
-extern const char *cfg_profile;
-extern int mp_size;
-extern struct flow_conf qos_conf[];
-extern int app_pipe_to_profile[MAX_SCHED_SUBPORTS][MAX_SCHED_PIPES];
-
-extern struct ring_conf ring_conf;
-extern struct burst_conf burst_conf;
-extern struct ring_thresh rx_thresh;
-extern struct ring_thresh tx_thresh;
-
-extern struct rte_sched_port_params port_params;
-
-int app_parse_args(int argc, char **argv);
-int app_init(void);
-
-void prompt(void);
-void app_rx_thread(struct thread_conf **qconf);
-void app_tx_thread(struct thread_conf **qconf);
-void app_worker_thread(struct thread_conf **qconf);
-void app_mixed_thread(struct thread_conf **qconf);
-
-void app_stat(void);
-int subport_stat(uint16_t port_id, uint32_t subport_id);
-int pipe_stat(uint16_t port_id, uint32_t subport_id, uint32_t pipe_id);
-int qavg_q(uint16_t port_id, uint32_t subport_id, uint32_t pipe_id,
-	   uint8_t tc, uint8_t q);
-int qavg_tcpipe(uint16_t port_id, uint32_t subport_id, uint32_t pipe_id,
-		uint8_t tc);
-int qavg_pipe(uint16_t port_id, uint32_t subport_id, uint32_t pipe_id);
-int qavg_tcsubport(uint16_t port_id, uint32_t subport_id, uint8_t tc);
-int qavg_subport(uint16_t port_id, uint32_t subport_id);
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif /* _MAIN_H_ */
diff --git a/examples/qos_sched/meson.build b/examples/qos_sched/meson.build
deleted file mode 100644
index 289b81c..0000000
--- a/examples/qos_sched/meson.build
+++ /dev/null
@@ -1,13 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-deps += ['sched', 'cfgfile']
-sources = files(
-	'app_thread.c', 'args.c', 'cfg_file.c', 'cmdline.c',
-	'init.c', 'main.c', 'stats.c'
-)
diff --git a/examples/qos_sched/profile.cfg b/examples/qos_sched/profile.cfg
deleted file mode 100644
index f5b704c..0000000
--- a/examples/qos_sched/profile.cfg
+++ /dev/null
@@ -1,104 +0,0 @@
-;   BSD LICENSE
-;
-;   Copyright(c) 2010-2014 Intel Corporation. All rights reserved.
-;   All rights reserved.
-;
-;   Redistribution and use in source and binary forms, with or without
-;   modification, are permitted provided that the following conditions
-;   are met:
-;
-;     * Redistributions of source code must retain the above copyright
-;       notice, this list of conditions and the following disclaimer.
-;     * Redistributions in binary form must reproduce the above copyright
-;       notice, this list of conditions and the following disclaimer in
-;       the documentation and/or other materials provided with the
-;       distribution.
-;     * Neither the name of Intel Corporation nor the names of its
-;       contributors may be used to endorse or promote products derived
-;       from this software without specific prior written permission.
-;
-;   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-;   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-;   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-;   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-;   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-;   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-;   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-;   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-;   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-;   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-;   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-; This file enables the following hierarchical scheduler configuration for each
-; 10GbE output port:
-;	* Single subport (subport 0):
-;		- Subport rate set to 100% of port rate
-;		- Each of the 4 traffic classes has rate set to 100% of port rate
-;	* 4K pipes per subport 0 (pipes 0 .. 4095) with identical configuration:
-;		- Pipe rate set to 1/4K of port rate
-;		- Each of the 4 traffic classes has rate set to 100% of pipe rate
-;		- Within each traffic class, the byte-level WRR weights for the 4 queues
-;         are set to 1:1:1:1
-;
-; For more details, please refer to chapter "Quality of Service (QoS) Framework"
-; of Data Plane Development Kit (DPDK) Programmer's Guide.
-
-; Port configuration
-[port]
-frame overhead = 24
-number of subports per port = 1
-number of pipes per subport = 4096
-queue sizes = 64 64 64 64
-
-; Subport configuration
-[subport 0]
-tb rate = 1250000000           ; Bytes per second
-tb size = 1000000              ; Bytes
-
-tc 0 rate = 1250000000         ; Bytes per second
-tc 1 rate = 1250000000         ; Bytes per second
-tc 2 rate = 1250000000         ; Bytes per second
-tc 3 rate = 1250000000         ; Bytes per second
-tc period = 10                 ; Milliseconds
-
-pipe 0-4095 = 0                ; These pipes are configured with pipe profile 0
-
-; Pipe configuration
-[pipe profile 0]
-tb rate = 305175               ; Bytes per second
-tb size = 1000000              ; Bytes
-
-tc 0 rate = 305175             ; Bytes per second
-tc 1 rate = 305175             ; Bytes per second
-tc 2 rate = 305175             ; Bytes per second
-tc 3 rate = 305175             ; Bytes per second
-tc period = 40                 ; Milliseconds
-
-tc 3 oversubscription weight = 1
-
-tc 0 wrr weights = 1 1 1 1
-tc 1 wrr weights = 1 1 1 1
-tc 2 wrr weights = 1 1 1 1
-tc 3 wrr weights = 1 1 1 1
-
-; RED params per traffic class and color (Green / Yellow / Red)
-[red]
-tc 0 wred min = 48 40 32
-tc 0 wred max = 64 64 64
-tc 0 wred inv prob = 10 10 10
-tc 0 wred weight = 9 9 9
-
-tc 1 wred min = 48 40 32
-tc 1 wred max = 64 64 64
-tc 1 wred inv prob = 10 10 10
-tc 1 wred weight = 9 9 9
-
-tc 2 wred min = 48 40 32
-tc 2 wred max = 64 64 64
-tc 2 wred inv prob = 10 10 10
-tc 2 wred weight = 9 9 9
-
-tc 3 wred min = 48 40 32
-tc 3 wred max = 64 64 64
-tc 3 wred inv prob = 10 10 10
-tc 3 wred weight = 9 9 9
diff --git a/examples/qos_sched/profile_ov.cfg b/examples/qos_sched/profile_ov.cfg
deleted file mode 100644
index 33000df..0000000
--- a/examples/qos_sched/profile_ov.cfg
+++ /dev/null
@@ -1,90 +0,0 @@
-;   BSD LICENSE
-;
-;   Copyright(c) 2010-2014 Intel Corporation. All rights reserved.
-;   All rights reserved.
-;
-;   Redistribution and use in source and binary forms, with or without
-;   modification, are permitted provided that the following conditions
-;   are met:
-;
-;     * Redistributions of source code must retain the above copyright
-;       notice, this list of conditions and the following disclaimer.
-;     * Redistributions in binary form must reproduce the above copyright
-;       notice, this list of conditions and the following disclaimer in
-;       the documentation and/or other materials provided with the
-;       distribution.
-;     * Neither the name of Intel Corporation nor the names of its
-;       contributors may be used to endorse or promote products derived
-;       from this software without specific prior written permission.
-;
-;   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-;   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-;   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-;   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-;   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-;   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-;   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-;   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-;   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-;   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-;   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-; Port configuration
-[port]
-frame overhead = 24
-number of subports per port = 1
-number of pipes per subport = 32
-queue sizes = 64 64 64 64
-
-; Subport configuration
-[subport 0]
-tb rate = 8400000           ; Bytes per second
-tb size = 100000            ; Bytes
-
-tc 0 rate = 8400000         ; Bytes per second
-tc 1 rate = 8400000         ; Bytes per second
-tc 2 rate = 8400000         ; Bytes per second
-tc 3 rate = 8400000         ; Bytes per second
-tc period = 10              ; Milliseconds
-
-pipe 0-31 = 0               ; These pipes are configured with pipe profile 0
-
-; Pipe configuration
-[pipe profile 0]
-tb rate = 16800000             ; Bytes per second
-tb size = 1000000              ; Bytes
-
-tc 0 rate = 16800000           ; Bytes per second
-tc 1 rate = 16800000           ; Bytes per second
-tc 2 rate = 16800000           ; Bytes per second
-tc 3 rate = 16800000           ; Bytes per second
-tc period = 28                 ; Milliseconds
-
-tc 3 oversubscription weight = 1
-
-tc 0 wrr weights = 1 1 1 1
-tc 1 wrr weights = 1 1 1 1
-tc 2 wrr weights = 1 1 1 1
-tc 3 wrr weights = 1 1 1 1
-
-; RED params per traffic class and color (Green / Yellow / Red)
-[red]
-tc 0 wred min = 48 40 32
-tc 0 wred max = 64 64 64
-tc 0 wred inv prob = 10 10 10
-tc 0 wred weight = 9 9 9
-
-tc 1 wred min = 48 40 32
-tc 1 wred max = 64 64 64
-tc 1 wred inv prob = 10 10 10
-tc 1 wred weight = 9 9 9
-
-tc 2 wred min = 48 40 32
-tc 2 wred max = 64 64 64
-tc 2 wred inv prob = 10 10 10
-tc 2 wred weight = 9 9 9
-
-tc 3 wred min = 48 40 32
-tc 3 wred max = 64 64 64
-tc 3 wred inv prob = 10 10 10
-tc 3 wred weight = 9 9 9
diff --git a/examples/qos_sched/stats.c b/examples/qos_sched/stats.c
deleted file mode 100644
index 8193d96..0000000
--- a/examples/qos_sched/stats.c
+++ /dev/null
@@ -1,288 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <unistd.h>
-#include <string.h>
-
-#include "main.h"
-
-int
-qavg_q(uint16_t port_id, uint32_t subport_id, uint32_t pipe_id, uint8_t tc,
-		uint8_t q)
-{
-        struct rte_sched_queue_stats stats;
-        struct rte_sched_port *port;
-        uint16_t qlen;
-        uint32_t queue_id, count, i;
-        uint32_t average;
-
-        for (i = 0; i < nb_pfc; i++) {
-                if (qos_conf[i].tx_port == port_id)
-                        break;
-        }
-        if (i == nb_pfc || subport_id >= port_params.n_subports_per_port || pipe_id >= port_params.n_pipes_per_subport
-                        || tc >= RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE || q >= RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS)
-                return -1;
-
-        port = qos_conf[i].sched_port;
-
-        queue_id = RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE * RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS * (subport_id * port_params.n_pipes_per_subport + pipe_id);
-        queue_id = queue_id + (tc * RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS + q);
-
-        average = 0;
-
-        for (count = 0; count < qavg_ntimes; count++) {
-                rte_sched_queue_read_stats(port, queue_id, &stats, &qlen);
-                average += qlen;
-                usleep(qavg_period);
-        }
-
-        average /= qavg_ntimes;
-
-        printf("\nAverage queue size: %" PRIu32 " bytes.\n\n", average);
-
-        return 0;
-}
-
-int
-qavg_tcpipe(uint16_t port_id, uint32_t subport_id, uint32_t pipe_id,
-	     uint8_t tc)
-{
-        struct rte_sched_queue_stats stats;
-        struct rte_sched_port *port;
-        uint16_t qlen;
-        uint32_t queue_id, count, i;
-        uint32_t average, part_average;
-
-        for (i = 0; i < nb_pfc; i++) {
-                if (qos_conf[i].tx_port == port_id)
-                        break;
-        }
-        if (i == nb_pfc || subport_id >= port_params.n_subports_per_port || pipe_id >= port_params.n_pipes_per_subport
-                        || tc >= RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE)
-                return -1;
-
-        port = qos_conf[i].sched_port;
-
-        queue_id = RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE * RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS * (subport_id * port_params.n_pipes_per_subport + pipe_id);
-
-        average = 0;
-
-        for (count = 0; count < qavg_ntimes; count++) {
-                part_average = 0;
-                for (i = 0; i < RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS; i++) {
-                        rte_sched_queue_read_stats(port, queue_id + (tc * RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS + i), &stats, &qlen);
-                        part_average += qlen;
-                }
-                average += part_average / RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS;
-                usleep(qavg_period);
-        }
-
-        average /= qavg_ntimes;
-
-        printf("\nAverage queue size: %" PRIu32 " bytes.\n\n", average);
-
-        return 0;
-}
-
-int
-qavg_pipe(uint16_t port_id, uint32_t subport_id, uint32_t pipe_id)
-{
-        struct rte_sched_queue_stats stats;
-        struct rte_sched_port *port;
-        uint16_t qlen;
-        uint32_t queue_id, count, i;
-        uint32_t average, part_average;
-
-        for (i = 0; i < nb_pfc; i++) {
-                if (qos_conf[i].tx_port == port_id)
-                        break;
-        }
-        if (i == nb_pfc || subport_id >= port_params.n_subports_per_port || pipe_id >= port_params.n_pipes_per_subport)
-                return -1;
-
-        port = qos_conf[i].sched_port;
-
-        queue_id = RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE * RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS * (subport_id * port_params.n_pipes_per_subport + pipe_id);
-
-        average = 0;
-
-        for (count = 0; count < qavg_ntimes; count++) {
-                part_average = 0;
-                for (i = 0; i < RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE * RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS; i++) {
-                        rte_sched_queue_read_stats(port, queue_id + i, &stats, &qlen);
-                        part_average += qlen;
-                }
-                average += part_average / (RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE * RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS);
-                usleep(qavg_period);
-        }
-
-        average /= qavg_ntimes;
-
-        printf("\nAverage queue size: %" PRIu32 " bytes.\n\n", average);
-
-        return 0;
-}
-
-int
-qavg_tcsubport(uint16_t port_id, uint32_t subport_id, uint8_t tc)
-{
-        struct rte_sched_queue_stats stats;
-        struct rte_sched_port *port;
-        uint16_t qlen;
-        uint32_t queue_id, count, i, j;
-        uint32_t average, part_average;
-
-        for (i = 0; i < nb_pfc; i++) {
-                if (qos_conf[i].tx_port == port_id)
-                        break;
-        }
-        if (i == nb_pfc || subport_id >= port_params.n_subports_per_port || tc >= RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE)
-                return -1;
-
-        port = qos_conf[i].sched_port;
-
-        average = 0;
-
-        for (count = 0; count < qavg_ntimes; count++) {
-                part_average = 0;
-                for (i = 0; i < port_params.n_pipes_per_subport; i++) {
-                        queue_id = RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE * RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS * (subport_id * port_params.n_pipes_per_subport + i);
-
-                        for (j = 0; j < RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS; j++) {
-                                rte_sched_queue_read_stats(port, queue_id + (tc * RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS + j), &stats, &qlen);
-                                part_average += qlen;
-                        }
-                }
-
-                average += part_average / (port_params.n_pipes_per_subport * RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS);
-                usleep(qavg_period);
-        }
-
-        average /= qavg_ntimes;
-
-        printf("\nAverage queue size: %" PRIu32 " bytes.\n\n", average);
-
-        return 0;
-}
-
-int
-qavg_subport(uint16_t port_id, uint32_t subport_id)
-{
-        struct rte_sched_queue_stats stats;
-        struct rte_sched_port *port;
-        uint16_t qlen;
-        uint32_t queue_id, count, i, j;
-        uint32_t average, part_average;
-
-        for (i = 0; i < nb_pfc; i++) {
-                if (qos_conf[i].tx_port == port_id)
-                        break;
-        }
-        if (i == nb_pfc || subport_id >= port_params.n_subports_per_port)
-                return -1;
-
-        port = qos_conf[i].sched_port;
-
-        average = 0;
-
-        for (count = 0; count < qavg_ntimes; count++) {
-                part_average = 0;
-                for (i = 0; i < port_params.n_pipes_per_subport; i++) {
-                        queue_id = RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE * RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS * (subport_id * port_params.n_pipes_per_subport + i);
-
-                        for (j = 0; j < RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE * RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS; j++) {
-                                rte_sched_queue_read_stats(port, queue_id + j, &stats, &qlen);
-                                part_average += qlen;
-                        }
-                }
-
-                average += part_average / (port_params.n_pipes_per_subport * RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE * RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS);
-                usleep(qavg_period);
-        }
-
-        average /= qavg_ntimes;
-
-        printf("\nAverage queue size: %" PRIu32 " bytes.\n\n", average);
-
-        return 0;
-}
-
-int
-subport_stat(uint16_t port_id, uint32_t subport_id)
-{
-        struct rte_sched_subport_stats stats;
-        struct rte_sched_port *port;
-        uint32_t tc_ov[RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE];
-        uint8_t i;
-
-        for (i = 0; i < nb_pfc; i++) {
-                if (qos_conf[i].tx_port == port_id)
-                        break;
-        }
-        if (i == nb_pfc || subport_id >= port_params.n_subports_per_port)
-                return -1;
-
-        port = qos_conf[i].sched_port;
-	memset (tc_ov, 0, sizeof(tc_ov));
-
-        rte_sched_subport_read_stats(port, subport_id, &stats, tc_ov);
-
-        printf("\n");
-        printf("+----+-------------+-------------+-------------+-------------+-------------+\n");
-        printf("| TC |   Pkts OK   |Pkts Dropped |  Bytes OK   |Bytes Dropped|  OV Status  |\n");
-        printf("+----+-------------+-------------+-------------+-------------+-------------+\n");
-
-        for (i = 0; i < RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE; i++) {
-                printf("|  %d | %11" PRIu32 " | %11" PRIu32 " | %11" PRIu32 " | %11" PRIu32 " | %11" PRIu32 " |\n", i,
-                                stats.n_pkts_tc[i], stats.n_pkts_tc_dropped[i],
-                                stats.n_bytes_tc[i], stats.n_bytes_tc_dropped[i], tc_ov[i]);
-                printf("+----+-------------+-------------+-------------+-------------+-------------+\n");
-        }
-        printf("\n");
-
-        return 0;
-}
-
-int
-pipe_stat(uint16_t port_id, uint32_t subport_id, uint32_t pipe_id)
-{
-        struct rte_sched_queue_stats stats;
-        struct rte_sched_port *port;
-        uint16_t qlen;
-        uint8_t i, j;
-        uint32_t queue_id;
-
-        for (i = 0; i < nb_pfc; i++) {
-                if (qos_conf[i].tx_port == port_id)
-                        break;
-        }
-        if (i == nb_pfc || subport_id >= port_params.n_subports_per_port || pipe_id >= port_params.n_pipes_per_subport)
-                return -1;
-
-        port = qos_conf[i].sched_port;
-
-        queue_id = RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE * RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS * (subport_id * port_params.n_pipes_per_subport + pipe_id);
-
-        printf("\n");
-        printf("+----+-------+-------------+-------------+-------------+-------------+-------------+\n");
-        printf("| TC | Queue |   Pkts OK   |Pkts Dropped |  Bytes OK   |Bytes Dropped|    Length   |\n");
-        printf("+----+-------+-------------+-------------+-------------+-------------+-------------+\n");
-
-        for (i = 0; i < RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE; i++) {
-                for (j = 0; j < RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS; j++) {
-
-                        rte_sched_queue_read_stats(port, queue_id + (i * RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS + j), &stats, &qlen);
-
-                        printf("|  %d |   %d   | %11" PRIu32 " | %11" PRIu32 " | %11" PRIu32 " | %11" PRIu32 " | %11i |\n", i, j,
-                                        stats.n_pkts, stats.n_pkts_dropped, stats.n_bytes, stats.n_bytes_dropped, qlen);
-                        printf("+----+-------+-------------+-------------+-------------+-------------+-------------+\n");
-                }
-                if (i < RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE - 1)
-                        printf("+----+-------+-------------+-------------+-------------+-------------+-------------+\n");
-        }
-        printf("\n");
-
-        return 0;
-}
diff --git a/examples/quota_watermark/Makefile b/examples/quota_watermark/Makefile
deleted file mode 100644
index a37b866..0000000
--- a/examples/quota_watermark/Makefile
+++ /dev/null
@@ -1,16 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-DIRS-$(CONFIG_RTE_EXEC_ENV_LINUXAPP) += qw
-DIRS-$(CONFIG_RTE_EXEC_ENV_LINUXAPP) += qwctl
-
-include $(RTE_SDK)/mk/rte.extsubdir.mk
diff --git a/examples/quota_watermark/include/conf.h b/examples/quota_watermark/include/conf.h
deleted file mode 100644
index 4f29aa6..0000000
--- a/examples/quota_watermark/include/conf.h
+++ /dev/null
@@ -1,19 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#ifndef _CONF_H_
-#define _CONF_H_
-
-#define RING_SIZE 1024
-#define MAX_PKT_QUOTA 64
-
-#define RX_DESC_PER_QUEUE   1024
-#define TX_DESC_PER_QUEUE   1024
-
-#define MBUF_DATA_SIZE     RTE_MBUF_DEFAULT_BUF_SIZE
-#define MBUF_PER_POOL 8192
-
-#define QUOTA_WATERMARK_MEMZONE_NAME "qw_global_vars"
-
-#endif /* _CONF_H_ */
diff --git a/examples/quota_watermark/qw/Makefile b/examples/quota_watermark/qw/Makefile
deleted file mode 100644
index 84299e5..0000000
--- a/examples/quota_watermark/qw/Makefile
+++ /dev/null
@@ -1,22 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-# binary name
-APP = qw
-
-# all source are stored in SRCS-y
-SRCS-y := args.c init.c main.c
-
-CFLAGS += -O3 -DQW_SOFTWARE_FC
-CFLAGS += $(WERROR_FLAGS)
-
-include $(RTE_SDK)/mk/rte.extapp.mk
diff --git a/examples/quota_watermark/qw/args.c b/examples/quota_watermark/qw/args.c
deleted file mode 100644
index a750ec2..0000000
--- a/examples/quota_watermark/qw/args.c
+++ /dev/null
@@ -1,78 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <unistd.h>
-
-#include <rte_common.h>
-#include <rte_lcore.h>
-
-#include "args.h"
-
-
-unsigned int portmask = 0;
-
-
-static void
-usage(const char *prgname)
-{
-	fprintf(stderr, "Usage: %s [EAL args] -- -p <portmask>\n"
-			"-p PORTMASK: hexadecimal bitmask of NIC ports to configure\n",
-			prgname);
-}
-
-static unsigned long
-parse_portmask(const char *portmask_str)
-{
-	return strtoul(portmask_str, NULL, 16);
-}
-
-static void
-check_core_count(void)
-{
-	if (rte_lcore_count() < 3)
-		rte_exit(EXIT_FAILURE,
-				"At least 3 cores need to be passed in the coremask\n");
-}
-
-static void
-check_portmask_value(unsigned int portmask)
-{
-	unsigned int port_nb = 0;
-
-	port_nb = __builtin_popcount(portmask);
-
-	if (port_nb == 0)
-		rte_exit(EXIT_FAILURE,
-				"At least 2 ports need to be passed in the portmask\n");
-
-	if (port_nb % 2 != 0)
-		rte_exit(EXIT_FAILURE,
-				"An even number of ports is required in the portmask\n");
-}
-
-int
-parse_qw_args(int argc, char **argv)
-{
-	int opt;
-
-	while ((opt = getopt(argc, argv, "h:p:")) != -1) {
-		switch (opt) {
-		case 'h':
-			usage(argv[0]);
-			break;
-		case 'p':
-			portmask = parse_portmask(optarg);
-			break;
-		default:
-			usage(argv[0]);
-		}
-	}
-
-	check_core_count();
-	check_portmask_value(portmask);
-
-	return 0;
-}
diff --git a/examples/quota_watermark/qw/args.h b/examples/quota_watermark/qw/args.h
deleted file mode 100644
index ab777db..0000000
--- a/examples/quota_watermark/qw/args.h
+++ /dev/null
@@ -1,12 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#ifndef _ARGS_H_
-#define _ARGS_H_
-
-extern unsigned int portmask;
-
-int parse_qw_args(int argc, char **argv);
-
-#endif /* _ARGS_H_ */
diff --git a/examples/quota_watermark/qw/init.c b/examples/quota_watermark/qw/init.c
deleted file mode 100644
index d4a6918..0000000
--- a/examples/quota_watermark/qw/init.c
+++ /dev/null
@@ -1,167 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <fcntl.h>
-#include <unistd.h>
-#include <sys/mman.h>
-
-#include <rte_eal.h>
-
-#include <rte_common.h>
-#include <rte_errno.h>
-#include <rte_ethdev.h>
-#include <rte_memzone.h>
-#include <rte_ring.h>
-#include <rte_string_fns.h>
-
-#include "args.h"
-#include "init.h"
-#include "main.h"
-#include "../include/conf.h"
-
-
-static struct rte_eth_conf port_conf = {
-		.rxmode = {
-			.split_hdr_size = 0,
-			.ignore_offload_bitfield = 1,
-			.offloads = DEV_RX_OFFLOAD_CRC_STRIP,
-		},
-		.txmode = {
-			.mq_mode = ETH_DCB_NONE,
-		},
-};
-
-static struct rte_eth_fc_conf fc_conf = {
-		.mode       = RTE_FC_TX_PAUSE,
-		.high_water = 80 * 510 / 100,
-		.low_water  = 60 * 510 / 100,
-		.pause_time = 1337,
-		.send_xon   = 0,
-};
-
-
-void configure_eth_port(uint16_t port_id)
-{
-	int ret;
-	uint16_t nb_rxd = RX_DESC_PER_QUEUE;
-	uint16_t nb_txd = TX_DESC_PER_QUEUE;
-	struct rte_eth_rxconf rxq_conf;
-	struct rte_eth_txconf txq_conf;
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_conf local_port_conf = port_conf;
-
-	rte_eth_dev_stop(port_id);
-
-	rte_eth_dev_info_get(port_id, &dev_info);
-	if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-		local_port_conf.txmode.offloads |=
-			DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-	ret = rte_eth_dev_configure(port_id, 1, 1, &local_port_conf);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Cannot configure port %u (error %d)\n",
-				(unsigned int) port_id, ret);
-
-	ret = rte_eth_dev_adjust_nb_rx_tx_desc(port_id, &nb_rxd, &nb_txd);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE,
-				"Cannot adjust number of descriptors for port %u (error %d)\n",
-				(unsigned int) port_id, ret);
-
-	/* Initialize the port's RX queue */
-	rxq_conf = dev_info.default_rxconf;
-	rxq_conf.offloads = local_port_conf.rxmode.offloads;
-	ret = rte_eth_rx_queue_setup(port_id, 0, nb_rxd,
-			rte_eth_dev_socket_id(port_id),
-			&rxq_conf,
-			mbuf_pool);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE,
-				"Failed to setup RX queue on port %u (error %d)\n",
-				(unsigned int) port_id, ret);
-
-	/* Initialize the port's TX queue */
-	txq_conf = dev_info.default_txconf;
-	txq_conf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-	txq_conf.offloads = local_port_conf.txmode.offloads;
-	ret = rte_eth_tx_queue_setup(port_id, 0, nb_txd,
-			rte_eth_dev_socket_id(port_id),
-			&txq_conf);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE,
-				"Failed to setup TX queue on port %u (error %d)\n",
-				(unsigned int) port_id, ret);
-
-	/* Initialize the port's flow control */
-	ret = rte_eth_dev_flow_ctrl_set(port_id, &fc_conf);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE,
-				"Failed to setup hardware flow control on port %u (error %d)\n",
-				(unsigned int) port_id, ret);
-
-	/* Start the port */
-	ret = rte_eth_dev_start(port_id);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Failed to start port %u (error %d)\n",
-				(unsigned int) port_id, ret);
-
-	/* Put it in promiscuous mode */
-	rte_eth_promiscuous_enable(port_id);
-}
-
-void
-init_dpdk(void)
-{
-	if (rte_eth_dev_count() < 2)
-		rte_exit(EXIT_FAILURE, "Not enough ethernet port available\n");
-}
-
-void init_ring(int lcore_id, uint16_t port_id)
-{
-	struct rte_ring *ring;
-	char ring_name[RTE_RING_NAMESIZE];
-
-	snprintf(ring_name, RTE_RING_NAMESIZE,
-			"core%d_port%d", lcore_id, port_id);
-	ring = rte_ring_create(ring_name, RING_SIZE, rte_socket_id(),
-			RING_F_SP_ENQ | RING_F_SC_DEQ);
-
-	if (ring == NULL)
-		rte_exit(EXIT_FAILURE, "%s\n", rte_strerror(rte_errno));
-
-	*high_watermark = 80 * RING_SIZE / 100;
-
-	rings[lcore_id][port_id] = ring;
-}
-
-void
-pair_ports(void)
-{
-	uint16_t i, j;
-
-	/* Pair ports with their "closest neighbour" in the portmask */
-	for (i = 0; i < RTE_MAX_ETHPORTS; i++)
-		if (is_bit_set(i, portmask))
-			for (j = i + 1; j < RTE_MAX_ETHPORTS; j++)
-				if (is_bit_set(j, portmask)) {
-					port_pairs[i] = j;
-					port_pairs[j] = i;
-					i = j;
-					break;
-				}
-}
-
-void
-setup_shared_variables(void)
-{
-	const struct rte_memzone *qw_memzone;
-
-	qw_memzone = rte_memzone_reserve(QUOTA_WATERMARK_MEMZONE_NAME,
-			3 * sizeof(int), rte_socket_id(), 0);
-	if (qw_memzone == NULL)
-		rte_exit(EXIT_FAILURE, "%s\n", rte_strerror(rte_errno));
-
-	quota = qw_memzone->addr;
-	low_watermark = (unsigned int *) qw_memzone->addr + 1;
-	high_watermark = (unsigned int *) qw_memzone->addr + 2;
-}
diff --git a/examples/quota_watermark/qw/init.h b/examples/quota_watermark/qw/init.h
deleted file mode 100644
index e0c90df..0000000
--- a/examples/quota_watermark/qw/init.h
+++ /dev/null
@@ -1,14 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#ifndef _INIT_H_
-#define _INIT_H_
-
-void configure_eth_port(uint16_t port_id);
-void init_dpdk(void);
-void init_ring(int lcore_id, uint16_t port_id);
-void pair_ports(void);
-void setup_shared_variables(void);
-
-#endif /* _INIT_H_ */
diff --git a/examples/quota_watermark/qw/main.c b/examples/quota_watermark/qw/main.c
deleted file mode 100644
index c55d387..0000000
--- a/examples/quota_watermark/qw/main.c
+++ /dev/null
@@ -1,365 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <rte_eal.h>
-
-#include <rte_common.h>
-#include <rte_debug.h>
-#include <rte_errno.h>
-#include <rte_ethdev.h>
-#include <rte_launch.h>
-#include <rte_lcore.h>
-#include <rte_log.h>
-#include <rte_mbuf.h>
-#include <rte_ring.h>
-
-#include <rte_byteorder.h>
-
-#include "args.h"
-#include "main.h"
-#include "init.h"
-#include "../include/conf.h"
-
-
-#ifdef QW_SOFTWARE_FC
-#define SEND_PAUSE_FRAME(port_id, duration) send_pause_frame(port_id, duration)
-#else
-#define SEND_PAUSE_FRAME(port_id, duration) do { } while(0)
-#endif
-
-#define ETHER_TYPE_FLOW_CONTROL 0x8808
-
-struct ether_fc_frame {
-	uint16_t opcode;
-	uint16_t param;
-} __attribute__((__packed__));
-
-
-int *quota;
-unsigned int *low_watermark;
-unsigned int *high_watermark;
-
-uint16_t port_pairs[RTE_MAX_ETHPORTS];
-
-struct rte_ring *rings[RTE_MAX_LCORE][RTE_MAX_ETHPORTS];
-struct rte_mempool *mbuf_pool;
-
-
-static void send_pause_frame(uint16_t port_id, uint16_t duration)
-{
-	struct rte_mbuf *mbuf;
-	struct ether_fc_frame *pause_frame;
-	struct ether_hdr *hdr;
-	struct ether_addr mac_addr;
-
-	RTE_LOG_DP(DEBUG, USER1,
-			"Sending PAUSE frame (duration=%d) on port %d\n",
-			duration, port_id);
-
-	/* Get a mbuf from the pool */
-	mbuf = rte_pktmbuf_alloc(mbuf_pool);
-	if (unlikely(mbuf == NULL))
-		return;
-
-	/* Prepare a PAUSE frame */
-	hdr = rte_pktmbuf_mtod(mbuf, struct ether_hdr *);
-	pause_frame = (struct ether_fc_frame *) &hdr[1];
-
-	rte_eth_macaddr_get(port_id, &mac_addr);
-	ether_addr_copy(&mac_addr, &hdr->s_addr);
-
-	void *tmp = &hdr->d_addr.addr_bytes[0];
-	*((uint64_t *)tmp) = 0x010000C28001ULL;
-
-	hdr->ether_type = rte_cpu_to_be_16(ETHER_TYPE_FLOW_CONTROL);
-
-	pause_frame->opcode = rte_cpu_to_be_16(0x0001);
-	pause_frame->param  = rte_cpu_to_be_16(duration);
-
-	mbuf->pkt_len  = 60;
-	mbuf->data_len = 60;
-
-	rte_eth_tx_burst(port_id, 0, &mbuf, 1);
-}
-
-/**
- * Get the previous enabled lcore ID
- *
- * @param lcore_id
- *   The current lcore ID.
- * @return
- *   The previous enabled lcore_id or -1 if not found.
- */
-static unsigned int
-get_previous_lcore_id(unsigned int lcore_id)
-{
-	int i;
-
-	for (i = lcore_id - 1; i >= 0; i--)
-		if (rte_lcore_is_enabled(i))
-			return i;
-
-	return -1;
-}
-
-/**
- * Get the last enabled lcore ID
- *
- * @return
- *   The last enabled lcore_id.
- */
-static unsigned int
-get_last_lcore_id(void)
-{
-	int i;
-
-	for (i = RTE_MAX_LCORE; i >= 0; i--)
-		if (rte_lcore_is_enabled(i))
-			return i;
-
-	return 0;
-}
-
-static void
-receive_stage(__attribute__((unused)) void *args)
-{
-	int i, ret;
-
-	uint16_t port_id;
-	uint16_t nb_rx_pkts;
-
-	unsigned int lcore_id;
-	unsigned int free;
-
-	struct rte_mbuf *pkts[MAX_PKT_QUOTA];
-	struct rte_ring *ring;
-	enum ring_state ring_state[RTE_MAX_ETHPORTS] = { RING_READY };
-
-	lcore_id = rte_lcore_id();
-
-	RTE_LOG(INFO, USER1,
-			"%s() started on core %u\n", __func__, lcore_id);
-
-	while (1) {
-
-		/* Process each port round robin style */
-		for (port_id = 0; port_id < RTE_MAX_ETHPORTS; port_id++) {
-
-			if (!is_bit_set(port_id, portmask))
-				continue;
-
-			ring = rings[lcore_id][port_id];
-
-			if (ring_state[port_id] != RING_READY) {
-				if (rte_ring_count(ring) > *low_watermark)
-					continue;
-				else
-					ring_state[port_id] = RING_READY;
-			}
-
-			/* Enqueue received packets on the RX ring */
-			nb_rx_pkts = rte_eth_rx_burst(port_id, 0, pkts,
-					(uint16_t) *quota);
-			ret = rte_ring_enqueue_bulk(ring, (void *) pkts,
-					nb_rx_pkts, &free);
-			if (RING_SIZE - free > *high_watermark) {
-				ring_state[port_id] = RING_OVERLOADED;
-				send_pause_frame(port_id, 1337);
-			}
-
-			if (ret == 0) {
-
-				/*
-				 * Return  mbufs to the pool,
-				 * effectively dropping packets
-				 */
-				for (i = 0; i < nb_rx_pkts; i++)
-					rte_pktmbuf_free(pkts[i]);
-			}
-		}
-	}
-}
-
-static int
-pipeline_stage(__attribute__((unused)) void *args)
-{
-	int i, ret;
-	int nb_dq_pkts;
-
-	uint16_t port_id;
-
-	unsigned int lcore_id, previous_lcore_id;
-	unsigned int free;
-
-	void *pkts[MAX_PKT_QUOTA];
-	struct rte_ring *rx, *tx;
-	enum ring_state ring_state[RTE_MAX_ETHPORTS] = { RING_READY };
-
-	lcore_id = rte_lcore_id();
-	previous_lcore_id = get_previous_lcore_id(lcore_id);
-
-	RTE_LOG(INFO, USER1,
-			"%s() started on core %u - processing packets from core %u\n",
-			__func__, lcore_id, previous_lcore_id);
-
-	while (1) {
-
-		for (port_id = 0; port_id < RTE_MAX_ETHPORTS; port_id++) {
-
-			if (!is_bit_set(port_id, portmask))
-				continue;
-
-			tx = rings[lcore_id][port_id];
-			rx = rings[previous_lcore_id][port_id];
-
-			if (ring_state[port_id] != RING_READY) {
-				if (rte_ring_count(tx) > *low_watermark)
-					continue;
-				else
-					ring_state[port_id] = RING_READY;
-			}
-
-			/* Dequeue up to quota mbuf from rx */
-			nb_dq_pkts = rte_ring_dequeue_burst(rx, pkts,
-					*quota, NULL);
-			if (unlikely(nb_dq_pkts < 0))
-				continue;
-
-			/* Enqueue them on tx */
-			ret = rte_ring_enqueue_bulk(tx, pkts,
-					nb_dq_pkts, &free);
-			if (RING_SIZE - free > *high_watermark)
-				ring_state[port_id] = RING_OVERLOADED;
-
-			if (ret == 0) {
-
-				/*
-				 * Return  mbufs to the pool,
-				 * effectively dropping packets
-				 */
-				for (i = 0; i < nb_dq_pkts; i++)
-					rte_pktmbuf_free(pkts[i]);
-			}
-		}
-	}
-
-	return 0;
-}
-
-static int
-send_stage(__attribute__((unused)) void *args)
-{
-	uint16_t nb_dq_pkts;
-
-	uint16_t port_id;
-	uint16_t dest_port_id;
-
-	unsigned int lcore_id, previous_lcore_id;
-
-	struct rte_ring *tx;
-	struct rte_mbuf *tx_pkts[MAX_PKT_QUOTA];
-
-	lcore_id = rte_lcore_id();
-	previous_lcore_id = get_previous_lcore_id(lcore_id);
-
-	RTE_LOG(INFO, USER1,
-			"%s() started on core %u - processing packets from core %u\n",
-			__func__, lcore_id, previous_lcore_id);
-
-	while (1) {
-
-		/* Process each ring round robin style */
-		for (port_id = 0; port_id < RTE_MAX_ETHPORTS; port_id++) {
-
-			if (!is_bit_set(port_id, portmask))
-				continue;
-
-			dest_port_id = port_pairs[port_id];
-			tx = rings[previous_lcore_id][port_id];
-
-			if (rte_ring_empty(tx))
-				continue;
-
-			/* Dequeue packets from tx and send them */
-			nb_dq_pkts = (uint16_t) rte_ring_dequeue_burst(tx,
-					(void *) tx_pkts, *quota, NULL);
-			rte_eth_tx_burst(dest_port_id, 0, tx_pkts, nb_dq_pkts);
-
-			/* TODO: Check if nb_dq_pkts == nb_tx_pkts? */
-		}
-	}
-
-	return 0;
-}
-
-int
-main(int argc, char **argv)
-{
-	int ret;
-	unsigned int lcore_id, master_lcore_id, last_lcore_id;
-
-	uint16_t port_id;
-
-	rte_log_set_global_level(RTE_LOG_INFO);
-
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Cannot initialize EAL\n");
-
-	argc -= ret;
-	argv += ret;
-
-	init_dpdk();
-	setup_shared_variables();
-
-	*quota = 32;
-	*low_watermark = 60 * RING_SIZE / 100;
-
-	last_lcore_id   = get_last_lcore_id();
-	master_lcore_id = rte_get_master_lcore();
-
-	/* Parse the application's arguments */
-	ret = parse_qw_args(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid quota/watermark argument(s)\n");
-
-	/* Create a pool of mbuf to store packets */
-	mbuf_pool = rte_pktmbuf_pool_create("mbuf_pool", MBUF_PER_POOL, 32, 0,
-			MBUF_DATA_SIZE, rte_socket_id());
-	if (mbuf_pool == NULL)
-		rte_panic("%s\n", rte_strerror(rte_errno));
-
-	for (port_id = 0; port_id < RTE_MAX_ETHPORTS; port_id++)
-		if (is_bit_set(port_id, portmask)) {
-			configure_eth_port(port_id);
-			init_ring(master_lcore_id, port_id);
-		}
-
-	pair_ports();
-
-	/*
-	 * Start pipeline_connect() on all the available slave lcores
-	 * but the last
-	 */
-	for (lcore_id = 0 ; lcore_id < last_lcore_id; lcore_id++) {
-		if (rte_lcore_is_enabled(lcore_id) &&
-				lcore_id != master_lcore_id) {
-
-			for (port_id = 0; port_id < RTE_MAX_ETHPORTS; port_id++)
-				if (is_bit_set(port_id, portmask))
-					init_ring(lcore_id, port_id);
-
-			rte_eal_remote_launch(pipeline_stage,
-					NULL, lcore_id);
-		}
-	}
-
-	/* Start send_stage() on the last slave core */
-	rte_eal_remote_launch(send_stage, NULL, last_lcore_id);
-
-	/* Start receive_stage() on the master core */
-	receive_stage(NULL);
-
-	return 0;
-}
diff --git a/examples/quota_watermark/qw/main.h b/examples/quota_watermark/qw/main.h
deleted file mode 100644
index 9903ddc..0000000
--- a/examples/quota_watermark/qw/main.h
+++ /dev/null
@@ -1,31 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#ifndef _MAIN_H_
-#define _MAIN_H_
-
-#include "../include/conf.h"
-
-enum ring_state {
-	RING_READY,
-	RING_OVERLOADED,
-};
-
-extern int *quota;
-extern unsigned int *low_watermark;
-extern unsigned int *high_watermark;
-
-extern uint16_t port_pairs[RTE_MAX_ETHPORTS];
-
-extern struct rte_ring *rings[RTE_MAX_LCORE][RTE_MAX_ETHPORTS];
-extern struct rte_mempool *mbuf_pool;
-
-
-static inline int
-is_bit_set(int i, unsigned int mask)
-{
-	return (1 << i) & mask;
-}
-
-#endif /* _MAIN_H_ */
diff --git a/examples/quota_watermark/qwctl/Makefile b/examples/quota_watermark/qwctl/Makefile
deleted file mode 100644
index b390128..0000000
--- a/examples/quota_watermark/qwctl/Makefile
+++ /dev/null
@@ -1,22 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-# binary name
-APP = qwctl
-
-# all source are stored in SRCS-y
-SRCS-y := commands.c qwctl.c
-
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-
-include $(RTE_SDK)/mk/rte.extapp.mk
diff --git a/examples/quota_watermark/qwctl/commands.c b/examples/quota_watermark/qwctl/commands.c
deleted file mode 100644
index a1c646b..0000000
--- a/examples/quota_watermark/qwctl/commands.c
+++ /dev/null
@@ -1,196 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdint.h>
-#include <string.h>
-#include <termios.h>
-
-#include <cmdline_rdline.h>
-#include <cmdline_parse.h>
-#include <cmdline_parse_num.h>
-#include <cmdline_parse_string.h>
-#include <cmdline.h>
-
-#include <rte_ring.h>
-
-#include "qwctl.h"
-#include "../include/conf.h"
-
-
-/**
- * help command
- */
-
-struct cmd_help_tokens {
-	cmdline_fixed_string_t verb;
-};
-
-cmdline_parse_token_string_t cmd_help_verb =
-		TOKEN_STRING_INITIALIZER(struct cmd_help_tokens, verb, "help");
-
-static void
-cmd_help_handler(__attribute__((unused)) void *parsed_result,
-		struct cmdline *cl,
-		__attribute__((unused)) void *data)
-{
-	cmdline_printf(cl, "Available commands:\n"
-			"- help\n"
-			"- set  [ring_name|variable] <value>\n"
-			"- show [ring_name|variable]\n"
-			"\n"
-			"Available variables:\n"
-			"- low_watermark\n"
-			"- quota\n"
-			"- ring names follow the core%%u_port%%u format\n");
-}
-
-cmdline_parse_inst_t cmd_help = {
-		.f = cmd_help_handler,
-		.data = NULL,
-		.help_str = "show help",
-		.tokens = {
-				(void *) &cmd_help_verb,
-				NULL,
-		},
-};
-
-
-/**
- * set command
- */
-
-struct cmd_set_tokens {
-	cmdline_fixed_string_t verb;
-	cmdline_fixed_string_t variable;
-	uint32_t value;
-};
-
-cmdline_parse_token_string_t cmd_set_verb =
-		TOKEN_STRING_INITIALIZER(struct cmd_set_tokens, verb, "set");
-
-cmdline_parse_token_string_t cmd_set_variable =
-		TOKEN_STRING_INITIALIZER(struct cmd_set_tokens, variable, NULL);
-
-cmdline_parse_token_num_t cmd_set_value =
-		TOKEN_NUM_INITIALIZER(struct cmd_set_tokens, value, UINT32);
-
-static void
-cmd_set_handler(__attribute__((unused)) void *parsed_result,
-		struct cmdline *cl,
-		__attribute__((unused)) void *data)
-{
-	struct cmd_set_tokens *tokens = parsed_result;
-	struct rte_ring *ring;
-
-	if (!strcmp(tokens->variable, "quota")) {
-
-		if (tokens->value > 0 && tokens->value <= MAX_PKT_QUOTA)
-			*quota = tokens->value;
-		else
-			cmdline_printf(cl, "quota must be between 1 and %u\n",
-					MAX_PKT_QUOTA);
-	}
-
-	else if (!strcmp(tokens->variable, "low_watermark")) {
-
-		if (tokens->value <= 100)
-			*low_watermark = tokens->value * RING_SIZE / 100;
-		else
-			cmdline_printf(cl,
-					"low_watermark must be between 0%% and 100%%\n");
-	}
-
-	else {
-
-		ring = rte_ring_lookup(tokens->variable);
-		if (ring == NULL)
-			cmdline_printf(cl, "Cannot find ring \"%s\"\n",
-					tokens->variable);
-		else
-			if (tokens->value >= *low_watermark * 100 / RING_SIZE
-					&& tokens->value <= 100)
-				*high_watermark = tokens->value *
-						RING_SIZE / 100;
-			else
-				cmdline_printf(cl,
-					"ring high watermark must be between %u%% and 100%%\n",
-					*low_watermark * 100 / RING_SIZE);
-	}
-}
-
-cmdline_parse_inst_t cmd_set = {
-		.f = cmd_set_handler,
-		.data = NULL,
-		.help_str = "Set a variable value",
-		.tokens = {
-				(void *) &cmd_set_verb,
-				(void *) &cmd_set_variable,
-				(void *) &cmd_set_value,
-				NULL,
-		},
-};
-
-
-/**
- * show command
- */
-
-struct cmd_show_tokens {
-	cmdline_fixed_string_t verb;
-	cmdline_fixed_string_t variable;
-};
-
-cmdline_parse_token_string_t cmd_show_verb =
-		TOKEN_STRING_INITIALIZER(struct cmd_show_tokens, verb, "show");
-
-cmdline_parse_token_string_t cmd_show_variable =
-		TOKEN_STRING_INITIALIZER(struct cmd_show_tokens,
-				variable, NULL);
-
-
-static void
-cmd_show_handler(__attribute__((unused)) void *parsed_result,
-		struct cmdline *cl,
-		__attribute__((unused)) void *data)
-{
-	struct cmd_show_tokens *tokens = parsed_result;
-	struct rte_ring *ring;
-
-	if (!strcmp(tokens->variable, "quota"))
-		cmdline_printf(cl, "Global quota: %d\n", *quota);
-
-	else if (!strcmp(tokens->variable, "low_watermark"))
-		cmdline_printf(cl, "Global low_watermark: %u\n",
-				*low_watermark);
-
-	else {
-
-		ring = rte_ring_lookup(tokens->variable);
-		if (ring == NULL)
-			cmdline_printf(cl, "Cannot find ring \"%s\"\n",
-					tokens->variable);
-		else
-			rte_ring_dump(stdout, ring);
-	}
-}
-
-cmdline_parse_inst_t cmd_show = {
-		.f = cmd_show_handler,
-		.data = NULL,
-		.help_str = "Show a variable value",
-		.tokens = {
-				(void *) &cmd_show_verb,
-				(void *) &cmd_show_variable,
-				NULL,
-		},
-};
-
-
-cmdline_parse_ctx_t qwctl_ctx[] = {
-		(cmdline_parse_inst_t *)&cmd_help,
-		(cmdline_parse_inst_t *)&cmd_set,
-		(cmdline_parse_inst_t *)&cmd_show,
-		NULL,
-};
diff --git a/examples/quota_watermark/qwctl/commands.h b/examples/quota_watermark/qwctl/commands.h
deleted file mode 100644
index 4a4e974..0000000
--- a/examples/quota_watermark/qwctl/commands.h
+++ /dev/null
@@ -1,12 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#ifndef _COMMANDS_H_
-#define _COMMANDS_H_
-
-#include <cmdline_parse.h>
-
-extern cmdline_parse_ctx_t qwctl_ctx[];
-
-#endif /* _COMMANDS_H_ */
diff --git a/examples/quota_watermark/qwctl/qwctl.c b/examples/quota_watermark/qwctl/qwctl.c
deleted file mode 100644
index 2f7914c..0000000
--- a/examples/quota_watermark/qwctl/qwctl.c
+++ /dev/null
@@ -1,67 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <fcntl.h>
-#include <stdio.h>
-#include <termios.h>
-#include <unistd.h>
-#include <sys/mman.h>
-
-#include <rte_eal.h>
-
-#include <rte_log.h>
-#include <rte_memzone.h>
-
-#include <cmdline_rdline.h>
-#include <cmdline_parse.h>
-#include <cmdline_socket.h>
-#include <cmdline.h>
-
-
-#include "qwctl.h"
-#include "commands.h"
-#include "../include/conf.h"
-
-
-int *quota;
-unsigned int *low_watermark;
-unsigned int *high_watermark;
-
-
-static void
-setup_shared_variables(void)
-{
-	const struct rte_memzone *qw_memzone;
-
-	qw_memzone = rte_memzone_lookup(QUOTA_WATERMARK_MEMZONE_NAME);
-	if (qw_memzone == NULL)
-		rte_exit(EXIT_FAILURE, "Couldn't find memzone\n");
-
-	quota = qw_memzone->addr;
-	low_watermark = (unsigned int *) qw_memzone->addr + 1;
-	high_watermark = (unsigned int *) qw_memzone->addr + 2;
-}
-
-int main(int argc, char **argv)
-{
-	int ret;
-	struct cmdline *cl;
-
-	rte_log_set_global_level(RTE_LOG_INFO);
-
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Cannot initialize EAL\n");
-
-	setup_shared_variables();
-
-	cl = cmdline_stdin_new(qwctl_ctx, "qwctl> ");
-	if (cl == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot create cmdline instance\n");
-
-	cmdline_interact(cl);
-	cmdline_stdin_exit(cl);
-
-	return 0;
-}
diff --git a/examples/quota_watermark/qwctl/qwctl.h b/examples/quota_watermark/qwctl/qwctl.h
deleted file mode 100644
index 2a45593..0000000
--- a/examples/quota_watermark/qwctl/qwctl.h
+++ /dev/null
@@ -1,12 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#ifndef _MAIN_H_
-#define _MAIN_H_
-
-extern int *quota;
-extern unsigned int *low_watermark;
-extern unsigned int *high_watermark;
-
-#endif /* _MAIN_H_ */
diff --git a/examples/rxtx_callbacks/Makefile b/examples/rxtx_callbacks/Makefile
deleted file mode 100644
index c72ba66..0000000
--- a/examples/rxtx_callbacks/Makefile
+++ /dev/null
@@ -1,65 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2015 Intel Corporation
-
-# binary name
-APP = rxtx_callbacks
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else # Build using legacy build system
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += $(WERROR_FLAGS)
-
-# workaround for a gcc bug with noreturn attribute
-# http://gcc.gnu.org/bugzilla/show_bug.cgi?id=12603
-ifeq ($(CONFIG_RTE_TOOLCHAIN_GCC),y)
-CFLAGS_main.o += -Wno-return-type
-endif
-
-EXTRA_CFLAGS += -O3 -g -Wfatal-errors
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-endif
diff --git a/examples/rxtx_callbacks/main.c b/examples/rxtx_callbacks/main.c
deleted file mode 100644
index 84b09cf..0000000
--- a/examples/rxtx_callbacks/main.c
+++ /dev/null
@@ -1,214 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#include <stdint.h>
-#include <inttypes.h>
-#include <rte_eal.h>
-#include <rte_ethdev.h>
-#include <rte_cycles.h>
-#include <rte_lcore.h>
-#include <rte_mbuf.h>
-
-#define RX_RING_SIZE 1024
-#define TX_RING_SIZE 1024
-
-#define NUM_MBUFS 8191
-#define MBUF_CACHE_SIZE 250
-#define BURST_SIZE 32
-
-static const struct rte_eth_conf port_conf_default = {
-	.rxmode = {
-		.max_rx_pkt_len = ETHER_MAX_LEN,
-		.ignore_offload_bitfield = 1,
-	},
-};
-
-static struct {
-	uint64_t total_cycles;
-	uint64_t total_pkts;
-} latency_numbers;
-
-
-static uint16_t
-add_timestamps(uint16_t port __rte_unused, uint16_t qidx __rte_unused,
-		struct rte_mbuf **pkts, uint16_t nb_pkts,
-		uint16_t max_pkts __rte_unused, void *_ __rte_unused)
-{
-	unsigned i;
-	uint64_t now = rte_rdtsc();
-
-	for (i = 0; i < nb_pkts; i++)
-		pkts[i]->udata64 = now;
-	return nb_pkts;
-}
-
-static uint16_t
-calc_latency(uint16_t port __rte_unused, uint16_t qidx __rte_unused,
-		struct rte_mbuf **pkts, uint16_t nb_pkts, void *_ __rte_unused)
-{
-	uint64_t cycles = 0;
-	uint64_t now = rte_rdtsc();
-	unsigned i;
-
-	for (i = 0; i < nb_pkts; i++)
-		cycles += now - pkts[i]->udata64;
-	latency_numbers.total_cycles += cycles;
-	latency_numbers.total_pkts += nb_pkts;
-
-	if (latency_numbers.total_pkts > (100 * 1000 * 1000ULL)) {
-		printf("Latency = %"PRIu64" cycles\n",
-		latency_numbers.total_cycles / latency_numbers.total_pkts);
-		latency_numbers.total_cycles = latency_numbers.total_pkts = 0;
-	}
-	return nb_pkts;
-}
-
-/*
- * Initialises a given port using global settings and with the rx buffers
- * coming from the mbuf_pool passed as parameter
- */
-static inline int
-port_init(uint16_t port, struct rte_mempool *mbuf_pool)
-{
-	struct rte_eth_conf port_conf = port_conf_default;
-	const uint16_t rx_rings = 1, tx_rings = 1;
-	uint16_t nb_rxd = RX_RING_SIZE;
-	uint16_t nb_txd = TX_RING_SIZE;
-	int retval;
-	uint16_t q;
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_txconf txconf;
-
-	if (!rte_eth_dev_is_valid_port(port))
-		return -1;
-
-	rte_eth_dev_info_get(port, &dev_info);
-	if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-		port_conf.txmode.offloads |=
-			DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-
-	retval = rte_eth_dev_configure(port, rx_rings, tx_rings, &port_conf);
-	if (retval != 0)
-		return retval;
-
-	retval = rte_eth_dev_adjust_nb_rx_tx_desc(port, &nb_rxd, &nb_txd);
-	if (retval != 0)
-		return retval;
-
-	for (q = 0; q < rx_rings; q++) {
-		retval = rte_eth_rx_queue_setup(port, q, nb_rxd,
-				rte_eth_dev_socket_id(port), NULL, mbuf_pool);
-		if (retval < 0)
-			return retval;
-	}
-
-	txconf = dev_info.default_txconf;
-	txconf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-	txconf.offloads = port_conf.txmode.offloads;
-	for (q = 0; q < tx_rings; q++) {
-		retval = rte_eth_tx_queue_setup(port, q, nb_txd,
-				rte_eth_dev_socket_id(port), &txconf);
-		if (retval < 0)
-			return retval;
-	}
-
-	retval  = rte_eth_dev_start(port);
-	if (retval < 0)
-		return retval;
-
-	struct ether_addr addr;
-
-	rte_eth_macaddr_get(port, &addr);
-	printf("Port %u MAC: %02"PRIx8" %02"PRIx8" %02"PRIx8
-			" %02"PRIx8" %02"PRIx8" %02"PRIx8"\n",
-			(unsigned)port,
-			addr.addr_bytes[0], addr.addr_bytes[1],
-			addr.addr_bytes[2], addr.addr_bytes[3],
-			addr.addr_bytes[4], addr.addr_bytes[5]);
-
-	rte_eth_promiscuous_enable(port);
-	rte_eth_add_rx_callback(port, 0, add_timestamps, NULL);
-	rte_eth_add_tx_callback(port, 0, calc_latency, NULL);
-
-	return 0;
-}
-
-/*
- * Main thread that does the work, reading from INPUT_PORT
- * and writing to OUTPUT_PORT
- */
-static  __attribute__((noreturn)) void
-lcore_main(void)
-{
-	uint16_t port;
-
-	RTE_ETH_FOREACH_DEV(port)
-		if (rte_eth_dev_socket_id(port) > 0 &&
-				rte_eth_dev_socket_id(port) !=
-						(int)rte_socket_id())
-			printf("WARNING, port %u is on remote NUMA node to "
-					"polling thread.\n\tPerformance will "
-					"not be optimal.\n", port);
-
-	printf("\nCore %u forwarding packets. [Ctrl+C to quit]\n",
-			rte_lcore_id());
-	for (;;) {
-		RTE_ETH_FOREACH_DEV(port) {
-			struct rte_mbuf *bufs[BURST_SIZE];
-			const uint16_t nb_rx = rte_eth_rx_burst(port, 0,
-					bufs, BURST_SIZE);
-			if (unlikely(nb_rx == 0))
-				continue;
-			const uint16_t nb_tx = rte_eth_tx_burst(port ^ 1, 0,
-					bufs, nb_rx);
-			if (unlikely(nb_tx < nb_rx)) {
-				uint16_t buf;
-
-				for (buf = nb_tx; buf < nb_rx; buf++)
-					rte_pktmbuf_free(bufs[buf]);
-			}
-		}
-	}
-}
-
-/* Main function, does initialisation and calls the per-lcore functions */
-int
-main(int argc, char *argv[])
-{
-	struct rte_mempool *mbuf_pool;
-	uint16_t nb_ports;
-	uint16_t portid;
-
-	/* init EAL */
-	int ret = rte_eal_init(argc, argv);
-
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Error with EAL initialization\n");
-	argc -= ret;
-	argv += ret;
-
-	nb_ports = rte_eth_dev_count();
-	if (nb_ports < 2 || (nb_ports & 1))
-		rte_exit(EXIT_FAILURE, "Error: number of ports must be even\n");
-
-	mbuf_pool = rte_pktmbuf_pool_create("MBUF_POOL",
-		NUM_MBUFS * nb_ports, MBUF_CACHE_SIZE, 0,
-		RTE_MBUF_DEFAULT_BUF_SIZE, rte_socket_id());
-	if (mbuf_pool == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot create mbuf pool\n");
-
-	/* initialize all ports */
-	RTE_ETH_FOREACH_DEV(portid)
-		if (port_init(portid, mbuf_pool) != 0)
-			rte_exit(EXIT_FAILURE, "Cannot init port %"PRIu8"\n",
-					portid);
-
-	if (rte_lcore_count() > 1)
-		printf("\nWARNING: Too much enabled lcores - "
-			"App uses only 1 lcore\n");
-
-	/* call lcore_main on master core only */
-	lcore_main();
-	return 0;
-}
diff --git a/examples/rxtx_callbacks/meson.build b/examples/rxtx_callbacks/meson.build
deleted file mode 100644
index 2b0a250..0000000
--- a/examples/rxtx_callbacks/meson.build
+++ /dev/null
@@ -1,12 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-allow_experimental_apis = true
-sources = files(
-	'main.c'
-)
diff --git a/examples/server_node_efd/Makefile b/examples/server_node_efd/Makefile
deleted file mode 100644
index d23aba3..0000000
--- a/examples/server_node_efd/Makefile
+++ /dev/null
@@ -1,16 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2016-2017 Intel Corporation
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-DIRS-$(CONFIG_RTE_EXEC_ENV_LINUXAPP) += server
-DIRS-$(CONFIG_RTE_EXEC_ENV_LINUXAPP) += node
-
-include $(RTE_SDK)/mk/rte.extsubdir.mk
diff --git a/examples/server_node_efd/node/Makefile b/examples/server_node_efd/node/Makefile
deleted file mode 100644
index fffbe35..0000000
--- a/examples/server_node_efd/node/Makefile
+++ /dev/null
@@ -1,20 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2016-2017 Intel Corporation
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-include $(RTE_SDK)/mk/rte.vars.mk
-
-# binary name
-APP = node
-
-# all source are stored in SRCS-y
-SRCS-y := node.c
-
-CFLAGS += $(WERROR_FLAGS) -O3
-CFLAGS += -I$(SRCDIR)/../shared
-
-include $(RTE_SDK)/mk/rte.extapp.mk
diff --git a/examples/server_node_efd/node/node.c b/examples/server_node_efd/node/node.c
deleted file mode 100644
index 84f7bcf..0000000
--- a/examples/server_node_efd/node/node.c
+++ /dev/null
@@ -1,386 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016-2017 Intel Corporation
- */
-
-#include <stdint.h>
-#include <stdio.h>
-#include <inttypes.h>
-#include <stdarg.h>
-#include <errno.h>
-#include <sys/queue.h>
-#include <stdlib.h>
-#include <getopt.h>
-#include <string.h>
-
-#include <rte_common.h>
-#include <rte_malloc.h>
-#include <rte_memory.h>
-#include <rte_memzone.h>
-#include <rte_eal.h>
-#include <rte_atomic.h>
-#include <rte_branch_prediction.h>
-#include <rte_log.h>
-#include <rte_per_lcore.h>
-#include <rte_launch.h>
-#include <rte_lcore.h>
-#include <rte_ring.h>
-#include <rte_debug.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-#include <rte_interrupts.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_string_fns.h>
-#include <rte_ip.h>
-
-#include "common.h"
-
-/* Number of packets to attempt to read from queue */
-#define PKT_READ_SIZE  ((uint16_t)32)
-
-/*
- * Our node id number - tells us which rx queue to read, and NIC TX
- * queue to write to.
- */
-static uint8_t node_id;
-
-#define MBQ_CAPACITY 32
-
-/* maps input ports to output ports for packets */
-static uint16_t output_ports[RTE_MAX_ETHPORTS];
-
-/* buffers up a set of packet that are ready to send */
-struct rte_eth_dev_tx_buffer *tx_buffer[RTE_MAX_ETHPORTS];
-
-/* shared data from server. We update statistics here */
-static struct tx_stats *tx_stats;
-
-static struct filter_stats *filter_stats;
-
-/*
- * print a usage message
- */
-static void
-usage(const char *progname)
-{
-	printf("Usage: %s [EAL args] -- -n <node_id>\n\n", progname);
-}
-
-/*
- * Convert the node id number from a string to an int.
- */
-static int
-parse_node_num(const char *node)
-{
-	char *end = NULL;
-	unsigned long temp;
-
-	if (node == NULL || *node == '\0')
-		return -1;
-
-	temp = strtoul(node, &end, 10);
-	if (end == NULL || *end != '\0')
-		return -1;
-
-	node_id = (uint8_t)temp;
-	return 0;
-}
-
-/*
- * Parse the application arguments to the node app.
- */
-static int
-parse_app_args(int argc, char *argv[])
-{
-	int option_index, opt;
-	char **argvopt = argv;
-	const char *progname = NULL;
-	static struct option lgopts[] = { /* no long options */
-		{NULL, 0, 0, 0 }
-	};
-	progname = argv[0];
-
-	while ((opt = getopt_long(argc, argvopt, "n:", lgopts,
-		&option_index)) != EOF) {
-		switch (opt) {
-		case 'n':
-			if (parse_node_num(optarg) != 0) {
-				usage(progname);
-				return -1;
-			}
-			break;
-		default:
-			usage(progname);
-			return -1;
-		}
-	}
-	return 0;
-}
-
-/*
- * Tx buffer error callback
- */
-static void
-flush_tx_error_callback(struct rte_mbuf **unsent, uint16_t count,
-		void *userdata) {
-	int i;
-	uint16_t port_id = (uintptr_t)userdata;
-
-	tx_stats->tx_drop[port_id] += count;
-
-	/* free the mbufs which failed from transmit */
-	for (i = 0; i < count; i++)
-		rte_pktmbuf_free(unsent[i]);
-
-}
-
-static void
-configure_tx_buffer(uint16_t port_id, uint16_t size)
-{
-	int ret;
-
-	/* Initialize TX buffers */
-	tx_buffer[port_id] = rte_zmalloc_socket("tx_buffer",
-			RTE_ETH_TX_BUFFER_SIZE(size), 0,
-			rte_eth_dev_socket_id(port_id));
-	if (tx_buffer[port_id] == NULL)
-		rte_exit(EXIT_FAILURE,
-			"Cannot allocate buffer for tx on port %u\n", port_id);
-
-	rte_eth_tx_buffer_init(tx_buffer[port_id], size);
-
-	ret = rte_eth_tx_buffer_set_err_callback(tx_buffer[port_id],
-			flush_tx_error_callback, (void *)(intptr_t)port_id);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE,
-			"Cannot set error callback for tx buffer on port %u\n",
-			port_id);
-}
-
-/*
- * set up output ports so that all traffic on port gets sent out
- * its paired port. Index using actual port numbers since that is
- * what comes in the mbuf structure.
- */
-static void
-configure_output_ports(const struct shared_info *info)
-{
-	int i;
-
-	if (info->num_ports > RTE_MAX_ETHPORTS)
-		rte_exit(EXIT_FAILURE, "Too many ethernet ports. "
-				"RTE_MAX_ETHPORTS = %u\n",
-				(unsigned int)RTE_MAX_ETHPORTS);
-	for (i = 0; i < info->num_ports - 1; i += 2) {
-		uint8_t p1 = info->id[i];
-		uint8_t p2 = info->id[i+1];
-
-		output_ports[p1] = p2;
-		output_ports[p2] = p1;
-
-		configure_tx_buffer(p1, MBQ_CAPACITY);
-		configure_tx_buffer(p2, MBQ_CAPACITY);
-
-	}
-}
-
-/*
- * Create the hash table that will contain the flows that
- * the node will handle, which will be used to decide if packet
- * is transmitted or dropped.
- */
-static struct rte_hash *
-create_hash_table(const struct shared_info *info)
-{
-	uint32_t num_flows_node = info->num_flows / info->num_nodes;
-	char name[RTE_HASH_NAMESIZE];
-	struct rte_hash *h;
-
-	/* create table */
-	struct rte_hash_parameters hash_params = {
-		.entries = num_flows_node * 2, /* table load = 50% */
-		.key_len = sizeof(uint32_t), /* Store IPv4 dest IP address */
-		.socket_id = rte_socket_id(),
-		.hash_func_init_val = 0,
-	};
-
-	snprintf(name, sizeof(name), "hash_table_%d", node_id);
-	hash_params.name = name;
-	h = rte_hash_create(&hash_params);
-
-	if (h == NULL)
-		rte_exit(EXIT_FAILURE,
-				"Problem creating the hash table for node %d\n",
-				node_id);
-	return h;
-}
-
-static void
-populate_hash_table(const struct rte_hash *h, const struct shared_info *info)
-{
-	unsigned int i;
-	int32_t ret;
-	uint32_t ip_dst;
-	uint32_t num_flows_node = 0;
-	uint64_t target_node;
-
-	/* Add flows in table */
-	for (i = 0; i < info->num_flows; i++) {
-		target_node = i % info->num_nodes;
-		if (target_node != node_id)
-			continue;
-
-		ip_dst = rte_cpu_to_be_32(i);
-
-		ret = rte_hash_add_key(h, (void *) &ip_dst);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "Unable to add entry %u "
-					"in hash table\n", i);
-		else
-			num_flows_node++;
-
-	}
-
-	printf("Hash table: Adding 0x%x keys\n", num_flows_node);
-}
-
-/*
- * This function performs routing of packets
- * Just sends each input packet out an output port based solely on the input
- * port it arrived on.
- */
-static inline void
-transmit_packet(struct rte_mbuf *buf)
-{
-	int sent;
-	const uint16_t in_port = buf->port;
-	const uint16_t out_port = output_ports[in_port];
-	struct rte_eth_dev_tx_buffer *buffer = tx_buffer[out_port];
-
-	sent = rte_eth_tx_buffer(out_port, node_id, buffer, buf);
-	if (sent)
-		tx_stats->tx[out_port] += sent;
-
-}
-
-static inline void
-handle_packets(struct rte_hash *h, struct rte_mbuf **bufs, uint16_t num_packets)
-{
-	struct ipv4_hdr *ipv4_hdr;
-	uint32_t ipv4_dst_ip[PKT_READ_SIZE];
-	const void *key_ptrs[PKT_READ_SIZE];
-	unsigned int i;
-	int32_t positions[PKT_READ_SIZE] = {0};
-
-	for (i = 0; i < num_packets; i++) {
-		/* Handle IPv4 header.*/
-		ipv4_hdr = rte_pktmbuf_mtod_offset(bufs[i], struct ipv4_hdr *,
-				sizeof(struct ether_hdr));
-		ipv4_dst_ip[i] = ipv4_hdr->dst_addr;
-		key_ptrs[i] = &ipv4_dst_ip[i];
-	}
-	/* Check if packets belongs to any flows handled by this node */
-	rte_hash_lookup_bulk(h, key_ptrs, num_packets, positions);
-
-	for (i = 0; i < num_packets; i++) {
-		if (likely(positions[i] >= 0)) {
-			filter_stats->passed++;
-			transmit_packet(bufs[i]);
-		} else {
-			filter_stats->drop++;
-			/* Drop packet, as flow is not handled by this node */
-			rte_pktmbuf_free(bufs[i]);
-		}
-	}
-}
-
-/*
- * Application main function - loops through
- * receiving and processing packets. Never returns
- */
-int
-main(int argc, char *argv[])
-{
-	const struct rte_memzone *mz;
-	struct rte_ring *rx_ring;
-	struct rte_hash *h;
-	struct rte_mempool *mp;
-	struct shared_info *info;
-	int need_flush = 0; /* indicates whether we have unsent packets */
-	int retval;
-	void *pkts[PKT_READ_SIZE];
-	uint16_t sent;
-
-	retval = rte_eal_init(argc, argv);
-	if (retval  < 0)
-		return -1;
-	argc -= retval;
-	argv += retval;
-
-	if (parse_app_args(argc, argv) < 0)
-		rte_exit(EXIT_FAILURE, "Invalid command-line arguments\n");
-
-	if (rte_eth_dev_count() == 0)
-		rte_exit(EXIT_FAILURE, "No Ethernet ports - bye\n");
-
-	rx_ring = rte_ring_lookup(get_rx_queue_name(node_id));
-	if (rx_ring == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot get RX ring - "
-				"is server process running?\n");
-
-	mp = rte_mempool_lookup(PKTMBUF_POOL_NAME);
-	if (mp == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot get mempool for mbufs\n");
-
-	mz = rte_memzone_lookup(MZ_SHARED_INFO);
-	if (mz == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot get port info structure\n");
-	info = mz->addr;
-	tx_stats = &(info->tx_stats[node_id]);
-	filter_stats = &(info->filter_stats[node_id]);
-
-	configure_output_ports(info);
-
-	h = create_hash_table(info);
-
-	populate_hash_table(h, info);
-
-	RTE_LOG(INFO, APP, "Finished Process Init.\n");
-
-	printf("\nNode process %d handling packets\n", node_id);
-	printf("[Press Ctrl-C to quit ...]\n");
-
-	for (;;) {
-		uint16_t  rx_pkts = PKT_READ_SIZE;
-		uint16_t port;
-
-		/*
-		 * Try dequeuing max possible packets first, if that fails,
-		 * get the most we can. Loop body should only execute once,
-		 * maximum
-		 */
-		while (rx_pkts > 0 &&
-				unlikely(rte_ring_dequeue_bulk(rx_ring, pkts,
-					rx_pkts, NULL) == 0))
-			rx_pkts = (uint16_t)RTE_MIN(rte_ring_count(rx_ring),
-					PKT_READ_SIZE);
-
-		if (unlikely(rx_pkts == 0)) {
-			if (need_flush)
-				for (port = 0; port < info->num_ports; port++) {
-					sent = rte_eth_tx_buffer_flush(
-							info->id[port],
-							node_id,
-							tx_buffer[port]);
-					if (unlikely(sent))
-						tx_stats->tx[port] += sent;
-				}
-			need_flush = 0;
-			continue;
-		}
-
-		handle_packets(h, (struct rte_mbuf **)pkts, rx_pkts);
-
-		need_flush = 1;
-	}
-}
diff --git a/examples/server_node_efd/server/Makefile b/examples/server_node_efd/server/Makefile
deleted file mode 100644
index cbb91eb..0000000
--- a/examples/server_node_efd/server/Makefile
+++ /dev/null
@@ -1,29 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2016-2017 Intel Corporation
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-ifneq ($(CONFIG_RTE_EXEC_ENV), "linuxapp")
-$(error This application can only operate in a linuxapp environment, \
-please change the definition of the RTE_TARGET environment variable)
-endif
-
-# binary name
-APP = server
-
-# all source are stored in SRCS-y
-SRCS-y := main.c init.c args.c
-
-INC := $(sort $(wildcard *.h))
-
-CFLAGS += $(WERROR_FLAGS) -O3
-CFLAGS += -I$(SRCDIR)/../shared
-
-include $(RTE_SDK)/mk/rte.extapp.mk
diff --git a/examples/server_node_efd/server/args.c b/examples/server_node_efd/server/args.c
deleted file mode 100644
index 0e5e897..0000000
--- a/examples/server_node_efd/server/args.c
+++ /dev/null
@@ -1,171 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016-2017 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <stdint.h>
-#include <getopt.h>
-#include <stdarg.h>
-#include <errno.h>
-
-#include <rte_memory.h>
-#include <rte_string_fns.h>
-
-#include "common.h"
-#include "args.h"
-#include "init.h"
-
-/* 1M flows by default */
-#define DEFAULT_NUM_FLOWS    0x100000
-
-/* global var for number of nodes - extern in header */
-uint8_t num_nodes;
-/* global var for number of flows - extern in header */
-uint32_t num_flows = DEFAULT_NUM_FLOWS;
-
-static const char *progname;
-
-/**
- * Prints out usage information to stdout
- */
-static void
-usage(void)
-{
-	printf("%s [EAL options] -- -p PORTMASK -n NUM_NODES -f NUM_FLOWS\n"
-		" -p PORTMASK: hexadecimal bitmask of ports to use\n"
-		" -n NUM_NODES: number of node processes to use\n"
-		" -f NUM_FLOWS: number of flows to be added in the EFD table\n",
-		progname);
-}
-
-/**
- * The ports to be used by the application are passed in
- * the form of a bitmask. This function parses the bitmask
- * and places the port numbers to be used into the port[]
- * array variable
- */
-static int
-parse_portmask(uint8_t max_ports, const char *portmask)
-{
-	char *end = NULL;
-	unsigned long pm;
-	uint8_t count = 0;
-
-	if (portmask == NULL || *portmask == '\0')
-		return -1;
-
-	/* convert parameter to a number and verify */
-	pm = strtoul(portmask, &end, 16);
-	if (end == NULL || *end != '\0' || pm == 0)
-		return -1;
-
-	/* loop through bits of the mask and mark ports */
-	while (pm != 0) {
-		if (pm & 0x01) { /* bit is set in mask, use port */
-			if (count >= max_ports)
-				printf("WARNING: requested port %u not present"
-				" - ignoring\n", (unsigned int)count);
-			else
-			    info->id[info->num_ports++] = count;
-		}
-		pm = (pm >> 1);
-		count++;
-	}
-
-	return 0;
-}
-
-/**
- * Take the number of nodes parameter passed to the app
- * and convert to a number to store in the num_nodes variable
- */
-static int
-parse_num_nodes(const char *nodes)
-{
-	char *end = NULL;
-	unsigned long temp;
-
-	if (nodes == NULL || *nodes == '\0')
-		return -1;
-
-	temp = strtoul(nodes, &end, 10);
-	if (end == NULL || *end != '\0' || temp == 0)
-		return -1;
-
-	num_nodes = (uint8_t)temp;
-	return 0;
-}
-
-static int
-parse_num_flows(const char *flows)
-{
-	char *end = NULL;
-
-	/* parse hexadecimal string */
-	num_flows = strtoul(flows, &end, 16);
-	if ((flows[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (num_flows == 0)
-		return -1;
-
-	return 0;
-}
-
-/**
- * The application specific arguments follow the DPDK-specific
- * arguments which are stripped by the DPDK init. This function
- * processes these application arguments, printing usage info
- * on error.
- */
-int
-parse_app_args(uint8_t max_ports, int argc, char *argv[])
-{
-	int option_index, opt;
-	char **argvopt = argv;
-	static struct option lgopts[] = { /* no long options */
-		{NULL, 0, 0, 0 }
-	};
-	progname = argv[0];
-
-	while ((opt = getopt_long(argc, argvopt, "n:f:p:", lgopts,
-			&option_index)) != EOF) {
-		switch (opt) {
-		case 'p':
-			if (parse_portmask(max_ports, optarg) != 0) {
-				usage();
-				return -1;
-			}
-			break;
-		case 'n':
-			if (parse_num_nodes(optarg) != 0) {
-				usage();
-				return -1;
-			}
-			break;
-		case 'f':
-			if (parse_num_flows(optarg) != 0) {
-				usage();
-				return -1;
-			}
-			break;
-		default:
-			printf("ERROR: Unknown option '%c'\n", opt);
-			usage();
-			return -1;
-		}
-	}
-
-	if (info->num_ports == 0 || num_nodes == 0) {
-		usage();
-		return -1;
-	}
-
-	if (info->num_ports % 2 != 0) {
-		printf("ERROR: application requires an even "
-				"number of ports to use\n");
-		return -1;
-	}
-	return 0;
-}
diff --git a/examples/server_node_efd/server/args.h b/examples/server_node_efd/server/args.h
deleted file mode 100644
index 226f669..0000000
--- a/examples/server_node_efd/server/args.h
+++ /dev/null
@@ -1,10 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016-2017 Intel Corporation
- */
-
-#ifndef _ARGS_H_
-#define _ARGS_H_
-
-int parse_app_args(uint8_t max_ports, int argc, char *argv[]);
-
-#endif /* ifndef _ARGS_H_ */
diff --git a/examples/server_node_efd/server/init.c b/examples/server_node_efd/server/init.c
deleted file mode 100644
index 07b6882..0000000
--- a/examples/server_node_efd/server/init.c
+++ /dev/null
@@ -1,359 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016-2017 Intel Corporation
- */
-
-#include <stdint.h>
-#include <stdio.h>
-#include <string.h>
-#include <sys/queue.h>
-#include <errno.h>
-#include <stdarg.h>
-#include <inttypes.h>
-
-#include <rte_common.h>
-#include <rte_memory.h>
-#include <rte_memzone.h>
-#include <rte_eal.h>
-#include <rte_byteorder.h>
-#include <rte_atomic.h>
-#include <rte_launch.h>
-#include <rte_per_lcore.h>
-#include <rte_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_debug.h>
-#include <rte_ring.h>
-#include <rte_log.h>
-#include <rte_mempool.h>
-#include <rte_memcpy.h>
-#include <rte_mbuf.h>
-#include <rte_interrupts.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_malloc.h>
-#include <rte_string_fns.h>
-#include <rte_cycles.h>
-#include <rte_efd.h>
-#include <rte_hash.h>
-
-#include "common.h"
-#include "args.h"
-#include "init.h"
-
-#define MBUFS_PER_NODE 1536
-#define MBUFS_PER_PORT 1536
-#define MBUF_CACHE_SIZE 512
-
-#define RTE_MP_RX_DESC_DEFAULT 512
-#define RTE_MP_TX_DESC_DEFAULT 512
-#define NODE_QUEUE_RINGSIZE 128
-
-#define NO_FLAGS 0
-
-/* The mbuf pool for packet rx */
-struct rte_mempool *pktmbuf_pool;
-
-/* array of info/queues for nodes */
-struct node *nodes;
-
-/* EFD table */
-struct rte_efd_table *efd_table;
-
-/* Shared info between server and nodes */
-struct shared_info *info;
-
-/**
- * Initialise the mbuf pool for packet reception for the NIC, and any other
- * buffer pools needed by the app - currently none.
- */
-static int
-init_mbuf_pools(void)
-{
-	const unsigned int num_mbufs = (num_nodes * MBUFS_PER_NODE) +
-			(info->num_ports * MBUFS_PER_PORT);
-
-	/*
-	 * Don't pass single-producer/single-consumer flags to mbuf create as it
-	 * seems faster to use a cache instead
-	 */
-	printf("Creating mbuf pool '%s' [%u mbufs] ...\n",
-			PKTMBUF_POOL_NAME, num_mbufs);
-	pktmbuf_pool = rte_pktmbuf_pool_create(PKTMBUF_POOL_NAME, num_mbufs,
-		MBUF_CACHE_SIZE, 0, RTE_MBUF_DEFAULT_BUF_SIZE, rte_socket_id());
-
-	return pktmbuf_pool == NULL; /* 0  on success */
-}
-
-/**
- * Initialise an individual port:
- * - configure number of rx and tx rings
- * - set up each rx ring, to pull from the main mbuf pool
- * - set up each tx ring
- * - start the port and report its status to stdout
- */
-static int
-init_port(uint16_t port_num)
-{
-	/* for port configuration all features are off by default */
-	struct rte_eth_conf port_conf = {
-		.rxmode = {
-			.mq_mode = ETH_MQ_RX_RSS,
-			.ignore_offload_bitfield = 1,
-		},
-	};
-	const uint16_t rx_rings = 1, tx_rings = num_nodes;
-	uint16_t rx_ring_size = RTE_MP_RX_DESC_DEFAULT;
-	uint16_t tx_ring_size = RTE_MP_TX_DESC_DEFAULT;
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_txconf txconf;
-
-	uint16_t q;
-	int retval;
-
-	printf("Port %u init ... ", port_num);
-	fflush(stdout);
-
-	rte_eth_dev_info_get(port_num, &dev_info);
-	if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-		port_conf.txmode.offloads |=
-			DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-
-	/*
-	 * Standard DPDK port initialisation - config port, then set up
-	 * rx and tx rings.
-	 */
-	retval = rte_eth_dev_configure(port_num, rx_rings, tx_rings, &port_conf);
-	if (retval != 0)
-		return retval;
-
-	retval = rte_eth_dev_adjust_nb_rx_tx_desc(port_num, &rx_ring_size,
-			&tx_ring_size);
-	if (retval != 0)
-		return retval;
-
-	for (q = 0; q < rx_rings; q++) {
-		retval = rte_eth_rx_queue_setup(port_num, q, rx_ring_size,
-				rte_eth_dev_socket_id(port_num),
-				NULL, pktmbuf_pool);
-		if (retval < 0)
-			return retval;
-	}
-
-	txconf = dev_info.default_txconf;
-	txconf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-	txconf.offloads = port_conf.txmode.offloads;
-	for (q = 0; q < tx_rings; q++) {
-		retval = rte_eth_tx_queue_setup(port_num, q, tx_ring_size,
-				rte_eth_dev_socket_id(port_num),
-				&txconf);
-		if (retval < 0)
-			return retval;
-	}
-
-	rte_eth_promiscuous_enable(port_num);
-
-	retval = rte_eth_dev_start(port_num);
-	if (retval < 0)
-		return retval;
-
-	printf("done:\n");
-
-	return 0;
-}
-
-/**
- * Set up the DPDK rings which will be used to pass packets, via
- * pointers, between the multi-process server and node processes.
- * Each node needs one RX queue.
- */
-static int
-init_shm_rings(void)
-{
-	unsigned int i;
-	unsigned int socket_id;
-	const char *q_name;
-	const unsigned int ringsize = NODE_QUEUE_RINGSIZE;
-
-	nodes = rte_malloc("node details",
-		sizeof(*nodes) * num_nodes, 0);
-	if (nodes == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot allocate memory for "
-				"node program details\n");
-
-	for (i = 0; i < num_nodes; i++) {
-		/* Create an RX queue for each node */
-		socket_id = rte_socket_id();
-		q_name = get_rx_queue_name(i);
-		nodes[i].rx_q = rte_ring_create(q_name,
-				ringsize, socket_id,
-				RING_F_SP_ENQ | RING_F_SC_DEQ);
-		if (nodes[i].rx_q == NULL)
-			rte_exit(EXIT_FAILURE, "Cannot create rx ring queue "
-					"for node %u\n", i);
-	}
-	return 0;
-}
-
-/*
- * Create EFD table which will contain all the flows
- * that will be distributed among the nodes
- */
-static void
-create_efd_table(void)
-{
-	uint8_t socket_id = rte_socket_id();
-
-	/* create table */
-	efd_table = rte_efd_create("flow table", num_flows * 2, sizeof(uint32_t),
-			1 << socket_id,	socket_id);
-
-	if (efd_table == NULL)
-		rte_exit(EXIT_FAILURE, "Problem creating the flow table\n");
-}
-
-static void
-populate_efd_table(void)
-{
-	unsigned int i;
-	int32_t ret;
-	uint32_t ip_dst;
-	uint8_t socket_id = rte_socket_id();
-	uint64_t node_id;
-
-	/* Add flows in table */
-	for (i = 0; i < num_flows; i++) {
-		node_id = i % num_nodes;
-
-		ip_dst = rte_cpu_to_be_32(i);
-		ret = rte_efd_update(efd_table, socket_id,
-				(void *)&ip_dst, (efd_value_t)node_id);
-		if (ret < 0)
-			rte_exit(EXIT_FAILURE, "Unable to add entry %u in "
-					"EFD table\n", i);
-	}
-
-	printf("EFD table: Adding 0x%x keys\n", num_flows);
-}
-
-/* Check the link status of all ports in up to 9s, and print them finally */
-static void
-check_all_ports_link_status(uint16_t port_num, uint32_t port_mask)
-{
-#define CHECK_INTERVAL 100 /* 100ms */
-#define MAX_CHECK_TIME 90 /* 9s (90 * 100ms) in total */
-	uint8_t count, all_ports_up, print_flag = 0;
-	uint16_t portid;
-	struct rte_eth_link link;
-
-	printf("\nChecking link status");
-	fflush(stdout);
-	for (count = 0; count <= MAX_CHECK_TIME; count++) {
-		all_ports_up = 1;
-		for (portid = 0; portid < port_num; portid++) {
-			if ((port_mask & (1 << info->id[portid])) == 0)
-				continue;
-			memset(&link, 0, sizeof(link));
-			rte_eth_link_get_nowait(info->id[portid], &link);
-			/* print link status if flag set */
-			if (print_flag == 1) {
-				if (link.link_status)
-					printf(
-					"Port%d Link Up. Speed %u Mbps - %s\n",
-						info->id[portid],
-						link.link_speed,
-				(link.link_duplex == ETH_LINK_FULL_DUPLEX) ?
-					("full-duplex") : ("half-duplex\n"));
-				else
-					printf("Port %d Link Down\n",
-						info->id[portid]);
-				continue;
-			}
-			/* clear all_ports_up flag if any link down */
-			if (link.link_status == ETH_LINK_DOWN) {
-				all_ports_up = 0;
-				break;
-			}
-		}
-		/* after finally printing all link status, get out */
-		if (print_flag == 1)
-			break;
-
-		if (all_ports_up == 0) {
-			printf(".");
-			fflush(stdout);
-			rte_delay_ms(CHECK_INTERVAL);
-		}
-
-		/* set the print_flag if all ports up or timeout */
-		if (all_ports_up == 1 || count == (MAX_CHECK_TIME - 1)) {
-			print_flag = 1;
-			printf("done\n");
-		}
-	}
-}
-
-/**
- * Main init function for the multi-process server app,
- * calls subfunctions to do each stage of the initialisation.
- */
-int
-init(int argc, char *argv[])
-{
-	int retval;
-	const struct rte_memzone *mz;
-	uint8_t i, total_ports;
-
-	/* init EAL, parsing EAL args */
-	retval = rte_eal_init(argc, argv);
-	if (retval < 0)
-		return -1;
-	argc -= retval;
-	argv += retval;
-
-	/* get total number of ports */
-	total_ports = rte_eth_dev_count();
-
-	/* set up array for port data */
-	mz = rte_memzone_reserve(MZ_SHARED_INFO, sizeof(*info),
-				rte_socket_id(), NO_FLAGS);
-	if (mz == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot reserve memory zone "
-				"for port information\n");
-	memset(mz->addr, 0, sizeof(*info));
-	info = mz->addr;
-
-	/* parse additional, application arguments */
-	retval = parse_app_args(total_ports, argc, argv);
-	if (retval != 0)
-		return -1;
-
-	/* initialise mbuf pools */
-	retval = init_mbuf_pools();
-	if (retval != 0)
-		rte_exit(EXIT_FAILURE, "Cannot create needed mbuf pools\n");
-
-	/* now initialise the ports we will use */
-	for (i = 0; i < info->num_ports; i++) {
-		retval = init_port(info->id[i]);
-		if (retval != 0)
-			rte_exit(EXIT_FAILURE, "Cannot initialise port %u\n",
-					(unsigned int) i);
-	}
-
-	check_all_ports_link_status(info->num_ports, (~0x0));
-
-	/* initialise the node queues/rings for inter-eu comms */
-	init_shm_rings();
-
-	/* Create the EFD table */
-	create_efd_table();
-
-	/* Populate the EFD table */
-	populate_efd_table();
-
-	/* Share the total number of nodes */
-	info->num_nodes = num_nodes;
-
-	/* Share the total number of flows */
-	info->num_flows = num_flows;
-	return 0;
-}
diff --git a/examples/server_node_efd/server/init.h b/examples/server_node_efd/server/init.h
deleted file mode 100644
index 506e2e4..0000000
--- a/examples/server_node_efd/server/init.h
+++ /dev/null
@@ -1,47 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016-2017 Intel Corporation
- */
-
-#ifndef _INIT_H_
-#define _INIT_H_
-
-/*
- * #include <rte_ring.h>
- * #include "args.h"
- */
-
-/*
- * Define a node structure with all needed info, including
- * stats from the nodes.
- */
-struct node {
-	struct rte_ring *rx_q;
-	unsigned int node_id;
-	/* these stats hold how many packets the node will actually receive,
-	 * and how many packets were dropped because the node's queue was full.
-	 * The port-info stats, in contrast, record how many packets were received
-	 * or transmitted on an actual NIC port.
-	 */
-	struct {
-		uint64_t rx;
-		uint64_t rx_drop;
-	} stats;
-};
-
-extern struct rte_efd_table *efd_table;
-extern struct node *nodes;
-
-/*
- * shared information between server and nodes: number of nodes,
- * port numbers, rx and tx stats etc.
- */
-extern struct shared_info *info;
-
-extern struct rte_mempool *pktmbuf_pool;
-extern uint8_t num_nodes;
-extern unsigned int num_sockets;
-extern uint32_t num_flows;
-
-int init(int argc, char *argv[]);
-
-#endif /* ifndef _INIT_H_ */
diff --git a/examples/server_node_efd/server/main.c b/examples/server_node_efd/server/main.c
deleted file mode 100644
index 404f1f1..0000000
--- a/examples/server_node_efd/server/main.c
+++ /dev/null
@@ -1,329 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016-2017 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <string.h>
-#include <unistd.h>
-#include <stdint.h>
-#include <stdarg.h>
-#include <inttypes.h>
-#include <sys/queue.h>
-#include <errno.h>
-#include <netinet/ip.h>
-
-#include <rte_common.h>
-#include <rte_memory.h>
-#include <rte_eal.h>
-#include <rte_launch.h>
-#include <rte_per_lcore.h>
-#include <rte_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_atomic.h>
-#include <rte_ring.h>
-#include <rte_log.h>
-#include <rte_debug.h>
-#include <rte_mempool.h>
-#include <rte_memcpy.h>
-#include <rte_mbuf.h>
-#include <rte_ether.h>
-#include <rte_interrupts.h>
-#include <rte_ethdev.h>
-#include <rte_byteorder.h>
-#include <rte_malloc.h>
-#include <rte_string_fns.h>
-#include <rte_efd.h>
-#include <rte_ip.h>
-
-#include "common.h"
-#include "args.h"
-#include "init.h"
-
-/*
- * When doing reads from the NIC or the node queues,
- * use this batch size
- */
-#define PACKET_READ_SIZE 32
-
-/*
- * Local buffers to put packets in, used to send packets in bursts to the
- * nodes
- */
-struct node_rx_buf {
-	struct rte_mbuf *buffer[PACKET_READ_SIZE];
-	uint16_t count;
-};
-
-struct efd_stats {
-	uint64_t distributed;
-	uint64_t drop;
-} flow_dist_stats;
-
-/* One buffer per node rx queue - dynamically allocate array */
-static struct node_rx_buf *cl_rx_buf;
-
-static const char *
-get_printable_mac_addr(uint16_t port)
-{
-	static const char err_address[] = "00:00:00:00:00:00";
-	static char addresses[RTE_MAX_ETHPORTS][sizeof(err_address)];
-	struct ether_addr mac;
-
-	if (unlikely(port >= RTE_MAX_ETHPORTS))
-		return err_address;
-	if (unlikely(addresses[port][0] == '\0')) {
-		rte_eth_macaddr_get(port, &mac);
-		snprintf(addresses[port], sizeof(addresses[port]),
-				"%02x:%02x:%02x:%02x:%02x:%02x\n",
-				mac.addr_bytes[0], mac.addr_bytes[1],
-				mac.addr_bytes[2], mac.addr_bytes[3],
-				mac.addr_bytes[4], mac.addr_bytes[5]);
-	}
-	return addresses[port];
-}
-
-/*
- * This function displays the recorded statistics for each port
- * and for each node. It uses ANSI terminal codes to clear
- * screen when called. It is called from a single non-master
- * thread in the server process, when the process is run with more
- * than one lcore enabled.
- */
-static void
-do_stats_display(void)
-{
-	unsigned int i, j;
-	const char clr[] = {27, '[', '2', 'J', '\0'};
-	const char topLeft[] = {27, '[', '1', ';', '1', 'H', '\0'};
-	uint64_t port_tx[RTE_MAX_ETHPORTS], port_tx_drop[RTE_MAX_ETHPORTS];
-	uint64_t node_tx[MAX_NODES], node_tx_drop[MAX_NODES];
-
-	/* to get TX stats, we need to do some summing calculations */
-	memset(port_tx, 0, sizeof(port_tx));
-	memset(port_tx_drop, 0, sizeof(port_tx_drop));
-	memset(node_tx, 0, sizeof(node_tx));
-	memset(node_tx_drop, 0, sizeof(node_tx_drop));
-
-	for (i = 0; i < num_nodes; i++) {
-		const struct tx_stats *tx = &info->tx_stats[i];
-
-		for (j = 0; j < info->num_ports; j++) {
-			const uint64_t tx_val = tx->tx[info->id[j]];
-			const uint64_t drop_val = tx->tx_drop[info->id[j]];
-
-			port_tx[j] += tx_val;
-			port_tx_drop[j] += drop_val;
-			node_tx[i] += tx_val;
-			node_tx_drop[i] += drop_val;
-		}
-	}
-
-	/* Clear screen and move to top left */
-	printf("%s%s", clr, topLeft);
-
-	printf("PORTS\n");
-	printf("-----\n");
-	for (i = 0; i < info->num_ports; i++)
-		printf("Port %u: '%s'\t", (unsigned int)info->id[i],
-				get_printable_mac_addr(info->id[i]));
-	printf("\n\n");
-	for (i = 0; i < info->num_ports; i++) {
-		printf("Port %u - rx: %9"PRIu64"\t"
-				"tx: %9"PRIu64"\n",
-				(unsigned int)info->id[i], info->rx_stats.rx[i],
-				port_tx[i]);
-	}
-
-	printf("\nSERVER\n");
-	printf("-----\n");
-	printf("distributed: %9"PRIu64", drop: %9"PRIu64"\n",
-			flow_dist_stats.distributed, flow_dist_stats.drop);
-
-	printf("\nNODES\n");
-	printf("-------\n");
-	for (i = 0; i < num_nodes; i++) {
-		const unsigned long long rx = nodes[i].stats.rx;
-		const unsigned long long rx_drop = nodes[i].stats.rx_drop;
-		const struct filter_stats *filter = &info->filter_stats[i];
-
-		printf("Node %2u - rx: %9llu, rx_drop: %9llu\n"
-				"            tx: %9"PRIu64", tx_drop: %9"PRIu64"\n"
-				"            filter_passed: %9"PRIu64", "
-				"filter_drop: %9"PRIu64"\n",
-				i, rx, rx_drop, node_tx[i], node_tx_drop[i],
-				filter->passed, filter->drop);
-	}
-
-	printf("\n");
-}
-
-/*
- * The function called from each non-master lcore used by the process.
- * The test_and_set function is used to randomly pick a single lcore on which
- * the code to display the statistics will run. Otherwise, the code just
- * repeatedly sleeps.
- */
-static int
-sleep_lcore(__attribute__((unused)) void *dummy)
-{
-	/* Used to pick a display thread - static, so zero-initialised */
-	static rte_atomic32_t display_stats;
-
-	/* Only one core should display stats */
-	if (rte_atomic32_test_and_set(&display_stats)) {
-		const unsigned int sleeptime = 1;
-
-		printf("Core %u displaying statistics\n", rte_lcore_id());
-
-		/* Longer initial pause so above printf is seen */
-		sleep(sleeptime * 3);
-
-		/* Loop forever: sleep always returns 0 or <= param */
-		while (sleep(sleeptime) <= sleeptime)
-			do_stats_display();
-	}
-	return 0;
-}
-
-/*
- * Function to set all the node statistic values to zero.
- * Called at program startup.
- */
-static void
-clear_stats(void)
-{
-	unsigned int i;
-
-	for (i = 0; i < num_nodes; i++)
-		nodes[i].stats.rx = nodes[i].stats.rx_drop = 0;
-}
-
-/*
- * send a burst of traffic to a node, assuming there are packets
- * available to be sent to this node
- */
-static void
-flush_rx_queue(uint16_t node)
-{
-	uint16_t j;
-	struct node *cl;
-
-	if (cl_rx_buf[node].count == 0)
-		return;
-
-	cl = &nodes[node];
-	if (rte_ring_enqueue_bulk(cl->rx_q, (void **)cl_rx_buf[node].buffer,
-			cl_rx_buf[node].count, NULL) != cl_rx_buf[node].count){
-		for (j = 0; j < cl_rx_buf[node].count; j++)
-			rte_pktmbuf_free(cl_rx_buf[node].buffer[j]);
-		cl->stats.rx_drop += cl_rx_buf[node].count;
-	} else
-		cl->stats.rx += cl_rx_buf[node].count;
-
-	cl_rx_buf[node].count = 0;
-}
-
-/*
- * marks a packet down to be sent to a particular node process
- */
-static inline void
-enqueue_rx_packet(uint8_t node, struct rte_mbuf *buf)
-{
-	cl_rx_buf[node].buffer[cl_rx_buf[node].count++] = buf;
-}
-
-/*
- * This function takes a group of packets and routes them
- * individually to the node process. Very simply round-robins the packets
- * without checking any of the packet contents.
- */
-static void
-process_packets(uint32_t port_num __rte_unused, struct rte_mbuf *pkts[],
-		uint16_t rx_count, unsigned int socket_id)
-{
-	uint16_t i;
-	uint8_t node;
-	efd_value_t data[RTE_EFD_BURST_MAX];
-	const void *key_ptrs[RTE_EFD_BURST_MAX];
-
-	struct ipv4_hdr *ipv4_hdr;
-	uint32_t ipv4_dst_ip[RTE_EFD_BURST_MAX];
-
-	for (i = 0; i < rx_count; i++) {
-		/* Handle IPv4 header.*/
-		ipv4_hdr = rte_pktmbuf_mtod_offset(pkts[i], struct ipv4_hdr *,
-				sizeof(struct ether_hdr));
-		ipv4_dst_ip[i] = ipv4_hdr->dst_addr;
-		key_ptrs[i] = (void *)&ipv4_dst_ip[i];
-	}
-
-	rte_efd_lookup_bulk(efd_table, socket_id, rx_count,
-				(const void **) key_ptrs, data);
-	for (i = 0; i < rx_count; i++) {
-		node = (uint8_t) ((uintptr_t)data[i]);
-
-		if (node >= num_nodes) {
-			/*
-			 * Node is out of range, which means that
-			 * flow has not been inserted
-			 */
-			flow_dist_stats.drop++;
-			rte_pktmbuf_free(pkts[i]);
-		} else {
-			flow_dist_stats.distributed++;
-			enqueue_rx_packet(node, pkts[i]);
-		}
-	}
-
-	for (i = 0; i < num_nodes; i++)
-		flush_rx_queue(i);
-}
-
-/*
- * Function called by the master lcore of the DPDK process.
- */
-static void
-do_packet_forwarding(void)
-{
-	unsigned int port_num = 0; /* indexes the port[] array */
-	unsigned int socket_id = rte_socket_id();
-
-	for (;;) {
-		struct rte_mbuf *buf[PACKET_READ_SIZE];
-		uint16_t rx_count;
-
-		/* read a port */
-		rx_count = rte_eth_rx_burst(info->id[port_num], 0,
-				buf, PACKET_READ_SIZE);
-		info->rx_stats.rx[port_num] += rx_count;
-
-		/* Now process the NIC packets read */
-		if (likely(rx_count > 0))
-			process_packets(port_num, buf, rx_count, socket_id);
-
-		/* move to next port */
-		if (++port_num == info->num_ports)
-			port_num = 0;
-	}
-}
-
-int
-main(int argc, char *argv[])
-{
-	/* initialise the system */
-	if (init(argc, argv) < 0)
-		return -1;
-	RTE_LOG(INFO, APP, "Finished Process Init.\n");
-
-	cl_rx_buf = calloc(num_nodes, sizeof(cl_rx_buf[0]));
-
-	/* clear statistics */
-	clear_stats();
-
-	/* put all other cores to sleep bar master */
-	rte_eal_mp_remote_launch(sleep_lcore, NULL, SKIP_MASTER);
-
-	do_packet_forwarding();
-	return 0;
-}
diff --git a/examples/server_node_efd/shared/common.h b/examples/server_node_efd/shared/common.h
deleted file mode 100644
index b8b533d..0000000
--- a/examples/server_node_efd/shared/common.h
+++ /dev/null
@@ -1,70 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2016-2017 Intel Corporation
- */
-
-#ifndef _COMMON_H_
-#define _COMMON_H_
-
-#include <rte_hash_crc.h>
-#include <rte_hash.h>
-
-#define MAX_NODES             16
-/*
- * Shared port info, including statistics information for display by server.
- * Structure will be put in a memzone.
- * - All port id values share one cache line as this data will be read-only
- * during operation.
- * - All rx statistic values share cache lines, as this data is written only
- * by the server process. (rare reads by stats display)
- * - The tx statistics have values for all ports per cache line, but the stats
- * themselves are written by the nodes, so we have a distinct set, on different
- * cache lines for each node to use.
- */
-struct rx_stats {
-	uint64_t rx[RTE_MAX_ETHPORTS];
-} __rte_cache_aligned;
-
-struct tx_stats {
-	uint64_t tx[RTE_MAX_ETHPORTS];
-	uint64_t tx_drop[RTE_MAX_ETHPORTS];
-} __rte_cache_aligned;
-
-struct filter_stats {
-	uint64_t drop;
-	uint64_t passed;
-} __rte_cache_aligned;
-
-struct shared_info {
-	uint8_t num_nodes;
-	uint16_t num_ports;
-	uint32_t num_flows;
-	uint16_t id[RTE_MAX_ETHPORTS];
-	struct rx_stats rx_stats;
-	struct tx_stats tx_stats[MAX_NODES];
-	struct filter_stats filter_stats[MAX_NODES];
-};
-
-/* define common names for structures shared between server and node */
-#define MP_NODE_RXQ_NAME "MProc_Node_%u_RX"
-#define PKTMBUF_POOL_NAME "MProc_pktmbuf_pool"
-#define MZ_SHARED_INFO "MProc_shared_info"
-
-/*
- * Given the rx queue name template above, get the queue name
- */
-static inline const char *
-get_rx_queue_name(unsigned int id)
-{
-	/*
-	 * Buffer for return value. Size calculated by %u being replaced
-	 * by maximum 3 digits (plus an extra byte for safety)
-	 */
-	static char buffer[sizeof(MP_NODE_RXQ_NAME) + 2];
-
-	snprintf(buffer, sizeof(buffer) - 1, MP_NODE_RXQ_NAME, id);
-	return buffer;
-}
-
-#define RTE_LOGTYPE_APP RTE_LOGTYPE_USER1
-
-#endif
diff --git a/examples/service_cores/Makefile b/examples/service_cores/Makefile
deleted file mode 100644
index 3156e35..0000000
--- a/examples/service_cores/Makefile
+++ /dev/null
@@ -1,64 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# binary name
-APP = service_cores
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += $(WERROR_FLAGS)
-
-# workaround for a gcc bug with noreturn attribute
-# http://gcc.gnu.org/bugzilla/show_bug.cgi?id=12603
-ifeq ($(CONFIG_RTE_TOOLCHAIN_GCC),y)
-CFLAGS_main.o += -Wno-return-type
-endif
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-
-endif
diff --git a/examples/service_cores/main.c b/examples/service_cores/main.c
deleted file mode 100644
index 2cd5729..0000000
--- a/examples/service_cores/main.c
+++ /dev/null
@@ -1,218 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2017 Intel Corporation
- */
-
-#include <unistd.h>
-#include <stdio.h>
-#include <string.h>
-#include <stdint.h>
-#include <errno.h>
-#include <sys/queue.h>
-
-#include <rte_memory.h>
-#include <rte_launch.h>
-#include <rte_eal.h>
-#include <rte_debug.h>
-#include <rte_cycles.h>
-
-/* allow application scheduling of the services */
-#include <rte_service.h>
-
-/* Allow application registration of its own services. An application does not
- * have to register services, but it can be useful if it wishes to run a
- * function on a core that is otherwise in use as a service core. In this
- * example, all services are dummy services registered by the sample app itself.
- */
-#include <rte_service_component.h>
-
-#define PROFILE_CORES_MAX 8
-#define PROFILE_SERVICE_PER_CORE 5
-
-/* dummy function to do "work" */
-static int32_t service_func(void *args)
-{
-	RTE_SET_USED(args);
-	rte_delay_us(2000);
-	return 0;
-}
-
-static struct rte_service_spec services[] = {
-	{"service_1", service_func, NULL, 0, 0},
-	{"service_2", service_func, NULL, 0, 0},
-	{"service_3", service_func, NULL, 0, 0},
-	{"service_4", service_func, NULL, 0, 0},
-	{"service_5", service_func, NULL, 0, 0},
-};
-#define NUM_SERVICES RTE_DIM(services)
-
-/* this struct holds the mapping of a particular core to all services */
-struct profile_for_core {
-	uint32_t mapped_services[PROFILE_SERVICE_PER_CORE];
-};
-
-/* struct that can be applied as the service core mapping. Items in this
- * struct will be passed to the ordinary rte_service_* APIs to configure the
- * service cores at runtime, based on the requirements.
- *
- * These profiles can be considered a "configuration" for the service cores,
- * where switching profile just changes the number of cores and the mappings
- * for each of them. As a result, the core requirements and performance of the
- * application scales.
- */
-struct profile {
-	char name[64];
-	uint32_t num_cores;
-	struct profile_for_core cores[PROFILE_CORES_MAX];
-};
-
-static struct profile profiles[] = {
-	/* profile 0: high performance */
-	{
-		.name = "High Performance",
-		.num_cores = 5,
-		.cores[0] = {.mapped_services = {1, 0, 0, 0, 0} },
-		.cores[1] = {.mapped_services = {0, 1, 0, 0, 0} },
-		.cores[2] = {.mapped_services = {0, 0, 1, 0, 0} },
-		.cores[3] = {.mapped_services = {0, 0, 0, 1, 0} },
-		.cores[4] = {.mapped_services = {0, 0, 0, 0, 1} },
-	},
-	/* profile 1: mid performance with single service priority */
-	{
-		.name = "Mid-High Performance",
-		.num_cores = 3,
-		.cores[0] = {.mapped_services = {1, 1, 0, 0, 0} },
-		.cores[1] = {.mapped_services = {0, 0, 1, 1, 0} },
-		.cores[2] = {.mapped_services = {0, 0, 0, 0, 1} },
-		.cores[3] = {.mapped_services = {0, 0, 0, 0, 0} },
-		.cores[4] = {.mapped_services = {0, 0, 0, 0, 0} },
-	},
-	/* profile 2: mid performance with single service priority */
-	{
-		.name = "Mid-Low Performance",
-		.num_cores = 2,
-		.cores[0] = {.mapped_services = {1, 1, 1, 0, 0} },
-		.cores[1] = {.mapped_services = {1, 1, 0, 1, 1} },
-		.cores[2] = {.mapped_services = {0, 0, 0, 0, 0} },
-		.cores[3] = {.mapped_services = {0, 0, 0, 0, 0} },
-		.cores[4] = {.mapped_services = {0, 0, 0, 0, 0} },
-	},
-	/* profile 3: scale down performance on single core */
-	{
-		.name = "Scale down performance",
-		.num_cores = 1,
-		.cores[0] = {.mapped_services = {1, 1, 1, 1, 1} },
-		.cores[1] = {.mapped_services = {0, 0, 0, 0, 0} },
-		.cores[2] = {.mapped_services = {0, 0, 0, 0, 0} },
-		.cores[3] = {.mapped_services = {0, 0, 0, 0, 0} },
-		.cores[4] = {.mapped_services = {0, 0, 0, 0, 0} },
-	},
-};
-#define NUM_PROFILES RTE_DIM(profiles)
-
-static void
-apply_profile(int profile_id)
-{
-	uint32_t i;
-	uint32_t s;
-	int ret;
-	struct profile *p = &profiles[profile_id];
-	const uint8_t core_off = 1;
-
-	for (i = 0; i < p->num_cores; i++) {
-		uint32_t core = i + core_off;
-		ret = rte_service_lcore_add(core);
-		if (ret && ret != -EALREADY)
-			printf("core %d added ret %d\n", core, ret);
-
-		ret = rte_service_lcore_start(core);
-		if (ret && ret != -EALREADY)
-			printf("core %d start ret %d\n", core, ret);
-
-		for (s = 0; s < NUM_SERVICES; s++) {
-			if (rte_service_map_lcore_set(s, core,
-					p->cores[i].mapped_services[s]))
-				printf("failed to map lcore %d\n", core);
-		}
-	}
-
-	for ( ; i < PROFILE_CORES_MAX; i++) {
-		uint32_t core = i + core_off;
-		for (s = 0; s < NUM_SERVICES; s++) {
-			ret = rte_service_map_lcore_set(s, core, 0);
-			if (ret && ret != -EINVAL) {
-				printf("%s %d: map lcore set = %d\n", __func__,
-						__LINE__, ret);
-			}
-		}
-		ret = rte_service_lcore_stop(core);
-		if (ret && ret != -EALREADY) {
-			printf("%s %d: lcore stop = %d\n", __func__,
-					__LINE__, ret);
-		}
-		ret = rte_service_lcore_del(core);
-		if (ret && ret != -EINVAL) {
-			printf("%s %d: lcore del = %d\n", __func__,
-					__LINE__, ret);
-		}
-	}
-}
-
-int
-main(int argc, char **argv)
-{
-	int ret;
-
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_panic("Cannot init EAL\n");
-
-	uint32_t i;
-	for (i = 0; i < NUM_SERVICES; i++) {
-		services[i].callback_userdata = 0;
-		uint32_t id;
-		ret = rte_service_component_register(&services[i], &id);
-		if (ret)
-			rte_exit(-1, "service register() failed");
-
-		/* set the service itself to be ready to run. In the case of
-		 * ethdev, eventdev etc PMDs, this will be set when the
-		 * appropriate configure or setup function is called.
-		 */
-		rte_service_component_runstate_set(id, 1);
-
-		/* Collect statistics for the service */
-		rte_service_set_stats_enable(id, 1);
-
-		/* the application sets the service to be active. Note that the
-		 * previous component_runstate_set() is the PMD indicating
-		 * ready, while this function is the application setting the
-		 * service to run. Applications can choose to not run a service
-		 * by setting runstate to 0 at any time.
-		 */
-		ret = rte_service_runstate_set(id, 1);
-		if (ret)
-			return -ENOEXEC;
-	}
-
-	i = 0;
-	while (1) {
-		const char clr[] = { 27, '[', '2', 'J', '\0' };
-		const char topLeft[] = { 27, '[', '1', ';', '1', 'H', '\0' };
-		printf("%s%s", clr, topLeft);
-
-		apply_profile(i);
-		printf("\n==> Profile: %s\n\n", profiles[i].name);
-
-		sleep(1);
-		rte_service_dump(stdout, UINT32_MAX);
-
-		sleep(5);
-		rte_service_dump(stdout, UINT32_MAX);
-
-		i++;
-		if (i >= NUM_PROFILES)
-			i = 0;
-	}
-
-	return 0;
-}
diff --git a/examples/service_cores/meson.build b/examples/service_cores/meson.build
deleted file mode 100644
index 2b0a250..0000000
--- a/examples/service_cores/meson.build
+++ /dev/null
@@ -1,12 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-allow_experimental_apis = true
-sources = files(
-	'main.c'
-)
diff --git a/examples/skeleton/Makefile b/examples/skeleton/Makefile
deleted file mode 100644
index a4a1860..0000000
--- a/examples/skeleton/Makefile
+++ /dev/null
@@ -1,65 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-# binary name
-APP = basicfwd
-
-# all source are stored in SRCS-y
-SRCS-y := basicfwd.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else # Build using legacy build system
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += $(WERROR_FLAGS)
-
-# workaround for a gcc bug with noreturn attribute
-# http://gcc.gnu.org/bugzilla/show_bug.cgi?id=12603
-ifeq ($(CONFIG_RTE_TOOLCHAIN_GCC),y)
-CFLAGS_main.o += -Wno-return-type
-endif
-
-EXTRA_CFLAGS += -O3 -g -Wfatal-errors
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-endif
diff --git a/examples/skeleton/basicfwd.c b/examples/skeleton/basicfwd.c
deleted file mode 100644
index 5ac1dc8..0000000
--- a/examples/skeleton/basicfwd.c
+++ /dev/null
@@ -1,200 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#include <stdint.h>
-#include <inttypes.h>
-#include <rte_eal.h>
-#include <rte_ethdev.h>
-#include <rte_cycles.h>
-#include <rte_lcore.h>
-#include <rte_mbuf.h>
-
-#define RX_RING_SIZE 1024
-#define TX_RING_SIZE 1024
-
-#define NUM_MBUFS 8191
-#define MBUF_CACHE_SIZE 250
-#define BURST_SIZE 32
-
-static const struct rte_eth_conf port_conf_default = {
-	.rxmode = {
-		.max_rx_pkt_len = ETHER_MAX_LEN,
-		.ignore_offload_bitfield = 1,
-	},
-};
-
-/* basicfwd.c: Basic DPDK skeleton forwarding example. */
-
-/*
- * Initializes a given port using global settings and with the RX buffers
- * coming from the mbuf_pool passed as a parameter.
- */
-static inline int
-port_init(uint16_t port, struct rte_mempool *mbuf_pool)
-{
-	struct rte_eth_conf port_conf = port_conf_default;
-	const uint16_t rx_rings = 1, tx_rings = 1;
-	uint16_t nb_rxd = RX_RING_SIZE;
-	uint16_t nb_txd = TX_RING_SIZE;
-	int retval;
-	uint16_t q;
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_txconf txconf;
-
-	if (!rte_eth_dev_is_valid_port(port))
-		return -1;
-
-	rte_eth_dev_info_get(port, &dev_info);
-	if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-		port_conf.txmode.offloads |=
-			DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-
-	/* Configure the Ethernet device. */
-	retval = rte_eth_dev_configure(port, rx_rings, tx_rings, &port_conf);
-	if (retval != 0)
-		return retval;
-
-	retval = rte_eth_dev_adjust_nb_rx_tx_desc(port, &nb_rxd, &nb_txd);
-	if (retval != 0)
-		return retval;
-
-	/* Allocate and set up 1 RX queue per Ethernet port. */
-	for (q = 0; q < rx_rings; q++) {
-		retval = rte_eth_rx_queue_setup(port, q, nb_rxd,
-				rte_eth_dev_socket_id(port), NULL, mbuf_pool);
-		if (retval < 0)
-			return retval;
-	}
-
-	txconf = dev_info.default_txconf;
-	txconf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-	txconf.offloads = port_conf.txmode.offloads;
-	/* Allocate and set up 1 TX queue per Ethernet port. */
-	for (q = 0; q < tx_rings; q++) {
-		retval = rte_eth_tx_queue_setup(port, q, nb_txd,
-				rte_eth_dev_socket_id(port), &txconf);
-		if (retval < 0)
-			return retval;
-	}
-
-	/* Start the Ethernet port. */
-	retval = rte_eth_dev_start(port);
-	if (retval < 0)
-		return retval;
-
-	/* Display the port MAC address. */
-	struct ether_addr addr;
-	rte_eth_macaddr_get(port, &addr);
-	printf("Port %u MAC: %02" PRIx8 " %02" PRIx8 " %02" PRIx8
-			   " %02" PRIx8 " %02" PRIx8 " %02" PRIx8 "\n",
-			port,
-			addr.addr_bytes[0], addr.addr_bytes[1],
-			addr.addr_bytes[2], addr.addr_bytes[3],
-			addr.addr_bytes[4], addr.addr_bytes[5]);
-
-	/* Enable RX in promiscuous mode for the Ethernet device. */
-	rte_eth_promiscuous_enable(port);
-
-	return 0;
-}
-
-/*
- * The lcore main. This is the main thread that does the work, reading from
- * an input port and writing to an output port.
- */
-static __attribute__((noreturn)) void
-lcore_main(void)
-{
-	uint16_t port;
-
-	/*
-	 * Check that the port is on the same NUMA node as the polling thread
-	 * for best performance.
-	 */
-	RTE_ETH_FOREACH_DEV(port)
-		if (rte_eth_dev_socket_id(port) > 0 &&
-				rte_eth_dev_socket_id(port) !=
-						(int)rte_socket_id())
-			printf("WARNING, port %u is on remote NUMA node to "
-					"polling thread.\n\tPerformance will "
-					"not be optimal.\n", port);
-
-	printf("\nCore %u forwarding packets. [Ctrl+C to quit]\n",
-			rte_lcore_id());
-
-	/* Run until the application is quit or killed. */
-	for (;;) {
-		/*
-		 * Receive packets on a port and forward them on the paired
-		 * port. The mapping is 0 -> 1, 1 -> 0, 2 -> 3, 3 -> 2, etc.
-		 */
-		RTE_ETH_FOREACH_DEV(port) {
-
-			/* Get burst of RX packets, from first port of pair. */
-			struct rte_mbuf *bufs[BURST_SIZE];
-			const uint16_t nb_rx = rte_eth_rx_burst(port, 0,
-					bufs, BURST_SIZE);
-
-			if (unlikely(nb_rx == 0))
-				continue;
-
-			/* Send burst of TX packets, to second port of pair. */
-			const uint16_t nb_tx = rte_eth_tx_burst(port ^ 1, 0,
-					bufs, nb_rx);
-
-			/* Free any unsent packets. */
-			if (unlikely(nb_tx < nb_rx)) {
-				uint16_t buf;
-				for (buf = nb_tx; buf < nb_rx; buf++)
-					rte_pktmbuf_free(bufs[buf]);
-			}
-		}
-	}
-}
-
-/*
- * The main function, which does initialization and calls the per-lcore
- * functions.
- */
-int
-main(int argc, char *argv[])
-{
-	struct rte_mempool *mbuf_pool;
-	unsigned nb_ports;
-	uint16_t portid;
-
-	/* Initialize the Environment Abstraction Layer (EAL). */
-	int ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Error with EAL initialization\n");
-
-	argc -= ret;
-	argv += ret;
-
-	/* Check that there is an even number of ports to send/receive on. */
-	nb_ports = rte_eth_dev_count();
-	if (nb_ports < 2 || (nb_ports & 1))
-		rte_exit(EXIT_FAILURE, "Error: number of ports must be even\n");
-
-	/* Creates a new mempool in memory to hold the mbufs. */
-	mbuf_pool = rte_pktmbuf_pool_create("MBUF_POOL", NUM_MBUFS * nb_ports,
-		MBUF_CACHE_SIZE, 0, RTE_MBUF_DEFAULT_BUF_SIZE, rte_socket_id());
-
-	if (mbuf_pool == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot create mbuf pool\n");
-
-	/* Initialize all ports. */
-	RTE_ETH_FOREACH_DEV(portid)
-		if (port_init(portid, mbuf_pool) != 0)
-			rte_exit(EXIT_FAILURE, "Cannot init port %"PRIu16 "\n",
-					portid);
-
-	if (rte_lcore_count() > 1)
-		printf("\nWARNING: Too many lcores enabled. Only 1 used.\n");
-
-	/* Call lcore_main on the master core only. */
-	lcore_main();
-
-	return 0;
-}
diff --git a/examples/skeleton/meson.build b/examples/skeleton/meson.build
deleted file mode 100644
index ef46b18..0000000
--- a/examples/skeleton/meson.build
+++ /dev/null
@@ -1,12 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-allow_experimental_apis = true
-sources = files(
-	'basicfwd.c'
-)
diff --git a/examples/tep_termination/Makefile b/examples/tep_termination/Makefile
deleted file mode 100644
index 2b93446..0000000
--- a/examples/tep_termination/Makefile
+++ /dev/null
@@ -1,66 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2015 Intel Corporation
-
-# binary name
-APP = tep_termination
-
-# all source are stored in SRCS-y
-SRCS-y := main.c vxlan_setup.c vxlan.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-LDFLAGS += -pthread
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else # Build using legacy build system
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-ifneq ($(CONFIG_RTE_EXEC_ENV),"linuxapp")
-$(error This application can only operate in a linuxapp environment, \
-please change the definition of the RTE_TARGET environment variable)
-endif
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-CFLAGS += -D_GNU_SOURCE
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-endif
diff --git a/examples/tep_termination/main.c b/examples/tep_termination/main.c
deleted file mode 100644
index e868541..0000000
--- a/examples/tep_termination/main.c
+++ /dev/null
@@ -1,1246 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#include <arpa/inet.h>
-#include <getopt.h>
-#include <linux/if_ether.h>
-#include <linux/if_vlan.h>
-#include <linux/virtio_net.h>
-#include <linux/virtio_ring.h>
-#include <signal.h>
-#include <stdint.h>
-#include <sys/eventfd.h>
-#include <sys/param.h>
-#include <unistd.h>
-
-#include <rte_atomic.h>
-#include <rte_cycles.h>
-#include <rte_ethdev.h>
-#include <rte_log.h>
-#include <rte_string_fns.h>
-#include <rte_malloc.h>
-#include <rte_vhost.h>
-#include <rte_pause.h>
-
-#include "main.h"
-#include "vxlan.h"
-#include "vxlan_setup.h"
-
-/* the maximum number of external ports supported */
-#define MAX_SUP_PORTS 1
-
-/**
- * Calculate the number of buffers needed per port
- */
-#define NUM_MBUFS_PER_PORT ((MAX_QUEUES * RTE_TEST_RX_DESC_DEFAULT) +\
-				(nb_switching_cores * MAX_PKT_BURST) +\
-				(nb_switching_cores * \
-				RTE_TEST_TX_DESC_DEFAULT) +\
-				(nb_switching_cores * MBUF_CACHE_SIZE))
-
-#define MBUF_CACHE_SIZE 128
-#define MBUF_DATA_SIZE RTE_MBUF_DEFAULT_BUF_SIZE
-
-#define MAX_PKT_BURST 32	/* Max burst size for RX/TX */
-#define BURST_TX_DRAIN_US 100	/* TX drain every ~100us */
-
-/* Defines how long we wait between retries on RX */
-#define BURST_RX_WAIT_US 15
-
-#define BURST_RX_RETRIES 4	/* Number of retries on RX. */
-
-#define JUMBO_FRAME_MAX_SIZE    0x2600
-
-/* State of virtio device. */
-#define DEVICE_MAC_LEARNING 0
-#define DEVICE_RX	    1
-#define DEVICE_SAFE_REMOVE  2
-
-/* Config_core_flag status definitions. */
-#define REQUEST_DEV_REMOVAL 1
-#define ACK_DEV_REMOVAL     0
-
-/* Configurable number of RX/TX ring descriptors */
-#define RTE_TEST_RX_DESC_DEFAULT 1024
-#define RTE_TEST_TX_DESC_DEFAULT 512
-
-/* Get first 4 bytes in mbuf headroom. */
-#define MBUF_HEADROOM_UINT32(mbuf) (*(uint32_t *)((uint8_t *)(mbuf) \
-		+ sizeof(struct rte_mbuf)))
-
-#define INVALID_PORT_ID 0xFFFF
-
-/* Size of buffers used for snprintfs. */
-#define MAX_PRINT_BUFF 6072
-
-/* Maximum character device basename size. */
-#define MAX_BASENAME_SZ 20
-
-/* Maximum long option length for option parsing. */
-#define MAX_LONG_OPT_SZ 64
-
-/* Used to compare MAC addresses. */
-#define MAC_ADDR_CMP 0xFFFFFFFFFFFFULL
-
-#define CMD_LINE_OPT_NB_DEVICES "nb-devices"
-#define CMD_LINE_OPT_UDP_PORT "udp-port"
-#define CMD_LINE_OPT_TX_CHECKSUM "tx-checksum"
-#define CMD_LINE_OPT_TSO_SEGSZ "tso-segsz"
-#define CMD_LINE_OPT_FILTER_TYPE "filter-type"
-#define CMD_LINE_OPT_ENCAP "encap"
-#define CMD_LINE_OPT_DECAP "decap"
-#define CMD_LINE_OPT_RX_RETRY "rx-retry"
-#define CMD_LINE_OPT_RX_RETRY_DELAY "rx-retry-delay"
-#define CMD_LINE_OPT_RX_RETRY_NUM "rx-retry-num"
-#define CMD_LINE_OPT_STATS "stats"
-#define CMD_LINE_OPT_DEV_BASENAME "dev-basename"
-
-/* mask of enabled ports */
-static uint32_t enabled_port_mask;
-
-/*Number of switching cores enabled*/
-static uint32_t nb_switching_cores;
-
-/* number of devices/queues to support*/
-uint16_t nb_devices = 2;
-
-/* max ring descriptor, ixgbe, i40e, e1000 all are 4096. */
-#define MAX_RING_DESC 4096
-
-struct vpool {
-	struct rte_mempool *pool;
-	struct rte_ring *ring;
-	uint32_t buf_size;
-} vpool_array[MAX_QUEUES+MAX_QUEUES];
-
-/* UDP tunneling port */
-uint16_t udp_port = 4789;
-
-/* enable/disable inner TX checksum */
-uint8_t tx_checksum = 0;
-
-/* TCP segment size */
-uint16_t tso_segsz = 0;
-
-/* enable/disable decapsulation */
-uint8_t rx_decap = 1;
-
-/* enable/disable encapsulation */
-uint8_t tx_encap = 1;
-
-/* RX filter type for tunneling packet */
-uint8_t filter_idx = 1;
-
-/* overlay packet operation */
-struct ol_switch_ops overlay_options = {
-	.port_configure = vxlan_port_init,
-	.tunnel_setup = vxlan_link,
-	.tunnel_destroy = vxlan_unlink,
-	.tx_handle = vxlan_tx_pkts,
-	.rx_handle = vxlan_rx_pkts,
-	.param_handle = NULL,
-};
-
-/* Enable stats. */
-uint32_t enable_stats = 0;
-/* Enable retries on RX. */
-static uint32_t enable_retry = 1;
-/* Specify timeout (in useconds) between retries on RX. */
-static uint32_t burst_rx_delay_time = BURST_RX_WAIT_US;
-/* Specify the number of retries on RX. */
-static uint32_t burst_rx_retry_num = BURST_RX_RETRIES;
-
-/* Character device basename. Can be set by user. */
-static char dev_basename[MAX_BASENAME_SZ] = "vhost-net";
-
-static unsigned lcore_ids[RTE_MAX_LCORE];
-uint16_t ports[RTE_MAX_ETHPORTS];
-
-static unsigned nb_ports; /**< The number of ports specified in command line */
-
-/* ethernet addresses of ports */
-struct ether_addr ports_eth_addr[RTE_MAX_ETHPORTS];
-
-/* heads for the main used and free linked lists for the data path. */
-static struct virtio_net_data_ll *ll_root_used;
-static struct virtio_net_data_ll *ll_root_free;
-
-/**
- * Array of data core structures containing information on
- * individual core linked lists.
- */
-static struct lcore_info lcore_info[RTE_MAX_LCORE];
-
-/* Used for queueing bursts of TX packets. */
-struct mbuf_table {
-	unsigned len;
-	unsigned txq_id;
-	struct rte_mbuf *m_table[MAX_PKT_BURST];
-};
-
-/* TX queue for each data core. */
-struct mbuf_table lcore_tx_queue[RTE_MAX_LCORE];
-
-struct device_statistics dev_statistics[MAX_DEVICES];
-
-/**
- * Set character device basename.
- */
-static int
-us_vhost_parse_basename(const char *q_arg)
-{
-	/* parse number string */
-	if (strlen(q_arg) >= MAX_BASENAME_SZ)
-		return -1;
-	else
-		snprintf((char *)&dev_basename, MAX_BASENAME_SZ, "%s", q_arg);
-
-	return 0;
-}
-
-/**
- * Parse the portmask provided at run time.
- */
-static int
-parse_portmask(const char *portmask)
-{
-	char *end = NULL;
-	unsigned long pm;
-
-	/* parse hexadecimal string */
-	pm = strtoul(portmask, &end, 16);
-	if ((portmask[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (pm == 0)
-		return -1;
-
-	return pm;
-}
-
-/**
- * Parse num options at run time.
- */
-static int
-parse_num_opt(const char *q_arg, uint32_t max_valid_value)
-{
-	char *end = NULL;
-	unsigned long num;
-
-	/* parse unsigned int string */
-	num = strtoul(q_arg, &end, 10);
-	if ((q_arg[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (num > max_valid_value)
-		return -1;
-
-	return num;
-}
-
-/**
- * Display usage
- */
-static void
-tep_termination_usage(const char *prgname)
-{
-	RTE_LOG(INFO, VHOST_CONFIG, "%s [EAL options] -- -p PORTMASK\n"
-	"               --udp-port: UDP destination port for VXLAN packet\n"
-	"		--nb-devices[1-64]: The number of virtIO device\n"
-	"               --tx-checksum [0|1]: inner Tx checksum offload\n"
-	"               --tso-segsz [0-N]: TCP segment size\n"
-	"               --decap [0|1]: tunneling packet decapsulation\n"
-	"               --encap [0|1]: tunneling packet encapsulation\n"
-	"               --filter-type[1-3]: filter type for tunneling packet\n"
-	"                   1: Inner MAC and tenent ID\n"
-	"                   2: Inner MAC and VLAN, and tenent ID\n"
-	"                   3: Outer MAC, Inner MAC and tenent ID\n"
-	"		-p PORTMASK: Set mask for ports to be used by application\n"
-	"		--rx-retry [0|1]: disable/enable(default) retries on rx."
-	"		 Enable retry if destintation queue is full\n"
-	"		--rx-retry-delay [0-N]: timeout(in usecond) between retries on RX."
-	"		 This makes effect only if retries on rx enabled\n"
-	"		--rx-retry-num [0-N]: the number of retries on rx."
-	"		 This makes effect only if retries on rx enabled\n"
-	"		--stats [0-N]: 0: Disable stats, N: Time in seconds to print stats\n"
-	"		--dev-basename: The basename to be used for the character device.\n",
-	       prgname);
-}
-
-/**
- * Parse the arguments given in the command line of the application.
- */
-static int
-tep_termination_parse_args(int argc, char **argv)
-{
-	int opt, ret;
-	int option_index;
-	unsigned i;
-	const char *prgname = argv[0];
-	static struct option long_option[] = {
-		{CMD_LINE_OPT_NB_DEVICES, required_argument, NULL, 0},
-		{CMD_LINE_OPT_UDP_PORT, required_argument, NULL, 0},
-		{CMD_LINE_OPT_TX_CHECKSUM, required_argument, NULL, 0},
-		{CMD_LINE_OPT_TSO_SEGSZ, required_argument, NULL, 0},
-		{CMD_LINE_OPT_DECAP, required_argument, NULL, 0},
-		{CMD_LINE_OPT_ENCAP, required_argument, NULL, 0},
-		{CMD_LINE_OPT_FILTER_TYPE, required_argument, NULL, 0},
-		{CMD_LINE_OPT_RX_RETRY, required_argument, NULL, 0},
-		{CMD_LINE_OPT_RX_RETRY_DELAY, required_argument, NULL, 0},
-		{CMD_LINE_OPT_RX_RETRY_NUM, required_argument, NULL, 0},
-		{CMD_LINE_OPT_STATS, required_argument, NULL, 0},
-		{CMD_LINE_OPT_DEV_BASENAME, required_argument, NULL, 0},
-		{NULL, 0, 0, 0},
-	};
-
-	/* Parse command line */
-	while ((opt = getopt_long(argc, argv, "p:",
-			long_option, &option_index)) != EOF) {
-		switch (opt) {
-		/* Portmask */
-		case 'p':
-			enabled_port_mask = parse_portmask(optarg);
-			if (enabled_port_mask == 0) {
-				RTE_LOG(INFO, VHOST_CONFIG,
-					"Invalid portmask\n");
-				tep_termination_usage(prgname);
-				return -1;
-			}
-			break;
-		case 0:
-			if (!strncmp(long_option[option_index].name,
-				CMD_LINE_OPT_NB_DEVICES,
-				sizeof(CMD_LINE_OPT_NB_DEVICES))) {
-				ret = parse_num_opt(optarg, MAX_DEVICES);
-				if (ret == -1) {
-					RTE_LOG(INFO, VHOST_CONFIG,
-					"Invalid argument for nb-devices [0-%d]\n",
-					MAX_DEVICES);
-					tep_termination_usage(prgname);
-					return -1;
-				} else
-					nb_devices = ret;
-			}
-
-			/* Enable/disable retries on RX. */
-			if (!strncmp(long_option[option_index].name,
-				CMD_LINE_OPT_RX_RETRY,
-				sizeof(CMD_LINE_OPT_RX_RETRY))) {
-				ret = parse_num_opt(optarg, 1);
-				if (ret == -1) {
-					RTE_LOG(INFO, VHOST_CONFIG,
-						"Invalid argument for rx-retry [0|1]\n");
-					tep_termination_usage(prgname);
-					return -1;
-				} else
-					enable_retry = ret;
-			}
-
-			if (!strncmp(long_option[option_index].name,
-				CMD_LINE_OPT_TSO_SEGSZ,
-				sizeof(CMD_LINE_OPT_TSO_SEGSZ))) {
-				ret = parse_num_opt(optarg, INT16_MAX);
-				if (ret == -1) {
-					RTE_LOG(INFO, VHOST_CONFIG,
-						"Invalid argument for TCP segment size [0-N]\n");
-					tep_termination_usage(prgname);
-					return -1;
-				} else
-					tso_segsz = ret;
-			}
-
-			if (!strncmp(long_option[option_index].name,
-					CMD_LINE_OPT_UDP_PORT,
-					sizeof(CMD_LINE_OPT_UDP_PORT))) {
-				ret = parse_num_opt(optarg, INT16_MAX);
-				if (ret == -1) {
-					RTE_LOG(INFO, VHOST_CONFIG,
-						"Invalid argument for UDP port [0-N]\n");
-					tep_termination_usage(prgname);
-					return -1;
-				} else
-					udp_port = ret;
-			}
-
-			/* Specify the retries delay time (in useconds) on RX.*/
-			if (!strncmp(long_option[option_index].name,
-				CMD_LINE_OPT_RX_RETRY_DELAY,
-				sizeof(CMD_LINE_OPT_RX_RETRY_DELAY))) {
-				ret = parse_num_opt(optarg, INT32_MAX);
-				if (ret == -1) {
-					RTE_LOG(INFO, VHOST_CONFIG,
-						"Invalid argument for rx-retry-delay [0-N]\n");
-					tep_termination_usage(prgname);
-					return -1;
-				} else
-					burst_rx_delay_time = ret;
-			}
-
-			/* Specify the retries number on RX. */
-			if (!strncmp(long_option[option_index].name,
-				CMD_LINE_OPT_RX_RETRY_NUM,
-				sizeof(CMD_LINE_OPT_RX_RETRY_NUM))) {
-				ret = parse_num_opt(optarg, INT32_MAX);
-				if (ret == -1) {
-					RTE_LOG(INFO, VHOST_CONFIG,
-						"Invalid argument for rx-retry-num [0-N]\n");
-					tep_termination_usage(prgname);
-					return -1;
-				} else
-					burst_rx_retry_num = ret;
-			}
-
-			if (!strncmp(long_option[option_index].name,
-				CMD_LINE_OPT_TX_CHECKSUM,
-				sizeof(CMD_LINE_OPT_TX_CHECKSUM))) {
-				ret = parse_num_opt(optarg, 1);
-				if (ret == -1) {
-					RTE_LOG(INFO, VHOST_CONFIG,
-						"Invalid argument for tx-checksum [0|1]\n");
-					tep_termination_usage(prgname);
-					return -1;
-				} else
-					tx_checksum = ret;
-			}
-
-			if (!strncmp(long_option[option_index].name,
-					CMD_LINE_OPT_FILTER_TYPE,
-					sizeof(CMD_LINE_OPT_FILTER_TYPE))) {
-				ret = parse_num_opt(optarg, 3);
-				if ((ret == -1) || (ret == 0)) {
-					RTE_LOG(INFO, VHOST_CONFIG,
-						"Invalid argument for filter type [1-3]\n");
-					tep_termination_usage(prgname);
-					return -1;
-				} else
-					filter_idx = ret - 1;
-			}
-
-			/* Enable/disable encapsulation on RX. */
-			if (!strncmp(long_option[option_index].name,
-				CMD_LINE_OPT_DECAP,
-				sizeof(CMD_LINE_OPT_DECAP))) {
-				ret = parse_num_opt(optarg, 1);
-				if (ret == -1) {
-					RTE_LOG(INFO, VHOST_CONFIG,
-						"Invalid argument for decap [0|1]\n");
-					tep_termination_usage(prgname);
-					return -1;
-				} else
-					rx_decap = ret;
-			}
-
-			/* Enable/disable encapsulation on TX. */
-			if (!strncmp(long_option[option_index].name,
-				CMD_LINE_OPT_ENCAP,
-				sizeof(CMD_LINE_OPT_ENCAP))) {
-				ret = parse_num_opt(optarg, 1);
-				if (ret == -1) {
-					RTE_LOG(INFO, VHOST_CONFIG,
-						"Invalid argument for encap [0|1]\n");
-					tep_termination_usage(prgname);
-					return -1;
-				} else
-					tx_encap = ret;
-			}
-
-			/* Enable/disable stats. */
-			if (!strncmp(long_option[option_index].name,
-				CMD_LINE_OPT_STATS,
-				sizeof(CMD_LINE_OPT_STATS))) {
-				ret = parse_num_opt(optarg, INT32_MAX);
-				if (ret == -1) {
-					RTE_LOG(INFO, VHOST_CONFIG,
-							"Invalid argument for stats [0..N]\n");
-					tep_termination_usage(prgname);
-					return -1;
-				} else
-					enable_stats = ret;
-			}
-
-			/* Set character device basename. */
-			if (!strncmp(long_option[option_index].name,
-				CMD_LINE_OPT_DEV_BASENAME,
-				sizeof(CMD_LINE_OPT_DEV_BASENAME))) {
-				if (us_vhost_parse_basename(optarg) == -1) {
-					RTE_LOG(INFO, VHOST_CONFIG,
-						"Invalid argument for character "
-						"device basename (Max %d characters)\n",
-						MAX_BASENAME_SZ);
-					tep_termination_usage(prgname);
-					return -1;
-				}
-			}
-
-			break;
-
-			/* Invalid option - print options. */
-		default:
-			tep_termination_usage(prgname);
-			return -1;
-		}
-	}
-
-	for (i = 0; i < RTE_MAX_ETHPORTS; i++) {
-		if (enabled_port_mask & (1 << i))
-			ports[nb_ports++] = (uint8_t)i;
-	}
-
-	if ((nb_ports ==  0) || (nb_ports > MAX_SUP_PORTS)) {
-		RTE_LOG(INFO, VHOST_PORT, "Current enabled port number is %u,"
-			"but only %u port can be enabled\n", nb_ports,
-			MAX_SUP_PORTS);
-		return -1;
-	}
-
-	return 0;
-}
-
-/**
- * Update the global var NB_PORTS and array PORTS
- * according to system ports number and return valid ports number
- */
-static unsigned
-check_ports_num(unsigned max_nb_ports)
-{
-	unsigned valid_nb_ports = nb_ports;
-	unsigned portid;
-
-	if (nb_ports > max_nb_ports) {
-		RTE_LOG(INFO, VHOST_PORT, "\nSpecified port number(%u) "
-			" exceeds total system port number(%u)\n",
-			nb_ports, max_nb_ports);
-		nb_ports = max_nb_ports;
-	}
-
-	for (portid = 0; portid < nb_ports; portid++) {
-		if (!rte_eth_dev_is_valid_port(ports[portid])) {
-			RTE_LOG(INFO, VHOST_PORT,
-				"\nSpecified port ID(%u) is not valid\n",
-				ports[portid]);
-			ports[portid] = INVALID_PORT_ID;
-			valid_nb_ports--;
-		}
-	}
-	return valid_nb_ports;
-}
-
-/**
- * This function routes the TX packet to the correct interface. This may be a local device
- * or the physical port.
- */
-static __rte_always_inline void
-virtio_tx_route(struct vhost_dev *vdev, struct rte_mbuf *m)
-{
-	struct mbuf_table *tx_q;
-	struct rte_mbuf **m_table;
-	unsigned len, ret = 0;
-	const uint16_t lcore_id = rte_lcore_id();
-
-	RTE_LOG_DP(DEBUG, VHOST_DATA, "(%d) TX: MAC address is external\n",
-		vdev->vid);
-
-	/* Add packet to the port tx queue */
-	tx_q = &lcore_tx_queue[lcore_id];
-	len = tx_q->len;
-
-	tx_q->m_table[len] = m;
-	len++;
-	if (enable_stats) {
-		dev_statistics[vdev->vid].tx_total++;
-		dev_statistics[vdev->vid].tx++;
-	}
-
-	if (unlikely(len == MAX_PKT_BURST)) {
-		m_table = (struct rte_mbuf **)tx_q->m_table;
-		ret = overlay_options.tx_handle(ports[0],
-			(uint16_t)tx_q->txq_id, m_table,
-			(uint16_t)tx_q->len);
-
-		/* Free any buffers not handled by TX and update
-		 * the port stats.
-		 */
-		if (unlikely(ret < len)) {
-			do {
-				rte_pktmbuf_free(m_table[ret]);
-			} while (++ret < len);
-		}
-
-		len = 0;
-	}
-
-	tx_q->len = len;
-	return;
-}
-
-/**
- * This function is called by each data core. It handles all
- * RX/TX registered with the core. For TX the specific lcore
- * linked list is used. For RX, MAC addresses are compared
- * with all devices in the main linked list.
- */
-static int
-switch_worker(__rte_unused void *arg)
-{
-	struct rte_mempool *mbuf_pool = arg;
-	struct vhost_dev *vdev = NULL;
-	struct rte_mbuf *pkts_burst[MAX_PKT_BURST];
-	struct virtio_net_data_ll *dev_ll;
-	struct mbuf_table *tx_q;
-	volatile struct lcore_ll_info *lcore_ll;
-	const uint64_t drain_tsc = (rte_get_tsc_hz() + US_PER_S - 1)
-					/ US_PER_S * BURST_TX_DRAIN_US;
-	uint64_t prev_tsc, diff_tsc, cur_tsc, ret_count = 0;
-	unsigned i, ret = 0;
-	const uint16_t lcore_id = rte_lcore_id();
-	const uint16_t num_cores = (uint16_t)rte_lcore_count();
-	uint16_t rx_count = 0;
-	uint16_t tx_count;
-	uint32_t retry = 0;
-
-	RTE_LOG(INFO, VHOST_DATA, "Procesing on Core %u started\n", lcore_id);
-	lcore_ll = lcore_info[lcore_id].lcore_ll;
-	prev_tsc = 0;
-
-	tx_q = &lcore_tx_queue[lcore_id];
-	for (i = 0; i < num_cores; i++) {
-		if (lcore_ids[i] == lcore_id) {
-			tx_q->txq_id = i;
-			break;
-		}
-	}
-
-	while (1) {
-		cur_tsc = rte_rdtsc();
-		/*
-		 * TX burst queue drain
-		 */
-		diff_tsc = cur_tsc - prev_tsc;
-		if (unlikely(diff_tsc > drain_tsc)) {
-
-			if (tx_q->len) {
-				RTE_LOG_DP(DEBUG, VHOST_DATA, "TX queue drained after "
-					"timeout with burst size %u\n",
-					tx_q->len);
-				ret = overlay_options.tx_handle(ports[0],
-					(uint16_t)tx_q->txq_id,
-					(struct rte_mbuf **)tx_q->m_table,
-					(uint16_t)tx_q->len);
-				if (unlikely(ret < tx_q->len)) {
-					do {
-						rte_pktmbuf_free(tx_q->m_table[ret]);
-					} while (++ret < tx_q->len);
-				}
-
-				tx_q->len = 0;
-			}
-
-			prev_tsc = cur_tsc;
-
-		}
-
-		rte_prefetch0(lcore_ll->ll_root_used);
-
-		/**
-		 * Inform the configuration core that we have exited
-		 * the linked list and that no devices are
-		 * in use if requested.
-		 */
-		if (lcore_ll->dev_removal_flag == REQUEST_DEV_REMOVAL)
-			lcore_ll->dev_removal_flag = ACK_DEV_REMOVAL;
-
-		/*
-		 * Process devices
-		 */
-		dev_ll = lcore_ll->ll_root_used;
-
-		while (dev_ll != NULL) {
-			vdev = dev_ll->vdev;
-
-			if (unlikely(vdev->remove)) {
-				dev_ll = dev_ll->next;
-				overlay_options.tunnel_destroy(vdev);
-				vdev->ready = DEVICE_SAFE_REMOVE;
-				continue;
-			}
-			if (likely(vdev->ready == DEVICE_RX)) {
-				/* Handle guest RX */
-				rx_count = rte_eth_rx_burst(ports[0],
-					vdev->rx_q, pkts_burst, MAX_PKT_BURST);
-
-				if (rx_count) {
-					/*
-					* Retry is enabled and the queue is
-					* full then we wait and retry to
-					* avoid packet loss. Here MAX_PKT_BURST
-					* must be less than virtio queue size
-					*/
-					if (enable_retry && unlikely(rx_count >
-						rte_vhost_avail_entries(vdev->vid, VIRTIO_RXQ))) {
-						for (retry = 0; retry < burst_rx_retry_num;
-							retry++) {
-							rte_delay_us(burst_rx_delay_time);
-							if (rx_count <= rte_vhost_avail_entries(vdev->vid, VIRTIO_RXQ))
-								break;
-						}
-					}
-
-					ret_count = overlay_options.rx_handle(vdev->vid, pkts_burst, rx_count);
-					if (enable_stats) {
-						rte_atomic64_add(
-						&dev_statistics[vdev->vid].rx_total_atomic,
-						rx_count);
-						rte_atomic64_add(
-						&dev_statistics[vdev->vid].rx_atomic, ret_count);
-					}
-					while (likely(rx_count)) {
-						rx_count--;
-						rte_pktmbuf_free(pkts_burst[rx_count]);
-					}
-
-				}
-			}
-
-			if (likely(!vdev->remove)) {
-				/* Handle guest TX*/
-				tx_count = rte_vhost_dequeue_burst(vdev->vid,
-						VIRTIO_TXQ, mbuf_pool,
-						pkts_burst, MAX_PKT_BURST);
-				/* If this is the first received packet we need to learn the MAC */
-				if (unlikely(vdev->ready == DEVICE_MAC_LEARNING) && tx_count) {
-					if (vdev->remove ||
-						(overlay_options.tunnel_setup(vdev, pkts_burst[0]) == -1)) {
-						while (tx_count)
-							rte_pktmbuf_free(pkts_burst[--tx_count]);
-					}
-				}
-				while (tx_count)
-					virtio_tx_route(vdev, pkts_burst[--tx_count]);
-			}
-
-			/* move to the next device in the list */
-			dev_ll = dev_ll->next;
-		}
-	}
-
-	return 0;
-}
-
-/**
- * Add an entry to a used linked list. A free entry must first be found
- * in the free linked list using get_data_ll_free_entry();
- */
-static void
-add_data_ll_entry(struct virtio_net_data_ll **ll_root_addr,
-	struct virtio_net_data_ll *ll_dev)
-{
-	struct virtio_net_data_ll *ll = *ll_root_addr;
-
-	/* Set next as NULL and use a compiler barrier to avoid reordering. */
-	ll_dev->next = NULL;
-	rte_compiler_barrier();
-
-	/* If ll == NULL then this is the first device. */
-	if (ll) {
-		/* Increment to the tail of the linked list. */
-		while (ll->next != NULL)
-			ll = ll->next;
-
-		ll->next = ll_dev;
-	} else {
-		*ll_root_addr = ll_dev;
-	}
-}
-
-/**
- * Remove an entry from a used linked list. The entry must then be added to
- * the free linked list using put_data_ll_free_entry().
- */
-static void
-rm_data_ll_entry(struct virtio_net_data_ll **ll_root_addr,
-	struct virtio_net_data_ll *ll_dev,
-	struct virtio_net_data_ll *ll_dev_last)
-{
-	struct virtio_net_data_ll *ll = *ll_root_addr;
-
-	if (unlikely((ll == NULL) || (ll_dev == NULL)))
-		return;
-
-	if (ll_dev == ll)
-		*ll_root_addr = ll_dev->next;
-	else
-		if (likely(ll_dev_last != NULL))
-			ll_dev_last->next = ll_dev->next;
-		else
-			RTE_LOG(ERR, VHOST_CONFIG,
-				"Remove entry form ll failed.\n");
-}
-
-/**
- * Find and return an entry from the free linked list.
- */
-static struct virtio_net_data_ll *
-get_data_ll_free_entry(struct virtio_net_data_ll **ll_root_addr)
-{
-	struct virtio_net_data_ll *ll_free = *ll_root_addr;
-	struct virtio_net_data_ll *ll_dev;
-
-	if (ll_free == NULL)
-		return NULL;
-
-	ll_dev = ll_free;
-	*ll_root_addr = ll_free->next;
-
-	return ll_dev;
-}
-
-/**
- * Place an entry back on to the free linked list.
- */
-static void
-put_data_ll_free_entry(struct virtio_net_data_ll **ll_root_addr,
-	struct virtio_net_data_ll *ll_dev)
-{
-	struct virtio_net_data_ll *ll_free = *ll_root_addr;
-
-	if (ll_dev == NULL)
-		return;
-
-	ll_dev->next = ll_free;
-	*ll_root_addr = ll_dev;
-}
-
-/**
- * Creates a linked list of a given size.
- */
-static struct virtio_net_data_ll *
-alloc_data_ll(uint32_t size)
-{
-	struct virtio_net_data_ll *ll_new;
-	uint32_t i;
-
-	/* Malloc and then chain the linked list. */
-	ll_new = malloc(size * sizeof(struct virtio_net_data_ll));
-	if (ll_new == NULL) {
-		RTE_LOG(ERR, VHOST_CONFIG,
-			"Failed to allocate memory for ll_new.\n");
-		return NULL;
-	}
-
-	for (i = 0; i < size - 1; i++) {
-		ll_new[i].vdev = NULL;
-		ll_new[i].next = &ll_new[i+1];
-	}
-	ll_new[i].next = NULL;
-
-	return ll_new;
-}
-
-/**
- * Create the main linked list along with each individual cores
- * linked list. A used and a free list are created to manage entries.
- */
-static int
-init_data_ll(void)
-{
-	int lcore;
-
-	RTE_LCORE_FOREACH_SLAVE(lcore) {
-		lcore_info[lcore].lcore_ll =
-			malloc(sizeof(struct lcore_ll_info));
-		if (lcore_info[lcore].lcore_ll == NULL) {
-			RTE_LOG(ERR, VHOST_CONFIG,
-				"Failed to allocate memory for lcore_ll.\n");
-			return -1;
-		}
-
-		lcore_info[lcore].lcore_ll->device_num = 0;
-		lcore_info[lcore].lcore_ll->dev_removal_flag = ACK_DEV_REMOVAL;
-		lcore_info[lcore].lcore_ll->ll_root_used = NULL;
-		if (nb_devices % nb_switching_cores)
-			lcore_info[lcore].lcore_ll->ll_root_free =
-				alloc_data_ll((nb_devices / nb_switching_cores)
-						+ 1);
-		else
-			lcore_info[lcore].lcore_ll->ll_root_free =
-				alloc_data_ll(nb_devices / nb_switching_cores);
-	}
-
-	/* Allocate devices up to a maximum of MAX_DEVICES. */
-	ll_root_free = alloc_data_ll(MIN((nb_devices), MAX_DEVICES));
-
-	return 0;
-}
-
-/**
- * Remove a device from the specific data core linked list and
- * from the main linked list. Synchonization occurs through the use
- * of the lcore dev_removal_flag.
- */
-static void
-destroy_device(int vid)
-{
-	struct virtio_net_data_ll *ll_lcore_dev_cur;
-	struct virtio_net_data_ll *ll_main_dev_cur;
-	struct virtio_net_data_ll *ll_lcore_dev_last = NULL;
-	struct virtio_net_data_ll *ll_main_dev_last = NULL;
-	struct vhost_dev *vdev = NULL;
-	int lcore;
-
-	ll_main_dev_cur = ll_root_used;
-	while (ll_main_dev_cur != NULL) {
-		if (ll_main_dev_cur->vdev->vid == vid) {
-			vdev = ll_main_dev_cur->vdev;
-			break;
-		}
-	}
-	if (!vdev)
-		return;
-
-	/* set the remove flag. */
-	vdev->remove = 1;
-	while (vdev->ready != DEVICE_SAFE_REMOVE)
-		rte_pause();
-
-	/* Search for entry to be removed from lcore ll */
-	ll_lcore_dev_cur = lcore_info[vdev->coreid].lcore_ll->ll_root_used;
-	while (ll_lcore_dev_cur != NULL) {
-		if (ll_lcore_dev_cur->vdev == vdev) {
-			break;
-		} else {
-			ll_lcore_dev_last = ll_lcore_dev_cur;
-			ll_lcore_dev_cur = ll_lcore_dev_cur->next;
-		}
-	}
-
-	if (ll_lcore_dev_cur == NULL) {
-		RTE_LOG(ERR, VHOST_CONFIG,
-			"(%d) Failed to find the dev to be destroy.\n", vid);
-		return;
-	}
-
-	/* Search for entry to be removed from main ll */
-	ll_main_dev_cur = ll_root_used;
-	ll_main_dev_last = NULL;
-	while (ll_main_dev_cur != NULL) {
-		if (ll_main_dev_cur->vdev == vdev) {
-			break;
-		} else {
-			ll_main_dev_last = ll_main_dev_cur;
-			ll_main_dev_cur = ll_main_dev_cur->next;
-		}
-	}
-
-	/* Remove entries from the lcore and main ll. */
-	rm_data_ll_entry(&lcore_info[vdev->coreid].lcore_ll->ll_root_used,
-			ll_lcore_dev_cur, ll_lcore_dev_last);
-	rm_data_ll_entry(&ll_root_used, ll_main_dev_cur, ll_main_dev_last);
-
-	/* Set the dev_removal_flag on each lcore. */
-	RTE_LCORE_FOREACH_SLAVE(lcore) {
-		lcore_info[lcore].lcore_ll->dev_removal_flag =
-			REQUEST_DEV_REMOVAL;
-	}
-
-	/*
-	 * Once each core has set the dev_removal_flag to
-	 * ACK_DEV_REMOVAL we can be sure that they can no longer access
-	 * the device removed from the linked lists and that the devices
-	 * are no longer in use.
-	 */
-	RTE_LCORE_FOREACH_SLAVE(lcore) {
-		while (lcore_info[lcore].lcore_ll->dev_removal_flag
-			!= ACK_DEV_REMOVAL)
-			rte_pause();
-	}
-
-	/* Add the entries back to the lcore and main free ll.*/
-	put_data_ll_free_entry(&lcore_info[vdev->coreid].lcore_ll->ll_root_free,
-				ll_lcore_dev_cur);
-	put_data_ll_free_entry(&ll_root_free, ll_main_dev_cur);
-
-	/* Decrement number of device on the lcore. */
-	lcore_info[vdev->coreid].lcore_ll->device_num--;
-
-	RTE_LOG(INFO, VHOST_DATA, "(%d) Device has been removed "
-		"from data core\n", vid);
-
-	rte_free(vdev);
-
-}
-
-/**
- * A new device is added to a data core. First the device is added
- * to the main linked list and the allocated to a specific data core.
- */
-static int
-new_device(int vid)
-{
-	struct virtio_net_data_ll *ll_dev;
-	int lcore, core_add = 0;
-	uint32_t device_num_min = nb_devices;
-	struct vhost_dev *vdev;
-
-	vdev = rte_zmalloc("vhost device", sizeof(*vdev), RTE_CACHE_LINE_SIZE);
-	if (vdev == NULL) {
-		RTE_LOG(INFO, VHOST_DATA,
-			"(%d) Couldn't allocate memory for vhost dev\n", vid);
-		return -1;
-	}
-	vdev->vid = vid;
-	/* Add device to main ll */
-	ll_dev = get_data_ll_free_entry(&ll_root_free);
-	if (ll_dev == NULL) {
-		RTE_LOG(INFO, VHOST_DATA, "(%d) No free entry found in"
-			" linked list Device limit of %d devices per core"
-			" has been reached\n", vid, nb_devices);
-		if (vdev->regions_hpa)
-			rte_free(vdev->regions_hpa);
-		rte_free(vdev);
-		return -1;
-	}
-	ll_dev->vdev = vdev;
-	add_data_ll_entry(&ll_root_used, ll_dev);
-	vdev->rx_q = vid;
-
-	/* reset ready flag */
-	vdev->ready = DEVICE_MAC_LEARNING;
-	vdev->remove = 0;
-
-	/* Find a suitable lcore to add the device. */
-	RTE_LCORE_FOREACH_SLAVE(lcore) {
-		if (lcore_info[lcore].lcore_ll->device_num < device_num_min) {
-			device_num_min = lcore_info[lcore].lcore_ll->device_num;
-			core_add = lcore;
-		}
-	}
-	/* Add device to lcore ll */
-	ll_dev = get_data_ll_free_entry(&lcore_info[core_add].lcore_ll->ll_root_free);
-	if (ll_dev == NULL) {
-		RTE_LOG(INFO, VHOST_DATA,
-			"(%d) Failed to add device to data core\n",
-			vid);
-		vdev->ready = DEVICE_SAFE_REMOVE;
-		destroy_device(vid);
-		rte_free(vdev->regions_hpa);
-		rte_free(vdev);
-		return -1;
-	}
-	ll_dev->vdev = vdev;
-	vdev->coreid = core_add;
-
-	add_data_ll_entry(&lcore_info[vdev->coreid].lcore_ll->ll_root_used,
-			ll_dev);
-
-	/* Initialize device stats */
-	memset(&dev_statistics[vid], 0,
-		sizeof(struct device_statistics));
-
-	/* Disable notifications. */
-	rte_vhost_enable_guest_notification(vid, VIRTIO_RXQ, 0);
-	rte_vhost_enable_guest_notification(vid, VIRTIO_TXQ, 0);
-	lcore_info[vdev->coreid].lcore_ll->device_num++;
-
-	RTE_LOG(INFO, VHOST_DATA, "(%d) Device has been added to data core %d\n",
-		vid, vdev->coreid);
-
-	return 0;
-}
-
-/**
- * These callback allow devices to be added to the data core when configuration
- * has been fully complete.
- */
-static const struct vhost_device_ops virtio_net_device_ops = {
-	.new_device =  new_device,
-	.destroy_device = destroy_device,
-};
-
-/**
- * This is a thread will wake up after a period to print stats if the user has
- * enabled them.
- */
-static void
-print_stats(void)
-{
-	struct virtio_net_data_ll *dev_ll;
-	uint64_t tx_dropped, rx_dropped;
-	uint64_t tx, tx_total, rx, rx_total, rx_ip_csum, rx_l4_csum;
-	int vid;
-	const char clr[] = { 27, '[', '2', 'J', '\0' };
-	const char top_left[] = { 27, '[', '1', ';', '1', 'H', '\0' };
-
-	while (1) {
-		sleep(enable_stats);
-
-		/* Clear screen and move to top left */
-		printf("%s%s", clr, top_left);
-
-		printf("\nDevice statistics ================================");
-
-		dev_ll = ll_root_used;
-		while (dev_ll != NULL) {
-			vid = dev_ll->vdev->vid;
-			tx_total = dev_statistics[vid].tx_total;
-			tx = dev_statistics[vid].tx;
-			tx_dropped = tx_total - tx;
-
-			rx_total = rte_atomic64_read(
-				&dev_statistics[vid].rx_total_atomic);
-			rx = rte_atomic64_read(
-				&dev_statistics[vid].rx_atomic);
-			rx_dropped = rx_total - rx;
-			rx_ip_csum = rte_atomic64_read(
-				&dev_statistics[vid].rx_bad_ip_csum);
-			rx_l4_csum = rte_atomic64_read(
-				&dev_statistics[vid].rx_bad_l4_csum);
-
-			printf("\nStatistics for device %d ----------"
-					"\nTX total:		%"PRIu64""
-					"\nTX dropped:		%"PRIu64""
-					"\nTX successful:		%"PRIu64""
-					"\nRX total:		%"PRIu64""
-					"\nRX bad IP csum:      %"PRIu64""
-					"\nRX bad L4 csum:      %"PRIu64""
-					"\nRX dropped:		%"PRIu64""
-					"\nRX successful:		%"PRIu64"",
-					vid,
-					tx_total,
-					tx_dropped,
-					tx,
-					rx_total,
-					rx_ip_csum,
-					rx_l4_csum,
-					rx_dropped,
-					rx);
-
-			dev_ll = dev_ll->next;
-		}
-		printf("\n================================================\n");
-	}
-}
-
-/**
- * Main function, does initialisation and calls the per-lcore functions.
- */
-int
-main(int argc, char *argv[])
-{
-	struct rte_mempool *mbuf_pool = NULL;
-	unsigned lcore_id, core_id = 0;
-	unsigned nb_ports, valid_nb_ports;
-	int ret;
-	uint16_t portid;
-	uint16_t queue_id;
-	static pthread_t tid;
-	char thread_name[RTE_MAX_THREAD_NAME_LEN];
-
-	/* init EAL */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Error with EAL initialization\n");
-	argc -= ret;
-	argv += ret;
-
-	/* parse app arguments */
-	ret = tep_termination_parse_args(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid argument\n");
-
-	for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++)
-		if (rte_lcore_is_enabled(lcore_id))
-			lcore_ids[core_id++] = lcore_id;
-
-	/* set the number of swithcing cores available */
-	nb_switching_cores = rte_lcore_count()-1;
-
-	/* Get the number of physical ports. */
-	nb_ports = rte_eth_dev_count();
-
-	/*
-	 * Update the global var NB_PORTS and global array PORTS
-	 * and get value of var VALID_NB_PORTS according to system ports number
-	 */
-	valid_nb_ports = check_ports_num(nb_ports);
-
-	if ((valid_nb_ports == 0) || (valid_nb_ports > MAX_SUP_PORTS)) {
-		rte_exit(EXIT_FAILURE, "Current enabled port number is %u,"
-			"but only %u port can be enabled\n", nb_ports,
-			MAX_SUP_PORTS);
-	}
-	/* Create the mbuf pool. */
-	mbuf_pool = rte_pktmbuf_pool_create(
-			"MBUF_POOL",
-			NUM_MBUFS_PER_PORT * valid_nb_ports,
-			MBUF_CACHE_SIZE,
-			0,
-			MBUF_DATA_SIZE,
-			rte_socket_id());
-	if (mbuf_pool == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot create mbuf pool\n");
-
-	for (queue_id = 0; queue_id < MAX_QUEUES + 1; queue_id++)
-		vpool_array[queue_id].pool = mbuf_pool;
-
-	/* initialize all ports */
-	RTE_ETH_FOREACH_DEV(portid) {
-		/* skip ports that are not enabled */
-		if ((enabled_port_mask & (1 << portid)) == 0) {
-			RTE_LOG(INFO, VHOST_PORT,
-				"Skipping disabled port %d\n", portid);
-			continue;
-		}
-		if (overlay_options.port_configure(portid, mbuf_pool) != 0)
-			rte_exit(EXIT_FAILURE,
-				"Cannot initialize network ports\n");
-	}
-
-	/* Initialise all linked lists. */
-	if (init_data_ll() == -1)
-		rte_exit(EXIT_FAILURE, "Failed to initialize linked list\n");
-
-	/* Initialize device stats */
-	memset(&dev_statistics, 0, sizeof(dev_statistics));
-
-	/* Enable stats if the user option is set. */
-	if (enable_stats) {
-		ret = pthread_create(&tid, NULL, (void *)print_stats, NULL);
-		if (ret != 0)
-			rte_exit(EXIT_FAILURE, "Cannot create print-stats thread\n");
-		snprintf(thread_name, RTE_MAX_THREAD_NAME_LEN, "print-stats");
-		ret = rte_thread_setname(tid, thread_name);
-		if (ret != 0)
-			RTE_LOG(DEBUG, VHOST_CONFIG, "Cannot set print-stats name\n");
-	}
-
-	/* Launch all data cores. */
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		rte_eal_remote_launch(switch_worker,
-			mbuf_pool, lcore_id);
-	}
-
-	ret = rte_vhost_driver_register((char *)&dev_basename, 0);
-	if (ret != 0)
-		rte_exit(EXIT_FAILURE, "failed to register vhost driver.\n");
-
-	rte_vhost_driver_disable_features(dev_basename,
-		1ULL << VIRTIO_NET_F_MRG_RXBUF);
-
-	ret = rte_vhost_driver_callback_register(dev_basename,
-		&virtio_net_device_ops);
-	if (ret != 0) {
-		rte_exit(EXIT_FAILURE,
-			"failed to register vhost driver callbacks.\n");
-	}
-
-	if (rte_vhost_driver_start(dev_basename) < 0) {
-		rte_exit(EXIT_FAILURE,
-			"failed to start vhost driver.\n");
-	}
-
-	RTE_LCORE_FOREACH_SLAVE(lcore_id)
-		rte_eal_wait_lcore(lcore_id);
-
-	return 0;
-}
diff --git a/examples/tep_termination/main.h b/examples/tep_termination/main.h
deleted file mode 100644
index 966c63a..0000000
--- a/examples/tep_termination/main.h
+++ /dev/null
@@ -1,93 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#ifndef _MAIN_H_
-#define _MAIN_H_
-
-#include <rte_ether.h>
-
-/* Macros for printing using RTE_LOG */
-#define RTE_LOGTYPE_VHOST_CONFIG RTE_LOGTYPE_USER1
-#define RTE_LOGTYPE_VHOST_DATA   RTE_LOGTYPE_USER2
-#define RTE_LOGTYPE_VHOST_PORT   RTE_LOGTYPE_USER3
-
-/* State of virtio device. */
-#define DEVICE_MAC_LEARNING	0
-#define DEVICE_RX		1
-#define DEVICE_SAFE_REMOVE	2
-
-#define MAX_QUEUES 512
-
-/* Max burst size for RX/TX */
-#define MAX_PKT_BURST 32
-
-/* Max number of devices. Limited by the application. */
-#define MAX_DEVICES 64
-
-enum {VIRTIO_RXQ, VIRTIO_TXQ, VIRTIO_QNUM};
-
-/* Per-device statistics struct */
-struct device_statistics {
-	uint64_t tx_total;
-	rte_atomic64_t rx_total_atomic;
-	uint64_t rx_total;
-	uint64_t tx;
-	rte_atomic64_t rx_atomic;
-	/**< Bad inner IP csum for tunneling pkt */
-	rte_atomic64_t rx_bad_ip_csum;
-	/**< Bad inner L4 csum for tunneling pkt */
-	rte_atomic64_t rx_bad_l4_csum;
-} __rte_cache_aligned;
-
-/**
- * Device linked list structure for data path.
- */
-struct vhost_dev {
-	int vid;
-	/**< Number of memory regions for gpa to hpa translation. */
-	uint32_t nregions_hpa;
-	/**< Memory region information for gpa to hpa translation. */
-	struct virtio_memory_regions_hpa *regions_hpa;
-	/**< Device MAC address (Obtained on first TX packet). */
-	struct ether_addr mac_address;
-	/**< RX queue number. */
-	uint16_t rx_q;
-	/**< Data core that the device is added to. */
-	uint16_t coreid;
-	/**< A device is set as ready if the MAC address has been set. */
-	volatile uint8_t ready;
-	/**< Device is marked for removal from the data core. */
-	volatile uint8_t remove;
-} __rte_cache_aligned;
-
-/**
- * Structure containing data core specific information.
- */
-struct lcore_ll_info {
-	/**< Pointer to head in free linked list. */
-	struct virtio_net_data_ll *ll_root_free;
-	/**< Pointer to head of used linked list. */
-	struct virtio_net_data_ll *ll_root_used;
-	/**< Number of devices on lcore. */
-	uint32_t device_num;
-	/**< Flag to synchronize device removal. */
-	volatile uint8_t dev_removal_flag;
-};
-
-struct lcore_info {
-	/**< Pointer to data core specific lcore_ll_info struct */
-	struct lcore_ll_info	*lcore_ll;
-};
-
-struct virtio_net_data_ll {
-	/**< Pointer to device created by configuration core. */
-	struct vhost_dev            *vdev;
-	/**< Pointer to next device in linked list. */
-	struct virtio_net_data_ll   *next;
-};
-
-uint32_t
-virtio_dev_rx(int vid, struct rte_mbuf **pkts, uint32_t count);
-
-#endif /* _MAIN_H_ */
diff --git a/examples/tep_termination/meson.build b/examples/tep_termination/meson.build
deleted file mode 100644
index 24697ec..0000000
--- a/examples/tep_termination/meson.build
+++ /dev/null
@@ -1,13 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-deps += ['hash', 'vhost']
-allow_experimental_apis = true
-sources = files(
-	'main.c', 'vxlan.c', 'vxlan_setup.c'
-)
diff --git a/examples/tep_termination/vxlan.c b/examples/tep_termination/vxlan.c
deleted file mode 100644
index 7732821..0000000
--- a/examples/tep_termination/vxlan.c
+++ /dev/null
@@ -1,236 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#include <stdint.h>
-#include <rte_mbuf.h>
-#include <rte_hash_crc.h>
-#include <rte_byteorder.h>
-#include <rte_udp.h>
-#include <rte_tcp.h>
-#include <rte_sctp.h>
-
-#include "main.h"
-#include "vxlan.h"
-
-static uint16_t
-get_psd_sum(void *l3_hdr, uint16_t ethertype, uint64_t ol_flags)
-{
-	if (ethertype == ETHER_TYPE_IPv4)
-		return rte_ipv4_phdr_cksum(l3_hdr, ol_flags);
-	else /* assume ethertype == ETHER_TYPE_IPv6 */
-		return rte_ipv6_phdr_cksum(l3_hdr, ol_flags);
-}
-
-/**
- * Parse an ethernet header to fill the ethertype, outer_l2_len, outer_l3_len and
- * ipproto. This function is able to recognize IPv4/IPv6 with one optional vlan
- * header.
- */
-static void
-parse_ethernet(struct ether_hdr *eth_hdr, union tunnel_offload_info *info,
-		uint8_t *l4_proto)
-{
-	struct ipv4_hdr *ipv4_hdr;
-	struct ipv6_hdr *ipv6_hdr;
-	uint16_t ethertype;
-
-	info->outer_l2_len = sizeof(struct ether_hdr);
-	ethertype = rte_be_to_cpu_16(eth_hdr->ether_type);
-
-	if (ethertype == ETHER_TYPE_VLAN) {
-		struct vlan_hdr *vlan_hdr = (struct vlan_hdr *)(eth_hdr + 1);
-		info->outer_l2_len  += sizeof(struct vlan_hdr);
-		ethertype = rte_be_to_cpu_16(vlan_hdr->eth_proto);
-	}
-
-	switch (ethertype) {
-	case ETHER_TYPE_IPv4:
-		ipv4_hdr = (struct ipv4_hdr *)
-			((char *)eth_hdr + info->outer_l2_len);
-		info->outer_l3_len = sizeof(struct ipv4_hdr);
-		*l4_proto = ipv4_hdr->next_proto_id;
-		break;
-	case ETHER_TYPE_IPv6:
-		ipv6_hdr = (struct ipv6_hdr *)
-			((char *)eth_hdr + info->outer_l2_len);
-		info->outer_l3_len = sizeof(struct ipv6_hdr);
-		*l4_proto = ipv6_hdr->proto;
-		break;
-	default:
-		info->outer_l3_len = 0;
-		*l4_proto = 0;
-		break;
-	}
-}
-
-/**
- * Calculate the checksum of a packet in hardware
- */
-static uint64_t
-process_inner_cksums(struct ether_hdr *eth_hdr, union tunnel_offload_info *info)
-{
-	void *l3_hdr = NULL;
-	uint8_t l4_proto;
-	uint16_t ethertype;
-	struct ipv4_hdr *ipv4_hdr;
-	struct ipv6_hdr *ipv6_hdr;
-	struct udp_hdr *udp_hdr;
-	struct tcp_hdr *tcp_hdr;
-	struct sctp_hdr *sctp_hdr;
-	uint64_t ol_flags = 0;
-
-	info->l2_len = sizeof(struct ether_hdr);
-	ethertype = rte_be_to_cpu_16(eth_hdr->ether_type);
-
-	if (ethertype == ETHER_TYPE_VLAN) {
-		struct vlan_hdr *vlan_hdr = (struct vlan_hdr *)(eth_hdr + 1);
-		info->l2_len  += sizeof(struct vlan_hdr);
-		ethertype = rte_be_to_cpu_16(vlan_hdr->eth_proto);
-	}
-
-	l3_hdr = (char *)eth_hdr + info->l2_len;
-
-	if (ethertype == ETHER_TYPE_IPv4) {
-		ipv4_hdr = (struct ipv4_hdr *)l3_hdr;
-		ipv4_hdr->hdr_checksum = 0;
-		ol_flags |= PKT_TX_IPV4;
-		ol_flags |= PKT_TX_IP_CKSUM;
-		info->l3_len = sizeof(struct ipv4_hdr);
-		l4_proto = ipv4_hdr->next_proto_id;
-	} else if (ethertype == ETHER_TYPE_IPv6) {
-		ipv6_hdr = (struct ipv6_hdr *)l3_hdr;
-		info->l3_len = sizeof(struct ipv6_hdr);
-		l4_proto = ipv6_hdr->proto;
-		ol_flags |= PKT_TX_IPV6;
-	} else
-		return 0; /* packet type not supported, nothing to do */
-
-	if (l4_proto == IPPROTO_UDP) {
-		udp_hdr = (struct udp_hdr *)((char *)l3_hdr + info->l3_len);
-		ol_flags |= PKT_TX_UDP_CKSUM;
-		udp_hdr->dgram_cksum = get_psd_sum(l3_hdr,
-				ethertype, ol_flags);
-	} else if (l4_proto == IPPROTO_TCP) {
-		tcp_hdr = (struct tcp_hdr *)((char *)l3_hdr + info->l3_len);
-		/* Put PKT_TX_TCP_SEG bit setting before get_psd_sum(), because
-		 * it depends on PKT_TX_TCP_SEG to calculate pseudo-header
-		 * checksum.
-		 */
-		if (tso_segsz != 0) {
-			ol_flags |= PKT_TX_TCP_SEG;
-			info->tso_segsz = tso_segsz;
-			info->l4_len = (tcp_hdr->data_off & 0xf0) >> 2;
-		}
-		ol_flags |= PKT_TX_TCP_CKSUM;
-		tcp_hdr->cksum = get_psd_sum(l3_hdr, ethertype, ol_flags);
-
-	} else if (l4_proto == IPPROTO_SCTP) {
-		sctp_hdr = (struct sctp_hdr *)((char *)l3_hdr + info->l3_len);
-		sctp_hdr->cksum = 0;
-		ol_flags |= PKT_TX_SCTP_CKSUM;
-	}
-
-	return ol_flags;
-}
-
-int
-decapsulation(struct rte_mbuf *pkt)
-{
-	uint8_t l4_proto = 0;
-	uint16_t outer_header_len;
-	struct udp_hdr *udp_hdr;
-	union tunnel_offload_info info = { .data = 0 };
-	struct ether_hdr *phdr = rte_pktmbuf_mtod(pkt, struct ether_hdr *);
-
-	parse_ethernet(phdr, &info, &l4_proto);
-
-	if (l4_proto != IPPROTO_UDP)
-		return -1;
-
-	udp_hdr = (struct udp_hdr *)((char *)phdr +
-		info.outer_l2_len + info.outer_l3_len);
-
-	/** check udp destination port, 4789 is the default vxlan port
-	 * (rfc7348) or that the rx offload flag is set (i40e only
-	 * currently)*/
-	if (udp_hdr->dst_port != rte_cpu_to_be_16(DEFAULT_VXLAN_PORT) &&
-		(pkt->packet_type & RTE_PTYPE_TUNNEL_MASK) == 0)
-		return -1;
-	outer_header_len = info.outer_l2_len + info.outer_l3_len
-		+ sizeof(struct udp_hdr) + sizeof(struct vxlan_hdr);
-
-	rte_pktmbuf_adj(pkt, outer_header_len);
-
-	return 0;
-}
-
-void
-encapsulation(struct rte_mbuf *m, uint8_t queue_id)
-{
-	uint vport_id;
-	uint64_t ol_flags = 0;
-	uint32_t old_len = m->pkt_len, hash;
-	union tunnel_offload_info tx_offload = { .data = 0 };
-	struct ether_hdr *phdr = rte_pktmbuf_mtod(m, struct ether_hdr *);
-
-	/*Allocate space for new ethernet, IPv4, UDP and VXLAN headers*/
-	struct ether_hdr *pneth = (struct ether_hdr *) rte_pktmbuf_prepend(m,
-		sizeof(struct ether_hdr) + sizeof(struct ipv4_hdr)
-		+ sizeof(struct udp_hdr) + sizeof(struct vxlan_hdr));
-
-	struct ipv4_hdr *ip = (struct ipv4_hdr *) &pneth[1];
-	struct udp_hdr *udp = (struct udp_hdr *) &ip[1];
-	struct vxlan_hdr *vxlan = (struct vxlan_hdr *) &udp[1];
-
-	/* convert TX queue ID to vport ID */
-	vport_id = queue_id - 1;
-
-	/* replace original Ethernet header with ours */
-	pneth = rte_memcpy(pneth, &app_l2_hdr[vport_id],
-		sizeof(struct ether_hdr));
-
-	/* copy in IP header */
-	ip = rte_memcpy(ip, &app_ip_hdr[vport_id],
-		sizeof(struct ipv4_hdr));
-	ip->total_length = rte_cpu_to_be_16(m->pkt_len
-				- sizeof(struct ether_hdr));
-
-	/* outer IP checksum */
-	ol_flags |= PKT_TX_OUTER_IP_CKSUM;
-	ip->hdr_checksum = 0;
-
-	/* inner IP checksum offload */
-	if (tx_checksum) {
-		ol_flags |= process_inner_cksums(phdr, &tx_offload);
-		m->l2_len = tx_offload.l2_len;
-		m->l3_len = tx_offload.l3_len;
-		m->l4_len = tx_offload.l4_len;
-		m->l2_len += ETHER_VXLAN_HLEN;
-	}
-
-	m->outer_l2_len = sizeof(struct ether_hdr);
-	m->outer_l3_len = sizeof(struct ipv4_hdr);
-
-	ol_flags |= PKT_TX_TUNNEL_VXLAN;
-
-	m->ol_flags |= ol_flags;
-	m->tso_segsz = tx_offload.tso_segsz;
-
-	/*VXLAN HEADER*/
-	vxlan->vx_flags = rte_cpu_to_be_32(VXLAN_HF_VNI);
-	vxlan->vx_vni = rte_cpu_to_be_32(vxdev.out_key << 8);
-
-	/*UDP HEADER*/
-	udp->dgram_cksum = 0;
-	udp->dgram_len = rte_cpu_to_be_16(old_len
-				+ sizeof(struct udp_hdr)
-				+ sizeof(struct vxlan_hdr));
-
-	udp->dst_port = rte_cpu_to_be_16(vxdev.dst_port);
-	hash = rte_hash_crc(phdr, 2 * ETHER_ADDR_LEN, phdr->ether_type);
-	udp->src_port = rte_cpu_to_be_16((((uint64_t) hash * PORT_RANGE) >> 32)
-					+ PORT_MIN);
-
-	return;
-}
diff --git a/examples/tep_termination/vxlan.h b/examples/tep_termination/vxlan.h
deleted file mode 100644
index bff786a..0000000
--- a/examples/tep_termination/vxlan.h
+++ /dev/null
@@ -1,57 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#ifndef _VXLAN_H_
-#define _VXLAN_H_
-
-#include <rte_ether.h>
-#include <rte_ip.h>
-
-#define PORT_MIN	49152
-#define PORT_MAX	65535
-#define PORT_RANGE ((PORT_MAX - PORT_MIN) + 1)
-
-#define VXLAN_N_PORTS  2
-#define VXLAN_HF_VNI 0x08000000
-#define DEFAULT_VXLAN_PORT 4789
-
-extern struct ipv4_hdr app_ip_hdr[VXLAN_N_PORTS];
-extern struct ether_hdr app_l2_hdr[VXLAN_N_PORTS];
-extern uint8_t tx_checksum;
-extern uint16_t tso_segsz;
-
-struct vxlan_port {
-	uint32_t vport_id;           /**< VirtIO port id */
-	uint32_t peer_ip;            /**< remote VTEP IP address */
-	struct ether_addr peer_mac;  /**< remote VTEP MAC address */
-	struct ether_addr vport_mac; /**< VirtIO port MAC address */
-} __rte_cache_aligned;
-
-struct vxlan_conf {
-	uint16_t dst_port;      /**< VXLAN UDP destination port */
-	uint32_t port_ip;       /**< DPDK port IP address*/
-	uint32_t in_key;        /**< VLAN  ID */
-	uint32_t out_key;       /**< VXLAN VNI */
-	struct vxlan_port port[VXLAN_N_PORTS]; /**< VXLAN configuration */
-} __rte_cache_aligned;
-
-extern struct vxlan_conf vxdev;
-
-/* structure that caches offload info for the current packet */
-union tunnel_offload_info {
-	uint64_t data;
-	struct {
-		uint64_t l2_len:7; /**< L2 (MAC) Header Length. */
-		uint64_t l3_len:9; /**< L3 (IP) Header Length. */
-		uint64_t l4_len:8; /**< L4 Header Length. */
-		uint64_t tso_segsz:16; /**< TCP TSO segment size */
-		uint64_t outer_l2_len:7; /**< outer L2 Header Length */
-		uint64_t outer_l3_len:16; /**< outer L3 Header Length */
-	};
-} __rte_cache_aligned;
-
-int decapsulation(struct rte_mbuf *pkt);
-void encapsulation(struct rte_mbuf *m, uint8_t queue_id);
-
-#endif /* _VXLAN_H_ */
diff --git a/examples/tep_termination/vxlan_setup.c b/examples/tep_termination/vxlan_setup.c
deleted file mode 100644
index 299c29d..0000000
--- a/examples/tep_termination/vxlan_setup.c
+++ /dev/null
@@ -1,442 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#include <getopt.h>
-#include <linux/if_ether.h>
-#include <linux/if_vlan.h>
-#include <linux/virtio_net.h>
-#include <linux/virtio_ring.h>
-#include <sys/param.h>
-#include <unistd.h>
-
-#include <rte_ethdev.h>
-#include <rte_log.h>
-#include <rte_string_fns.h>
-#include <rte_mbuf.h>
-#include <rte_malloc.h>
-#include <rte_ip.h>
-#include <rte_udp.h>
-#include <rte_tcp.h>
-
-#include "main.h"
-#include "rte_vhost.h"
-#include "vxlan.h"
-#include "vxlan_setup.h"
-
-#define IPV4_HEADER_LEN 20
-#define UDP_HEADER_LEN  8
-#define VXLAN_HEADER_LEN 8
-
-#define IP_VERSION 0x40
-#define IP_HDRLEN  0x05 /* default IP header length == five 32-bits words. */
-#define IP_DEFTTL  64   /* from RFC 1340. */
-#define IP_VHL_DEF (IP_VERSION | IP_HDRLEN)
-
-#define IP_DN_FRAGMENT_FLAG 0x0040
-
-/* Used to compare MAC addresses. */
-#define MAC_ADDR_CMP 0xFFFFFFFFFFFFULL
-
-/* Configurable number of RX/TX ring descriptors */
-#define RTE_TEST_RX_DESC_DEFAULT 1024
-#define RTE_TEST_TX_DESC_DEFAULT 512
-
-/* Default inner VLAN ID */
-#define INNER_VLAN_ID 100
-
-/* VXLAN device */
-struct vxlan_conf vxdev;
-
-struct ipv4_hdr app_ip_hdr[VXLAN_N_PORTS];
-struct ether_hdr app_l2_hdr[VXLAN_N_PORTS];
-
-/* local VTEP IP address */
-uint8_t vxlan_multicast_ips[2][4] = { {239, 1, 1, 1 }, {239, 1, 2, 1 } };
-
-/* Remote VTEP IP address */
-uint8_t vxlan_overlay_ips[2][4] = { {192, 168, 10, 1}, {192, 168, 30, 1} };
-
-/* Remote VTEP MAC address */
-uint8_t peer_mac[6] = {0x00, 0x11, 0x01, 0x00, 0x00, 0x01};
-
-/* VXLAN RX filter type */
-uint8_t tep_filter_type[] = {RTE_TUNNEL_FILTER_IMAC_TENID,
-			RTE_TUNNEL_FILTER_IMAC_IVLAN_TENID,
-			RTE_TUNNEL_FILTER_OMAC_TENID_IMAC,};
-
-/* Options for configuring ethernet port */
-static struct rte_eth_conf port_conf = {
-	.rxmode = {
-		.split_hdr_size = 0,
-		.ignore_offload_bitfield = 1,
-		.offloads = DEV_RX_OFFLOAD_CRC_STRIP,
-	},
-	.txmode = {
-		.mq_mode = ETH_MQ_TX_NONE,
-		.offloads = (DEV_TX_OFFLOAD_IPV4_CKSUM |
-			     DEV_TX_OFFLOAD_UDP_CKSUM |
-			     DEV_TX_OFFLOAD_TCP_CKSUM |
-			     DEV_TX_OFFLOAD_SCTP_CKSUM |
-			     DEV_TX_OFFLOAD_OUTER_IPV4_CKSUM |
-			     DEV_TX_OFFLOAD_TCP_TSO |
-			     DEV_TX_OFFLOAD_MULTI_SEGS |
-			     DEV_TX_OFFLOAD_VXLAN_TNL_TSO),
-	},
-};
-
-/**
- * The one or two device(s) that belongs to the same tenant ID can
- * be assigned in a VM.
- */
-const uint16_t tenant_id_conf[] = {
-	1000, 1000, 1001, 1001, 1002, 1002, 1003, 1003,
-	1004, 1004, 1005, 1005, 1006, 1006, 1007, 1007,
-	1008, 1008, 1009, 1009, 1010, 1010, 1011, 1011,
-	1012, 1012, 1013, 1013, 1014, 1014, 1015, 1015,
-	1016, 1016, 1017, 1017, 1018, 1018, 1019, 1019,
-	1020, 1020, 1021, 1021, 1022, 1022, 1023, 1023,
-	1024, 1024, 1025, 1025, 1026, 1026, 1027, 1027,
-	1028, 1028, 1029, 1029, 1030, 1030, 1031, 1031,
-};
-
-/**
- * Initialises a given port using global settings and with the rx buffers
- * coming from the mbuf_pool passed as parameter
- */
-int
-vxlan_port_init(uint16_t port, struct rte_mempool *mbuf_pool)
-{
-	int retval;
-	uint16_t q;
-	struct rte_eth_dev_info dev_info;
-	uint16_t rx_rings, tx_rings = (uint16_t)rte_lcore_count();
-	uint16_t rx_ring_size = RTE_TEST_RX_DESC_DEFAULT;
-	uint16_t tx_ring_size = RTE_TEST_TX_DESC_DEFAULT;
-	struct rte_eth_udp_tunnel tunnel_udp;
-	struct rte_eth_rxconf *rxconf;
-	struct rte_eth_txconf *txconf;
-	struct vxlan_conf *pconf = &vxdev;
-	struct rte_eth_conf local_port_conf = port_conf;
-
-	pconf->dst_port = udp_port;
-
-	rte_eth_dev_info_get(port, &dev_info);
-
-	if (dev_info.max_rx_queues > MAX_QUEUES) {
-		rte_exit(EXIT_FAILURE,
-			"please define MAX_QUEUES no less than %u in %s\n",
-			dev_info.max_rx_queues, __FILE__);
-	}
-
-	rxconf = &dev_info.default_rxconf;
-	txconf = &dev_info.default_txconf;
-	txconf->txq_flags = ETH_TXQ_FLAGS_IGNORE;
-
-	if (!rte_eth_dev_is_valid_port(port))
-		return -1;
-
-	rx_rings = nb_devices;
-	if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-		local_port_conf.txmode.offloads |=
-			DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-	/* Configure ethernet device. */
-	retval = rte_eth_dev_configure(port, rx_rings, tx_rings,
-				       &local_port_conf);
-	if (retval != 0)
-		return retval;
-
-	retval = rte_eth_dev_adjust_nb_rx_tx_desc(port, &rx_ring_size,
-			&tx_ring_size);
-	if (retval != 0)
-		return retval;
-
-	/* Setup the queues. */
-	rxconf->offloads = local_port_conf.rxmode.offloads;
-	for (q = 0; q < rx_rings; q++) {
-		retval = rte_eth_rx_queue_setup(port, q, rx_ring_size,
-						rte_eth_dev_socket_id(port),
-						rxconf,
-						mbuf_pool);
-		if (retval < 0)
-			return retval;
-	}
-	txconf->offloads = local_port_conf.txmode.offloads;
-	for (q = 0; q < tx_rings; q++) {
-		retval = rte_eth_tx_queue_setup(port, q, tx_ring_size,
-						rte_eth_dev_socket_id(port),
-						txconf);
-		if (retval < 0)
-			return retval;
-	}
-
-	/* Start the device. */
-	retval  = rte_eth_dev_start(port);
-	if (retval < 0)
-		return retval;
-
-	/* Configure UDP port for UDP tunneling */
-	tunnel_udp.udp_port = udp_port;
-	tunnel_udp.prot_type = RTE_TUNNEL_TYPE_VXLAN;
-	retval = rte_eth_dev_udp_tunnel_port_add(port, &tunnel_udp);
-	if (retval < 0)
-		return retval;
-	rte_eth_macaddr_get(port, &ports_eth_addr[port]);
-	RTE_LOG(INFO, PORT, "Port %u MAC: %02"PRIx8" %02"PRIx8" %02"PRIx8
-			" %02"PRIx8" %02"PRIx8" %02"PRIx8"\n",
-			port,
-			ports_eth_addr[port].addr_bytes[0],
-			ports_eth_addr[port].addr_bytes[1],
-			ports_eth_addr[port].addr_bytes[2],
-			ports_eth_addr[port].addr_bytes[3],
-			ports_eth_addr[port].addr_bytes[4],
-			ports_eth_addr[port].addr_bytes[5]);
-
-	if (tso_segsz != 0) {
-		struct rte_eth_dev_info dev_info;
-		rte_eth_dev_info_get(port, &dev_info);
-		if ((dev_info.tx_offload_capa & DEV_TX_OFFLOAD_TCP_TSO) == 0)
-			RTE_LOG(WARNING, PORT,
-				"hardware TSO offload is not supported\n");
-	}
-	return 0;
-}
-
-static int
-vxlan_rx_process(struct rte_mbuf *pkt)
-{
-	int ret = 0;
-
-	if (rx_decap)
-		ret = decapsulation(pkt);
-
-	return ret;
-}
-
-static void
-vxlan_tx_process(uint8_t queue_id, struct rte_mbuf *pkt)
-{
-	if (tx_encap)
-		encapsulation(pkt, queue_id);
-
-	return;
-}
-
-/*
- * This function learns the MAC address of the device and set init
- * L2 header and L3 header info.
- */
-int
-vxlan_link(struct vhost_dev *vdev, struct rte_mbuf *m)
-{
-	int i, ret;
-	struct ether_hdr *pkt_hdr;
-	uint64_t portid = vdev->vid;
-	struct ipv4_hdr *ip;
-
-	struct rte_eth_tunnel_filter_conf tunnel_filter_conf;
-
-	if (unlikely(portid >= VXLAN_N_PORTS)) {
-		RTE_LOG(INFO, VHOST_DATA,
-			"(%d) WARNING: Not configuring device,"
-			"as already have %d ports for VXLAN.",
-			vdev->vid, VXLAN_N_PORTS);
-		return -1;
-	}
-
-	/* Learn MAC address of guest device from packet */
-	pkt_hdr = rte_pktmbuf_mtod(m, struct ether_hdr *);
-	if (is_same_ether_addr(&(pkt_hdr->s_addr), &vdev->mac_address)) {
-		RTE_LOG(INFO, VHOST_DATA,
-			"(%d) WARNING: This device is using an existing"
-			" MAC address and has not been registered.\n",
-			vdev->vid);
-		return -1;
-	}
-
-	for (i = 0; i < ETHER_ADDR_LEN; i++) {
-		vdev->mac_address.addr_bytes[i] =
-			vxdev.port[portid].vport_mac.addr_bytes[i] =
-			pkt_hdr->s_addr.addr_bytes[i];
-		vxdev.port[portid].peer_mac.addr_bytes[i] = peer_mac[i];
-	}
-
-	memset(&tunnel_filter_conf, 0,
-		sizeof(struct rte_eth_tunnel_filter_conf));
-
-	ether_addr_copy(&ports_eth_addr[0], &tunnel_filter_conf.outer_mac);
-	tunnel_filter_conf.filter_type = tep_filter_type[filter_idx];
-
-	/* inner MAC */
-	ether_addr_copy(&vdev->mac_address, &tunnel_filter_conf.inner_mac);
-
-	tunnel_filter_conf.queue_id = vdev->rx_q;
-	tunnel_filter_conf.tenant_id = tenant_id_conf[vdev->rx_q];
-
-	if (tep_filter_type[filter_idx] == RTE_TUNNEL_FILTER_IMAC_IVLAN_TENID)
-		tunnel_filter_conf.inner_vlan = INNER_VLAN_ID;
-
-	tunnel_filter_conf.tunnel_type = RTE_TUNNEL_TYPE_VXLAN;
-
-	ret = rte_eth_dev_filter_ctrl(ports[0],
-		RTE_ETH_FILTER_TUNNEL,
-		RTE_ETH_FILTER_ADD,
-		&tunnel_filter_conf);
-	if (ret) {
-		RTE_LOG(ERR, VHOST_DATA,
-			"%d Failed to add device MAC address to cloud filter\n",
-		vdev->rx_q);
-		return -1;
-	}
-
-	/* Print out inner MAC and VNI info. */
-	RTE_LOG(INFO, VHOST_DATA,
-		"(%d) MAC_ADDRESS %02x:%02x:%02x:%02x:%02x:%02x and VNI %d registered\n",
-		vdev->rx_q,
-		vdev->mac_address.addr_bytes[0],
-		vdev->mac_address.addr_bytes[1],
-		vdev->mac_address.addr_bytes[2],
-		vdev->mac_address.addr_bytes[3],
-		vdev->mac_address.addr_bytes[4],
-		vdev->mac_address.addr_bytes[5],
-		tenant_id_conf[vdev->rx_q]);
-
-	vxdev.port[portid].vport_id = portid;
-
-	for (i = 0; i < 4; i++) {
-		/* Local VTEP IP */
-		vxdev.port_ip |= vxlan_multicast_ips[portid][i] << (8 * i);
-		/* Remote VTEP IP */
-		vxdev.port[portid].peer_ip |=
-			vxlan_overlay_ips[portid][i] << (8 * i);
-	}
-
-	vxdev.out_key = tenant_id_conf[vdev->rx_q];
-	ether_addr_copy(&vxdev.port[portid].peer_mac,
-			&app_l2_hdr[portid].d_addr);
-	ether_addr_copy(&ports_eth_addr[0],
-			&app_l2_hdr[portid].s_addr);
-	app_l2_hdr[portid].ether_type = rte_cpu_to_be_16(ETHER_TYPE_IPv4);
-
-	ip = &app_ip_hdr[portid];
-	ip->version_ihl = IP_VHL_DEF;
-	ip->type_of_service = 0;
-	ip->total_length = 0;
-	ip->packet_id = 0;
-	ip->fragment_offset = IP_DN_FRAGMENT_FLAG;
-	ip->time_to_live = IP_DEFTTL;
-	ip->next_proto_id = IPPROTO_UDP;
-	ip->hdr_checksum = 0;
-	ip->src_addr = vxdev.port_ip;
-	ip->dst_addr = vxdev.port[portid].peer_ip;
-
-	/* Set device as ready for RX. */
-	vdev->ready = DEVICE_RX;
-
-	return 0;
-}
-
-/**
- * Removes cloud filter. Ensures that nothing is adding buffers to the RX
- * queue before disabling RX on the device.
- */
-void
-vxlan_unlink(struct vhost_dev *vdev)
-{
-	unsigned i = 0, rx_count;
-	int ret;
-	struct rte_mbuf *pkts_burst[MAX_PKT_BURST];
-	struct rte_eth_tunnel_filter_conf tunnel_filter_conf;
-
-	if (vdev->ready == DEVICE_RX) {
-		memset(&tunnel_filter_conf, 0,
-			sizeof(struct rte_eth_tunnel_filter_conf));
-
-		ether_addr_copy(&ports_eth_addr[0], &tunnel_filter_conf.outer_mac);
-		ether_addr_copy(&vdev->mac_address, &tunnel_filter_conf.inner_mac);
-		tunnel_filter_conf.tenant_id = tenant_id_conf[vdev->rx_q];
-		tunnel_filter_conf.filter_type = tep_filter_type[filter_idx];
-
-		if (tep_filter_type[filter_idx] ==
-			RTE_TUNNEL_FILTER_IMAC_IVLAN_TENID)
-			tunnel_filter_conf.inner_vlan = INNER_VLAN_ID;
-
-		tunnel_filter_conf.queue_id = vdev->rx_q;
-		tunnel_filter_conf.tunnel_type = RTE_TUNNEL_TYPE_VXLAN;
-
-		ret = rte_eth_dev_filter_ctrl(ports[0],
-				RTE_ETH_FILTER_TUNNEL,
-				RTE_ETH_FILTER_DELETE,
-				&tunnel_filter_conf);
-		if (ret) {
-			RTE_LOG(ERR, VHOST_DATA,
-				"%d Failed to add device MAC address to cloud filter\n",
-				vdev->rx_q);
-			return;
-		}
-		for (i = 0; i < ETHER_ADDR_LEN; i++)
-			vdev->mac_address.addr_bytes[i] = 0;
-
-		/* Clear out the receive buffers */
-		rx_count = rte_eth_rx_burst(ports[0],
-				(uint16_t)vdev->rx_q,
-				pkts_burst, MAX_PKT_BURST);
-
-		while (rx_count) {
-			for (i = 0; i < rx_count; i++)
-				rte_pktmbuf_free(pkts_burst[i]);
-
-			rx_count = rte_eth_rx_burst(ports[0],
-					(uint16_t)vdev->rx_q,
-					pkts_burst, MAX_PKT_BURST);
-		}
-		vdev->ready = DEVICE_MAC_LEARNING;
-	}
-}
-
-/* Transmit packets after encapsulating */
-int
-vxlan_tx_pkts(uint16_t port_id, uint16_t queue_id,
-		struct rte_mbuf **tx_pkts, uint16_t nb_pkts) {
-	int ret = 0;
-	uint16_t i;
-
-	for (i = 0; i < nb_pkts; i++)
-		vxlan_tx_process(queue_id, tx_pkts[i]);
-
-	ret = rte_eth_tx_burst(port_id, queue_id, tx_pkts, nb_pkts);
-
-	return ret;
-}
-
-/* Check for decapsulation and pass packets directly to VIRTIO device */
-int
-vxlan_rx_pkts(int vid, struct rte_mbuf **pkts_burst, uint32_t rx_count)
-{
-	uint32_t i = 0;
-	uint32_t count = 0;
-	int ret;
-	struct rte_mbuf *pkts_valid[rx_count];
-
-	for (i = 0; i < rx_count; i++) {
-		if (enable_stats) {
-			rte_atomic64_add(
-				&dev_statistics[vid].rx_bad_ip_csum,
-				(pkts_burst[i]->ol_flags & PKT_RX_IP_CKSUM_BAD)
-				!= 0);
-			rte_atomic64_add(
-				&dev_statistics[vid].rx_bad_ip_csum,
-				(pkts_burst[i]->ol_flags & PKT_RX_L4_CKSUM_BAD)
-				!= 0);
-		}
-		ret = vxlan_rx_process(pkts_burst[i]);
-		if (unlikely(ret < 0))
-			continue;
-
-		pkts_valid[count] = pkts_burst[i];
-			count++;
-	}
-
-	ret = rte_vhost_enqueue_burst(vid, VIRTIO_RXQ, pkts_valid, count);
-	return ret;
-}
diff --git a/examples/tep_termination/vxlan_setup.h b/examples/tep_termination/vxlan_setup.h
deleted file mode 100644
index 2c20e2e..0000000
--- a/examples/tep_termination/vxlan_setup.h
+++ /dev/null
@@ -1,58 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2015 Intel Corporation
- */
-
-#ifndef VXLAN_SETUP_H_
-#define VXLAN_SETUP_H_
-
-extern uint16_t nb_devices;
-extern uint16_t udp_port;
-extern uint8_t filter_idx;
-extern uint16_t ports[RTE_MAX_ETHPORTS];
-extern struct ether_addr ports_eth_addr[RTE_MAX_ETHPORTS];
-extern uint32_t enable_stats;
-extern struct device_statistics dev_statistics[MAX_DEVICES];
-extern uint8_t rx_decap;
-extern uint8_t tx_encap;
-
-typedef int (*ol_port_configure_t)(uint16_t port,
-				   struct rte_mempool *mbuf_pool);
-
-typedef int (*ol_tunnel_setup_t)(struct vhost_dev *vdev,
-				 struct rte_mbuf *m);
-
-typedef void (*ol_tunnel_destroy_t)(struct vhost_dev *vdev);
-
-typedef int (*ol_tx_handle_t)(uint16_t port_id, uint16_t queue_id,
-			      struct rte_mbuf **tx_pkts, uint16_t nb_pkts);
-
-typedef int (*ol_rx_handle_t)(int vid, struct rte_mbuf **pkts,
-			      uint32_t count);
-
-typedef int (*ol_param_handle)(int vid);
-
-struct ol_switch_ops {
-	ol_port_configure_t        port_configure;
-	ol_tunnel_setup_t          tunnel_setup;
-	ol_tunnel_destroy_t        tunnel_destroy;
-	ol_tx_handle_t             tx_handle;
-	ol_rx_handle_t             rx_handle;
-	ol_param_handle            param_handle;
-};
-
-int
-vxlan_port_init(uint16_t port, struct rte_mempool *mbuf_pool);
-
-int
-vxlan_link(struct vhost_dev *vdev, struct rte_mbuf *m);
-
-void
-vxlan_unlink(struct vhost_dev *vdev);
-
-int
-vxlan_tx_pkts(uint16_t port_id, uint16_t queue_id,
-			struct rte_mbuf **tx_pkts, uint16_t nb_pkts);
-int
-vxlan_rx_pkts(int vid, struct rte_mbuf **pkts, uint32_t count);
-
-#endif /* VXLAN_SETUP_H_ */
diff --git a/examples/timer/Makefile b/examples/timer/Makefile
deleted file mode 100644
index 42b23f2..0000000
--- a/examples/timer/Makefile
+++ /dev/null
@@ -1,61 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-# binary name
-APP = timer
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else # Build using legacy build system
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -O3
-CFLAGS += $(WERROR_FLAGS)
-
-# workaround for a gcc bug with noreturn attribute
-# http://gcc.gnu.org/bugzilla/show_bug.cgi?id=12603
-ifeq ($(CONFIG_RTE_TOOLCHAIN_GCC),y)
-CFLAGS_main.o += -Wno-return-type
-endif
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-endif
diff --git a/examples/timer/main.c b/examples/timer/main.c
deleted file mode 100644
index 968a941..0000000
--- a/examples/timer/main.c
+++ /dev/null
@@ -1,121 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdio.h>
-#include <string.h>
-#include <stdint.h>
-#include <errno.h>
-#include <sys/queue.h>
-
-#include <rte_common.h>
-#include <rte_memory.h>
-#include <rte_launch.h>
-#include <rte_eal.h>
-#include <rte_per_lcore.h>
-#include <rte_lcore.h>
-#include <rte_cycles.h>
-#include <rte_timer.h>
-#include <rte_debug.h>
-
-#define TIMER_RESOLUTION_CYCLES 20000000ULL /* around 10ms at 2 Ghz */
-
-static struct rte_timer timer0;
-static struct rte_timer timer1;
-
-/* timer0 callback */
-static void
-timer0_cb(__attribute__((unused)) struct rte_timer *tim,
-	  __attribute__((unused)) void *arg)
-{
-	static unsigned counter = 0;
-	unsigned lcore_id = rte_lcore_id();
-
-	printf("%s() on lcore %u\n", __func__, lcore_id);
-
-	/* this timer is automatically reloaded until we decide to
-	 * stop it, when counter reaches 20. */
-	if ((counter ++) == 20)
-		rte_timer_stop(tim);
-}
-
-/* timer1 callback */
-static void
-timer1_cb(__attribute__((unused)) struct rte_timer *tim,
-	  __attribute__((unused)) void *arg)
-{
-	unsigned lcore_id = rte_lcore_id();
-	uint64_t hz;
-
-	printf("%s() on lcore %u\n", __func__, lcore_id);
-
-	/* reload it on another lcore */
-	hz = rte_get_timer_hz();
-	lcore_id = rte_get_next_lcore(lcore_id, 0, 1);
-	rte_timer_reset(tim, hz/3, SINGLE, lcore_id, timer1_cb, NULL);
-}
-
-static __attribute__((noreturn)) int
-lcore_mainloop(__attribute__((unused)) void *arg)
-{
-	uint64_t prev_tsc = 0, cur_tsc, diff_tsc;
-	unsigned lcore_id;
-
-	lcore_id = rte_lcore_id();
-	printf("Starting mainloop on core %u\n", lcore_id);
-
-	while (1) {
-		/*
-		 * Call the timer handler on each core: as we don't
-		 * need a very precise timer, so only call
-		 * rte_timer_manage() every ~10ms (at 2Ghz). In a real
-		 * application, this will enhance performances as
-		 * reading the HPET timer is not efficient.
-		 */
-		cur_tsc = rte_rdtsc();
-		diff_tsc = cur_tsc - prev_tsc;
-		if (diff_tsc > TIMER_RESOLUTION_CYCLES) {
-			rte_timer_manage();
-			prev_tsc = cur_tsc;
-		}
-	}
-}
-
-int
-main(int argc, char **argv)
-{
-	int ret;
-	uint64_t hz;
-	unsigned lcore_id;
-
-	/* init EAL */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_panic("Cannot init EAL\n");
-
-	/* init RTE timer library */
-	rte_timer_subsystem_init();
-
-	/* init timer structures */
-	rte_timer_init(&timer0);
-	rte_timer_init(&timer1);
-
-	/* load timer0, every second, on master lcore, reloaded automatically */
-	hz = rte_get_timer_hz();
-	lcore_id = rte_lcore_id();
-	rte_timer_reset(&timer0, hz, PERIODICAL, lcore_id, timer0_cb, NULL);
-
-	/* load timer1, every second/3, on next lcore, reloaded manually */
-	lcore_id = rte_get_next_lcore(lcore_id, 0, 1);
-	rte_timer_reset(&timer1, hz/3, SINGLE, lcore_id, timer1_cb, NULL);
-
-	/* call lcore_mainloop() on every slave lcore */
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		rte_eal_remote_launch(lcore_mainloop, NULL, lcore_id);
-	}
-
-	/* call it on master lcore too */
-	(void) lcore_mainloop(NULL);
-
-	return 0;
-}
diff --git a/examples/timer/meson.build b/examples/timer/meson.build
deleted file mode 100644
index c3d9016..0000000
--- a/examples/timer/meson.build
+++ /dev/null
@@ -1,12 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-deps += 'timer'
-sources = files(
-	'main.c'
-)
diff --git a/examples/vhost/Makefile b/examples/vhost/Makefile
deleted file mode 100644
index 67cc55b..0000000
--- a/examples/vhost/Makefile
+++ /dev/null
@@ -1,69 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-# binary name
-APP = vhost-switch
-
-# all source are stored in SRCS-y
-SRCS-y := main.c virtio_net.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-LDFLAGS += -pthread
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else # Build using legacy build system
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-ifneq ($(CONFIG_RTE_EXEC_ENV),"linuxapp")
-$(info This application can only operate in a linuxapp environment, \
-please change the definition of the RTE_TARGET environment variable)
-all:
-else
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -O2 -D_FILE_OFFSET_BITS=64
-CFLAGS += $(WERROR_FLAGS)
-CFLAGS += -D_GNU_SOURCE
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-
-endif
-endif
diff --git a/examples/vhost/main.c b/examples/vhost/main.c
deleted file mode 100644
index 7cddac7..0000000
--- a/examples/vhost/main.c
+++ /dev/null
@@ -1,1576 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2017 Intel Corporation
- */
-
-#include <arpa/inet.h>
-#include <getopt.h>
-#include <linux/if_ether.h>
-#include <linux/if_vlan.h>
-#include <linux/virtio_net.h>
-#include <linux/virtio_ring.h>
-#include <signal.h>
-#include <stdint.h>
-#include <sys/eventfd.h>
-#include <sys/param.h>
-#include <unistd.h>
-
-#include <rte_atomic.h>
-#include <rte_cycles.h>
-#include <rte_ethdev.h>
-#include <rte_log.h>
-#include <rte_string_fns.h>
-#include <rte_malloc.h>
-#include <rte_vhost.h>
-#include <rte_ip.h>
-#include <rte_tcp.h>
-#include <rte_pause.h>
-
-#include "main.h"
-
-#ifndef MAX_QUEUES
-#define MAX_QUEUES 128
-#endif
-
-/* the maximum number of external ports supported */
-#define MAX_SUP_PORTS 1
-
-#define MBUF_CACHE_SIZE	128
-#define MBUF_DATA_SIZE	RTE_MBUF_DEFAULT_BUF_SIZE
-
-#define BURST_TX_DRAIN_US 100	/* TX drain every ~100us */
-
-#define BURST_RX_WAIT_US 15	/* Defines how long we wait between retries on RX */
-#define BURST_RX_RETRIES 4		/* Number of retries on RX. */
-
-#define JUMBO_FRAME_MAX_SIZE    0x2600
-
-/* State of virtio device. */
-#define DEVICE_MAC_LEARNING 0
-#define DEVICE_RX			1
-#define DEVICE_SAFE_REMOVE	2
-
-/* Configurable number of RX/TX ring descriptors */
-#define RTE_TEST_RX_DESC_DEFAULT 1024
-#define RTE_TEST_TX_DESC_DEFAULT 512
-
-#define INVALID_PORT_ID 0xFF
-
-/* Max number of devices. Limited by vmdq. */
-#define MAX_DEVICES 64
-
-/* Size of buffers used for snprintfs. */
-#define MAX_PRINT_BUFF 6072
-
-/* Maximum long option length for option parsing. */
-#define MAX_LONG_OPT_SZ 64
-
-/* mask of enabled ports */
-static uint32_t enabled_port_mask = 0;
-
-/* Promiscuous mode */
-static uint32_t promiscuous;
-
-/* number of devices/queues to support*/
-static uint32_t num_queues = 0;
-static uint32_t num_devices;
-
-static struct rte_mempool *mbuf_pool;
-static int mergeable;
-
-/* Enable VM2VM communications. If this is disabled then the MAC address compare is skipped. */
-typedef enum {
-	VM2VM_DISABLED = 0,
-	VM2VM_SOFTWARE = 1,
-	VM2VM_HARDWARE = 2,
-	VM2VM_LAST
-} vm2vm_type;
-static vm2vm_type vm2vm_mode = VM2VM_SOFTWARE;
-
-/* Enable stats. */
-static uint32_t enable_stats = 0;
-/* Enable retries on RX. */
-static uint32_t enable_retry = 1;
-
-/* Disable TX checksum offload */
-static uint32_t enable_tx_csum;
-
-/* Disable TSO offload */
-static uint32_t enable_tso;
-
-static int client_mode;
-static int dequeue_zero_copy;
-
-static int builtin_net_driver;
-
-/* Specify timeout (in useconds) between retries on RX. */
-static uint32_t burst_rx_delay_time = BURST_RX_WAIT_US;
-/* Specify the number of retries on RX. */
-static uint32_t burst_rx_retry_num = BURST_RX_RETRIES;
-
-/* Socket file paths. Can be set by user */
-static char *socket_files;
-static int nb_sockets;
-
-/* empty vmdq configuration structure. Filled in programatically */
-static struct rte_eth_conf vmdq_conf_default = {
-	.rxmode = {
-		.mq_mode        = ETH_MQ_RX_VMDQ_ONLY,
-		.split_hdr_size = 0,
-		.ignore_offload_bitfield = 1,
-		/*
-		 * VLAN strip is necessary for 1G NIC such as I350,
-		 * this fixes bug of ipv4 forwarding in guest can't
-		 * forward pakets from one virtio dev to another virtio dev.
-		 */
-		.offloads = (DEV_RX_OFFLOAD_CRC_STRIP |
-			     DEV_RX_OFFLOAD_VLAN_STRIP),
-	},
-
-	.txmode = {
-		.mq_mode = ETH_MQ_TX_NONE,
-		.offloads = (DEV_TX_OFFLOAD_IPV4_CKSUM |
-			     DEV_TX_OFFLOAD_TCP_CKSUM |
-			     DEV_TX_OFFLOAD_VLAN_INSERT |
-			     DEV_TX_OFFLOAD_MULTI_SEGS |
-			     DEV_TX_OFFLOAD_TCP_TSO),
-	},
-	.rx_adv_conf = {
-		/*
-		 * should be overridden separately in code with
-		 * appropriate values
-		 */
-		.vmdq_rx_conf = {
-			.nb_queue_pools = ETH_8_POOLS,
-			.enable_default_pool = 0,
-			.default_pool = 0,
-			.nb_pool_maps = 0,
-			.pool_map = {{0, 0},},
-		},
-	},
-};
-
-
-static unsigned lcore_ids[RTE_MAX_LCORE];
-static uint16_t ports[RTE_MAX_ETHPORTS];
-static unsigned num_ports = 0; /**< The number of ports specified in command line */
-static uint16_t num_pf_queues, num_vmdq_queues;
-static uint16_t vmdq_pool_base, vmdq_queue_base;
-static uint16_t queues_per_pool;
-
-const uint16_t vlan_tags[] = {
-	1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007,
-	1008, 1009, 1010, 1011,	1012, 1013, 1014, 1015,
-	1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023,
-	1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031,
-	1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039,
-	1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047,
-	1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055,
-	1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063,
-};
-
-/* ethernet addresses of ports */
-static struct ether_addr vmdq_ports_eth_addr[RTE_MAX_ETHPORTS];
-
-static struct vhost_dev_tailq_list vhost_dev_list =
-	TAILQ_HEAD_INITIALIZER(vhost_dev_list);
-
-static struct lcore_info lcore_info[RTE_MAX_LCORE];
-
-/* Used for queueing bursts of TX packets. */
-struct mbuf_table {
-	unsigned len;
-	unsigned txq_id;
-	struct rte_mbuf *m_table[MAX_PKT_BURST];
-};
-
-/* TX queue for each data core. */
-struct mbuf_table lcore_tx_queue[RTE_MAX_LCORE];
-
-#define MBUF_TABLE_DRAIN_TSC	((rte_get_tsc_hz() + US_PER_S - 1) \
-				 / US_PER_S * BURST_TX_DRAIN_US)
-#define VLAN_HLEN       4
-
-/*
- * Builds up the correct configuration for VMDQ VLAN pool map
- * according to the pool & queue limits.
- */
-static inline int
-get_eth_conf(struct rte_eth_conf *eth_conf, uint32_t num_devices)
-{
-	struct rte_eth_vmdq_rx_conf conf;
-	struct rte_eth_vmdq_rx_conf *def_conf =
-		&vmdq_conf_default.rx_adv_conf.vmdq_rx_conf;
-	unsigned i;
-
-	memset(&conf, 0, sizeof(conf));
-	conf.nb_queue_pools = (enum rte_eth_nb_pools)num_devices;
-	conf.nb_pool_maps = num_devices;
-	conf.enable_loop_back = def_conf->enable_loop_back;
-	conf.rx_mode = def_conf->rx_mode;
-
-	for (i = 0; i < conf.nb_pool_maps; i++) {
-		conf.pool_map[i].vlan_id = vlan_tags[ i ];
-		conf.pool_map[i].pools = (1UL << i);
-	}
-
-	(void)(rte_memcpy(eth_conf, &vmdq_conf_default, sizeof(*eth_conf)));
-	(void)(rte_memcpy(&eth_conf->rx_adv_conf.vmdq_rx_conf, &conf,
-		   sizeof(eth_conf->rx_adv_conf.vmdq_rx_conf)));
-	return 0;
-}
-
-/*
- * Validate the device number according to the max pool number gotten form
- * dev_info. If the device number is invalid, give the error message and
- * return -1. Each device must have its own pool.
- */
-static inline int
-validate_num_devices(uint32_t max_nb_devices)
-{
-	if (num_devices > max_nb_devices) {
-		RTE_LOG(ERR, VHOST_PORT, "invalid number of devices\n");
-		return -1;
-	}
-	return 0;
-}
-
-/*
- * Initialises a given port using global settings and with the rx buffers
- * coming from the mbuf_pool passed as parameter
- */
-static inline int
-port_init(uint16_t port)
-{
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_conf port_conf;
-	struct rte_eth_rxconf *rxconf;
-	struct rte_eth_txconf *txconf;
-	int16_t rx_rings, tx_rings;
-	uint16_t rx_ring_size, tx_ring_size;
-	int retval;
-	uint16_t q;
-
-	/* The max pool number from dev_info will be used to validate the pool number specified in cmd line */
-	rte_eth_dev_info_get (port, &dev_info);
-
-	rxconf = &dev_info.default_rxconf;
-	txconf = &dev_info.default_txconf;
-	rxconf->rx_drop_en = 1;
-	txconf->txq_flags = ETH_TXQ_FLAGS_IGNORE;
-
-	/*configure the number of supported virtio devices based on VMDQ limits */
-	num_devices = dev_info.max_vmdq_pools;
-
-	rx_ring_size = RTE_TEST_RX_DESC_DEFAULT;
-	tx_ring_size = RTE_TEST_TX_DESC_DEFAULT;
-
-	/*
-	 * When dequeue zero copy is enabled, guest Tx used vring will be
-	 * updated only when corresponding mbuf is freed. Thus, the nb_tx_desc
-	 * (tx_ring_size here) must be small enough so that the driver will
-	 * hit the free threshold easily and free mbufs timely. Otherwise,
-	 * guest Tx vring would be starved.
-	 */
-	if (dequeue_zero_copy)
-		tx_ring_size = 64;
-
-	tx_rings = (uint16_t)rte_lcore_count();
-
-	retval = validate_num_devices(MAX_DEVICES);
-	if (retval < 0)
-		return retval;
-
-	/* Get port configuration. */
-	retval = get_eth_conf(&port_conf, num_devices);
-	if (retval < 0)
-		return retval;
-	/* NIC queues are divided into pf queues and vmdq queues.  */
-	num_pf_queues = dev_info.max_rx_queues - dev_info.vmdq_queue_num;
-	queues_per_pool = dev_info.vmdq_queue_num / dev_info.max_vmdq_pools;
-	num_vmdq_queues = num_devices * queues_per_pool;
-	num_queues = num_pf_queues + num_vmdq_queues;
-	vmdq_queue_base = dev_info.vmdq_queue_base;
-	vmdq_pool_base  = dev_info.vmdq_pool_base;
-	printf("pf queue num: %u, configured vmdq pool num: %u, each vmdq pool has %u queues\n",
-		num_pf_queues, num_devices, queues_per_pool);
-
-	if (!rte_eth_dev_is_valid_port(port))
-		return -1;
-
-	rx_rings = (uint16_t)dev_info.max_rx_queues;
-	if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-		port_conf.txmode.offloads |=
-			DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-	/* Configure ethernet device. */
-	retval = rte_eth_dev_configure(port, rx_rings, tx_rings, &port_conf);
-	if (retval != 0) {
-		RTE_LOG(ERR, VHOST_PORT, "Failed to configure port %u: %s.\n",
-			port, strerror(-retval));
-		return retval;
-	}
-
-	retval = rte_eth_dev_adjust_nb_rx_tx_desc(port, &rx_ring_size,
-		&tx_ring_size);
-	if (retval != 0) {
-		RTE_LOG(ERR, VHOST_PORT, "Failed to adjust number of descriptors "
-			"for port %u: %s.\n", port, strerror(-retval));
-		return retval;
-	}
-	if (rx_ring_size > RTE_TEST_RX_DESC_DEFAULT) {
-		RTE_LOG(ERR, VHOST_PORT, "Mbuf pool has an insufficient size "
-			"for Rx queues on port %u.\n", port);
-		return -1;
-	}
-
-	/* Setup the queues. */
-	rxconf->offloads = port_conf.rxmode.offloads;
-	for (q = 0; q < rx_rings; q ++) {
-		retval = rte_eth_rx_queue_setup(port, q, rx_ring_size,
-						rte_eth_dev_socket_id(port),
-						rxconf,
-						mbuf_pool);
-		if (retval < 0) {
-			RTE_LOG(ERR, VHOST_PORT,
-				"Failed to setup rx queue %u of port %u: %s.\n",
-				q, port, strerror(-retval));
-			return retval;
-		}
-	}
-	txconf->offloads = port_conf.txmode.offloads;
-	for (q = 0; q < tx_rings; q ++) {
-		retval = rte_eth_tx_queue_setup(port, q, tx_ring_size,
-						rte_eth_dev_socket_id(port),
-						txconf);
-		if (retval < 0) {
-			RTE_LOG(ERR, VHOST_PORT,
-				"Failed to setup tx queue %u of port %u: %s.\n",
-				q, port, strerror(-retval));
-			return retval;
-		}
-	}
-
-	/* Start the device. */
-	retval  = rte_eth_dev_start(port);
-	if (retval < 0) {
-		RTE_LOG(ERR, VHOST_PORT, "Failed to start port %u: %s\n",
-			port, strerror(-retval));
-		return retval;
-	}
-
-	if (promiscuous)
-		rte_eth_promiscuous_enable(port);
-
-	rte_eth_macaddr_get(port, &vmdq_ports_eth_addr[port]);
-	RTE_LOG(INFO, VHOST_PORT, "Max virtio devices supported: %u\n", num_devices);
-	RTE_LOG(INFO, VHOST_PORT, "Port %u MAC: %02"PRIx8" %02"PRIx8" %02"PRIx8
-			" %02"PRIx8" %02"PRIx8" %02"PRIx8"\n",
-			port,
-			vmdq_ports_eth_addr[port].addr_bytes[0],
-			vmdq_ports_eth_addr[port].addr_bytes[1],
-			vmdq_ports_eth_addr[port].addr_bytes[2],
-			vmdq_ports_eth_addr[port].addr_bytes[3],
-			vmdq_ports_eth_addr[port].addr_bytes[4],
-			vmdq_ports_eth_addr[port].addr_bytes[5]);
-
-	return 0;
-}
-
-/*
- * Set socket file path.
- */
-static int
-us_vhost_parse_socket_path(const char *q_arg)
-{
-	/* parse number string */
-	if (strnlen(q_arg, PATH_MAX) == PATH_MAX)
-		return -1;
-
-	socket_files = realloc(socket_files, PATH_MAX * (nb_sockets + 1));
-	snprintf(socket_files + nb_sockets * PATH_MAX, PATH_MAX, "%s", q_arg);
-	nb_sockets++;
-
-	return 0;
-}
-
-/*
- * Parse the portmask provided at run time.
- */
-static int
-parse_portmask(const char *portmask)
-{
-	char *end = NULL;
-	unsigned long pm;
-
-	errno = 0;
-
-	/* parse hexadecimal string */
-	pm = strtoul(portmask, &end, 16);
-	if ((portmask[0] == '\0') || (end == NULL) || (*end != '\0') || (errno != 0))
-		return -1;
-
-	if (pm == 0)
-		return -1;
-
-	return pm;
-
-}
-
-/*
- * Parse num options at run time.
- */
-static int
-parse_num_opt(const char *q_arg, uint32_t max_valid_value)
-{
-	char *end = NULL;
-	unsigned long num;
-
-	errno = 0;
-
-	/* parse unsigned int string */
-	num = strtoul(q_arg, &end, 10);
-	if ((q_arg[0] == '\0') || (end == NULL) || (*end != '\0') || (errno != 0))
-		return -1;
-
-	if (num > max_valid_value)
-		return -1;
-
-	return num;
-
-}
-
-/*
- * Display usage
- */
-static void
-us_vhost_usage(const char *prgname)
-{
-	RTE_LOG(INFO, VHOST_CONFIG, "%s [EAL options] -- -p PORTMASK\n"
-	"		--vm2vm [0|1|2]\n"
-	"		--rx_retry [0|1] --mergeable [0|1] --stats [0-N]\n"
-	"		--socket-file <path>\n"
-	"		--nb-devices ND\n"
-	"		-p PORTMASK: Set mask for ports to be used by application\n"
-	"		--vm2vm [0|1|2]: disable/software(default)/hardware vm2vm comms\n"
-	"		--rx-retry [0|1]: disable/enable(default) retries on rx. Enable retry if destintation queue is full\n"
-	"		--rx-retry-delay [0-N]: timeout(in usecond) between retries on RX. This makes effect only if retries on rx enabled\n"
-	"		--rx-retry-num [0-N]: the number of retries on rx. This makes effect only if retries on rx enabled\n"
-	"		--mergeable [0|1]: disable(default)/enable RX mergeable buffers\n"
-	"		--stats [0-N]: 0: Disable stats, N: Time in seconds to print stats\n"
-	"		--socket-file: The path of the socket file.\n"
-	"		--tx-csum [0|1] disable/enable TX checksum offload.\n"
-	"		--tso [0|1] disable/enable TCP segment offload.\n"
-	"		--client register a vhost-user socket as client mode.\n"
-	"		--dequeue-zero-copy enables dequeue zero copy\n",
-	       prgname);
-}
-
-/*
- * Parse the arguments given in the command line of the application.
- */
-static int
-us_vhost_parse_args(int argc, char **argv)
-{
-	int opt, ret;
-	int option_index;
-	unsigned i;
-	const char *prgname = argv[0];
-	static struct option long_option[] = {
-		{"vm2vm", required_argument, NULL, 0},
-		{"rx-retry", required_argument, NULL, 0},
-		{"rx-retry-delay", required_argument, NULL, 0},
-		{"rx-retry-num", required_argument, NULL, 0},
-		{"mergeable", required_argument, NULL, 0},
-		{"stats", required_argument, NULL, 0},
-		{"socket-file", required_argument, NULL, 0},
-		{"tx-csum", required_argument, NULL, 0},
-		{"tso", required_argument, NULL, 0},
-		{"client", no_argument, &client_mode, 1},
-		{"dequeue-zero-copy", no_argument, &dequeue_zero_copy, 1},
-		{"builtin-net-driver", no_argument, &builtin_net_driver, 1},
-		{NULL, 0, 0, 0},
-	};
-
-	/* Parse command line */
-	while ((opt = getopt_long(argc, argv, "p:P",
-			long_option, &option_index)) != EOF) {
-		switch (opt) {
-		/* Portmask */
-		case 'p':
-			enabled_port_mask = parse_portmask(optarg);
-			if (enabled_port_mask == 0) {
-				RTE_LOG(INFO, VHOST_CONFIG, "Invalid portmask\n");
-				us_vhost_usage(prgname);
-				return -1;
-			}
-			break;
-
-		case 'P':
-			promiscuous = 1;
-			vmdq_conf_default.rx_adv_conf.vmdq_rx_conf.rx_mode =
-				ETH_VMDQ_ACCEPT_BROADCAST |
-				ETH_VMDQ_ACCEPT_MULTICAST;
-
-			break;
-
-		case 0:
-			/* Enable/disable vm2vm comms. */
-			if (!strncmp(long_option[option_index].name, "vm2vm",
-				MAX_LONG_OPT_SZ)) {
-				ret = parse_num_opt(optarg, (VM2VM_LAST - 1));
-				if (ret == -1) {
-					RTE_LOG(INFO, VHOST_CONFIG,
-						"Invalid argument for "
-						"vm2vm [0|1|2]\n");
-					us_vhost_usage(prgname);
-					return -1;
-				} else {
-					vm2vm_mode = (vm2vm_type)ret;
-				}
-			}
-
-			/* Enable/disable retries on RX. */
-			if (!strncmp(long_option[option_index].name, "rx-retry", MAX_LONG_OPT_SZ)) {
-				ret = parse_num_opt(optarg, 1);
-				if (ret == -1) {
-					RTE_LOG(INFO, VHOST_CONFIG, "Invalid argument for rx-retry [0|1]\n");
-					us_vhost_usage(prgname);
-					return -1;
-				} else {
-					enable_retry = ret;
-				}
-			}
-
-			/* Enable/disable TX checksum offload. */
-			if (!strncmp(long_option[option_index].name, "tx-csum", MAX_LONG_OPT_SZ)) {
-				ret = parse_num_opt(optarg, 1);
-				if (ret == -1) {
-					RTE_LOG(INFO, VHOST_CONFIG, "Invalid argument for tx-csum [0|1]\n");
-					us_vhost_usage(prgname);
-					return -1;
-				} else
-					enable_tx_csum = ret;
-			}
-
-			/* Enable/disable TSO offload. */
-			if (!strncmp(long_option[option_index].name, "tso", MAX_LONG_OPT_SZ)) {
-				ret = parse_num_opt(optarg, 1);
-				if (ret == -1) {
-					RTE_LOG(INFO, VHOST_CONFIG, "Invalid argument for tso [0|1]\n");
-					us_vhost_usage(prgname);
-					return -1;
-				} else
-					enable_tso = ret;
-			}
-
-			/* Specify the retries delay time (in useconds) on RX. */
-			if (!strncmp(long_option[option_index].name, "rx-retry-delay", MAX_LONG_OPT_SZ)) {
-				ret = parse_num_opt(optarg, INT32_MAX);
-				if (ret == -1) {
-					RTE_LOG(INFO, VHOST_CONFIG, "Invalid argument for rx-retry-delay [0-N]\n");
-					us_vhost_usage(prgname);
-					return -1;
-				} else {
-					burst_rx_delay_time = ret;
-				}
-			}
-
-			/* Specify the retries number on RX. */
-			if (!strncmp(long_option[option_index].name, "rx-retry-num", MAX_LONG_OPT_SZ)) {
-				ret = parse_num_opt(optarg, INT32_MAX);
-				if (ret == -1) {
-					RTE_LOG(INFO, VHOST_CONFIG, "Invalid argument for rx-retry-num [0-N]\n");
-					us_vhost_usage(prgname);
-					return -1;
-				} else {
-					burst_rx_retry_num = ret;
-				}
-			}
-
-			/* Enable/disable RX mergeable buffers. */
-			if (!strncmp(long_option[option_index].name, "mergeable", MAX_LONG_OPT_SZ)) {
-				ret = parse_num_opt(optarg, 1);
-				if (ret == -1) {
-					RTE_LOG(INFO, VHOST_CONFIG, "Invalid argument for mergeable [0|1]\n");
-					us_vhost_usage(prgname);
-					return -1;
-				} else {
-					mergeable = !!ret;
-					if (ret) {
-						vmdq_conf_default.rxmode.offloads |=
-							DEV_RX_OFFLOAD_JUMBO_FRAME;
-						vmdq_conf_default.rxmode.max_rx_pkt_len
-							= JUMBO_FRAME_MAX_SIZE;
-					}
-				}
-			}
-
-			/* Enable/disable stats. */
-			if (!strncmp(long_option[option_index].name, "stats", MAX_LONG_OPT_SZ)) {
-				ret = parse_num_opt(optarg, INT32_MAX);
-				if (ret == -1) {
-					RTE_LOG(INFO, VHOST_CONFIG,
-						"Invalid argument for stats [0..N]\n");
-					us_vhost_usage(prgname);
-					return -1;
-				} else {
-					enable_stats = ret;
-				}
-			}
-
-			/* Set socket file path. */
-			if (!strncmp(long_option[option_index].name,
-						"socket-file", MAX_LONG_OPT_SZ)) {
-				if (us_vhost_parse_socket_path(optarg) == -1) {
-					RTE_LOG(INFO, VHOST_CONFIG,
-					"Invalid argument for socket name (Max %d characters)\n",
-					PATH_MAX);
-					us_vhost_usage(prgname);
-					return -1;
-				}
-			}
-
-			break;
-
-			/* Invalid option - print options. */
-		default:
-			us_vhost_usage(prgname);
-			return -1;
-		}
-	}
-
-	for (i = 0; i < RTE_MAX_ETHPORTS; i++) {
-		if (enabled_port_mask & (1 << i))
-			ports[num_ports++] = i;
-	}
-
-	if ((num_ports ==  0) || (num_ports > MAX_SUP_PORTS)) {
-		RTE_LOG(INFO, VHOST_PORT, "Current enabled port number is %u,"
-			"but only %u port can be enabled\n",num_ports, MAX_SUP_PORTS);
-		return -1;
-	}
-
-	return 0;
-}
-
-/*
- * Update the global var NUM_PORTS and array PORTS according to system ports number
- * and return valid ports number
- */
-static unsigned check_ports_num(unsigned nb_ports)
-{
-	unsigned valid_num_ports = num_ports;
-	unsigned portid;
-
-	if (num_ports > nb_ports) {
-		RTE_LOG(INFO, VHOST_PORT, "\nSpecified port number(%u) exceeds total system port number(%u)\n",
-			num_ports, nb_ports);
-		num_ports = nb_ports;
-	}
-
-	for (portid = 0; portid < num_ports; portid ++) {
-		if (!rte_eth_dev_is_valid_port(ports[portid])) {
-			RTE_LOG(INFO, VHOST_PORT,
-				"\nSpecified port ID(%u) is not valid\n",
-				ports[portid]);
-			ports[portid] = INVALID_PORT_ID;
-			valid_num_ports--;
-		}
-	}
-	return valid_num_ports;
-}
-
-static __rte_always_inline struct vhost_dev *
-find_vhost_dev(struct ether_addr *mac)
-{
-	struct vhost_dev *vdev;
-
-	TAILQ_FOREACH(vdev, &vhost_dev_list, global_vdev_entry) {
-		if (vdev->ready == DEVICE_RX &&
-		    is_same_ether_addr(mac, &vdev->mac_address))
-			return vdev;
-	}
-
-	return NULL;
-}
-
-/*
- * This function learns the MAC address of the device and registers this along with a
- * vlan tag to a VMDQ.
- */
-static int
-link_vmdq(struct vhost_dev *vdev, struct rte_mbuf *m)
-{
-	struct ether_hdr *pkt_hdr;
-	int i, ret;
-
-	/* Learn MAC address of guest device from packet */
-	pkt_hdr = rte_pktmbuf_mtod(m, struct ether_hdr *);
-
-	if (find_vhost_dev(&pkt_hdr->s_addr)) {
-		RTE_LOG(ERR, VHOST_DATA,
-			"(%d) device is using a registered MAC!\n",
-			vdev->vid);
-		return -1;
-	}
-
-	for (i = 0; i < ETHER_ADDR_LEN; i++)
-		vdev->mac_address.addr_bytes[i] = pkt_hdr->s_addr.addr_bytes[i];
-
-	/* vlan_tag currently uses the device_id. */
-	vdev->vlan_tag = vlan_tags[vdev->vid];
-
-	/* Print out VMDQ registration info. */
-	RTE_LOG(INFO, VHOST_DATA,
-		"(%d) mac %02x:%02x:%02x:%02x:%02x:%02x and vlan %d registered\n",
-		vdev->vid,
-		vdev->mac_address.addr_bytes[0], vdev->mac_address.addr_bytes[1],
-		vdev->mac_address.addr_bytes[2], vdev->mac_address.addr_bytes[3],
-		vdev->mac_address.addr_bytes[4], vdev->mac_address.addr_bytes[5],
-		vdev->vlan_tag);
-
-	/* Register the MAC address. */
-	ret = rte_eth_dev_mac_addr_add(ports[0], &vdev->mac_address,
-				(uint32_t)vdev->vid + vmdq_pool_base);
-	if (ret)
-		RTE_LOG(ERR, VHOST_DATA,
-			"(%d) failed to add device MAC address to VMDQ\n",
-			vdev->vid);
-
-	rte_eth_dev_set_vlan_strip_on_queue(ports[0], vdev->vmdq_rx_q, 1);
-
-	/* Set device as ready for RX. */
-	vdev->ready = DEVICE_RX;
-
-	return 0;
-}
-
-/*
- * Removes MAC address and vlan tag from VMDQ. Ensures that nothing is adding buffers to the RX
- * queue before disabling RX on the device.
- */
-static inline void
-unlink_vmdq(struct vhost_dev *vdev)
-{
-	unsigned i = 0;
-	unsigned rx_count;
-	struct rte_mbuf *pkts_burst[MAX_PKT_BURST];
-
-	if (vdev->ready == DEVICE_RX) {
-		/*clear MAC and VLAN settings*/
-		rte_eth_dev_mac_addr_remove(ports[0], &vdev->mac_address);
-		for (i = 0; i < 6; i++)
-			vdev->mac_address.addr_bytes[i] = 0;
-
-		vdev->vlan_tag = 0;
-
-		/*Clear out the receive buffers*/
-		rx_count = rte_eth_rx_burst(ports[0],
-					(uint16_t)vdev->vmdq_rx_q, pkts_burst, MAX_PKT_BURST);
-
-		while (rx_count) {
-			for (i = 0; i < rx_count; i++)
-				rte_pktmbuf_free(pkts_burst[i]);
-
-			rx_count = rte_eth_rx_burst(ports[0],
-					(uint16_t)vdev->vmdq_rx_q, pkts_burst, MAX_PKT_BURST);
-		}
-
-		vdev->ready = DEVICE_MAC_LEARNING;
-	}
-}
-
-static __rte_always_inline void
-virtio_xmit(struct vhost_dev *dst_vdev, struct vhost_dev *src_vdev,
-	    struct rte_mbuf *m)
-{
-	uint16_t ret;
-
-	if (builtin_net_driver) {
-		ret = vs_enqueue_pkts(dst_vdev, VIRTIO_RXQ, &m, 1);
-	} else {
-		ret = rte_vhost_enqueue_burst(dst_vdev->vid, VIRTIO_RXQ, &m, 1);
-	}
-
-	if (enable_stats) {
-		rte_atomic64_inc(&dst_vdev->stats.rx_total_atomic);
-		rte_atomic64_add(&dst_vdev->stats.rx_atomic, ret);
-		src_vdev->stats.tx_total++;
-		src_vdev->stats.tx += ret;
-	}
-}
-
-/*
- * Check if the packet destination MAC address is for a local device. If so then put
- * the packet on that devices RX queue. If not then return.
- */
-static __rte_always_inline int
-virtio_tx_local(struct vhost_dev *vdev, struct rte_mbuf *m)
-{
-	struct ether_hdr *pkt_hdr;
-	struct vhost_dev *dst_vdev;
-
-	pkt_hdr = rte_pktmbuf_mtod(m, struct ether_hdr *);
-
-	dst_vdev = find_vhost_dev(&pkt_hdr->d_addr);
-	if (!dst_vdev)
-		return -1;
-
-	if (vdev->vid == dst_vdev->vid) {
-		RTE_LOG_DP(DEBUG, VHOST_DATA,
-			"(%d) TX: src and dst MAC is same. Dropping packet.\n",
-			vdev->vid);
-		return 0;
-	}
-
-	RTE_LOG_DP(DEBUG, VHOST_DATA,
-		"(%d) TX: MAC address is local\n", dst_vdev->vid);
-
-	if (unlikely(dst_vdev->remove)) {
-		RTE_LOG_DP(DEBUG, VHOST_DATA,
-			"(%d) device is marked for removal\n", dst_vdev->vid);
-		return 0;
-	}
-
-	virtio_xmit(dst_vdev, vdev, m);
-	return 0;
-}
-
-/*
- * Check if the destination MAC of a packet is one local VM,
- * and get its vlan tag, and offset if it is.
- */
-static __rte_always_inline int
-find_local_dest(struct vhost_dev *vdev, struct rte_mbuf *m,
-	uint32_t *offset, uint16_t *vlan_tag)
-{
-	struct vhost_dev *dst_vdev;
-	struct ether_hdr *pkt_hdr = rte_pktmbuf_mtod(m, struct ether_hdr *);
-
-	dst_vdev = find_vhost_dev(&pkt_hdr->d_addr);
-	if (!dst_vdev)
-		return 0;
-
-	if (vdev->vid == dst_vdev->vid) {
-		RTE_LOG_DP(DEBUG, VHOST_DATA,
-			"(%d) TX: src and dst MAC is same. Dropping packet.\n",
-			vdev->vid);
-		return -1;
-	}
-
-	/*
-	 * HW vlan strip will reduce the packet length
-	 * by minus length of vlan tag, so need restore
-	 * the packet length by plus it.
-	 */
-	*offset  = VLAN_HLEN;
-	*vlan_tag = vlan_tags[vdev->vid];
-
-	RTE_LOG_DP(DEBUG, VHOST_DATA,
-		"(%d) TX: pkt to local VM device id: (%d), vlan tag: %u.\n",
-		vdev->vid, dst_vdev->vid, *vlan_tag);
-
-	return 0;
-}
-
-static uint16_t
-get_psd_sum(void *l3_hdr, uint64_t ol_flags)
-{
-	if (ol_flags & PKT_TX_IPV4)
-		return rte_ipv4_phdr_cksum(l3_hdr, ol_flags);
-	else /* assume ethertype == ETHER_TYPE_IPv6 */
-		return rte_ipv6_phdr_cksum(l3_hdr, ol_flags);
-}
-
-static void virtio_tx_offload(struct rte_mbuf *m)
-{
-	void *l3_hdr;
-	struct ipv4_hdr *ipv4_hdr = NULL;
-	struct tcp_hdr *tcp_hdr = NULL;
-	struct ether_hdr *eth_hdr = rte_pktmbuf_mtod(m, struct ether_hdr *);
-
-	l3_hdr = (char *)eth_hdr + m->l2_len;
-
-	if (m->ol_flags & PKT_TX_IPV4) {
-		ipv4_hdr = l3_hdr;
-		ipv4_hdr->hdr_checksum = 0;
-		m->ol_flags |= PKT_TX_IP_CKSUM;
-	}
-
-	tcp_hdr = (struct tcp_hdr *)((char *)l3_hdr + m->l3_len);
-	tcp_hdr->cksum = get_psd_sum(l3_hdr, m->ol_flags);
-}
-
-static inline void
-free_pkts(struct rte_mbuf **pkts, uint16_t n)
-{
-	while (n--)
-		rte_pktmbuf_free(pkts[n]);
-}
-
-static __rte_always_inline void
-do_drain_mbuf_table(struct mbuf_table *tx_q)
-{
-	uint16_t count;
-
-	count = rte_eth_tx_burst(ports[0], tx_q->txq_id,
-				 tx_q->m_table, tx_q->len);
-	if (unlikely(count < tx_q->len))
-		free_pkts(&tx_q->m_table[count], tx_q->len - count);
-
-	tx_q->len = 0;
-}
-
-/*
- * This function routes the TX packet to the correct interface. This
- * may be a local device or the physical port.
- */
-static __rte_always_inline void
-virtio_tx_route(struct vhost_dev *vdev, struct rte_mbuf *m, uint16_t vlan_tag)
-{
-	struct mbuf_table *tx_q;
-	unsigned offset = 0;
-	const uint16_t lcore_id = rte_lcore_id();
-	struct ether_hdr *nh;
-
-
-	nh = rte_pktmbuf_mtod(m, struct ether_hdr *);
-	if (unlikely(is_broadcast_ether_addr(&nh->d_addr))) {
-		struct vhost_dev *vdev2;
-
-		TAILQ_FOREACH(vdev2, &vhost_dev_list, global_vdev_entry) {
-			if (vdev2 != vdev)
-				virtio_xmit(vdev2, vdev, m);
-		}
-		goto queue2nic;
-	}
-
-	/*check if destination is local VM*/
-	if ((vm2vm_mode == VM2VM_SOFTWARE) && (virtio_tx_local(vdev, m) == 0)) {
-		rte_pktmbuf_free(m);
-		return;
-	}
-
-	if (unlikely(vm2vm_mode == VM2VM_HARDWARE)) {
-		if (unlikely(find_local_dest(vdev, m, &offset,
-					     &vlan_tag) != 0)) {
-			rte_pktmbuf_free(m);
-			return;
-		}
-	}
-
-	RTE_LOG_DP(DEBUG, VHOST_DATA,
-		"(%d) TX: MAC address is external\n", vdev->vid);
-
-queue2nic:
-
-	/*Add packet to the port tx queue*/
-	tx_q = &lcore_tx_queue[lcore_id];
-
-	nh = rte_pktmbuf_mtod(m, struct ether_hdr *);
-	if (unlikely(nh->ether_type == rte_cpu_to_be_16(ETHER_TYPE_VLAN))) {
-		/* Guest has inserted the vlan tag. */
-		struct vlan_hdr *vh = (struct vlan_hdr *) (nh + 1);
-		uint16_t vlan_tag_be = rte_cpu_to_be_16(vlan_tag);
-		if ((vm2vm_mode == VM2VM_HARDWARE) &&
-			(vh->vlan_tci != vlan_tag_be))
-			vh->vlan_tci = vlan_tag_be;
-	} else {
-		m->ol_flags |= PKT_TX_VLAN_PKT;
-
-		/*
-		 * Find the right seg to adjust the data len when offset is
-		 * bigger than tail room size.
-		 */
-		if (unlikely(vm2vm_mode == VM2VM_HARDWARE)) {
-			if (likely(offset <= rte_pktmbuf_tailroom(m)))
-				m->data_len += offset;
-			else {
-				struct rte_mbuf *seg = m;
-
-				while ((seg->next != NULL) &&
-					(offset > rte_pktmbuf_tailroom(seg)))
-					seg = seg->next;
-
-				seg->data_len += offset;
-			}
-			m->pkt_len += offset;
-		}
-
-		m->vlan_tci = vlan_tag;
-	}
-
-	if (m->ol_flags & PKT_TX_TCP_SEG)
-		virtio_tx_offload(m);
-
-	tx_q->m_table[tx_q->len++] = m;
-	if (enable_stats) {
-		vdev->stats.tx_total++;
-		vdev->stats.tx++;
-	}
-
-	if (unlikely(tx_q->len == MAX_PKT_BURST))
-		do_drain_mbuf_table(tx_q);
-}
-
-
-static __rte_always_inline void
-drain_mbuf_table(struct mbuf_table *tx_q)
-{
-	static uint64_t prev_tsc;
-	uint64_t cur_tsc;
-
-	if (tx_q->len == 0)
-		return;
-
-	cur_tsc = rte_rdtsc();
-	if (unlikely(cur_tsc - prev_tsc > MBUF_TABLE_DRAIN_TSC)) {
-		prev_tsc = cur_tsc;
-
-		RTE_LOG_DP(DEBUG, VHOST_DATA,
-			"TX queue drained after timeout with burst size %u\n",
-			tx_q->len);
-		do_drain_mbuf_table(tx_q);
-	}
-}
-
-static __rte_always_inline void
-drain_eth_rx(struct vhost_dev *vdev)
-{
-	uint16_t rx_count, enqueue_count;
-	struct rte_mbuf *pkts[MAX_PKT_BURST];
-
-	rx_count = rte_eth_rx_burst(ports[0], vdev->vmdq_rx_q,
-				    pkts, MAX_PKT_BURST);
-	if (!rx_count)
-		return;
-
-	/*
-	 * When "enable_retry" is set, here we wait and retry when there
-	 * is no enough free slots in the queue to hold @rx_count packets,
-	 * to diminish packet loss.
-	 */
-	if (enable_retry &&
-	    unlikely(rx_count > rte_vhost_avail_entries(vdev->vid,
-			VIRTIO_RXQ))) {
-		uint32_t retry;
-
-		for (retry = 0; retry < burst_rx_retry_num; retry++) {
-			rte_delay_us(burst_rx_delay_time);
-			if (rx_count <= rte_vhost_avail_entries(vdev->vid,
-					VIRTIO_RXQ))
-				break;
-		}
-	}
-
-	if (builtin_net_driver) {
-		enqueue_count = vs_enqueue_pkts(vdev, VIRTIO_RXQ,
-						pkts, rx_count);
-	} else {
-		enqueue_count = rte_vhost_enqueue_burst(vdev->vid, VIRTIO_RXQ,
-						pkts, rx_count);
-	}
-	if (enable_stats) {
-		rte_atomic64_add(&vdev->stats.rx_total_atomic, rx_count);
-		rte_atomic64_add(&vdev->stats.rx_atomic, enqueue_count);
-	}
-
-	free_pkts(pkts, rx_count);
-}
-
-static __rte_always_inline void
-drain_virtio_tx(struct vhost_dev *vdev)
-{
-	struct rte_mbuf *pkts[MAX_PKT_BURST];
-	uint16_t count;
-	uint16_t i;
-
-	if (builtin_net_driver) {
-		count = vs_dequeue_pkts(vdev, VIRTIO_TXQ, mbuf_pool,
-					pkts, MAX_PKT_BURST);
-	} else {
-		count = rte_vhost_dequeue_burst(vdev->vid, VIRTIO_TXQ,
-					mbuf_pool, pkts, MAX_PKT_BURST);
-	}
-
-	/* setup VMDq for the first packet */
-	if (unlikely(vdev->ready == DEVICE_MAC_LEARNING) && count) {
-		if (vdev->remove || link_vmdq(vdev, pkts[0]) == -1)
-			free_pkts(pkts, count);
-	}
-
-	for (i = 0; i < count; ++i)
-		virtio_tx_route(vdev, pkts[i], vlan_tags[vdev->vid]);
-}
-
-/*
- * Main function of vhost-switch. It basically does:
- *
- * for each vhost device {
- *    - drain_eth_rx()
- *
- *      Which drains the host eth Rx queue linked to the vhost device,
- *      and deliver all of them to guest virito Rx ring associated with
- *      this vhost device.
- *
- *    - drain_virtio_tx()
- *
- *      Which drains the guest virtio Tx queue and deliver all of them
- *      to the target, which could be another vhost device, or the
- *      physical eth dev. The route is done in function "virtio_tx_route".
- * }
- */
-static int
-switch_worker(void *arg __rte_unused)
-{
-	unsigned i;
-	unsigned lcore_id = rte_lcore_id();
-	struct vhost_dev *vdev;
-	struct mbuf_table *tx_q;
-
-	RTE_LOG(INFO, VHOST_DATA, "Procesing on Core %u started\n", lcore_id);
-
-	tx_q = &lcore_tx_queue[lcore_id];
-	for (i = 0; i < rte_lcore_count(); i++) {
-		if (lcore_ids[i] == lcore_id) {
-			tx_q->txq_id = i;
-			break;
-		}
-	}
-
-	while(1) {
-		drain_mbuf_table(tx_q);
-
-		/*
-		 * Inform the configuration core that we have exited the
-		 * linked list and that no devices are in use if requested.
-		 */
-		if (lcore_info[lcore_id].dev_removal_flag == REQUEST_DEV_REMOVAL)
-			lcore_info[lcore_id].dev_removal_flag = ACK_DEV_REMOVAL;
-
-		/*
-		 * Process vhost devices
-		 */
-		TAILQ_FOREACH(vdev, &lcore_info[lcore_id].vdev_list,
-			      lcore_vdev_entry) {
-			if (unlikely(vdev->remove)) {
-				unlink_vmdq(vdev);
-				vdev->ready = DEVICE_SAFE_REMOVE;
-				continue;
-			}
-
-			if (likely(vdev->ready == DEVICE_RX))
-				drain_eth_rx(vdev);
-
-			if (likely(!vdev->remove))
-				drain_virtio_tx(vdev);
-		}
-	}
-
-	return 0;
-}
-
-/*
- * Remove a device from the specific data core linked list and from the
- * main linked list. Synchonization  occurs through the use of the
- * lcore dev_removal_flag. Device is made volatile here to avoid re-ordering
- * of dev->remove=1 which can cause an infinite loop in the rte_pause loop.
- */
-static void
-destroy_device(int vid)
-{
-	struct vhost_dev *vdev = NULL;
-	int lcore;
-
-	TAILQ_FOREACH(vdev, &vhost_dev_list, global_vdev_entry) {
-		if (vdev->vid == vid)
-			break;
-	}
-	if (!vdev)
-		return;
-	/*set the remove flag. */
-	vdev->remove = 1;
-	while(vdev->ready != DEVICE_SAFE_REMOVE) {
-		rte_pause();
-	}
-
-	if (builtin_net_driver)
-		vs_vhost_net_remove(vdev);
-
-	TAILQ_REMOVE(&lcore_info[vdev->coreid].vdev_list, vdev,
-		     lcore_vdev_entry);
-	TAILQ_REMOVE(&vhost_dev_list, vdev, global_vdev_entry);
-
-
-	/* Set the dev_removal_flag on each lcore. */
-	RTE_LCORE_FOREACH_SLAVE(lcore)
-		lcore_info[lcore].dev_removal_flag = REQUEST_DEV_REMOVAL;
-
-	/*
-	 * Once each core has set the dev_removal_flag to ACK_DEV_REMOVAL
-	 * we can be sure that they can no longer access the device removed
-	 * from the linked lists and that the devices are no longer in use.
-	 */
-	RTE_LCORE_FOREACH_SLAVE(lcore) {
-		while (lcore_info[lcore].dev_removal_flag != ACK_DEV_REMOVAL)
-			rte_pause();
-	}
-
-	lcore_info[vdev->coreid].device_num--;
-
-	RTE_LOG(INFO, VHOST_DATA,
-		"(%d) device has been removed from data core\n",
-		vdev->vid);
-
-	rte_free(vdev);
-}
-
-/*
- * A new device is added to a data core. First the device is added to the main linked list
- * and the allocated to a specific data core.
- */
-static int
-new_device(int vid)
-{
-	int lcore, core_add = 0;
-	uint32_t device_num_min = num_devices;
-	struct vhost_dev *vdev;
-
-	vdev = rte_zmalloc("vhost device", sizeof(*vdev), RTE_CACHE_LINE_SIZE);
-	if (vdev == NULL) {
-		RTE_LOG(INFO, VHOST_DATA,
-			"(%d) couldn't allocate memory for vhost dev\n",
-			vid);
-		return -1;
-	}
-	vdev->vid = vid;
-
-	if (builtin_net_driver)
-		vs_vhost_net_setup(vdev);
-
-	TAILQ_INSERT_TAIL(&vhost_dev_list, vdev, global_vdev_entry);
-	vdev->vmdq_rx_q = vid * queues_per_pool + vmdq_queue_base;
-
-	/*reset ready flag*/
-	vdev->ready = DEVICE_MAC_LEARNING;
-	vdev->remove = 0;
-
-	/* Find a suitable lcore to add the device. */
-	RTE_LCORE_FOREACH_SLAVE(lcore) {
-		if (lcore_info[lcore].device_num < device_num_min) {
-			device_num_min = lcore_info[lcore].device_num;
-			core_add = lcore;
-		}
-	}
-	vdev->coreid = core_add;
-
-	TAILQ_INSERT_TAIL(&lcore_info[vdev->coreid].vdev_list, vdev,
-			  lcore_vdev_entry);
-	lcore_info[vdev->coreid].device_num++;
-
-	/* Disable notifications. */
-	rte_vhost_enable_guest_notification(vid, VIRTIO_RXQ, 0);
-	rte_vhost_enable_guest_notification(vid, VIRTIO_TXQ, 0);
-
-	RTE_LOG(INFO, VHOST_DATA,
-		"(%d) device has been added to data core %d\n",
-		vid, vdev->coreid);
-
-	return 0;
-}
-
-/*
- * These callback allow devices to be added to the data core when configuration
- * has been fully complete.
- */
-static const struct vhost_device_ops virtio_net_device_ops =
-{
-	.new_device =  new_device,
-	.destroy_device = destroy_device,
-};
-
-/*
- * This is a thread will wake up after a period to print stats if the user has
- * enabled them.
- */
-static void
-print_stats(void)
-{
-	struct vhost_dev *vdev;
-	uint64_t tx_dropped, rx_dropped;
-	uint64_t tx, tx_total, rx, rx_total;
-	const char clr[] = { 27, '[', '2', 'J', '\0' };
-	const char top_left[] = { 27, '[', '1', ';', '1', 'H','\0' };
-
-	while(1) {
-		sleep(enable_stats);
-
-		/* Clear screen and move to top left */
-		printf("%s%s\n", clr, top_left);
-		printf("Device statistics =================================\n");
-
-		TAILQ_FOREACH(vdev, &vhost_dev_list, global_vdev_entry) {
-			tx_total   = vdev->stats.tx_total;
-			tx         = vdev->stats.tx;
-			tx_dropped = tx_total - tx;
-
-			rx_total   = rte_atomic64_read(&vdev->stats.rx_total_atomic);
-			rx         = rte_atomic64_read(&vdev->stats.rx_atomic);
-			rx_dropped = rx_total - rx;
-
-			printf("Statistics for device %d\n"
-				"-----------------------\n"
-				"TX total:              %" PRIu64 "\n"
-				"TX dropped:            %" PRIu64 "\n"
-				"TX successful:         %" PRIu64 "\n"
-				"RX total:              %" PRIu64 "\n"
-				"RX dropped:            %" PRIu64 "\n"
-				"RX successful:         %" PRIu64 "\n",
-				vdev->vid,
-				tx_total, tx_dropped, tx,
-				rx_total, rx_dropped, rx);
-		}
-
-		printf("===================================================\n");
-	}
-}
-
-static void
-unregister_drivers(int socket_num)
-{
-	int i, ret;
-
-	for (i = 0; i < socket_num; i++) {
-		ret = rte_vhost_driver_unregister(socket_files + i * PATH_MAX);
-		if (ret != 0)
-			RTE_LOG(ERR, VHOST_CONFIG,
-				"Fail to unregister vhost driver for %s.\n",
-				socket_files + i * PATH_MAX);
-	}
-}
-
-/* When we receive a INT signal, unregister vhost driver */
-static void
-sigint_handler(__rte_unused int signum)
-{
-	/* Unregister vhost driver. */
-	unregister_drivers(nb_sockets);
-
-	exit(0);
-}
-
-/*
- * While creating an mbuf pool, one key thing is to figure out how
- * many mbuf entries is enough for our use. FYI, here are some
- * guidelines:
- *
- * - Each rx queue would reserve @nr_rx_desc mbufs at queue setup stage
- *
- * - For each switch core (A CPU core does the packet switch), we need
- *   also make some reservation for receiving the packets from virtio
- *   Tx queue. How many is enough depends on the usage. It's normally
- *   a simple calculation like following:
- *
- *       MAX_PKT_BURST * max packet size / mbuf size
- *
- *   So, we definitely need allocate more mbufs when TSO is enabled.
- *
- * - Similarly, for each switching core, we should serve @nr_rx_desc
- *   mbufs for receiving the packets from physical NIC device.
- *
- * - We also need make sure, for each switch core, we have allocated
- *   enough mbufs to fill up the mbuf cache.
- */
-static void
-create_mbuf_pool(uint16_t nr_port, uint32_t nr_switch_core, uint32_t mbuf_size,
-	uint32_t nr_queues, uint32_t nr_rx_desc, uint32_t nr_mbuf_cache)
-{
-	uint32_t nr_mbufs;
-	uint32_t nr_mbufs_per_core;
-	uint32_t mtu = 1500;
-
-	if (mergeable)
-		mtu = 9000;
-	if (enable_tso)
-		mtu = 64 * 1024;
-
-	nr_mbufs_per_core  = (mtu + mbuf_size) * MAX_PKT_BURST /
-			(mbuf_size - RTE_PKTMBUF_HEADROOM);
-	nr_mbufs_per_core += nr_rx_desc;
-	nr_mbufs_per_core  = RTE_MAX(nr_mbufs_per_core, nr_mbuf_cache);
-
-	nr_mbufs  = nr_queues * nr_rx_desc;
-	nr_mbufs += nr_mbufs_per_core * nr_switch_core;
-	nr_mbufs *= nr_port;
-
-	mbuf_pool = rte_pktmbuf_pool_create("MBUF_POOL", nr_mbufs,
-					    nr_mbuf_cache, 0, mbuf_size,
-					    rte_socket_id());
-	if (mbuf_pool == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot create mbuf pool\n");
-}
-
-/*
- * Main function, does initialisation and calls the per-lcore functions.
- */
-int
-main(int argc, char *argv[])
-{
-	unsigned lcore_id, core_id = 0;
-	unsigned nb_ports, valid_num_ports;
-	int ret, i;
-	uint16_t portid;
-	static pthread_t tid;
-	char thread_name[RTE_MAX_THREAD_NAME_LEN];
-	uint64_t flags = 0;
-
-	signal(SIGINT, sigint_handler);
-
-	/* init EAL */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Error with EAL initialization\n");
-	argc -= ret;
-	argv += ret;
-
-	/* parse app arguments */
-	ret = us_vhost_parse_args(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid argument\n");
-
-	for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++) {
-		TAILQ_INIT(&lcore_info[lcore_id].vdev_list);
-
-		if (rte_lcore_is_enabled(lcore_id))
-			lcore_ids[core_id++] = lcore_id;
-	}
-
-	if (rte_lcore_count() > RTE_MAX_LCORE)
-		rte_exit(EXIT_FAILURE,"Not enough cores\n");
-
-	/* Get the number of physical ports. */
-	nb_ports = rte_eth_dev_count();
-
-	/*
-	 * Update the global var NUM_PORTS and global array PORTS
-	 * and get value of var VALID_NUM_PORTS according to system ports number
-	 */
-	valid_num_ports = check_ports_num(nb_ports);
-
-	if ((valid_num_ports ==  0) || (valid_num_ports > MAX_SUP_PORTS)) {
-		RTE_LOG(INFO, VHOST_PORT, "Current enabled port number is %u,"
-			"but only %u port can be enabled\n",num_ports, MAX_SUP_PORTS);
-		return -1;
-	}
-
-	/*
-	 * FIXME: here we are trying to allocate mbufs big enough for
-	 * @MAX_QUEUES, but the truth is we're never going to use that
-	 * many queues here. We probably should only do allocation for
-	 * those queues we are going to use.
-	 */
-	create_mbuf_pool(valid_num_ports, rte_lcore_count() - 1, MBUF_DATA_SIZE,
-			 MAX_QUEUES, RTE_TEST_RX_DESC_DEFAULT, MBUF_CACHE_SIZE);
-
-	if (vm2vm_mode == VM2VM_HARDWARE) {
-		/* Enable VT loop back to let L2 switch to do it. */
-		vmdq_conf_default.rx_adv_conf.vmdq_rx_conf.enable_loop_back = 1;
-		RTE_LOG(DEBUG, VHOST_CONFIG,
-			"Enable loop back for L2 switch in vmdq.\n");
-	}
-
-	/* initialize all ports */
-	RTE_ETH_FOREACH_DEV(portid) {
-		/* skip ports that are not enabled */
-		if ((enabled_port_mask & (1 << portid)) == 0) {
-			RTE_LOG(INFO, VHOST_PORT,
-				"Skipping disabled port %d\n", portid);
-			continue;
-		}
-		if (port_init(portid) != 0)
-			rte_exit(EXIT_FAILURE,
-				"Cannot initialize network ports\n");
-	}
-
-	/* Enable stats if the user option is set. */
-	if (enable_stats) {
-		ret = pthread_create(&tid, NULL, (void *)print_stats, NULL);
-		if (ret != 0)
-			rte_exit(EXIT_FAILURE,
-				"Cannot create print-stats thread\n");
-
-		/* Set thread_name for aid in debugging.  */
-		snprintf(thread_name, RTE_MAX_THREAD_NAME_LEN, "print-stats");
-		ret = rte_thread_setname(tid, thread_name);
-		if (ret != 0)
-			RTE_LOG(DEBUG, VHOST_CONFIG,
-				"Cannot set print-stats name\n");
-	}
-
-	/* Launch all data cores. */
-	RTE_LCORE_FOREACH_SLAVE(lcore_id)
-		rte_eal_remote_launch(switch_worker, NULL, lcore_id);
-
-	if (client_mode)
-		flags |= RTE_VHOST_USER_CLIENT;
-
-	if (dequeue_zero_copy)
-		flags |= RTE_VHOST_USER_DEQUEUE_ZERO_COPY;
-
-	/* Register vhost user driver to handle vhost messages. */
-	for (i = 0; i < nb_sockets; i++) {
-		char *file = socket_files + i * PATH_MAX;
-		ret = rte_vhost_driver_register(file, flags);
-		if (ret != 0) {
-			unregister_drivers(i);
-			rte_exit(EXIT_FAILURE,
-				"vhost driver register failure.\n");
-		}
-
-		if (builtin_net_driver)
-			rte_vhost_driver_set_features(file, VIRTIO_NET_FEATURES);
-
-		if (mergeable == 0) {
-			rte_vhost_driver_disable_features(file,
-				1ULL << VIRTIO_NET_F_MRG_RXBUF);
-		}
-
-		if (enable_tx_csum == 0) {
-			rte_vhost_driver_disable_features(file,
-				1ULL << VIRTIO_NET_F_CSUM);
-		}
-
-		if (enable_tso == 0) {
-			rte_vhost_driver_disable_features(file,
-				1ULL << VIRTIO_NET_F_HOST_TSO4);
-			rte_vhost_driver_disable_features(file,
-				1ULL << VIRTIO_NET_F_HOST_TSO6);
-			rte_vhost_driver_disable_features(file,
-				1ULL << VIRTIO_NET_F_GUEST_TSO4);
-			rte_vhost_driver_disable_features(file,
-				1ULL << VIRTIO_NET_F_GUEST_TSO6);
-		}
-
-		if (promiscuous) {
-			rte_vhost_driver_enable_features(file,
-				1ULL << VIRTIO_NET_F_CTRL_RX);
-		}
-
-		ret = rte_vhost_driver_callback_register(file,
-			&virtio_net_device_ops);
-		if (ret != 0) {
-			rte_exit(EXIT_FAILURE,
-				"failed to register vhost driver callbacks.\n");
-		}
-
-		if (rte_vhost_driver_start(file) < 0) {
-			rte_exit(EXIT_FAILURE,
-				"failed to start vhost driver.\n");
-		}
-	}
-
-	RTE_LCORE_FOREACH_SLAVE(lcore_id)
-		rte_eal_wait_lcore(lcore_id);
-
-	return 0;
-
-}
diff --git a/examples/vhost/main.h b/examples/vhost/main.h
deleted file mode 100644
index 764c33a..0000000
--- a/examples/vhost/main.h
+++ /dev/null
@@ -1,92 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2017 Intel Corporation
- */
-
-#ifndef _MAIN_H_
-#define _MAIN_H_
-
-#include <sys/queue.h>
-
-#include <rte_ether.h>
-
-/* Macros for printing using RTE_LOG */
-#define RTE_LOGTYPE_VHOST_CONFIG RTE_LOGTYPE_USER1
-#define RTE_LOGTYPE_VHOST_DATA   RTE_LOGTYPE_USER2
-#define RTE_LOGTYPE_VHOST_PORT   RTE_LOGTYPE_USER3
-
-enum {VIRTIO_RXQ, VIRTIO_TXQ, VIRTIO_QNUM};
-
-#define MAX_PKT_BURST 32		/* Max burst size for RX/TX */
-
-struct device_statistics {
-	uint64_t	tx;
-	uint64_t	tx_total;
-	rte_atomic64_t	rx_atomic;
-	rte_atomic64_t	rx_total_atomic;
-};
-
-struct vhost_queue {
-	struct rte_vhost_vring	vr;
-	uint16_t		last_avail_idx;
-	uint16_t		last_used_idx;
-};
-
-struct vhost_dev {
-	/**< Number of memory regions for gpa to hpa translation. */
-	uint32_t nregions_hpa;
-	/**< Device MAC address (Obtained on first TX packet). */
-	struct ether_addr mac_address;
-	/**< RX VMDQ queue number. */
-	uint16_t vmdq_rx_q;
-	/**< Vlan tag assigned to the pool */
-	uint32_t vlan_tag;
-	/**< Data core that the device is added to. */
-	uint16_t coreid;
-	/**< A device is set as ready if the MAC address has been set. */
-	volatile uint8_t ready;
-	/**< Device is marked for removal from the data core. */
-	volatile uint8_t remove;
-
-	int vid;
-	uint64_t features;
-	size_t hdr_len;
-	uint16_t nr_vrings;
-	struct rte_vhost_memory *mem;
-	struct device_statistics stats;
-	TAILQ_ENTRY(vhost_dev) global_vdev_entry;
-	TAILQ_ENTRY(vhost_dev) lcore_vdev_entry;
-
-#define MAX_QUEUE_PAIRS	4
-	struct vhost_queue queues[MAX_QUEUE_PAIRS * 2];
-} __rte_cache_aligned;
-
-TAILQ_HEAD(vhost_dev_tailq_list, vhost_dev);
-
-
-#define REQUEST_DEV_REMOVAL	1
-#define ACK_DEV_REMOVAL		0
-
-/*
- * Structure containing data core specific information.
- */
-struct lcore_info {
-	uint32_t		device_num;
-
-	/* Flag to synchronize device removal. */
-	volatile uint8_t	dev_removal_flag;
-
-	struct vhost_dev_tailq_list vdev_list;
-};
-
-/* we implement non-extra virtio net features */
-#define VIRTIO_NET_FEATURES	0
-
-void vs_vhost_net_setup(struct vhost_dev *dev);
-void vs_vhost_net_remove(struct vhost_dev *dev);
-uint16_t vs_enqueue_pkts(struct vhost_dev *dev, uint16_t queue_id,
-			 struct rte_mbuf **pkts, uint32_t count);
-
-uint16_t vs_dequeue_pkts(struct vhost_dev *dev, uint16_t queue_id,
-			 struct rte_mempool *mbuf_pool,
-			 struct rte_mbuf **pkts, uint16_t count);
-#endif /* _MAIN_H_ */
diff --git a/examples/vhost/meson.build b/examples/vhost/meson.build
deleted file mode 100644
index 64c84ee..0000000
--- a/examples/vhost/meson.build
+++ /dev/null
@@ -1,13 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-deps += 'vhost'
-allow_experimental_apis = true
-sources = files(
-	'main.c', 'virtio_net.c'
-)
diff --git a/examples/vhost/virtio_net.c b/examples/vhost/virtio_net.c
deleted file mode 100644
index 5a965a3..0000000
--- a/examples/vhost/virtio_net.c
+++ /dev/null
@@ -1,440 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2017 Intel Corporation
- */
-
-#include <stdint.h>
-#include <stdbool.h>
-#include <linux/virtio_net.h>
-
-#include <rte_mbuf.h>
-#include <rte_memcpy.h>
-#include <rte_vhost.h>
-
-#include "main.h"
-
-/*
- * A very simple vhost-user net driver implementation, without
- * any extra features being enabled, such as TSO and mrg-Rx.
- */
-
-void
-vs_vhost_net_setup(struct vhost_dev *dev)
-{
-	uint16_t i;
-	int vid = dev->vid;
-	struct vhost_queue *queue;
-
-	RTE_LOG(INFO, VHOST_CONFIG,
-		"setting builtin vhost-user net driver\n");
-
-	rte_vhost_get_negotiated_features(vid, &dev->features);
-	if (dev->features & (1 << VIRTIO_NET_F_MRG_RXBUF))
-		dev->hdr_len = sizeof(struct virtio_net_hdr_mrg_rxbuf);
-	else
-		dev->hdr_len = sizeof(struct virtio_net_hdr);
-
-	rte_vhost_get_mem_table(vid, &dev->mem);
-
-	dev->nr_vrings = rte_vhost_get_vring_num(vid);
-	for (i = 0; i < dev->nr_vrings; i++) {
-		queue = &dev->queues[i];
-
-		queue->last_used_idx  = 0;
-		queue->last_avail_idx = 0;
-		rte_vhost_get_vhost_vring(vid, i, &queue->vr);
-	}
-}
-
-void
-vs_vhost_net_remove(struct vhost_dev *dev)
-{
-	free(dev->mem);
-}
-
-static __rte_always_inline int
-enqueue_pkt(struct vhost_dev *dev, struct rte_vhost_vring *vr,
-	    struct rte_mbuf *m, uint16_t desc_idx)
-{
-	uint32_t desc_avail, desc_offset;
-	uint64_t desc_chunck_len;
-	uint32_t mbuf_avail, mbuf_offset;
-	uint32_t cpy_len;
-	struct vring_desc *desc;
-	uint64_t desc_addr, desc_gaddr;
-	struct virtio_net_hdr virtio_hdr = {0, 0, 0, 0, 0, 0};
-	/* A counter to avoid desc dead loop chain */
-	uint16_t nr_desc = 1;
-
-	desc = &vr->desc[desc_idx];
-	desc_chunck_len = desc->len;
-	desc_gaddr = desc->addr;
-	desc_addr = rte_vhost_va_from_guest_pa(
-			dev->mem, desc_gaddr, &desc_chunck_len);
-	/*
-	 * Checking of 'desc_addr' placed outside of 'unlikely' macro to avoid
-	 * performance issue with some versions of gcc (4.8.4 and 5.3.0) which
-	 * otherwise stores offset on the stack instead of in a register.
-	 */
-	if (unlikely(desc->len < dev->hdr_len) || !desc_addr)
-		return -1;
-
-	rte_prefetch0((void *)(uintptr_t)desc_addr);
-
-	/* write virtio-net header */
-	if (likely(desc_chunck_len >= dev->hdr_len)) {
-		*(struct virtio_net_hdr *)(uintptr_t)desc_addr = virtio_hdr;
-		desc_offset = dev->hdr_len;
-	} else {
-		uint64_t len;
-		uint64_t remain = dev->hdr_len;
-		uint64_t src = (uint64_t)(uintptr_t)&virtio_hdr, dst;
-		uint64_t guest_addr = desc_gaddr;
-
-		while (remain) {
-			len = remain;
-			dst = rte_vhost_va_from_guest_pa(dev->mem,
-					guest_addr, &len);
-			if (unlikely(!dst || !len))
-				return -1;
-
-			rte_memcpy((void *)(uintptr_t)dst,
-					(void *)(uintptr_t)src,
-					len);
-
-			remain -= len;
-			guest_addr += len;
-			dst += len;
-		}
-
-		desc_chunck_len = desc->len - dev->hdr_len;
-		desc_gaddr += dev->hdr_len;
-		desc_addr = rte_vhost_va_from_guest_pa(
-				dev->mem, desc_gaddr,
-				&desc_chunck_len);
-		if (unlikely(!desc_addr))
-			return -1;
-
-		desc_offset = 0;
-	}
-
-	desc_avail  = desc->len - dev->hdr_len;
-
-	mbuf_avail  = rte_pktmbuf_data_len(m);
-	mbuf_offset = 0;
-	while (mbuf_avail != 0 || m->next != NULL) {
-		/* done with current mbuf, fetch next */
-		if (mbuf_avail == 0) {
-			m = m->next;
-
-			mbuf_offset = 0;
-			mbuf_avail  = rte_pktmbuf_data_len(m);
-		}
-
-		/* done with current desc buf, fetch next */
-		if (desc_avail == 0) {
-			if ((desc->flags & VRING_DESC_F_NEXT) == 0) {
-				/* Room in vring buffer is not enough */
-				return -1;
-			}
-			if (unlikely(desc->next >= vr->size ||
-				     ++nr_desc > vr->size))
-				return -1;
-
-			desc = &vr->desc[desc->next];
-			desc_chunck_len = desc->len;
-			desc_gaddr = desc->addr;
-			desc_addr = rte_vhost_va_from_guest_pa(
-					dev->mem, desc_gaddr, &desc_chunck_len);
-			if (unlikely(!desc_addr))
-				return -1;
-
-			desc_offset = 0;
-			desc_avail  = desc->len;
-		} else if (unlikely(desc_chunck_len == 0)) {
-			desc_chunck_len = desc_avail;
-			desc_gaddr += desc_offset;
-			desc_addr = rte_vhost_va_from_guest_pa(dev->mem,
-					desc_gaddr,
-					&desc_chunck_len);
-			if (unlikely(!desc_addr))
-				return -1;
-
-			desc_offset = 0;
-		}
-
-		cpy_len = RTE_MIN(desc_chunck_len, mbuf_avail);
-		rte_memcpy((void *)((uintptr_t)(desc_addr + desc_offset)),
-			rte_pktmbuf_mtod_offset(m, void *, mbuf_offset),
-			cpy_len);
-
-		mbuf_avail  -= cpy_len;
-		mbuf_offset += cpy_len;
-		desc_avail  -= cpy_len;
-		desc_offset += cpy_len;
-		desc_chunck_len -= cpy_len;
-	}
-
-	return 0;
-}
-
-uint16_t
-vs_enqueue_pkts(struct vhost_dev *dev, uint16_t queue_id,
-		struct rte_mbuf **pkts, uint32_t count)
-{
-	struct vhost_queue *queue;
-	struct rte_vhost_vring *vr;
-	uint16_t avail_idx, free_entries, start_idx;
-	uint16_t desc_indexes[MAX_PKT_BURST];
-	uint16_t used_idx;
-	uint32_t i;
-
-	queue = &dev->queues[queue_id];
-	vr    = &queue->vr;
-
-	avail_idx = *((volatile uint16_t *)&vr->avail->idx);
-	start_idx = queue->last_used_idx;
-	free_entries = avail_idx - start_idx;
-	count = RTE_MIN(count, free_entries);
-	count = RTE_MIN(count, (uint32_t)MAX_PKT_BURST);
-	if (count == 0)
-		return 0;
-
-	/* Retrieve all of the desc indexes first to avoid caching issues. */
-	rte_prefetch0(&vr->avail->ring[start_idx & (vr->size - 1)]);
-	for (i = 0; i < count; i++) {
-		used_idx = (start_idx + i) & (vr->size - 1);
-		desc_indexes[i] = vr->avail->ring[used_idx];
-		vr->used->ring[used_idx].id = desc_indexes[i];
-		vr->used->ring[used_idx].len = pkts[i]->pkt_len +
-					       dev->hdr_len;
-	}
-
-	rte_prefetch0(&vr->desc[desc_indexes[0]]);
-	for (i = 0; i < count; i++) {
-		uint16_t desc_idx = desc_indexes[i];
-		int err;
-
-		err = enqueue_pkt(dev, vr, pkts[i], desc_idx);
-		if (unlikely(err)) {
-			used_idx = (start_idx + i) & (vr->size - 1);
-			vr->used->ring[used_idx].len = dev->hdr_len;
-		}
-
-		if (i + 1 < count)
-			rte_prefetch0(&vr->desc[desc_indexes[i+1]]);
-	}
-
-	rte_smp_wmb();
-
-	*(volatile uint16_t *)&vr->used->idx += count;
-	queue->last_used_idx += count;
-
-	rte_vhost_vring_call(dev->vid, queue_id);
-
-	return count;
-}
-
-static __rte_always_inline int
-dequeue_pkt(struct vhost_dev *dev, struct rte_vhost_vring *vr,
-	    struct rte_mbuf *m, uint16_t desc_idx,
-	    struct rte_mempool *mbuf_pool)
-{
-	struct vring_desc *desc;
-	uint64_t desc_addr, desc_gaddr;
-	uint32_t desc_avail, desc_offset;
-	uint64_t desc_chunck_len;
-	uint32_t mbuf_avail, mbuf_offset;
-	uint32_t cpy_len;
-	struct rte_mbuf *cur = m, *prev = m;
-	/* A counter to avoid desc dead loop chain */
-	uint32_t nr_desc = 1;
-
-	desc = &vr->desc[desc_idx];
-	if (unlikely((desc->len < dev->hdr_len)) ||
-			(desc->flags & VRING_DESC_F_INDIRECT))
-		return -1;
-
-	desc_chunck_len = desc->len;
-	desc_gaddr = desc->addr;
-	desc_addr = rte_vhost_va_from_guest_pa(
-			dev->mem, desc_gaddr, &desc_chunck_len);
-	if (unlikely(!desc_addr))
-		return -1;
-
-	/*
-	 * We don't support ANY_LAYOUT, neither VERSION_1, meaning
-	 * a Tx packet from guest must have 2 desc buffers at least:
-	 * the first for storing the header and the others for
-	 * storing the data.
-	 *
-	 * And since we don't support TSO, we could simply skip the
-	 * header.
-	 */
-	desc = &vr->desc[desc->next];
-	desc_chunck_len = desc->len;
-	desc_gaddr = desc->addr;
-	desc_addr = rte_vhost_va_from_guest_pa(
-			dev->mem, desc_gaddr, &desc_chunck_len);
-	if (unlikely(!desc_addr))
-		return -1;
-	rte_prefetch0((void *)(uintptr_t)desc_addr);
-
-	desc_offset = 0;
-	desc_avail  = desc->len;
-	nr_desc    += 1;
-
-	mbuf_offset = 0;
-	mbuf_avail  = m->buf_len - RTE_PKTMBUF_HEADROOM;
-	while (1) {
-		cpy_len = RTE_MIN(desc_chunck_len, mbuf_avail);
-		rte_memcpy(rte_pktmbuf_mtod_offset(cur, void *,
-						   mbuf_offset),
-			(void *)((uintptr_t)(desc_addr + desc_offset)),
-			cpy_len);
-
-		mbuf_avail  -= cpy_len;
-		mbuf_offset += cpy_len;
-		desc_avail  -= cpy_len;
-		desc_offset += cpy_len;
-		desc_chunck_len -= cpy_len;
-
-		/* This desc reaches to its end, get the next one */
-		if (desc_avail == 0) {
-			if ((desc->flags & VRING_DESC_F_NEXT) == 0)
-				break;
-
-			if (unlikely(desc->next >= vr->size ||
-				     ++nr_desc > vr->size))
-				return -1;
-			desc = &vr->desc[desc->next];
-
-			desc_chunck_len = desc->len;
-			desc_gaddr = desc->addr;
-			desc_addr = rte_vhost_va_from_guest_pa(
-					dev->mem, desc_gaddr, &desc_chunck_len);
-			if (unlikely(!desc_addr))
-				return -1;
-			rte_prefetch0((void *)(uintptr_t)desc_addr);
-
-			desc_offset = 0;
-			desc_avail  = desc->len;
-		} else if (unlikely(desc_chunck_len == 0)) {
-			desc_chunck_len = desc_avail;
-			desc_gaddr += desc_offset;
-			desc_addr = rte_vhost_va_from_guest_pa(dev->mem,
-					desc_gaddr,
-					&desc_chunck_len);
-			if (unlikely(!desc_addr))
-				return -1;
-
-			desc_offset = 0;
-		}
-
-		/*
-		 * This mbuf reaches to its end, get a new one
-		 * to hold more data.
-		 */
-		if (mbuf_avail == 0) {
-			cur = rte_pktmbuf_alloc(mbuf_pool);
-			if (unlikely(cur == NULL)) {
-				RTE_LOG(ERR, VHOST_DATA, "Failed to "
-					"allocate memory for mbuf.\n");
-				return -1;
-			}
-
-			prev->next = cur;
-			prev->data_len = mbuf_offset;
-			m->nb_segs += 1;
-			m->pkt_len += mbuf_offset;
-			prev = cur;
-
-			mbuf_offset = 0;
-			mbuf_avail  = cur->buf_len - RTE_PKTMBUF_HEADROOM;
-		}
-	}
-
-	prev->data_len = mbuf_offset;
-	m->pkt_len    += mbuf_offset;
-
-	return 0;
-}
-
-uint16_t
-vs_dequeue_pkts(struct vhost_dev *dev, uint16_t queue_id,
-	struct rte_mempool *mbuf_pool, struct rte_mbuf **pkts, uint16_t count)
-{
-	struct vhost_queue *queue;
-	struct rte_vhost_vring *vr;
-	uint32_t desc_indexes[MAX_PKT_BURST];
-	uint32_t used_idx;
-	uint32_t i = 0;
-	uint16_t free_entries;
-	uint16_t avail_idx;
-
-	queue = &dev->queues[queue_id];
-	vr    = &queue->vr;
-
-	free_entries = *((volatile uint16_t *)&vr->avail->idx) -
-			queue->last_avail_idx;
-	if (free_entries == 0)
-		return 0;
-
-	/* Prefetch available and used ring */
-	avail_idx = queue->last_avail_idx & (vr->size - 1);
-	used_idx  = queue->last_used_idx  & (vr->size - 1);
-	rte_prefetch0(&vr->avail->ring[avail_idx]);
-	rte_prefetch0(&vr->used->ring[used_idx]);
-
-	count = RTE_MIN(count, MAX_PKT_BURST);
-	count = RTE_MIN(count, free_entries);
-
-	if (unlikely(count == 0))
-		return 0;
-
-	/*
-	 * Retrieve all of the head indexes first and pre-update used entries
-	 * to avoid caching issues.
-	 */
-	for (i = 0; i < count; i++) {
-		avail_idx = (queue->last_avail_idx + i) & (vr->size - 1);
-		used_idx  = (queue->last_used_idx  + i) & (vr->size - 1);
-		desc_indexes[i] = vr->avail->ring[avail_idx];
-
-		vr->used->ring[used_idx].id  = desc_indexes[i];
-		vr->used->ring[used_idx].len = 0;
-	}
-
-	/* Prefetch descriptor index. */
-	rte_prefetch0(&vr->desc[desc_indexes[0]]);
-	for (i = 0; i < count; i++) {
-		int err;
-
-		if (likely(i + 1 < count))
-			rte_prefetch0(&vr->desc[desc_indexes[i + 1]]);
-
-		pkts[i] = rte_pktmbuf_alloc(mbuf_pool);
-		if (unlikely(pkts[i] == NULL)) {
-			RTE_LOG(ERR, VHOST_DATA,
-				"Failed to allocate memory for mbuf.\n");
-			break;
-		}
-
-		err = dequeue_pkt(dev, vr, pkts[i], desc_indexes[i], mbuf_pool);
-		if (unlikely(err)) {
-			rte_pktmbuf_free(pkts[i]);
-			break;
-		}
-
-	}
-
-	queue->last_avail_idx += i;
-	queue->last_used_idx += i;
-	rte_smp_wmb();
-	rte_smp_rmb();
-
-	vr->used->idx += i;
-
-	rte_vhost_vring_call(dev->vid, queue_id);
-
-	return i;
-}
diff --git a/examples/vhost_scsi/Makefile b/examples/vhost_scsi/Makefile
deleted file mode 100644
index 31bd256..0000000
--- a/examples/vhost_scsi/Makefile
+++ /dev/null
@@ -1,67 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2017 Intel Corporation
-
-# binary name
-APP = vhost-scsi
-
-# all source are stored in SRCS-y
-SRCS-y := scsi.c vhost_scsi.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-CFLAGS += -D_GNU_SOURCE -D_FILE_OFFSET_BITS=64
-LDFLAGS += -pthread
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else # Build using legacy build system
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-ifneq ($(CONFIG_RTE_EXEC_ENV),"linuxapp")
-$(info This application can only operate in a linuxapp environment, \
-please change the definition of the RTE_TARGET environment variable)
-all:
-else
-
-CFLAGS += -D_GNU_SOURCE -D_FILE_OFFSET_BITS=64
-CFLAGS += -O2
-CFLAGS += $(WERROR_FLAGS)
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-
-endif
-endif
diff --git a/examples/vhost_scsi/meson.build b/examples/vhost_scsi/meson.build
deleted file mode 100644
index bd78e84..0000000
--- a/examples/vhost_scsi/meson.build
+++ /dev/null
@@ -1,13 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-deps += 'vhost'
-cflags += ['-D_GNU_SOURCE','-D_FILE_OFFSET_BITS=64']
-sources = files(
-	'scsi.c', 'vhost_scsi.c'
-)
diff --git a/examples/vhost_scsi/scsi.c b/examples/vhost_scsi/scsi.c
deleted file mode 100644
index 2a034bb..0000000
--- a/examples/vhost_scsi/scsi.c
+++ /dev/null
@@ -1,512 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2017 Intel Corporation
- */
-
-/**
- * This work is largely based on the "vhost-user-scsi" implementation by
- * SPDK(https://github.com/spdk/spdk).
- */
-
-#include <stdio.h>
-#include <stdint.h>
-#include <unistd.h>
-#include <assert.h>
-#include <ctype.h>
-#include <string.h>
-#include <stddef.h>
-
-#include <rte_atomic.h>
-#include <rte_cycles.h>
-#include <rte_log.h>
-#include <rte_malloc.h>
-#include <rte_byteorder.h>
-
-#include "vhost_scsi.h"
-#include "scsi_spec.h"
-
-#define INQ_OFFSET(field) (offsetof(struct scsi_cdb_inquiry_data, field) + \
-			  sizeof(((struct scsi_cdb_inquiry_data *)0x0)->field))
-
-static void
-vhost_strcpy_pad(void *dst, const char *src, size_t size, int pad)
-{
-	size_t len;
-
-	len = strlen(src);
-	if (len < size) {
-		memcpy(dst, src, len);
-		memset((char *)dst + len, pad, size - len);
-	} else {
-		memcpy(dst, src, size);
-	}
-}
-
-static int
-vhost_hex2bin(char ch)
-{
-	if ((ch >= '0') && (ch <= '9'))
-		return ch - '0';
-	ch = tolower(ch);
-	if ((ch >= 'a') && (ch <= 'f'))
-		return ch - 'a' + 10;
-	return (int)ch;
-}
-
-static void
-vhost_bdev_scsi_set_naa_ieee_extended(const char *name, uint8_t *buf)
-{
-	int i, value, count = 0;
-	uint64_t *temp64, local_value;
-
-	for (i = 0; (i < 16) && (name[i] != '\0'); i++) {
-		value = vhost_hex2bin(name[i]);
-		if (i % 2)
-			buf[count++] |= value << 4;
-		else
-			buf[count] = value;
-	}
-
-	local_value = *(uint64_t *)buf;
-	/*
-	 * see spc3r23 7.6.3.6.2,
-	 *  NAA IEEE Extended identifer format
-	 */
-	local_value &= 0x0fff000000ffffffull;
-	/* NAA 02, and 00 03 47 for IEEE Intel */
-	local_value |= 0x2000000347000000ull;
-
-	temp64 = (uint64_t *)buf;
-	*temp64 = rte_cpu_to_be_64(local_value);
-}
-
-static void
-scsi_task_build_sense_data(struct vhost_scsi_task *task, int sk,
-			   int asc, int ascq)
-{
-	uint8_t *cp;
-	int resp_code;
-
-	resp_code = 0x70; /* Current + Fixed format */
-
-	/* Sense Data */
-	cp = (uint8_t *)task->resp->sense;
-
-	/* VALID(7) RESPONSE CODE(6-0) */
-	cp[0] = 0x80 | resp_code;
-	/* Obsolete */
-	cp[1] = 0;
-	/* FILEMARK(7) EOM(6) ILI(5) SENSE KEY(3-0) */
-	cp[2] = sk & 0xf;
-	/* INFORMATION */
-	memset(&cp[3], 0, 4);
-
-	/* ADDITIONAL SENSE LENGTH */
-	cp[7] = 10;
-
-	/* COMMAND-SPECIFIC INFORMATION */
-	memset(&cp[8], 0, 4);
-	/* ADDITIONAL SENSE CODE */
-	cp[12] = asc;
-	/* ADDITIONAL SENSE CODE QUALIFIER */
-	cp[13] = ascq;
-	/* FIELD REPLACEABLE UNIT CODE */
-	cp[14] = 0;
-
-	/* SKSV(7) SENSE KEY SPECIFIC(6-0,7-0,7-0) */
-	cp[15] = 0;
-	cp[16] = 0;
-	cp[17] = 0;
-
-	/* SenseLength */
-	task->resp->sense_len = 18;
-}
-
-static void
-scsi_task_set_status(struct vhost_scsi_task *task, int sc, int sk,
-		     int asc, int ascq)
-{
-	if (sc == SCSI_STATUS_CHECK_CONDITION)
-		scsi_task_build_sense_data(task, sk, asc, ascq);
-	task->resp->status = sc;
-}
-
-static int
-vhost_bdev_scsi_inquiry_command(struct vhost_block_dev *bdev,
-				struct vhost_scsi_task *task)
-{
-	int hlen = 0;
-	uint32_t alloc_len = 0;
-	uint16_t len = 0;
-	uint16_t *temp16;
-	int pc;
-	int pd;
-	int evpd;
-	int i;
-	uint8_t *buf;
-	struct scsi_cdb_inquiry *inq;
-
-	inq = (struct scsi_cdb_inquiry *)task->req->cdb;
-
-	assert(task->iovs_cnt == 1);
-
-	/* At least 36Bytes for inquiry command */
-	if (task->data_len < 0x24)
-		goto inq_error;
-
-	pd = SPC_PERIPHERAL_DEVICE_TYPE_DISK;
-	pc = inq->page_code;
-	evpd = inq->evpd & 0x1;
-
-	if (!evpd && pc)
-		goto inq_error;
-
-	if (evpd) {
-		struct scsi_vpd_page *vpage = (struct scsi_vpd_page *)
-					      task->iovs[0].iov_base;
-
-		/* PERIPHERAL QUALIFIER(7-5) PERIPHERAL DEVICE TYPE(4-0) */
-		vpage->peripheral = pd;
-		/* PAGE CODE */
-		vpage->page_code = pc;
-
-		switch (pc) {
-		case SPC_VPD_SUPPORTED_VPD_PAGES:
-			hlen = 4;
-			vpage->params[0] = SPC_VPD_SUPPORTED_VPD_PAGES;
-			vpage->params[1] = SPC_VPD_UNIT_SERIAL_NUMBER;
-			vpage->params[2] = SPC_VPD_DEVICE_IDENTIFICATION;
-			len = 3;
-			/* PAGE LENGTH */
-			vpage->alloc_len = rte_cpu_to_be_16(len);
-			break;
-		case SPC_VPD_UNIT_SERIAL_NUMBER:
-			hlen = 4;
-			strncpy((char *)vpage->params, bdev->name, 32);
-			vpage->alloc_len = rte_cpu_to_be_16(32);
-			break;
-		case SPC_VPD_DEVICE_IDENTIFICATION:
-			buf = vpage->params;
-			struct scsi_desig_desc *desig;
-
-			hlen = 4;
-			/* NAA designator */
-			desig = (struct scsi_desig_desc *)buf;
-			desig->code_set = SPC_VPD_CODE_SET_BINARY;
-			desig->protocol_id = SPC_PROTOCOL_IDENTIFIER_ISCSI;
-			desig->type = SPC_VPD_IDENTIFIER_TYPE_NAA;
-			desig->association = SPC_VPD_ASSOCIATION_LOGICAL_UNIT;
-			desig->reserved0 = 0;
-			desig->piv = 1;
-			desig->reserved1 = 0;
-			desig->len = 8;
-			vhost_bdev_scsi_set_naa_ieee_extended(bdev->name,
-							      desig->desig);
-			len = sizeof(struct scsi_desig_desc) + 8;
-
-			buf += sizeof(struct scsi_desig_desc) + desig->len;
-
-			/* T10 Vendor ID designator */
-			desig = (struct scsi_desig_desc *)buf;
-			desig->code_set = SPC_VPD_CODE_SET_ASCII;
-			desig->protocol_id = SPC_PROTOCOL_IDENTIFIER_ISCSI;
-			desig->type = SPC_VPD_IDENTIFIER_TYPE_T10_VENDOR_ID;
-			desig->association = SPC_VPD_ASSOCIATION_LOGICAL_UNIT;
-			desig->reserved0 = 0;
-			desig->piv = 1;
-			desig->reserved1 = 0;
-			desig->len = 8 + 16 + 32;
-			strncpy((char *)desig->desig, "INTEL", 8);
-			vhost_strcpy_pad((char *)&desig->desig[8],
-					 bdev->product_name, 16, ' ');
-			strncpy((char *)&desig->desig[24], bdev->name, 32);
-			len += sizeof(struct scsi_desig_desc) + 8 + 16 + 32;
-
-			buf += sizeof(struct scsi_desig_desc) + desig->len;
-
-			/* SCSI Device Name designator */
-			desig = (struct scsi_desig_desc *)buf;
-			desig->code_set = SPC_VPD_CODE_SET_UTF8;
-			desig->protocol_id = SPC_PROTOCOL_IDENTIFIER_ISCSI;
-			desig->type = SPC_VPD_IDENTIFIER_TYPE_SCSI_NAME;
-			desig->association = SPC_VPD_ASSOCIATION_TARGET_DEVICE;
-			desig->reserved0 = 0;
-			desig->piv = 1;
-			desig->reserved1 = 0;
-			desig->len = snprintf((char *)desig->desig,
-					      255, "%s", bdev->name);
-			len += sizeof(struct scsi_desig_desc) + desig->len;
-
-			buf += sizeof(struct scsi_desig_desc) + desig->len;
-			vpage->alloc_len = rte_cpu_to_be_16(len);
-			break;
-		default:
-			goto inq_error;
-		}
-
-	} else {
-		struct scsi_cdb_inquiry_data *inqdata =
-			(struct scsi_cdb_inquiry_data *)task->iovs[0].iov_base;
-		/* Standard INQUIRY data */
-		/* PERIPHERAL QUALIFIER(7-5) PERIPHERAL DEVICE TYPE(4-0) */
-		inqdata->peripheral = pd;
-
-		/* RMB(7) */
-		inqdata->rmb = 0;
-
-		/* VERSION */
-		/* See SPC3/SBC2/MMC4/SAM2 for more details */
-		inqdata->version = SPC_VERSION_SPC3;
-
-		/* NORMACA(5) HISUP(4) RESPONSE DATA FORMAT(3-0) */
-		/* format 2 */ /* hierarchical support */
-		inqdata->response = 2 | 1 << 4;
-
-		hlen = 5;
-
-		/* SCCS(7) ACC(6) TPGS(5-4) 3PC(3) PROTECT(0) */
-		/* Not support TPGS */
-		inqdata->flags = 0;
-
-		/* MULTIP */
-		inqdata->flags2 = 0x10;
-
-		/* WBUS16(5) SYNC(4) LINKED(3) CMDQUE(1) VS(0) */
-		/* CMDQUE */
-		inqdata->flags3 = 0x2;
-
-		/* T10 VENDOR IDENTIFICATION */
-		strncpy((char *)inqdata->t10_vendor_id, "INTEL", 8);
-
-		/* PRODUCT IDENTIFICATION */
-		snprintf((char *)inqdata->product_id,
-				RTE_DIM(inqdata->product_id), "%s",
-				bdev->product_name);
-
-		/* PRODUCT REVISION LEVEL */
-		strncpy((char *)inqdata->product_rev, "0001", 4);
-
-		/* Standard inquiry data ends here. Only populate
-		 * remaining fields if alloc_len indicates enough
-		 * space to hold it.
-		 */
-		len = INQ_OFFSET(product_rev) - 5;
-
-		if (alloc_len >= INQ_OFFSET(vendor)) {
-			/* Vendor specific */
-			memset(inqdata->vendor, 0x20, 20);
-			len += sizeof(inqdata->vendor);
-		}
-
-		if (alloc_len >= INQ_OFFSET(ius)) {
-			/* CLOCKING(3-2) QAS(1) IUS(0) */
-			inqdata->ius = 0;
-			len += sizeof(inqdata->ius);
-		}
-
-		if (alloc_len >= INQ_OFFSET(reserved)) {
-			/* Reserved */
-			inqdata->reserved = 0;
-			len += sizeof(inqdata->reserved);
-		}
-
-		/* VERSION DESCRIPTOR 1-8 */
-		if (alloc_len >= INQ_OFFSET(reserved) + 2) {
-			temp16 = (uint16_t *)&inqdata->desc[0];
-			*temp16 = rte_cpu_to_be_16(0x0960);
-			len += 2;
-		}
-
-		if (alloc_len >= INQ_OFFSET(reserved) + 4) {
-			/* SPC-3 (no version claimed) */
-			temp16 = (uint16_t *)&inqdata->desc[2];
-			*temp16 = rte_cpu_to_be_16(0x0300);
-			len += 2;
-		}
-
-		if (alloc_len >= INQ_OFFSET(reserved) + 6) {
-			/* SBC-2 (no version claimed) */
-			temp16 = (uint16_t *)&inqdata->desc[4];
-			*temp16 = rte_cpu_to_be_16(0x0320);
-			len += 2;
-		}
-
-		if (alloc_len >= INQ_OFFSET(reserved) + 8) {
-			/* SAM-2 (no version claimed) */
-			temp16 = (uint16_t *)&inqdata->desc[6];
-			*temp16 = rte_cpu_to_be_16(0x0040);
-			len += 2;
-		}
-
-		if (alloc_len > INQ_OFFSET(reserved) + 8) {
-			i = alloc_len - (INQ_OFFSET(reserved) + 8);
-			if (i > 30)
-				i = 30;
-			memset(&inqdata->desc[8], 0, i);
-			len += i;
-		}
-
-		/* ADDITIONAL LENGTH */
-		inqdata->add_len = len;
-	}
-
-	/* STATUS GOOD */
-	scsi_task_set_status(task, SCSI_STATUS_GOOD, 0, 0, 0);
-	return hlen + len;
-
-inq_error:
-	scsi_task_set_status(task, SCSI_STATUS_CHECK_CONDITION,
-				     SCSI_SENSE_ILLEGAL_REQUEST,
-				     SCSI_ASC_INVALID_FIELD_IN_CDB,
-				     SCSI_ASCQ_CAUSE_NOT_REPORTABLE);
-	return 0;
-}
-
-static int
-vhost_bdev_scsi_readwrite(struct vhost_block_dev *bdev,
-			  struct vhost_scsi_task *task,
-			  uint64_t lba, __rte_unused uint32_t xfer_len)
-{
-	uint32_t i;
-	uint64_t offset;
-	uint32_t nbytes = 0;
-
-	offset = lba * bdev->blocklen;
-
-	for (i = 0; i < task->iovs_cnt; i++) {
-		if (task->dxfer_dir == SCSI_DIR_TO_DEV)
-			memcpy(bdev->data + offset, task->iovs[i].iov_base,
-			       task->iovs[i].iov_len);
-		else
-			memcpy(task->iovs[i].iov_base, bdev->data + offset,
-			       task->iovs[i].iov_len);
-		offset += task->iovs[i].iov_len;
-		nbytes += task->iovs[i].iov_len;
-	}
-
-	return nbytes;
-}
-
-static int
-vhost_bdev_scsi_process_block(struct vhost_block_dev *bdev,
-			      struct vhost_scsi_task *task)
-{
-	uint64_t lba, *temp64;
-	uint32_t xfer_len, *temp32;
-	uint16_t *temp16;
-	uint8_t *cdb = (uint8_t *)task->req->cdb;
-
-	switch (cdb[0]) {
-	case SBC_READ_6:
-	case SBC_WRITE_6:
-		lba = (uint64_t)cdb[1] << 16;
-		lba |= (uint64_t)cdb[2] << 8;
-		lba |= (uint64_t)cdb[3];
-		xfer_len = cdb[4];
-		if (xfer_len == 0)
-			xfer_len = 256;
-		return vhost_bdev_scsi_readwrite(bdev, task, lba, xfer_len);
-
-	case SBC_READ_10:
-	case SBC_WRITE_10:
-		temp32 = (uint32_t *)&cdb[2];
-		lba = rte_be_to_cpu_32(*temp32);
-		temp16 = (uint16_t *)&cdb[7];
-		xfer_len = rte_be_to_cpu_16(*temp16);
-		return vhost_bdev_scsi_readwrite(bdev, task, lba, xfer_len);
-
-	case SBC_READ_12:
-	case SBC_WRITE_12:
-		temp32 = (uint32_t *)&cdb[2];
-		lba = rte_be_to_cpu_32(*temp32);
-		temp32 = (uint32_t *)&cdb[6];
-		xfer_len = rte_be_to_cpu_32(*temp32);
-		return vhost_bdev_scsi_readwrite(bdev, task, lba, xfer_len);
-
-	case SBC_READ_16:
-	case SBC_WRITE_16:
-		temp64 = (uint64_t *)&cdb[2];
-		lba = rte_be_to_cpu_64(*temp64);
-		temp32 = (uint32_t *)&cdb[10];
-		xfer_len = rte_be_to_cpu_32(*temp32);
-		return vhost_bdev_scsi_readwrite(bdev, task, lba, xfer_len);
-
-	case SBC_READ_CAPACITY_10: {
-		uint8_t buffer[8];
-
-		if (bdev->blockcnt - 1 > 0xffffffffULL)
-			memset(buffer, 0xff, 4);
-		else {
-			temp32 = (uint32_t *)buffer;
-			*temp32 = rte_cpu_to_be_32(bdev->blockcnt - 1);
-		}
-		temp32 = (uint32_t *)&buffer[4];
-		*temp32 = rte_cpu_to_be_32(bdev->blocklen);
-		memcpy(task->iovs[0].iov_base, buffer, sizeof(buffer));
-		task->resp->status = SCSI_STATUS_GOOD;
-		return sizeof(buffer);
-	}
-
-	case SBC_SYNCHRONIZE_CACHE_10:
-	case SBC_SYNCHRONIZE_CACHE_16:
-		task->resp->status = SCSI_STATUS_GOOD;
-		return 0;
-	}
-
-	scsi_task_set_status(task, SCSI_STATUS_CHECK_CONDITION,
-			     SCSI_SENSE_ILLEGAL_REQUEST,
-			     SCSI_ASC_INVALID_FIELD_IN_CDB,
-			     SCSI_ASCQ_CAUSE_NOT_REPORTABLE);
-	return 0;
-}
-
-int
-vhost_bdev_process_scsi_commands(struct vhost_block_dev *bdev,
-				 struct vhost_scsi_task *task)
-{
-	int len;
-	uint8_t *data;
-	uint64_t *temp64, fmt_lun = 0;
-	uint32_t *temp32;
-	const uint8_t *lun;
-	uint8_t *cdb = (uint8_t *)task->req->cdb;
-
-	lun = (const uint8_t *)task->req->lun;
-	/* only 1 LUN supported */
-	if (lun[0] != 1 || lun[1] >= 1)
-		return -1;
-
-	switch (cdb[0]) {
-	case SPC_INQUIRY:
-		len = vhost_bdev_scsi_inquiry_command(bdev, task);
-		task->data_len = len;
-		break;
-	case SPC_REPORT_LUNS:
-		data = (uint8_t *)task->iovs[0].iov_base;
-		fmt_lun |= (0x0ULL & 0x00ffULL) << 48;
-		temp64 = (uint64_t *)&data[8];
-		*temp64 = rte_cpu_to_be_64(fmt_lun);
-		temp32 = (uint32_t *)data;
-		*temp32 = rte_cpu_to_be_32(8);
-		task->data_len = 16;
-		scsi_task_set_status(task, SCSI_STATUS_GOOD, 0, 0, 0);
-		break;
-	case SPC_MODE_SELECT_6:
-	case SPC_MODE_SELECT_10:
-		/* don't support it now */
-		scsi_task_set_status(task, SCSI_STATUS_GOOD, 0, 0, 0);
-		break;
-	case SPC_MODE_SENSE_6:
-	case SPC_MODE_SENSE_10:
-		/* don't support it now */
-		scsi_task_set_status(task, SCSI_STATUS_GOOD, 0, 0, 0);
-		break;
-	case SPC_TEST_UNIT_READY:
-		scsi_task_set_status(task, SCSI_STATUS_GOOD, 0, 0, 0);
-		break;
-	default:
-		len = vhost_bdev_scsi_process_block(bdev, task);
-		task->data_len = len;
-	}
-
-	return 0;
-}
diff --git a/examples/vhost_scsi/scsi_spec.h b/examples/vhost_scsi/scsi_spec.h
deleted file mode 100644
index 5c7a894..0000000
--- a/examples/vhost_scsi/scsi_spec.h
+++ /dev/null
@@ -1,464 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2017 Intel Corporation
- */
-
-/**
- * SCSI specification definition
- * refer http://www.t10.org/drafts.htm#SPC_Family for SPC-3 and SBC-3
- */
-
-#ifndef _SCSI_SPEC_H
-#define _SCSI_SPEC_H
-
-#include <stdint.h>
-
-enum scsi_group_code {
-	SCSI_6BYTE_CMD = 0x00,
-	SCSI_10BYTE_CMD = 0x20,
-	SCSI_10BYTE_CMD2 = 0x40,
-	SCSI_16BYTE_CMD = 0x80,
-	SCSI_12BYTE_CMD = 0xa0,
-};
-
-#define SCSI_GROUP_MASK	0xe0
-#define SCSI_OPCODE_MASK	0x1f
-
-enum scsi_status {
-	SCSI_STATUS_GOOD = 0x00,
-	SCSI_STATUS_CHECK_CONDITION = 0x02,
-	SCSI_STATUS_CONDITION_MET = 0x04,
-	SCSI_STATUS_BUSY = 0x08,
-	SCSI_STATUS_INTERMEDIATE = 0x10,
-	SCSI_STATUS_INTERMEDIATE_CONDITION_MET = 0x14,
-	SCSI_STATUS_RESERVATION_CONFLICT = 0x18,
-	SCSI_STATUS_Obsolete = 0x22,
-	SCSI_STATUS_TASK_SET_FULL = 0x28,
-	SCSI_STATUS_ACA_ACTIVE = 0x30,
-	SCSI_STATUS_TASK_ABORTED = 0x40,
-};
-
-enum scsi_sense {
-	SCSI_SENSE_NO_SENSE = 0x00,
-	SCSI_SENSE_RECOVERED_ERROR = 0x01,
-	SCSI_SENSE_NOT_READY = 0x02,
-	SCSI_SENSE_MEDIUM_ERROR = 0x03,
-	SCSI_SENSE_HARDWARE_ERROR = 0x04,
-	SCSI_SENSE_ILLEGAL_REQUEST = 0x05,
-	SCSI_SENSE_UNIT_ATTENTION = 0x06,
-	SCSI_SENSE_DATA_PROTECT = 0x07,
-	SCSI_SENSE_BLANK_CHECK = 0x08,
-	SCSI_SENSE_VENDOR_SPECIFIC = 0x09,
-	SCSI_SENSE_COPY_ABORTED = 0x0a,
-	SCSI_SENSE_ABORTED_COMMAND = 0x0b,
-	SCSI_SENSE_VOLUME_OVERFLOW = 0x0d,
-	SCSI_SENSE_MISCOMPARE = 0x0e,
-};
-
-enum scsi_asc {
-	SCSI_ASC_NO_ADDITIONAL_SENSE = 0x00,
-	SCSI_ASC_PERIPHERAL_DEVICE_WRITE_FAULT = 0x03,
-	SCSI_ASC_LOGICAL_UNIT_NOT_READY = 0x04,
-	SCSI_ASC_WARNING = 0x0b,
-	SCSI_ASC_LOGICAL_BLOCK_GUARD_CHECK_FAILED = 0x10,
-	SCSI_ASC_LOGICAL_BLOCK_APP_TAG_CHECK_FAILED = 0x10,
-	SCSI_ASC_LOGICAL_BLOCK_REF_TAG_CHECK_FAILED = 0x10,
-	SCSI_ASC_UNRECOVERED_READ_ERROR = 0x11,
-	SCSI_ASC_MISCOMPARE_DURING_VERIFY_OPERATION = 0x1d,
-	SCSI_ASC_INVALID_COMMAND_OPERATION_CODE = 0x20,
-	SCSI_ASC_ACCESS_DENIED = 0x20,
-	SCSI_ASC_LOGICAL_BLOCK_ADDRESS_OUT_OF_RANGE = 0x21,
-	SCSI_ASC_INVALID_FIELD_IN_CDB = 0x24,
-	SCSI_ASC_LOGICAL_UNIT_NOT_SUPPORTED = 0x25,
-	SCSI_ASC_WRITE_PROTECTED = 0x27,
-	SCSI_ASC_FORMAT_COMMAND_FAILED = 0x31,
-	SCSI_ASC_INTERNAL_TARGET_FAILURE = 0x44,
-};
-
-enum scsi_ascq {
-	SCSI_ASCQ_CAUSE_NOT_REPORTABLE = 0x00,
-	SCSI_ASCQ_BECOMING_READY = 0x01,
-	SCSI_ASCQ_FORMAT_COMMAND_FAILED = 0x01,
-	SCSI_ASCQ_LOGICAL_BLOCK_GUARD_CHECK_FAILED = 0x01,
-	SCSI_ASCQ_LOGICAL_BLOCK_APP_TAG_CHECK_FAILED = 0x02,
-	SCSI_ASCQ_NO_ACCESS_RIGHTS = 0x02,
-	SCSI_ASCQ_LOGICAL_BLOCK_REF_TAG_CHECK_FAILED = 0x03,
-	SCSI_ASCQ_POWER_LOSS_EXPECTED = 0x08,
-	SCSI_ASCQ_INVALID_LU_IDENTIFIER = 0x09,
-};
-
-enum spc_opcode {
-	/* SPC3 related */
-	SPC_ACCESS_CONTROL_IN = 0x86,
-	SPC_ACCESS_CONTROL_OUT = 0x87,
-	SPC_EXTENDED_COPY = 0x83,
-	SPC_INQUIRY = 0x12,
-	SPC_LOG_SELECT = 0x4c,
-	SPC_LOG_SENSE = 0x4d,
-	SPC_MODE_SELECT_6 = 0x15,
-	SPC_MODE_SELECT_10 = 0x55,
-	SPC_MODE_SENSE_6 = 0x1a,
-	SPC_MODE_SENSE_10 = 0x5a,
-	SPC_PERSISTENT_RESERVE_IN = 0x5e,
-	SPC_PERSISTENT_RESERVE_OUT = 0x5f,
-	SPC_PREVENT_ALLOW_MEDIUM_REMOVAL = 0x1e,
-	SPC_READ_ATTRIBUTE = 0x8c,
-	SPC_READ_BUFFER = 0x3c,
-	SPC_RECEIVE_COPY_RESULTS = 0x84,
-	SPC_RECEIVE_DIAGNOSTIC_RESULTS = 0x1c,
-	SPC_REPORT_LUNS = 0xa0,
-	SPC_REQUEST_SENSE = 0x03,
-	SPC_SEND_DIAGNOSTIC = 0x1d,
-	SPC_TEST_UNIT_READY = 0x00,
-	SPC_WRITE_ATTRIBUTE = 0x8d,
-	SPC_WRITE_BUFFER = 0x3b,
-
-	SPC_SERVICE_ACTION_IN_12 = 0xab,
-	SPC_SERVICE_ACTION_OUT_12 = 0xa9,
-	SPC_SERVICE_ACTION_IN_16 = 0x9e,
-	SPC_SERVICE_ACTION_OUT_16 = 0x9f,
-
-	SPC_VARIABLE_LENGTH = 0x7f,
-
-	SPC_MO_CHANGE_ALIASES = 0x0b,
-	SPC_MO_SET_DEVICE_IDENTIFIER = 0x06,
-	SPC_MO_SET_PRIORITY = 0x0e,
-	SPC_MO_SET_TARGET_PORT_GROUPS = 0x0a,
-	SPC_MO_SET_TIMESTAMP = 0x0f,
-	SPC_MI_REPORT_ALIASES = 0x0b,
-	SPC_MI_REPORT_DEVICE_IDENTIFIER = 0x05,
-	SPC_MI_REPORT_PRIORITY = 0x0e,
-	SPC_MI_REPORT_SUPPORTED_OPERATION_CODES = 0x0c,
-	SPC_MI_REPORT_SUPPORTED_TASK_MANAGEMENT_FUNCTIONS = 0x0d,
-	SPC_MI_REPORT_TARGET_PORT_GROUPS = 0x0a,
-	SPC_MI_REPORT_TIMESTAMP = 0x0f,
-
-	/* SPC2 related (Obsolete) */
-	SPC2_RELEASE_6 = 0x17,
-	SPC2_RELEASE_10 = 0x57,
-	SPC2_RESERVE_6 = 0x16,
-	SPC2_RESERVE_10 = 0x56,
-};
-
-enum scc_opcode {
-	SCC_MAINTENANCE_IN = 0xa3,
-	SCC_MAINTENANCE_OUT = 0xa4,
-};
-
-enum sbc_opcode {
-	SBC_COMPARE_AND_WRITE = 0x89,
-	SBC_FORMAT_UNIT = 0x04,
-	SBC_GET_LBA_STATUS = 0x0012009e,
-	SBC_ORWRITE_16 = 0x8b,
-	SBC_PRE_FETCH_10 = 0x34,
-	SBC_PRE_FETCH_16 = 0x90,
-	SBC_READ_6 = 0x08,
-	SBC_READ_10 = 0x28,
-	SBC_READ_12 = 0xa8,
-	SBC_READ_16 = 0x88,
-	SBC_READ_ATTRIBUTE = 0x8c,
-	SBC_READ_BUFFER = 0x3c,
-	SBC_READ_CAPACITY_10 = 0x25,
-	SBC_READ_DEFECT_DATA_10 = 0x37,
-	SBC_READ_DEFECT_DATA_12 = 0xb7,
-	SBC_READ_LONG_10 = 0x3e,
-	SBC_REASSIGN_BLOCKS = 0x07,
-	SBC_SANITIZE = 0x48,
-	SBC_START_STOP_UNIT = 0x1b,
-	SBC_SYNCHRONIZE_CACHE_10 = 0x35,
-	SBC_SYNCHRONIZE_CACHE_16 = 0x91,
-	SBC_UNMAP = 0x42,
-	SBC_VERIFY_10 = 0x2f,
-	SBC_VERIFY_12 = 0xaf,
-	SBC_VERIFY_16 = 0x8f,
-	SBC_WRITE_6 = 0x0a,
-	SBC_WRITE_10 = 0x2a,
-	SBC_WRITE_12 = 0xaa,
-	SBC_WRITE_16 = 0x8a,
-	SBC_WRITE_AND_VERIFY_10 = 0x2e,
-	SBC_WRITE_AND_VERIFY_12 = 0xae,
-	SBC_WRITE_AND_VERIFY_16 = 0x8e,
-	SBC_WRITE_LONG_10 = 0x3f,
-	SBC_WRITE_SAME_10 = 0x41,
-	SBC_WRITE_SAME_16 = 0x93,
-	SBC_XDREAD_10 = 0x52,
-	SBC_XDWRITE_10 = 0x50,
-	SBC_XDWRITEREAD_10 = 0x53,
-	SBC_XPWRITE_10 = 0x51,
-
-	SBC_SAI_READ_CAPACITY_16 = 0x10,
-	SBC_SAI_READ_LONG_16 = 0x11,
-	SBC_SAO_WRITE_LONG_16 = 0x11,
-
-	SBC_VL_READ_32 = 0x0009,
-	SBC_VL_VERIFY_32 = 0x000a,
-	SBC_VL_WRITE_32 = 0x000b,
-	SBC_VL_WRITE_AND_VERIFY_32 = 0x000c,
-	SBC_VL_WRITE_SAME_32 = 0x000d,
-	SBC_VL_XDREAD_32 = 0x0003,
-	SBC_VL_XDWRITE_32 = 0x0004,
-	SBC_VL_XDWRITEREAD_32 = 0x0007,
-	SBC_VL_XPWRITE_32 = 0x0006,
-};
-
-enum mmc_opcode {
-	/* MMC6 */
-	MMC_READ_DISC_STRUCTURE = 0xad,
-
-	/* MMC4 */
-	MMC_BLANK = 0xa1,
-	MMC_CLOSE_TRACK_SESSION = 0x5b,
-	MMC_ERASE_10 = 0x2c,
-	MMC_FORMAT_UNIT = 0x04,
-	MMC_GET_CONFIGURATION = 0x46,
-	MMC_GET_EVENT_STATUS_NOTIFICATION = 0x4a,
-	MMC_GET_PERFORMANCE = 0xac,
-	MMC_INQUIRY = 0x12,
-	MMC_LOAD_UNLOAD_MEDIUM = 0xa6,
-	MMC_MECHANISM_STATUS = 0xbd,
-	MMC_MODE_SELECT_10 = 0x55,
-	MMC_MODE_SENSE_10 = 0x5a,
-	MMC_PAUSE_RESUME = 0x4b,
-	MMC_PLAY_AUDIO_10 = 0x45,
-	MMC_PLAY_AUDIO_12 = 0xa5,
-	MMC_PLAY_AUDIO_MSF = 0x47,
-	MMC_PREVENT_ALLOW_MEDIUM_REMOVAL = 0x1e,
-	MMC_READ_10 = 0x28,
-	MMC_READ_12 = 0xa8,
-	MMC_READ_BUFFER = 0x3c,
-	MMC_READ_BUFFER_CAPACITY = 0x5c,
-	MMC_READ_CAPACITY = 0x25,
-	MMC_READ_CD = 0xbe,
-	MMC_READ_CD_MSF = 0xb9,
-	MMC_READ_DISC_INFORMATION = 0x51,
-	MMC_READ_DVD_STRUCTURE = 0xad,
-	MMC_READ_FORMAT_CAPACITIES = 0x23,
-	MMC_READ_SUB_CHANNEL = 0x42,
-	MMC_READ_TOC_PMA_ATIP = 0x43,
-	MMC_READ_TRACK_INFORMATION = 0x52,
-	MMC_REPAIR_TRACK = 0x58,
-	MMC_REPORT_KEY = 0xa4,
-	MMC_REQUEST_SENSE = 0x03,
-	MMC_RESERVE_TRACK = 0x53,
-	MMC_SCAN = 0xba,
-	MMC_SEEK_10 = 0x2b,
-	MMC_SEND_CUE_SHEET = 0x5d,
-	MMC_SEND_DVD_STRUCTURE = 0xbf,
-	MMC_SEND_KEY = 0xa3,
-	MMC_SEND_OPC_INFORMATION = 0x54,
-	MMC_SET_CD_SPEED = 0xbb,
-	MMC_SET_READ_AHEAD = 0xa7,
-	MMC_SET_STREAMING = 0xb6,
-	MMC_START_STOP_UNIT = 0x1b,
-	MMC_STOP_PLAY_SCAN = 0x4e,
-	MMC_SYNCHRONIZE_CACHE = 0x35,
-	MMC_TEST_UNIT_READY = 0x00,
-	MMC_VERIFY_10 = 0x2f,
-	MMC_WRITE_10 = 0xa2,
-	MMC_WRITE_12 = 0xaa,
-	MMC_WRITE_AND_VERIFY_10 = 0x2e,
-	MMC_WRITE_BUFFER = 0x3b,
-};
-
-enum ssc_opcode {
-	SSC_ERASE_6 = 0x19,
-	SSC_FORMAT_MEDIUM = 0x04,
-	SSC_LOAD_UNLOAD = 0x1b,
-	SSC_LOCATE_10 = 0x2b,
-	SSC_LOCATE_16 = 0x92,
-	SSC_MOVE_MEDIUM_ATTACHED = 0xa7,
-	SSC_READ_6 = 0x08,
-	SSC_READ_BLOCK_LIMITS = 0x05,
-	SSC_READ_ELEMENT_STATUS_ATTACHED = 0xb4,
-	SSC_READ_POSITION = 0x34,
-	SSC_READ_REVERSE_6 = 0x0f,
-	SSC_RECOVER_BUFFERED_DATA = 0x14,
-	SSC_REPORT_DENSITY_SUPPORT = 0x44,
-	SSC_REWIND = 0x01,
-	SSC_SET_CAPACITY = 0x0b,
-	SSC_SPACE_6 = 0x11,
-	SSC_SPACE_16 = 0x91,
-	SSC_VERIFY_6 = 0x13,
-	SSC_WRITE_6 = 0x0a,
-	SSC_WRITE_FILEMARKS_6 = 0x10,
-};
-
-enum spc_vpd {
-	SPC_VPD_DEVICE_IDENTIFICATION = 0x83,
-	SPC_VPD_EXTENDED_INQUIRY_DATA = 0x86,
-	SPC_VPD_MANAGEMENT_NETWORK_ADDRESSES = 0x85,
-	SPC_VPD_MODE_PAGE_POLICY = 0x87,
-	SPC_VPD_SCSI_PORTS = 0x88,
-	SPC_VPD_SOFTWARE_INTERFACE_IDENTIFICATION = 0x84,
-	SPC_VPD_SUPPORTED_VPD_PAGES = 0x00,
-	SPC_VPD_UNIT_SERIAL_NUMBER = 0x80,
-	SPC_VPD_BLOCK_LIMITS = 0xb0,
-	SPC_VPD_BLOCK_DEV_CHARS = 0xb1,
-	SPC_VPD_BLOCK_THIN_PROVISION = 0xb2,
-};
-
-enum {
-	SPC_PERIPHERAL_DEVICE_TYPE_DISK = 0x00,
-	SPC_PERIPHERAL_DEVICE_TYPE_TAPE = 0x01,
-	SPC_PERIPHERAL_DEVICE_TYPE_DVD = 0x05,
-	SPC_PERIPHERAL_DEVICE_TYPE_CHANGER = 0x08,
-
-	SPC_VERSION_NONE = 0x00,
-	SPC_VERSION_SPC = 0x03,
-	SPC_VERSION_SPC2 = 0x04,
-	SPC_VERSION_SPC3 = 0x05,
-	SPC_VERSION_SPC4 = 0x06,
-
-	SPC_PROTOCOL_IDENTIFIER_FC = 0x00,
-	SPC_PROTOCOL_IDENTIFIER_PSCSI = 0x01,
-	SPC_PROTOCOL_IDENTIFIER_SSA = 0x02,
-	SPC_PROTOCOL_IDENTIFIER_IEEE1394 = 0x03,
-	SPC_PROTOCOL_IDENTIFIER_RDMA = 0x04,
-	SPC_PROTOCOL_IDENTIFIER_ISCSI = 0x05,
-	SPC_PROTOCOL_IDENTIFIER_SAS = 0x06,
-	SPC_PROTOCOL_IDENTIFIER_ADT = 0x07,
-	SPC_PROTOCOL_IDENTIFIER_ATA = 0x08,
-
-	SPC_VPD_CODE_SET_BINARY = 0x01,
-	SPC_VPD_CODE_SET_ASCII = 0x02,
-	SPC_VPD_CODE_SET_UTF8 = 0x03,
-
-	SPC_VPD_ASSOCIATION_LOGICAL_UNIT = 0x00,
-	SPC_VPD_ASSOCIATION_TARGET_PORT = 0x01,
-	SPC_VPD_ASSOCIATION_TARGET_DEVICE = 0x02,
-
-	SPC_VPD_IDENTIFIER_TYPE_VENDOR_SPECIFIC = 0x00,
-	SPC_VPD_IDENTIFIER_TYPE_T10_VENDOR_ID = 0x01,
-	SPC_VPD_IDENTIFIER_TYPE_EUI64 = 0x02,
-	SPC_VPD_IDENTIFIER_TYPE_NAA = 0x03,
-	SPC_VPD_IDENTIFIER_TYPE_RELATIVE_TARGET_PORT = 0x04,
-	SPC_VPD_IDENTIFIER_TYPE_TARGET_PORT_GROUP = 0x05,
-	SPC_VPD_IDENTIFIER_TYPE_LOGICAL_UNIT_GROUP = 0x06,
-	SPC_VPD_IDENTIFIER_TYPE_MD5_LOGICAL_UNIT = 0x07,
-	SPC_VPD_IDENTIFIER_TYPE_SCSI_NAME = 0x08,
-};
-
-struct scsi_cdb_inquiry {
-	uint8_t opcode;
-	uint8_t evpd;
-	uint8_t page_code;
-	uint16_t alloc_len;
-	uint8_t control;
-};
-
-struct scsi_cdb_inquiry_data {
-	uint8_t peripheral;
-	uint8_t rmb;
-	uint8_t version;
-	uint8_t response;
-	uint8_t add_len;
-	uint8_t flags;
-	uint8_t flags2;
-	uint8_t flags3;
-	uint8_t t10_vendor_id[8];
-	uint8_t product_id[16];
-	uint8_t product_rev[4];
-	uint8_t vendor[20];
-	uint8_t ius;
-	uint8_t reserved;
-	uint8_t desc[];
-};
-
-struct scsi_vpd_page {
-	uint8_t peripheral;
-	uint8_t page_code;
-	uint16_t alloc_len;
-	uint8_t params[];
-};
-
-#define SCSI_VEXT_REF_CHK		0x01
-#define SCSI_VEXT_APP_CHK		0x02
-#define SCSI_VEXT_GRD_CHK		0x04
-#define SCSI_VEXT_SIMPSUP		0x01
-#define SCSI_VEXT_ORDSUP		0x02
-#define SCSI_VEXT_HEADSUP		0x04
-#define SCSI_VEXT_PRIOR_SUP	0x08
-#define SCSI_VEXT_GROUP_SUP	0x10
-#define SCSI_VEXT_UASK_SUP		0x20
-#define SCSI_VEXT_V_SUP		0x01
-#define SCSI_VEXT_NV_SUP		0x02
-#define SCSI_VEXT_CRD_SUP		0x04
-#define SCSI_VEXT_WU_SUP		0x08
-
-struct scsi_vpd_ext_inquiry {
-	uint8_t peripheral;
-	uint8_t page_code;
-	uint16_t alloc_len;
-	uint8_t check;
-	uint8_t sup;
-	uint8_t sup2;
-	uint8_t luiclr;
-	uint8_t cbcs;
-	uint8_t micro_dl;
-	uint8_t reserved[54];
-};
-
-#define SPC_VPD_DESIG_PIV	0x80
-
-/* designation descriptor */
-struct scsi_desig_desc {
-	uint8_t code_set	: 4;
-	uint8_t protocol_id	: 4;
-	uint8_t type		: 4;
-	uint8_t association	: 2;
-	uint8_t reserved0	: 1;
-	uint8_t piv		: 1;
-	uint8_t reserved1;
-	uint8_t	len;
-	uint8_t desig[];
-};
-
-/* mode page policy descriptor */
-struct scsi_mpage_policy_desc {
-	uint8_t page_code;
-	uint8_t sub_page_code;
-	uint8_t policy;
-	uint8_t reserved;
-};
-
-/* target port descriptor */
-struct scsi_tgt_port_desc {
-	uint8_t code_set;
-	uint8_t desig_type;
-	uint8_t reserved;
-	uint8_t	len;
-	uint8_t designator[];
-};
-
-/* SCSI port designation descriptor */
-struct scsi_port_desc {
-	uint16_t reserved;
-	uint16_t rel_port_id;
-	uint16_t reserved2;
-	uint16_t init_port_len;
-	uint16_t init_port_id;
-	uint16_t reserved3;
-	uint16_t tgt_desc_len;
-	uint8_t tgt_desc[];
-};
-
-/* SCSI UNMAP block descriptor */
-struct scsi_unmap_bdesc {
-	/* UNMAP LOGICAL BLOCK ADDRESS */
-	uint64_t lba;
-
-	/* NUMBER OF LOGICAL BLOCKS */
-	uint32_t block_count;
-
-	/* RESERVED */
-	uint32_t reserved;
-};
-
-#define SCSI_UNMAP_LBPU				(1 << 7)
-#define SCSI_UNMAP_LBPWS			(1 << 6)
-#define SCSI_UNMAP_LBPWS10			(1 << 5)
-
-#define SCSI_UNMAP_FULL_PROVISIONING	0x00
-#define SCSI_UNMAP_RESOURCE_PROVISIONING	0x01
-#define SCSI_UNMAP_THIN_PROVISIONING	0x02
-
-#endif /* _SCSI_SPEC_H */
diff --git a/examples/vhost_scsi/vhost_scsi.c b/examples/vhost_scsi/vhost_scsi.c
deleted file mode 100644
index 2908ff6..0000000
--- a/examples/vhost_scsi/vhost_scsi.c
+++ /dev/null
@@ -1,482 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2017 Intel Corporation
- */
-
-#include <stdint.h>
-#include <unistd.h>
-#include <stdbool.h>
-#include <signal.h>
-#include <assert.h>
-#include <semaphore.h>
-#include <linux/virtio_scsi.h>
-#include <linux/virtio_ring.h>
-
-#include <rte_atomic.h>
-#include <rte_cycles.h>
-#include <rte_log.h>
-#include <rte_malloc.h>
-#include <rte_vhost.h>
-
-#include "vhost_scsi.h"
-#include "scsi_spec.h"
-
-#define VIRTIO_SCSI_FEATURES ((1 << VIRTIO_F_NOTIFY_ON_EMPTY) |\
-			      (1 << VIRTIO_SCSI_F_INOUT) |\
-			      (1 << VIRTIO_SCSI_F_CHANGE))
-
-/* Path to folder where character device will be created. Can be set by user. */
-static char dev_pathname[PATH_MAX] = "";
-
-static struct vhost_scsi_ctrlr *g_vhost_ctrlr;
-static int g_should_stop;
-static sem_t exit_sem;
-
-static struct vhost_scsi_ctrlr *
-vhost_scsi_ctrlr_find(__rte_unused const char *ctrlr_name)
-{
-	/* currently we only support 1 socket file fd */
-	return g_vhost_ctrlr;
-}
-
-static uint64_t gpa_to_vva(int vid, uint64_t gpa, uint64_t *len)
-{
-	char path[PATH_MAX];
-	struct vhost_scsi_ctrlr *ctrlr;
-	int ret = 0;
-
-	ret = rte_vhost_get_ifname(vid, path, PATH_MAX);
-	if (ret) {
-		fprintf(stderr, "Cannot get socket name\n");
-		assert(ret != 0);
-	}
-
-	ctrlr = vhost_scsi_ctrlr_find(path);
-	if (!ctrlr) {
-		fprintf(stderr, "Controller is not ready\n");
-		assert(ctrlr != NULL);
-	}
-
-	assert(ctrlr->mem != NULL);
-
-	return rte_vhost_va_from_guest_pa(ctrlr->mem, gpa, len);
-}
-
-static struct vring_desc *
-descriptor_get_next(struct vring_desc *vq_desc, struct vring_desc *cur_desc)
-{
-	return &vq_desc[cur_desc->next];
-}
-
-static bool
-descriptor_has_next(struct vring_desc *cur_desc)
-{
-	return !!(cur_desc->flags & VRING_DESC_F_NEXT);
-}
-
-static bool
-descriptor_is_wr(struct vring_desc *cur_desc)
-{
-	return !!(cur_desc->flags & VRING_DESC_F_WRITE);
-}
-
-static void
-submit_completion(struct vhost_scsi_task *task, uint32_t q_idx)
-{
-	struct rte_vhost_vring *vq;
-	struct vring_used *used;
-
-	vq = task->vq;
-	used = vq->used;
-	/* Fill out the next entry in the "used" ring.  id = the
-	 * index of the descriptor that contained the SCSI request.
-	 * len = the total amount of data transferred for the SCSI
-	 * request. We must report the correct len, for variable
-	 * length SCSI CDBs, where we may return less data than
-	 * allocated by the guest VM.
-	 */
-	used->ring[used->idx & (vq->size - 1)].id = task->req_idx;
-	used->ring[used->idx & (vq->size - 1)].len = task->data_len;
-	used->idx++;
-
-	/* Send an interrupt back to the guest VM so that it knows
-	 * a completion is ready to be processed.
-	 */
-	rte_vhost_vring_call(task->bdev->vid, q_idx);
-}
-
-static void
-vhost_process_read_payload_chain(struct vhost_scsi_task *task)
-{
-	void *data;
-	uint64_t chunck_len;
-
-	task->iovs_cnt = 0;
-	chunck_len = task->desc->len;
-	task->resp = (void *)(uintptr_t)gpa_to_vva(task->bdev->vid,
-						   task->desc->addr,
-						   &chunck_len);
-	if (!task->resp || chunck_len != task->desc->len) {
-		fprintf(stderr, "failed to translate desc address.\n");
-		return;
-	}
-
-	while (descriptor_has_next(task->desc)) {
-		task->desc = descriptor_get_next(task->vq->desc, task->desc);
-		chunck_len = task->desc->len;
-		data = (void *)(uintptr_t)gpa_to_vva(task->bdev->vid,
-						     task->desc->addr,
-							 &chunck_len);
-		if (!data || chunck_len != task->desc->len) {
-			fprintf(stderr, "failed to translate desc address.\n");
-			return;
-		}
-
-		task->iovs[task->iovs_cnt].iov_base = data;
-		task->iovs[task->iovs_cnt].iov_len = task->desc->len;
-		task->data_len += task->desc->len;
-		task->iovs_cnt++;
-	}
-}
-
-static void
-vhost_process_write_payload_chain(struct vhost_scsi_task *task)
-{
-	void *data;
-	uint64_t chunck_len;
-
-	task->iovs_cnt = 0;
-
-	do {
-		chunck_len = task->desc->len;
-		data = (void *)(uintptr_t)gpa_to_vva(task->bdev->vid,
-						     task->desc->addr,
-							 &chunck_len);
-		if (!data || chunck_len != task->desc->len) {
-			fprintf(stderr, "failed to translate desc address.\n");
-			return;
-		}
-
-		task->iovs[task->iovs_cnt].iov_base = data;
-		task->iovs[task->iovs_cnt].iov_len = task->desc->len;
-		task->data_len += task->desc->len;
-		task->iovs_cnt++;
-		task->desc = descriptor_get_next(task->vq->desc, task->desc);
-	} while (descriptor_has_next(task->desc));
-
-	chunck_len = task->desc->len;
-	task->resp = (void *)(uintptr_t)gpa_to_vva(task->bdev->vid,
-						   task->desc->addr,
-						   &chunck_len);
-	if (!task->resp || chunck_len != task->desc->len)
-		fprintf(stderr, "failed to translate desc address.\n");
-}
-
-static struct vhost_block_dev *
-vhost_scsi_bdev_construct(const char *bdev_name, const char *bdev_serial,
-			  uint32_t blk_size, uint64_t blk_cnt,
-			  bool wce_enable)
-{
-	struct vhost_block_dev *bdev;
-
-	bdev = rte_zmalloc(NULL, sizeof(*bdev), RTE_CACHE_LINE_SIZE);
-	if (!bdev)
-		return NULL;
-
-	strncpy(bdev->name, bdev_name, sizeof(bdev->name));
-	strncpy(bdev->product_name, bdev_serial, sizeof(bdev->product_name));
-	bdev->blocklen = blk_size;
-	bdev->blockcnt = blk_cnt;
-	bdev->write_cache = wce_enable;
-
-	/* use memory as disk storage space */
-	bdev->data = rte_zmalloc(NULL, blk_cnt * blk_size, 0);
-	if (!bdev->data) {
-		fprintf(stderr, "no enough reseverd huge memory for disk\n");
-		return NULL;
-	}
-
-	return bdev;
-}
-
-static void
-process_requestq(struct vhost_scsi_ctrlr *ctrlr, uint32_t q_idx)
-{
-	int ret;
-	struct vhost_scsi_queue *scsi_vq;
-	struct rte_vhost_vring *vq;
-
-	scsi_vq = &ctrlr->bdev->queues[q_idx];
-	vq = &scsi_vq->vq;
-	ret = rte_vhost_get_vhost_vring(ctrlr->bdev->vid, q_idx, vq);
-	assert(ret == 0);
-
-	while (vq->avail->idx != scsi_vq->last_used_idx) {
-		int req_idx;
-		uint16_t last_idx;
-		struct vhost_scsi_task *task;
-		uint64_t chunck_len;
-
-		last_idx = scsi_vq->last_used_idx & (vq->size - 1);
-		req_idx = vq->avail->ring[last_idx];
-
-		task = rte_zmalloc(NULL, sizeof(*task), 0);
-		assert(task != NULL);
-
-		task->ctrlr = ctrlr;
-		task->bdev = ctrlr->bdev;
-		task->vq = vq;
-		task->req_idx = req_idx;
-		task->desc = &task->vq->desc[task->req_idx];
-
-		/* does not support indirect descriptors */
-		assert((task->desc->flags & VRING_DESC_F_INDIRECT) == 0);
-		scsi_vq->last_used_idx++;
-
-		chunck_len = task->desc->len;
-		task->req = (void *)(uintptr_t)gpa_to_vva(task->bdev->vid,
-							  task->desc->addr,
-							  &chunck_len);
-		if (!task->req || chunck_len != task->desc->len) {
-			fprintf(stderr, "failed to translate desc address.\n");
-			return;
-		}
-
-		task->desc = descriptor_get_next(task->vq->desc, task->desc);
-		if (!descriptor_has_next(task->desc)) {
-			task->dxfer_dir = SCSI_DIR_NONE;
-			chunck_len = task->desc->len;
-			task->resp = (void *)(uintptr_t)
-					      gpa_to_vva(task->bdev->vid,
-							 task->desc->addr,
-							 &chunck_len);
-			if (!task->resp || chunck_len != task->desc->len) {
-				fprintf(stderr, "failed to translate desc address.\n");
-				return;
-			}
-		} else if (!descriptor_is_wr(task->desc)) {
-			task->dxfer_dir = SCSI_DIR_TO_DEV;
-			vhost_process_write_payload_chain(task);
-		} else {
-			task->dxfer_dir = SCSI_DIR_FROM_DEV;
-			vhost_process_read_payload_chain(task);
-		}
-
-		ret = vhost_bdev_process_scsi_commands(ctrlr->bdev, task);
-		if (ret) {
-			/* invalid response */
-			task->resp->response = VIRTIO_SCSI_S_BAD_TARGET;
-		} else {
-			/* successfully */
-			task->resp->response = VIRTIO_SCSI_S_OK;
-			task->resp->status = 0;
-			task->resp->resid = 0;
-		}
-		submit_completion(task, q_idx);
-		rte_free(task);
-	}
-}
-
-/* Main framework for processing IOs */
-static void *
-ctrlr_worker(void *arg)
-{
-	uint32_t idx, num;
-	struct vhost_scsi_ctrlr *ctrlr = (struct vhost_scsi_ctrlr *)arg;
-	cpu_set_t cpuset;
-	pthread_t thread;
-
-	thread = pthread_self();
-	CPU_ZERO(&cpuset);
-	CPU_SET(0, &cpuset);
-	pthread_setaffinity_np(thread, sizeof(cpu_set_t), &cpuset);
-
-	num =  rte_vhost_get_vring_num(ctrlr->bdev->vid);
-	fprintf(stdout, "Ctrlr Worker Thread Started with %u Vring\n", num);
-
-	if (num != NUM_OF_SCSI_QUEUES) {
-		fprintf(stderr, "Only 1 IO queue are supported\n");
-		exit(0);
-	}
-
-	while (!g_should_stop && ctrlr->bdev != NULL) {
-		/* At least 3 vrings, currently only can support 1 IO queue
-		 * Queue 2 for IO queue, does not support TMF and hotplug
-		 * for the example application now
-		 */
-		for (idx = 2; idx < num; idx++)
-			process_requestq(ctrlr, idx);
-	}
-
-	fprintf(stdout, "Ctrlr Worker Thread Exiting\n");
-	sem_post(&exit_sem);
-	return NULL;
-}
-
-static int
-new_device(int vid)
-{
-	char path[PATH_MAX];
-	struct vhost_scsi_ctrlr *ctrlr;
-	struct vhost_scsi_queue *scsi_vq;
-	struct rte_vhost_vring *vq;
-	pthread_t tid;
-	int i, ret;
-
-	ret = rte_vhost_get_ifname(vid, path, PATH_MAX);
-	if (ret) {
-		fprintf(stderr, "Cannot get socket name\n");
-		return -1;
-	}
-
-	ctrlr = vhost_scsi_ctrlr_find(path);
-	if (!ctrlr) {
-		fprintf(stderr, "Controller is not ready\n");
-		return -1;
-	}
-
-	ret = rte_vhost_get_mem_table(vid, &ctrlr->mem);
-	if (ret) {
-		fprintf(stderr, "Get Controller memory region failed\n");
-		return -1;
-	}
-	assert(ctrlr->mem != NULL);
-
-	/* hardcoded block device information with 128MiB */
-	ctrlr->bdev = vhost_scsi_bdev_construct("malloc0", "vhost_scsi_malloc0",
-						4096, 32768, 0);
-	if (!ctrlr->bdev)
-		return -1;
-
-	ctrlr->bdev->vid = vid;
-
-	/* Disable Notifications */
-	for (i = 0; i < NUM_OF_SCSI_QUEUES; i++) {
-		rte_vhost_enable_guest_notification(vid, i, 0);
-		/* restore used index */
-		scsi_vq = &ctrlr->bdev->queues[i];
-		vq = &scsi_vq->vq;
-		ret = rte_vhost_get_vhost_vring(ctrlr->bdev->vid, i, vq);
-		assert(ret == 0);
-		scsi_vq->last_used_idx = vq->used->idx;
-		scsi_vq->last_avail_idx = vq->used->idx;
-	}
-
-	g_should_stop = 0;
-	fprintf(stdout, "New Device %s, Device ID %d\n", path, vid);
-	if (pthread_create(&tid, NULL, &ctrlr_worker, ctrlr) < 0) {
-		fprintf(stderr, "Worker Thread Started Failed\n");
-		return -1;
-	}
-	pthread_detach(tid);
-	return 0;
-}
-
-static void
-destroy_device(int vid)
-{
-	char path[PATH_MAX];
-	struct vhost_scsi_ctrlr *ctrlr;
-
-	rte_vhost_get_ifname(vid, path, PATH_MAX);
-	fprintf(stdout, "Destroy %s Device ID %d\n", path, vid);
-	ctrlr = vhost_scsi_ctrlr_find(path);
-	if (!ctrlr) {
-		fprintf(stderr, "Destroy Ctrlr Failed\n");
-		return;
-	}
-	ctrlr->bdev = NULL;
-	g_should_stop = 1;
-
-	sem_wait(&exit_sem);
-}
-
-static const struct vhost_device_ops vhost_scsi_device_ops = {
-	.new_device =  new_device,
-	.destroy_device = destroy_device,
-};
-
-static struct vhost_scsi_ctrlr *
-vhost_scsi_ctrlr_construct(const char *ctrlr_name)
-{
-	int ret;
-	struct vhost_scsi_ctrlr *ctrlr;
-	char *path;
-	char cwd[PATH_MAX];
-
-	/* always use current directory */
-	path = getcwd(cwd, PATH_MAX);
-	if (!path) {
-		fprintf(stderr, "Cannot get current working directory\n");
-		return NULL;
-	}
-	snprintf(dev_pathname, sizeof(dev_pathname), "%s/%s", path, ctrlr_name);
-
-	if (access(dev_pathname, F_OK) != -1) {
-		if (unlink(dev_pathname) != 0)
-			rte_exit(EXIT_FAILURE, "Cannot remove %s.\n",
-				 dev_pathname);
-	}
-
-	if (rte_vhost_driver_register(dev_pathname, 0) != 0) {
-		fprintf(stderr, "socket %s already exists\n", dev_pathname);
-		return NULL;
-	}
-
-	fprintf(stdout, "socket file: %s created\n", dev_pathname);
-
-	ret = rte_vhost_driver_set_features(dev_pathname, VIRTIO_SCSI_FEATURES);
-	if (ret != 0) {
-		fprintf(stderr, "Set vhost driver features failed\n");
-		return NULL;
-	}
-
-	ctrlr = rte_zmalloc(NULL, sizeof(*ctrlr), RTE_CACHE_LINE_SIZE);
-	if (!ctrlr)
-		return NULL;
-
-	rte_vhost_driver_callback_register(dev_pathname,
-					   &vhost_scsi_device_ops);
-
-	return ctrlr;
-}
-
-static void
-signal_handler(__rte_unused int signum)
-{
-
-	if (access(dev_pathname, F_OK) == 0)
-		unlink(dev_pathname);
-	exit(0);
-}
-
-int main(int argc, char *argv[])
-{
-	int ret;
-
-	signal(SIGINT, signal_handler);
-
-	/* init EAL */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Error with EAL initialization\n");
-
-	g_vhost_ctrlr = vhost_scsi_ctrlr_construct("vhost.socket");
-	if (g_vhost_ctrlr == NULL) {
-		fprintf(stderr, "Construct vhost scsi controller failed\n");
-		return 0;
-	}
-
-	if (sem_init(&exit_sem, 0, 0) < 0) {
-		fprintf(stderr, "Error init exit_sem\n");
-		return -1;
-	}
-
-	rte_vhost_driver_start(dev_pathname);
-
-	/* loop for exit the application */
-	while (1)
-		sleep(1);
-
-	return 0;
-}
-
diff --git a/examples/vhost_scsi/vhost_scsi.h b/examples/vhost_scsi/vhost_scsi.h
deleted file mode 100644
index 7f98d8d..0000000
--- a/examples/vhost_scsi/vhost_scsi.h
+++ /dev/null
@@ -1,79 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2017 Intel Corporation
- */
-
-#ifndef _VHOST_SCSI_H_
-#define _VHOST_SCSI_H_
-
-#include <sys/uio.h>
-#include <stdint.h>
-#include <linux/virtio_scsi.h>
-#include <linux/virtio_ring.h>
-
-#include <rte_vhost.h>
-
-struct vhost_scsi_queue {
-	struct rte_vhost_vring vq;
-	uint16_t last_avail_idx;
-	uint16_t last_used_idx;
-};
-
-#define NUM_OF_SCSI_QUEUES 3
-
-struct vhost_block_dev {
-	/** ID for vhost library. */
-	int vid;
-	/** Queues for the block device */
-	struct vhost_scsi_queue queues[NUM_OF_SCSI_QUEUES];
-	/** Unique name for this block device. */
-	char name[64];
-
-	/** Unique product name for this kind of block device. */
-	char product_name[256];
-
-	/** Size in bytes of a logical block for the backend */
-	uint32_t blocklen;
-
-	/** Number of blocks */
-	uint64_t blockcnt;
-
-	/** write cache enabled, not used at the moment */
-	int write_cache;
-
-	/** use memory as disk storage space */
-	uint8_t *data;
-};
-
-struct vhost_scsi_ctrlr {
-	/** Only support 1 LUN for the example */
-	struct vhost_block_dev *bdev;
-	/** VM memory region */
-	struct rte_vhost_memory *mem;
-} __rte_cache_aligned;
-
-#define VHOST_SCSI_MAX_IOVS 128
-
-enum scsi_data_dir {
-	SCSI_DIR_NONE = 0,
-	SCSI_DIR_TO_DEV = 1,
-	SCSI_DIR_FROM_DEV = 2,
-};
-
-struct vhost_scsi_task {
-	int req_idx;
-	uint32_t dxfer_dir;
-	uint32_t data_len;
-	struct virtio_scsi_cmd_req *req;
-	struct virtio_scsi_cmd_resp *resp;
-	struct iovec iovs[VHOST_SCSI_MAX_IOVS];
-	uint32_t iovs_cnt;
-	struct vring_desc *desc;
-	struct rte_vhost_vring *vq;
-	struct vhost_block_dev *bdev;
-	struct vhost_scsi_ctrlr *ctrlr;
-};
-
-int vhost_bdev_process_scsi_commands(struct vhost_block_dev *bdev,
-				     struct vhost_scsi_task *task);
-
-#endif /* _VHOST_SCSI_H_ */
diff --git a/examples/vm_power_manager/Makefile b/examples/vm_power_manager/Makefile
deleted file mode 100644
index 608d0d9..0000000
--- a/examples/vm_power_manager/Makefile
+++ /dev/null
@@ -1,54 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-ifneq ($(shell pkg-config --atleast-version=0.9.3 libvirt; echo $$?), 0)
-$(error vm_power_manager requires libvirt >= 0.9.3)
-else
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-# binary name
-APP = vm_power_mgr
-
-# all source are stored in SRCS-y
-SRCS-y := main.c vm_power_cli.c power_manager.c channel_manager.c
-SRCS-y += channel_monitor.c
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += -O3 -I$(RTE_SDK)/lib/librte_power/
-CFLAGS += $(WERROR_FLAGS)
-
-LDLIBS += -lvirt
-
-ifeq ($(CONFIG_RTE_BUILD_SHARED_LIB),y)
-
-ifeq ($(CONFIG_RTE_LIBRTE_IXGBE_PMD),y)
-LDLIBS += -lrte_pmd_ixgbe
-endif
-
-ifeq ($(CONFIG_RTE_LIBRTE_I40E_PMD),y)
-LDLIBS += -lrte_pmd_i40e
-endif
-
-ifeq ($(CONFIG_RTE_LIBRTE_BNXT_PMD),y)
-LDLIBS += -lrte_pmd_bnxt
-endif
-
-endif
-
-# workaround for a gcc bug with noreturn attribute
-# http://gcc.gnu.org/bugzilla/show_bug.cgi?id=12603
-ifeq ($(CONFIG_RTE_TOOLCHAIN_GCC),y)
-CFLAGS_main.o += -Wno-return-type
-endif
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-
-endif # libvirt check
diff --git a/examples/vm_power_manager/channel_manager.c b/examples/vm_power_manager/channel_manager.c
deleted file mode 100644
index 927fc35..0000000
--- a/examples/vm_power_manager/channel_manager.c
+++ /dev/null
@@ -1,844 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <sys/un.h>
-#include <fcntl.h>
-#include <unistd.h>
-#include <inttypes.h>
-#include <dirent.h>
-#include <errno.h>
-
-#include <sys/queue.h>
-#include <sys/types.h>
-#include <sys/socket.h>
-#include <sys/select.h>
-
-#include <rte_malloc.h>
-#include <rte_memory.h>
-#include <rte_mempool.h>
-#include <rte_log.h>
-#include <rte_atomic.h>
-#include <rte_spinlock.h>
-
-#include <libvirt/libvirt.h>
-
-#include "channel_manager.h"
-#include "channel_commands.h"
-#include "channel_monitor.h"
-
-
-#define RTE_LOGTYPE_CHANNEL_MANAGER RTE_LOGTYPE_USER1
-
-#define ITERATIVE_BITMASK_CHECK_64(mask_u64b, i) \
-		for (i = 0; mask_u64b; mask_u64b &= ~(1ULL << i++)) \
-		if ((mask_u64b >> i) & 1) \
-
-/* Global pointer to libvirt connection */
-static virConnectPtr global_vir_conn_ptr;
-
-static unsigned char *global_cpumaps;
-static virVcpuInfo *global_vircpuinfo;
-static size_t global_maplen;
-
-static unsigned global_n_host_cpus;
-
-/*
- * Represents a single Virtual Machine
- */
-struct virtual_machine_info {
-	char name[CHANNEL_MGR_MAX_NAME_LEN];
-	rte_atomic64_t pcpu_mask[CHANNEL_CMDS_MAX_CPUS];
-	struct channel_info *channels[CHANNEL_CMDS_MAX_VM_CHANNELS];
-	uint64_t channel_mask;
-	uint8_t num_channels;
-	enum vm_status status;
-	virDomainPtr domainPtr;
-	virDomainInfo info;
-	rte_spinlock_t config_spinlock;
-	LIST_ENTRY(virtual_machine_info) vms_info;
-};
-
-LIST_HEAD(, virtual_machine_info) vm_list_head;
-
-static struct virtual_machine_info *
-find_domain_by_name(const char *name)
-{
-	struct virtual_machine_info *info;
-	LIST_FOREACH(info, &vm_list_head, vms_info) {
-		if (!strncmp(info->name, name, CHANNEL_MGR_MAX_NAME_LEN-1))
-			return info;
-	}
-	return NULL;
-}
-
-static int
-update_pcpus_mask(struct virtual_machine_info *vm_info)
-{
-	virVcpuInfoPtr cpuinfo;
-	unsigned i, j;
-	int n_vcpus;
-	uint64_t mask;
-
-	memset(global_cpumaps, 0, CHANNEL_CMDS_MAX_CPUS*global_maplen);
-
-	if (!virDomainIsActive(vm_info->domainPtr)) {
-		n_vcpus = virDomainGetVcpuPinInfo(vm_info->domainPtr,
-				vm_info->info.nrVirtCpu, global_cpumaps, global_maplen,
-				VIR_DOMAIN_AFFECT_CONFIG);
-		if (n_vcpus < 0) {
-			RTE_LOG(ERR, CHANNEL_MANAGER, "Error getting vCPU info for "
-					"in-active VM '%s'\n", vm_info->name);
-			return -1;
-		}
-		goto update_pcpus;
-	}
-
-	memset(global_vircpuinfo, 0, sizeof(*global_vircpuinfo)*
-			CHANNEL_CMDS_MAX_CPUS);
-
-	cpuinfo = global_vircpuinfo;
-
-	n_vcpus = virDomainGetVcpus(vm_info->domainPtr, cpuinfo,
-			CHANNEL_CMDS_MAX_CPUS, global_cpumaps, global_maplen);
-	if (n_vcpus < 0) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Error getting vCPU info for "
-				"active VM '%s'\n", vm_info->name);
-		return -1;
-	}
-update_pcpus:
-	if (n_vcpus >= CHANNEL_CMDS_MAX_CPUS) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Number of vCPUS(%u) is out of range "
-				"0...%d\n", n_vcpus, CHANNEL_CMDS_MAX_CPUS-1);
-		return -1;
-	}
-	if (n_vcpus != vm_info->info.nrVirtCpu) {
-		RTE_LOG(INFO, CHANNEL_MANAGER, "Updating the number of vCPUs for VM '%s"
-				" from %d -> %d\n", vm_info->name, vm_info->info.nrVirtCpu,
-				n_vcpus);
-		vm_info->info.nrVirtCpu = n_vcpus;
-	}
-	for (i = 0; i < vm_info->info.nrVirtCpu; i++) {
-		mask = 0;
-		for (j = 0; j < global_n_host_cpus; j++) {
-			if (VIR_CPU_USABLE(global_cpumaps, global_maplen, i, j) > 0) {
-				mask |= 1ULL << j;
-			}
-		}
-		rte_atomic64_set(&vm_info->pcpu_mask[i], mask);
-	}
-	return 0;
-}
-
-int
-set_pcpus_mask(char *vm_name, unsigned vcpu, uint64_t core_mask)
-{
-	unsigned i = 0;
-	int flags = VIR_DOMAIN_AFFECT_LIVE|VIR_DOMAIN_AFFECT_CONFIG;
-	struct virtual_machine_info *vm_info;
-	uint64_t mask = core_mask;
-
-	if (vcpu >= CHANNEL_CMDS_MAX_CPUS) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "vCPU(%u) exceeds max allowable(%d)\n",
-				vcpu, CHANNEL_CMDS_MAX_CPUS-1);
-		return -1;
-	}
-
-	vm_info = find_domain_by_name(vm_name);
-	if (vm_info == NULL) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "VM '%s' not found\n", vm_name);
-		return -1;
-	}
-
-	if (!virDomainIsActive(vm_info->domainPtr)) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Unable to set vCPU(%u) to pCPU "
-				"mask(0x%"PRIx64") for VM '%s', VM is not active\n",
-				vcpu, core_mask, vm_info->name);
-		return -1;
-	}
-
-	if (vcpu >= vm_info->info.nrVirtCpu) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "vCPU(%u) exceeds the assigned number of "
-				"vCPUs(%u)\n", vcpu, vm_info->info.nrVirtCpu);
-		return -1;
-	}
-	memset(global_cpumaps, 0 , CHANNEL_CMDS_MAX_CPUS * global_maplen);
-	ITERATIVE_BITMASK_CHECK_64(mask, i) {
-		VIR_USE_CPU(global_cpumaps, i);
-		if (i >= global_n_host_cpus) {
-			RTE_LOG(ERR, CHANNEL_MANAGER, "CPU(%u) exceeds the available "
-					"number of CPUs(%u)\n", i, global_n_host_cpus);
-			return -1;
-		}
-	}
-	if (virDomainPinVcpuFlags(vm_info->domainPtr, vcpu, global_cpumaps,
-			global_maplen, flags) < 0) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Unable to set vCPU(%u) to pCPU "
-				"mask(0x%"PRIx64") for VM '%s'\n", vcpu, core_mask,
-				vm_info->name);
-		return -1;
-	}
-	rte_atomic64_set(&vm_info->pcpu_mask[vcpu], core_mask);
-	return 0;
-
-}
-
-int
-set_pcpu(char *vm_name, unsigned vcpu, unsigned core_num)
-{
-	uint64_t mask = 1ULL << core_num;
-
-	return set_pcpus_mask(vm_name, vcpu, mask);
-}
-
-uint64_t
-get_pcpus_mask(struct channel_info *chan_info, unsigned vcpu)
-{
-	struct virtual_machine_info *vm_info =
-			(struct virtual_machine_info *)chan_info->priv_info;
-	return rte_atomic64_read(&vm_info->pcpu_mask[vcpu]);
-}
-
-static inline int
-channel_exists(struct virtual_machine_info *vm_info, unsigned channel_num)
-{
-	rte_spinlock_lock(&(vm_info->config_spinlock));
-	if (vm_info->channel_mask & (1ULL << channel_num)) {
-		rte_spinlock_unlock(&(vm_info->config_spinlock));
-		return 1;
-	}
-	rte_spinlock_unlock(&(vm_info->config_spinlock));
-	return 0;
-}
-
-
-
-static int
-open_non_blocking_channel(struct channel_info *info)
-{
-	int ret, flags;
-	struct sockaddr_un sock_addr;
-	fd_set soc_fd_set;
-	struct timeval tv;
-
-	info->fd = socket(AF_UNIX, SOCK_STREAM, 0);
-	if (info->fd == -1) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Error(%s) creating socket for '%s'\n",
-				strerror(errno),
-				info->channel_path);
-		return -1;
-	}
-	sock_addr.sun_family = AF_UNIX;
-	memcpy(&sock_addr.sun_path, info->channel_path,
-			strlen(info->channel_path)+1);
-
-	/* Get current flags */
-	flags = fcntl(info->fd, F_GETFL, 0);
-	if (flags < 0) {
-		RTE_LOG(WARNING, CHANNEL_MANAGER, "Error(%s) fcntl get flags socket for"
-				"'%s'\n", strerror(errno), info->channel_path);
-		return 1;
-	}
-	/* Set to Non Blocking */
-	flags |= O_NONBLOCK;
-	if (fcntl(info->fd, F_SETFL, flags) < 0) {
-		RTE_LOG(WARNING, CHANNEL_MANAGER, "Error(%s) setting non-blocking "
-				"socket for '%s'\n", strerror(errno), info->channel_path);
-		return -1;
-	}
-	ret = connect(info->fd, (struct sockaddr *)&sock_addr,
-			sizeof(sock_addr));
-	if (ret < 0) {
-		/* ECONNREFUSED error is given when VM is not active */
-		if (errno == ECONNREFUSED) {
-			RTE_LOG(WARNING, CHANNEL_MANAGER, "VM is not active or has not "
-					"activated its endpoint to channel %s\n",
-					info->channel_path);
-			return -1;
-		}
-		/* Wait for tv_sec if in progress */
-		else if (errno == EINPROGRESS) {
-			tv.tv_sec = 2;
-			tv.tv_usec = 0;
-			FD_ZERO(&soc_fd_set);
-			FD_SET(info->fd, &soc_fd_set);
-			if (select(info->fd+1, NULL, &soc_fd_set, NULL, &tv) > 0) {
-				RTE_LOG(WARNING, CHANNEL_MANAGER, "Timeout or error on channel "
-						"'%s'\n", info->channel_path);
-				return -1;
-			}
-		} else {
-			/* Any other error */
-			RTE_LOG(WARNING, CHANNEL_MANAGER, "Error(%s) connecting socket"
-					" for '%s'\n", strerror(errno), info->channel_path);
-			return -1;
-		}
-	}
-	return 0;
-}
-
-static int
-setup_channel_info(struct virtual_machine_info **vm_info_dptr,
-		struct channel_info **chan_info_dptr, unsigned channel_num)
-{
-	struct channel_info *chan_info = *chan_info_dptr;
-	struct virtual_machine_info *vm_info = *vm_info_dptr;
-
-	chan_info->channel_num = channel_num;
-	chan_info->priv_info = (void *)vm_info;
-	chan_info->status = CHANNEL_MGR_CHANNEL_DISCONNECTED;
-	if (open_non_blocking_channel(chan_info) < 0) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Could not open channel: "
-				"'%s' for VM '%s'\n",
-				chan_info->channel_path, vm_info->name);
-		return -1;
-	}
-	if (add_channel_to_monitor(&chan_info) < 0) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Could add channel: "
-				"'%s' to epoll ctl for VM '%s'\n",
-				chan_info->channel_path, vm_info->name);
-		return -1;
-
-	}
-	rte_spinlock_lock(&(vm_info->config_spinlock));
-	vm_info->num_channels++;
-	vm_info->channel_mask |= 1ULL << channel_num;
-	vm_info->channels[channel_num] = chan_info;
-	chan_info->status = CHANNEL_MGR_CHANNEL_CONNECTED;
-	rte_spinlock_unlock(&(vm_info->config_spinlock));
-	return 0;
-}
-
-int
-add_all_channels(const char *vm_name)
-{
-	DIR *d;
-	struct dirent *dir;
-	struct virtual_machine_info *vm_info;
-	struct channel_info *chan_info;
-	char *token, *remaining, *tail_ptr;
-	char socket_name[PATH_MAX];
-	unsigned channel_num;
-	int num_channels_enabled = 0;
-
-	/* verify VM exists */
-	vm_info = find_domain_by_name(vm_name);
-	if (vm_info == NULL) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "VM: '%s' not found"
-				" during channel discovery\n", vm_name);
-		return 0;
-	}
-	if (!virDomainIsActive(vm_info->domainPtr)) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "VM: '%s' is not active\n", vm_name);
-		vm_info->status = CHANNEL_MGR_VM_INACTIVE;
-		return 0;
-	}
-	d = opendir(CHANNEL_MGR_SOCKET_PATH);
-	if (d == NULL) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Error opening directory '%s': %s\n",
-				CHANNEL_MGR_SOCKET_PATH, strerror(errno));
-		return -1;
-	}
-	while ((dir = readdir(d)) != NULL) {
-		if (!strncmp(dir->d_name, ".", 1) ||
-				!strncmp(dir->d_name, "..", 2))
-			continue;
-
-		snprintf(socket_name, sizeof(socket_name), "%s", dir->d_name);
-		remaining = socket_name;
-		/* Extract vm_name from "<vm_name>.<channel_num>" */
-		token = strsep(&remaining, ".");
-		if (remaining == NULL)
-			continue;
-		if (strncmp(vm_name, token, CHANNEL_MGR_MAX_NAME_LEN))
-			continue;
-
-		/* remaining should contain only <channel_num> */
-		errno = 0;
-		channel_num = (unsigned)strtol(remaining, &tail_ptr, 0);
-		if ((errno != 0) || (remaining[0] == '\0') ||
-				tail_ptr == NULL || (*tail_ptr != '\0')) {
-			RTE_LOG(WARNING, CHANNEL_MANAGER, "Malformed channel name"
-					"'%s' found it should be in the form of "
-					"'<guest_name>.<channel_num>(decimal)'\n",
-					dir->d_name);
-			continue;
-		}
-		if (channel_num >= CHANNEL_CMDS_MAX_VM_CHANNELS) {
-			RTE_LOG(WARNING, CHANNEL_MANAGER, "Channel number(%u) is "
-					"greater than max allowable: %d, skipping '%s%s'\n",
-					channel_num, CHANNEL_CMDS_MAX_VM_CHANNELS-1,
-					CHANNEL_MGR_SOCKET_PATH, dir->d_name);
-			continue;
-		}
-		/* if channel has not been added previously */
-		if (channel_exists(vm_info, channel_num))
-			continue;
-
-		chan_info = rte_malloc(NULL, sizeof(*chan_info),
-				RTE_CACHE_LINE_SIZE);
-		if (chan_info == NULL) {
-			RTE_LOG(ERR, CHANNEL_MANAGER, "Error allocating memory for "
-				"channel '%s%s'\n", CHANNEL_MGR_SOCKET_PATH, dir->d_name);
-			continue;
-		}
-
-		snprintf(chan_info->channel_path,
-				sizeof(chan_info->channel_path), "%s%s",
-				CHANNEL_MGR_SOCKET_PATH, dir->d_name);
-
-		if (setup_channel_info(&vm_info, &chan_info, channel_num) < 0) {
-			rte_free(chan_info);
-			continue;
-		}
-
-		num_channels_enabled++;
-	}
-	closedir(d);
-	return num_channels_enabled;
-}
-
-int
-add_channels(const char *vm_name, unsigned *channel_list,
-		unsigned len_channel_list)
-{
-	struct virtual_machine_info *vm_info;
-	struct channel_info *chan_info;
-	char socket_path[PATH_MAX];
-	unsigned i;
-	int num_channels_enabled = 0;
-
-	vm_info = find_domain_by_name(vm_name);
-	if (vm_info == NULL) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Unable to add channels: VM '%s' "
-				"not found\n", vm_name);
-		return 0;
-	}
-
-	if (!virDomainIsActive(vm_info->domainPtr)) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "VM: '%s' is not active\n", vm_name);
-		vm_info->status = CHANNEL_MGR_VM_INACTIVE;
-		return 0;
-	}
-
-	for (i = 0; i < len_channel_list; i++) {
-
-		if (channel_list[i] >= CHANNEL_CMDS_MAX_VM_CHANNELS) {
-			RTE_LOG(INFO, CHANNEL_MANAGER, "Channel(%u) is out of range "
-							"0...%d\n", channel_list[i],
-							CHANNEL_CMDS_MAX_VM_CHANNELS-1);
-			continue;
-		}
-		if (channel_exists(vm_info, channel_list[i])) {
-			RTE_LOG(INFO, CHANNEL_MANAGER, "Channel already exists, skipping  "
-					"'%s.%u'\n", vm_name, i);
-			continue;
-		}
-
-		snprintf(socket_path, sizeof(socket_path), "%s%s.%u",
-				CHANNEL_MGR_SOCKET_PATH, vm_name, channel_list[i]);
-		errno = 0;
-		if (access(socket_path, F_OK) < 0) {
-			RTE_LOG(ERR, CHANNEL_MANAGER, "Channel path '%s' error: "
-					"%s\n", socket_path, strerror(errno));
-			continue;
-		}
-		chan_info = rte_malloc(NULL, sizeof(*chan_info),
-				RTE_CACHE_LINE_SIZE);
-		if (chan_info == NULL) {
-			RTE_LOG(ERR, CHANNEL_MANAGER, "Error allocating memory for "
-					"channel '%s'\n", socket_path);
-			continue;
-		}
-		snprintf(chan_info->channel_path,
-				sizeof(chan_info->channel_path), "%s%s.%u",
-				CHANNEL_MGR_SOCKET_PATH, vm_name, channel_list[i]);
-		if (setup_channel_info(&vm_info, &chan_info, channel_list[i]) < 0) {
-			rte_free(chan_info);
-			continue;
-		}
-		num_channels_enabled++;
-
-	}
-	return num_channels_enabled;
-}
-
-int
-remove_channel(struct channel_info **chan_info_dptr)
-{
-	struct virtual_machine_info *vm_info;
-	struct channel_info *chan_info = *chan_info_dptr;
-
-	close(chan_info->fd);
-
-	vm_info = (struct virtual_machine_info *)chan_info->priv_info;
-
-	rte_spinlock_lock(&(vm_info->config_spinlock));
-	vm_info->channel_mask &= ~(1ULL << chan_info->channel_num);
-	vm_info->num_channels--;
-	rte_spinlock_unlock(&(vm_info->config_spinlock));
-
-	rte_free(chan_info);
-	return 0;
-}
-
-int
-set_channel_status_all(const char *vm_name, enum channel_status status)
-{
-	struct virtual_machine_info *vm_info;
-	unsigned i;
-	uint64_t mask;
-	int num_channels_changed = 0;
-
-	if (!(status == CHANNEL_MGR_CHANNEL_CONNECTED ||
-			status == CHANNEL_MGR_CHANNEL_DISABLED)) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Channels can only be enabled or "
-				"disabled: Unable to change status for VM '%s'\n", vm_name);
-	}
-	vm_info = find_domain_by_name(vm_name);
-	if (vm_info == NULL) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Unable to disable channels: VM '%s' "
-				"not found\n", vm_name);
-		return 0;
-	}
-
-	rte_spinlock_lock(&(vm_info->config_spinlock));
-	mask = vm_info->channel_mask;
-	ITERATIVE_BITMASK_CHECK_64(mask, i) {
-		vm_info->channels[i]->status = status;
-		num_channels_changed++;
-	}
-	rte_spinlock_unlock(&(vm_info->config_spinlock));
-	return num_channels_changed;
-
-}
-
-int
-set_channel_status(const char *vm_name, unsigned *channel_list,
-		unsigned len_channel_list, enum channel_status status)
-{
-	struct virtual_machine_info *vm_info;
-	unsigned i;
-	int num_channels_changed = 0;
-
-	if (!(status == CHANNEL_MGR_CHANNEL_CONNECTED ||
-			status == CHANNEL_MGR_CHANNEL_DISABLED)) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Channels can only be enabled or "
-				"disabled: Unable to change status for VM '%s'\n", vm_name);
-	}
-	vm_info = find_domain_by_name(vm_name);
-	if (vm_info == NULL) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Unable to add channels: VM '%s' "
-				"not found\n", vm_name);
-		return 0;
-	}
-	for (i = 0; i < len_channel_list; i++) {
-		if (channel_exists(vm_info, channel_list[i])) {
-			rte_spinlock_lock(&(vm_info->config_spinlock));
-			vm_info->channels[channel_list[i]]->status = status;
-			rte_spinlock_unlock(&(vm_info->config_spinlock));
-			num_channels_changed++;
-		}
-	}
-	return num_channels_changed;
-}
-
-void
-get_all_vm(int *num_vm, int *num_vcpu)
-{
-
-	virNodeInfo node_info;
-	virDomainPtr *domptr;
-	uint64_t mask;
-	int i, ii, numVcpus[MAX_VCPUS], cpu, n_vcpus;
-	unsigned int jj;
-	const char *vm_name;
-	unsigned int domain_flags = VIR_CONNECT_LIST_DOMAINS_RUNNING |
-				VIR_CONNECT_LIST_DOMAINS_PERSISTENT;
-	unsigned int domain_flag = VIR_DOMAIN_VCPU_CONFIG;
-
-
-	memset(global_cpumaps, 0, CHANNEL_CMDS_MAX_CPUS*global_maplen);
-	if (virNodeGetInfo(global_vir_conn_ptr, &node_info)) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Unable to retrieve node Info\n");
-		return;
-	}
-
-	/* Returns number of pcpus */
-	global_n_host_cpus = (unsigned int)node_info.cpus;
-
-	/* Returns number of active domains */
-	*num_vm = virConnectListAllDomains(global_vir_conn_ptr, &domptr,
-					domain_flags);
-	if (*num_vm <= 0) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "No Active Domains Running\n");
-		return;
-	}
-
-	for (i = 0; i < *num_vm; i++) {
-
-		/* Get Domain Names */
-		vm_name = virDomainGetName(domptr[i]);
-		lvm_info[i].vm_name = vm_name;
-
-		/* Get Number of Vcpus */
-		numVcpus[i] = virDomainGetVcpusFlags(domptr[i], domain_flag);
-
-		/* Get Number of VCpus & VcpuPinInfo */
-		n_vcpus = virDomainGetVcpuPinInfo(domptr[i],
-				numVcpus[i], global_cpumaps,
-				global_maplen, domain_flag);
-
-		if ((int)n_vcpus > 0) {
-			*num_vcpu = n_vcpus;
-			lvm_info[i].num_cpus = n_vcpus;
-		}
-
-		/* Save pcpu in use by libvirt VMs */
-		for (ii = 0; ii < n_vcpus; ii++) {
-			mask = 0;
-			for (jj = 0; jj < global_n_host_cpus; jj++) {
-				if (VIR_CPU_USABLE(global_cpumaps,
-						global_maplen, ii, jj) > 0) {
-					mask |= 1ULL << jj;
-				}
-			}
-			ITERATIVE_BITMASK_CHECK_64(mask, cpu) {
-				lvm_info[i].pcpus[ii] = cpu;
-			}
-		}
-	}
-}
-
-int
-get_info_vm(const char *vm_name, struct vm_info *info)
-{
-	struct virtual_machine_info *vm_info;
-	unsigned i, channel_num = 0;
-	uint64_t mask;
-
-	vm_info = find_domain_by_name(vm_name);
-	if (vm_info == NULL) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "VM '%s' not found\n", vm_name);
-		return -1;
-	}
-	info->status = CHANNEL_MGR_VM_ACTIVE;
-	if (!virDomainIsActive(vm_info->domainPtr))
-		info->status = CHANNEL_MGR_VM_INACTIVE;
-
-	rte_spinlock_lock(&(vm_info->config_spinlock));
-
-	mask = vm_info->channel_mask;
-	ITERATIVE_BITMASK_CHECK_64(mask, i) {
-		info->channels[channel_num].channel_num = i;
-		memcpy(info->channels[channel_num].channel_path,
-				vm_info->channels[i]->channel_path, UNIX_PATH_MAX);
-		info->channels[channel_num].status = vm_info->channels[i]->status;
-		info->channels[channel_num].fd = vm_info->channels[i]->fd;
-		channel_num++;
-	}
-
-	info->num_channels = channel_num;
-	info->num_vcpus = vm_info->info.nrVirtCpu;
-	rte_spinlock_unlock(&(vm_info->config_spinlock));
-
-	memcpy(info->name, vm_info->name, sizeof(vm_info->name));
-	for (i = 0; i < info->num_vcpus; i++) {
-		info->pcpu_mask[i] = rte_atomic64_read(&vm_info->pcpu_mask[i]);
-	}
-	return 0;
-}
-
-int
-add_vm(const char *vm_name)
-{
-	struct virtual_machine_info *new_domain;
-	virDomainPtr dom_ptr;
-	int i;
-
-	if (find_domain_by_name(vm_name) != NULL) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Unable to add VM: VM '%s' "
-				"already exists\n", vm_name);
-		return -1;
-	}
-
-	if (global_vir_conn_ptr == NULL) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "No connection to hypervisor exists\n");
-		return -1;
-	}
-	dom_ptr = virDomainLookupByName(global_vir_conn_ptr, vm_name);
-	if (dom_ptr == NULL) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Error on VM lookup with libvirt: "
-				"VM '%s' not found\n", vm_name);
-		return -1;
-	}
-
-	new_domain = rte_malloc("virtual_machine_info", sizeof(*new_domain),
-			RTE_CACHE_LINE_SIZE);
-	if (new_domain == NULL) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Unable to allocate memory for VM "
-				"info\n");
-		return -1;
-	}
-	new_domain->domainPtr = dom_ptr;
-	if (virDomainGetInfo(new_domain->domainPtr, &new_domain->info) != 0) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Unable to get libvirt VM info\n");
-		rte_free(new_domain);
-		return -1;
-	}
-	if (new_domain->info.nrVirtCpu > CHANNEL_CMDS_MAX_CPUS) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Error the number of virtual CPUs(%u) is "
-				"greater than allowable(%d)\n", new_domain->info.nrVirtCpu,
-				CHANNEL_CMDS_MAX_CPUS);
-		rte_free(new_domain);
-		return -1;
-	}
-
-	for (i = 0; i < CHANNEL_CMDS_MAX_CPUS; i++) {
-		rte_atomic64_init(&new_domain->pcpu_mask[i]);
-	}
-	if (update_pcpus_mask(new_domain) < 0) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Error getting physical CPU pinning\n");
-		rte_free(new_domain);
-		return -1;
-	}
-	strncpy(new_domain->name, vm_name, sizeof(new_domain->name));
-	new_domain->name[sizeof(new_domain->name) - 1] = '\0';
-	new_domain->channel_mask = 0;
-	new_domain->num_channels = 0;
-
-	if (!virDomainIsActive(dom_ptr))
-		new_domain->status = CHANNEL_MGR_VM_INACTIVE;
-	else
-		new_domain->status = CHANNEL_MGR_VM_ACTIVE;
-
-	rte_spinlock_init(&(new_domain->config_spinlock));
-	LIST_INSERT_HEAD(&vm_list_head, new_domain, vms_info);
-	return 0;
-}
-
-int
-remove_vm(const char *vm_name)
-{
-	struct virtual_machine_info *vm_info = find_domain_by_name(vm_name);
-
-	if (vm_info == NULL) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Unable to remove VM: VM '%s' "
-				"not found\n", vm_name);
-		return -1;
-	}
-	rte_spinlock_lock(&vm_info->config_spinlock);
-	if (vm_info->num_channels != 0) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Unable to remove VM '%s', there are "
-				"%"PRId8" channels still active\n",
-				vm_name, vm_info->num_channels);
-		rte_spinlock_unlock(&vm_info->config_spinlock);
-		return -1;
-	}
-	LIST_REMOVE(vm_info, vms_info);
-	rte_spinlock_unlock(&vm_info->config_spinlock);
-	rte_free(vm_info);
-	return 0;
-}
-
-static void
-disconnect_hypervisor(void)
-{
-	if (global_vir_conn_ptr != NULL) {
-		virConnectClose(global_vir_conn_ptr);
-		global_vir_conn_ptr = NULL;
-	}
-}
-
-static int
-connect_hypervisor(const char *path)
-{
-	if (global_vir_conn_ptr != NULL) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Error connecting to %s, connection "
-				"already established\n", path);
-		return -1;
-	}
-	global_vir_conn_ptr = virConnectOpen(path);
-	if (global_vir_conn_ptr == NULL) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Error failed to open connection to "
-				"Hypervisor '%s'\n", path);
-		return -1;
-	}
-	return 0;
-}
-
-int
-channel_manager_init(const char *path)
-{
-	virNodeInfo info;
-
-	LIST_INIT(&vm_list_head);
-	if (connect_hypervisor(path) < 0) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Unable to initialize channel manager\n");
-		return -1;
-	}
-
-	global_maplen = VIR_CPU_MAPLEN(CHANNEL_CMDS_MAX_CPUS);
-
-	global_vircpuinfo = rte_zmalloc(NULL, sizeof(*global_vircpuinfo) *
-			CHANNEL_CMDS_MAX_CPUS, RTE_CACHE_LINE_SIZE);
-	if (global_vircpuinfo == NULL) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Error allocating memory for CPU Info\n");
-		goto error;
-	}
-	global_cpumaps = rte_zmalloc(NULL, CHANNEL_CMDS_MAX_CPUS * global_maplen,
-			RTE_CACHE_LINE_SIZE);
-	if (global_cpumaps == NULL) {
-		goto error;
-	}
-
-	if (virNodeGetInfo(global_vir_conn_ptr, &info)) {
-		RTE_LOG(ERR, CHANNEL_MANAGER, "Unable to retrieve node Info\n");
-		goto error;
-	}
-
-	global_n_host_cpus = (unsigned)info.cpus;
-
-	if (global_n_host_cpus > CHANNEL_CMDS_MAX_CPUS) {
-		RTE_LOG(WARNING, CHANNEL_MANAGER, "The number of host CPUs(%u) exceeds the "
-				"maximum of %u. No cores over %u should be used.\n",
-				global_n_host_cpus, CHANNEL_CMDS_MAX_CPUS,
-				CHANNEL_CMDS_MAX_CPUS - 1);
-		global_n_host_cpus = CHANNEL_CMDS_MAX_CPUS;
-	}
-
-	return 0;
-error:
-	disconnect_hypervisor();
-	return -1;
-}
-
-void
-channel_manager_exit(void)
-{
-	unsigned i;
-	uint64_t mask;
-	struct virtual_machine_info *vm_info;
-
-	LIST_FOREACH(vm_info, &vm_list_head, vms_info) {
-
-		rte_spinlock_lock(&(vm_info->config_spinlock));
-
-		mask = vm_info->channel_mask;
-		ITERATIVE_BITMASK_CHECK_64(mask, i) {
-			remove_channel_from_monitor(vm_info->channels[i]);
-			close(vm_info->channels[i]->fd);
-			rte_free(vm_info->channels[i]);
-		}
-		rte_spinlock_unlock(&(vm_info->config_spinlock));
-
-		LIST_REMOVE(vm_info, vms_info);
-		rte_free(vm_info);
-	}
-
-	rte_free(global_cpumaps);
-	rte_free(global_vircpuinfo);
-	disconnect_hypervisor();
-}
diff --git a/examples/vm_power_manager/channel_manager.h b/examples/vm_power_manager/channel_manager.h
deleted file mode 100644
index 872ec61..0000000
--- a/examples/vm_power_manager/channel_manager.h
+++ /dev/null
@@ -1,322 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#ifndef CHANNEL_MANAGER_H_
-#define CHANNEL_MANAGER_H_
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-#include <linux/limits.h>
-#include <sys/un.h>
-#include <rte_atomic.h>
-
-/* Maximum number of CPUs */
-#define CHANNEL_CMDS_MAX_CPUS        64
-#if CHANNEL_CMDS_MAX_CPUS > 64
-#error Maximum number of cores is 64, overflow is guaranteed to \
-    cause problems with VM Power Management
-#endif
-
-/* Maximum name length including '\0' terminator */
-#define CHANNEL_MGR_MAX_NAME_LEN    64
-
-/* Maximum number of channels to each Virtual Machine */
-#define CHANNEL_MGR_MAX_CHANNELS    64
-
-/* Hypervisor Path for libvirt(qemu/KVM) */
-#define CHANNEL_MGR_DEFAULT_HV_PATH "qemu:///system"
-
-/* File socket directory */
-#define CHANNEL_MGR_SOCKET_PATH     "/tmp/powermonitor/"
-
-#ifndef UNIX_PATH_MAX
-struct sockaddr_un _sockaddr_un;
-#define UNIX_PATH_MAX sizeof(_sockaddr_un.sun_path)
-#endif
-
-#define MAX_VMS 4
-#define MAX_VCPUS 20
-
-
-struct libvirt_vm_info {
-	const char *vm_name;
-	unsigned int pcpus[MAX_VCPUS];
-	uint8_t num_cpus;
-};
-
-struct libvirt_vm_info lvm_info[MAX_VMS];
-/* Communication Channel Status */
-enum channel_status { CHANNEL_MGR_CHANNEL_DISCONNECTED = 0,
-	CHANNEL_MGR_CHANNEL_CONNECTED,
-	CHANNEL_MGR_CHANNEL_DISABLED,
-	CHANNEL_MGR_CHANNEL_PROCESSING};
-
-/* VM libvirt(qemu/KVM) connection status */
-enum vm_status { CHANNEL_MGR_VM_INACTIVE = 0, CHANNEL_MGR_VM_ACTIVE};
-
-/*
- *  Represents a single and exclusive VM channel that exists between a guest and
- *  the host.
- */
-struct channel_info {
-	char channel_path[UNIX_PATH_MAX]; /**< Path to host socket */
-	volatile uint32_t status;    /**< Connection status(enum channel_status) */
-	int fd;                      /**< AF_UNIX socket fd */
-	unsigned channel_num;        /**< CHANNEL_MGR_SOCKET_PATH/<vm_name>.channel_num */
-	void *priv_info;             /**< Pointer to private info, do not modify */
-};
-
-/* Represents a single VM instance used to return internal information about
- * a VM */
-struct vm_info {
-	char name[CHANNEL_MGR_MAX_NAME_LEN];          /**< VM name */
-	enum vm_status status;                        /**< libvirt status */
-	uint64_t pcpu_mask[CHANNEL_CMDS_MAX_CPUS];    /**< pCPU mask for each vCPU */
-	unsigned num_vcpus;                           /**< number of vCPUS */
-	struct channel_info channels[CHANNEL_MGR_MAX_CHANNELS]; /**< Array of channel_info */
-	unsigned num_channels;                        /**< Number of channels */
-};
-
-/**
- * Initialize the Channel Manager resources and connect to the Hypervisor
- * specified in path.
- * This must be successfully called first before calling any other functions.
- * It must only be call once;
- *
- * @param path
- *  Must be a local path, e.g. qemu:///system.
- *
- * @return
- *  - 0 on success.
- *  - Negative on error.
- */
-int channel_manager_init(const char *path);
-
-/**
- * Free resources associated with the Channel Manager.
- *
- * @param path
- *  Must be a local path, e.g. qemu:///system.
- *
- * @return
- *  None
- */
-void channel_manager_exit(void);
-
-/**
- * Get the Physical CPU mask for VM lcore channel(vcpu), result is assigned to
- * core_mask.
- * It is not thread-safe.
- *
- * @param chan_info
- *  Pointer to struct channel_info
- *
- * @param vcpu
- *  The virtual CPU to query.
- *
- *
- * @return
- *  - 0 on error.
- *  - >0 on success.
- */
-uint64_t get_pcpus_mask(struct channel_info *chan_info, unsigned vcpu);
-
-/**
- * Set the Physical CPU mask for the specified vCPU.
- * It is not thread-safe.
- *
- * @param name
- *  Virtual Machine name to lookup
- *
- * @param vcpu
- *  The virtual CPU to set.
- *
- * @param core_mask
- *  The core mask of the physical CPU(s) to bind the vCPU
- *
- * @return
- *  - 0 on success.
- *  - Negative on error.
- */
-int set_pcpus_mask(char *vm_name, unsigned vcpu, uint64_t core_mask);
-
-/**
- * Set the Physical CPU for the specified vCPU.
- * It is not thread-safe.
- *
- * @param name
- *  Virtual Machine name to lookup
- *
- * @param vcpu
- *  The virtual CPU to set.
- *
- * @param core_num
- *  The core number of the physical CPU(s) to bind the vCPU
- *
- * @return
- *  - 0 on success.
- *  - Negative on error.
- */
-int set_pcpu(char *vm_name, unsigned vcpu, unsigned core_num);
-/**
- * Add a VM as specified by name to the Channel Manager. The name must
- * correspond to a valid libvirt domain name.
- * This is required prior to adding channels.
- * It is not thread-safe.
- *
- * @param name
- *  Virtual Machine name to lookup.
- *
- * @return
- *  - 0 on success.
- *  - Negative on error.
- */
-int add_vm(const char *name);
-
-/**
- * Remove a previously added Virtual Machine from the Channel Manager
- * It is not thread-safe.
- *
- * @param name
- *  Virtual Machine name to lookup.
- *
- * @return
- *  - 0 on success.
- *  - Negative on error.
- */
-int remove_vm(const char *name);
-
-/**
- * Add all available channels to the VM as specified by name.
- * Channels in the form of paths
- * (CHANNEL_MGR_SOCKET_PATH/<vm_name>.<channel_number>) will only be parsed.
- * It is not thread-safe.
- *
- * @param name
- *  Virtual Machine name to lookup.
- *
- * @return
- *  - N the number of channels added for the VM
- */
-int add_all_channels(const char *vm_name);
-
-/**
- * Add the channel numbers in channel_list to the domain specified by name.
- * Channels in the form of paths
- * (CHANNEL_MGR_SOCKET_PATH/<vm_name>.<channel_number>) will only be parsed.
- * It is not thread-safe.
- *
- * @param name
- *  Virtual Machine name to add channels.
- *
- * @param channel_list
- *  Pointer to list of unsigned integers, representing the channel number to add
- *  It must be allocated outside of this function.
- *
- * @param num_channels
- *  The amount of channel numbers in channel_list
- *
- * @return
- *  - N the number of channels added for the VM
- *  - 0 for error
- */
-int add_channels(const char *vm_name, unsigned *channel_list,
-		unsigned num_channels);
-
-/**
- * Remove a channel definition from the channel manager. This must only be
- * called from the channel monitor thread.
- *
- * @param chan_info
- *  Pointer to a valid struct channel_info.
- *
- * @return
- *  - 0 on success.
- *  - Negative on error.
- */
-int remove_channel(struct channel_info **chan_info_dptr);
-
-/**
- * For all channels associated with a Virtual Machine name, update the
- * connection status. Valid states are CHANNEL_MGR_CHANNEL_CONNECTED or
- * CHANNEL_MGR_CHANNEL_DISABLED only.
- *
- *
- * @param name
- *  Virtual Machine name to modify all channels.
- *
- * @param status
- *  The status to set each channel
- *
- * @param num_channels
- *  The amount of channel numbers in channel_list
- *
- * @return
- *  - N the number of channels added for the VM
- *  - 0 for error
- */
-int set_channel_status_all(const char *name, enum channel_status status);
-
-/**
- * For all channels in channel_list associated with a Virtual Machine name
- * update the connection status of each.
- * Valid states are CHANNEL_MGR_CHANNEL_CONNECTED or
- * CHANNEL_MGR_CHANNEL_DISABLED only.
- * It is not thread-safe.
- *
- * @param name
- *  Virtual Machine name to add channels.
- *
- * @param channel_list
- *  Pointer to list of unsigned integers, representing the channel numbers to
- *  modify.
- *  It must be allocated outside of this function.
- *
- * @param num_channels
- *  The amount of channel numbers in channel_list
- *
- * @return
- *  - N the number of channels modified for the VM
- *  - 0 for error
- */
-int set_channel_status(const char *vm_name, unsigned *channel_list,
-		unsigned len_channel_list, enum channel_status status);
-
-/**
- * Populates a pointer to struct vm_info associated with vm_name.
- *
- * @param vm_name
- *  The name of the virtual machine to lookup.
- *
- *  @param vm_info
- *   Pointer to a struct vm_info, this must be allocated prior to calling this
- *   function.
- *
- * @return
- *  - 0 on success.
- *  - Negative on error.
- */
-int get_info_vm(const char *vm_name, struct vm_info *info);
-
-/**
- * Populates a table with all domains running and their physical cpu.
- * All information is gathered through libvirt api.
- *
- * @param num_vm
- *  modified to store number of active VMs
- *
- * @param num_vcpu
-    modified to store number of vcpus active
- *
- * @return
- *   void
- */
-void get_all_vm(int *num_vm, int *num_vcpu);
-#ifdef __cplusplus
-}
-#endif
-
-#endif /* CHANNEL_MANAGER_H_ */
diff --git a/examples/vm_power_manager/channel_monitor.c b/examples/vm_power_manager/channel_monitor.c
deleted file mode 100644
index 73bddd9..0000000
--- a/examples/vm_power_manager/channel_monitor.c
+++ /dev/null
@@ -1,525 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <unistd.h>
-#include <stdio.h>
-#include <stdlib.h>
-#include <stdint.h>
-#include <signal.h>
-#include <errno.h>
-#include <string.h>
-#include <sys/types.h>
-#include <sys/epoll.h>
-#include <sys/queue.h>
-#include <sys/time.h>
-
-#include <rte_log.h>
-#include <rte_memory.h>
-#include <rte_malloc.h>
-#include <rte_atomic.h>
-#include <rte_cycles.h>
-#include <rte_ethdev.h>
-#include <rte_pmd_i40e.h>
-
-#include <libvirt/libvirt.h>
-#include "channel_monitor.h"
-#include "channel_commands.h"
-#include "channel_manager.h"
-#include "power_manager.h"
-
-#define RTE_LOGTYPE_CHANNEL_MONITOR RTE_LOGTYPE_USER1
-
-#define MAX_EVENTS 256
-
-uint64_t vsi_pkt_count_prev[384];
-uint64_t rdtsc_prev[384];
-
-double time_period_ms = 1;
-static volatile unsigned run_loop = 1;
-static int global_event_fd;
-static unsigned int policy_is_set;
-static struct epoll_event *global_events_list;
-static struct policy policies[MAX_VMS];
-
-void channel_monitor_exit(void)
-{
-	run_loop = 0;
-	rte_free(global_events_list);
-}
-
-static void
-core_share(int pNo, int z, int x, int t)
-{
-	if (policies[pNo].core_share[z].pcpu == lvm_info[x].pcpus[t]) {
-		if (strcmp(policies[pNo].pkt.vm_name,
-				lvm_info[x].vm_name) != 0) {
-			policies[pNo].core_share[z].status = 1;
-			power_manager_scale_core_max(
-					policies[pNo].core_share[z].pcpu);
-		}
-	}
-}
-
-static void
-core_share_status(int pNo)
-{
-
-	int noVms, noVcpus, z, x, t;
-
-	get_all_vm(&noVms, &noVcpus);
-
-	/* Reset Core Share Status. */
-	for (z = 0; z < noVcpus; z++)
-		policies[pNo].core_share[z].status = 0;
-
-	/* Foreach vcpu in a policy. */
-	for (z = 0; z < policies[pNo].pkt.num_vcpu; z++) {
-		/* Foreach VM on the platform. */
-		for (x = 0; x < noVms; x++) {
-			/* Foreach vcpu of VMs on platform. */
-			for (t = 0; t < lvm_info[x].num_cpus; t++)
-				core_share(pNo, z, x, t);
-		}
-	}
-}
-
-static void
-get_pcpu_to_control(struct policy *pol)
-{
-
-	/* Convert vcpu to pcpu. */
-	struct vm_info info;
-	int pcpu, count;
-	uint64_t mask_u64b;
-
-	RTE_LOG(INFO, CHANNEL_MONITOR, "Looking for pcpu for %s\n",
-			pol->pkt.vm_name);
-	get_info_vm(pol->pkt.vm_name, &info);
-
-	for (count = 0; count < pol->pkt.num_vcpu; count++) {
-		mask_u64b = info.pcpu_mask[pol->pkt.vcpu_to_control[count]];
-		for (pcpu = 0; mask_u64b; mask_u64b &= ~(1ULL << pcpu++)) {
-			if ((mask_u64b >> pcpu) & 1)
-				pol->core_share[count].pcpu = pcpu;
-		}
-	}
-}
-
-static int
-get_pfid(struct policy *pol)
-{
-
-	int i, x, ret = 0;
-
-	for (i = 0; i < pol->pkt.nb_mac_to_monitor; i++) {
-
-		RTE_ETH_FOREACH_DEV(x) {
-			ret = rte_pmd_i40e_query_vfid_by_mac(x,
-				(struct ether_addr *)&(pol->pkt.vfid[i]));
-			if (ret != -EINVAL) {
-				pol->port[i] = x;
-				break;
-			}
-		}
-		if (ret == -EINVAL || ret == -ENOTSUP || ret == ENODEV) {
-			RTE_LOG(INFO, CHANNEL_MONITOR,
-				"Error with Policy. MAC not found on "
-				"attached ports ");
-			pol->enabled = 0;
-			return ret;
-		}
-		pol->pfid[i] = ret;
-	}
-	return 1;
-}
-
-static int
-update_policy(struct channel_packet *pkt)
-{
-
-	unsigned int updated = 0;
-	int i;
-
-	for (i = 0; i < MAX_VMS; i++) {
-		if (strcmp(policies[i].pkt.vm_name, pkt->vm_name) == 0) {
-			policies[i].pkt = *pkt;
-			get_pcpu_to_control(&policies[i]);
-			if (get_pfid(&policies[i]) == -1) {
-				updated = 1;
-				break;
-			}
-			core_share_status(i);
-			policies[i].enabled = 1;
-			updated = 1;
-		}
-	}
-	if (!updated) {
-		for (i = 0; i < MAX_VMS; i++) {
-			if (policies[i].enabled == 0) {
-				policies[i].pkt = *pkt;
-				get_pcpu_to_control(&policies[i]);
-				if (get_pfid(&policies[i]) == -1)
-					break;
-				core_share_status(i);
-				policies[i].enabled = 1;
-				break;
-			}
-		}
-	}
-	return 0;
-}
-
-static uint64_t
-get_pkt_diff(struct policy *pol)
-{
-
-	uint64_t vsi_pkt_count,
-		vsi_pkt_total = 0,
-		vsi_pkt_count_prev_total = 0;
-	double rdtsc_curr, rdtsc_diff, diff;
-	int x;
-	struct rte_eth_stats vf_stats;
-
-	for (x = 0; x < pol->pkt.nb_mac_to_monitor; x++) {
-
-		/*Read vsi stats*/
-		if (rte_pmd_i40e_get_vf_stats(x, pol->pfid[x], &vf_stats) == 0)
-			vsi_pkt_count = vf_stats.ipackets;
-		else
-			vsi_pkt_count = -1;
-
-		vsi_pkt_total += vsi_pkt_count;
-
-		vsi_pkt_count_prev_total += vsi_pkt_count_prev[pol->pfid[x]];
-		vsi_pkt_count_prev[pol->pfid[x]] = vsi_pkt_count;
-	}
-
-	rdtsc_curr = rte_rdtsc_precise();
-	rdtsc_diff = rdtsc_curr - rdtsc_prev[pol->pfid[x-1]];
-	rdtsc_prev[pol->pfid[x-1]] = rdtsc_curr;
-
-	diff = (vsi_pkt_total - vsi_pkt_count_prev_total) *
-			((double)rte_get_tsc_hz() / rdtsc_diff);
-
-	return diff;
-}
-
-static void
-apply_traffic_profile(struct policy *pol)
-{
-
-	int count;
-	uint64_t diff = 0;
-
-	diff = get_pkt_diff(pol);
-
-	RTE_LOG(INFO, CHANNEL_MONITOR, "Applying traffic profile\n");
-
-	if (diff >= (pol->pkt.traffic_policy.max_max_packet_thresh)) {
-		for (count = 0; count < pol->pkt.num_vcpu; count++) {
-			if (pol->core_share[count].status != 1)
-				power_manager_scale_core_max(
-						pol->core_share[count].pcpu);
-		}
-	} else if (diff >= (pol->pkt.traffic_policy.avg_max_packet_thresh)) {
-		for (count = 0; count < pol->pkt.num_vcpu; count++) {
-			if (pol->core_share[count].status != 1)
-				power_manager_scale_core_med(
-						pol->core_share[count].pcpu);
-		}
-	} else if (diff < (pol->pkt.traffic_policy.avg_max_packet_thresh)) {
-		for (count = 0; count < pol->pkt.num_vcpu; count++) {
-			if (pol->core_share[count].status != 1)
-				power_manager_scale_core_min(
-						pol->core_share[count].pcpu);
-		}
-	}
-}
-
-static void
-apply_time_profile(struct policy *pol)
-{
-
-	int count, x;
-	struct timeval tv;
-	struct tm *ptm;
-	char time_string[40];
-
-	/* Obtain the time of day, and convert it to a tm struct. */
-	gettimeofday(&tv, NULL);
-	ptm = localtime(&tv.tv_sec);
-	/* Format the date and time, down to a single second. */
-	strftime(time_string, sizeof(time_string), "%Y-%m-%d %H:%M:%S", ptm);
-
-	for (x = 0; x < HOURS; x++) {
-
-		if (ptm->tm_hour == pol->pkt.timer_policy.busy_hours[x]) {
-			for (count = 0; count < pol->pkt.num_vcpu; count++) {
-				if (pol->core_share[count].status != 1) {
-					power_manager_scale_core_max(
-						pol->core_share[count].pcpu);
-				RTE_LOG(INFO, CHANNEL_MONITOR,
-					"Scaling up core %d to max\n",
-					pol->core_share[count].pcpu);
-				}
-			}
-			break;
-		} else if (ptm->tm_hour ==
-				pol->pkt.timer_policy.quiet_hours[x]) {
-			for (count = 0; count < pol->pkt.num_vcpu; count++) {
-				if (pol->core_share[count].status != 1) {
-					power_manager_scale_core_min(
-						pol->core_share[count].pcpu);
-				RTE_LOG(INFO, CHANNEL_MONITOR,
-					"Scaling down core %d to min\n",
-					pol->core_share[count].pcpu);
-			}
-		}
-			break;
-		} else if (ptm->tm_hour ==
-			pol->pkt.timer_policy.hours_to_use_traffic_profile[x]) {
-			apply_traffic_profile(pol);
-			break;
-		}
-	}
-}
-
-static void
-apply_workload_profile(struct policy *pol)
-{
-
-	int count;
-
-	if (pol->pkt.workload == HIGH) {
-		for (count = 0; count < pol->pkt.num_vcpu; count++) {
-			if (pol->core_share[count].status != 1)
-				power_manager_scale_core_max(
-						pol->core_share[count].pcpu);
-		}
-	} else if (pol->pkt.workload == MEDIUM) {
-		for (count = 0; count < pol->pkt.num_vcpu; count++) {
-			if (pol->core_share[count].status != 1)
-				power_manager_scale_core_med(
-						pol->core_share[count].pcpu);
-		}
-	} else if (pol->pkt.workload == LOW) {
-		for (count = 0; count < pol->pkt.num_vcpu; count++) {
-			if (pol->core_share[count].status != 1)
-				power_manager_scale_core_min(
-						pol->core_share[count].pcpu);
-		}
-	}
-}
-
-static void
-apply_policy(struct policy *pol)
-{
-
-	struct channel_packet *pkt = &pol->pkt;
-
-	/*Check policy to use*/
-	if (pkt->policy_to_use == TRAFFIC)
-		apply_traffic_profile(pol);
-	else if (pkt->policy_to_use == TIME)
-		apply_time_profile(pol);
-	else if (pkt->policy_to_use == WORKLOAD)
-		apply_workload_profile(pol);
-}
-
-
-static int
-process_request(struct channel_packet *pkt, struct channel_info *chan_info)
-{
-	uint64_t core_mask;
-
-	if (chan_info == NULL)
-		return -1;
-
-	if (rte_atomic32_cmpset(&(chan_info->status), CHANNEL_MGR_CHANNEL_CONNECTED,
-			CHANNEL_MGR_CHANNEL_PROCESSING) == 0)
-		return -1;
-
-	if (pkt->command == CPU_POWER) {
-		core_mask = get_pcpus_mask(chan_info, pkt->resource_id);
-		if (core_mask == 0) {
-			RTE_LOG(ERR, CHANNEL_MONITOR, "Error get physical CPU mask for "
-				"channel '%s' using vCPU(%u)\n", chan_info->channel_path,
-				(unsigned)pkt->unit);
-			return -1;
-		}
-		if (__builtin_popcountll(core_mask) == 1) {
-
-			unsigned core_num = __builtin_ffsll(core_mask) - 1;
-
-			switch (pkt->unit) {
-			case(CPU_POWER_SCALE_MIN):
-					power_manager_scale_core_min(core_num);
-			break;
-			case(CPU_POWER_SCALE_MAX):
-					power_manager_scale_core_max(core_num);
-			break;
-			case(CPU_POWER_SCALE_DOWN):
-					power_manager_scale_core_down(core_num);
-			break;
-			case(CPU_POWER_SCALE_UP):
-					power_manager_scale_core_up(core_num);
-			break;
-			case(CPU_POWER_ENABLE_TURBO):
-				power_manager_enable_turbo_core(core_num);
-			break;
-			case(CPU_POWER_DISABLE_TURBO):
-				power_manager_disable_turbo_core(core_num);
-			break;
-			default:
-				break;
-			}
-		} else {
-			switch (pkt->unit) {
-			case(CPU_POWER_SCALE_MIN):
-					power_manager_scale_mask_min(core_mask);
-			break;
-			case(CPU_POWER_SCALE_MAX):
-					power_manager_scale_mask_max(core_mask);
-			break;
-			case(CPU_POWER_SCALE_DOWN):
-					power_manager_scale_mask_down(core_mask);
-			break;
-			case(CPU_POWER_SCALE_UP):
-					power_manager_scale_mask_up(core_mask);
-			break;
-			case(CPU_POWER_ENABLE_TURBO):
-				power_manager_enable_turbo_mask(core_mask);
-			break;
-			case(CPU_POWER_DISABLE_TURBO):
-				power_manager_disable_turbo_mask(core_mask);
-			break;
-			default:
-				break;
-			}
-
-		}
-	}
-
-	if (pkt->command == PKT_POLICY) {
-		RTE_LOG(INFO, CHANNEL_MONITOR, "\nProcessing Policy request from Guest\n");
-		update_policy(pkt);
-		policy_is_set = 1;
-	}
-
-	/* Return is not checked as channel status may have been set to DISABLED
-	 * from management thread
-	 */
-	rte_atomic32_cmpset(&(chan_info->status), CHANNEL_MGR_CHANNEL_PROCESSING,
-			CHANNEL_MGR_CHANNEL_CONNECTED);
-	return 0;
-
-}
-
-int
-add_channel_to_monitor(struct channel_info **chan_info)
-{
-	struct channel_info *info = *chan_info;
-	struct epoll_event event;
-
-	event.events = EPOLLIN;
-	event.data.ptr = info;
-	if (epoll_ctl(global_event_fd, EPOLL_CTL_ADD, info->fd, &event) < 0) {
-		RTE_LOG(ERR, CHANNEL_MONITOR, "Unable to add channel '%s' "
-				"to epoll\n", info->channel_path);
-		return -1;
-	}
-	return 0;
-}
-
-int
-remove_channel_from_monitor(struct channel_info *chan_info)
-{
-	if (epoll_ctl(global_event_fd, EPOLL_CTL_DEL, chan_info->fd, NULL) < 0) {
-		RTE_LOG(ERR, CHANNEL_MONITOR, "Unable to remove channel '%s' "
-				"from epoll\n", chan_info->channel_path);
-		return -1;
-	}
-	return 0;
-}
-
-int
-channel_monitor_init(void)
-{
-	global_event_fd = epoll_create1(0);
-	if (global_event_fd == 0) {
-		RTE_LOG(ERR, CHANNEL_MONITOR, "Error creating epoll context with "
-				"error %s\n", strerror(errno));
-		return -1;
-	}
-	global_events_list = rte_malloc("epoll_events", sizeof(*global_events_list)
-			* MAX_EVENTS, RTE_CACHE_LINE_SIZE);
-	if (global_events_list == NULL) {
-		RTE_LOG(ERR, CHANNEL_MONITOR, "Unable to rte_malloc for "
-				"epoll events\n");
-		return -1;
-	}
-	return 0;
-}
-
-void
-run_channel_monitor(void)
-{
-	while (run_loop) {
-		int n_events, i;
-
-		n_events = epoll_wait(global_event_fd, global_events_list,
-				MAX_EVENTS, 1);
-		if (!run_loop)
-			break;
-		for (i = 0; i < n_events; i++) {
-			struct channel_info *chan_info = (struct channel_info *)
-					global_events_list[i].data.ptr;
-			if ((global_events_list[i].events & EPOLLERR) ||
-				(global_events_list[i].events & EPOLLHUP)) {
-				RTE_LOG(DEBUG, CHANNEL_MONITOR, "Remote closed connection for "
-						"channel '%s'\n",
-						chan_info->channel_path);
-				remove_channel(&chan_info);
-				continue;
-			}
-			if (global_events_list[i].events & EPOLLIN) {
-
-				int n_bytes, err = 0;
-				struct channel_packet pkt;
-				void *buffer = &pkt;
-				int buffer_len = sizeof(pkt);
-
-				while (buffer_len > 0) {
-					n_bytes = read(chan_info->fd,
-							buffer, buffer_len);
-					if (n_bytes == buffer_len)
-						break;
-					if (n_bytes == -1) {
-						err = errno;
-						RTE_LOG(DEBUG, CHANNEL_MONITOR,
-							"Received error on "
-							"channel '%s' read: %s\n",
-							chan_info->channel_path,
-							strerror(err));
-						remove_channel(&chan_info);
-						break;
-					}
-					buffer = (char *)buffer + n_bytes;
-					buffer_len -= n_bytes;
-				}
-				if (!err)
-					process_request(&pkt, chan_info);
-			}
-		}
-		rte_delay_us(time_period_ms*1000);
-		if (policy_is_set) {
-			int j;
-
-			for (j = 0; j < MAX_VMS; j++) {
-				if (policies[j].enabled == 1)
-					apply_policy(&policies[j]);
-			}
-		}
-	}
-}
diff --git a/examples/vm_power_manager/channel_monitor.h b/examples/vm_power_manager/channel_monitor.h
deleted file mode 100644
index 7362a80..0000000
--- a/examples/vm_power_manager/channel_monitor.h
+++ /dev/null
@@ -1,91 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#ifndef CHANNEL_MONITOR_H_
-#define CHANNEL_MONITOR_H_
-
-#include "channel_manager.h"
-#include "channel_commands.h"
-
-struct core_share {
-	unsigned int pcpu;
-	/*
-	 * 1 CORE SHARE
-	 * 0 NOT SHARED
-	 */
-	int status;
-};
-
-struct policy {
-	struct channel_packet pkt;
-	uint32_t pfid[MAX_VFS];
-	uint32_t port[MAX_VFS];
-	unsigned int enabled;
-	struct core_share core_share[MAX_VCPU_PER_VM];
-};
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-/**
- * Setup the Channel Monitor resources required to initialize epoll.
- * Must be called first before calling other functions.
- *
- * @return
- *  - 0 on success.
- *  - Negative on error.
- */
-int channel_monitor_init(void);
-
-/**
- * Run the channel monitor, loops forever on on epoll_wait.
- *
- *
- * @return
- *  None
- */
-void run_channel_monitor(void);
-
-/**
- * Exit the Channel Monitor, exiting the epoll_wait loop and events processing.
- *
- * @return
- *  - 0 on success.
- *  - Negative on error.
- */
-void channel_monitor_exit(void);
-
-/**
- * Add an open channel to monitor via epoll. A pointer to struct channel_info
- * will be registered with epoll for event processing.
- * It is thread-safe.
- *
- * @param chan_info
- *  Pointer to struct channel_info pointer.
- *
- * @return
- *  - 0 on success.
- *  - Negative on error.
- */
-int add_channel_to_monitor(struct channel_info **chan_info);
-
-/**
- * Remove a previously added channel from epoll control.
- *
- * @param chan_info
- *  Pointer to struct channel_info.
- *
- * @return
- *  - 0 on success.
- *  - Negative on error.
- */
-int remove_channel_from_monitor(struct channel_info *chan_info);
-
-#ifdef __cplusplus
-}
-#endif
-
-
-#endif /* CHANNEL_MONITOR_H_ */
diff --git a/examples/vm_power_manager/guest_cli/Makefile b/examples/vm_power_manager/guest_cli/Makefile
deleted file mode 100644
index d710e22..0000000
--- a/examples/vm_power_manager/guest_cli/Makefile
+++ /dev/null
@@ -1,28 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-# binary name
-APP = guest_vm_power_mgr
-
-# all source are stored in SRCS-y
-SRCS-y := main.c vm_power_cli_guest.c
-
-CFLAGS += -O3 -I$(RTE_SDK)/lib/librte_power/
-CFLAGS += $(WERROR_FLAGS)
-
-# workaround for a gcc bug with noreturn attribute
-# http://gcc.gnu.org/bugzilla/show_bug.cgi?id=12603
-ifeq ($(CONFIG_RTE_TOOLCHAIN_GCC),y)
-CFLAGS_main.o += -Wno-return-type
-endif
-
-include $(RTE_SDK)/mk/rte.extapp.mk
diff --git a/examples/vm_power_manager/guest_cli/main.c b/examples/vm_power_manager/guest_cli/main.c
deleted file mode 100644
index b17936d..0000000
--- a/examples/vm_power_manager/guest_cli/main.c
+++ /dev/null
@@ -1,55 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-/*
-#include <stdio.h>
-#include <string.h>
-#include <stdint.h>
-#include <sys/epoll.h>
-#include <fcntl.h>
-#include <unistd.h>
-#include <stdlib.h>
-#include <errno.h>
-*/
-#include <signal.h>
-
-#include <rte_lcore.h>
-#include <rte_power.h>
-#include <rte_debug.h>
-
-#include "vm_power_cli_guest.h"
-
-static void
-sig_handler(int signo)
-{
-	printf("Received signal %d, exiting...\n", signo);
-	unsigned lcore_id;
-
-	RTE_LCORE_FOREACH(lcore_id) {
-		rte_power_exit(lcore_id);
-	}
-
-}
-
-int
-main(int argc, char **argv)
-{
-	int ret;
-	unsigned lcore_id;
-
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_panic("Cannot init EAL\n");
-
-	signal(SIGINT, sig_handler);
-	signal(SIGTERM, sig_handler);
-
-	rte_power_set_env(PM_ENV_KVM_VM);
-	RTE_LCORE_FOREACH(lcore_id) {
-		rte_power_init(lcore_id);
-	}
-	run_cli(NULL);
-
-	return 0;
-}
diff --git a/examples/vm_power_manager/guest_cli/vm_power_cli_guest.c b/examples/vm_power_manager/guest_cli/vm_power_cli_guest.c
deleted file mode 100644
index 43bdeac..0000000
--- a/examples/vm_power_manager/guest_cli/vm_power_cli_guest.c
+++ /dev/null
@@ -1,228 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-
-#include <stdint.h>
-#include <string.h>
-#include <stdio.h>
-#include <termios.h>
-
-#include <cmdline_rdline.h>
-#include <cmdline_parse.h>
-#include <cmdline_parse_string.h>
-#include <cmdline_parse_num.h>
-#include <cmdline_socket.h>
-#include <cmdline.h>
-#include <rte_log.h>
-#include <rte_lcore.h>
-#include <rte_ethdev.h>
-
-#include <rte_power.h>
-#include <guest_channel.h>
-
-#include "vm_power_cli_guest.h"
-
-
-#define CHANNEL_PATH "/dev/virtio-ports/virtio.serial.port.poweragent"
-
-
-#define RTE_LOGTYPE_GUEST_CHANNEL RTE_LOGTYPE_USER1
-
-struct cmd_quit_result {
-	cmdline_fixed_string_t quit;
-};
-
-static void cmd_quit_parsed(__attribute__((unused)) void *parsed_result,
-				__attribute__((unused)) struct cmdline *cl,
-			    __attribute__((unused)) void *data)
-{
-	unsigned lcore_id;
-
-	RTE_LCORE_FOREACH(lcore_id) {
-		rte_power_exit(lcore_id);
-	}
-	cmdline_quit(cl);
-}
-
-cmdline_parse_token_string_t cmd_quit_quit =
-	TOKEN_STRING_INITIALIZER(struct cmd_quit_result, quit, "quit");
-
-cmdline_parse_inst_t cmd_quit = {
-	.f = cmd_quit_parsed,  /* function to call */
-	.data = NULL,      /* 2nd arg of func */
-	.help_str = "close the application",
-	.tokens = {        /* token list, NULL terminated */
-		(void *)&cmd_quit_quit,
-		NULL,
-	},
-};
-
-/* *** VM operations *** */
-
-struct cmd_set_cpu_freq_result {
-	cmdline_fixed_string_t set_cpu_freq;
-	uint8_t lcore_id;
-	cmdline_fixed_string_t cmd;
-};
-
-static void
-cmd_set_cpu_freq_parsed(void *parsed_result, struct cmdline *cl,
-		       __attribute__((unused)) void *data)
-{
-	int ret = -1;
-	struct cmd_set_cpu_freq_result *res = parsed_result;
-
-	if (!strcmp(res->cmd , "up"))
-		ret = rte_power_freq_up(res->lcore_id);
-	else if (!strcmp(res->cmd , "down"))
-		ret = rte_power_freq_down(res->lcore_id);
-	else if (!strcmp(res->cmd , "min"))
-		ret = rte_power_freq_min(res->lcore_id);
-	else if (!strcmp(res->cmd , "max"))
-		ret = rte_power_freq_max(res->lcore_id);
-	else if (!strcmp(res->cmd, "enable_turbo"))
-		ret = rte_power_freq_enable_turbo(res->lcore_id);
-	else if (!strcmp(res->cmd, "disable_turbo"))
-		ret = rte_power_freq_disable_turbo(res->lcore_id);
-	if (ret != 1)
-		cmdline_printf(cl, "Error sending message: %s\n", strerror(ret));
-}
-
-cmdline_parse_token_string_t cmd_set_cpu_freq =
-	TOKEN_STRING_INITIALIZER(struct cmd_set_cpu_freq_result,
-			set_cpu_freq, "set_cpu_freq");
-cmdline_parse_token_string_t cmd_set_cpu_freq_core_num =
-	TOKEN_NUM_INITIALIZER(struct cmd_set_cpu_freq_result,
-			lcore_id, UINT8);
-cmdline_parse_token_string_t cmd_set_cpu_freq_cmd_cmd =
-	TOKEN_STRING_INITIALIZER(struct cmd_set_cpu_freq_result,
-			cmd, "up#down#min#max#enable_turbo#disable_turbo");
-
-cmdline_parse_inst_t cmd_set_cpu_freq_set = {
-	.f = cmd_set_cpu_freq_parsed,
-	.data = NULL,
-	.help_str = "set_cpu_freq <core_num> "
-			"<up|down|min|max|enable_turbo|disable_turbo>, "
-			"adjust the frequency for the specified core.",
-	.tokens = {
-		(void *)&cmd_set_cpu_freq,
-		(void *)&cmd_set_cpu_freq_core_num,
-		(void *)&cmd_set_cpu_freq_cmd_cmd,
-		NULL,
-	},
-};
-
-struct cmd_send_policy_result {
-	cmdline_fixed_string_t send_policy;
-	cmdline_fixed_string_t cmd;
-};
-
-union PFID {
-	struct ether_addr addr;
-	uint64_t pfid;
-};
-
-static inline int
-send_policy(void)
-{
-	struct channel_packet pkt;
-	int ret;
-
-	union PFID pfid;
-	/* Use port MAC address as the vfid */
-	rte_eth_macaddr_get(0, &pfid.addr);
-	printf("Port %u MAC: %02" PRIx8 ":%02" PRIx8 ":%02" PRIx8 ":"
-			"%02" PRIx8 ":%02" PRIx8 ":%02" PRIx8 "\n",
-			1,
-			pfid.addr.addr_bytes[0], pfid.addr.addr_bytes[1],
-			pfid.addr.addr_bytes[2], pfid.addr.addr_bytes[3],
-			pfid.addr.addr_bytes[4], pfid.addr.addr_bytes[5]);
-	pkt.vfid[0] = pfid.pfid;
-
-	pkt.nb_mac_to_monitor = 1;
-	pkt.t_boost_status.tbEnabled = false;
-
-	pkt.vcpu_to_control[0] = 0;
-	pkt.vcpu_to_control[1] = 1;
-	pkt.num_vcpu = 2;
-	/* Dummy Population. */
-	pkt.traffic_policy.min_packet_thresh = 96000;
-	pkt.traffic_policy.avg_max_packet_thresh = 1800000;
-	pkt.traffic_policy.max_max_packet_thresh = 2000000;
-
-	pkt.timer_policy.busy_hours[0] = 3;
-	pkt.timer_policy.busy_hours[1] = 4;
-	pkt.timer_policy.busy_hours[2] = 5;
-	pkt.timer_policy.quiet_hours[0] = 11;
-	pkt.timer_policy.quiet_hours[1] = 12;
-	pkt.timer_policy.quiet_hours[2] = 13;
-
-	pkt.timer_policy.hours_to_use_traffic_profile[0] = 8;
-	pkt.timer_policy.hours_to_use_traffic_profile[1] = 10;
-
-	pkt.workload = LOW;
-	pkt.policy_to_use = TIME;
-	pkt.command = PKT_POLICY;
-	strcpy(pkt.vm_name, "ubuntu2");
-	ret = rte_power_guest_channel_send_msg(&pkt, 1);
-	if (ret == 0)
-		return 1;
-	RTE_LOG(DEBUG, POWER, "Error sending message: %s\n",
-			ret > 0 ? strerror(ret) : "channel not connected");
-	return -1;
-}
-
-static void
-cmd_send_policy_parsed(void *parsed_result, struct cmdline *cl,
-		       __attribute__((unused)) void *data)
-{
-	int ret = -1;
-	struct cmd_send_policy_result *res = parsed_result;
-
-	if (!strcmp(res->cmd, "now")) {
-		printf("Sending Policy down now!\n");
-		ret = send_policy();
-	}
-	if (ret != 1)
-		cmdline_printf(cl, "Error sending message: %s\n",
-				strerror(ret));
-}
-
-cmdline_parse_token_string_t cmd_send_policy =
-	TOKEN_STRING_INITIALIZER(struct cmd_send_policy_result,
-			send_policy, "send_policy");
-cmdline_parse_token_string_t cmd_send_policy_cmd_cmd =
-	TOKEN_STRING_INITIALIZER(struct cmd_send_policy_result,
-			cmd, "now");
-
-cmdline_parse_inst_t cmd_send_policy_set = {
-	.f = cmd_send_policy_parsed,
-	.data = NULL,
-	.help_str = "send_policy now",
-	.tokens = {
-		(void *)&cmd_send_policy,
-		(void *)&cmd_send_policy_cmd_cmd,
-		NULL,
-	},
-};
-
-cmdline_parse_ctx_t main_ctx[] = {
-		(cmdline_parse_inst_t *)&cmd_quit,
-		(cmdline_parse_inst_t *)&cmd_send_policy_set,
-		(cmdline_parse_inst_t *)&cmd_set_cpu_freq_set,
-		NULL,
-};
-
-void
-run_cli(__attribute__((unused)) void *arg)
-{
-	struct cmdline *cl;
-
-	cl = cmdline_stdin_new(main_ctx, "vmpower(guest)> ");
-	if (cl == NULL)
-		return;
-
-	cmdline_interact(cl);
-	cmdline_stdin_exit(cl);
-}
diff --git a/examples/vm_power_manager/guest_cli/vm_power_cli_guest.h b/examples/vm_power_manager/guest_cli/vm_power_cli_guest.h
deleted file mode 100644
index 75a2629..0000000
--- a/examples/vm_power_manager/guest_cli/vm_power_cli_guest.h
+++ /dev/null
@@ -1,20 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#ifndef VM_POWER_CLI_H_
-#define VM_POWER_CLI_H_
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-#include "channel_commands.h"
-
-void run_cli(__attribute__((unused)) void *arg);
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif /* VM_POWER_CLI_H_ */
diff --git a/examples/vm_power_manager/main.c b/examples/vm_power_manager/main.c
deleted file mode 100644
index db0ddb0..0000000
--- a/examples/vm_power_manager/main.c
+++ /dev/null
@@ -1,357 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdio.h>
-#include <string.h>
-#include <stdint.h>
-#include <sys/epoll.h>
-#include <fcntl.h>
-#include <unistd.h>
-#include <stdlib.h>
-#include <signal.h>
-#include <errno.h>
-
-#include <sys/queue.h>
-
-#include <rte_common.h>
-#include <rte_eal.h>
-#include <rte_launch.h>
-#include <rte_log.h>
-#include <rte_per_lcore.h>
-#include <rte_lcore.h>
-#include <rte_ethdev.h>
-#include <getopt.h>
-#include <rte_cycles.h>
-#include <rte_debug.h>
-
-#include "channel_manager.h"
-#include "channel_monitor.h"
-#include "power_manager.h"
-#include "vm_power_cli.h"
-#include <rte_pmd_ixgbe.h>
-#include <rte_pmd_i40e.h>
-#include <rte_pmd_bnxt.h>
-
-#define RX_RING_SIZE 1024
-#define TX_RING_SIZE 1024
-
-#define NUM_MBUFS 8191
-#define MBUF_CACHE_SIZE 250
-#define BURST_SIZE 32
-
-static uint32_t enabled_port_mask;
-static volatile bool force_quit;
-
-/****************/
-static const struct rte_eth_conf port_conf_default = {
-	.rxmode = {
-		.max_rx_pkt_len = ETHER_MAX_LEN,
-		.ignore_offload_bitfield = 1,
-	},
-};
-
-static inline int
-port_init(uint16_t port, struct rte_mempool *mbuf_pool)
-{
-	struct rte_eth_conf port_conf = port_conf_default;
-	const uint16_t rx_rings = 1, tx_rings = 1;
-	int retval;
-	uint16_t q;
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_txconf txq_conf;
-
-	if (!rte_eth_dev_is_valid_port(port))
-		return -1;
-
-	rte_eth_dev_info_get(port, &dev_info);
-	if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-		port_conf.txmode.offloads |=
-			DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-
-	/* Configure the Ethernet device. */
-	retval = rte_eth_dev_configure(port, rx_rings, tx_rings, &port_conf);
-	if (retval != 0)
-		return retval;
-
-	/* Allocate and set up 1 RX queue per Ethernet port. */
-	for (q = 0; q < rx_rings; q++) {
-		retval = rte_eth_rx_queue_setup(port, q, RX_RING_SIZE,
-				rte_eth_dev_socket_id(port), NULL, mbuf_pool);
-		if (retval < 0)
-			return retval;
-	}
-
-	txq_conf = dev_info.default_txconf;
-	txq_conf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-	txq_conf.offloads = port_conf.txmode.offloads;
-	/* Allocate and set up 1 TX queue per Ethernet port. */
-	for (q = 0; q < tx_rings; q++) {
-		retval = rte_eth_tx_queue_setup(port, q, TX_RING_SIZE,
-				rte_eth_dev_socket_id(port), &txq_conf);
-		if (retval < 0)
-			return retval;
-	}
-
-	/* Start the Ethernet port. */
-	retval = rte_eth_dev_start(port);
-	if (retval < 0)
-		return retval;
-
-	/* Display the port MAC address. */
-	struct ether_addr addr;
-	rte_eth_macaddr_get(port, &addr);
-	printf("Port %u MAC: %02" PRIx8 " %02" PRIx8 " %02" PRIx8
-			   " %02" PRIx8 " %02" PRIx8 " %02" PRIx8 "\n",
-			(unsigned int)port,
-			addr.addr_bytes[0], addr.addr_bytes[1],
-			addr.addr_bytes[2], addr.addr_bytes[3],
-			addr.addr_bytes[4], addr.addr_bytes[5]);
-
-	/* Enable RX in promiscuous mode for the Ethernet device. */
-	rte_eth_promiscuous_enable(port);
-
-
-	return 0;
-}
-
-static int
-parse_portmask(const char *portmask)
-{
-	char *end = NULL;
-	unsigned long pm;
-
-	/* parse hexadecimal string */
-	pm = strtoul(portmask, &end, 16);
-	if ((portmask[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (pm == 0)
-		return -1;
-
-	return pm;
-}
-/* Parse the argument given in the command line of the application */
-static int
-parse_args(int argc, char **argv)
-{
-	int opt, ret;
-	char **argvopt;
-	int option_index;
-	char *prgname = argv[0];
-	static struct option lgopts[] = {
-		{ "mac-updating", no_argument, 0, 1},
-		{ "no-mac-updating", no_argument, 0, 0},
-		{NULL, 0, 0, 0}
-	};
-	argvopt = argv;
-
-	while ((opt = getopt_long(argc, argvopt, "p:q:T:",
-				  lgopts, &option_index)) != EOF) {
-
-		switch (opt) {
-		/* portmask */
-		case 'p':
-			enabled_port_mask = parse_portmask(optarg);
-			if (enabled_port_mask == 0) {
-				printf("invalid portmask\n");
-				return -1;
-			}
-			break;
-		/* long options */
-		case 0:
-			break;
-
-		default:
-			return -1;
-		}
-	}
-
-	if (optind >= 0)
-		argv[optind-1] = prgname;
-
-	ret = optind-1;
-	optind = 0; /* reset getopt lib */
-	return ret;
-}
-
-static void
-check_all_ports_link_status(uint32_t port_mask)
-{
-#define CHECK_INTERVAL 100 /* 100ms */
-#define MAX_CHECK_TIME 90 /* 9s (90 * 100ms) in total */
-	uint16_t portid, count, all_ports_up, print_flag = 0;
-	struct rte_eth_link link;
-
-	printf("\nChecking link status");
-	fflush(stdout);
-	for (count = 0; count <= MAX_CHECK_TIME; count++) {
-		if (force_quit)
-			return;
-		all_ports_up = 1;
-		RTE_ETH_FOREACH_DEV(portid) {
-			if (force_quit)
-				return;
-			if ((port_mask & (1 << portid)) == 0)
-				continue;
-			memset(&link, 0, sizeof(link));
-			rte_eth_link_get_nowait(portid, &link);
-			/* print link status if flag set */
-			if (print_flag == 1) {
-				if (link.link_status)
-					printf("Port %d Link Up - speed %u "
-						"Mbps - %s\n", (uint16_t)portid,
-						(unsigned int)link.link_speed,
-				(link.link_duplex == ETH_LINK_FULL_DUPLEX) ?
-					("full-duplex") : ("half-duplex\n"));
-				else
-					printf("Port %d Link Down\n",
-						(uint16_t)portid);
-				continue;
-			}
-		       /* clear all_ports_up flag if any link down */
-			if (link.link_status == ETH_LINK_DOWN) {
-				all_ports_up = 0;
-				break;
-			}
-		}
-		/* after finally printing all link status, get out */
-		if (print_flag == 1)
-			break;
-
-		if (all_ports_up == 0) {
-			printf(".");
-			fflush(stdout);
-			rte_delay_ms(CHECK_INTERVAL);
-		}
-
-		/* set the print_flag if all ports up or timeout */
-		if (all_ports_up == 1 || count == (MAX_CHECK_TIME - 1)) {
-			print_flag = 1;
-			printf("done\n");
-		}
-	}
-}
-static int
-run_monitor(__attribute__((unused)) void *arg)
-{
-	if (channel_monitor_init() < 0) {
-		printf("Unable to initialize channel monitor\n");
-		return -1;
-	}
-	run_channel_monitor();
-	return 0;
-}
-
-static void
-sig_handler(int signo)
-{
-	printf("Received signal %d, exiting...\n", signo);
-	channel_monitor_exit();
-	channel_manager_exit();
-	power_manager_exit();
-
-}
-
-int
-main(int argc, char **argv)
-{
-	int ret;
-	unsigned lcore_id;
-	unsigned int nb_ports;
-	struct rte_mempool *mbuf_pool;
-	uint16_t portid;
-
-
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_panic("Cannot init EAL\n");
-
-	signal(SIGINT, sig_handler);
-	signal(SIGTERM, sig_handler);
-
-	argc -= ret;
-	argv += ret;
-
-	/* parse application arguments (after the EAL ones) */
-	ret = parse_args(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid arguments\n");
-
-	nb_ports = rte_eth_dev_count();
-
-	mbuf_pool = rte_pktmbuf_pool_create("MBUF_POOL", NUM_MBUFS * nb_ports,
-		MBUF_CACHE_SIZE, 0, RTE_MBUF_DEFAULT_BUF_SIZE, rte_socket_id());
-
-	if (mbuf_pool == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot create mbuf pool\n");
-
-	/* Initialize ports. */
-	RTE_ETH_FOREACH_DEV(portid) {
-		struct ether_addr eth;
-		int w, j;
-		int ret;
-
-		if ((enabled_port_mask & (1 << portid)) == 0)
-			continue;
-
-		eth.addr_bytes[0] = 0xe0;
-		eth.addr_bytes[1] = 0xe0;
-		eth.addr_bytes[2] = 0xe0;
-		eth.addr_bytes[3] = 0xe0;
-		eth.addr_bytes[4] = portid + 0xf0;
-
-		if (port_init(portid, mbuf_pool) != 0)
-			rte_exit(EXIT_FAILURE, "Cannot init port %"PRIu8 "\n",
-					portid);
-
-		for (w = 0; w < MAX_VFS; w++) {
-			eth.addr_bytes[5] = w + 0xf0;
-
-			ret = rte_pmd_ixgbe_set_vf_mac_addr(portid,
-						w, &eth);
-			if (ret == -ENOTSUP)
-				ret = rte_pmd_i40e_set_vf_mac_addr(portid,
-						w, &eth);
-			if (ret == -ENOTSUP)
-				ret = rte_pmd_bnxt_set_vf_mac_addr(portid,
-						w, &eth);
-
-			switch (ret) {
-			case 0:
-				printf("Port %d VF %d MAC: ",
-						portid, w);
-				for (j = 0; j < 6; j++) {
-					printf("%02x", eth.addr_bytes[j]);
-					if (j < 5)
-						printf(":");
-				}
-				printf("\n");
-				break;
-			}
-		}
-	}
-
-	lcore_id = rte_get_next_lcore(-1, 1, 0);
-	if (lcore_id == RTE_MAX_LCORE) {
-		RTE_LOG(ERR, EAL, "A minimum of two cores are required to run "
-				"application\n");
-		return 0;
-	}
-
-	check_all_ports_link_status(enabled_port_mask);
-	rte_eal_remote_launch(run_monitor, NULL, lcore_id);
-
-	if (power_manager_init() < 0) {
-		printf("Unable to initialize power manager\n");
-		return -1;
-	}
-	if (channel_manager_init(CHANNEL_MGR_DEFAULT_HV_PATH) < 0) {
-		printf("Unable to initialize channel manager\n");
-		return -1;
-	}
-	run_cli(NULL);
-
-	rte_eal_mp_wait_lcore();
-	return 0;
-}
diff --git a/examples/vm_power_manager/power_manager.c b/examples/vm_power_manager/power_manager.c
deleted file mode 100644
index 35db255..0000000
--- a/examples/vm_power_manager/power_manager.c
+++ /dev/null
@@ -1,281 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <sys/un.h>
-#include <fcntl.h>
-#include <unistd.h>
-#include <dirent.h>
-#include <errno.h>
-
-#include <sys/types.h>
-
-#include <rte_log.h>
-#include <rte_power.h>
-#include <rte_spinlock.h>
-
-#include "power_manager.h"
-
-#define RTE_LOGTYPE_POWER_MANAGER RTE_LOGTYPE_USER1
-
-#define POWER_SCALE_CORE(DIRECTION, core_num , ret) do { \
-	if (core_num >= POWER_MGR_MAX_CPUS) \
-		return -1; \
-	if (!(global_enabled_cpus & (1ULL << core_num))) \
-		return -1; \
-	rte_spinlock_lock(&global_core_freq_info[core_num].power_sl); \
-	ret = rte_power_freq_##DIRECTION(core_num); \
-	rte_spinlock_unlock(&global_core_freq_info[core_num].power_sl); \
-} while (0)
-
-#define POWER_SCALE_MASK(DIRECTION, core_mask, ret) do { \
-	int i; \
-	for (i = 0; core_mask; core_mask &= ~(1 << i++)) { \
-		if ((core_mask >> i) & 1) { \
-			if (!(global_enabled_cpus & (1ULL << i))) \
-				continue; \
-			rte_spinlock_lock(&global_core_freq_info[i].power_sl); \
-			if (rte_power_freq_##DIRECTION(i) != 1) \
-				ret = -1; \
-			rte_spinlock_unlock(&global_core_freq_info[i].power_sl); \
-		} \
-	} \
-} while (0)
-
-struct freq_info {
-	rte_spinlock_t power_sl;
-	uint32_t freqs[RTE_MAX_LCORE_FREQS];
-	unsigned num_freqs;
-} __rte_cache_aligned;
-
-static struct freq_info global_core_freq_info[POWER_MGR_MAX_CPUS];
-
-static uint64_t global_enabled_cpus;
-
-#define SYSFS_CPU_PATH "/sys/devices/system/cpu/cpu%u/topology/core_id"
-
-static unsigned
-set_host_cpus_mask(void)
-{
-	char path[PATH_MAX];
-	unsigned i;
-	unsigned num_cpus = 0;
-
-	for (i = 0; i < POWER_MGR_MAX_CPUS; i++) {
-		snprintf(path, sizeof(path), SYSFS_CPU_PATH, i);
-		if (access(path, F_OK) == 0) {
-			global_enabled_cpus |= 1ULL << i;
-			num_cpus++;
-		} else
-			return num_cpus;
-	}
-	return num_cpus;
-}
-
-int
-power_manager_init(void)
-{
-	unsigned int i, num_cpus, num_freqs;
-	uint64_t cpu_mask;
-	int ret = 0;
-
-	num_cpus = set_host_cpus_mask();
-	if (num_cpus == 0) {
-		RTE_LOG(ERR, POWER_MANAGER, "Unable to detected host CPUs, please "
-			"ensure that sufficient privileges exist to inspect sysfs\n");
-		return -1;
-	}
-	rte_power_set_env(PM_ENV_ACPI_CPUFREQ);
-	cpu_mask = global_enabled_cpus;
-	for (i = 0; cpu_mask; cpu_mask &= ~(1 << i++)) {
-		if (rte_power_init(i) < 0)
-			RTE_LOG(ERR, POWER_MANAGER,
-					"Unable to initialize power manager "
-					"for core %u\n", i);
-		num_freqs = rte_power_freqs(i, global_core_freq_info[i].freqs,
-					RTE_MAX_LCORE_FREQS);
-		if (num_freqs == 0) {
-			RTE_LOG(ERR, POWER_MANAGER,
-				"Unable to get frequency list for core %u\n",
-				i);
-			global_enabled_cpus &= ~(1 << i);
-			num_cpus--;
-			ret = -1;
-		}
-		global_core_freq_info[i].num_freqs = num_freqs;
-		rte_spinlock_init(&global_core_freq_info[i].power_sl);
-	}
-	RTE_LOG(INFO, POWER_MANAGER, "Detected %u host CPUs , enabled core mask:"
-					" 0x%"PRIx64"\n", num_cpus, global_enabled_cpus);
-	return ret;
-
-}
-
-uint32_t
-power_manager_get_current_frequency(unsigned core_num)
-{
-	uint32_t freq, index;
-
-	if (core_num >= POWER_MGR_MAX_CPUS) {
-		RTE_LOG(ERR, POWER_MANAGER, "Core(%u) is out of range 0...%d\n",
-				core_num, POWER_MGR_MAX_CPUS-1);
-		return -1;
-	}
-	if (!(global_enabled_cpus & (1ULL << core_num)))
-		return 0;
-
-	rte_spinlock_lock(&global_core_freq_info[core_num].power_sl);
-	index = rte_power_get_freq(core_num);
-	rte_spinlock_unlock(&global_core_freq_info[core_num].power_sl);
-	if (index >= POWER_MGR_MAX_CPUS)
-		freq = 0;
-	else
-		freq = global_core_freq_info[core_num].freqs[index];
-
-	return freq;
-}
-
-int
-power_manager_exit(void)
-{
-	unsigned int i;
-	int ret = 0;
-
-	for (i = 0; global_enabled_cpus; global_enabled_cpus &= ~(1 << i++)) {
-		if (rte_power_exit(i) < 0) {
-			RTE_LOG(ERR, POWER_MANAGER, "Unable to shutdown power manager "
-					"for core %u\n", i);
-			ret = -1;
-		}
-	}
-	global_enabled_cpus = 0;
-	return ret;
-}
-
-int
-power_manager_scale_mask_up(uint64_t core_mask)
-{
-	int ret = 0;
-
-	POWER_SCALE_MASK(up, core_mask, ret);
-	return ret;
-}
-
-int
-power_manager_scale_mask_down(uint64_t core_mask)
-{
-	int ret = 0;
-
-	POWER_SCALE_MASK(down, core_mask, ret);
-	return ret;
-}
-
-int
-power_manager_scale_mask_min(uint64_t core_mask)
-{
-	int ret = 0;
-
-	POWER_SCALE_MASK(min, core_mask, ret);
-	return ret;
-}
-
-int
-power_manager_scale_mask_max(uint64_t core_mask)
-{
-	int ret = 0;
-
-	POWER_SCALE_MASK(max, core_mask, ret);
-	return ret;
-}
-
-int
-power_manager_enable_turbo_mask(uint64_t core_mask)
-{
-	int ret = 0;
-
-	POWER_SCALE_MASK(enable_turbo, core_mask, ret);
-	return ret;
-}
-
-int
-power_manager_disable_turbo_mask(uint64_t core_mask)
-{
-	int ret = 0;
-
-	POWER_SCALE_MASK(disable_turbo, core_mask, ret);
-	return ret;
-}
-
-int
-power_manager_scale_core_up(unsigned core_num)
-{
-	int ret = 0;
-
-	POWER_SCALE_CORE(up, core_num, ret);
-	return ret;
-}
-
-int
-power_manager_scale_core_down(unsigned core_num)
-{
-	int ret = 0;
-
-	POWER_SCALE_CORE(down, core_num, ret);
-	return ret;
-}
-
-int
-power_manager_scale_core_min(unsigned core_num)
-{
-	int ret = 0;
-
-	POWER_SCALE_CORE(min, core_num, ret);
-	return ret;
-}
-
-int
-power_manager_scale_core_max(unsigned core_num)
-{
-	int ret = 0;
-
-	POWER_SCALE_CORE(max, core_num, ret);
-	return ret;
-}
-
-int
-power_manager_enable_turbo_core(unsigned int core_num)
-{
-	int ret = 0;
-
-	POWER_SCALE_CORE(enable_turbo, core_num, ret);
-	return ret;
-}
-
-int
-power_manager_disable_turbo_core(unsigned int core_num)
-{
-	int ret = 0;
-
-	POWER_SCALE_CORE(disable_turbo, core_num, ret);
-	return ret;
-}
-
-int
-power_manager_scale_core_med(unsigned int core_num)
-{
-	int ret = 0;
-
-	if (core_num >= POWER_MGR_MAX_CPUS)
-		return -1;
-	if (!(global_enabled_cpus & (1ULL << core_num)))
-		return -1;
-	rte_spinlock_lock(&global_core_freq_info[core_num].power_sl);
-	ret = rte_power_set_freq(core_num,
-				global_core_freq_info[core_num].num_freqs / 2);
-	rte_spinlock_unlock(&global_core_freq_info[core_num].power_sl);
-	return ret;
-}
diff --git a/examples/vm_power_manager/power_manager.h b/examples/vm_power_manager/power_manager.h
deleted file mode 100644
index 8a8a84a..0000000
--- a/examples/vm_power_manager/power_manager.h
+++ /dev/null
@@ -1,224 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#ifndef POWER_MANAGER_H_
-#define POWER_MANAGER_H_
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-/* Maximum number of CPUS to manage */
-#define POWER_MGR_MAX_CPUS 64
-/**
- * Initialize power management.
- * Initializes resources and verifies the number of CPUs on the system.
- * Wraps librte_power int rte_power_init(unsigned lcore_id);
- *
- * @return
- *  - 0 on success.
- *  - Negative on error.
- */
-int power_manager_init(void);
-
-/**
- * Exit power management. Must be called prior to exiting the application.
- *
- * @return
- *  - 0 on success.
- *  - Negative on error.
- */
-int power_manager_exit(void);
-
-/**
- * Scale up the frequency of the cores specified in core_mask.
- * It is thread-safe.
- *
- * @param core_mask
- *  The uint64_t bit-mask of cores to change frequency.
- *
- * @return
- *  - 1 on success.
- *  - Negative on error.
- */
-int power_manager_scale_mask_up(uint64_t core_mask);
-
-/**
- * Scale down the frequency of the cores specified in core_mask.
- * It is thread-safe.
- *
- * @param core_mask
- *  The uint64_t bit-mask of cores to change frequency.
- *
- * @return
- *  - 1 on success.
- *  - Negative on error.
- */
-int power_manager_scale_mask_down(uint64_t core_mask);
-
-/**
- * Scale to the minimum frequency of the cores specified in core_mask.
- * It is thread-safe.
- *
- * @param core_mask
- *  The uint64_t bit-mask of cores to change frequency.
- *
- * @return
- *  - 1 on success.
- *  - Negative on error.
- */
-int power_manager_scale_mask_min(uint64_t core_mask);
-
-/**
- * Scale to the maximum frequency of the cores specified in core_mask.
- * It is thread-safe.
- *
- * @param core_mask
- *  The uint64_t bit-mask of cores to change frequency.
- *
- * @return
- *  - 1 on success.
- *  - Negative on error.
- */
-int power_manager_scale_mask_max(uint64_t core_mask);
-
-/**
- * Enable Turbo Boost on the cores specified in core_mask.
- * It is thread-safe.
- *
- * @param core_mask
- *  The uint64_t bit-mask of cores to change frequency.
- *
- * @return
- *  - 1 on success.
- *  - Negative on error.
- */
-int power_manager_enable_turbo_mask(uint64_t core_mask);
-
-/**
- * Disable Turbo Boost on the cores specified in core_mask.
- * It is thread-safe.
- *
- * @param core_mask
- *  The uint64_t bit-mask of cores to change frequency.
- *
- * @return
- *  - 1 on success.
- *  - Negative on error.
- */
-int power_manager_disable_turbo_mask(uint64_t core_mask);
-
-/**
- * Scale up frequency for the core specified by core_num.
- * It is thread-safe.
- *
- * @param core_num
- *  The core number to change frequency
- *
- * @return
- *  - 1 on success.
- *  - Negative on error.
- */
-int power_manager_scale_core_up(unsigned core_num);
-
-/**
- * Scale down frequency for the core specified by core_num.
- * It is thread-safe.
- *
- * @param core_num
- *  The core number to change frequency
- *
- * @return
- *  - 1 on success.
- *  - 0 if frequency not changed.
- *  - Negative on error.
- */
-int power_manager_scale_core_down(unsigned core_num);
-
-/**
- * Scale to minimum frequency for the core specified by core_num.
- * It is thread-safe.
- *
- * @param core_num
- *  The core number to change frequency
- *
- * @return
- *  - 1 on success.
- *  - 0 if frequency not changed.
- *  - Negative on error.
- */
-int power_manager_scale_core_min(unsigned core_num);
-
-/**
- * Scale to maximum frequency for the core specified by core_num.
- * It is thread-safe.
- *
- * @param core_num
- *  The core number to change frequency
- *
- * @return
- *  - 1 on success.
- *  - 0 if frequency not changed.
- *  - Negative on error.
- */
-int power_manager_scale_core_max(unsigned core_num);
-
-/**
- * Enable Turbo Boost for the core specified by core_num.
- * It is thread-safe.
- *
- * @param core_num
- *  The core number to boost
- *
- * @return
- *  - 1 on success.
- *  - Negative on error.
- */
-int power_manager_enable_turbo_core(unsigned int core_num);
-
-/**
- * Disable Turbo Boost for the core specified by core_num.
- * It is thread-safe.
- *
- * @param core_num
- *  The core number to boost
- *
- * @return
- *  - 1 on success.
- *  - Negative on error.
- */
-int power_manager_disable_turbo_core(unsigned int core_num);
-
-/**
- * Get the current freuency of the core specified by core_num
- *
- * @param core_num
- *  The core number to get the current frequency
- *
- * @return
- *  - 0  on error
- *  - >0 for current frequency.
- */
-uint32_t power_manager_get_current_frequency(unsigned core_num);
-
-/**
- * Scale to medium frequency for the core specified by core_num.
- * It is thread-safe.
- *
- * @param core_num
- *  The core number to change frequency
- *
- * @return
- *  - 1 on success.
- *  - 0 if frequency not changed.
- *  - Negative on error.
- */
-int power_manager_scale_core_med(unsigned int core_num);
-
-#ifdef __cplusplus
-}
-#endif
-
-
-#endif /* POWER_MANAGER_H_ */
diff --git a/examples/vm_power_manager/vm_power_cli.c b/examples/vm_power_manager/vm_power_cli.c
deleted file mode 100644
index d588d38..0000000
--- a/examples/vm_power_manager/vm_power_cli.c
+++ /dev/null
@@ -1,650 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdlib.h>
-#include <stdint.h>
-#include <inttypes.h>
-#include <stdio.h>
-#include <string.h>
-#include <termios.h>
-#include <errno.h>
-
-#include <cmdline_rdline.h>
-#include <cmdline_parse.h>
-#include <cmdline_parse_string.h>
-#include <cmdline_parse_num.h>
-#include <cmdline_socket.h>
-#include <cmdline.h>
-
-#include "vm_power_cli.h"
-#include "channel_manager.h"
-#include "channel_monitor.h"
-#include "power_manager.h"
-#include "channel_commands.h"
-
-struct cmd_quit_result {
-	cmdline_fixed_string_t quit;
-};
-
-static void cmd_quit_parsed(__attribute__((unused)) void *parsed_result,
-		struct cmdline *cl,
-		__attribute__((unused)) void *data)
-{
-	channel_monitor_exit();
-	channel_manager_exit();
-	power_manager_exit();
-	cmdline_quit(cl);
-}
-
-cmdline_parse_token_string_t cmd_quit_quit =
-	TOKEN_STRING_INITIALIZER(struct cmd_quit_result, quit, "quit");
-
-cmdline_parse_inst_t cmd_quit = {
-	.f = cmd_quit_parsed,  /* function to call */
-	.data = NULL,      /* 2nd arg of func */
-	.help_str = "close the application",
-	.tokens = {        /* token list, NULL terminated */
-		(void *)&cmd_quit_quit,
-		NULL,
-	},
-};
-
-/* *** VM operations *** */
-struct cmd_show_vm_result {
-	cmdline_fixed_string_t show_vm;
-	cmdline_fixed_string_t vm_name;
-};
-
-static void
-cmd_show_vm_parsed(void *parsed_result, struct cmdline *cl,
-		__attribute__((unused)) void *data)
-{
-	struct cmd_show_vm_result *res = parsed_result;
-	struct vm_info info;
-	unsigned i;
-
-	if (get_info_vm(res->vm_name, &info) != 0)
-		return;
-	cmdline_printf(cl, "VM: '%s', status = ", info.name);
-	if (info.status == CHANNEL_MGR_VM_ACTIVE)
-		cmdline_printf(cl, "ACTIVE\n");
-	else
-		cmdline_printf(cl, "INACTIVE\n");
-	cmdline_printf(cl, "Channels %u\n", info.num_channels);
-	for (i = 0; i < info.num_channels; i++) {
-		cmdline_printf(cl, "  [%u]: %s, status = ", i,
-				info.channels[i].channel_path);
-		switch (info.channels[i].status) {
-		case CHANNEL_MGR_CHANNEL_CONNECTED:
-			cmdline_printf(cl, "CONNECTED\n");
-			break;
-		case CHANNEL_MGR_CHANNEL_DISCONNECTED:
-			cmdline_printf(cl, "DISCONNECTED\n");
-			break;
-		case CHANNEL_MGR_CHANNEL_DISABLED:
-			cmdline_printf(cl, "DISABLED\n");
-			break;
-		case CHANNEL_MGR_CHANNEL_PROCESSING:
-			cmdline_printf(cl, "PROCESSING\n");
-			break;
-		default:
-			cmdline_printf(cl, "UNKNOWN\n");
-			break;
-		}
-	}
-	cmdline_printf(cl, "Virtual CPU(s): %u\n", info.num_vcpus);
-	for (i = 0; i < info.num_vcpus; i++) {
-		cmdline_printf(cl, "  [%u]: Physical CPU Mask 0x%"PRIx64"\n", i,
-				info.pcpu_mask[i]);
-	}
-}
-
-
-
-cmdline_parse_token_string_t cmd_vm_show =
-	TOKEN_STRING_INITIALIZER(struct cmd_show_vm_result,
-				show_vm, "show_vm");
-cmdline_parse_token_string_t cmd_show_vm_name =
-	TOKEN_STRING_INITIALIZER(struct cmd_show_vm_result,
-			vm_name, NULL);
-
-cmdline_parse_inst_t cmd_show_vm_set = {
-	.f = cmd_show_vm_parsed,
-	.data = NULL,
-	.help_str = "show_vm <vm_name>, prints the information on the "
-			"specified VM(s), the information lists the number of vCPUS, the "
-			"pinning to pCPU(s) as a bit mask, along with any communication "
-			"channels associated with each VM",
-	.tokens = {
-		(void *)&cmd_vm_show,
-		(void *)&cmd_show_vm_name,
-		NULL,
-	},
-};
-
-/* *** vCPU to pCPU mapping operations *** */
-struct cmd_set_pcpu_mask_result {
-	cmdline_fixed_string_t set_pcpu_mask;
-	cmdline_fixed_string_t vm_name;
-	uint8_t vcpu;
-	uint64_t core_mask;
-};
-
-static void
-cmd_set_pcpu_mask_parsed(void *parsed_result, struct cmdline *cl,
-		__attribute__((unused)) void *data)
-{
-	struct cmd_set_pcpu_mask_result *res = parsed_result;
-
-	if (set_pcpus_mask(res->vm_name, res->vcpu, res->core_mask) == 0)
-		cmdline_printf(cl, "Pinned vCPU(%"PRId8") to pCPU core "
-				"mask(0x%"PRIx64")\n", res->vcpu, res->core_mask);
-	else
-		cmdline_printf(cl, "Unable to pin vCPU(%"PRId8") to pCPU core "
-				"mask(0x%"PRIx64")\n", res->vcpu, res->core_mask);
-}
-
-cmdline_parse_token_string_t cmd_set_pcpu_mask =
-		TOKEN_STRING_INITIALIZER(struct cmd_set_pcpu_mask_result,
-				set_pcpu_mask, "set_pcpu_mask");
-cmdline_parse_token_string_t cmd_set_pcpu_mask_vm_name =
-		TOKEN_STRING_INITIALIZER(struct cmd_set_pcpu_mask_result,
-				vm_name, NULL);
-cmdline_parse_token_num_t set_pcpu_mask_vcpu =
-		TOKEN_NUM_INITIALIZER(struct cmd_set_pcpu_mask_result,
-				vcpu, UINT8);
-cmdline_parse_token_num_t set_pcpu_mask_core_mask =
-		TOKEN_NUM_INITIALIZER(struct cmd_set_pcpu_mask_result,
-				core_mask, UINT64);
-
-
-cmdline_parse_inst_t cmd_set_pcpu_mask_set = {
-		.f = cmd_set_pcpu_mask_parsed,
-		.data = NULL,
-		.help_str = "set_pcpu_mask <vm_name> <vcpu> <pcpu>, Set the binding "
-				"of Virtual CPU on VM to the Physical CPU mask.",
-				.tokens = {
-						(void *)&cmd_set_pcpu_mask,
-						(void *)&cmd_set_pcpu_mask_vm_name,
-						(void *)&set_pcpu_mask_vcpu,
-						(void *)&set_pcpu_mask_core_mask,
-						NULL,
-		},
-};
-
-struct cmd_set_pcpu_result {
-	cmdline_fixed_string_t set_pcpu;
-	cmdline_fixed_string_t vm_name;
-	uint8_t vcpu;
-	uint8_t core;
-};
-
-static void
-cmd_set_pcpu_parsed(void *parsed_result, struct cmdline *cl,
-		__attribute__((unused)) void *data)
-{
-	struct cmd_set_pcpu_result *res = parsed_result;
-
-	if (set_pcpu(res->vm_name, res->vcpu, res->core) == 0)
-		cmdline_printf(cl, "Pinned vCPU(%"PRId8") to pCPU core "
-				"%"PRId8")\n", res->vcpu, res->core);
-	else
-		cmdline_printf(cl, "Unable to pin vCPU(%"PRId8") to pCPU core "
-				"%"PRId8")\n", res->vcpu, res->core);
-}
-
-cmdline_parse_token_string_t cmd_set_pcpu =
-		TOKEN_STRING_INITIALIZER(struct cmd_set_pcpu_result,
-				set_pcpu, "set_pcpu");
-cmdline_parse_token_string_t cmd_set_pcpu_vm_name =
-		TOKEN_STRING_INITIALIZER(struct cmd_set_pcpu_result,
-				vm_name, NULL);
-cmdline_parse_token_num_t set_pcpu_vcpu =
-		TOKEN_NUM_INITIALIZER(struct cmd_set_pcpu_result,
-				vcpu, UINT8);
-cmdline_parse_token_num_t set_pcpu_core =
-		TOKEN_NUM_INITIALIZER(struct cmd_set_pcpu_result,
-				core, UINT64);
-
-
-cmdline_parse_inst_t cmd_set_pcpu_set = {
-		.f = cmd_set_pcpu_parsed,
-		.data = NULL,
-		.help_str = "set_pcpu <vm_name> <vcpu> <pcpu>, Set the binding "
-				"of Virtual CPU on VM to the Physical CPU.",
-				.tokens = {
-						(void *)&cmd_set_pcpu,
-						(void *)&cmd_set_pcpu_vm_name,
-						(void *)&set_pcpu_vcpu,
-						(void *)&set_pcpu_core,
-						NULL,
-		},
-};
-
-struct cmd_vm_op_result {
-	cmdline_fixed_string_t op_vm;
-	cmdline_fixed_string_t vm_name;
-};
-
-static void
-cmd_vm_op_parsed(void *parsed_result, struct cmdline *cl,
-		__attribute__((unused)) void *data)
-{
-	struct cmd_vm_op_result *res = parsed_result;
-
-	if (!strcmp(res->op_vm, "add_vm")) {
-		if (add_vm(res->vm_name) < 0)
-			cmdline_printf(cl, "Unable to add VM '%s'\n", res->vm_name);
-	} else if (remove_vm(res->vm_name) < 0)
-		cmdline_printf(cl, "Unable to remove VM '%s'\n", res->vm_name);
-}
-
-cmdline_parse_token_string_t cmd_vm_op =
-	TOKEN_STRING_INITIALIZER(struct cmd_vm_op_result,
-			op_vm, "add_vm#rm_vm");
-cmdline_parse_token_string_t cmd_vm_name =
-	TOKEN_STRING_INITIALIZER(struct cmd_vm_op_result,
-			vm_name, NULL);
-
-cmdline_parse_inst_t cmd_vm_op_set = {
-	.f = cmd_vm_op_parsed,
-	.data = NULL,
-	.help_str = "add_vm|rm_vm <name>, add a VM for "
-			"subsequent operations with the CLI or remove a previously added "
-			"VM from the VM Power Manager",
-	.tokens = {
-		(void *)&cmd_vm_op,
-		(void *)&cmd_vm_name,
-	NULL,
-	},
-};
-
-/* *** VM channel operations *** */
-struct cmd_channels_op_result {
-	cmdline_fixed_string_t op;
-	cmdline_fixed_string_t vm_name;
-	cmdline_fixed_string_t channel_list;
-};
-static void
-cmd_channels_op_parsed(void *parsed_result, struct cmdline *cl,
-			__attribute__((unused)) void *data)
-{
-	unsigned num_channels = 0, channel_num, i;
-	int channels_added;
-	unsigned channel_list[CHANNEL_CMDS_MAX_VM_CHANNELS];
-	char *token, *remaining, *tail_ptr;
-	struct cmd_channels_op_result *res = parsed_result;
-
-	if (!strcmp(res->channel_list, "all")) {
-		channels_added = add_all_channels(res->vm_name);
-		cmdline_printf(cl, "Added %d channels for VM '%s'\n",
-				channels_added, res->vm_name);
-		return;
-	}
-
-	remaining = res->channel_list;
-	while (1) {
-		if (remaining == NULL || remaining[0] == '\0')
-			break;
-
-		token = strsep(&remaining, ",");
-		if (token == NULL)
-			break;
-		errno = 0;
-		channel_num = (unsigned)strtol(token, &tail_ptr, 10);
-		if ((errno != 0) || tail_ptr == NULL || (*tail_ptr != '\0'))
-			break;
-
-		if (channel_num == CHANNEL_CMDS_MAX_VM_CHANNELS) {
-			cmdline_printf(cl, "Channel number '%u' exceeds the maximum number "
-					"of allowable channels(%u) for VM '%s'\n", channel_num,
-					CHANNEL_CMDS_MAX_VM_CHANNELS, res->vm_name);
-			return;
-		}
-		channel_list[num_channels++] = channel_num;
-	}
-	for (i = 0; i < num_channels; i++)
-		cmdline_printf(cl, "[%u]: Adding channel %u\n", i, channel_list[i]);
-
-	channels_added = add_channels(res->vm_name, channel_list,
-			num_channels);
-	cmdline_printf(cl, "Enabled %d channels for '%s'\n", channels_added,
-			res->vm_name);
-}
-
-cmdline_parse_token_string_t cmd_channels_op =
-	TOKEN_STRING_INITIALIZER(struct cmd_channels_op_result,
-				op, "add_channels");
-cmdline_parse_token_string_t cmd_channels_vm_name =
-	TOKEN_STRING_INITIALIZER(struct cmd_channels_op_result,
-			vm_name, NULL);
-cmdline_parse_token_string_t cmd_channels_list =
-	TOKEN_STRING_INITIALIZER(struct cmd_channels_op_result,
-			channel_list, NULL);
-
-cmdline_parse_inst_t cmd_channels_op_set = {
-	.f = cmd_channels_op_parsed,
-	.data = NULL,
-	.help_str = "add_channels <vm_name> <list>|all, add "
-			"communication channels for the specified VM, the "
-			"virtio channels must be enabled in the VM "
-			"configuration(qemu/libvirt) and the associated VM must be active. "
-			"<list> is a comma-separated list of channel numbers to add, using "
-			"the keyword 'all' will attempt to add all channels for the VM",
-	.tokens = {
-		(void *)&cmd_channels_op,
-		(void *)&cmd_channels_vm_name,
-		(void *)&cmd_channels_list,
-		NULL,
-	},
-};
-
-struct cmd_channels_status_op_result {
-	cmdline_fixed_string_t op;
-	cmdline_fixed_string_t vm_name;
-	cmdline_fixed_string_t channel_list;
-	cmdline_fixed_string_t status;
-};
-
-static void
-cmd_channels_status_op_parsed(void *parsed_result, struct cmdline *cl,
-		       __attribute__((unused)) void *data)
-{
-	unsigned num_channels = 0, channel_num;
-	int changed;
-	unsigned channel_list[CHANNEL_CMDS_MAX_VM_CHANNELS];
-	char *token, *remaining, *tail_ptr;
-	struct cmd_channels_status_op_result *res = parsed_result;
-	enum channel_status status;
-
-	if (!strcmp(res->status, "enabled"))
-		status = CHANNEL_MGR_CHANNEL_CONNECTED;
-	else
-		status = CHANNEL_MGR_CHANNEL_DISABLED;
-
-	if (!strcmp(res->channel_list, "all")) {
-		changed = set_channel_status_all(res->vm_name, status);
-		cmdline_printf(cl, "Updated status of %d channels "
-				"for VM '%s'\n", changed, res->vm_name);
-		return;
-	}
-	remaining = res->channel_list;
-	while (1) {
-		if (remaining == NULL || remaining[0] == '\0')
-			break;
-		token = strsep(&remaining, ",");
-		if (token == NULL)
-			break;
-		errno = 0;
-		channel_num = (unsigned)strtol(token, &tail_ptr, 10);
-		if ((errno != 0) || tail_ptr == NULL || (*tail_ptr != '\0'))
-			break;
-
-		if (channel_num == CHANNEL_CMDS_MAX_VM_CHANNELS) {
-			cmdline_printf(cl, "%u exceeds the maximum number of allowable "
-					"channels(%u) for VM '%s'\n", channel_num,
-					CHANNEL_CMDS_MAX_VM_CHANNELS, res->vm_name);
-			return;
-		}
-		channel_list[num_channels++] = channel_num;
-	}
-	changed = set_channel_status(res->vm_name, channel_list, num_channels,
-			status);
-	cmdline_printf(cl, "Updated status of %d channels "
-					"for VM '%s'\n", changed, res->vm_name);
-}
-
-cmdline_parse_token_string_t cmd_channels_status_op =
-	TOKEN_STRING_INITIALIZER(struct cmd_channels_status_op_result,
-				op, "set_channel_status");
-cmdline_parse_token_string_t cmd_channels_status_vm_name =
-	TOKEN_STRING_INITIALIZER(struct cmd_channels_status_op_result,
-			vm_name, NULL);
-cmdline_parse_token_string_t cmd_channels_status_list =
-	TOKEN_STRING_INITIALIZER(struct cmd_channels_status_op_result,
-			channel_list, NULL);
-cmdline_parse_token_string_t cmd_channels_status =
-	TOKEN_STRING_INITIALIZER(struct cmd_channels_status_op_result,
-			status, "enabled#disabled");
-
-cmdline_parse_inst_t cmd_channels_status_op_set = {
-	.f = cmd_channels_status_op_parsed,
-	.data = NULL,
-	.help_str = "set_channel_status <vm_name> <list>|all enabled|disabled, "
-			" enable or disable the communication channels in "
-			"list(comma-separated) for the specified VM, alternatively "
-			"list can be replaced with keyword 'all'. "
-			"Disabled channels will still receive packets on the host, "
-			"however the commands they specify will be ignored. "
-			"Set status to 'enabled' to begin processing requests again.",
-	.tokens = {
-		(void *)&cmd_channels_status_op,
-		(void *)&cmd_channels_status_vm_name,
-		(void *)&cmd_channels_status_list,
-		(void *)&cmd_channels_status,
-		NULL,
-	},
-};
-
-/* *** CPU Frequency operations *** */
-struct cmd_show_cpu_freq_mask_result {
-	cmdline_fixed_string_t show_cpu_freq_mask;
-	uint64_t core_mask;
-};
-
-static void
-cmd_show_cpu_freq_mask_parsed(void *parsed_result, struct cmdline *cl,
-		       __attribute__((unused)) void *data)
-{
-	struct cmd_show_cpu_freq_mask_result *res = parsed_result;
-	unsigned i;
-	uint64_t mask = res->core_mask;
-	uint32_t freq;
-
-	for (i = 0; mask; mask &= ~(1ULL << i++)) {
-		if ((mask >> i) & 1) {
-			freq = power_manager_get_current_frequency(i);
-			if (freq > 0)
-				cmdline_printf(cl, "Core %u: %"PRId32"\n", i, freq);
-		}
-	}
-}
-
-cmdline_parse_token_string_t cmd_show_cpu_freq_mask =
-	TOKEN_STRING_INITIALIZER(struct cmd_show_cpu_freq_mask_result,
-			show_cpu_freq_mask, "show_cpu_freq_mask");
-cmdline_parse_token_num_t cmd_show_cpu_freq_mask_core_mask =
-	TOKEN_NUM_INITIALIZER(struct cmd_show_cpu_freq_mask_result,
-			core_mask, UINT64);
-
-cmdline_parse_inst_t cmd_show_cpu_freq_mask_set = {
-	.f = cmd_show_cpu_freq_mask_parsed,
-	.data = NULL,
-	.help_str = "show_cpu_freq_mask <mask>, Get the current frequency for each "
-			"core specified in the mask",
-	.tokens = {
-		(void *)&cmd_show_cpu_freq_mask,
-		(void *)&cmd_show_cpu_freq_mask_core_mask,
-		NULL,
-	},
-};
-
-struct cmd_set_cpu_freq_mask_result {
-	cmdline_fixed_string_t set_cpu_freq_mask;
-	uint64_t core_mask;
-	cmdline_fixed_string_t cmd;
-};
-
-static void
-cmd_set_cpu_freq_mask_parsed(void *parsed_result, struct cmdline *cl,
-			__attribute__((unused)) void *data)
-{
-	struct cmd_set_cpu_freq_mask_result *res = parsed_result;
-	int ret = -1;
-
-	if (!strcmp(res->cmd , "up"))
-		ret = power_manager_scale_mask_up(res->core_mask);
-	else if (!strcmp(res->cmd , "down"))
-		ret = power_manager_scale_mask_down(res->core_mask);
-	else if (!strcmp(res->cmd , "min"))
-		ret = power_manager_scale_mask_min(res->core_mask);
-	else if (!strcmp(res->cmd , "max"))
-		ret = power_manager_scale_mask_max(res->core_mask);
-	else if (!strcmp(res->cmd, "enable_turbo"))
-		ret = power_manager_enable_turbo_mask(res->core_mask);
-	else if (!strcmp(res->cmd, "disable_turbo"))
-		ret = power_manager_disable_turbo_mask(res->core_mask);
-	if (ret < 0) {
-		cmdline_printf(cl, "Error scaling core_mask(0x%"PRIx64") '%s' , not "
-				"all cores specified have been scaled\n",
-				res->core_mask, res->cmd);
-	};
-}
-
-cmdline_parse_token_string_t cmd_set_cpu_freq_mask =
-	TOKEN_STRING_INITIALIZER(struct cmd_set_cpu_freq_mask_result,
-			set_cpu_freq_mask, "set_cpu_freq_mask");
-cmdline_parse_token_num_t cmd_set_cpu_freq_mask_core_mask =
-	TOKEN_NUM_INITIALIZER(struct cmd_set_cpu_freq_mask_result,
-			core_mask, UINT64);
-cmdline_parse_token_string_t cmd_set_cpu_freq_mask_result =
-	TOKEN_STRING_INITIALIZER(struct cmd_set_cpu_freq_mask_result,
-			cmd, "up#down#min#max#enable_turbo#disable_turbo");
-
-cmdline_parse_inst_t cmd_set_cpu_freq_mask_set = {
-	.f = cmd_set_cpu_freq_mask_parsed,
-	.data = NULL,
-	.help_str = "set_cpu_freq <core_mask> <up|down|min|max|enable_turbo|disable_turbo>, adjust the current "
-			"frequency for the cores specified in <core_mask>",
-	.tokens = {
-		(void *)&cmd_set_cpu_freq_mask,
-		(void *)&cmd_set_cpu_freq_mask_core_mask,
-		(void *)&cmd_set_cpu_freq_mask_result,
-		NULL,
-	},
-};
-
-
-
-struct cmd_show_cpu_freq_result {
-	cmdline_fixed_string_t show_cpu_freq;
-	uint8_t core_num;
-};
-
-static void
-cmd_show_cpu_freq_parsed(void *parsed_result, struct cmdline *cl,
-		       __attribute__((unused)) void *data)
-{
-	struct cmd_show_cpu_freq_result *res = parsed_result;
-	uint32_t curr_freq = power_manager_get_current_frequency(res->core_num);
-
-	if (curr_freq == 0) {
-		cmdline_printf(cl, "Unable to get frequency for core %u\n",
-				res->core_num);
-		return;
-	}
-	cmdline_printf(cl, "Core %u frequency: %"PRId32"\n", res->core_num,
-			curr_freq);
-}
-
-cmdline_parse_token_string_t cmd_show_cpu_freq =
-	TOKEN_STRING_INITIALIZER(struct cmd_show_cpu_freq_result,
-			show_cpu_freq, "show_cpu_freq");
-
-cmdline_parse_token_num_t cmd_show_cpu_freq_core_num =
-	TOKEN_NUM_INITIALIZER(struct cmd_show_cpu_freq_result,
-			core_num, UINT8);
-
-cmdline_parse_inst_t cmd_show_cpu_freq_set = {
-	.f = cmd_show_cpu_freq_parsed,
-	.data = NULL,
-	.help_str = "Get the current frequency for the specified core",
-	.tokens = {
-		(void *)&cmd_show_cpu_freq,
-		(void *)&cmd_show_cpu_freq_core_num,
-		NULL,
-	},
-};
-
-struct cmd_set_cpu_freq_result {
-	cmdline_fixed_string_t set_cpu_freq;
-	uint8_t core_num;
-	cmdline_fixed_string_t cmd;
-};
-
-static void
-cmd_set_cpu_freq_parsed(void *parsed_result, struct cmdline *cl,
-		       __attribute__((unused)) void *data)
-{
-	int ret = -1;
-	struct cmd_set_cpu_freq_result *res = parsed_result;
-
-	if (!strcmp(res->cmd , "up"))
-		ret = power_manager_scale_core_up(res->core_num);
-	else if (!strcmp(res->cmd , "down"))
-		ret = power_manager_scale_core_down(res->core_num);
-	else if (!strcmp(res->cmd , "min"))
-		ret = power_manager_scale_core_min(res->core_num);
-	else if (!strcmp(res->cmd , "max"))
-		ret = power_manager_scale_core_max(res->core_num);
-	else if (!strcmp(res->cmd, "enable_turbo"))
-		ret = power_manager_enable_turbo_core(res->core_num);
-	else if (!strcmp(res->cmd, "disable_turbo"))
-		ret = power_manager_disable_turbo_core(res->core_num);
-	if (ret < 0) {
-		cmdline_printf(cl, "Error scaling core(%u) '%s'\n", res->core_num,
-				res->cmd);
-	}
-}
-
-cmdline_parse_token_string_t cmd_set_cpu_freq =
-	TOKEN_STRING_INITIALIZER(struct cmd_set_cpu_freq_result,
-			set_cpu_freq, "set_cpu_freq");
-cmdline_parse_token_num_t cmd_set_cpu_freq_core_num =
-	TOKEN_NUM_INITIALIZER(struct cmd_set_cpu_freq_result,
-			core_num, UINT8);
-cmdline_parse_token_string_t cmd_set_cpu_freq_cmd_cmd =
-	TOKEN_STRING_INITIALIZER(struct cmd_set_cpu_freq_result,
-			cmd, "up#down#min#max#enable_turbo#disable_turbo");
-
-cmdline_parse_inst_t cmd_set_cpu_freq_set = {
-	.f = cmd_set_cpu_freq_parsed,
-	.data = NULL,
-	.help_str = "set_cpu_freq <core_num> <up|down|min|max|enable_turbo|disable_turbo>, adjust the current "
-			"frequency for the specified core",
-	.tokens = {
-		(void *)&cmd_set_cpu_freq,
-		(void *)&cmd_set_cpu_freq_core_num,
-		(void *)&cmd_set_cpu_freq_cmd_cmd,
-		NULL,
-	},
-};
-
-cmdline_parse_ctx_t main_ctx[] = {
-		(cmdline_parse_inst_t *)&cmd_quit,
-		(cmdline_parse_inst_t *)&cmd_vm_op_set,
-		(cmdline_parse_inst_t *)&cmd_channels_op_set,
-		(cmdline_parse_inst_t *)&cmd_channels_status_op_set,
-		(cmdline_parse_inst_t *)&cmd_show_vm_set,
-		(cmdline_parse_inst_t *)&cmd_show_cpu_freq_mask_set,
-		(cmdline_parse_inst_t *)&cmd_set_cpu_freq_mask_set,
-		(cmdline_parse_inst_t *)&cmd_show_cpu_freq_set,
-		(cmdline_parse_inst_t *)&cmd_set_cpu_freq_set,
-		(cmdline_parse_inst_t *)&cmd_set_pcpu_mask_set,
-		(cmdline_parse_inst_t *)&cmd_set_pcpu_set,
-		NULL,
-};
-
-void
-run_cli(__attribute__((unused)) void *arg)
-{
-	struct cmdline *cl;
-
-	cl = cmdline_stdin_new(main_ctx, "vmpower> ");
-	if (cl == NULL)
-		return;
-
-	cmdline_interact(cl);
-	cmdline_stdin_exit(cl);
-}
diff --git a/examples/vm_power_manager/vm_power_cli.h b/examples/vm_power_manager/vm_power_cli.h
deleted file mode 100644
index 075c255..0000000
--- a/examples/vm_power_manager/vm_power_cli.h
+++ /dev/null
@@ -1,18 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#ifndef VM_POWER_CLI_H_
-#define VM_POWER_CLI_H_
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-void run_cli(__attribute__((unused)) void *arg);
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif /* VM_POWER_CLI_H_ */
diff --git a/examples/vmdq/Makefile b/examples/vmdq/Makefile
deleted file mode 100644
index e2d1149..0000000
--- a/examples/vmdq/Makefile
+++ /dev/null
@@ -1,59 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-# binary name
-APP = vmdq_app
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else # Build using legacy build system
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += $(WERROR_FLAGS)
-
-EXTRA_CFLAGS += -O3
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-endif
diff --git a/examples/vmdq/main.c b/examples/vmdq/main.c
deleted file mode 100644
index 2f3eb74..0000000
--- a/examples/vmdq/main.c
+++ /dev/null
@@ -1,621 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdint.h>
-#include <sys/queue.h>
-#include <stdlib.h>
-#include <string.h>
-#include <stdio.h>
-#include <assert.h>
-#include <errno.h>
-#include <signal.h>
-#include <stdarg.h>
-#include <inttypes.h>
-#include <getopt.h>
-
-#include <rte_common.h>
-#include <rte_log.h>
-#include <rte_memory.h>
-#include <rte_memcpy.h>
-#include <rte_eal.h>
-#include <rte_launch.h>
-#include <rte_atomic.h>
-#include <rte_cycles.h>
-#include <rte_prefetch.h>
-#include <rte_lcore.h>
-#include <rte_per_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_interrupts.h>
-#include <rte_random.h>
-#include <rte_debug.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-
-#define MAX_QUEUES 1024
-/*
- * 1024 queues require to meet the needs of a large number of vmdq_pools.
- * (RX/TX_queue_nb * RX/TX_ring_descriptors_nb) per port.
- */
-#define NUM_MBUFS_PER_PORT (MAX_QUEUES * RTE_MAX(RTE_TEST_RX_DESC_DEFAULT, \
-						RTE_TEST_TX_DESC_DEFAULT))
-#define MBUF_CACHE_SIZE 64
-
-#define MAX_PKT_BURST 32
-
-/*
- * Configurable number of RX/TX ring descriptors
- */
-#define RTE_TEST_RX_DESC_DEFAULT 1024
-#define RTE_TEST_TX_DESC_DEFAULT 1024
-
-#define INVALID_PORT_ID 0xFF
-
-/* mask of enabled ports */
-static uint32_t enabled_port_mask;
-
-/* number of pools (if user does not specify any, 8 by default */
-static uint32_t num_queues = 8;
-static uint32_t num_pools = 8;
-
-/* empty vmdq configuration structure. Filled in programatically */
-static const struct rte_eth_conf vmdq_conf_default = {
-	.rxmode = {
-		.mq_mode        = ETH_MQ_RX_VMDQ_ONLY,
-		.split_hdr_size = 0,
-		.ignore_offload_bitfield = 1,
-	},
-
-	.txmode = {
-		.mq_mode = ETH_MQ_TX_NONE,
-	},
-	.rx_adv_conf = {
-		/*
-		 * should be overridden separately in code with
-		 * appropriate values
-		 */
-		.vmdq_rx_conf = {
-			.nb_queue_pools = ETH_8_POOLS,
-			.enable_default_pool = 0,
-			.default_pool = 0,
-			.nb_pool_maps = 0,
-			.pool_map = {{0, 0},},
-		},
-	},
-};
-
-static unsigned lcore_ids[RTE_MAX_LCORE];
-static uint16_t ports[RTE_MAX_ETHPORTS];
-static unsigned num_ports; /**< The number of ports specified in command line */
-
-/* array used for printing out statistics */
-volatile unsigned long rxPackets[MAX_QUEUES] = {0};
-
-const uint16_t vlan_tags[] = {
-	0,  1,  2,  3,  4,  5,  6,  7,
-	8,  9, 10, 11,	12, 13, 14, 15,
-	16, 17, 18, 19, 20, 21, 22, 23,
-	24, 25, 26, 27, 28, 29, 30, 31,
-	32, 33, 34, 35, 36, 37, 38, 39,
-	40, 41, 42, 43, 44, 45, 46, 47,
-	48, 49, 50, 51, 52, 53, 54, 55,
-	56, 57, 58, 59, 60, 61, 62, 63,
-};
-const uint16_t num_vlans = RTE_DIM(vlan_tags);
-static uint16_t num_pf_queues,  num_vmdq_queues;
-static uint16_t vmdq_pool_base, vmdq_queue_base;
-/* pool mac addr template, pool mac addr is like: 52 54 00 12 port# pool# */
-static struct ether_addr pool_addr_template = {
-	.addr_bytes = {0x52, 0x54, 0x00, 0x12, 0x00, 0x00}
-};
-
-/* ethernet addresses of ports */
-static struct ether_addr vmdq_ports_eth_addr[RTE_MAX_ETHPORTS];
-
-#define MAX_QUEUE_NUM_10G 128
-#define MAX_QUEUE_NUM_1G 8
-#define MAX_POOL_MAP_NUM_10G 64
-#define MAX_POOL_MAP_NUM_1G 32
-#define MAX_POOL_NUM_10G 64
-#define MAX_POOL_NUM_1G 8
-/*
- * Builds up the correct configuration for vmdq based on the vlan tags array
- * given above, and determine the queue number and pool map number according to
- * valid pool number
- */
-static inline int
-get_eth_conf(struct rte_eth_conf *eth_conf, uint32_t num_pools)
-{
-	struct rte_eth_vmdq_rx_conf conf;
-	unsigned i;
-
-	conf.nb_queue_pools = (enum rte_eth_nb_pools)num_pools;
-	conf.nb_pool_maps = num_pools;
-	conf.enable_default_pool = 0;
-	conf.default_pool = 0; /* set explicit value, even if not used */
-
-	for (i = 0; i < conf.nb_pool_maps; i++) {
-		conf.pool_map[i].vlan_id = vlan_tags[i];
-		conf.pool_map[i].pools = (1UL << (i % num_pools));
-	}
-
-	(void)(rte_memcpy(eth_conf, &vmdq_conf_default, sizeof(*eth_conf)));
-	(void)(rte_memcpy(&eth_conf->rx_adv_conf.vmdq_rx_conf, &conf,
-		   sizeof(eth_conf->rx_adv_conf.vmdq_rx_conf)));
-	return 0;
-}
-
-/*
- * Initialises a given port using global settings and with the rx buffers
- * coming from the mbuf_pool passed as parameter
- */
-static inline int
-port_init(uint16_t port, struct rte_mempool *mbuf_pool)
-{
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_rxconf *rxconf;
-	struct rte_eth_txconf *txconf;
-	struct rte_eth_conf port_conf;
-	uint16_t rxRings, txRings;
-	uint16_t rxRingSize = RTE_TEST_RX_DESC_DEFAULT;
-	uint16_t txRingSize = RTE_TEST_TX_DESC_DEFAULT;
-	int retval;
-	uint16_t q;
-	uint16_t queues_per_pool;
-	uint32_t max_nb_pools;
-
-	/*
-	 * The max pool number from dev_info will be used to validate the pool
-	 * number specified in cmd line
-	 */
-	rte_eth_dev_info_get(port, &dev_info);
-	max_nb_pools = (uint32_t)dev_info.max_vmdq_pools;
-	/*
-	 * We allow to process part of VMDQ pools specified by num_pools in
-	 * command line.
-	 */
-	if (num_pools > max_nb_pools) {
-		printf("num_pools %d >max_nb_pools %d\n",
-			num_pools, max_nb_pools);
-		return -1;
-	}
-	retval = get_eth_conf(&port_conf, max_nb_pools);
-	if (retval < 0)
-		return retval;
-
-	/*
-	 * NIC queues are divided into pf queues and vmdq queues.
-	 */
-	/* There is assumption here all ports have the same configuration! */
-	num_pf_queues = dev_info.max_rx_queues - dev_info.vmdq_queue_num;
-	queues_per_pool = dev_info.vmdq_queue_num / dev_info.max_vmdq_pools;
-	num_vmdq_queues = num_pools * queues_per_pool;
-	num_queues = num_pf_queues + num_vmdq_queues;
-	vmdq_queue_base = dev_info.vmdq_queue_base;
-	vmdq_pool_base  = dev_info.vmdq_pool_base;
-
-	printf("pf queue num: %u, configured vmdq pool num: %u,"
-		" each vmdq pool has %u queues\n",
-		num_pf_queues, num_pools, queues_per_pool);
-	printf("vmdq queue base: %d pool base %d\n",
-		vmdq_queue_base, vmdq_pool_base);
-	if (!rte_eth_dev_is_valid_port(port))
-		return -1;
-
-	/*
-	 * Though in this example, we only receive packets from the first queue
-	 * of each pool and send packets through first rte_lcore_count() tx
-	 * queues of vmdq queues, all queues including pf queues are setup.
-	 * This is because VMDQ queues doesn't always start from zero, and the
-	 * PMD layer doesn't support selectively initialising part of rx/tx
-	 * queues.
-	 */
-	rxRings = (uint16_t)dev_info.max_rx_queues;
-	txRings = (uint16_t)dev_info.max_tx_queues;
-
-	rte_eth_dev_info_get(port, &dev_info);
-	if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-		port_conf.txmode.offloads |=
-			DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-	retval = rte_eth_dev_configure(port, rxRings, txRings, &port_conf);
-	if (retval != 0)
-		return retval;
-
-	retval = rte_eth_dev_adjust_nb_rx_tx_desc(port, &rxRingSize,
-				&txRingSize);
-	if (retval != 0)
-		return retval;
-	if (RTE_MAX(rxRingSize, txRingSize) > RTE_MAX(RTE_TEST_RX_DESC_DEFAULT,
-			RTE_TEST_TX_DESC_DEFAULT)) {
-		printf("Mbuf pool has an insufficient size for port %u.\n",
-			port);
-		return -1;
-	}
-
-	rxconf = &dev_info.default_rxconf;
-	rxconf->rx_drop_en = 1;
-	txconf = &dev_info.default_txconf;
-	txconf->txq_flags = ETH_TXQ_FLAGS_IGNORE;
-	txconf->offloads = port_conf.txmode.offloads;
-	for (q = 0; q < rxRings; q++) {
-		retval = rte_eth_rx_queue_setup(port, q, rxRingSize,
-					rte_eth_dev_socket_id(port),
-					rxconf,
-					mbuf_pool);
-		if (retval < 0) {
-			printf("initialise rx queue %d failed\n", q);
-			return retval;
-		}
-	}
-
-	for (q = 0; q < txRings; q++) {
-		retval = rte_eth_tx_queue_setup(port, q, txRingSize,
-					rte_eth_dev_socket_id(port),
-					txconf);
-		if (retval < 0) {
-			printf("initialise tx queue %d failed\n", q);
-			return retval;
-		}
-	}
-
-	retval  = rte_eth_dev_start(port);
-	if (retval < 0) {
-		printf("port %d start failed\n", port);
-		return retval;
-	}
-
-	rte_eth_macaddr_get(port, &vmdq_ports_eth_addr[port]);
-	printf("Port %u MAC: %02"PRIx8" %02"PRIx8" %02"PRIx8
-			" %02"PRIx8" %02"PRIx8" %02"PRIx8"\n",
-			(unsigned)port,
-			vmdq_ports_eth_addr[port].addr_bytes[0],
-			vmdq_ports_eth_addr[port].addr_bytes[1],
-			vmdq_ports_eth_addr[port].addr_bytes[2],
-			vmdq_ports_eth_addr[port].addr_bytes[3],
-			vmdq_ports_eth_addr[port].addr_bytes[4],
-			vmdq_ports_eth_addr[port].addr_bytes[5]);
-
-	/*
-	 * Set mac for each pool.
-	 * There is no default mac for the pools in i40.
-	 * Removes this after i40e fixes this issue.
-	 */
-	for (q = 0; q < num_pools; q++) {
-		struct ether_addr mac;
-		mac = pool_addr_template;
-		mac.addr_bytes[4] = port;
-		mac.addr_bytes[5] = q;
-		printf("Port %u vmdq pool %u set mac %02x:%02x:%02x:%02x:%02x:%02x\n",
-			port, q,
-			mac.addr_bytes[0], mac.addr_bytes[1],
-			mac.addr_bytes[2], mac.addr_bytes[3],
-			mac.addr_bytes[4], mac.addr_bytes[5]);
-		retval = rte_eth_dev_mac_addr_add(port, &mac,
-				q + vmdq_pool_base);
-		if (retval) {
-			printf("mac addr add failed at pool %d\n", q);
-			return retval;
-		}
-	}
-
-	return 0;
-}
-
-/* Check num_pools parameter and set it if OK*/
-static int
-vmdq_parse_num_pools(const char *q_arg)
-{
-	char *end = NULL;
-	int n;
-
-	/* parse number string */
-	n = strtol(q_arg, &end, 10);
-	if ((q_arg[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (num_pools > num_vlans) {
-		printf("num_pools %d > num_vlans %d\n", num_pools, num_vlans);
-		return -1;
-	}
-
-	num_pools = n;
-
-	return 0;
-}
-
-
-static int
-parse_portmask(const char *portmask)
-{
-	char *end = NULL;
-	unsigned long pm;
-
-	/* parse hexadecimal string */
-	pm = strtoul(portmask, &end, 16);
-	if ((portmask[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (pm == 0)
-		return -1;
-
-	return pm;
-}
-
-/* Display usage */
-static void
-vmdq_usage(const char *prgname)
-{
-	printf("%s [EAL options] -- -p PORTMASK]\n"
-	"  --nb-pools NP: number of pools\n",
-	       prgname);
-}
-
-/*  Parse the argument (num_pools) given in the command line of the application */
-static int
-vmdq_parse_args(int argc, char **argv)
-{
-	int opt;
-	int option_index;
-	unsigned i;
-	const char *prgname = argv[0];
-	static struct option long_option[] = {
-		{"nb-pools", required_argument, NULL, 0},
-		{NULL, 0, 0, 0}
-	};
-
-	/* Parse command line */
-	while ((opt = getopt_long(argc, argv, "p:", long_option,
-		&option_index)) != EOF) {
-		switch (opt) {
-		/* portmask */
-		case 'p':
-			enabled_port_mask = parse_portmask(optarg);
-			if (enabled_port_mask == 0) {
-				printf("invalid portmask\n");
-				vmdq_usage(prgname);
-				return -1;
-			}
-			break;
-		case 0:
-			if (vmdq_parse_num_pools(optarg) == -1) {
-				printf("invalid number of pools\n");
-				vmdq_usage(prgname);
-				return -1;
-			}
-			break;
-
-		default:
-			vmdq_usage(prgname);
-			return -1;
-		}
-	}
-
-	for (i = 0; i < RTE_MAX_ETHPORTS; i++) {
-		if (enabled_port_mask & (1 << i))
-			ports[num_ports++] = (uint8_t)i;
-	}
-
-	if (num_ports < 2 || num_ports % 2) {
-		printf("Current enabled port number is %u,"
-			"but it should be even and at least 2\n", num_ports);
-		return -1;
-	}
-
-	return 0;
-}
-
-static void
-update_mac_address(struct rte_mbuf *m, unsigned dst_port)
-{
-	struct ether_hdr *eth;
-	void *tmp;
-
-	eth = rte_pktmbuf_mtod(m, struct ether_hdr *);
-
-	/* 02:00:00:00:00:xx */
-	tmp = &eth->d_addr.addr_bytes[0];
-	*((uint64_t *)tmp) = 0x000000000002 + ((uint64_t)dst_port << 40);
-
-	/* src addr */
-	ether_addr_copy(&vmdq_ports_eth_addr[dst_port], &eth->s_addr);
-}
-
-/* When we receive a HUP signal, print out our stats */
-static void
-sighup_handler(int signum)
-{
-	unsigned q;
-	for (q = 0; q < num_queues; q++) {
-		if (q % (num_queues/num_pools) == 0)
-			printf("\nPool %u: ", q/(num_queues/num_pools));
-		printf("%lu ", rxPackets[q]);
-	}
-	printf("\nFinished handling signal %d\n", signum);
-}
-
-/*
- * Main thread that does the work, reading from INPUT_PORT
- * and writing to OUTPUT_PORT
- */
-static int
-lcore_main(__attribute__((__unused__)) void *dummy)
-{
-	const uint16_t lcore_id = (uint16_t)rte_lcore_id();
-	const uint16_t num_cores = (uint16_t)rte_lcore_count();
-	uint16_t core_id = 0;
-	uint16_t startQueue, endQueue;
-	uint16_t q, i, p;
-	const uint16_t remainder = (uint16_t)(num_vmdq_queues % num_cores);
-
-	for (i = 0; i < num_cores; i++)
-		if (lcore_ids[i] == lcore_id) {
-			core_id = i;
-			break;
-		}
-
-	if (remainder != 0) {
-		if (core_id < remainder) {
-			startQueue = (uint16_t)(core_id *
-					(num_vmdq_queues / num_cores + 1));
-			endQueue = (uint16_t)(startQueue +
-					(num_vmdq_queues / num_cores) + 1);
-		} else {
-			startQueue = (uint16_t)(core_id *
-					(num_vmdq_queues / num_cores) +
-					remainder);
-			endQueue = (uint16_t)(startQueue +
-					(num_vmdq_queues / num_cores));
-		}
-	} else {
-		startQueue = (uint16_t)(core_id *
-				(num_vmdq_queues / num_cores));
-		endQueue = (uint16_t)(startQueue +
-				(num_vmdq_queues / num_cores));
-	}
-
-	/* vmdq queue idx doesn't always start from zero.*/
-	startQueue += vmdq_queue_base;
-	endQueue   += vmdq_queue_base;
-	printf("core %u(lcore %u) reading queues %i-%i\n", (unsigned)core_id,
-		(unsigned)lcore_id, startQueue, endQueue - 1);
-
-	if (startQueue == endQueue) {
-		printf("lcore %u has nothing to do\n", lcore_id);
-		return 0;
-	}
-
-	for (;;) {
-		struct rte_mbuf *buf[MAX_PKT_BURST];
-		const uint16_t buf_size = sizeof(buf) / sizeof(buf[0]);
-
-		for (p = 0; p < num_ports; p++) {
-			const uint8_t sport = ports[p];
-			/* 0 <-> 1, 2 <-> 3 etc */
-			const uint8_t dport = ports[p ^ 1];
-			if ((sport == INVALID_PORT_ID) || (dport == INVALID_PORT_ID))
-				continue;
-
-			for (q = startQueue; q < endQueue; q++) {
-				const uint16_t rxCount = rte_eth_rx_burst(sport,
-					q, buf, buf_size);
-
-				if (unlikely(rxCount == 0))
-					continue;
-
-				rxPackets[q] += rxCount;
-
-				for (i = 0; i < rxCount; i++)
-					update_mac_address(buf[i], dport);
-
-				const uint16_t txCount = rte_eth_tx_burst(dport,
-					vmdq_queue_base + core_id,
-					buf,
-					rxCount);
-
-				if (txCount != rxCount) {
-					for (i = txCount; i < rxCount; i++)
-						rte_pktmbuf_free(buf[i]);
-				}
-			}
-		}
-	}
-}
-
-/*
- * Update the global var NUM_PORTS and array PORTS according to system ports number
- * and return valid ports number
- */
-static unsigned check_ports_num(unsigned nb_ports)
-{
-	unsigned valid_num_ports = num_ports;
-	unsigned portid;
-
-	if (num_ports > nb_ports) {
-		printf("\nSpecified port number(%u) exceeds total system port number(%u)\n",
-			num_ports, nb_ports);
-		num_ports = nb_ports;
-	}
-
-	for (portid = 0; portid < num_ports; portid++) {
-		if (!rte_eth_dev_is_valid_port(ports[portid])) {
-			printf("\nSpecified port ID(%u) is not valid\n",
-				ports[portid]);
-			ports[portid] = INVALID_PORT_ID;
-			valid_num_ports--;
-		}
-	}
-	return valid_num_ports;
-}
-
-/* Main function, does initialisation and calls the per-lcore functions */
-int
-main(int argc, char *argv[])
-{
-	struct rte_mempool *mbuf_pool;
-	unsigned lcore_id, core_id = 0;
-	int ret;
-	unsigned nb_ports, valid_num_ports;
-	uint16_t portid;
-
-	signal(SIGHUP, sighup_handler);
-
-	/* init EAL */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Error with EAL initialization\n");
-	argc -= ret;
-	argv += ret;
-
-	/* parse app arguments */
-	ret = vmdq_parse_args(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid VMDQ argument\n");
-
-	for (lcore_id = 0; lcore_id < RTE_MAX_LCORE; lcore_id++)
-		if (rte_lcore_is_enabled(lcore_id))
-			lcore_ids[core_id++] = lcore_id;
-
-	if (rte_lcore_count() > RTE_MAX_LCORE)
-		rte_exit(EXIT_FAILURE, "Not enough cores\n");
-
-	nb_ports = rte_eth_dev_count();
-
-	/*
-	 * Update the global var NUM_PORTS and global array PORTS
-	 * and get value of var VALID_NUM_PORTS according to system ports number
-	 */
-	valid_num_ports = check_ports_num(nb_ports);
-
-	if (valid_num_ports < 2 || valid_num_ports % 2) {
-		printf("Current valid ports number is %u\n", valid_num_ports);
-		rte_exit(EXIT_FAILURE, "Error with valid ports number is not even or less than 2\n");
-	}
-
-	mbuf_pool = rte_pktmbuf_pool_create("MBUF_POOL",
-		NUM_MBUFS_PER_PORT * nb_ports, MBUF_CACHE_SIZE,
-		0, RTE_MBUF_DEFAULT_BUF_SIZE, rte_socket_id());
-	if (mbuf_pool == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot create mbuf pool\n");
-
-	/* initialize all ports */
-	RTE_ETH_FOREACH_DEV(portid) {
-		/* skip ports that are not enabled */
-		if ((enabled_port_mask & (1 << portid)) == 0) {
-			printf("\nSkipping disabled port %d\n", portid);
-			continue;
-		}
-		if (port_init(portid, mbuf_pool) != 0)
-			rte_exit(EXIT_FAILURE, "Cannot initialize network ports\n");
-	}
-
-	/* call lcore_main() on every lcore */
-	rte_eal_mp_remote_launch(lcore_main, NULL, CALL_MASTER);
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		if (rte_eal_wait_lcore(lcore_id) < 0)
-			return -1;
-	}
-
-	return 0;
-}
diff --git a/examples/vmdq/meson.build b/examples/vmdq/meson.build
deleted file mode 100644
index 2b0a250..0000000
--- a/examples/vmdq/meson.build
+++ /dev/null
@@ -1,12 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-allow_experimental_apis = true
-sources = files(
-	'main.c'
-)
diff --git a/examples/vmdq_dcb/Makefile b/examples/vmdq_dcb/Makefile
deleted file mode 100644
index 3bd80a0..0000000
--- a/examples/vmdq_dcb/Makefile
+++ /dev/null
@@ -1,67 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2010-2014 Intel Corporation
-
-# binary name
-APP = vmdq_dcb_app
-
-# all source are stored in SRCS-y
-SRCS-y := main.c
-
-# Build using pkg-config variables if possible
-$(shell pkg-config --exists libdpdk)
-ifeq ($(.SHELLSTATUS),0)
-
-all: shared
-.PHONY: shared static
-shared: build/$(APP)-shared
-	ln -sf $(APP)-shared build/$(APP)
-static: build/$(APP)-static
-	ln -sf $(APP)-static build/$(APP)
-
-PC_FILE := $(shell pkg-config --path libdpdk)
-CFLAGS += -O3 $(shell pkg-config --cflags libdpdk)
-LDFLAGS_SHARED = $(shell pkg-config --libs libdpdk)
-LDFLAGS_STATIC = -Wl,-Bstatic $(shell pkg-config --static --libs libdpdk)
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-
-build/$(APP)-shared: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_SHARED)
-
-build/$(APP)-static: $(SRCS-y) Makefile $(PC_FILE) | build
-	$(CC) $(CFLAGS) $(SRCS-y) -o $@ $(LDFLAGS) $(LDFLAGS_STATIC)
-
-build:
-	@mkdir -p $@
-
-.PHONY: clean
-clean:
-	rm -f build/$(APP) build/$(APP)-static build/$(APP)-shared
-	rmdir --ignore-fail-on-non-empty build
-
-else # Build using legacy build system
-
-ifeq ($(RTE_SDK),)
-$(error "Please define RTE_SDK environment variable")
-endif
-
-# Default target, can be overridden by command line or environment
-RTE_TARGET ?= x86_64-native-linuxapp-gcc
-
-include $(RTE_SDK)/mk/rte.vars.mk
-
-CFLAGS += -DALLOW_EXPERIMENTAL_API
-CFLAGS += $(WERROR_FLAGS)
-
-# workaround for a gcc bug with noreturn attribute
-# http://gcc.gnu.org/bugzilla/show_bug.cgi?id=12603
-ifeq ($(CONFIG_RTE_TOOLCHAIN_GCC),y)
-CFLAGS_main.o += -Wno-return-type
-endif
-ifeq ($(CONFIG_RTE_TOOLCHAIN_ICC),y)
-CFLAGS_main.o += -diag-disable=vec
-endif
-EXTRA_CFLAGS += -O3 -g
-
-include $(RTE_SDK)/mk/rte.extapp.mk
-endif
diff --git a/examples/vmdq_dcb/main.c b/examples/vmdq_dcb/main.c
deleted file mode 100644
index 9c68ab0..0000000
--- a/examples/vmdq_dcb/main.c
+++ /dev/null
@@ -1,684 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(c) 2010-2014 Intel Corporation
- */
-
-#include <stdint.h>
-#include <sys/queue.h>
-#include <stdlib.h>
-#include <string.h>
-#include <stdio.h>
-#include <assert.h>
-#include <errno.h>
-#include <signal.h>
-#include <stdarg.h>
-#include <inttypes.h>
-#include <getopt.h>
-
-#include <rte_common.h>
-#include <rte_log.h>
-#include <rte_memory.h>
-#include <rte_memcpy.h>
-#include <rte_eal.h>
-#include <rte_launch.h>
-#include <rte_atomic.h>
-#include <rte_cycles.h>
-#include <rte_prefetch.h>
-#include <rte_lcore.h>
-#include <rte_per_lcore.h>
-#include <rte_branch_prediction.h>
-#include <rte_interrupts.h>
-#include <rte_random.h>
-#include <rte_debug.h>
-#include <rte_ether.h>
-#include <rte_ethdev.h>
-#include <rte_mempool.h>
-#include <rte_mbuf.h>
-
-/* basic constants used in application */
-#define MAX_QUEUES 1024
-/*
- * 1024 queues require to meet the needs of a large number of vmdq_pools.
- * (RX/TX_queue_nb * RX/TX_ring_descriptors_nb) per port.
- */
-#define NUM_MBUFS_PER_PORT (MAX_QUEUES * RTE_MAX(RTE_TEST_RX_DESC_DEFAULT, \
-						RTE_TEST_TX_DESC_DEFAULT))
-#define MBUF_CACHE_SIZE 64
-
-#define MAX_PKT_BURST 32
-
-/*
- * Configurable number of RX/TX ring descriptors
- */
-#define RTE_TEST_RX_DESC_DEFAULT 1024
-#define RTE_TEST_TX_DESC_DEFAULT 1024
-
-#define INVALID_PORT_ID 0xFF
-
-/* mask of enabled ports */
-static uint32_t enabled_port_mask;
-static uint16_t ports[RTE_MAX_ETHPORTS];
-static unsigned num_ports;
-
-/* number of pools (if user does not specify any, 32 by default */
-static enum rte_eth_nb_pools num_pools = ETH_32_POOLS;
-static enum rte_eth_nb_tcs   num_tcs   = ETH_4_TCS;
-static uint16_t num_queues, num_vmdq_queues;
-static uint16_t vmdq_pool_base, vmdq_queue_base;
-static uint8_t rss_enable;
-
-/* empty vmdq+dcb configuration structure. Filled in programatically */
-static const struct rte_eth_conf vmdq_dcb_conf_default = {
-	.rxmode = {
-		.mq_mode        = ETH_MQ_RX_VMDQ_DCB,
-		.split_hdr_size = 0,
-		.ignore_offload_bitfield = 1,
-	},
-	.txmode = {
-		.mq_mode = ETH_MQ_TX_VMDQ_DCB,
-	},
-	/*
-	 * should be overridden separately in code with
-	 * appropriate values
-	 */
-	.rx_adv_conf = {
-		.vmdq_dcb_conf = {
-			.nb_queue_pools = ETH_32_POOLS,
-			.enable_default_pool = 0,
-			.default_pool = 0,
-			.nb_pool_maps = 0,
-			.pool_map = {{0, 0},},
-			.dcb_tc = {0},
-		},
-		.dcb_rx_conf = {
-				.nb_tcs = ETH_4_TCS,
-				/** Traffic class each UP mapped to. */
-				.dcb_tc = {0},
-		},
-		.vmdq_rx_conf = {
-			.nb_queue_pools = ETH_32_POOLS,
-			.enable_default_pool = 0,
-			.default_pool = 0,
-			.nb_pool_maps = 0,
-			.pool_map = {{0, 0},},
-		},
-	},
-	.tx_adv_conf = {
-		.vmdq_dcb_tx_conf = {
-			.nb_queue_pools = ETH_32_POOLS,
-			.dcb_tc = {0},
-		},
-	},
-};
-
-/* array used for printing out statistics */
-volatile unsigned long rxPackets[MAX_QUEUES] = {0};
-
-const uint16_t vlan_tags[] = {
-	0,  1,  2,  3,  4,  5,  6,  7,
-	8,  9, 10, 11,	12, 13, 14, 15,
-	16, 17, 18, 19, 20, 21, 22, 23,
-	24, 25, 26, 27, 28, 29, 30, 31
-};
-
-const uint16_t num_vlans = RTE_DIM(vlan_tags);
-/* pool mac addr template, pool mac addr is like: 52 54 00 12 port# pool# */
-static struct ether_addr pool_addr_template = {
-	.addr_bytes = {0x52, 0x54, 0x00, 0x12, 0x00, 0x00}
-};
-
-/* ethernet addresses of ports */
-static struct ether_addr vmdq_ports_eth_addr[RTE_MAX_ETHPORTS];
-
-/* Builds up the correct configuration for vmdq+dcb based on the vlan tags array
- * given above, and the number of traffic classes available for use. */
-static inline int
-get_eth_conf(struct rte_eth_conf *eth_conf)
-{
-	struct rte_eth_vmdq_dcb_conf conf;
-	struct rte_eth_vmdq_rx_conf  vmdq_conf;
-	struct rte_eth_dcb_rx_conf   dcb_conf;
-	struct rte_eth_vmdq_dcb_tx_conf tx_conf;
-	uint8_t i;
-
-	conf.nb_queue_pools = (enum rte_eth_nb_pools)num_pools;
-	vmdq_conf.nb_queue_pools = (enum rte_eth_nb_pools)num_pools;
-	tx_conf.nb_queue_pools = (enum rte_eth_nb_pools)num_pools;
-	conf.nb_pool_maps = num_pools;
-	vmdq_conf.nb_pool_maps = num_pools;
-	conf.enable_default_pool = 0;
-	vmdq_conf.enable_default_pool = 0;
-	conf.default_pool = 0; /* set explicit value, even if not used */
-	vmdq_conf.default_pool = 0;
-
-	for (i = 0; i < conf.nb_pool_maps; i++) {
-		conf.pool_map[i].vlan_id = vlan_tags[i];
-		vmdq_conf.pool_map[i].vlan_id = vlan_tags[i];
-		conf.pool_map[i].pools = 1UL << i;
-		vmdq_conf.pool_map[i].pools = 1UL << i;
-	}
-	for (i = 0; i < ETH_DCB_NUM_USER_PRIORITIES; i++){
-		conf.dcb_tc[i] = i % num_tcs;
-		dcb_conf.dcb_tc[i] = i % num_tcs;
-		tx_conf.dcb_tc[i] = i % num_tcs;
-	}
-	dcb_conf.nb_tcs = (enum rte_eth_nb_tcs)num_tcs;
-	(void)(rte_memcpy(eth_conf, &vmdq_dcb_conf_default, sizeof(*eth_conf)));
-	(void)(rte_memcpy(&eth_conf->rx_adv_conf.vmdq_dcb_conf, &conf,
-			  sizeof(conf)));
-	(void)(rte_memcpy(&eth_conf->rx_adv_conf.dcb_rx_conf, &dcb_conf,
-			  sizeof(dcb_conf)));
-	(void)(rte_memcpy(&eth_conf->rx_adv_conf.vmdq_rx_conf, &vmdq_conf,
-			  sizeof(vmdq_conf)));
-	(void)(rte_memcpy(&eth_conf->tx_adv_conf.vmdq_dcb_tx_conf, &tx_conf,
-			  sizeof(tx_conf)));
-	if (rss_enable) {
-		eth_conf->rxmode.mq_mode = ETH_MQ_RX_VMDQ_DCB_RSS;
-		eth_conf->rx_adv_conf.rss_conf.rss_hf = ETH_RSS_IP |
-							ETH_RSS_UDP |
-							ETH_RSS_TCP |
-							ETH_RSS_SCTP;
-	}
-	return 0;
-}
-
-/*
- * Initialises a given port using global settings and with the rx buffers
- * coming from the mbuf_pool passed as parameter
- */
-static inline int
-port_init(uint16_t port, struct rte_mempool *mbuf_pool)
-{
-	struct rte_eth_dev_info dev_info;
-	struct rte_eth_conf port_conf = {0};
-	uint16_t rxRingSize = RTE_TEST_RX_DESC_DEFAULT;
-	uint16_t txRingSize = RTE_TEST_TX_DESC_DEFAULT;
-	int retval;
-	uint16_t q;
-	uint16_t queues_per_pool;
-	uint32_t max_nb_pools;
-	struct rte_eth_txconf txq_conf;
-
-	/*
-	 * The max pool number from dev_info will be used to validate the pool
-	 * number specified in cmd line
-	 */
-	rte_eth_dev_info_get(port, &dev_info);
-	max_nb_pools = (uint32_t)dev_info.max_vmdq_pools;
-	/*
-	 * We allow to process part of VMDQ pools specified by num_pools in
-	 * command line.
-	 */
-	if (num_pools > max_nb_pools) {
-		printf("num_pools %d >max_nb_pools %d\n",
-			num_pools, max_nb_pools);
-		return -1;
-	}
-
-	/*
-	 * NIC queues are divided into pf queues and vmdq queues.
-	 * There is assumption here all ports have the same configuration!
-	*/
-	vmdq_queue_base = dev_info.vmdq_queue_base;
-	vmdq_pool_base  = dev_info.vmdq_pool_base;
-	printf("vmdq queue base: %d pool base %d\n",
-		vmdq_queue_base, vmdq_pool_base);
-	if (vmdq_pool_base == 0) {
-		num_vmdq_queues = dev_info.max_rx_queues;
-		num_queues = dev_info.max_rx_queues;
-		if (num_tcs != num_vmdq_queues / num_pools) {
-			printf("nb_tcs %d is invalid considering with"
-				" nb_pools %d, nb_tcs * nb_pools should = %d\n",
-				num_tcs, num_pools, num_vmdq_queues);
-			return -1;
-		}
-	} else {
-		queues_per_pool = dev_info.vmdq_queue_num /
-				  dev_info.max_vmdq_pools;
-		if (num_tcs > queues_per_pool) {
-			printf("num_tcs %d > num of queues per pool %d\n",
-				num_tcs, queues_per_pool);
-			return -1;
-		}
-		num_vmdq_queues = num_pools * queues_per_pool;
-		num_queues = vmdq_queue_base + num_vmdq_queues;
-		printf("Configured vmdq pool num: %u,"
-			" each vmdq pool has %u queues\n",
-			num_pools, queues_per_pool);
-	}
-
-	if (!rte_eth_dev_is_valid_port(port))
-		return -1;
-
-	retval = get_eth_conf(&port_conf);
-	if (retval < 0)
-		return retval;
-
-	rte_eth_dev_info_get(port, &dev_info);
-	if (dev_info.tx_offload_capa & DEV_TX_OFFLOAD_MBUF_FAST_FREE)
-		port_conf.txmode.offloads |=
-			DEV_TX_OFFLOAD_MBUF_FAST_FREE;
-	/*
-	 * Though in this example, all queues including pf queues are setup.
-	 * This is because VMDQ queues doesn't always start from zero, and the
-	 * PMD layer doesn't support selectively initialising part of rx/tx
-	 * queues.
-	 */
-	retval = rte_eth_dev_configure(port, num_queues, num_queues, &port_conf);
-	if (retval != 0)
-		return retval;
-
-	retval = rte_eth_dev_adjust_nb_rx_tx_desc(port, &rxRingSize,
-				&txRingSize);
-	if (retval != 0)
-		return retval;
-	if (RTE_MAX(rxRingSize, txRingSize) >
-	    RTE_MAX(RTE_TEST_RX_DESC_DEFAULT, RTE_TEST_TX_DESC_DEFAULT)) {
-		printf("Mbuf pool has an insufficient size for port %u.\n",
-			port);
-		return -1;
-	}
-
-	for (q = 0; q < num_queues; q++) {
-		retval = rte_eth_rx_queue_setup(port, q, rxRingSize,
-					rte_eth_dev_socket_id(port),
-					NULL,
-					mbuf_pool);
-		if (retval < 0) {
-			printf("initialize rx queue %d failed\n", q);
-			return retval;
-		}
-	}
-
-	txq_conf = dev_info.default_txconf;
-	txq_conf.txq_flags = ETH_TXQ_FLAGS_IGNORE;
-	txq_conf.offloads = port_conf.txmode.offloads;
-	for (q = 0; q < num_queues; q++) {
-		retval = rte_eth_tx_queue_setup(port, q, txRingSize,
-					rte_eth_dev_socket_id(port),
-					&txq_conf);
-		if (retval < 0) {
-			printf("initialize tx queue %d failed\n", q);
-			return retval;
-		}
-	}
-
-	retval  = rte_eth_dev_start(port);
-	if (retval < 0) {
-		printf("port %d start failed\n", port);
-		return retval;
-	}
-
-	rte_eth_macaddr_get(port, &vmdq_ports_eth_addr[port]);
-	printf("Port %u MAC: %02"PRIx8" %02"PRIx8" %02"PRIx8
-			" %02"PRIx8" %02"PRIx8" %02"PRIx8"\n",
-			(unsigned)port,
-			vmdq_ports_eth_addr[port].addr_bytes[0],
-			vmdq_ports_eth_addr[port].addr_bytes[1],
-			vmdq_ports_eth_addr[port].addr_bytes[2],
-			vmdq_ports_eth_addr[port].addr_bytes[3],
-			vmdq_ports_eth_addr[port].addr_bytes[4],
-			vmdq_ports_eth_addr[port].addr_bytes[5]);
-
-	/* Set mac for each pool.*/
-	for (q = 0; q < num_pools; q++) {
-		struct ether_addr mac;
-
-		mac = pool_addr_template;
-		mac.addr_bytes[4] = port;
-		mac.addr_bytes[5] = q;
-		printf("Port %u vmdq pool %u set mac %02x:%02x:%02x:%02x:%02x:%02x\n",
-			port, q,
-			mac.addr_bytes[0], mac.addr_bytes[1],
-			mac.addr_bytes[2], mac.addr_bytes[3],
-			mac.addr_bytes[4], mac.addr_bytes[5]);
-		retval = rte_eth_dev_mac_addr_add(port, &mac,
-				q + vmdq_pool_base);
-		if (retval) {
-			printf("mac addr add failed at pool %d\n", q);
-			return retval;
-		}
-	}
-
-	return 0;
-}
-
-/* Check num_pools parameter and set it if OK*/
-static int
-vmdq_parse_num_pools(const char *q_arg)
-{
-	char *end = NULL;
-	int n;
-
-	/* parse number string */
-	n = strtol(q_arg, &end, 10);
-	if ((q_arg[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-	if (n != 16 && n != 32)
-		return -1;
-	if (n == 16)
-		num_pools = ETH_16_POOLS;
-	else
-		num_pools = ETH_32_POOLS;
-
-	return 0;
-}
-
-/* Check num_tcs parameter and set it if OK*/
-static int
-vmdq_parse_num_tcs(const char *q_arg)
-{
-	char *end = NULL;
-	int n;
-
-	/* parse number string */
-	n = strtol(q_arg, &end, 10);
-	if ((q_arg[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (n != 4 && n != 8)
-		return -1;
-	if (n == 4)
-		num_tcs = ETH_4_TCS;
-	else
-		num_tcs = ETH_8_TCS;
-
-	return 0;
-}
-
-static int
-parse_portmask(const char *portmask)
-{
-	char *end = NULL;
-	unsigned long pm;
-
-	/* parse hexadecimal string */
-	pm = strtoul(portmask, &end, 16);
-	if ((portmask[0] == '\0') || (end == NULL) || (*end != '\0'))
-		return -1;
-
-	if (pm == 0)
-		return -1;
-
-	return pm;
-}
-
-/* Display usage */
-static void
-vmdq_usage(const char *prgname)
-{
-	printf("%s [EAL options] -- -p PORTMASK]\n"
-	"  --nb-pools NP: number of pools (32 default, 16)\n"
-	"  --nb-tcs NP: number of TCs (4 default, 8)\n"
-	"  --enable-rss: enable RSS (disabled by default)\n",
-	       prgname);
-}
-
-/*  Parse the argument (num_pools) given in the command line of the application */
-static int
-vmdq_parse_args(int argc, char **argv)
-{
-	int opt;
-	int option_index;
-	unsigned i;
-	const char *prgname = argv[0];
-	static struct option long_option[] = {
-		{"nb-pools", required_argument, NULL, 0},
-		{"nb-tcs", required_argument, NULL, 0},
-		{"enable-rss", 0, NULL, 0},
-		{NULL, 0, 0, 0}
-	};
-
-	/* Parse command line */
-	while ((opt = getopt_long(argc, argv, "p:", long_option,
-		&option_index)) != EOF) {
-		switch (opt) {
-		/* portmask */
-		case 'p':
-			enabled_port_mask = parse_portmask(optarg);
-			if (enabled_port_mask == 0) {
-				printf("invalid portmask\n");
-				vmdq_usage(prgname);
-				return -1;
-			}
-			break;
-		case 0:
-			if (!strcmp(long_option[option_index].name, "nb-pools")) {
-				if (vmdq_parse_num_pools(optarg) == -1) {
-					printf("invalid number of pools\n");
-					return -1;
-				}
-			}
-
-			if (!strcmp(long_option[option_index].name, "nb-tcs")) {
-				if (vmdq_parse_num_tcs(optarg) == -1) {
-					printf("invalid number of tcs\n");
-					return -1;
-				}
-			}
-
-			if (!strcmp(long_option[option_index].name, "enable-rss"))
-				rss_enable = 1;
-			break;
-
-		default:
-			vmdq_usage(prgname);
-			return -1;
-		}
-	}
-
-	for (i = 0; i < RTE_MAX_ETHPORTS; i++) {
-		if (enabled_port_mask & (1 << i))
-			ports[num_ports++] = (uint8_t)i;
-	}
-
-	if (num_ports < 2 || num_ports % 2) {
-		printf("Current enabled port number is %u,"
-			" but it should be even and at least 2\n", num_ports);
-		return -1;
-	}
-
-	return 0;
-}
-
-static void
-update_mac_address(struct rte_mbuf *m, unsigned dst_port)
-{
-	struct ether_hdr *eth;
-	void *tmp;
-
-	eth = rte_pktmbuf_mtod(m, struct ether_hdr *);
-
-	/* 02:00:00:00:00:xx */
-	tmp = &eth->d_addr.addr_bytes[0];
-	*((uint64_t *)tmp) = 0x000000000002 + ((uint64_t)dst_port << 40);
-
-	/* src addr */
-	ether_addr_copy(&vmdq_ports_eth_addr[dst_port], &eth->s_addr);
-}
-
-/* When we receive a HUP signal, print out our stats */
-static void
-sighup_handler(int signum)
-{
-	unsigned q = vmdq_queue_base;
-
-	for (; q < num_queues; q++) {
-		if (q % (num_vmdq_queues / num_pools) == 0)
-			printf("\nPool %u: ", (q - vmdq_queue_base) /
-					      (num_vmdq_queues / num_pools));
-		printf("%lu ", rxPackets[q]);
-	}
-	printf("\nFinished handling signal %d\n", signum);
-}
-
-/*
- * Main thread that does the work, reading from INPUT_PORT
- * and writing to OUTPUT_PORT
- */
-static int
-lcore_main(void *arg)
-{
-	const uintptr_t core_num = (uintptr_t)arg;
-	const unsigned num_cores = rte_lcore_count();
-	uint16_t startQueue, endQueue;
-	uint16_t q, i, p;
-	const uint16_t quot = (uint16_t)(num_vmdq_queues / num_cores);
-	const uint16_t remainder = (uint16_t)(num_vmdq_queues % num_cores);
-
-
-	if (remainder) {
-		if (core_num < remainder) {
-			startQueue = (uint16_t)(core_num * (quot + 1));
-			endQueue = (uint16_t)(startQueue + quot + 1);
-		} else {
-			startQueue = (uint16_t)(core_num * quot + remainder);
-			endQueue = (uint16_t)(startQueue + quot);
-		}
-	} else {
-		startQueue = (uint16_t)(core_num * quot);
-		endQueue = (uint16_t)(startQueue + quot);
-	}
-
-	/* vmdq queue idx doesn't always start from zero.*/
-	startQueue += vmdq_queue_base;
-	endQueue   += vmdq_queue_base;
-	printf("Core %u(lcore %u) reading queues %i-%i\n", (unsigned)core_num,
-	       rte_lcore_id(), startQueue, endQueue - 1);
-
-	if (startQueue == endQueue) {
-		printf("lcore %u has nothing to do\n", (unsigned)core_num);
-		return 0;
-	}
-
-	for (;;) {
-		struct rte_mbuf *buf[MAX_PKT_BURST];
-		const uint16_t buf_size = sizeof(buf) / sizeof(buf[0]);
-		for (p = 0; p < num_ports; p++) {
-			const uint8_t src = ports[p];
-			const uint8_t dst = ports[p ^ 1]; /* 0 <-> 1, 2 <-> 3 etc */
-
-			if ((src == INVALID_PORT_ID) || (dst == INVALID_PORT_ID))
-				continue;
-
-			for (q = startQueue; q < endQueue; q++) {
-				const uint16_t rxCount = rte_eth_rx_burst(src,
-					q, buf, buf_size);
-
-				if (unlikely(rxCount == 0))
-					continue;
-
-				rxPackets[q] += rxCount;
-
-				for (i = 0; i < rxCount; i++)
-					update_mac_address(buf[i], dst);
-
-				const uint16_t txCount = rte_eth_tx_burst(dst,
-					q, buf, rxCount);
-				if (txCount != rxCount) {
-					for (i = txCount; i < rxCount; i++)
-						rte_pktmbuf_free(buf[i]);
-				}
-			}
-		}
-	}
-}
-
-/*
- * Update the global var NUM_PORTS and array PORTS according to system ports number
- * and return valid ports number
- */
-static unsigned check_ports_num(unsigned nb_ports)
-{
-	unsigned valid_num_ports = num_ports;
-	unsigned portid;
-
-	if (num_ports > nb_ports) {
-		printf("\nSpecified port number(%u) exceeds total system port number(%u)\n",
-			num_ports, nb_ports);
-		num_ports = nb_ports;
-	}
-
-	for (portid = 0; portid < num_ports; portid++) {
-		if (!rte_eth_dev_is_valid_port(ports[portid])) {
-			printf("\nSpecified port ID(%u) is not valid\n",
-				ports[portid]);
-			ports[portid] = INVALID_PORT_ID;
-			valid_num_ports--;
-		}
-	}
-	return valid_num_ports;
-}
-
-
-/* Main function, does initialisation and calls the per-lcore functions */
-int
-main(int argc, char *argv[])
-{
-	unsigned cores;
-	struct rte_mempool *mbuf_pool;
-	unsigned lcore_id;
-	uintptr_t i;
-	int ret;
-	unsigned nb_ports, valid_num_ports;
-	uint16_t portid;
-
-	signal(SIGHUP, sighup_handler);
-
-	/* init EAL */
-	ret = rte_eal_init(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Error with EAL initialization\n");
-	argc -= ret;
-	argv += ret;
-
-	/* parse app arguments */
-	ret = vmdq_parse_args(argc, argv);
-	if (ret < 0)
-		rte_exit(EXIT_FAILURE, "Invalid VMDQ argument\n");
-
-	cores = rte_lcore_count();
-	if ((cores & (cores - 1)) != 0 || cores > RTE_MAX_LCORE) {
-		rte_exit(EXIT_FAILURE,"This program can only run on an even"
-				" number of cores(1-%d)\n\n", RTE_MAX_LCORE);
-	}
-
-	nb_ports = rte_eth_dev_count();
-
-	/*
-	 * Update the global var NUM_PORTS and global array PORTS
-	 * and get value of var VALID_NUM_PORTS according to system ports number
-	 */
-	valid_num_ports = check_ports_num(nb_ports);
-
-	if (valid_num_ports < 2 || valid_num_ports % 2) {
-		printf("Current valid ports number is %u\n", valid_num_ports);
-		rte_exit(EXIT_FAILURE, "Error with valid ports number is not even or less than 2\n");
-	}
-
-	mbuf_pool = rte_pktmbuf_pool_create("MBUF_POOL",
-		NUM_MBUFS_PER_PORT * nb_ports, MBUF_CACHE_SIZE,
-		0, RTE_MBUF_DEFAULT_BUF_SIZE, rte_socket_id());
-	if (mbuf_pool == NULL)
-		rte_exit(EXIT_FAILURE, "Cannot create mbuf pool\n");
-
-	/* initialize all ports */
-	RTE_ETH_FOREACH_DEV(portid) {
-		/* skip ports that are not enabled */
-		if ((enabled_port_mask & (1 << portid)) == 0) {
-			printf("\nSkipping disabled port %d\n", portid);
-			continue;
-		}
-		if (port_init(portid, mbuf_pool) != 0)
-			rte_exit(EXIT_FAILURE, "Cannot initialize network ports\n");
-	}
-
-	/* call lcore_main() on every slave lcore */
-	i = 0;
-	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		rte_eal_remote_launch(lcore_main, (void*)i++, lcore_id);
-	}
-	/* call on master too */
-	(void) lcore_main((void*)i);
-
-	return 0;
-}
diff --git a/examples/vmdq_dcb/meson.build b/examples/vmdq_dcb/meson.build
deleted file mode 100644
index 2b0a250..0000000
--- a/examples/vmdq_dcb/meson.build
+++ /dev/null
@@ -1,12 +0,0 @@
-# SPDX-License-Identifier: BSD-3-Clause
-# Copyright(c) 2017 Intel Corporation
-
-# meson file, for building this example as part of a main DPDK build.
-#
-# To build this example as a standalone application with an already-installed
-# DPDK instance, use 'make'
-
-allow_experimental_apis = true
-sources = files(
-	'main.c'
-)
diff --git a/lib/Makefile b/lib/Makefile
index ec965a6..9378464 100644
--- a/lib/Makefile
+++ b/lib/Makefile
@@ -9,10 +9,12 @@ DIRS-$(CONFIG_RTE_LIBRTE_PCI) += librte_pci
 DEPDIRS-librte_pci := librte_eal
 DIRS-$(CONFIG_RTE_LIBRTE_RING) += librte_ring
 DEPDIRS-librte_ring := librte_eal
+DIRS-$(CONFIG_RTE_CIRCULAR_QUEUE) += librte_circular_queue
+DEPDIRS-librte_circular_queue := librte_eal
 DIRS-$(CONFIG_RTE_LIBRTE_MEMPOOL) += librte_mempool
-DEPDIRS-librte_mempool := librte_eal librte_ring
+DEPDIRS-librte_mempool := librte_eal librte_ring librte_circular_queue
 DIRS-$(CONFIG_RTE_LIBRTE_MBUF) += librte_mbuf
-DEPDIRS-librte_mbuf := librte_eal librte_mempool
+DEPDIRS-librte_mbuf := librte_eal librte_mempool librte_circular_queue
 DIRS-$(CONFIG_RTE_LIBRTE_TIMER) += librte_timer
 DEPDIRS-librte_timer := librte_eal
 DIRS-$(CONFIG_RTE_LIBRTE_CFGFILE) += librte_cfgfile
diff --git a/lib/librte_circular_queue/Makefile b/lib/librte_circular_queue/Makefile
new file mode 100644
index 0000000..6c54a78
--- /dev/null
+++ b/lib/librte_circular_queue/Makefile
@@ -0,0 +1,22 @@
+# SPDX-License-Identifier: BSD-3-Clause
+# Copyright(c) 2010-2014 Intel Corporation
+
+include $(RTE_SDK)/mk/rte.vars.mk
+
+# library name
+LIB = librte_circular_queue.a
+
+CFLAGS += $(WERROR_FLAGS) -I$(SRCDIR) -O3
+LDLIBS += -lrte_eal
+
+EXPORT_MAP := rte_librte_circular_queue_version.map
+
+LIBABIVER := 1
+
+# all source are stored in SRCS-y
+#SRCS-$(CONFIG_RTE_LIBRTE_CIRCULAR_QUEUE) := rte_librte_circular_queue.c
+
+# install includes
+SYMLINK-$(CONFIG_RTE_LIBRTE_RING)-include := rte_circular_queue.h 
+
+include $(RTE_SDK)/mk/rte.lib.mk
diff --git a/lib/librte_circular_queue/meson.build b/lib/librte_circular_queue/meson.build
new file mode 100644
index 0000000..87b3408
--- /dev/null
+++ b/lib/librte_circular_queue/meson.build
@@ -0,0 +1,4 @@
+# SPDX-License-Identifier: BSD-3-Clause
+# Copyright(c) 2017 Intel Corporation
+
+headers = files('rte_librte_circular_queue.h')
diff --git a/lib/librte_circular_queue/rte_circular_queue.h b/lib/librte_circular_queue/rte_circular_queue.h
new file mode 100644
index 0000000..4a8bb26
--- /dev/null
+++ b/lib/librte_circular_queue/rte_circular_queue.h
@@ -0,0 +1,386 @@
+/**
+ * @file rte_circular_queue.h
+ * @brief lock-free single-producer-single-consumer circular queue
+ * @author zhangzhao  (zhangzhao@ict.ac.cn) 
+ * @date 2019.6.10 
+ * @version 1.0
+ * Function list: \n
+ *   1.rte_cirq_init(): initialize circular queue and allocate memory \n
+ *   2.rte_cirq_add(): insert an element to the queue's head \n
+ *   3.rte_cirq_get(): get an element from queue's tail and remove it from queue \n
+ *   4.rte_cirq_count(): calculate number of items in the ciecular queue\n
+ *   5.rte_cirq_prefetch(): get an element from queue's tail without remove
+ *   6.rte_cirq_destroy(): free the memory chunk in the queue
+ *   7.rte_cirq_init_fast(): init the queue with alloc mem chunk from mempool
+ *   8.rte_cirq_destroy_fast(): free the mem chunk alloced by rte_cirq_init_fast()
+ */
+/*----------------------------------------------------------------------------*/
+/* - History:
+ *   1. Date: 2019.6.10 
+ *       Author: zhangzhao
+ *       Modification: create
+ */
+#ifndef __RTE_CIRCULAR_QUEUE_H_
+#define __RTE_CIRCULAR_QUEUE_H_
+
+//#define _GNU_SOURCE
+#include <stdint.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <pthread.h>
+#include <sched.h>  
+#include <errno.h>
+#include <sys/queue.h>  // /usr/include/sys/queue.h
+/******************************************************************************/
+struct rte_circular_queue;
+typedef struct rte_circular_queue * rte_cirq_t;
+/******************************************************************************/
+#ifndef SUCCESS
+	#define SUCCESS 1
+#endif
+#ifndef RTE_STATIC_BUFF_SIZE
+	#define RTE_STATIC_BUFF_SIZE    8
+#endif
+/******************************************************************************/
+/* data structures */
+struct rte_circular_queue
+{
+
+    volatile uint32_t head;    ///< index which ready to insert
+    RTE_STD_C11
+    union {
+        void **queue;
+        void *d_queue[RTE_STATIC_BUFF_SIZE];
+    };
+    uint32_t size;    ///< queue size
+    volatile uint32_t tail;    ///< index which ready to get
+}; 
+
+// this struct is not milti-thread safe! make sure it's only processed by
+// one thread (stack thread)
+struct fast_rte_cirq_mempool
+{
+    void **free_queues;
+    uint32_t size;            // num of queues in the mempool
+    uint32_t point;            // point to the available queue
+    uint32_t length;        // length of every queue
+};
+typedef struct fast_rte_cirq_mempool *frte_cirq_mp_t;
+/******************************************************************************/
+/* function declarations */
+/* local inline functions */
+static inline uint32_t 
+rte_cirq_pree(rte_cirq_t q, uint32_t p)
+{
+    return p? p-1: q->size-1;
+}
+
+static inline uint32_t 
+rte_cirq_succ(rte_cirq_t q, uint32_t p)
+{
+    return (p + 1) % q->size;
+}
+/*----------------------------------------------------------------------------*/
+/* global inline functions */
+/**
+ * test if the queue is full
+ *
+ * @param q        target circular queue
+ *
+ * @return
+ *     return TRUE if the queue is full; otherwise return FALSE
+ * @note
+ *     it may not be multi-thread safe, the result may not be correct
+ */
+static inline uint32_t 
+rte_cirq_full(rte_cirq_t q)
+{
+    return rte_cirq_succ(q, q->head) == q->tail;
+}
+
+/**
+ * test if the queue is empty
+ * 
+ * @param q     target circular queue
+ * 
+ * @return 
+ *     return TRUE if the queue is empty; otherwise return FALSE
+ * @note
+ *     it may not be multi-thread safe, the result may not be correct
+ */
+static inline int 
+rte_cirq_empty(rte_cirq_t q)
+{
+    return q->head == q->tail;
+}
+
+/**
+ * count how many items in the circular queue
+ *
+ * @param q     target ciecular queue
+ *
+ * @return
+ *    return the num of items in the queue
+ * @note
+ *     it may not be multi-thread safe, the result may not be correct
+ */
+static inline uint32_t
+rte_cirq_count(rte_cirq_t q)
+{
+    return q->head>=q->tail ? q->head-q->tail : q->head+q->size-q->tail;
+}
+
+/**
+ * init circular queue and allocate memory for queue
+ * 
+ * @param q     target circular queue 
+ * @param size     max size of queue
+ * 
+ * @return void
+ */
+static inline void 
+rte_cirq_init(rte_cirq_t q, uint32_t size)
+{
+    q->head = 0;
+    q->tail = 0;
+    q->size = size;
+    q->queue = calloc(size, sizeof(void*));
+}
+
+/**
+ * add an element into circular queue's head
+ *
+ * @param q     target circular queue
+ * @param item     element to be inserted
+ * 
+ * @return 
+ *     return 0 if the queue is full; otherwise return SUCCESS means succeed
+ * @see ERROR @see SUCCESS
+ */
+static inline int 
+rte_cirq_add(rte_cirq_t q, void *item)
+{
+    if (rte_cirq_full(q)) {
+        return 0;
+    }
+    
+    q->queue[q->head] = item;
+    _mm_sfence();
+    q->head = rte_cirq_succ(q, q->head);
+    return SUCCESS;
+}
+
+/**
+ * get the element from the circular queue's tail
+ * 
+ * @param q     target circular queue
+ * 
+ * @return 
+ *     return NULL if the queue is empty; otherwise return the pointer to the
+ *     element of queue's tail and remove it from the queue
+ */
+static inline void *
+rte_cirq_get(rte_cirq_t q)
+{
+    void *ret;
+    if (rte_cirq_empty(q)) {
+        return NULL;
+    }
+    ret = q->queue[q->tail];
+    _mm_sfence();
+    q->tail = rte_cirq_succ(q, q->tail);
+    return ret;
+}
+
+/**
+ * get the element from the circular queue's tail
+ * 
+ * @param q     target circular queue
+ * 
+ * @return 
+ *     return NULL if the queue is empty; otherwise return the pointer to the
+ *     element of queue's tail and remove it from the queue
+ */
+static inline int
+rte_cirq_get_bulk(rte_cirq_t q,void **obj,int n)
+{
+    int ret = 0;
+        int i = 0;
+        ret = rte_cirq_count(q);
+        if(ret > n )
+        {
+            ret = n;
+        }
+        for( i = 0; i<ret; i++)
+        {
+			obj[i] = rte_cirq_get(q);
+        }
+    return ret;
+}
+
+/**
+ * get the element from queue's tail without remove it 
+ * 
+ * @param q     target circular queue
+ * 
+ * @return 
+ *     return NULL if the queue is empty; otherwise return the pointer to the
+ *     element of queue's tail
+ */
+static inline void *
+rte_cirq_prefetch(rte_cirq_t q)
+{
+    return rte_cirq_empty(q)? NULL : q->queue[q->tail];
+}
+
+/**
+ * free the members alloced in the circular queue
+ *
+ * @param q     target circular queue
+ *
+ * @return null
+ */
+static inline void 
+rte_cirq_destroy(rte_cirq_t q)
+{
+    if (!rte_cirq_empty(q)) {
+//DO STH
+    }
+    free(q->queue);
+} 
+
+/******************************************************************************/
+/******************************************************************************/
+/* Fast circular_queues alloc memory from mempool, benefit to queues which    */
+/* would be allocated and freed frequently.                                      */
+/* It is specially designed for rcvbuf and sndbuf of every stream.              */
+/******************************************************************************/
+#if 0
+/**
+ *
+ * init the mempool for fast_rte_cirq
+ *
+ * @param mp        target mempol
+ * @param size        num of queues in the mempool
+ * @param length    length of every queue in the mempool
+ *
+ * @return null
+ */
+static inline void
+fast_rte_cirq_mempool_init(frte_cirq_mp_t mp, int size, int length)
+{
+    int i;
+    mp->size = size;
+    mp->point = size - 1;
+    mp->length = length;
+    mp->free_queues = calloc(size, sizeof(struct rte_circular_queue));
+    void *tmp = calloc(size, length*sizeof(void *));
+    for (i=0; i<size; i++) {
+        mp->free_queues[i] = tmp + i*length*sizeof(void *);
+    }
+}
+
+static inline void*
+fast_rte_cirq_mempool_alloc(frte_cirq_mp_t mp)
+{
+    if (mp->point) {
+        return mp->free_queues[mp->point--];
+    } else {
+    }
+}
+
+static inline void
+fast_rte_cirq_mempool_free(frte_cirq_mp_t mp, void* item)
+{
+    if (mp->point == mp->size-1) {
+    } else {
+        mp->free_queues[mp->point++] = item;
+    }
+}
+
+/**
+ * init the queue and alloc the chunk from pre-alloced mempool
+ *
+ * @param q            target circular queue
+ * @param mp        where the rte_ring alloced from
+ *
+ * @return 
+ *  return SUCCESS if sucess; otherwise reurn FALSE
+ *
+ * @note
+ *  only dpdk rte_ring mode is available now, default mode is still alloced
+ *  from kernel using calloc()
+ * @note
+ *  fast_rte_cirq_mempool is not multi-thread safe!
+ */
+static inline int
+rte_cirq_init_fast(rte_cirq_t q, frte_cirq_mp_t mp)
+{
+    q->head = 0;
+    q->tail = 0;
+    q->size = mp->length;
+    q->queue = fast_rte_cirq_mempool_alloc(mp);
+    return SUCCESS;
+} 
+
+/**
+ * free the mem chunk alloced by rte_cirq_init_fast()
+ *
+ * @param q                target circular queue
+ * @param mp        where the rte_ring alloced from
+ *
+ * @return null
+ *
+ * @note
+ *  now is only used for mbuf_queue
+ * @note
+ *  fast_rte_cirq_mempool is not multi-thread safe!
+ */
+static inline void
+rte_cirq_destroy_fast(rte_cirq_t q, frte_cirq_mp_t mp)
+{
+    if (!rte_cirq_empty(q)) {
+    }
+    fast_rte_cirq_mempool_free(mp, q->queue);
+}
+/******************************************************************************/
+#endif
+static inline int
+dir_rte_cirq_init(rte_cirq_t q)
+{
+    q->head = 0;
+    q->tail = 0;
+    q->size = 4;
+    return SUCCESS;
+}
+
+static inline int
+dir_rte_cirq_add(rte_cirq_t q, void* item)
+{
+    if (rte_cirq_full(q)) {
+        return 0;
+    }
+    
+    q->d_queue[q->head] = item;
+    _mm_sfence();
+    q->head = rte_cirq_succ(q, q->head);
+    return SUCCESS;
+}
+
+static inline void*
+dir_rte_cirq_get(rte_cirq_t q)
+{
+    void *ret;
+    if (rte_cirq_empty(q)) {
+        return NULL;
+    }
+    ret = q->d_queue[q->tail];
+    _mm_sfence();
+    q->tail = rte_cirq_succ(q, q->tail);
+    return ret;
+
+}
+
+
+/******************************************************************************/
+#endif //#ifndef __CIRCULAR_QUEUE_H_
diff --git a/lib/librte_circular_queue/test.h b/lib/librte_circular_queue/test.h
new file mode 100644
index 0000000..bc37f2c
--- /dev/null
+++ b/lib/librte_circular_queue/test.h
@@ -0,0 +1,398 @@
+/**
+ * @file rte_circular_queue.h
+ * @brief lock-free single-producer-single-consumer circular queue
+ * @author zhangzhao  (zhangzhao@ict.ac.cn) 
+ * @date 2019.6.10 
+ * @version 1.0
+ * Function list: \n
+ *   1.rte_cirq_init(): initialize circular queue and allocate memory \n
+ *   2.rte_cirq_add(): insert an element to the queue's head \n
+ *   3.rte_cirq_get(): get an element from queue's tail and remove it from queue \n
+ *   4.rte_cirq_count(): calculate number of items in the ciecular queue\n
+ *   5.rte_cirq_prefetch(): get an element from queue's tail without remove
+ *   6.rte_cirq_destroy(): free the memory chunk in the queue
+ *   7.rte_cirq_init_fast(): init the queue with alloc mem chunk from mempool
+ *   8.rte_cirq_destroy_fast(): free the mem chunk alloced by rte_cirq_init_fast()
+ */
+/*----------------------------------------------------------------------------*/
+/* - History:
+ *   1. Date: 2019.6.10 
+ *   	Author: zhangzhao
+ *   	Modification: create
+ */
+#ifndef __RTE_CIRCULAR_QUEUE_H_
+#define __RTE_CIRCULAR_QUEUE_H_
+
+//#define _GNU_SOURCE
+#include <stdint.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <pthread.h>
+#include <sched.h>  
+#include <errno.h>
+#include <sys/queue.h>  // /usr/include/sys/queue.h
+/******************************************************************************/
+struct rte_circular_queue;
+typedef struct rte_circular_queue * rte_cirq_t;
+/******************************************************************************/
+
+
+#define STATIC_BUFF_SIZE	4
+/******************************************************************************/
+/* data structures */
+struct rte_circular_queue
+{
+	union {
+		void **queue;
+		void *d_queue[STATIC_BUFF_SIZE];
+	};
+	volatile uint32_t head;	///< index which ready to insert
+	uint32_t size;	///< queue size
+	volatile uint32_t tail;	///< index which ready to get
+}; 
+
+// this struct is not milti-thread safe! make sure it's only processed by
+// one thread (stack thread)
+struct fast_rte_cirq_mempool
+{
+	void **free_queues;
+	uint32_t size;			// num of queues in the mempool
+	uint32_t point;			// point to the available queue
+	uint32_t length;		// length of every queue
+};
+typedef struct fast_rte_cirq_mempool *frte_cirq_mp_t;
+/******************************************************************************/
+/* function declarations */
+/* local inline functions */
+static inline uint32_t 
+rte_cirq_pree(rte_cirq_t q, uint32_t p)
+{
+	return p? p-1: q->size-1;
+}
+
+static inline uint32_t 
+rte_cirq_succ(rte_cirq_t q, uint32_t p)
+{
+	return (p + 1) % q->size;
+}
+/*----------------------------------------------------------------------------*/
+/* global inline functions */
+/**
+ * test if the queue is full
+ *
+ * @param q		target circular queue
+ *
+ * @return
+ * 	return TRUE if the queue is full; otherwise return FALSE
+ * @note
+ * 	it may not be multi-thread safe, the result may not be correct
+ */
+static inline uint32_t 
+rte_cirq_full(rte_cirq_t q)
+{
+	return rte_cirq_succ(q, q->head) == q->tail;
+}
+
+/**
+ * test if the queue is empty
+ * 
+ * @param q 	target circular queue
+ * 
+ * @return 
+ * 	return TRUE if the queue is empty; otherwise return FALSE
+ * @note
+ * 	it may not be multi-thread safe, the result may not be correct
+ */
+static inline int 
+rte_cirq_empty(rte_cirq_t q)
+{
+	return q->head == q->tail;
+}
+
+/**
+ * count how many items in the circular queue
+ *
+ * @param q 	target ciecular queue
+ *
+ * @return
+ *	return the num of items in the queue
+ * @note
+ * 	it may not be multi-thread safe, the result may not be correct
+ */
+static inline uint32_t
+rte_cirq_count(rte_cirq_t q)
+{
+	return q->head>=q->tail ? q->head-q->tail : q->head+q->size-q->tail;
+}
+
+/**
+ * init circular queue and allocate memory for queue
+ * 
+ * @param q 	target circular queue 
+ * @param size 	max size of queue
+ * 
+ * @return void
+ */
+static inline void 
+rte_cirq_init(rte_cirq_t q, uint32_t size)
+{
+	q->head = 0;
+	q->tail = 0;
+	q->size = size;
+	q->queue = calloc(size, sizeof(void*));
+}
+
+/**
+ * add an element into circular queue's head
+ *
+ * @param q 	target circular queue
+ * @param item 	element to be inserted
+ * 
+ * @return 
+ * 	return FAILED if the queue is full; otherwise return SUCCESS means succeed
+ * @see ERROR @see SUCCESS
+ */
+static inline int 
+rte_cirq_add(rte_cirq_t q, void *item)
+{
+	int ret;
+	if (rte_cirq_full(q)) {
+		return FAILED;
+	}
+	
+	q->queue[q->head] = item;
+	_mm_sfence();
+	q->head = rte_cirq_succ(q, q->head);
+	return SUCCESS;
+}
+
+
+/**
+ * get the N element from the circular queue's tail
+ * 
+ * @param q 	target circular queue
+ * @param n     get element num
+ * @param tar   target element list
+ * @return 
+ * 	return NULL if the queue is empty; otherwise return the pointer to the
+ * 	element of queue's tail and remove it from the queue
+ */
+static inline void *
+rte_cirq_get_bulk(rte_cirq_t q,void **obj,int num)
+{
+	int ret = 0;
+        int i = 0;
+        ret = rte_cirq_count(ring);
+        if(ret > n )
+        {
+            ret = n;
+        }
+        for( i = 0; i<ret; i++)
+        {
+	    *obj[i] = q->queue[q->tail + i];
+ 	    _mm_sfence();
+	    q->tail = rte_cirq_succ(q, q->tail);
+        }
+	return ret;
+}
+
+/**
+ * get the element from the circular queue's tail
+ * 
+ * @param q 	target circular queue
+ * 
+ * @return 
+ * 	return NULL if the queue is empty; otherwise return the pointer to the
+ * 	element of queue's tail and remove it from the queue
+ */
+static inline void *
+rte_cirq_get(rte_cirq_t q)
+{
+	void *ret;
+	if (rte_cirq_empty(q)) {
+		return NULL;
+	}
+	ret = q->queue[q->tail];
+	_mm_sfence();
+	q->tail = rte_cirq_succ(q, q->tail);
+	return ret;
+}
+
+/**
+ * get the element from queue's tail without remove it 
+ * 
+ * @param q 	target circular queue
+ * 
+ * @return 
+ * 	return NULL if the queue is empty; otherwise return the pointer to the
+ * 	element of queue's tail
+ */
+static inline void *
+rte_cirq_prefetch(rte_cirq_t q)
+{
+	return rte_cirq_empty(q)? NULL : q->queue[q->tail];
+}
+
+/**
+ * free the members alloced in the circular queue
+ *
+ * @param q 	target circular queue
+ *
+ * @return null
+ */
+static inline void 
+rte_cirq_destroy(rte_cirq_t q)
+{
+	if (!rte_cirq_empty(q)) {
+//DO STH
+	}
+	free(q->queue);
+} 
+
+/**
+ * trace circular queue's detail info
+ *
+ * @param q		target circular queue
+ * 
+ * @return null
+ * @note
+ * 	it may not be multi-thread safe, the result may not be correct
+ */
+static inline void 
+rte_cirq_print_info(rte_cirq_t q)
+{
+}
+
+/******************************************************************************/
+/******************************************************************************/
+/* Fast circular_queues alloc memory from mempool, benefit to queues which    */
+/* would be allocated and freed frequently.									  */
+/* It is specially designed for rcvbuf and sndbuf of every stream.			  */
+/******************************************************************************/
+/**
+ * init the mempool for fast_rte_cirq
+ *
+ * @param mp		target mempol
+ * @param size		num of queues in the mempool
+ * @param length	length of every queue in the mempool
+ *
+ * @return null
+ */
+static inline void
+fast_rte_cirq_mempool_init(frte_cirq_mp_t mp, int size, int length)
+{
+	int i;
+	mp->size = size;
+	mp->point = size - 1;
+	mp->length = length;
+	mp->free_queues = calloc(size, sizeof(struct circular_queue));
+	void *tmp = calloc(size, length*sizeof(void *));
+	for (i=0; i<size; i++) {
+		mp->free_queues[i] = tmp + i*length*sizeof(void *);
+	}
+}
+
+static inline void*
+fast_rte_cirq_mempool_alloc(frte_cirq_mp_t mp)
+{
+	if (mp->point) {
+		return mp->free_queues[mp->point--];
+	} else {
+	}
+}
+
+static inline void
+fast_rte_cirq_mempool_free(frte_cirq_mp_t mp, void* item)
+{
+	if (mp->point == mp->size-1) {
+	} else {
+		mp->free_queues[mp->point++] = item;
+	}
+}
+
+/**
+ * init the queue and alloc the chunk from pre-alloced mempool
+ *
+ * @param q			target circular queue
+ * @param mp		where the rte_ring alloced from
+ *
+ * @return 
+ *  return SUCCESS if sucess; otherwise reurn FALSE
+ *
+ * @note
+ *  only dpdk rte_ring mode is available now, default mode is still alloced
+ *  from kernel using calloc()
+ * @note
+ *  fast_rte_cirq_mempool is not multi-thread safe!
+ */
+static inline int
+rte_cirq_init_fast(rte_cirq_t q, frte_cirq_mp_t mp)
+{
+	q->head = 0;
+	q->tail = 0;
+	q->size = mp->length;
+	q->queue = fast_rte_cirq_mempool_alloc(mp);
+	return SUCCESS;
+} 
+
+/**
+ * free the mem chunk alloced by rte_cirq_init_fast()
+ *
+ * @param q				target circular queue
+ * @param mp		where the rte_ring alloced from
+ *
+ * @return null
+ *
+ * @note
+ *  now is only used for mbuf_queue
+ * @note
+ *  fast_rte_cirq_mempool is not multi-thread safe!
+ */
+static inline void
+rte_cirq_destroy_fast(rte_cirq_t q, frte_cirq_mp_t mp)
+{
+	if (!rte_cirq_empty(q)) {
+	}
+	fast_rte_cirq_mempool_free(mp, q->queue);
+}
+/******************************************************************************/
+static inline int
+dir_rte_cirq_init(rte_cirq_t q)
+{
+	q->head = 0;
+	q->tail = 0;
+	q->size = 4;
+	return SUCCESS;
+}
+
+static inline int
+dir_rte_cirq_add(rte_cirq_t q, void* item)
+{
+	int ret;
+	if (rte_cirq_full(q)) {
+		return FAILED;
+	}
+	
+	q->d_queue[q->head] = item;
+	_mm_sfence();
+	q->head = rte_cirq_succ(q, q->head);
+	return SUCCESS;
+}
+
+static inline void*
+dir_rte_cirq_get(rte_cirq_t q)
+{
+	void *ret;
+	if (rte_cirq_empty(q)) {
+		return NULL;
+	}
+	ret = q->d_queue[q->tail];
+	_mm_sfence();
+	q->tail = rte_cirq_succ(q, q->tail);
+	return ret;
+
+}
+
+
+/******************************************************************************/
+#endif //#ifndef __CIRCULAR_QUEUE_H_
diff --git a/lib/librte_hash/Makefile b/lib/librte_hash/Makefile
index c8c435d..a8d2373 100644
--- a/lib/librte_hash/Makefile
+++ b/lib/librte_hash/Makefile
@@ -6,7 +6,7 @@ include $(RTE_SDK)/mk/rte.vars.mk
 # library name
 LIB = librte_hash.a
 
-CFLAGS += -O3
+CFLAGS += -O3 -g
 CFLAGS += $(WERROR_FLAGS) -I$(SRCDIR)
 LDLIBS += -lrte_eal -lrte_ring
 
diff --git a/lib/librte_mbuf/rte_mbuf.h b/lib/librte_mbuf/rte_mbuf.h
index f247e43..1757411 100644
--- a/lib/librte_mbuf/rte_mbuf.h
+++ b/lib/librte_mbuf/rte_mbuf.h
@@ -41,7 +41,9 @@
 #include <rte_prefetch.h>
 #include <rte_branch_prediction.h>
 #include <rte_mbuf_ptype.h>
+#include <rte_circular_queue.h>
 
+//ptr->udata64 = 2;
 #ifdef __cplusplus
 extern "C" {
 #endif
@@ -161,12 +163,12 @@
 /**
  * Indicate that security offload processing was applied on the RX packet.
  */
-#define PKT_RX_SEC_OFFLOAD		(1ULL << 18)
+#define PKT_RX_SEC_OFFLOAD        (1ULL << 18)
 
 /**
  * Indicate that security offload processing failed on the RX packet.
  */
-#define PKT_RX_SEC_OFFLOAD_FAILED  	(1ULL << 19)
+#define PKT_RX_SEC_OFFLOAD_FAILED      (1ULL << 19)
 
 /**
  * The RX packet is a double VLAN, and the outer tci has been
@@ -186,12 +188,12 @@
  * fragmentation in SW or in HW. When use UFO, mbuf->tso_segsz is used
  * to store the MSS of UDP fragments.
  */
-#define PKT_TX_UDP_SEG	(1ULL << 42)
+#define PKT_TX_UDP_SEG    (1ULL << 42)
 
 /**
  * Request security offload processing on the TX packet.
  */
-#define PKT_TX_SEC_OFFLOAD 		(1ULL << 43)
+#define PKT_TX_SEC_OFFLOAD         (1ULL << 43)
 
 /**
  * Offload the MACsec. This flag must be set by the application to enable
@@ -308,16 +310,16 @@
  * which can be set for packet.
  */
 #define PKT_TX_OFFLOAD_MASK (    \
-		PKT_TX_IP_CKSUM |        \
-		PKT_TX_L4_MASK |         \
-		PKT_TX_OUTER_IP_CKSUM |  \
-		PKT_TX_TCP_SEG |         \
-		PKT_TX_IEEE1588_TMST |	 \
-		PKT_TX_QINQ_PKT |        \
-		PKT_TX_VLAN_PKT |        \
-		PKT_TX_TUNNEL_MASK |	 \
-		PKT_TX_MACSEC |		 \
-		PKT_TX_SEC_OFFLOAD)
+        PKT_TX_IP_CKSUM |        \
+        PKT_TX_L4_MASK |         \
+        PKT_TX_OUTER_IP_CKSUM |  \
+        PKT_TX_TCP_SEG |         \
+        PKT_TX_IEEE1588_TMST |     \
+        PKT_TX_QINQ_PKT |        \
+        PKT_TX_VLAN_PKT |        \
+        PKT_TX_TUNNEL_MASK |     \
+        PKT_TX_MACSEC |         \
+        PKT_TX_SEC_OFFLOAD)
 
 #define __RESERVED           (1ULL << 61) /**< reserved for future mbuf use */
 
@@ -379,15 +381,16 @@
  */
 int rte_get_tx_ol_flag_list(uint64_t mask, char *buf, size_t buflen);
 
+//static inline void rte_pktmbuf_free(struct rte_mbuf *m);
 /**
  * Some NICs need at least 2KB buffer to RX standard Ethernet frame without
  * splitting it into multiple segments.
  * So, for mbufs that planned to be involved into RX/TX, the recommended
  * minimal buffer length is 2KB + RTE_PKTMBUF_HEADROOM.
  */
-#define	RTE_MBUF_DEFAULT_DATAROOM	2048
-#define	RTE_MBUF_DEFAULT_BUF_SIZE	\
-	(RTE_MBUF_DEFAULT_DATAROOM + RTE_PKTMBUF_HEADROOM)
+#define    RTE_MBUF_DEFAULT_DATAROOM    2048
+#define    RTE_MBUF_DEFAULT_BUF_SIZE    \
+    (RTE_MBUF_DEFAULT_DATAROOM + RTE_PKTMBUF_HEADROOM)
 
 /* define a set of marker types that can be used to refer to set points in the
  * mbuf */
@@ -403,169 +406,195 @@
  * The generic rte_mbuf, containing a packet mbuf.
  */
 struct rte_mbuf {
-	MARKER cacheline0;
-
-	void *buf_addr;           /**< Virtual address of segment buffer. */
-	/**
-	 * Physical address of segment buffer.
-	 * Force alignment to 8-bytes, so as to ensure we have the exact
-	 * same mbuf cacheline0 layout for 32-bit and 64-bit. This makes
-	 * working on vector drivers easier.
-	 */
-	RTE_STD_C11
-	union {
-		rte_iova_t buf_iova;
-		rte_iova_t buf_physaddr; /**< deprecated */
-	} __rte_aligned(sizeof(rte_iova_t));
-
-	/* next 8 bytes are initialised on RX descriptor rearm */
-	MARKER64 rearm_data;
-	uint16_t data_off;
-
-	/**
-	 * Reference counter. Its size should at least equal to the size
-	 * of port field (16 bits), to support zero-copy broadcast.
-	 * It should only be accessed using the following functions:
-	 * rte_mbuf_refcnt_update(), rte_mbuf_refcnt_read(), and
-	 * rte_mbuf_refcnt_set(). The functionality of these functions (atomic,
-	 * or non-atomic) is controlled by the CONFIG_RTE_MBUF_REFCNT_ATOMIC
-	 * config option.
-	 */
-	RTE_STD_C11
-	union {
-		rte_atomic16_t refcnt_atomic; /**< Atomically accessed refcnt */
-		uint16_t refcnt;              /**< Non-atomically accessed refcnt */
-	};
-	uint16_t nb_segs;         /**< Number of segments. */
-
-	/** Input port (16 bits to support more than 256 virtual ports). */
-	uint16_t port;
-
-	uint64_t ol_flags;        /**< Offload features. */
-
-	/* remaining bytes are set on RX when pulling packet from descriptor */
-	MARKER rx_descriptor_fields1;
-
-	/*
-	 * The packet type, which is the combination of outer/inner L2, L3, L4
-	 * and tunnel types. The packet_type is about data really present in the
-	 * mbuf. Example: if vlan stripping is enabled, a received vlan packet
-	 * would have RTE_PTYPE_L2_ETHER and not RTE_PTYPE_L2_VLAN because the
-	 * vlan is stripped from the data.
-	 */
-	RTE_STD_C11
-	union {
-		uint32_t packet_type; /**< L2/L3/L4 and tunnel information. */
+    MARKER cacheline0;
+
+    void *buf_addr;           /**< Virtual address of segment buffer. */
+    /**
+     * Physical address of segment buffer.
+     * Force alignment to 8-bytes, so as to ensure we have the exact
+     * same mbuf cacheline0 layout for 32-bit and 64-bit. This makes
+     * working on vector drivers easier.
+     */
+    RTE_STD_C11
+    union {
+        rte_iova_t buf_iova;
+        rte_iova_t buf_physaddr; /**< deprecated */
+    } __rte_aligned(sizeof(rte_iova_t));
+
+    /* next 8 bytes are initialised on RX descriptor rearm */
+    MARKER64 rearm_data;
+    uint16_t data_off;
+
+    /**
+     * Reference counter. Its size should at least equal to the size
+     * of port field (16 bits), to support zero-copy broadcast.
+     * It should only be accessed using the following functions:
+     * rte_mbuf_refcnt_update(), rte_mbuf_refcnt_read(), and
+     * rte_mbuf_refcnt_set(). The functionality of these functions (atomic,
+     * or non-atomic) is controlled by the CONFIG_RTE_MBUF_REFCNT_ATOMIC
+     * config option.
+     */
+    RTE_STD_C11
+    union {
+        rte_atomic16_t refcnt_atomic; /**< Atomically accessed refcnt */
+        uint16_t refcnt;              /**< Non-atomically accessed refcnt */
+    };
+    uint16_t nb_segs;         /**< Number of segments. */
+
+    /** Input port (16 bits to support more than 256 virtual ports). */
+    uint16_t port;
+
+    uint64_t ol_flags;        /**< Offload features. */
+
+    /* remaining bytes are set on RX when pulling packet from descriptor */
+    MARKER rx_descriptor_fields1;
+
+    /*
+     * The packet type, which is the combination of outer/inner L2, L3, L4
+     * and tunnel types. The packet_type is about data really present in the
+     * mbuf. Example: if vlan stripping is enabled, a received vlan packet
+     * would have RTE_PTYPE_L2_ETHER and not RTE_PTYPE_L2_VLAN because the
+     * vlan is stripped from the data.
+     */
+    RTE_STD_C11
+    union {
+        uint32_t packet_type; /**< L2/L3/L4 and tunnel information. */
+        struct {
+            uint32_t l2_type:4; /**< (Outer) L2 type. */
+            uint32_t l3_type:4; /**< (Outer) L3 type. */
+            uint32_t l4_type:4; /**< (Outer) L4 type. */
+            uint32_t tun_type:4; /**< Tunnel type. */
+            RTE_STD_C11
+            union {
+                uint8_t inner_esp_next_proto;
+                /**< ESP next protocol type, valid if
+                 * RTE_PTYPE_TUNNEL_ESP tunnel type is set
+                 * on both Tx and Rx.
+                 */
+                __extension__
+                struct {
+                    uint8_t inner_l2_type:4;
+                    /**< Inner L2 type. */
+                    uint8_t inner_l3_type:4;
+                    /**< Inner L3 type. */
+                };
+            };
+            uint32_t inner_l4_type:4; /**< Inner L4 type. */
+        };
+    };
+
+    uint32_t pkt_len;         /**< Total pkt len: sum of all segments. */
+    uint16_t data_len;        /**< Amount of data in segment buffer. */
+    /** VLAN TCI (CPU order), valid if PKT_RX_VLAN is set. */
+    uint16_t vlan_tci;
+
+    union {
+        uint32_t rss;     /**< RSS hash result if RSS enabled */
+        struct {
+            RTE_STD_C11
+            union {
+                struct {
+                    uint16_t hash;
+                    uint16_t id;
+                };
+                uint32_t lo;
+                /**< Second 4 flexible bytes */
+            };
+            uint32_t hi;
+            /**< First 4 flexible bytes or FD ID, dependent on
+                 PKT_RX_FDIR_* flag in ol_flags. */
+        } fdir;           /**< Filter identifier if FDIR enabled */
+        struct {
+            uint32_t lo;
+            uint32_t hi;
+        } sched;          /**< Hierarchical scheduler */
+        uint32_t usr;      /**< User defined tags. See rte_distributor_process() */
+    } hash;                   /**< hash information */
+
+    /** Outer VLAN TCI (CPU order), valid if PKT_RX_QINQ is set. */
+    uint16_t vlan_tci_outer;
+
+    uint16_t buf_len;         /**< Length of segment buffer. */
+
+    /** Valid if PKT_RX_TIMESTAMP is set. The unit and time reference
+     * are not normalized but are always the same for a given port.
+     */
+    uint64_t timestamp;
+
+    /* second cache line - fields only used in slow path or on TX */
+    MARKER cacheline1 __rte_cache_min_aligned;
+
+    RTE_STD_C11
+    union {
+        void *userdata;   /**< Can be used for external metadata */
+        uint64_t udata64; /**< Allow 8-byte userdata on 32-bit */
+    };
+
+    struct rte_mempool *pool; /**< Pool from which mbuf was allocated. */
+    struct rte_mbuf *next;    /**< Next segment of scattered packet. */
+
+    /* fields to support TX offloads */
+    RTE_STD_C11
+    union {
+        uint64_t tx_offload;       /**< combined for easy fetch */
+        __extension__
+        struct {
+            uint64_t l2_len:7;
+            /**< L2 (MAC) Header Length for non-tunneling pkt.
+             * Outer_L4_len + ... + Inner_L2_len for tunneling pkt.
+             */
+            uint64_t l3_len:9; /**< L3 (IP) Header Length. */
+            uint64_t l4_len:8; /**< L4 (TCP/UDP) Header Length. */
+            uint64_t tso_segsz:16; /**< TCP TSO segment size */
+
+            /* fields for TX offloading of tunnels */
+            uint64_t outer_l3_len:9; /**< Outer L3 (IP) Hdr Length. */
+            uint64_t outer_l2_len:7; /**< Outer L2 (MAC) Hdr Length. */
+
+            /* uint64_t unused:8; */
+        };
+    };
+
+    /** Size of the application private data. In case of an indirect
+     * mbuf, it stores the direct mbuf private data size. */
+    uint16_t priv_size;
+
+    /** Timesync flags for use with IEEE1588. */
+    uint16_t timesync;
+
+    /** Sequence number. See also rte_reorder_insert(). */
+    uint32_t seqn;
+
+    /* the following is defined by shenyifan */
+    RTE_STD_C11
+    uint8_t mbuf_state:4;
+    RTE_STD_C11
+    uint8_t priority:1;
+    RTE_STD_C11
+	uint8_t holding:1;
+    RTE_STD_C11
+	uint8_t op_p:2;
+    uint8_t score;
+    uint16_t payload_len;
+    uint32_t tcp_seq;
+    struct rte_mbuf *buf_next;
+    RTE_STD_C11
+	union {	/**< debug info */
+		void *q_ts;	/**< ts for request processing stages*/
+		uint64_t mbuf_ts;	/**< used for single interval test */
+//		uint64_t acount; /**< Allow 8-byte userdata on 32-bit */
 		struct {
-			uint32_t l2_type:4; /**< (Outer) L2 type. */
-			uint32_t l3_type:4; /**< (Outer) L3 type. */
-			uint32_t l4_type:4; /**< (Outer) L4 type. */
-			uint32_t tun_type:4; /**< Tunnel type. */
-			RTE_STD_C11
-			union {
-				uint8_t inner_esp_next_proto;
-				/**< ESP next protocol type, valid if
-				 * RTE_PTYPE_TUNNEL_ESP tunnel type is set
-				 * on both Tx and Rx.
-				 */
-				__extension__
-				struct {
-					uint8_t inner_l2_type:4;
-					/**< Inner L2 type. */
-					uint8_t inner_l3_type:4;
-					/**< Inner L3 type. */
-				};
-			};
-			uint32_t inner_l4_type:4; /**< Inner L4 type. */
+			uint32_t stream_id;
+			struct { // mbuf operation trace
+				uint8_t last_operation:4; 
+				uint8_t last_core:4;	/**< last option core*/
+			} op_trace[4];
 		};
 	};
-
-	uint32_t pkt_len;         /**< Total pkt len: sum of all segments. */
-	uint16_t data_len;        /**< Amount of data in segment buffer. */
-	/** VLAN TCI (CPU order), valid if PKT_RX_VLAN is set. */
-	uint16_t vlan_tci;
-
-	union {
-		uint32_t rss;     /**< RSS hash result if RSS enabled */
-		struct {
-			RTE_STD_C11
-			union {
-				struct {
-					uint16_t hash;
-					uint16_t id;
-				};
-				uint32_t lo;
-				/**< Second 4 flexible bytes */
-			};
-			uint32_t hi;
-			/**< First 4 flexible bytes or FD ID, dependent on
-			     PKT_RX_FDIR_* flag in ol_flags. */
-		} fdir;           /**< Filter identifier if FDIR enabled */
-		struct {
-			uint32_t lo;
-			uint32_t hi;
-		} sched;          /**< Hierarchical scheduler */
-		uint32_t usr;	  /**< User defined tags. See rte_distributor_process() */
-	} hash;                   /**< hash information */
-
-	/** Outer VLAN TCI (CPU order), valid if PKT_RX_QINQ is set. */
-	uint16_t vlan_tci_outer;
-
-	uint16_t buf_len;         /**< Length of segment buffer. */
-
-	/** Valid if PKT_RX_TIMESTAMP is set. The unit and time reference
-	 * are not normalized but are always the same for a given port.
-	 */
-	uint64_t timestamp;
-
-	/* second cache line - fields only used in slow path or on TX */
-	MARKER cacheline1 __rte_cache_min_aligned;
-
-	RTE_STD_C11
-	union {
-		void *userdata;   /**< Can be used for external metadata */
-		uint64_t udata64; /**< Allow 8-byte userdata on 32-bit */
-	};
-
-	struct rte_mempool *pool; /**< Pool from which mbuf was allocated. */
-	struct rte_mbuf *next;    /**< Next segment of scattered packet. */
-
-	/* fields to support TX offloads */
-	RTE_STD_C11
-	union {
-		uint64_t tx_offload;       /**< combined for easy fetch */
-		__extension__
-		struct {
-			uint64_t l2_len:7;
-			/**< L2 (MAC) Header Length for non-tunneling pkt.
-			 * Outer_L4_len + ... + Inner_L2_len for tunneling pkt.
-			 */
-			uint64_t l3_len:9; /**< L3 (IP) Header Length. */
-			uint64_t l4_len:8; /**< L4 (TCP/UDP) Header Length. */
-			uint64_t tso_segsz:16; /**< TCP TSO segment size */
-
-			/* fields for TX offloading of tunnels */
-			uint64_t outer_l3_len:9; /**< Outer L3 (IP) Hdr Length. */
-			uint64_t outer_l2_len:7; /**< Outer L2 (MAC) Hdr Length. */
-
-			/* uint64_t unused:8; */
-		};
-	};
-
-	/** Size of the application private data. In case of an indirect
-	 * mbuf, it stores the direct mbuf private data size. */
-	uint16_t priv_size;
-
-	/** Timesync flags for use with IEEE1588. */
-	uint16_t timesync;
-
-	/** Sequence number. See also rte_reorder_insert(). */
-	uint32_t seqn;
-
 } __rte_cache_aligned;
 
 /**< Maximum number of nb_segs allowed. */
-#define RTE_MBUF_MAX_NB_SEGS	UINT16_MAX
+#define RTE_MBUF_MAX_NB_SEGS    UINT16_MAX
 
 /**
  * Prefetch the first part of the mbuf
@@ -580,7 +609,7 @@ struct rte_mbuf {
 static inline void
 rte_mbuf_prefetch_part1(struct rte_mbuf *m)
 {
-	rte_prefetch0(&m->cacheline0);
+    rte_prefetch0(&m->cacheline0);
 }
 
 /**
@@ -598,9 +627,9 @@ struct rte_mbuf {
 rte_mbuf_prefetch_part2(struct rte_mbuf *m)
 {
 #if RTE_CACHE_LINE_SIZE == 64
-	rte_prefetch0(&m->cacheline1);
+    rte_prefetch0(&m->cacheline1);
 #else
-	RTE_SET_USED(m);
+    RTE_SET_USED(m);
 #endif
 }
 
@@ -618,14 +647,14 @@ struct rte_mbuf {
 static inline rte_iova_t
 rte_mbuf_data_iova(const struct rte_mbuf *mb)
 {
-	return mb->buf_iova + mb->data_off;
+    return mb->buf_iova + mb->data_off;
 }
 
 __rte_deprecated
 static inline phys_addr_t
 rte_mbuf_data_dma_addr(const struct rte_mbuf *mb)
 {
-	return rte_mbuf_data_iova(mb);
+    return rte_mbuf_data_iova(mb);
 }
 
 /**
@@ -643,14 +672,14 @@ struct rte_mbuf {
 static inline rte_iova_t
 rte_mbuf_data_iova_default(const struct rte_mbuf *mb)
 {
-	return mb->buf_iova + RTE_PKTMBUF_HEADROOM;
+    return mb->buf_iova + RTE_PKTMBUF_HEADROOM;
 }
 
 __rte_deprecated
 static inline phys_addr_t
 rte_mbuf_data_dma_addr_default(const struct rte_mbuf *mb)
 {
-	return rte_mbuf_data_iova_default(mb);
+    return rte_mbuf_data_iova_default(mb);
 }
 
 /**
@@ -664,7 +693,7 @@ struct rte_mbuf {
 static inline struct rte_mbuf *
 rte_mbuf_from_indirect(struct rte_mbuf *mi)
 {
-	return (struct rte_mbuf *)RTE_PTR_SUB(mi->buf_addr, sizeof(*mi) + mi->priv_size);
+    return (struct rte_mbuf *)RTE_PTR_SUB(mi->buf_addr, sizeof(*mi) + mi->priv_size);
 }
 
 /**
@@ -678,9 +707,9 @@ struct rte_mbuf {
 static inline char *
 rte_mbuf_to_baddr(struct rte_mbuf *md)
 {
-	char *buffer_addr;
-	buffer_addr = (char *)md + sizeof(*md) + rte_pktmbuf_priv_size(md->pool);
-	return buffer_addr;
+    char *buffer_addr;
+    buffer_addr = (char *)md + sizeof(*md) + rte_pktmbuf_priv_size(md->pool);
+    return buffer_addr;
 }
 
 /**
@@ -700,8 +729,8 @@ struct rte_mbuf {
  * appended after the mempool structure (in private data).
  */
 struct rte_pktmbuf_pool_private {
-	uint16_t mbuf_data_room_size; /**< Size of data space in each mbuf. */
-	uint16_t mbuf_priv_size;      /**< Size of private area in each mbuf. */
+    uint16_t mbuf_data_room_size; /**< Size of data space in each mbuf. */
+    uint16_t mbuf_priv_size;      /**< Size of private area in each mbuf. */
 };
 
 #ifdef RTE_LIBRTE_MBUF_DEBUG
@@ -728,7 +757,7 @@ struct rte_pktmbuf_pool_private {
 static inline uint16_t
 rte_mbuf_refcnt_read(const struct rte_mbuf *m)
 {
-	return (uint16_t)(rte_atomic16_read(&m->refcnt_atomic));
+    return (uint16_t)(rte_atomic16_read(&m->refcnt_atomic));
 }
 
 /**
@@ -741,14 +770,14 @@ struct rte_pktmbuf_pool_private {
 static inline void
 rte_mbuf_refcnt_set(struct rte_mbuf *m, uint16_t new_value)
 {
-	rte_atomic16_set(&m->refcnt_atomic, (int16_t)new_value);
+    rte_atomic16_set(&m->refcnt_atomic, (int16_t)new_value);
 }
 
 /* internal */
 static inline uint16_t
 __rte_mbuf_refcnt_update(struct rte_mbuf *m, int16_t value)
 {
-	return (uint16_t)(rte_atomic16_add_return(&m->refcnt_atomic, value));
+    return (uint16_t)(rte_atomic16_add_return(&m->refcnt_atomic, value));
 }
 
 /**
@@ -763,20 +792,20 @@ struct rte_pktmbuf_pool_private {
 static inline uint16_t
 rte_mbuf_refcnt_update(struct rte_mbuf *m, int16_t value)
 {
-	/*
-	 * The atomic_add is an expensive operation, so we don't want to
-	 * call it in the case where we know we are the uniq holder of
-	 * this mbuf (i.e. ref_cnt == 1). Otherwise, an atomic
-	 * operation has to be used because concurrent accesses on the
-	 * reference counter can occur.
-	 */
-	if (likely(rte_mbuf_refcnt_read(m) == 1)) {
-		++value;
-		rte_mbuf_refcnt_set(m, (uint16_t)value);
-		return (uint16_t)value;
-	}
-
-	return __rte_mbuf_refcnt_update(m, value);
+    /*
+     * The atomic_add is an expensive operation, so we don't want to
+     * call it in the case where we know we are the uniq holder of
+     * this mbuf (i.e. ref_cnt == 1). Otherwise, an atomic
+     * operation has to be used because concurrent accesses on the
+     * reference counter can occur.
+     */
+    if (likely(rte_mbuf_refcnt_read(m) == 1)) {
+        ++value;
+        rte_mbuf_refcnt_set(m, (uint16_t)value);
+        return (uint16_t)value;
+    }
+
+    return __rte_mbuf_refcnt_update(m, value);
 }
 
 #else /* ! RTE_MBUF_REFCNT_ATOMIC */
@@ -785,8 +814,8 @@ struct rte_pktmbuf_pool_private {
 static inline uint16_t
 __rte_mbuf_refcnt_update(struct rte_mbuf *m, int16_t value)
 {
-	m->refcnt = (uint16_t)(m->refcnt + value);
-	return m->refcnt;
+    m->refcnt = (uint16_t)(m->refcnt + value);
+    return m->refcnt;
 }
 
 /**
@@ -795,7 +824,7 @@ struct rte_pktmbuf_pool_private {
 static inline uint16_t
 rte_mbuf_refcnt_update(struct rte_mbuf *m, int16_t value)
 {
-	return __rte_mbuf_refcnt_update(m, value);
+    return __rte_mbuf_refcnt_update(m, value);
 }
 
 /**
@@ -804,7 +833,7 @@ struct rte_pktmbuf_pool_private {
 static inline uint16_t
 rte_mbuf_refcnt_read(const struct rte_mbuf *m)
 {
-	return m->refcnt;
+    return m->refcnt;
 }
 
 /**
@@ -813,15 +842,15 @@ struct rte_pktmbuf_pool_private {
 static inline void
 rte_mbuf_refcnt_set(struct rte_mbuf *m, uint16_t new_value)
 {
-	m->refcnt = new_value;
+    m->refcnt = new_value;
 }
 
 #endif /* RTE_MBUF_REFCNT_ATOMIC */
 
 /** Mbuf prefetch */
 #define RTE_MBUF_PREFETCH_TO_FREE(m) do {       \
-	if ((m) != NULL)                        \
-		rte_prefetch0(m);               \
+    if ((m) != NULL)                        \
+        rte_prefetch0(m);               \
 } while (0)
 
 
@@ -840,13 +869,15 @@ struct rte_pktmbuf_pool_private {
 void
 rte_mbuf_sanity_check(const struct rte_mbuf *m, int is_header);
 
-#define MBUF_RAW_ALLOC_CHECK(m) do {				\
-	RTE_ASSERT(rte_mbuf_refcnt_read(m) == 1);		\
-	RTE_ASSERT((m)->next == NULL);				\
-	RTE_ASSERT((m)->nb_segs == 1);				\
-	__rte_mbuf_sanity_check(m, 0);				\
+#define MBUF_RAW_ALLOC_CHECK(m) do {                \
+    RTE_ASSERT(rte_mbuf_refcnt_read(m) == 1);        \
+    RTE_ASSERT((m)->next == NULL);                \
+    RTE_ASSERT((m)->nb_segs == 1);                \
+    __rte_mbuf_sanity_check(m, 0);                \
 } while (0)
 
+
+
 /**
  * Allocate an uninitialized mbuf from mempool *mp*.
  *
@@ -868,12 +899,44 @@ struct rte_pktmbuf_pool_private {
  */
 static inline struct rte_mbuf *rte_mbuf_raw_alloc(struct rte_mempool *mp)
 {
-	struct rte_mbuf *m;
+    struct rte_mbuf *m;
+    void *pkt = NULL;
+    struct rte_circular_queue *ring;
+    int i = 0;
+    int ring_num = mp->ring_num;
+    if(mp->private_type == 1)
+    { 
+		//first try to get mbuf frong local ring
+        for(i = 0;i < ring_num ;i++)
+        {
+            ring = mp->local_ring[i];
+            pkt = rte_cirq_get(ring);
+            if(pkt  != NULL)
+            {
+                m = (struct rte_mbuf *)(pkt);
+                MBUF_RAW_ALLOC_CHECK(m);
+
+				if(m!= NULL && m->udata64 == 2)
+				{
+					
+		    		rte_exit(EXIT_FAILURE,"get a wrong packet pkt from mp local_ring \n ");
+				}
+				return m;
+            }
+        }
+    }
+	m = NULL;
+
+    if (rte_mempool_get(mp, (void **)&m) < 0) {
+        return NULL;
+	}
 
-	if (rte_mempool_get(mp, (void **)&m) < 0)
-		return NULL;
-	MBUF_RAW_ALLOC_CHECK(m);
-	return m;
+	if(m!= NULL && m->udata64 == 2)
+	{
+		    rte_exit(EXIT_FAILURE,"get a wrong packet pkt from mp rte_mempool_get %d\n ",rte_mempool_avail_count(mp));
+	}
+    MBUF_RAW_ALLOC_CHECK(m);
+    return m;
 }
 
 /**
@@ -893,12 +956,17 @@ static inline struct rte_mbuf *rte_mbuf_raw_alloc(struct rte_mempool *mp)
 static __rte_always_inline void
 rte_mbuf_raw_free(struct rte_mbuf *m)
 {
-	RTE_ASSERT(RTE_MBUF_DIRECT(m));
-	RTE_ASSERT(rte_mbuf_refcnt_read(m) == 1);
-	RTE_ASSERT(m->next == NULL);
-	RTE_ASSERT(m->nb_segs == 1);
-	__rte_mbuf_sanity_check(m, 0);
-	rte_mempool_put(m->pool, m);
+    RTE_ASSERT(RTE_MBUF_DIRECT(m));
+    RTE_ASSERT(rte_mbuf_refcnt_read(m) == 1);
+    RTE_ASSERT(m->next == NULL);
+    RTE_ASSERT(m->nb_segs == 1);
+    __rte_mbuf_sanity_check(m, 0);
+	if(m->udata64 == 2)
+	{
+		rte_exit(EXIT_FAILURE,"get a wrong packet pkt in rte_mbuf_raw_free \n ");
+	} else {
+    	rte_mempool_put(m->pool, m);
+	}
 }
 
 /* compat with older versions */
@@ -906,7 +974,7 @@ static inline struct rte_mbuf *rte_mbuf_raw_alloc(struct rte_mempool *mp)
 static inline void
 __rte_mbuf_raw_free(struct rte_mbuf *m)
 {
-	rte_mbuf_raw_free(m);
+    rte_mbuf_raw_free(m);
 }
 
 /* Operations on ctrl mbuf */
@@ -931,7 +999,7 @@ static inline struct rte_mbuf *rte_mbuf_raw_alloc(struct rte_mempool *mp)
  *   The index of the mbuf in the pool table.
  */
 void rte_ctrlmbuf_init(struct rte_mempool *mp, void *opaque_arg,
-		void *m, unsigned i);
+        void *m, unsigned i);
 
 /**
  * Allocate a new mbuf (type is ctrl) from mempool *mp*.
@@ -987,7 +1055,7 @@ void rte_ctrlmbuf_init(struct rte_mempool *mp, void *opaque_arg,
 static inline int
 rte_is_ctrlmbuf(struct rte_mbuf *m)
 {
-	return !!(m->ol_flags & CTRL_MBUF_FLAG);
+    return !!(m->ol_flags & CTRL_MBUF_FLAG);
 }
 
 /* Operations on pkt mbuf */
@@ -1012,7 +1080,7 @@ void rte_ctrlmbuf_init(struct rte_mempool *mp, void *opaque_arg,
  *   The index of the mbuf in the pool table.
  */
 void rte_pktmbuf_init(struct rte_mempool *mp, void *opaque_arg,
-		      void *m, unsigned i);
+              void *m, unsigned i);
 
 
 /**
@@ -1070,8 +1138,8 @@ void rte_pktmbuf_init(struct rte_mempool *mp, void *opaque_arg,
  */
 struct rte_mempool *
 rte_pktmbuf_pool_create(const char *name, unsigned n,
-	unsigned cache_size, uint16_t priv_size, uint16_t data_room_size,
-	int socket_id);
+    unsigned cache_size, uint16_t priv_size, uint16_t data_room_size,
+    int socket_id);
 
 /**
  * Create a mbuf pool with a given mempool ops name
@@ -1112,8 +1180,8 @@ struct rte_mempool *
  */
 struct rte_mempool * __rte_experimental
 rte_pktmbuf_pool_create_by_ops(const char *name, unsigned int n,
-	unsigned int cache_size, uint16_t priv_size, uint16_t data_room_size,
-	int socket_id, const char *ops_name);
+    unsigned int cache_size, uint16_t priv_size, uint16_t data_room_size,
+    int socket_id, const char *ops_name);
 
 /**
  * Get the data room size of mbufs stored in a pktmbuf_pool
@@ -1129,10 +1197,10 @@ struct rte_mempool * __rte_experimental
 static inline uint16_t
 rte_pktmbuf_data_room_size(struct rte_mempool *mp)
 {
-	struct rte_pktmbuf_pool_private *mbp_priv;
+    struct rte_pktmbuf_pool_private *mbp_priv;
 
-	mbp_priv = (struct rte_pktmbuf_pool_private *)rte_mempool_get_priv(mp);
-	return mbp_priv->mbuf_data_room_size;
+    mbp_priv = (struct rte_pktmbuf_pool_private *)rte_mempool_get_priv(mp);
+    return mbp_priv->mbuf_data_room_size;
 }
 
 /**
@@ -1150,10 +1218,10 @@ struct rte_mempool * __rte_experimental
 static inline uint16_t
 rte_pktmbuf_priv_size(struct rte_mempool *mp)
 {
-	struct rte_pktmbuf_pool_private *mbp_priv;
+    struct rte_pktmbuf_pool_private *mbp_priv;
 
-	mbp_priv = (struct rte_pktmbuf_pool_private *)rte_mempool_get_priv(mp);
-	return mbp_priv->mbuf_priv_size;
+    mbp_priv = (struct rte_pktmbuf_pool_private *)rte_mempool_get_priv(mp);
+    return mbp_priv->mbuf_priv_size;
 }
 
 /**
@@ -1166,8 +1234,8 @@ struct rte_mempool * __rte_experimental
  */
 static inline void rte_pktmbuf_reset_headroom(struct rte_mbuf *m)
 {
-	m->data_off = (uint16_t)RTE_MIN((uint16_t)RTE_PKTMBUF_HEADROOM,
-					(uint16_t)m->buf_len);
+    m->data_off = (uint16_t)RTE_MIN((uint16_t)RTE_PKTMBUF_HEADROOM,
+                    (uint16_t)m->buf_len);
 }
 
 /**
@@ -1182,20 +1250,20 @@ static inline void rte_pktmbuf_reset_headroom(struct rte_mbuf *m)
 
 static inline void rte_pktmbuf_reset(struct rte_mbuf *m)
 {
-	m->next = NULL;
-	m->pkt_len = 0;
-	m->tx_offload = 0;
-	m->vlan_tci = 0;
-	m->vlan_tci_outer = 0;
-	m->nb_segs = 1;
-	m->port = MBUF_INVALID_PORT;
-
-	m->ol_flags = 0;
-	m->packet_type = 0;
-	rte_pktmbuf_reset_headroom(m);
-
-	m->data_len = 0;
-	__rte_mbuf_sanity_check(m, 1);
+    m->next = NULL;
+    m->pkt_len = 0;
+    m->tx_offload = 0;
+    m->vlan_tci = 0;
+    m->vlan_tci_outer = 0;
+    m->nb_segs = 1;
+    m->port = MBUF_INVALID_PORT;
+
+    m->ol_flags = 0;
+    m->packet_type = 0;
+    rte_pktmbuf_reset_headroom(m);
+
+    m->data_len = 0;
+    __rte_mbuf_sanity_check(m, 1);
 }
 
 /**
@@ -1213,10 +1281,15 @@ static inline void rte_pktmbuf_reset(struct rte_mbuf *m)
  */
 static inline struct rte_mbuf *rte_pktmbuf_alloc(struct rte_mempool *mp)
 {
-	struct rte_mbuf *m;
-	if ((m = rte_mbuf_raw_alloc(mp)) != NULL)
-		rte_pktmbuf_reset(m);
-	return m;
+    struct rte_mbuf *m;
+    if ((m = rte_mbuf_raw_alloc(mp)) != NULL)
+        rte_pktmbuf_reset(m);
+
+	if(m != NULL && m->udata64 == 2)
+	{
+			rte_exit(EXIT_FAILURE,"rte_pktmbuf alloc is wrong and exit mp->name is %s \n",mp->name);
+	}
+    return m;
 }
 
 /**
@@ -1234,45 +1307,45 @@ static inline struct rte_mbuf *rte_pktmbuf_alloc(struct rte_mempool *mp)
  *   - -ENOENT: Not enough entries in the mempool; no mbufs are retrieved.
  */
 static inline int rte_pktmbuf_alloc_bulk(struct rte_mempool *pool,
-	 struct rte_mbuf **mbufs, unsigned count)
+     struct rte_mbuf **mbufs, unsigned count)
 {
-	unsigned idx = 0;
-	int rc;
-
-	rc = rte_mempool_get_bulk(pool, (void **)mbufs, count);
-	if (unlikely(rc))
-		return rc;
-
-	/* To understand duff's device on loop unwinding optimization, see
-	 * https://en.wikipedia.org/wiki/Duff's_device.
-	 * Here while() loop is used rather than do() while{} to avoid extra
-	 * check if count is zero.
-	 */
-	switch (count % 4) {
-	case 0:
-		while (idx != count) {
-			MBUF_RAW_ALLOC_CHECK(mbufs[idx]);
-			rte_pktmbuf_reset(mbufs[idx]);
-			idx++;
-			/* fall-through */
-	case 3:
-			MBUF_RAW_ALLOC_CHECK(mbufs[idx]);
-			rte_pktmbuf_reset(mbufs[idx]);
-			idx++;
-			/* fall-through */
-	case 2:
-			MBUF_RAW_ALLOC_CHECK(mbufs[idx]);
-			rte_pktmbuf_reset(mbufs[idx]);
-			idx++;
-			/* fall-through */
-	case 1:
-			MBUF_RAW_ALLOC_CHECK(mbufs[idx]);
-			rte_pktmbuf_reset(mbufs[idx]);
-			idx++;
-			/* fall-through */
-		}
-	}
-	return 0;
+    unsigned idx = 0;
+    int rc;
+
+    rc = rte_mempool_get_bulk(pool, (void **)mbufs, count);
+    if (unlikely(rc))
+        return rc;
+
+    /* To understand duff's device on loop unwinding optimization, see
+     * https://en.wikipedia.org/wiki/Duff's_device.
+     * Here while() loop is used rather than do() while{} to avoid extra
+     * check if count is zero.
+     */
+    switch (count % 4) {
+    case 0:
+        while (idx != count) {
+            MBUF_RAW_ALLOC_CHECK(mbufs[idx]);
+            rte_pktmbuf_reset(mbufs[idx]);
+            idx++;
+            /* fall-through */
+    case 3:
+            MBUF_RAW_ALLOC_CHECK(mbufs[idx]);
+            rte_pktmbuf_reset(mbufs[idx]);
+            idx++;
+            /* fall-through */
+    case 2:
+            MBUF_RAW_ALLOC_CHECK(mbufs[idx]);
+            rte_pktmbuf_reset(mbufs[idx]);
+            idx++;
+            /* fall-through */
+    case 1:
+            MBUF_RAW_ALLOC_CHECK(mbufs[idx]);
+            rte_pktmbuf_reset(mbufs[idx]);
+            idx++;
+            /* fall-through */
+        }
+    }
+    return 0;
 }
 
 /**
@@ -1294,40 +1367,40 @@ static inline int rte_pktmbuf_alloc_bulk(struct rte_mempool *pool,
  */
 static inline void rte_pktmbuf_attach(struct rte_mbuf *mi, struct rte_mbuf *m)
 {
-	struct rte_mbuf *md;
-
-	RTE_ASSERT(RTE_MBUF_DIRECT(mi) &&
-	    rte_mbuf_refcnt_read(mi) == 1);
-
-	/* if m is not direct, get the mbuf that embeds the data */
-	if (RTE_MBUF_DIRECT(m))
-		md = m;
-	else
-		md = rte_mbuf_from_indirect(m);
-
-	rte_mbuf_refcnt_update(md, 1);
-	mi->priv_size = m->priv_size;
-	mi->buf_iova = m->buf_iova;
-	mi->buf_addr = m->buf_addr;
-	mi->buf_len = m->buf_len;
-
-	mi->data_off = m->data_off;
-	mi->data_len = m->data_len;
-	mi->port = m->port;
-	mi->vlan_tci = m->vlan_tci;
-	mi->vlan_tci_outer = m->vlan_tci_outer;
-	mi->tx_offload = m->tx_offload;
-	mi->hash = m->hash;
-
-	mi->next = NULL;
-	mi->pkt_len = mi->data_len;
-	mi->nb_segs = 1;
-	mi->ol_flags = m->ol_flags | IND_ATTACHED_MBUF;
-	mi->packet_type = m->packet_type;
-	mi->timestamp = m->timestamp;
-
-	__rte_mbuf_sanity_check(mi, 1);
-	__rte_mbuf_sanity_check(m, 0);
+    struct rte_mbuf *md;
+
+    RTE_ASSERT(RTE_MBUF_DIRECT(mi) &&
+        rte_mbuf_refcnt_read(mi) == 1);
+
+    /* if m is not direct, get the mbuf that embeds the data */
+    if (RTE_MBUF_DIRECT(m))
+        md = m;
+    else
+        md = rte_mbuf_from_indirect(m);
+
+    rte_mbuf_refcnt_update(md, 1);
+    mi->priv_size = m->priv_size;
+    mi->buf_iova = m->buf_iova;
+    mi->buf_addr = m->buf_addr;
+    mi->buf_len = m->buf_len;
+
+    mi->data_off = m->data_off;
+    mi->data_len = m->data_len;
+    mi->port = m->port;
+    mi->vlan_tci = m->vlan_tci;
+    mi->vlan_tci_outer = m->vlan_tci_outer;
+    mi->tx_offload = m->tx_offload;
+    mi->hash = m->hash;
+
+    mi->next = NULL;
+    mi->pkt_len = mi->data_len;
+    mi->nb_segs = 1;
+    mi->ol_flags = m->ol_flags | IND_ATTACHED_MBUF;
+    mi->packet_type = m->packet_type;
+    mi->timestamp = m->timestamp;
+
+    __rte_mbuf_sanity_check(mi, 1);
+    __rte_mbuf_sanity_check(m, 0);
 }
 
 /**
@@ -1345,29 +1418,31 @@ static inline void rte_pktmbuf_attach(struct rte_mbuf *mi, struct rte_mbuf *m)
  */
 static inline void rte_pktmbuf_detach(struct rte_mbuf *m)
 {
-	struct rte_mbuf *md = rte_mbuf_from_indirect(m);
-	struct rte_mempool *mp = m->pool;
-	uint32_t mbuf_size, buf_len;
-	uint16_t priv_size;
-
-	priv_size = rte_pktmbuf_priv_size(mp);
-	mbuf_size = (uint32_t)(sizeof(struct rte_mbuf) + priv_size);
-	buf_len = rte_pktmbuf_data_room_size(mp);
-
-	m->priv_size = priv_size;
-	m->buf_addr = (char *)m + mbuf_size;
-	m->buf_iova = rte_mempool_virt2iova(m) + mbuf_size;
-	m->buf_len = (uint16_t)buf_len;
-	rte_pktmbuf_reset_headroom(m);
-	m->data_len = 0;
-	m->ol_flags = 0;
-
-	if (rte_mbuf_refcnt_update(md, -1) == 0) {
-		md->next = NULL;
-		md->nb_segs = 1;
-		rte_mbuf_refcnt_set(md, 1);
-		rte_mbuf_raw_free(md);
-	}
+    struct rte_mbuf *md = rte_mbuf_from_indirect(m);
+    struct rte_mempool *mp = m->pool;
+    uint32_t mbuf_size, buf_len;
+    uint16_t priv_size;
+
+    priv_size = rte_pktmbuf_priv_size(mp);
+    mbuf_size = (uint32_t)(sizeof(struct rte_mbuf) + priv_size);
+    buf_len = rte_pktmbuf_data_room_size(mp);
+
+    m->priv_size = priv_size;
+    m->buf_addr = (char *)m + mbuf_size;
+    m->buf_iova = rte_mempool_virt2iova(m) + mbuf_size;
+    m->buf_len = (uint16_t)buf_len;
+    rte_pktmbuf_reset_headroom(m);
+    m->data_len = 0;
+    m->ol_flags = 0;
+
+
+
+    if (rte_mbuf_refcnt_update(md, -1) == 0) {
+        md->next = NULL;
+        md->nb_segs = 1;
+        rte_mbuf_refcnt_set(md, 1);
+        rte_mbuf_raw_free(md);
+    }
 }
 
 /**
@@ -1387,34 +1462,38 @@ static inline void rte_pktmbuf_detach(struct rte_mbuf *m)
 static __rte_always_inline struct rte_mbuf *
 rte_pktmbuf_prefree_seg(struct rte_mbuf *m)
 {
-	__rte_mbuf_sanity_check(m, 0);
+    __rte_mbuf_sanity_check(m, 0);
+	if(m->udata64 == 2)
+	{
+		rte_exit(EXIT_FAILURE,"add  a udata64 == 2 in rte_pktmbuf_prefree_seg \n");
+		return NULL;
+	}
+    if (likely(rte_mbuf_refcnt_read(m) == 1)) {
 
-	if (likely(rte_mbuf_refcnt_read(m) == 1)) {
+        if (RTE_MBUF_INDIRECT(m))
+            rte_pktmbuf_detach(m);
 
-		if (RTE_MBUF_INDIRECT(m))
-			rte_pktmbuf_detach(m);
+        if (m->next != NULL) {
+            m->next = NULL;
+            m->nb_segs = 1;
+        }
 
-		if (m->next != NULL) {
-			m->next = NULL;
-			m->nb_segs = 1;
-		}
+        return m;
 
-		return m;
+    } else if (__rte_mbuf_refcnt_update(m, -1) == 0) {
 
-	} else if (__rte_mbuf_refcnt_update(m, -1) == 0) {
+        if (RTE_MBUF_INDIRECT(m))
+            rte_pktmbuf_detach(m);
 
-		if (RTE_MBUF_INDIRECT(m))
-			rte_pktmbuf_detach(m);
-
-		if (m->next != NULL) {
-			m->next = NULL;
-			m->nb_segs = 1;
-		}
-		rte_mbuf_refcnt_set(m, 1);
+        if (m->next != NULL) {
+            m->next = NULL;
+            m->nb_segs = 1;
+        }
+        rte_mbuf_refcnt_set(m, 1);
 
-		return m;
-	}
-	return NULL;
+        return m;
+    }
+    return NULL;
 }
 
 /* deprecated, replaced by rte_pktmbuf_prefree_seg() */
@@ -1422,7 +1501,7 @@ static inline void rte_pktmbuf_detach(struct rte_mbuf *m)
 static inline struct rte_mbuf *
 __rte_pktmbuf_prefree_seg(struct rte_mbuf *m)
 {
-	return rte_pktmbuf_prefree_seg(m);
+    return rte_pktmbuf_prefree_seg(m);
 }
 
 /**
@@ -1436,12 +1515,62 @@ static inline void rte_pktmbuf_detach(struct rte_mbuf *m)
  */
 static __rte_always_inline void
 rte_pktmbuf_free_seg(struct rte_mbuf *m)
-{
-	m = rte_pktmbuf_prefree_seg(m);
-	if (likely(m != NULL))
-		rte_mbuf_raw_free(m);
+{   
+    if(m->udata64 == 2)
+    {
+        m = NULL;
+        return;
+    }
+    else
+    {
+        m = rte_pktmbuf_prefree_seg(m);
+
+    	if (likely(m != NULL))
+    	{
+        	rte_mbuf_raw_free(m);
+    	}
+    }
+
 }
 
+
+static inline void rte_pktmbuf_free_forward(struct rte_mbuf *m,int core_id)
+{
+    struct rte_circular_queue *ring;
+    struct rte_mempool *mp;
+
+    struct rte_mbuf *m_next;
+    mp = m->pool;
+    ring = mp->local_ring[core_id];
+
+	if(mp->core_id == core_id){
+    	if (m != NULL){
+       		__rte_mbuf_sanity_check(m, 1);
+		}
+
+    	while (m != NULL) {
+        	m_next = m->next;
+        	rte_pktmbuf_free_seg(m);
+        	m = m_next;
+    	}
+	}
+
+    if(likely(ring != NULL))
+    {
+		
+    	while (m != NULL) {
+        	m_next = m->next;
+        	m = m_next;
+        	if (rte_cirq_add(ring,m) != 1)
+			{
+				rte_exit(EXIT_FAILURE,"cirq is full and exit ");
+			}
+		}
+    } else {
+		rte_exit(EXIT_FAILURE,"mp->ring == NULL and exit ");
+	}
+
+}
 /**
  * Free a packet mbuf back into its original mempool.
  *
@@ -1453,16 +1582,16 @@ static inline void rte_pktmbuf_detach(struct rte_mbuf *m)
  */
 static inline void rte_pktmbuf_free(struct rte_mbuf *m)
 {
-	struct rte_mbuf *m_next;
+    struct rte_mbuf *m_next;
 
-	if (m != NULL)
-		__rte_mbuf_sanity_check(m, 1);
+    if (m != NULL)
+        __rte_mbuf_sanity_check(m, 1);
 
-	while (m != NULL) {
-		m_next = m->next;
-		rte_pktmbuf_free_seg(m);
-		m = m_next;
-	}
+    while (m != NULL) {
+        m_next = m->next;
+        rte_pktmbuf_free_seg(m);
+        m = m_next;
+    }
 }
 
 /**
@@ -1483,40 +1612,40 @@ static inline void rte_pktmbuf_free(struct rte_mbuf *m)
  *   - NULL if allocation fails.
  */
 static inline struct rte_mbuf *rte_pktmbuf_clone(struct rte_mbuf *md,
-		struct rte_mempool *mp)
+        struct rte_mempool *mp)
 {
-	struct rte_mbuf *mc, *mi, **prev;
-	uint32_t pktlen;
-	uint16_t nseg;
-
-	if (unlikely ((mc = rte_pktmbuf_alloc(mp)) == NULL))
-		return NULL;
-
-	mi = mc;
-	prev = &mi->next;
-	pktlen = md->pkt_len;
-	nseg = 0;
-
-	do {
-		nseg++;
-		rte_pktmbuf_attach(mi, md);
-		*prev = mi;
-		prev = &mi->next;
-	} while ((md = md->next) != NULL &&
-	    (mi = rte_pktmbuf_alloc(mp)) != NULL);
-
-	*prev = NULL;
-	mc->nb_segs = nseg;
-	mc->pkt_len = pktlen;
-
-	/* Allocation of new indirect segment failed */
-	if (unlikely (mi == NULL)) {
-		rte_pktmbuf_free(mc);
-		return NULL;
-	}
-
-	__rte_mbuf_sanity_check(mc, 1);
-	return mc;
+    struct rte_mbuf *mc, *mi, **prev;
+    uint32_t pktlen;
+    uint16_t nseg;
+
+    if (unlikely ((mc = rte_pktmbuf_alloc(mp)) == NULL))
+        return NULL;
+
+    mi = mc;
+    prev = &mi->next;
+    pktlen = md->pkt_len;
+    nseg = 0;
+
+    do {
+        nseg++;
+        rte_pktmbuf_attach(mi, md);
+        *prev = mi;
+        prev = &mi->next;
+    } while ((md = md->next) != NULL &&
+        (mi = rte_pktmbuf_alloc(mp)) != NULL);
+
+    *prev = NULL;
+    mc->nb_segs = nseg;
+    mc->pkt_len = pktlen;
+
+    /* Allocation of new indirect segment failed */
+    if (unlikely (mi == NULL)) {
+        rte_pktmbuf_free(mc);
+        return NULL;
+    }
+
+    __rte_mbuf_sanity_check(mc, 1);
+    return mc;
 }
 
 /**
@@ -1532,11 +1661,11 @@ static inline struct rte_mbuf *rte_pktmbuf_clone(struct rte_mbuf *md,
  */
 static inline void rte_pktmbuf_refcnt_update(struct rte_mbuf *m, int16_t v)
 {
-	__rte_mbuf_sanity_check(m, 1);
+    __rte_mbuf_sanity_check(m, 1);
 
-	do {
-		rte_mbuf_refcnt_update(m, v);
-	} while ((m = m->next) != NULL);
+    do {
+        rte_mbuf_refcnt_update(m, v);
+    } while ((m = m->next) != NULL);
 }
 
 /**
@@ -1549,8 +1678,8 @@ static inline void rte_pktmbuf_refcnt_update(struct rte_mbuf *m, int16_t v)
  */
 static inline uint16_t rte_pktmbuf_headroom(const struct rte_mbuf *m)
 {
-	__rte_mbuf_sanity_check(m, 0);
-	return m->data_off;
+    __rte_mbuf_sanity_check(m, 0);
+    return m->data_off;
 }
 
 /**
@@ -1563,9 +1692,9 @@ static inline uint16_t rte_pktmbuf_headroom(const struct rte_mbuf *m)
  */
 static inline uint16_t rte_pktmbuf_tailroom(const struct rte_mbuf *m)
 {
-	__rte_mbuf_sanity_check(m, 0);
-	return (uint16_t)(m->buf_len - rte_pktmbuf_headroom(m) -
-			  m->data_len);
+    __rte_mbuf_sanity_check(m, 0);
+    return (uint16_t)(m->buf_len - rte_pktmbuf_headroom(m) -
+              m->data_len);
 }
 
 /**
@@ -1578,10 +1707,10 @@ static inline uint16_t rte_pktmbuf_tailroom(const struct rte_mbuf *m)
  */
 static inline struct rte_mbuf *rte_pktmbuf_lastseg(struct rte_mbuf *m)
 {
-	__rte_mbuf_sanity_check(m, 1);
-	while (m->next != NULL)
-		m = m->next;
-	return m;
+    __rte_mbuf_sanity_check(m, 1);
+    while (m->next != NULL)
+        m = m->next;
+    return m;
 }
 
 /**
@@ -1598,8 +1727,8 @@ static inline struct rte_mbuf *rte_pktmbuf_lastseg(struct rte_mbuf *m)
  * @param t
  *   The type to cast the result into.
  */
-#define rte_pktmbuf_mtod_offset(m, t, o)	\
-	((t)((char *)(m)->buf_addr + (m)->data_off + (o)))
+#define rte_pktmbuf_mtod_offset(m, t, o)    \
+    ((t)((char *)(m)->buf_addr + (m)->data_off + (o)))
 
 /**
  * A macro that points to the start of the data in the mbuf.
@@ -1625,11 +1754,11 @@ static inline struct rte_mbuf *rte_pktmbuf_lastseg(struct rte_mbuf *m)
  *   The offset into the data to calculate address from.
  */
 #define rte_pktmbuf_iova_offset(m, o) \
-	(rte_iova_t)((m)->buf_iova + (m)->data_off + (o))
+    (rte_iova_t)((m)->buf_iova + (m)->data_off + (o))
 
 /* deprecated */
 #define rte_pktmbuf_mtophys_offset(m, o) \
-	rte_pktmbuf_iova_offset(m, o)
+    rte_pktmbuf_iova_offset(m, o)
 
 /**
  * A macro that returns the IO address that points to the start of the
@@ -1679,21 +1808,21 @@ static inline struct rte_mbuf *rte_pktmbuf_lastseg(struct rte_mbuf *m)
  *   NULL if there is not enough headroom space in the first segment
  */
 static inline char *rte_pktmbuf_prepend(struct rte_mbuf *m,
-					uint16_t len)
+                    uint16_t len)
 {
-	__rte_mbuf_sanity_check(m, 1);
+    __rte_mbuf_sanity_check(m, 1);
 
-	if (unlikely(len > rte_pktmbuf_headroom(m)))
-		return NULL;
+    if (unlikely(len > rte_pktmbuf_headroom(m)))
+        return NULL;
 
-	/* NB: elaborating the subtraction like this instead of using
-	 *     -= allows us to ensure the result type is uint16_t
-	 *     avoiding compiler warnings on gcc 8.1 at least */
-	m->data_off = (uint16_t)(m->data_off - len);
-	m->data_len = (uint16_t)(m->data_len + len);
-	m->pkt_len  = (m->pkt_len + len);
+    /* NB: elaborating the subtraction like this instead of using
+     *     -= allows us to ensure the result type is uint16_t
+     *     avoiding compiler warnings on gcc 8.1 at least */
+    m->data_off = (uint16_t)(m->data_off - len);
+    m->data_len = (uint16_t)(m->data_len + len);
+    m->pkt_len  = (m->pkt_len + len);
 
-	return (char *)m->buf_addr + m->data_off;
+    return (char *)m->buf_addr + m->data_off;
 }
 
 /**
@@ -1713,19 +1842,19 @@ static inline char *rte_pktmbuf_prepend(struct rte_mbuf *m,
  */
 static inline char *rte_pktmbuf_append(struct rte_mbuf *m, uint16_t len)
 {
-	void *tail;
-	struct rte_mbuf *m_last;
+    void *tail;
+    struct rte_mbuf *m_last;
 
-	__rte_mbuf_sanity_check(m, 1);
+    __rte_mbuf_sanity_check(m, 1);
 
-	m_last = rte_pktmbuf_lastseg(m);
-	if (unlikely(len > rte_pktmbuf_tailroom(m_last)))
-		return NULL;
+    m_last = rte_pktmbuf_lastseg(m);
+    if (unlikely(len > rte_pktmbuf_tailroom(m_last)))
+        return NULL;
 
-	tail = (char *)m_last->buf_addr + m_last->data_off + m_last->data_len;
-	m_last->data_len = (uint16_t)(m_last->data_len + len);
-	m->pkt_len  = (m->pkt_len + len);
-	return (char*) tail;
+    tail = (char *)m_last->buf_addr + m_last->data_off + m_last->data_len;
+    m_last->data_len = (uint16_t)(m_last->data_len + len);
+    m->pkt_len  = (m->pkt_len + len);
+    return (char*) tail;
 }
 
 /**
@@ -1744,18 +1873,18 @@ static inline char *rte_pktmbuf_append(struct rte_mbuf *m, uint16_t len)
  */
 static inline char *rte_pktmbuf_adj(struct rte_mbuf *m, uint16_t len)
 {
-	__rte_mbuf_sanity_check(m, 1);
-
-	if (unlikely(len > m->data_len))
-		return NULL;
-
-	/* NB: elaborating the addition like this instead of using
-	 *     += allows us to ensure the result type is uint16_t
-	 *     avoiding compiler warnings on gcc 8.1 at least */
-	m->data_len = (uint16_t)(m->data_len - len);
-	m->data_off = (uint16_t)(m->data_off + len);
-	m->pkt_len  = (m->pkt_len - len);
-	return (char *)m->buf_addr + m->data_off;
+    __rte_mbuf_sanity_check(m, 1);
+
+    if (unlikely(len > m->data_len))
+        return NULL;
+
+    /* NB: elaborating the addition like this instead of using
+     *     += allows us to ensure the result type is uint16_t
+     *     avoiding compiler warnings on gcc 8.1 at least */
+    m->data_len = (uint16_t)(m->data_len - len);
+    m->data_off = (uint16_t)(m->data_off + len);
+    m->pkt_len  = (m->pkt_len - len);
+    return (char *)m->buf_addr + m->data_off;
 }
 
 /**
@@ -1774,17 +1903,17 @@ static inline char *rte_pktmbuf_adj(struct rte_mbuf *m, uint16_t len)
  */
 static inline int rte_pktmbuf_trim(struct rte_mbuf *m, uint16_t len)
 {
-	struct rte_mbuf *m_last;
+    struct rte_mbuf *m_last;
 
-	__rte_mbuf_sanity_check(m, 1);
+    __rte_mbuf_sanity_check(m, 1);
 
-	m_last = rte_pktmbuf_lastseg(m);
-	if (unlikely(len > m_last->data_len))
-		return -1;
+    m_last = rte_pktmbuf_lastseg(m);
+    if (unlikely(len > m_last->data_len))
+        return -1;
 
-	m_last->data_len = (uint16_t)(m_last->data_len - len);
-	m->pkt_len  = (m->pkt_len - len);
-	return 0;
+    m_last->data_len = (uint16_t)(m_last->data_len - len);
+    m->pkt_len  = (m->pkt_len - len);
+    return 0;
 }
 
 /**
@@ -1798,15 +1927,15 @@ static inline int rte_pktmbuf_trim(struct rte_mbuf *m, uint16_t len)
  */
 static inline int rte_pktmbuf_is_contiguous(const struct rte_mbuf *m)
 {
-	__rte_mbuf_sanity_check(m, 1);
-	return !!(m->nb_segs == 1);
+    __rte_mbuf_sanity_check(m, 1);
+    return !!(m->nb_segs == 1);
 }
 
 /**
  * @internal used by rte_pktmbuf_read().
  */
 const void *__rte_pktmbuf_read(const struct rte_mbuf *m, uint32_t off,
-	uint32_t len, void *buf);
+    uint32_t len, void *buf);
 
 /**
  * Read len data bytes in a mbuf at specified offset.
@@ -1829,12 +1958,12 @@ const void *__rte_pktmbuf_read(const struct rte_mbuf *m, uint32_t off,
  *   or in the user buffer. If mbuf is too small, NULL is returned.
  */
 static inline const void *rte_pktmbuf_read(const struct rte_mbuf *m,
-	uint32_t off, uint32_t len, void *buf)
+    uint32_t off, uint32_t len, void *buf)
 {
-	if (likely(off + len <= rte_pktmbuf_data_len(m)))
-		return rte_pktmbuf_mtod_offset(m, char *, off);
-	else
-		return __rte_pktmbuf_read(m, off, len, buf);
+    if (likely(off + len <= rte_pktmbuf_data_len(m)))
+        return rte_pktmbuf_mtod_offset(m, char *, off);
+    else
+        return __rte_pktmbuf_read(m, off, len, buf);
 }
 
 /**
@@ -1855,27 +1984,27 @@ static inline const void *rte_pktmbuf_read(const struct rte_mbuf *m,
  */
 static inline int rte_pktmbuf_chain(struct rte_mbuf *head, struct rte_mbuf *tail)
 {
-	struct rte_mbuf *cur_tail;
+    struct rte_mbuf *cur_tail;
 
-	/* Check for number-of-segments-overflow */
-	if (head->nb_segs + tail->nb_segs > RTE_MBUF_MAX_NB_SEGS)
-		return -EOVERFLOW;
+    /* Check for number-of-segments-overflow */
+    if (head->nb_segs + tail->nb_segs > RTE_MBUF_MAX_NB_SEGS)
+        return -EOVERFLOW;
 
-	/* Chain 'tail' onto the old tail */
-	cur_tail = rte_pktmbuf_lastseg(head);
-	cur_tail->next = tail;
+    /* Chain 'tail' onto the old tail */
+    cur_tail = rte_pktmbuf_lastseg(head);
+    cur_tail->next = tail;
 
-	/* accumulate number of segments and total length.
-	 * NB: elaborating the addition like this instead of using
-	 *     -= allows us to ensure the result type is uint16_t
-	 *     avoiding compiler warnings on gcc 8.1 at least */
-	head->nb_segs = (uint16_t)(head->nb_segs + tail->nb_segs);
-	head->pkt_len += tail->pkt_len;
+    /* accumulate number of segments and total length.
+     * NB: elaborating the addition like this instead of using
+     *     -= allows us to ensure the result type is uint16_t
+     *     avoiding compiler warnings on gcc 8.1 at least */
+    head->nb_segs = (uint16_t)(head->nb_segs + tail->nb_segs);
+    head->pkt_len += tail->pkt_len;
 
-	/* pkt_len is only set in the head */
-	tail->pkt_len = tail->data_len;
+    /* pkt_len is only set in the head */
+    tail->pkt_len = tail->data_len;
 
-	return 0;
+    return 0;
 }
 
 /**
@@ -1891,46 +2020,46 @@ static inline int rte_pktmbuf_chain(struct rte_mbuf *head, struct rte_mbuf *tail
 static inline int
 rte_validate_tx_offload(const struct rte_mbuf *m)
 {
-	uint64_t ol_flags = m->ol_flags;
-	uint64_t inner_l3_offset = m->l2_len;
-
-	/* Does packet set any of available offloads? */
-	if (!(ol_flags & PKT_TX_OFFLOAD_MASK))
-		return 0;
-
-	if (ol_flags & PKT_TX_OUTER_IP_CKSUM)
-		/* NB: elaborating the addition like this instead of using
-		 *     += gives the result uint64_t type instead of int,
-		 *     avoiding compiler warnings on gcc 8.1 at least */
-		inner_l3_offset = inner_l3_offset + m->outer_l2_len +
-				  m->outer_l3_len;
-
-	/* Headers are fragmented */
-	if (rte_pktmbuf_data_len(m) < inner_l3_offset + m->l3_len + m->l4_len)
-		return -ENOTSUP;
-
-	/* IP checksum can be counted only for IPv4 packet */
-	if ((ol_flags & PKT_TX_IP_CKSUM) && (ol_flags & PKT_TX_IPV6))
-		return -EINVAL;
-
-	/* IP type not set when required */
-	if (ol_flags & (PKT_TX_L4_MASK | PKT_TX_TCP_SEG))
-		if (!(ol_flags & (PKT_TX_IPV4 | PKT_TX_IPV6)))
-			return -EINVAL;
-
-	/* Check requirements for TSO packet */
-	if (ol_flags & PKT_TX_TCP_SEG)
-		if ((m->tso_segsz == 0) ||
-				((ol_flags & PKT_TX_IPV4) &&
-				!(ol_flags & PKT_TX_IP_CKSUM)))
-			return -EINVAL;
-
-	/* PKT_TX_OUTER_IP_CKSUM set for non outer IPv4 packet. */
-	if ((ol_flags & PKT_TX_OUTER_IP_CKSUM) &&
-			!(ol_flags & PKT_TX_OUTER_IPV4))
-		return -EINVAL;
-
-	return 0;
+    uint64_t ol_flags = m->ol_flags;
+    uint64_t inner_l3_offset = m->l2_len;
+
+    /* Does packet set any of available offloads? */
+    if (!(ol_flags & PKT_TX_OFFLOAD_MASK))
+        return 0;
+
+    if (ol_flags & PKT_TX_OUTER_IP_CKSUM)
+        /* NB: elaborating the addition like this instead of using
+         *     += gives the result uint64_t type instead of int,
+         *     avoiding compiler warnings on gcc 8.1 at least */
+        inner_l3_offset = inner_l3_offset + m->outer_l2_len +
+                  m->outer_l3_len;
+
+    /* Headers are fragmented */
+    if (rte_pktmbuf_data_len(m) < inner_l3_offset + m->l3_len + m->l4_len)
+        return -ENOTSUP;
+
+    /* IP checksum can be counted only for IPv4 packet */
+    if ((ol_flags & PKT_TX_IP_CKSUM) && (ol_flags & PKT_TX_IPV6))
+        return -EINVAL;
+
+    /* IP type not set when required */
+    if (ol_flags & (PKT_TX_L4_MASK | PKT_TX_TCP_SEG))
+        if (!(ol_flags & (PKT_TX_IPV4 | PKT_TX_IPV6)))
+            return -EINVAL;
+
+    /* Check requirements for TSO packet */
+    if (ol_flags & PKT_TX_TCP_SEG)
+        if ((m->tso_segsz == 0) ||
+                ((ol_flags & PKT_TX_IPV4) &&
+                !(ol_flags & PKT_TX_IP_CKSUM)))
+            return -EINVAL;
+
+    /* PKT_TX_OUTER_IP_CKSUM set for non outer IPv4 packet. */
+    if ((ol_flags & PKT_TX_OUTER_IP_CKSUM) &&
+            !(ol_flags & PKT_TX_OUTER_IPV4))
+        return -EINVAL;
+
+    return 0;
 }
 
 /**
@@ -1948,40 +2077,40 @@ static inline int rte_pktmbuf_chain(struct rte_mbuf *head, struct rte_mbuf *tail
 static inline int
 rte_pktmbuf_linearize(struct rte_mbuf *mbuf)
 {
-	size_t seg_len, copy_len;
-	struct rte_mbuf *m;
-	struct rte_mbuf *m_next;
-	char *buffer;
+    size_t seg_len, copy_len;
+    struct rte_mbuf *m;
+    struct rte_mbuf *m_next;
+    char *buffer;
 
-	if (rte_pktmbuf_is_contiguous(mbuf))
-		return 0;
+    if (rte_pktmbuf_is_contiguous(mbuf))
+        return 0;
 
-	/* Extend first segment to the total packet length */
-	copy_len = rte_pktmbuf_pkt_len(mbuf) - rte_pktmbuf_data_len(mbuf);
+    /* Extend first segment to the total packet length */
+    copy_len = rte_pktmbuf_pkt_len(mbuf) - rte_pktmbuf_data_len(mbuf);
 
-	if (unlikely(copy_len > rte_pktmbuf_tailroom(mbuf)))
-		return -1;
+    if (unlikely(copy_len > rte_pktmbuf_tailroom(mbuf)))
+        return -1;
 
-	buffer = rte_pktmbuf_mtod_offset(mbuf, char *, mbuf->data_len);
-	mbuf->data_len = (uint16_t)(mbuf->pkt_len);
+    buffer = rte_pktmbuf_mtod_offset(mbuf, char *, mbuf->data_len);
+    mbuf->data_len = (uint16_t)(mbuf->pkt_len);
 
-	/* Append data from next segments to the first one */
-	m = mbuf->next;
-	while (m != NULL) {
-		m_next = m->next;
+    /* Append data from next segments to the first one */
+    m = mbuf->next;
+    while (m != NULL) {
+        m_next = m->next;
 
-		seg_len = rte_pktmbuf_data_len(m);
-		rte_memcpy(buffer, rte_pktmbuf_mtod(m, char *), seg_len);
-		buffer += seg_len;
+        seg_len = rte_pktmbuf_data_len(m);
+        rte_memcpy(buffer, rte_pktmbuf_mtod(m, char *), seg_len);
+        buffer += seg_len;
 
-		rte_pktmbuf_free_seg(m);
-		m = m_next;
-	}
+        rte_pktmbuf_free_seg(m);
+        m = m_next;
+    }
 
-	mbuf->next = NULL;
-	mbuf->nb_segs = 1;
+    mbuf->next = NULL;
+    mbuf->nb_segs = 1;
 
-	return 0;
+    return 0;
 }
 
 /**
diff --git a/lib/librte_mempool/rte_mempool.c b/lib/librte_mempool/rte_mempool.c
index abbee58..406ad96 100644
--- a/lib/librte_mempool/rte_mempool.c
+++ b/lib/librte_mempool/rte_mempool.c
@@ -39,7 +39,8 @@
 };
 EAL_REGISTER_TAILQ(rte_mempool_tailq)
 
-#define CACHE_FLUSHTHRESH_MULTIPLIER 1.5
+#define CACHE_FLUSHTHRESH_MULTIPLIER 1
+//#define CACHE_FLUSHTHRESH_MULTIPLIER 1.5
 #define CALC_CACHE_FLUSHTHRESH(c)	\
 	((typeof(c))((c) * CACHE_FLUSHTHRESH_MULTIPLIER))
 
@@ -801,6 +802,7 @@ struct rte_mempool *
 	/* asked cache too big */
 	if (cache_size > RTE_MEMPOOL_CACHE_MAX_SIZE ||
 	    CALC_CACHE_FLUSHTHRESH(cache_size) > n) {
+                fprintf(stderr,"/* asked cache too big cache size is %d n is %d CALC_CACHE_FLUSH is %d RTE_MEMPOOL_CACHE_MAX_SIZE is %d*/\n",cache_size,n,CALC_CACHE_FLUSHTHRESH(cache_size),RTE_MEMPOOL_CACHE_MAX_SIZE);
 		rte_errno = EINVAL;
 		return NULL;
 	}
@@ -811,6 +813,8 @@ struct rte_mempool *
 
 	/* calculate mempool object sizes. */
 	if (!rte_mempool_calc_obj_size(elt_size, flags, &objsz)) {
+
+                fprintf(stderr,"/* MEMPOOL_HEADER_SIZE */\n");
 		rte_errno = EINVAL;
 		return NULL;
 	}
@@ -913,6 +917,8 @@ struct rte_mempool *
 	if (mp == NULL)
 		return NULL;
 
+	//int private_type;
+    mp->private_type = 0;
 	/*
 	 * Since we have 4 combinations of the SP/SC/MP/MC examine the flags to
 	 * set the correct index into the table of ops structs.
diff --git a/lib/librte_mempool/rte_mempool.h b/lib/librte_mempool/rte_mempool.h
index 8b1b7f7..6885454 100644
--- a/lib/librte_mempool/rte_mempool.h
+++ b/lib/librte_mempool/rte_mempool.h
@@ -50,6 +50,7 @@
 #include <rte_ring.h>
 #include <rte_memcpy.h>
 #include <rte_common.h>
+#include <rte_circular_queue.h>
 
 #ifdef __cplusplus
 extern "C" {
@@ -64,58 +65,249 @@
  * A structure that stores the mempool statistics (per-lcore).
  */
 struct rte_mempool_debug_stats {
-	uint64_t put_bulk;         /**< Number of puts. */
-	uint64_t put_objs;         /**< Number of objects successfully put. */
-	uint64_t get_success_bulk; /**< Successful allocation number. */
-	uint64_t get_success_objs; /**< Objects successfully allocated. */
-	uint64_t get_fail_bulk;    /**< Failed allocation number. */
-	uint64_t get_fail_objs;    /**< Objects that failed to be allocated. */
+    uint64_t put_bulk;         /**< Number of puts. */
+    uint64_t put_objs;         /**< Number of objects successfully put. */
+    uint64_t get_success_bulk; /**< Successful allocation number. */
+    uint64_t get_success_objs; /**< Objects successfully allocated. */
+    uint64_t get_fail_bulk;    /**< Failed allocation number. */
+    uint64_t get_fail_objs;    /**< Objects that failed to be allocated. */
 } __rte_cache_aligned;
 #endif
 
+__extension__
+typedef void    *MARKERT[0];   /**< generic marker for a point in a structure */
+__extension__
+typedef uint8_t  MARKERT8[0];  /**< generic marker with 1B alignment */
+__extension__
+typedef uint64_t MARKERT64[0]; /**< marker that allows us to overwrite 8 bytes
+                               * with a single assignment */
+/**
+ */
+struct rte_mbuft {
+    MARKERT cacheline0;
+
+    void *buf_addr;           /**< Virtual address of segment buffer. */
+    /**
+     * Physical address of segment buffer.
+     * Force alignment to 8-bytes, so as to ensure we have the exact
+     * same mbuf cacheline0 layout for 32-bit and 64-bit. This makes
+     * working on vector drivers easier.
+     */
+    RTE_STD_C11
+    union {
+        rte_iova_t buf_iova;
+        rte_iova_t buf_physaddr; /**< deprecated */
+    } __rte_aligned(sizeof(rte_iova_t));
+
+    /* next 8 bytes are initialised on RX descriptor rearm */
+    MARKERT64 rearm_data;
+    uint16_t data_off;
+
+    /**
+     * Reference counter. Its size should at least equal to the size
+     * of port field (16 bits), to support zero-copy broadcast.
+     * It should only be accessed using the following functions:
+     * rte_mbuf_refcnt_update(), rte_mbuf_refcnt_read(), and
+     * rte_mbuf_refcnt_set(). The functionality of these functions (atomic,
+     * or non-atomic) is controlled by the CONFIG_RTE_MBUF_REFCNT_ATOMIC
+     * config option.
+     */
+    RTE_STD_C11
+    union {
+        rte_atomic16_t refcnt_atomic; /**< Atomically accessed refcnt */
+        uint16_t refcnt;              /**< Non-atomically accessed refcnt */
+    };
+    uint16_t nb_segs;         /**< Number of segments. */
+
+    /** Input port (16 bits to support more than 256 virtual ports). */
+    uint16_t port;
+
+    uint64_t ol_flags;        /**< Offload features. */
+
+    /* remaining bytes are set on RX when pulling packet from descriptor */
+    MARKERT rx_descriptor_fields1;
+
+    /*
+     * The packet type, which is the combination of outer/inner L2, L3, L4
+     * and tunnel types. The packet_type is about data really present in the
+
+     * would have RTE_PTYPE_L2_ETHER and not RTE_PTYPE_L2_VLAN because the
+     * vlan is stripped from the data.
+     */
+    RTE_STD_C11
+    union {
+        uint32_t packet_type; /**< L2/L3/L4 and tunnel information. */
+        struct {
+            uint32_t l2_type:4; /**< (Outer) L2 type. */
+            uint32_t l3_type:4; /**< (Outer) L3 type. */
+            uint32_t l4_type:4; /**< (Outer) L4 type. */
+            uint32_t tun_type:4; /**< Tunnel type. */
+            RTE_STD_C11
+            union {
+                uint8_t inner_esp_next_proto;
+                /**< ESP next protocol type, valid if
+                 * RTE_PTYPE_TUNNEL_ESP tunnel type is set
+                 * on both Tx and Rx.
+                 */
+                __extension__
+                struct {
+                    uint8_t inner_l2_type:4;
+                    /**< Inner L2 type. */
+                    uint8_t inner_l3_type:4;
+                    /**< Inner L3 type. */
+                };
+            };
+            uint32_t inner_l4_type:4; /**< Inner L4 type. */
+        };
+    };
+
+    uint32_t pkt_len;         /**< Total pkt len: sum of all segments. */
+    uint16_t data_len;        /**< Amount of data in segment buffer. */
+    /** VLAN TCI (CPU order), valid if PKT_RX_VLAN is set. */
+    uint16_t vlan_tci;
+
+    union {
+        uint32_t rss;     /**< RSS hash result if RSS enabled */
+        struct {
+            RTE_STD_C11
+            union {
+                struct {
+                    uint16_t hash;
+                    uint16_t id;
+                };
+                uint32_t lo;
+                /**< Second 4 flexible bytes */
+            };
+            uint32_t hi;
+
+            /**< First 4 flexible bytes or FD ID, dependent on
+                 PKT_RX_FDIR_* flag in ol_flags. */
+        } fdir;           /**< Filter identifier if FDIR enabled */
+        struct {
+            uint32_t lo;
+            uint32_t hi;
+        } sched;          /**< Hierarchical scheduler */
+        uint32_t usr;      /**< User defined tags. See rte_distributor_process() */
+    } hash;                   /**< hash information */
+
+    /** Outer VLAN TCI (CPU order), valid if PKT_RX_QINQ is set. */
+    uint16_t vlan_tci_outer;
+
+    uint16_t buf_len;         /**< Length of segment buffer. */
+
+    /** Valid if PKT_RX_TIMESTAMP is set. The unit and time reference
+     * are not normalized but are always the same for a given port.
+     */
+    uint64_t timestamp;
+
+    /* second cache line - fields only used in slow path or on TX */
+    MARKERT cacheline1 __rte_cache_min_aligned;
+
+    RTE_STD_C11
+    union {
+        void *userdata;   /**< Can be used for external metadata */
+        uint64_t udata64; /**< Allow 8-byte userdata on 32-bit */
+    };
+
+    struct rte_mempool *pool; /**< Pool from which mbuf was allocated. */
+    struct rte_mbuft *next;    /**< Next segment of scattered packet. */
+
+    /* fields to support TX offloads */
+    RTE_STD_C11
+    union {
+        uint64_t tx_offload;       /**< combined for easy fetch */
+        __extension__
+        struct {
+            uint64_t l2_len:7;
+            /**< L2 (MAC) Header Length for non-tunneling pkt.
+             * Outer_L4_len + ... + Inner_L2_len for tunneling pkt.
+             */
+            uint64_t l3_len:9; /**< L3 (IP) Header Length. */
+            uint64_t l4_len:8; /**< L4 (TCP/UDP) Header Length. */
+            uint64_t tso_segsz:16; /**< TCP TSO segment size */
+
+            /* fields for TX offloading of tunnels */
+            uint64_t outer_l3_len:9; /**< Outer L3 (IP) Hdr Length. */
+            uint64_t outer_l2_len:7; /**< Outer L2 (MAC) Hdr Length. */
+
+
+            /* uint64_t unused:8; */
+        };
+    };
+
+    /** Size of the application private data. In case of an indirect
+     * mbuf, it stores the direct mbuf private data size. */
+    uint16_t priv_size;
+
+    /** Timesync flags for use with IEEE1588. */
+    uint16_t timesync;
+
+    /** Sequence number. See also rte_reorder_insert(). */
+    uint32_t seqn;
+
+    /* the following is defined by shenyifan */
+    RTE_STD_C11
+    uint8_t mbuf_state:7;
+    RTE_STD_C11
+    uint8_t priority:1;
+    uint8_t score;
+    uint16_t payload_len;
+    uint32_t tcp_seq;
+    struct rte_mbuft *buf_next;
+    RTE_STD_C11
+	union {	/**< debug info */
+		void *q_ts;
+		uint64_t mbuf_ts;	/**< used for mbuf_ts test */
+		uint64_t acount; /**< Allow 8-byte userdata on 32-bit */
+    	RTE_STD_C11
+		struct {
+			uint32_t stream_id;
+		};
+	};
+} __rte_cache_aligned;
 /**
  * A structure that stores a per-core object cache.
  */
 struct rte_mempool_cache {
-	uint32_t size;	      /**< Size of the cache */
-	uint32_t flushthresh; /**< Threshold before we flush excess elements */
-	uint32_t len;	      /**< Current cache count */
-	/*
-	 * Cache is allocated to this size to allow it to overflow in certain
-	 * cases to avoid needless emptying of cache.
-	 */
-	void *objs[RTE_MEMPOOL_CACHE_MAX_SIZE * 3]; /**< Cache objects */
+    uint32_t size;          /**< Size of the cache */
+    uint32_t flushthresh; /**< Threshold before we flush excess elements */
+    uint32_t len;          /**< Current cache count */
+    /*
+     * Cache is allocated to this size to allow it to overflow in certain
+     * cases to avoid needless emptying of cache.
+     */
+    void *objs[RTE_MEMPOOL_CACHE_MAX_SIZE * 3]; /**< Cache objects */
 } __rte_cache_aligned;
 
 /**
  * A structure that stores the size of mempool elements.
  */
 struct rte_mempool_objsz {
-	uint32_t elt_size;     /**< Size of an element. */
-	uint32_t header_size;  /**< Size of header (before elt). */
-	uint32_t trailer_size; /**< Size of trailer (after elt). */
-	uint32_t total_size;
-	/**< Total size of an object (header + elt + trailer). */
+    uint32_t elt_size;     /**< Size of an element. */
+    uint32_t header_size;  /**< Size of header (before elt). */
+    uint32_t trailer_size; /**< Size of trailer (after elt). */
+    uint32_t total_size;
+    /**< Total size of an object (header + elt + trailer). */
 };
 
 /**< Maximum length of a memory pool's name. */
 #define RTE_MEMPOOL_NAMESIZE (RTE_RING_NAMESIZE - \
-			      sizeof(RTE_MEMPOOL_MZ_PREFIX) + 1)
+                  sizeof(RTE_MEMPOOL_MZ_PREFIX) + 1)
 #define RTE_MEMPOOL_MZ_PREFIX "MP_"
 
 /* "MP_<name>" */
-#define	RTE_MEMPOOL_MZ_FORMAT	RTE_MEMPOOL_MZ_PREFIX "%s"
+#define    RTE_MEMPOOL_MZ_FORMAT    RTE_MEMPOOL_MZ_PREFIX "%s"
 
-#define	MEMPOOL_PG_SHIFT_MAX	(sizeof(uintptr_t) * CHAR_BIT - 1)
+#define    MEMPOOL_PG_SHIFT_MAX    (sizeof(uintptr_t) * CHAR_BIT - 1)
 
 /** Mempool over one chunk of physically continuous memory */
-#define	MEMPOOL_PG_NUM_DEFAULT	1
+#define    MEMPOOL_PG_NUM_DEFAULT    1
 
 #ifndef RTE_MEMPOOL_ALIGN
-#define RTE_MEMPOOL_ALIGN	RTE_CACHE_LINE_SIZE
+#define RTE_MEMPOOL_ALIGN    RTE_CACHE_LINE_SIZE
 #endif
 
-#define RTE_MEMPOOL_ALIGN_MASK	(RTE_MEMPOOL_ALIGN - 1)
+#define RTE_MEMPOOL_ALIGN_MASK    (RTE_MEMPOOL_ALIGN - 1)
 
 /**
  * Mempool object header structure
@@ -127,15 +319,15 @@ struct rte_mempool_objsz {
  * double-frees.
  */
 struct rte_mempool_objhdr {
-	STAILQ_ENTRY(rte_mempool_objhdr) next; /**< Next in list. */
-	struct rte_mempool *mp;          /**< The mempool owning the object. */
-	RTE_STD_C11
-	union {
-		rte_iova_t iova;         /**< IO address of the object. */
-		phys_addr_t physaddr;    /**< deprecated - Physical address of the object. */
-	};
+    STAILQ_ENTRY(rte_mempool_objhdr) next; /**< Next in list. */
+    struct rte_mempool *mp;          /**< The mempool owning the object. */
+    RTE_STD_C11
+    union {
+        rte_iova_t iova;         /**< IO address of the object. */
+        phys_addr_t physaddr;    /**< deprecated - Physical address of the object. */
+    };
 #ifdef RTE_LIBRTE_MEMPOOL_DEBUG
-	uint64_t cookie;                 /**< Debug cookie. */
+    uint64_t cookie;                 /**< Debug cookie. */
 #endif
 };
 
@@ -153,7 +345,7 @@ struct rte_mempool_objhdr {
  * trailer structure containing a cookie preventing memory corruptions.
  */
 struct rte_mempool_objtlr {
-	uint64_t cookie;                 /**< Debug cookie. */
+    uint64_t cookie;                 /**< Debug cookie. */
 };
 
 #endif
@@ -167,7 +359,7 @@ struct rte_mempool_objtlr {
  * Callback used to free a memory chunk
  */
 typedef void (rte_mempool_memchunk_free_cb_t)(struct rte_mempool_memhdr *memhdr,
-	void *opaque);
+    void *opaque);
 
 /**
  * Mempool objects memory header structure
@@ -176,66 +368,72 @@ typedef void (rte_mempool_memchunk_free_cb_t)(struct rte_mempool_memhdr *memhdr,
  * and physically contiguous.
  */
 struct rte_mempool_memhdr {
-	STAILQ_ENTRY(rte_mempool_memhdr) next; /**< Next in list. */
-	struct rte_mempool *mp;  /**< The mempool owning the chunk */
-	void *addr;              /**< Virtual address of the chunk */
-	RTE_STD_C11
-	union {
-		rte_iova_t iova;       /**< IO address of the chunk */
-		phys_addr_t phys_addr; /**< Physical address of the chunk */
-	};
-	size_t len;              /**< length of the chunk */
-	rte_mempool_memchunk_free_cb_t *free_cb; /**< Free callback */
-	void *opaque;            /**< Argument passed to the free callback */
+    STAILQ_ENTRY(rte_mempool_memhdr) next; /**< Next in list. */
+    struct rte_mempool *mp;  /**< The mempool owning the chunk */
+    void *addr;              /**< Virtual address of the chunk */
+    RTE_STD_C11
+    union {
+        rte_iova_t iova;       /**< IO address of the chunk */
+        phys_addr_t phys_addr; /**< Physical address of the chunk */
+    };
+    size_t len;              /**< length of the chunk */
+    rte_mempool_memchunk_free_cb_t *free_cb; /**< Free callback */
+    void *opaque;            /**< Argument passed to the free callback */
 };
 
 /**
  * The RTE mempool structure.
  */
 struct rte_mempool {
-	/*
-	 * Note: this field kept the RTE_MEMZONE_NAMESIZE size due to ABI
-	 * compatibility requirements, it could be changed to
-	 * RTE_MEMPOOL_NAMESIZE next time the ABI changes
-	 */
-	char name[RTE_MEMZONE_NAMESIZE]; /**< Name of mempool. */
-	RTE_STD_C11
-	union {
-		void *pool_data;         /**< Ring or pool to store objects. */
-		uint64_t pool_id;        /**< External mempool identifier. */
-	};
-	void *pool_config;               /**< optional args for ops alloc. */
-	const struct rte_memzone *mz;    /**< Memzone where pool is alloc'd. */
-	unsigned int flags;              /**< Flags of the mempool. */
-	int socket_id;                   /**< Socket id passed at create. */
-	uint32_t size;                   /**< Max size of the mempool. */
-	uint32_t cache_size;
-	/**< Size of per-lcore default local cache. */
-
-	uint32_t elt_size;               /**< Size of an element. */
-	uint32_t header_size;            /**< Size of header (before elt). */
-	uint32_t trailer_size;           /**< Size of trailer (after elt). */
-
-	unsigned private_data_size;      /**< Size of private data. */
-	/**
-	 * Index into rte_mempool_ops_table array of mempool ops
-	 * structs, which contain callback function pointers.
-	 * We're using an index here rather than pointers to the callbacks
-	 * to facilitate any secondary processes that may want to use
-	 * this mempool.
-	 */
-	int32_t ops_index;
-
-	struct rte_mempool_cache *local_cache; /**< Per-lcore local cache */
-
-	uint32_t populated_size;         /**< Number of populated objects. */
-	struct rte_mempool_objhdr_list elt_list; /**< List of objects in pool */
-	uint32_t nb_mem_chunks;          /**< Number of memory chunks */
-	struct rte_mempool_memhdr_list mem_list; /**< List of memory chunks */
+    /*
+     * Note: this field kept the RTE_MEMZONE_NAMESIZE size due to ABI
+     * compatibility requirements, it could be changed to
+     * RTE_MEMPOOL_NAMESIZE next time the ABI changes
+     */
+    char name[RTE_MEMZONE_NAMESIZE]; /**< Name of mempool. */
+    RTE_STD_C11
+    union {
+        void *pool_data;         /**< Ring or pool to store objects. */
+        uint64_t pool_id;        /**< External mempool identifier. */
+    };
+    void *pool_config;               /**< optional args for ops alloc. */
+    const struct rte_memzone *mz;    /**< Memzone where pool is alloc'd. */
+    unsigned int flags;              /**< Flags of the mempool. */
+    int socket_id;                   /**< Socket id passed at create. */
+    int private_type;
+	int core_id;
+    int ring_num;
+    uint32_t size;                   /**< Max size of the mempool. */
+    uint32_t cache_size;
+    /**< Size of per-lcore default local cache. */
+
+    uint32_t elt_size;               /**< Size of an element. */
+    uint32_t header_size;            /**< Size of header (before elt). */
+    uint32_t trailer_size;           /**< Size of trailer (after elt). */
+
+    unsigned private_data_size;      /**< Size of private data. */
+    /**
+     * Index into rte_mempool_ops_table array of mempool ops
+     * structs, which contain callback function pointers.
+     * We're using an index here rather than pointers to the callbacks
+     * to facilitate any secondary processes that may want to use
+     * this mempool.
+     */
+    int32_t ops_index;
+
+    struct rte_mempool_cache *local_cache; /**< Per-lcore local cache */
+   
+    struct rte_circular_queue *local_ring[32];  /**< Per-lcore local ring */
+    
+
+    uint32_t populated_size;         /**< Number of populated objects. */
+    struct rte_mempool_objhdr_list elt_list; /**< List of objects in pool */
+    uint32_t nb_mem_chunks;          /**< Number of memory chunks */
+    struct rte_mempool_memhdr_list mem_list; /**< List of memory chunks */
 
 #ifdef RTE_LIBRTE_MEMPOOL_DEBUG
-	/** Per-lcore statistics. */
-	struct rte_mempool_debug_stats stats[RTE_MAX_LCORE];
+    /** Per-lcore statistics. */
+    struct rte_mempool_debug_stats stats[RTE_MAX_LCORE];
 #endif
 }  __rte_cache_aligned;
 
@@ -276,12 +474,12 @@ struct rte_mempool {
  */
 #ifdef RTE_LIBRTE_MEMPOOL_DEBUG
 #define __MEMPOOL_STAT_ADD(mp, name, n) do {                    \
-		unsigned __lcore_id = rte_lcore_id();           \
-		if (__lcore_id < RTE_MAX_LCORE) {               \
-			mp->stats[__lcore_id].name##_objs += n;	\
-			mp->stats[__lcore_id].name##_bulk += 1;	\
-		}                                               \
-	} while(0)
+        unsigned __lcore_id = rte_lcore_id();           \
+        if (__lcore_id < RTE_MAX_LCORE) {               \
+            mp->stats[__lcore_id].name##_objs += n;    \
+            mp->stats[__lcore_id].name##_bulk += 1;    \
+        }                                               \
+    } while(0)
 #else
 #define __MEMPOOL_STAT_ADD(mp, name, n) do {} while(0)
 #endif
@@ -295,14 +493,14 @@ struct rte_mempool {
  *   Size of the per-lcore cache.
  */
 #define MEMPOOL_HEADER_SIZE(mp, cs) \
-	(sizeof(*(mp)) + (((cs) == 0) ? 0 : \
-	(sizeof(struct rte_mempool_cache) * RTE_MAX_LCORE)))
+    (sizeof(*(mp)) + (((cs) == 0) ? 0 : \
+    (sizeof(struct rte_mempool_cache) * RTE_MAX_LCORE)))
 
 /* return the header of a mempool object (internal) */
 static inline struct rte_mempool_objhdr *__mempool_get_header(void *obj)
 {
-	return (struct rte_mempool_objhdr *)RTE_PTR_SUB(obj,
-		sizeof(struct rte_mempool_objhdr));
+    return (struct rte_mempool_objhdr *)RTE_PTR_SUB(obj,
+        sizeof(struct rte_mempool_objhdr));
 }
 
 /**
@@ -316,15 +514,15 @@ static inline struct rte_mempool_objhdr *__mempool_get_header(void *obj)
  */
 static inline struct rte_mempool *rte_mempool_from_obj(void *obj)
 {
-	struct rte_mempool_objhdr *hdr = __mempool_get_header(obj);
-	return hdr->mp;
+    struct rte_mempool_objhdr *hdr = __mempool_get_header(obj);
+    return hdr->mp;
 }
 
 /* return the trailer of a mempool object (internal) */
 static inline struct rte_mempool_objtlr *__mempool_get_trailer(void *obj)
 {
-	struct rte_mempool *mp = rte_mempool_from_obj(obj);
-	return (struct rte_mempool_objtlr *)RTE_PTR_ADD(obj, mp->elt_size);
+    struct rte_mempool *mp = rte_mempool_from_obj(obj);
+    return (struct rte_mempool_objtlr *)RTE_PTR_ADD(obj, mp->elt_size);
 }
 
 /**
@@ -342,11 +540,11 @@ static inline struct rte_mempool_objtlr *__mempool_get_trailer(void *obj)
  *   - 2: just check that cookie is valid (free or allocated)
  */
 void rte_mempool_check_cookies(const struct rte_mempool *mp,
-	void * const *obj_table_const, unsigned n, int free);
+    void * const *obj_table_const, unsigned n, int free);
 
 #ifdef RTE_LIBRTE_MEMPOOL_DEBUG
 #define __mempool_check_cookies(mp, obj_table_const, n, free) \
-	rte_mempool_check_cookies(mp, obj_table_const, n, free)
+    rte_mempool_check_cookies(mp, obj_table_const, n, free)
 #else
 #define __mempool_check_cookies(mp, obj_table_const, n, free) do {} while(0)
 #endif /* RTE_LIBRTE_MEMPOOL_DEBUG */
@@ -374,13 +572,13 @@ void rte_mempool_check_cookies(const struct rte_mempool *mp,
  * Enqueue an object into the external pool.
  */
 typedef int (*rte_mempool_enqueue_t)(struct rte_mempool *mp,
-		void * const *obj_table, unsigned int n);
+        void * const *obj_table, unsigned int n);
 
 /**
  * Dequeue an object from the external pool.
  */
 typedef int (*rte_mempool_dequeue_t)(struct rte_mempool *mp,
-		void **obj_table, unsigned int n);
+        void **obj_table, unsigned int n);
 
 /**
  * Return the number of available objects in the external pool.
@@ -391,7 +589,7 @@ typedef int (*rte_mempool_dequeue_t)(struct rte_mempool *mp,
  * Get the mempool capabilities.
  */
 typedef int (*rte_mempool_get_capabilities_t)(const struct rte_mempool *mp,
-		unsigned int *flags);
+        unsigned int *flags);
 
 /**
  * Notify new memory area to mempool.
@@ -401,20 +599,20 @@ typedef int (*rte_mempool_ops_register_memory_area_t)
 
 /** Structure defining mempool operations structure */
 struct rte_mempool_ops {
-	char name[RTE_MEMPOOL_OPS_NAMESIZE]; /**< Name of mempool ops struct. */
-	rte_mempool_alloc_t alloc;       /**< Allocate private data. */
-	rte_mempool_free_t free;         /**< Free the external pool. */
-	rte_mempool_enqueue_t enqueue;   /**< Enqueue an object. */
-	rte_mempool_dequeue_t dequeue;   /**< Dequeue an object. */
-	rte_mempool_get_count get_count; /**< Get qty of available objs. */
-	/**
-	 * Get the mempool capabilities
-	 */
-	rte_mempool_get_capabilities_t get_capabilities;
-	/**
-	 * Notify new memory area to mempool
-	 */
-	rte_mempool_ops_register_memory_area_t register_memory_area;
+    char name[RTE_MEMPOOL_OPS_NAMESIZE]; /**< Name of mempool ops struct. */
+    rte_mempool_alloc_t alloc;       /**< Allocate private data. */
+    rte_mempool_free_t free;         /**< Free the external pool. */
+    rte_mempool_enqueue_t enqueue;   /**< Enqueue an object. */
+    rte_mempool_dequeue_t dequeue;   /**< Dequeue an object. */
+    rte_mempool_get_count get_count; /**< Get qty of available objs. */
+    /**
+     * Get the mempool capabilities
+     */
+    rte_mempool_get_capabilities_t get_capabilities;
+    /**
+     * Notify new memory area to mempool
+     */
+    rte_mempool_ops_register_memory_area_t register_memory_area;
 } __rte_cache_aligned;
 
 #define RTE_MEMPOOL_MAX_OPS_IDX 16  /**< Max registered ops structs */
@@ -429,12 +627,12 @@ struct rte_mempool_ops {
  * This results in us simply having "ops_index" in the mempool struct.
  */
 struct rte_mempool_ops_table {
-	rte_spinlock_t sl;     /**< Spinlock for add/delete. */
-	uint32_t num_ops;      /**< Number of used ops structs in the table. */
-	/**
-	 * Storage for all possible ops structs.
-	 */
-	struct rte_mempool_ops ops[RTE_MEMPOOL_MAX_OPS_IDX];
+    rte_spinlock_t sl;     /**< Spinlock for add/delete. */
+    uint32_t num_ops;      /**< Number of used ops structs in the table. */
+    /**
+     * Storage for all possible ops structs.
+     */
+    struct rte_mempool_ops ops[RTE_MEMPOOL_MAX_OPS_IDX];
 } __rte_cache_aligned;
 
 /** Array of registered ops structs. */
@@ -452,9 +650,9 @@ struct rte_mempool_ops_table {
 static inline struct rte_mempool_ops *
 rte_mempool_get_ops(int ops_index)
 {
-	RTE_VERIFY((ops_index >= 0) && (ops_index < RTE_MEMPOOL_MAX_OPS_IDX));
+    RTE_VERIFY((ops_index >= 0) && (ops_index < RTE_MEMPOOL_MAX_OPS_IDX));
 
-	return &rte_mempool_ops_table.ops[ops_index];
+    return &rte_mempool_ops_table.ops[ops_index];
 }
 
 /**
@@ -484,12 +682,12 @@ struct rte_mempool_ops_table {
  */
 static inline int
 rte_mempool_ops_dequeue_bulk(struct rte_mempool *mp,
-		void **obj_table, unsigned n)
+        void **obj_table, unsigned n)
 {
-	struct rte_mempool_ops *ops;
+    struct rte_mempool_ops *ops;
 
-	ops = rte_mempool_get_ops(mp->ops_index);
-	return ops->dequeue(mp, obj_table, n);
+    ops = rte_mempool_get_ops(mp->ops_index);
+    return ops->dequeue(mp, obj_table, n);
 }
 
 /**
@@ -507,12 +705,26 @@ struct rte_mempool_ops_table {
  */
 static inline int
 rte_mempool_ops_enqueue_bulk(struct rte_mempool *mp, void * const *obj_table,
-		unsigned n)
+        unsigned n)
 {
-	struct rte_mempool_ops *ops;
-
-	ops = rte_mempool_get_ops(mp->ops_index);
-	return ops->enqueue(mp, obj_table, n);
+    struct rte_mempool_ops *ops;
+
+    ops = rte_mempool_get_ops(mp->ops_index);
+#if 0
+	struct rte_mbuft *t;
+	unsigned int i = 0;
+	if(mp->private_type == 2){
+		for(i = 0; i < n;i++){
+			t = (struct rte_mbuft *)obj_table[i];
+//			t->free_t++;
+			if(t->free_t > t->alloc_t)
+			{
+				RTE_LOG(INFO, EAL,"mp->name is %s and t->udata64 is %ld   \n",mp->name,t->udata64);
+			}
+		}
+	}
+#endif
+    return ops->enqueue(mp, obj_table, n);
 }
 
 /**
@@ -541,7 +753,7 @@ struct rte_mempool_ops_table {
  */
 int
 rte_mempool_ops_get_capabilities(const struct rte_mempool *mp,
-					unsigned int *flags);
+                    unsigned int *flags);
 /**
  * @internal wrapper for mempool_ops register_memory_area callback.
  * API to notify the mempool handler when a new memory area is added to pool.
@@ -561,7 +773,7 @@ struct rte_mempool_ops_table {
  */
 int
 rte_mempool_ops_register_memory_area(const struct rte_mempool *mp,
-				char *vaddr, rte_iova_t iova, size_t len);
+                char *vaddr, rte_iova_t iova, size_t len);
 
 /**
  * @internal wrapper for mempool_ops free callback.
@@ -591,7 +803,7 @@ struct rte_mempool_ops_table {
  */
 int
 rte_mempool_set_ops_byname(struct rte_mempool *mp, const char *name,
-		void *pool_config);
+        void *pool_config);
 
 /**
  * Register mempool operations.
@@ -610,12 +822,12 @@ struct rte_mempool_ops_table {
  * Note that the rte_mempool_register_ops fails silently here when
  * more than RTE_MEMPOOL_MAX_OPS_IDX is registered.
  */
-#define MEMPOOL_REGISTER_OPS(ops)					\
-	void mp_hdlr_init_##ops(void);					\
-	void __attribute__((constructor, used)) mp_hdlr_init_##ops(void)\
-	{								\
-		rte_mempool_register_ops(&ops);			\
-	}
+#define MEMPOOL_REGISTER_OPS(ops)                    \
+    void mp_hdlr_init_##ops(void);                    \
+    void __attribute__((constructor, used)) mp_hdlr_init_##ops(void)\
+    {                                \
+        rte_mempool_register_ops(&ops);            \
+    }
 
 /**
  * An object callback function for mempool.
@@ -623,7 +835,7 @@ struct rte_mempool_ops_table {
  * Used by rte_mempool_create() and rte_mempool_obj_iter().
  */
 typedef void (rte_mempool_obj_cb_t)(struct rte_mempool *mp,
-		void *opaque, void *obj, unsigned obj_idx);
+        void *opaque, void *obj, unsigned obj_idx);
 typedef rte_mempool_obj_cb_t rte_mempool_obj_ctor_t; /* compat */
 
 /**
@@ -632,8 +844,8 @@ typedef void (rte_mempool_obj_cb_t)(struct rte_mempool *mp,
  * Used by rte_mempool_mem_iter().
  */
 typedef void (rte_mempool_mem_cb_t)(struct rte_mempool *mp,
-		void *opaque, struct rte_mempool_memhdr *memhdr,
-		unsigned mem_idx);
+        void *opaque, struct rte_mempool_memhdr *memhdr,
+        unsigned mem_idx);
 
 /**
  * A mempool constructor callback function.
@@ -724,10 +936,10 @@ typedef void (rte_mempool_mem_cb_t)(struct rte_mempool *mp,
  */
 struct rte_mempool *
 rte_mempool_create(const char *name, unsigned n, unsigned elt_size,
-		   unsigned cache_size, unsigned private_data_size,
-		   rte_mempool_ctor_t *mp_init, void *mp_init_arg,
-		   rte_mempool_obj_cb_t *obj_init, void *obj_init_arg,
-		   int socket_id, unsigned flags);
+           unsigned cache_size, unsigned private_data_size,
+           rte_mempool_ctor_t *mp_init, void *mp_init_arg,
+           rte_mempool_obj_cb_t *obj_init, void *obj_init_arg,
+           int socket_id, unsigned flags);
 
 /**
  * Create a new mempool named *name* in memory.
@@ -789,11 +1001,11 @@ struct rte_mempool *
  */
 struct rte_mempool *
 rte_mempool_xmem_create(const char *name, unsigned n, unsigned elt_size,
-		unsigned cache_size, unsigned private_data_size,
-		rte_mempool_ctor_t *mp_init, void *mp_init_arg,
-		rte_mempool_obj_cb_t *obj_init, void *obj_init_arg,
-		int socket_id, unsigned flags, void *vaddr,
-		const rte_iova_t iova[], uint32_t pg_num, uint32_t pg_shift);
+        unsigned cache_size, unsigned private_data_size,
+        rte_mempool_ctor_t *mp_init, void *mp_init_arg,
+        rte_mempool_obj_cb_t *obj_init, void *obj_init_arg,
+        int socket_id, unsigned flags, void *vaddr,
+        const rte_iova_t iova[], uint32_t pg_num, uint32_t pg_shift);
 
 /**
  * Create an empty mempool
@@ -831,8 +1043,8 @@ struct rte_mempool *
  */
 struct rte_mempool *
 rte_mempool_create_empty(const char *name, unsigned n, unsigned elt_size,
-	unsigned cache_size, unsigned private_data_size,
-	int socket_id, unsigned flags);
+    unsigned cache_size, unsigned private_data_size,
+    int socket_id, unsigned flags);
 /**
  * Free a mempool
  *
@@ -874,13 +1086,13 @@ struct rte_mempool *
  *   mempool and a negative errno is returned.
  */
 int rte_mempool_populate_iova(struct rte_mempool *mp, char *vaddr,
-	rte_iova_t iova, size_t len, rte_mempool_memchunk_free_cb_t *free_cb,
-	void *opaque);
+    rte_iova_t iova, size_t len, rte_mempool_memchunk_free_cb_t *free_cb,
+    void *opaque);
 
 __rte_deprecated
 int rte_mempool_populate_phys(struct rte_mempool *mp, char *vaddr,
-	phys_addr_t paddr, size_t len, rte_mempool_memchunk_free_cb_t *free_cb,
-	void *opaque);
+    phys_addr_t paddr, size_t len, rte_mempool_memchunk_free_cb_t *free_cb,
+    void *opaque);
 
 /**
  * Add physical memory for objects in the pool at init
@@ -909,13 +1121,13 @@ int rte_mempool_populate_phys(struct rte_mempool *mp, char *vaddr,
  *   mempool and a negative errno is returned.
  */
 int rte_mempool_populate_iova_tab(struct rte_mempool *mp, char *vaddr,
-	const rte_iova_t iova[], uint32_t pg_num, uint32_t pg_shift,
-	rte_mempool_memchunk_free_cb_t *free_cb, void *opaque);
+    const rte_iova_t iova[], uint32_t pg_num, uint32_t pg_shift,
+    rte_mempool_memchunk_free_cb_t *free_cb, void *opaque);
 
 __rte_deprecated
 int rte_mempool_populate_phys_tab(struct rte_mempool *mp, char *vaddr,
-	const phys_addr_t paddr[], uint32_t pg_num, uint32_t pg_shift,
-	rte_mempool_memchunk_free_cb_t *free_cb, void *opaque);
+    const phys_addr_t paddr[], uint32_t pg_num, uint32_t pg_shift,
+    rte_mempool_memchunk_free_cb_t *free_cb, void *opaque);
 
 /**
  * Add virtually contiguous memory for objects in the pool at init
@@ -943,8 +1155,8 @@ int rte_mempool_populate_phys_tab(struct rte_mempool *mp, char *vaddr,
  */
 int
 rte_mempool_populate_virt(struct rte_mempool *mp, char *addr,
-	size_t len, size_t pg_sz, rte_mempool_memchunk_free_cb_t *free_cb,
-	void *opaque);
+    size_t len, size_t pg_sz, rte_mempool_memchunk_free_cb_t *free_cb,
+    void *opaque);
 
 /**
  * Add memory for objects in the pool at init
@@ -992,7 +1204,7 @@ int rte_mempool_populate_phys_tab(struct rte_mempool *mp, char *vaddr,
  *   Number of objects iterated.
  */
 uint32_t rte_mempool_obj_iter(struct rte_mempool *mp,
-	rte_mempool_obj_cb_t *obj_cb, void *obj_cb_arg);
+    rte_mempool_obj_cb_t *obj_cb, void *obj_cb_arg);
 
 /**
  * Call a function for each mempool memory chunk
@@ -1010,7 +1222,7 @@ uint32_t rte_mempool_obj_iter(struct rte_mempool *mp,
  *   Number of memory chunks iterated.
  */
 uint32_t rte_mempool_mem_iter(struct rte_mempool *mp,
-	rte_mempool_mem_cb_t *mem_cb, void *mem_cb_arg);
+    rte_mempool_mem_cb_t *mem_cb, void *mem_cb_arg);
 
 /**
  * Dump the status of the mempool to a file.
@@ -1058,10 +1270,10 @@ struct rte_mempool_cache *
  */
 static __rte_always_inline void
 rte_mempool_cache_flush(struct rte_mempool_cache *cache,
-			struct rte_mempool *mp)
+            struct rte_mempool *mp)
 {
-	rte_mempool_ops_enqueue_bulk(mp, cache->objs, cache->len);
-	cache->len = 0;
+    rte_mempool_ops_enqueue_bulk(mp, cache->objs, cache->len);
+    cache->len = 0;
 }
 
 /**
@@ -1077,13 +1289,13 @@ struct rte_mempool_cache *
 static __rte_always_inline struct rte_mempool_cache *
 rte_mempool_default_cache(struct rte_mempool *mp, unsigned lcore_id)
 {
-	if (mp->cache_size == 0)
-		return NULL;
+    if (mp->cache_size == 0)
+        return NULL;
 
-	if (lcore_id >= RTE_MAX_LCORE)
-		return NULL;
+    if (lcore_id >= RTE_MAX_LCORE)
+        return NULL;
 
-	return &mp->local_cache[lcore_id];
+    return &mp->local_cache[lcore_id];
 }
 
 /**
@@ -1100,47 +1312,47 @@ struct rte_mempool_cache *
  */
 static __rte_always_inline void
 __mempool_generic_put(struct rte_mempool *mp, void * const *obj_table,
-		      unsigned int n, struct rte_mempool_cache *cache)
+              unsigned int n, struct rte_mempool_cache *cache)
 {
-	void **cache_objs;
+    void **cache_objs;
 
-	/* increment stat now, adding in mempool always success */
-	__MEMPOOL_STAT_ADD(mp, put, n);
+    /* increment stat now, adding in mempool always success */
+    __MEMPOOL_STAT_ADD(mp, put, n);
 
-	/* No cache provided or if put would overflow mem allocated for cache */
-	if (unlikely(cache == NULL || n > RTE_MEMPOOL_CACHE_MAX_SIZE))
-		goto ring_enqueue;
+    /* No cache provided or if put would overflow mem allocated for cache */
+    if (unlikely(cache == NULL || n > RTE_MEMPOOL_CACHE_MAX_SIZE))
+        goto ring_enqueue;
 
-	cache_objs = &cache->objs[cache->len];
+    cache_objs = &cache->objs[cache->len];
 
-	/*
-	 * The cache follows the following algorithm
-	 *   1. Add the objects to the cache
-	 *   2. Anything greater than the cache min value (if it crosses the
-	 *   cache flush threshold) is flushed to the ring.
-	 */
+    /*
+     * The cache follows the following algorithm
+     *   1. Add the objects to the cache
+     *   2. Anything greater than the cache min value (if it crosses the
+     *   cache flush threshold) is flushed to the ring.
+     */
 
-	/* Add elements back into the cache */
-	rte_memcpy(&cache_objs[0], obj_table, sizeof(void *) * n);
+    /* Add elements back into the cache */
+    rte_memcpy(&cache_objs[0], obj_table, sizeof(void *) * n);
 
-	cache->len += n;
+    cache->len += n;
 
-	if (cache->len >= cache->flushthresh) {
-		rte_mempool_ops_enqueue_bulk(mp, &cache->objs[cache->size],
-				cache->len - cache->size);
-		cache->len = cache->size;
-	}
+    if (cache->len >= cache->flushthresh) {
+        rte_mempool_ops_enqueue_bulk(mp, &cache->objs[cache->size],
+                cache->len - cache->size);
+        cache->len = cache->size;
+    }
 
-	return;
+    return;
 
 ring_enqueue:
 
-	/* push remaining objects in ring */
+    /* push remaining objects in ring */
 #ifdef RTE_LIBRTE_MEMPOOL_DEBUG
-	if (rte_mempool_ops_enqueue_bulk(mp, obj_table, n) < 0)
-		rte_panic("cannot put objects in mempool\n");
+    if (rte_mempool_ops_enqueue_bulk(mp, obj_table, n) < 0)
+        rte_panic("cannot put objects in mempool\n");
 #else
-	rte_mempool_ops_enqueue_bulk(mp, obj_table, n);
+    rte_mempool_ops_enqueue_bulk(mp, obj_table, n);
 #endif
 }
 
@@ -1159,10 +1371,22 @@ struct rte_mempool_cache *
  */
 static __rte_always_inline void
 rte_mempool_generic_put(struct rte_mempool *mp, void * const *obj_table,
-			unsigned int n, struct rte_mempool_cache *cache)
+            unsigned int n, struct rte_mempool_cache *cache)
 {
-	__mempool_check_cookies(mp, obj_table, n, 0);
-	__mempool_generic_put(mp, obj_table, n, cache);
+#if 0
+	struct rte_mbuft *t;
+	unsigned int i = 0;
+	if(mp->private_type == 2){
+		for(i = 0; i < n;i++){
+			t = (struct rte_mbuft *)obj_table[i];
+			if(t->udata64 == 2 ) {
+				rte_exit(EXIT_FAILURE,"get a wrong packet pkt in rte_mempool_put and mp->name is %s \n ",mp->name);
+			}
+		}
+	}
+#endif
+    __mempool_check_cookies(mp, obj_table, n, 0);
+    __mempool_generic_put(mp, obj_table, n, cache);
 }
 
 /**
@@ -1181,11 +1405,12 @@ struct rte_mempool_cache *
  */
 static __rte_always_inline void
 rte_mempool_put_bulk(struct rte_mempool *mp, void * const *obj_table,
-		     unsigned int n)
+             unsigned int n)
 {
-	struct rte_mempool_cache *cache;
-	cache = rte_mempool_default_cache(mp, rte_lcore_id());
-	rte_mempool_generic_put(mp, obj_table, n, cache);
+
+    struct rte_mempool_cache *cache;
+    cache = rte_mempool_default_cache(mp, rte_lcore_id());
+    rte_mempool_generic_put(mp, obj_table, n, cache);
 }
 
 /**
@@ -1203,7 +1428,14 @@ struct rte_mempool_cache *
 static __rte_always_inline void
 rte_mempool_put(struct rte_mempool *mp, void *obj)
 {
-	rte_mempool_put_bulk(mp, &obj, 1);
+#if 0
+	struct rte_mbuft *t ;
+	t = (struct rte_mbuft*)obj;
+	if(t->udata64 == 2 ) {
+		rte_exit(EXIT_FAILURE,"get a wrong packet pkt in rte_mempool_put and mp->name is %s \n ",mp->name);
+	}
+#endif
+    rte_mempool_put_bulk(mp, &obj, 1);
 }
 
 /**
@@ -1222,60 +1454,60 @@ struct rte_mempool_cache *
  */
 static __rte_always_inline int
 __mempool_generic_get(struct rte_mempool *mp, void **obj_table,
-		      unsigned int n, struct rte_mempool_cache *cache)
+              unsigned int n, struct rte_mempool_cache *cache)
 {
-	int ret;
-	uint32_t index, len;
-	void **cache_objs;
-
-	/* No cache provided or cannot be satisfied from cache */
-	if (unlikely(cache == NULL || n >= cache->size))
-		goto ring_dequeue;
-
-	cache_objs = cache->objs;
-
-	/* Can this be satisfied from the cache? */
-	if (cache->len < n) {
-		/* No. Backfill the cache first, and then fill from it */
-		uint32_t req = n + (cache->size - cache->len);
-
-		/* How many do we require i.e. number to fill the cache + the request */
-		ret = rte_mempool_ops_dequeue_bulk(mp,
-			&cache->objs[cache->len], req);
-		if (unlikely(ret < 0)) {
-			/*
-			 * In the offchance that we are buffer constrained,
-			 * where we are not able to allocate cache + n, go to
-			 * the ring directly. If that fails, we are truly out of
-			 * buffers.
-			 */
-			goto ring_dequeue;
-		}
+    int ret;
+    uint32_t index, len;
+    void **cache_objs;
 
-		cache->len += req;
-	}
+    /* No cache provided or cannot be satisfied from cache */
+    if (unlikely(cache == NULL || n >= cache->size))
+        goto ring_dequeue;
+
+    cache_objs = cache->objs;
 
-	/* Now fill in the response ... */
-	for (index = 0, len = cache->len - 1; index < n; ++index, len--, obj_table++)
-		*obj_table = cache_objs[len];
+    /* Can this be satisfied from the cache? */
+    if (cache->len < n) {
+        /* No. Backfill the cache first, and then fill from it */
+        uint32_t req = n + (cache->size - cache->len);
 
-	cache->len -= n;
+        /* How many do we require i.e. number to fill the cache + the request */
+        ret = rte_mempool_ops_dequeue_bulk(mp,
+            &cache->objs[cache->len], req);
+        if (unlikely(ret < 0)) {
+            /*
+             * In the offchance that we are buffer constrained,
+             * where we are not able to allocate cache + n, go to
+             * the ring directly. If that fails, we are truly out of
+             * buffers.
+             */
+            goto ring_dequeue;
+        }
 
-	__MEMPOOL_STAT_ADD(mp, get_success, n);
+        cache->len += req;
+    }
 
-	return 0;
+    /* Now fill in the response ... */
+    for (index = 0, len = cache->len - 1; index < n; ++index, len--, obj_table++)
+        *obj_table = cache_objs[len];
+
+    cache->len -= n;
+
+    __MEMPOOL_STAT_ADD(mp, get_success, n);
+
+    return 0;
 
 ring_dequeue:
 
-	/* get remaining objects from ring */
-	ret = rte_mempool_ops_dequeue_bulk(mp, obj_table, n);
+    /* get remaining objects from ring */
+    ret = rte_mempool_ops_dequeue_bulk(mp, obj_table, n);
 
-	if (ret < 0)
-		__MEMPOOL_STAT_ADD(mp, get_fail, n);
-	else
-		__MEMPOOL_STAT_ADD(mp, get_success, n);
+    if (ret < 0)
+        __MEMPOOL_STAT_ADD(mp, get_fail, n);
+    else
+        __MEMPOOL_STAT_ADD(mp, get_success, n);
 
-	return ret;
+    return ret;
 }
 
 /**
@@ -1300,13 +1532,13 @@ struct rte_mempool_cache *
  */
 static __rte_always_inline int
 rte_mempool_generic_get(struct rte_mempool *mp, void **obj_table,
-			unsigned int n, struct rte_mempool_cache *cache)
+            unsigned int n, struct rte_mempool_cache *cache)
 {
-	int ret;
-	ret = __mempool_generic_get(mp, obj_table, n, cache);
-	if (ret == 0)
-		__mempool_check_cookies(mp, obj_table, n, 1);
-	return ret;
+    int ret;
+    ret = __mempool_generic_get(mp, obj_table, n, cache);
+    if (ret == 0)
+        __mempool_check_cookies(mp, obj_table, n, 1);
+    return ret;
 }
 
 /**
@@ -1334,9 +1566,29 @@ struct rte_mempool_cache *
 static __rte_always_inline int
 rte_mempool_get_bulk(struct rte_mempool *mp, void **obj_table, unsigned int n)
 {
-	struct rte_mempool_cache *cache;
-	cache = rte_mempool_default_cache(mp, rte_lcore_id());
-	return rte_mempool_generic_get(mp, obj_table, n, cache);
+
+    struct rte_mempool_cache *cache;
+    struct rte_circular_queue *ring;
+    int i;
+    int ring_num = mp->ring_num;
+    unsigned core_id;
+    core_id = rte_lcore_id(); 
+    cache = rte_mempool_default_cache(mp, core_id);
+
+    if(mp->private_type == 1)
+    {
+        for(i = 0;i < ring_num ;i++)
+        {
+            ring = mp->local_ring[i];
+            if(rte_cirq_count(ring) > n)
+            {
+                return rte_cirq_get_bulk(ring,obj_table,n);
+            }
+        }
+    }
+    
+    return rte_mempool_generic_get(mp, obj_table, n, cache);
+
 }
 
 /**
@@ -1362,7 +1614,8 @@ struct rte_mempool_cache *
 static __rte_always_inline int
 rte_mempool_get(struct rte_mempool *mp, void **obj_p)
 {
-	return rte_mempool_get_bulk(mp, obj_p, 1);
+
+    return rte_mempool_get_bulk(mp, obj_p, 1);
 }
 
 /**
@@ -1410,7 +1663,7 @@ struct rte_mempool_cache *
 static inline int
 rte_mempool_full(const struct rte_mempool *mp)
 {
-	return !!(rte_mempool_avail_count(mp) == mp->size);
+    return !!(rte_mempool_avail_count(mp) == mp->size);
 }
 
 /**
@@ -1429,7 +1682,7 @@ struct rte_mempool_cache *
 static inline int
 rte_mempool_empty(const struct rte_mempool *mp)
 {
-	return !!(rte_mempool_avail_count(mp) == 0);
+    return !!(rte_mempool_avail_count(mp) == 0);
 }
 
 /**
@@ -1445,17 +1698,17 @@ struct rte_mempool_cache *
 static inline rte_iova_t
 rte_mempool_virt2iova(const void *elt)
 {
-	const struct rte_mempool_objhdr *hdr;
-	hdr = (const struct rte_mempool_objhdr *)RTE_PTR_SUB(elt,
-		sizeof(*hdr));
-	return hdr->iova;
+    const struct rte_mempool_objhdr *hdr;
+    hdr = (const struct rte_mempool_objhdr *)RTE_PTR_SUB(elt,
+        sizeof(*hdr));
+    return hdr->iova;
 }
 
 __rte_deprecated
 static inline phys_addr_t
 rte_mempool_virt2phy(__rte_unused const struct rte_mempool *mp, const void *elt)
 {
-	return rte_mempool_virt2iova(elt);
+    return rte_mempool_virt2iova(elt);
 }
 
 /**
@@ -1480,8 +1733,8 @@ struct rte_mempool_cache *
  */
 static inline void *rte_mempool_get_priv(struct rte_mempool *mp)
 {
-	return (char *)mp +
-		MEMPOOL_HEADER_SIZE(mp, mp->cache_size);
+    return (char *)mp +
+        MEMPOOL_HEADER_SIZE(mp, mp->cache_size);
 }
 
 /**
@@ -1524,7 +1777,7 @@ static inline void *rte_mempool_get_priv(struct rte_mempool *mp)
  *   Total size of the mempool object.
  */
 uint32_t rte_mempool_calc_obj_size(uint32_t elt_size, uint32_t flags,
-	struct rte_mempool_objsz *sz);
+    struct rte_mempool_objsz *sz);
 
 /**
  * Get the size of memory required to store mempool elements.
@@ -1550,7 +1803,7 @@ uint32_t rte_mempool_calc_obj_size(uint32_t elt_size, uint32_t flags,
  *   Required memory size aligned at page boundary.
  */
 size_t rte_mempool_xmem_size(uint32_t elt_num, size_t total_elt_sz,
-	uint32_t pg_shift, unsigned int flags);
+    uint32_t pg_shift, unsigned int flags);
 
 /**
  * Get the size of memory required to store mempool elements.
@@ -1581,8 +1834,8 @@ size_t rte_mempool_xmem_size(uint32_t elt_num, size_t total_elt_sz,
  *   is the actual number of elements that can be stored in that buffer.
  */
 ssize_t rte_mempool_xmem_usage(void *vaddr, uint32_t elt_num,
-	size_t total_elt_sz, const rte_iova_t iova[], uint32_t pg_num,
-	uint32_t pg_shift, unsigned int flags);
+    size_t total_elt_sz, const rte_iova_t iova[], uint32_t pg_num,
+    uint32_t pg_shift, unsigned int flags);
 
 /**
  * Walk list of all memory pools
@@ -1593,7 +1846,7 @@ ssize_t rte_mempool_xmem_usage(void *vaddr, uint32_t elt_num,
  *   Argument passed to iterator
  */
 void rte_mempool_walk(void (*func)(struct rte_mempool *, void *arg),
-		      void *arg);
+              void *arg);
 
 #ifdef __cplusplus
 }
diff --git a/mk/rte.app.mk b/mk/rte.app.mk
index 0b00104..268a2af 100644
--- a/mk/rte.app.mk
+++ b/mk/rte.app.mk
@@ -316,6 +316,10 @@ O_TO_EXE = $(LD) -o $@ $(OBJS-y) \
 	$(LDLIBS) $(LDFLAGS) $(LDFLAGS_$(@)) $(EXTRA_LDFLAGS) \
 	$(MAPFLAGS)
 endif
+#the follow three lines was added by shenyifan
+$(shell if [ ! -d ${RTE_SDK}/${RTE_TARGET}/lib ]; then mkdir ${RTE_SDK}/${RTE_TARGET}/lib; fi)
+LINKER_FLAGS = $(call linkerprefix,$(LDLIBS))
+$(shell echo ${LINKER_FLAGS} > ${RTE_SDK}/${RTE_TARGET}/lib/ldflags.txt)
 O_TO_EXE_STR = $(subst ','\'',$(O_TO_EXE)) #'# fix syntax highlight
 O_TO_EXE_DISP = $(if $(V),"$(O_TO_EXE_STR)","  LD $(@)")
 O_TO_EXE_CMD = "cmd_$@ = $(O_TO_EXE_STR)"
diff --git a/mk/rte.cpuflags.mk b/mk/rte.cpuflags.mk
index 6071313..b399b99 100644
--- a/mk/rte.cpuflags.mk
+++ b/mk/rte.cpuflags.mk
@@ -113,3 +113,5 @@ space:= $(empty) $(empty)
 CPUFLAGSTMP1 := $(addprefix RTE_CPUFLAG_,$(CPUFLAGS))
 CPUFLAGSTMP2 := $(subst $(space),$(comma),$(CPUFLAGSTMP1))
 CPUFLAGS_LIST := -DRTE_COMPILE_TIME_CPUFLAGS=$(CPUFLAGSTMP2)
+#$(shell echo ${MACHINE_CFLAGS} > /home/shenyifan/cflags.txt)
+$(shell echo ${MACHINE_CFLAGS} > ${RTE_SDK}/${RTE_TARGET}/include/cflags.txt)
diff --git a/usertools/dpdk-setup.sh b/usertools/dpdk-setup.sh
index 5eebbce..158c4dd 100755
--- a/usertools/dpdk-setup.sh
+++ b/usertools/dpdk-setup.sh
@@ -11,6 +11,7 @@
 #
 cd $(dirname ${BASH_SOURCE[0]})/..
 export RTE_SDK=$PWD
+export RTE_TARGET=x86_64-native-linuxapp-gcc
 echo "------------------------------------------------------------------------------"
 echo " RTE_SDK exported as $RTE_SDK"
 echo "------------------------------------------------------------------------------"
@@ -76,7 +77,7 @@ setup_target()
 		fi
 	fi
 	if [ "$QUIT" == "0" ] ; then
-		make install T=${RTE_TARGET}
+		make install T=${RTE_TARGET}  -j10
 	fi
 	echo "------------------------------------------------------------------------------"
 	echo " RTE_TARGET exported as $RTE_TARGET"
